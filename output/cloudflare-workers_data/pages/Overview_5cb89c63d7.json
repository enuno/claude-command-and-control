{
  "title": "Overview",
  "content": "Preview URLs allow you to preview new versions of your Worker without deploying it to production.\n\nThere are two types of preview URLs:\n\n* **Versioned Preview URLs**: A unique URL generated automatically for each new version of your Worker.\n* **Aliased Preview URLs**: A static, human-readable alias that you can manually assign to a Worker version.\n\nBoth preview URL types follow the format: `<VERSION_PREFIX OR ALIAS>-<WORKER_NAME>.<SUBDOMAIN>.workers.dev`.\n\n* Integrated into CI/CD pipelines, allowing automatic generation of preview environments for every pull request.\n* Used for collaboration between teams to test code changes in a live environment and verify updates.\n* Used to test new API endpoints, validate data formats, and ensure backward compatibility with existing services.\n\nWhen testing zone level performance or security features for a version, we recommend using [version overrides](https://developers.cloudflare.com/workers/configuration/versions-and-deployments/gradual-deployments/#version-overrides) so that your zone's performance and security settings apply.\n\nPreview URLs are only available for Worker versions uploaded after 2024-09-25.\n\n## Types of Preview URLs\n\n### Versioned Preview URLs\n\nEvery time you create a new [version](https://developers.cloudflare.com/workers/configuration/versions-and-deployments/#versions) of your Worker, a unique static version preview URL is generated automatically. These URLs use a version prefix and follow the format `<VERSION_PREFIX>-<WORKER_NAME>.<SUBDOMAIN>.workers.dev`.\n\nNew versions of a Worker are created when you run:\n\n* [`wrangler deploy`](https://developers.cloudflare.com/workers/wrangler/commands/#deploy)\n* [`wrangler versions upload`](https://developers.cloudflare.com/workers/wrangler/commands/#versions-upload)\n* Or when you make edits via the Cloudflare dashboard\n\nIf Preview URLs have been enabled, they are public and available immediately after version creation.\n\nMinimum required Wrangler version: 3.74.0. Check your version by running `wrangler --version`. To update Wrangler, refer to [Install/Update Wrangler](https://developers.cloudflare.com/workers/wrangler/install-and-update/).\n\n#### View versioned preview URLs using Wrangler\n\nThe [`wrangler versions upload`](https://developers.cloudflare.com/workers/wrangler/commands/#versions-upload) command uploads a new [version](https://developers.cloudflare.com/workers/configuration/versions-and-deployments/#versions) of your Worker and returns a preview URL for each version uploaded.\n\n#### View versioned preview URLs on the Workers dashboard\n\n1. In the Cloudflare dashboard, go to the **Workers & Pages** page.\n\n[Go to **Workers & Pages**](https://dash.cloudflare.com/?to=/:account/workers-and-pages)\n\n2. Select your Worker.\n\n3. Go to the **Deployments** tab, and find the version you would like to view.\n\n### Aliased preview URLs\n\nAliased preview URLs let you assign a persistent, readable alias to a specific Worker version. These are useful for linking to stable previews across many versions (e.g. to share an upcoming but still actively being developed new feature). A common workflow would be to assign an alias for the branch that you're working on. These types of preview URLs follow the same pattern as other preview URLs: `<ALIAS>-<WORKER_NAME>.<SUBDOMAIN>.workers.dev`\n\nMinimum required Wrangler version: `4.21.0`. Check your version by running `wrangler --version`. To update Wrangler, refer to [Install/Update Wrangler](https://developers.cloudflare.com/workers/wrangler/install-and-update/).\n\nAliases may be created during `versions upload`, by providing the `--preview-alias` flag with a valid alias name:\n\nThe resulting alias would be associated with this version, and immediately available at: `staging-<WORKER_NAME>.<SUBDOMAIN>.workers.dev`\n\n#### Rules and limitations\n\n* Aliases may only be created during version upload.\n* Aliases must use only lowercase letters, numbers, and dashes.\n* Aliases must begin with a lowercase letter.\n* The alias and Worker name combined (with a dash) must not exceed 63 characters due to DNS label limits.\n* Only the 1000 most recently deployed aliases are retained. When a new alias is created beyond this limit, the least recently deployed alias is deleted.\n\n## Manage access to Preview URLs\n\nWhen enabled, all preview URLs are available publicly. You can use [Cloudflare Access](https://developers.cloudflare.com/cloudflare-one/access-controls/policies/) to require visitors to authenticate before accessing preview URLs. You can limit access to yourself, your teammates, your organization, or anyone else you specify in your [access policy](https://developers.cloudflare.com/cloudflare-one/access-controls/policies/).\n\nTo limit your preview URLs to authorized emails only:\n\n1. In the Cloudflare dashboard, go to the **Workers & Pages** page.\n\n[Go to **Workers & Pages**](https://dash.cloudflare.com/?to=/:account/workers-and-pages)\n\n2. In **Overview**, select your Worker.\n\n3. Go to **Settings** > **Domains & Routes**.\n\n4. For Preview URLs, click **Enable Cloudflare Access**.\n\n5. Optionally, to configure the Access application, click **Manage Cloudflare Access**. There, you can change the email addresses you want to authorize. View [Access policies](https://developers.cloudflare.com/cloudflare-one/access-controls/policies/#selectors) to learn about configuring alternate rules.\n\n6. [Validate the Access JWT](https://developers.cloudflare.com/cloudflare-one/access-controls/applications/http-apps/authorization-cookie/validating-json/#cloudflare-workers-example) in your Worker script using the audience (`aud`) tag and JWKs URL provided.\n\n## Toggle Preview URLs (Enable or Disable)\n\n* Preview URLs are enabled by default when `workers_dev` is enabled.\n* Preview URLs are disabled by default when `workers_dev` is disabled.\n* Disabling Preview URLs will disable routing to both versioned and aliased preview URLs.\n\n### From the Dashboard\n\nTo toggle Preview URLs for a Worker:\n\n1. In the Cloudflare dashboard, go to the **Workers & Pages** page.\n\n[Go to **Workers & Pages**](https://dash.cloudflare.com/?to=/:account/workers-and-pages)\n\n2. In **Overview**, select your Worker.\n\n3. Go to **Settings** > **Domains & Routes**.\n\n4. For Preview URLs, click **Enable** or **Disable**.\n\n5. Confirm your action.\n\n### From the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/)\n\nWrangler 3.91.0 or higher is required to use this feature.\n\nOlder Wrangler versions will default to Preview URLs being enabled.\n\nTo toggle Preview URLs for a Worker, include any of the following in your Worker's Wrangler file:\n\nIf not given, `preview_urls = workers_dev` is the default.\n\nIf you enable or disable Preview URLs in the Cloudflare dashboard, but do not update your Worker's Wrangler file accordingly, the Preview URLs status will change the next time you deploy your Worker with Wrangler.\n\n* Preview URLs are not generated for Workers that implement a [Durable Object](https://developers.cloudflare.com/durable-objects/).\n* Preview URLs are not currently generated for [Workers for Platforms](https://developers.cloudflare.com/cloudflare-for-platforms/workers-for-platforms/) [user Workers](https://developers.cloudflare.com/cloudflare-for-platforms/workers-for-platforms/how-workers-for-platforms-works/#user-workers). This is a temporary limitation, we are working to remove it.\n* You cannot currently configure Preview URLs to run on a subdomain other than [`workers.dev`](https://developers.cloudflare.com/workers/configuration/routing/workers-dev/).\n* You cannot view logs for Preview URLs today, this includes Workers Logs, Wrangler tail and Logpush.\n\n<page>\n---\ntitle: Routes and domains · Cloudflare Workers docs\ndescription: Connect your Worker to an external endpoint (via Routes, Custom\n  Domains or a `workers.dev` subdomain) such that it can be accessed by the\n  Internet.\nlastUpdated: 2024-11-04T16:38:55.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/configuration/routing/\n  md: https://developers.cloudflare.com/workers/configuration/routing/index.md\n---\n\nTo allow a Worker to receive inbound HTTP requests, you must connect it to an external endpoint such that it can be accessed by the Internet.\n\nThere are three types of routes:\n\n* [Custom Domains](https://developers.cloudflare.com/workers/configuration/routing/custom-domains): Routes to a domain or subdomain (such as `example.com` or `shop.example.com`) within a Cloudflare zone where the Worker is the origin.\n\n* [Routes](https://developers.cloudflare.com/workers/configuration/routing/routes/): Routes that are set within a Cloudflare zone where your origin server, if you have one, is behind a Worker that the Worker can communicate with.\n\n* [`workers.dev`](https://developers.cloudflare.com/workers/configuration/routing/workers-dev/): A `workers.dev` subdomain route is automatically created for each Worker to help you getting started quickly. You may choose to [disable](https://developers.cloudflare.com/workers/configuration/routing/workers-dev/) your `workers.dev` subdomain.\n\n## What is best for me?\n\nIt's recommended to run production Workers on a [Workers route or custom domain](https://developers.cloudflare.com/workers/configuration/routing/), rather than on your `workers.dev` subdomain. Your `workers.dev` subdomain is treated as a [Free website](https://www.cloudflare.com/plans/) and is intended for personal or hobby projects that aren't business-critical.\n\nCustom Domains are recommended for use cases where your Worker is your application's origin server. Custom Domains can also be invoked within the same zone via `fetch()`, unlike Routes.\n\nRoutes are recommended for use cases where your application's origin server is external to Cloudflare. Note that Routes cannot be the target of a same-zone `fetch()` call.\n\n<page>\n---\ntitle: Secrets · Cloudflare Workers docs\ndescription: Store sensitive information, like API keys and auth tokens, in your Worker.\nlastUpdated: 2025-12-30T07:16:34.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/configuration/secrets/\n  md: https://developers.cloudflare.com/workers/configuration/secrets/index.md\n---\n\nSecrets are a type of binding that allow you to attach encrypted text values to your Worker. Secrets are used for storing sensitive information like API keys and auth tokens.\n\nYou can access secrets in your Worker code through:\n\n* The [`env` parameter](https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch/#parameters) passed to your Worker's [`fetch` event handler](https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch/).\n* Importing `env` from [`cloudflare:workers`](https://developers.cloudflare.com/workers/runtime-apis/bindings/#importing-env-as-a-global) to access secrets from anywhere in your code.\n* [`process.env`](https://developers.cloudflare.com/workers/configuration/environment-variables) in Workers that have [Node.js compatibility](https://developers.cloudflare.com/workers/runtime-apis/nodejs/) enabled.\n\n## Access your secrets with Workers\n\nSecrets can be accessed from Workers as you would any other [environment variables](https://developers.cloudflare.com/workers/configuration/environment-variables/). For instance, given a `DB_CONNECTION_STRING` secret, you can access it in your Worker code through the `env` parameter:\n\nYou can also import `env` from `cloudflare:workers` to access secrets from anywhere in your code, including outside of request handlers:\n\nFor more details on accessing `env` globally, refer to [Importing `env` as a global](https://developers.cloudflare.com/workers/runtime-apis/bindings/#importing-env-as-a-global).\n\nSecrets described on this page are defined and managed on a per-Worker level. If you want to use account-level secrets, refer to [Secrets Store](https://developers.cloudflare.com/secrets-store/). Account-level secrets are configured on your Worker as a [Secrets Store binding](https://developers.cloudflare.com/secrets-store/integrations/workers/).\n\n## Local Development with Secrets\n\nDo not use `vars` to store sensitive information in your Worker's Wrangler configuration file. Use secrets instead.\n\nPut secrets for use in local development in either a `.dev.vars` file or a `.env` file, in the same directory as the Wrangler configuration file.\n\nChoose to use either `.dev.vars` or `.env` but not both. If you define a `.dev.vars` file, then values in `.env` files will not be included in the `env` object during local development.\n\nThese files should be formatted using the [dotenv](https://hexdocs.pm/dotenvy/dotenv-file-format.html) syntax. For example:\n\nDo not commit secrets to git\n\nThe `.dev.vars` and `.env` files should not committed to git. Add `.dev.vars*` and `.env*` to your project's `.gitignore` file.\n\nTo set different secrets for each Cloudflare environment, create files named `.dev.vars.<environment-name>` or `.env.<environment-name>`.\n\nWhen you select a Cloudflare environment in your local development, the corresponding environment-specific file will be loaded ahead of the generic `.dev.vars` (or `.env`) file.\n\n* When using `.dev.vars.<environment-name>` files, all secrets must be defined per environment. If `.dev.vars.<environment-name>` exists then only this will be loaded; the `.dev.vars` file will not be loaded.\n\n* In contrast, all matching `.env` files are loaded and the values are merged. For each variable, the value from the most specific file is used, with the following precedence:\n\n* `.env.<environment-name>.local` (most specific)\n  * `.env.local`\n  * `.env.<environment-name>`\n  * `.env` (least specific)\n\nControlling `.env` handling\n\nIt is possible to control how `.env` files are loaded in local development by setting environment variables on the process running the tools.\n\n* To disable loading local dev vars from `.env` files without providing a `.dev.vars` file, set the `CLOUDFLARE_LOAD_DEV_VARS_FROM_DOT_ENV` environment variable to `\"false\"`.\n* To include every environment variable defined in your system's process environment as a local development variable, ensure there is no `.dev.vars` and then set the `CLOUDFLARE_INCLUDE_PROCESS_ENV` environment variable to `\"true\"`.\n\n## Secrets on deployed Workers\n\n### Adding secrets to your project\n\nSecrets can be added through [`wrangler secret put`](https://developers.cloudflare.com/workers/wrangler/commands/#secret) or [`wrangler versions secret put`](https://developers.cloudflare.com/workers/wrangler/commands/#versions-secret-put) commands.\n\n`wrangler secret put` creates a new version of the Worker and deploys it immediately.\n\nIf using [gradual deployments](https://developers.cloudflare.com/workers/configuration/versions-and-deployments/gradual-deployments/), instead use the `wrangler versions secret put` command. This will only create a new version of the Worker, that can then be deploying using [`wrangler versions deploy`](https://developers.cloudflare.com/workers/wrangler/commands/#versions-deploy).\n\nWrangler versions before 3.73.0 require you to specify a `--x-versions` flag.\n\n#### Via the dashboard\n\nTo add a secret via the dashboard:\n\n1. In the Cloudflare dashboard, go to the **Workers & Pages** page.\n\n[Go to **Workers & Pages**](https://dash.cloudflare.com/?to=/:account/workers-and-pages)\n\n2. In **Overview**, select your Worker > **Settings**.\n\n3. Under **Variables and Secrets**, select **Add**.\n\n4. Select the type **Secret**, input a **Variable name**, and input its **Value**. This secret will be made available to your Worker but the value will be hidden in Wrangler and the dashboard.\n\n5. (Optional) To add more secrets, select **Add variable**.\n\n6. Select **Deploy** to implement your changes.\n\n### Delete secrets from your project\n\nSecrets can be deleted through [`wrangler secret delete`](https://developers.cloudflare.com/workers/wrangler/commands/#secret-delete) or [`wrangler versions secret delete`](https://developers.cloudflare.com/workers/wrangler/commands/#versions-secret-delete) commands.\n\n`wrangler secret delete` creates a new version of the Worker and deploys it immediately.\n\nIf using [gradual deployments](https://developers.cloudflare.com/workers/configuration/versions-and-deployments/gradual-deployments/), instead use the `wrangler versions secret delete` command. This will only create a new version of the Worker, that can then be deploying using [`wrangler versions deploy`](https://developers.cloudflare.com/workers/wrangler/commands/#versions-deploy).\n\n#### Via the dashboard\n\nTo delete a secret from your Worker project via the dashboard:\n\n1. In the Cloudflare dashboard, go to the **Workers & Pages** page.\n\n[Go to **Workers & Pages**](https://dash.cloudflare.com/?to=/:account/workers-and-pages)\n\n2. In **Overview**, select your Worker > **Settings**.\n\n3. Under **Variables and Secrets**, select **Edit**.\n\n4. In the **Edit** drawer, select **X** next to the secret you want to delete.\n\n5. Select **Deploy** to implement your changes.\n\n6. (Optional) Instead of using the edit drawer, you can click the delete icon next to the secret.\n\n## Compare secrets and environment variables\n\nUse secrets for sensitive information\n\nDo not use plaintext environment variables to store sensitive information. Use [secrets](https://developers.cloudflare.com/workers/configuration/secrets/) or [Secrets Store bindings](https://developers.cloudflare.com/secrets-store/integrations/workers/) instead.\n\n[Secrets](https://developers.cloudflare.com/workers/configuration/secrets/) are [environment variables](https://developers.cloudflare.com/workers/configuration/environment-variables/). The difference is secret values are not visible within Wrangler or Cloudflare dashboard after you define them. This means that sensitive data, including passwords or API tokens, should always be encrypted to prevent data leaks. To your Worker, there is no difference between an environment variable and a secret. The secret's value is passed through as defined.\n\n* [Wrangler secret commands](https://developers.cloudflare.com/workers/wrangler/commands/#secret) - Review the Wrangler commands to create, delete and list secrets.\n* [Cloudflare Secrets Store](https://developers.cloudflare.com/secrets-store/) - Encrypt and store sensitive information as secrets that are securely reusable across your account.\n\n<page>\n---\ntitle: Workers Sites · Cloudflare Workers docs\ndescription: Use [Workers Static Assets](/workers/static-assets/) to host\n  full-stack applications instead of Workers Sites. Do not use Workers Sites for\n  new projects.\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/configuration/sites/\n  md: https://developers.cloudflare.com/workers/configuration/sites/index.md\n---\n\nUse Workers Static Assets Instead\n\nYou should use [Workers Static Assets](https://developers.cloudflare.com/workers/static-assets/) to host full-stack applications instead of Workers Sites. It has been deprecated in Wrangler v4, and the [Cloudflare Vite plugin](https://developers.cloudflare.com/workers/vite-plugin/) does not support Workers Sites. Do not use Workers Sites for new projects.\n\nWorkers Sites enables developers to deploy static applications directly to Workers. It can be used for deploying applications built with static site generators like [Hugo](https://gohugo.io) and [Gatsby](https://www.gatsbyjs.org), or front-end frameworks like [Vue](https://vuejs.org) and [React](https://reactjs.org).\n\nTo deploy with Workers Sites, select from one of these three approaches depending on the state of your target project:\n\n## 1. Start from scratch\n\nIf you are ready to start a brand new project, this quick start guide will help you set up the infrastructure to deploy a HTML website to Workers.\n\n[Start from scratch](https://developers.cloudflare.com/workers/configuration/sites/start-from-scratch/)\n\n## 2. Deploy an existing static site\n\nIf you have an existing project or static assets that you want to deploy with Workers, this quick start guide will help you install Wrangler and configure Workers Sites for your project.\n\n[Start from an existing static site](https://developers.cloudflare.com/workers/configuration/sites/start-from-existing/)\n\n## 3. Add static assets to an existing Workers project\n\nIf you already have a Worker deployed to Cloudflare, this quick start guide will show you how to configure the existing codebase to use Workers Sites.\n\n[Start from an existing Worker](https://developers.cloudflare.com/workers/configuration/sites/start-from-worker/)\n\nWorkers Sites is built on Workers KV, and usage rates may apply. Refer to [Pricing](https://developers.cloudflare.com/workers/platform/pricing/) to learn more.\n\n<page>\n---\ntitle: Smart Placement · Cloudflare Workers docs\ndescription: Speed up your Worker application by automatically placing your\n  workloads in an optimal location that minimizes latency.\nlastUpdated: 2025-09-08T17:05:16.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/configuration/smart-placement/\n  md: https://developers.cloudflare.com/workers/configuration/smart-placement/index.md\n---\n\nBy default, [Workers](https://developers.cloudflare.com/workers/) and [Pages Functions](https://developers.cloudflare.com/pages/functions/) are invoked in a data center closest to where the request was received. If you are running back-end logic in a Worker, it may be more performant to run that Worker closer to your back-end infrastructure rather than the end user. Smart Placement automatically places your workloads in an optimal location that minimizes latency and speeds up your applications.\n\nThe following example demonstrates how moving your Worker close to your back-end services could decrease application latency:\n\nYou have a user in Sydney, Australia who is accessing an application running on Workers. This application makes multiple round trips to a database located in Frankfurt, Germany in order to serve the user’s request.\n\n![A user located in Sydney, AU connecting to a Worker in the same region which then makes multiple round trips to a database located in Frankfurt, DE. ](https://developers.cloudflare.com/_astro/workers-smart-placement-disabled.CgvAE24H_ZlRB8R.webp)\n\nThe issue is the time that it takes the Worker to perform multiple round trips to the database. Instead of the request being processed close to the user, the Cloudflare network, with Smart Placement enabled, would process the request in a data center closest to the database.\n\n![A user located in Sydney, AU connecting to a Worker in Frankfurt, DE which then makes multiple round trips to a database also located in Frankfurt, DE. ](https://developers.cloudflare.com/_astro/workers-smart-placement-enabled.D6RN33at_20sSCa.webp)\n\n## Understand how Smart Placement works\n\nSmart Placement is enabled on a per-Worker basis. Once enabled, Smart Placement analyzes the [request duration](https://developers.cloudflare.com/workers/observability/metrics-and-analytics/#request-duration) of the Worker in different Cloudflare locations around the world on a regular basis. Smart Placement decides where to run the Worker by comparing the estimated request duration in the location closest to where the request was received (the default location where the Worker would run) to a set of candidate locations around the world. For each candidate location, Smart Placement considers the performance of the Worker in that location as well as the network latency added by forwarding the request to that location. If the estimated request duration in the best candidate location is significantly faster than the location where the request was received, the request will be forwarded to that candidate location. Otherwise, the Worker will run in the default location closest to where the request was received.\n\nSmart Placement only considers candidate locations where the Worker has previously run, since the estimated request duration in each candidate location is based on historical data from the Worker running in that location. This means that Smart Placement cannot run the Worker in a location that it does not normally receive traffic from.\n\nSmart Placement only affects the execution of [fetch event handlers](https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch/). Smart Placement does not affect the execution of [RPC methods](https://developers.cloudflare.com/workers/runtime-apis/rpc/) or [named entrypoints](https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings/rpc/#named-entrypoints). Workers without a fetch event handler will be ignored by Smart Placement. For Workers with both fetch and non-fetch event handlers, Smart Placement will only affect the execution of the fetch event handler.\n\nSimilarly, Smart Placement will not affect where [static assets](https://developers.cloudflare.com/workers/static-assets/) are served from. Static assets will continue to be served from the location nearest to the incoming request. If a Worker is invoked and your code retrieves assets via the [static assets binding](https://developers.cloudflare.com/workers/static-assets/binding/), then assets will be served from the location that your Worker runs in.\n\n## Enable Smart Placement\n\nSmart Placement is available to users on all Workers plans.\n\n### Enable Smart Placement via Wrangler\n\nTo enable Smart Placement via Wrangler:\n\n1. Make sure that you have `wrangler@2.20.0` or later [installed](https://developers.cloudflare.com/workers/wrangler/install-and-update/).\n\n2. Add the following to your Worker project's Wrangler file:\n\n3. Wait for Smart Placement to analyze your Worker. This process may take up to 15 minutes.\n\n4. View your Worker's [request duration analytics](https://developers.cloudflare.com/workers/observability/metrics-and-analytics/#request-duration).\n\n### Enable Smart Placement via the dashboard\n\nTo enable Smart Placement via the dashboard:\n\n1. In the Cloudflare dashboard, go to the **Workers & Pages** page.\n\n[Go to **Workers & Pages**](https://dash.cloudflare.com/?to=/:account/workers-and-pages)\n\n2. In **Overview**,select your Worker.\n\n3. Select **Settings** > **General**.\n\n4. Under **Placement**, choose **Smart**.\n\n5. Wait for Smart Placement to analyze your Worker. Smart Placement requires consistent traffic to the Worker from multiple locations around the world to make a placement decision. The analysis process may take up to 15 minutes.\n\n6. View your Worker's [request duration analytics](https://developers.cloudflare.com/workers/observability/metrics-and-analytics/#request-duration)\n\nA Worker's metadata contains details about a Worker's placement status. Query your Worker's placement status through the following Workers API endpoint:\n\nPossible placement states include:\n\n* *(not present)*: The Worker has not been analyzed for Smart Placement yet. The Worker will always run in the default Cloudflare location closest to where the request was received.\n* `SUCCESS`: The Worker was successfully analyzed and will be optimized by Smart Placement. The Worker will run in the Cloudflare location that minimizes expected request duration, which may be the default location closest to where the request was received or may be a faster location elsewhere in the world.\n* `INSUFFICIENT_INVOCATIONS`: The Worker has not received enough requests to make a placement decision. Smart Placement requires consistent traffic to the Worker from multiple locations around the world. The Worker will always run in the default Cloudflare location closest to where the request was received.\n* `UNSUPPORTED_APPLICATION`: Smart Placement began optimizing the Worker and measured the results, which showed that Smart Placement made the Worker slower. In response, Smart Placement reverted the placement decision. The Worker will always run in the default Cloudflare location closest to where the request was received, and Smart Placement will not analyze the Worker again until it's redeployed. This state is rare and accounts for less that 1% of Workers with Smart Placement enabled.\n\n### Request Duration Analytics\n\nOnce Smart Placement is enabled, data about request duration gets collected. Request duration is measured at the data center closest to the end user.\n\nBy default, one percent (1%) of requests are not routed with Smart Placement. These requests serve as a baseline to compare to.\n\n### `cf-placement` header\n\nOnce Smart Placement is enabled, Cloudflare adds a `cf-placement` header to all requests. This can be used to check whether a request has been routed with Smart Placement and where the Worker is processing the request (which is shown as the nearest airport code to the data center).\n\nFor example, the `cf-placement: remote-LHR` header's `remote` value indicates that the request was routed using Smart Placement to a Cloudflare data center near London. The `cf-placement: local-EWR` header's `local` value indicates that the request was not routed using Smart Placement and the Worker was invoked in a data center closest to where the request was received, close to Newark Liberty International Airport (EWR).\n\nWe may remove the `cf-placement` header before Smart Placement enters general availability.\n\nIf you are building full-stack applications on Workers, we recommend splitting up the front-end and back-end logic into different Workers and using [Service Bindings](https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings/) to connect your front-end logic and back-end logic Workers.\n\n![Smart Placement and Service Bindings](https://developers.cloudflare.com/_astro/smart-placement-service-bindings.Ce58BYeF_1YYSoG.webp)\n\nEnabling Smart Placement on your back-end Worker will invoke it close to your back-end service, while the front-end Worker serves requests close to the user. This architecture maintains fast, reactive front-ends while also improving latency when the back-end Worker is called.\n\n## Give feedback on Smart Placement\n\nSmart Placement is in beta. To share your thoughts and experience with Smart Placement, join the [Cloudflare Developer Discord](https://discord.cloudflare.com).\n\n<page>\n---\ntitle: Versions & Deployments · Cloudflare Workers docs\ndescription: Upload versions of Workers and create deployments to release new versions.\nlastUpdated: 2025-10-22T21:56:17.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/configuration/versions-and-deployments/\n  md: https://developers.cloudflare.com/workers/configuration/versions-and-deployments/index.md\n---\n\nVersions track changes to your Worker. Deployments configure how those changes are deployed to your traffic.\n\nYou can upload changes (versions) to your Worker independent of changing the version that is actively serving traffic (deployment).\n\n![Versions and Deployments](https://developers.cloudflare.com/_astro/versions-and-deployments.Dnwtp7bX_AGXxo.webp)\n\nUsing versions and deployments is useful if:\n\n* You are running critical applications on Workers and want to reduce risk when deploying new versions of your Worker using a rolling deployment strategy.\n* You want to monitor for performance differences when deploying new versions of your Worker.\n* You have a CI/CD pipeline configured for Workers but want to cut manual releases.\n\nA version is defined by the state of code as well as the state of configuration in a Worker's [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). Versions track historical changes to [bundled code](https://developers.cloudflare.com/workers/wrangler/bundling/), [static assets](https://developers.cloudflare.com/workers/static-assets/) and changes to configuration like [bindings](https://developers.cloudflare.com/workers/runtime-apis/bindings/) and [compatibility date and compatibility flags](https://developers.cloudflare.com/workers/configuration/compatibility-dates/) over time.\n\nVersions also track metadata associated with a version, including: the version ID, the user that created the version, deploy source, and timestamp. Optionally, a version message and version tag can be configured on version upload.\n\nState changes for associated Workers [storage resources](https://developers.cloudflare.com/workers/platform/storage-options/) such as [KV](https://developers.cloudflare.com/kv/), [R2](https://developers.cloudflare.com/r2/), [Durable Objects](https://developers.cloudflare.com/durable-objects/) and [D1](https://developers.cloudflare.com/d1/) are not tracked with versions.\n\nDeployments track the version(s) of your Worker that are actively serving traffic. A deployment can consist of one or two versions of a Worker.\n\nBy default, Workers supports an all-at-once deployment model where traffic is immediately shifted from one version to the newly deployed version automatically. Alternatively, you can use [gradual deployments](https://developers.cloudflare.com/workers/configuration/versions-and-deployments/gradual-deployments/) to create a rolling deployment strategy.\n\nYou can also track metadata associated with a deployment, including: the user that created the deployment, deploy source, timestamp and the version(s) in the deployment. Optionally, you can configure a deployment message when you create a deployment.\n\n## Use versions and deployments\n\n### Create a new version\n\nReview the different ways you can create versions of your Worker and deploy them.\n\n#### Upload a new version and deploy it immediately\n\nA new version that is automatically deployed to 100% of traffic when:\n\n* Changes are uploaded with [`wrangler deploy`](https://developers.cloudflare.com/workers/wrangler/commands/#deploy) via the Cloudflare Dashboard\n* Changes are deployed with the command [`npx wrangler deploy`](https://developers.cloudflare.com/workers/wrangler/commands/#deploy) via [Workers Builds](https://developers.cloudflare.com/workers/ci-cd/builds)\n* Changes are uploaded with the [Workers Script Upload API](https://developers.cloudflare.com/api/resources/workers/subresources/scripts/methods/update/)\n\n#### Upload a new version to be gradually deployed or deployed at a later time\n\nWrangler versions before 3.73.0 require you to specify a `--x-versions` flag.\n\nTo create a new version of your Worker that is not deployed immediately, use the [`wrangler versions upload`](https://developers.cloudflare.com/workers/wrangler/commands/#versions-upload) command or create a new version via the Cloudflare dashboard using the **Save** button. You can find the **Save** option under the down arrow beside the \"Deploy\" button.\n\nVersions created in this way can then be deployed all at once or gradually deployed using the [`wrangler versions deploy`](https://developers.cloudflare.com/workers/wrangler/commands/#versions-deploy) command or via the Cloudflare dashboard under the **Deployments** tab.\n\nWhen using [Wrangler](https://developers.cloudflare.com/workers/wrangler/), changes made to a Worker's triggers [routes, domains](https://developers.cloudflare.com/workers/configuration/routing/) or [cron triggers](https://developers.cloudflare.com/workers/configuration/cron-triggers/) need to be applied with the command [`wrangler triggers deploy`](https://developers.cloudflare.com/workers/wrangler/commands/#triggers).\n\nNew versions are not created when you make changes to [resources connected to your Worker](https://developers.cloudflare.com/workers/runtime-apis/bindings/). For example, if two Workers (Worker A and Worker B) are connected via a [service binding](https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings/), changing the code of Worker B will not create a new version of Worker A. Changing the code of Worker B will only create a new version of Worker B. Changes to the service binding (such as, deleting the binding or updating the [environment](https://developers.cloudflare.com/workers/wrangler/environments/) it points to) on Worker A will also not create a new version of Worker B.\n\n#### Directly manage Versions and Deployments\n\nSee examples of creating a Worker, Versions, and Deployments directly with the API, library SDKs, and Terraform in [Infrastructure as Code](https://developers.cloudflare.com/workers/platform/infrastructure-as-code/).\n\n### View versions and deployments\n\nWrangler allows you to view the 100 most recent versions and deployments. Refer to the [`versions list`](https://developers.cloudflare.com/workers/wrangler/commands/#list-4) and [`deployments`](https://developers.cloudflare.com/workers/wrangler/commands/#list-5) documentation to view the commands.\n\n#### Via the Cloudflare dashboard\n\nTo view your deployments in the Cloudflare dashboard:\n\n1. In the Cloudflare dashboard, go to the **Workers & Pages** page.\n\n[Go to **Workers & Pages**](https://dash.cloudflare.com/?to=/:account/workers-and-pages)\n\n2. Select your Worker > **Deployments**.\n\nYou must use [C3](https://developers.cloudflare.com/workers/get-started/guide/#1-create-a-new-worker-project) or [`wrangler deploy`](https://developers.cloudflare.com/workers/wrangler/commands/#deploy) the first time you create a new Workers project. Using [`wrangler versions upload`](https://developers.cloudflare.com/workers/wrangler/commands/#versions-upload) the first time you upload a Worker will fail.\n\n### Service worker syntax\n\nService worker syntax is not supported for versions that are uploaded through [`wrangler versions upload`](https://developers.cloudflare.com/workers/wrangler/commands/#versions-upload). You must use ES modules format.\n\nRefer to [Migrate from Service Workers to ES modules](https://developers.cloudflare.com/workers/reference/migrate-to-module-workers/#advantages-of-migrating) to learn how to migrate your Workers from the service worker format to the ES modules format.\n\n### Durable Object migrations\n\nUploading a version with [Durable Object migrations](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/) is not supported. Use [`wrangler deploy`](https://developers.cloudflare.com/workers/wrangler/commands/#deploy) if you are applying a [Durable Object migration](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/).\n\nThis will be supported in the near future.\n\n<page>\n---\ntitle: Page Rules with Workers · Cloudflare Workers docs\ndescription: Review the interaction between various Page Rules and Workers.\nlastUpdated: 2025-09-15T16:47:39.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/configuration/workers-with-page-rules/\n  md: https://developers.cloudflare.com/workers/configuration/workers-with-page-rules/index.md\n---\n\nPage Rules trigger certain actions whenever a request matches one of the URL patterns you define. You can define a page rule to trigger one or more actions whenever a certain URL pattern is matched. Refer to [Page Rules](https://developers.cloudflare.com/rules/page-rules/) to learn more about configuring Page Rules.\n\n## Page Rules with Workers\n\nCloudflare acts as a [reverse proxy](https://www.cloudflare.com/learning/what-is-cloudflare/) to provide services, like Page Rules, to Internet properties. Your application's traffic will pass through a Cloudflare data center that is closest to the visitor. There are hundreds of these around the world, each of which are capable of running services like Workers and Page Rules. If your application is built on Workers and/or Pages, the [Cloudflare global network](https://www.cloudflare.com/learning/serverless/glossary/what-is-edge-computing/) acts as your origin server and responds to requests directly from the Cloudflare global network.\n\nWhen using Page Rules with Workers, the following workflow is applied.\n\n1. Request arrives at Cloudflare data center.\n2. Cloudflare decides if this request is a Worker route. Because this is a Worker route, Cloudflare evaluates and disabled a number of features, including some that would be set by Page Rules.\n3. Page Rules run as part of normal request processing with some features now disabled.\n4. Worker executes.\n5. Worker makes a same-zone or other-zone subrequest. Because this is a Worker route, Cloudflare disables a number of features, including some that would be set by Page Rules.\n\nPage Rules are evaluated both at the client-to-Worker request stage (step 2) and the Worker subrequest stage (step 5).\n\nIf you are experiencing Page Rule errors when running Workers, contact your Cloudflare account team or [Cloudflare Support](https://developers.cloudflare.com/support/contacting-cloudflare-support/).\n\n## Affected Page Rules\n\nThe following Page Rules may not work as expected when an incoming request is matched to a Worker route:\n\n* Always Online\n* [Always Use HTTPS](https://developers.cloudflare.com/workers/configuration/workers-with-page-rules/#always-use-https)\n* [Automatic HTTPS Rewrites](https://developers.cloudflare.com/workers/configuration/workers-with-page-rules/#automatic-https-rewrites)\n* [Browser Cache TTL](https://developers.cloudflare.com/workers/configuration/workers-with-page-rules/#browser-cache-ttl)\n* [Browser Integrity Check](https://developers.cloudflare.com/workers/configuration/workers-with-page-rules/#browser-integrity-check)\n* [Cache Deception Armor](https://developers.cloudflare.com/workers/configuration/workers-with-page-rules/#cache-deception-armor)\n* [Cache Level](https://developers.cloudflare.com/workers/configuration/workers-with-page-rules/#cache-level)\n* Disable Apps\n* [Disable Zaraz](https://developers.cloudflare.com/workers/configuration/workers-with-page-rules/#disable-zaraz)\n* [Edge Cache TTL](https://developers.cloudflare.com/workers/configuration/workers-with-page-rules/#edge-cache-ttl)\n* [Email Obfuscation](https://developers.cloudflare.com/workers/configuration/workers-with-page-rules/#email-obfuscation)\n* [Forwarding URL](https://developers.cloudflare.com/workers/configuration/workers-with-page-rules/#forwarding-url)\n* Host Header Override\n* [IP Geolocation Header](https://developers.cloudflare.com/workers/configuration/workers-with-page-rules/#ip-geolocation-header)\n* Mirage (deprecated)\n* [Origin Cache Control](https://developers.cloudflare.com/workers/configuration/workers-with-page-rules/#origin-cache-control)\n* [Rocket Loader](https://developers.cloudflare.com/workers/configuration/workers-with-page-rules/#rocket-loader)\n* [Security Level](https://developers.cloudflare.com/workers/configuration/workers-with-page-rules/#security-level)\n* [SSL](https://developers.cloudflare.com/workers/configuration/workers-with-page-rules/#ssl)\n\nThis is because the default setting of these Page Rules will be disabled when Cloudflare recognizes that the request is headed to a Worker.\n\nDue to ongoing changes to the Workers runtime, detailed documentation on how these rules will be affected are updated following testing.\n\nTo learn what these Page Rules do, refer to [Page Rules](https://developers.cloudflare.com/rules/page-rules/).\n\nSame zone versus other zone\n\nA same zone subrequest is a request the Worker makes to an orange-clouded hostname in the same zone the Worker runs on. Depending on your DNS configuration, any request that falls outside that definition may be considered an other zone request by the Cloudflare network.\n\n| Source | Target | Behavior |\n| - | - | - |\n| Client | Worker | Rule Respected |\n| Worker | Same Zone | Rule Ignored |\n| Worker | Other Zone | Rule Ignored |\n\n### Automatic HTTPS Rewrites\n\n| Source | Target | Behavior |\n| - | - | - |\n| Client | Worker | Rule Ignored |\n| Worker | Same Zone | Rule Respected |\n| Worker | Other Zone | Rule Ignored |\n\n### Browser Cache TTL\n\n| Source | Target | Behavior |\n| - | - | - |\n| Client | Worker | Rule Ignored |\n| Worker | Same Zone | Rule Respected |\n| Worker | Other Zone | Rule Ignored |\n\n### Browser Integrity Check\n\n| Source | Target | Behavior |\n| - | - | - |\n| Client | Worker | Rule Respected |\n| Worker | Same Zone | Rule Ignored |\n| Worker | Other Zone | Rule Ignored |\n\n### Cache Deception Armor\n\n| Source | Target | Behavior |\n| - | - | - |\n| Client | Worker | Rule Respected |\n| Worker | Same Zone | Rule Respected |\n| Worker | Other Zone | Rule Ignored |\n\n| Source | Target | Behavior |\n| - | - | - |\n| Client | Worker | Rule Respected |\n| Worker | Same Zone | Rule Respected |\n| Worker | Other Zone | Rule Ignored |\n\n| Source | Target | Behavior |\n| - | - | - |\n| Client | Worker | Rule Respected |\n| Worker | Same Zone | Rule Respected |\n| Worker | Other Zone | Rule Ignored |\n\n| Source | Target | Behavior |\n| - | - | - |\n| Client | Worker | Rule Respected |\n| Worker | Same Zone | Rule Respected |\n| Worker | Other Zone | Rule Ignored |\n\n### Email Obfuscation\n\n| Source | Target | Behavior |\n| - | - | - |\n| Client | Worker | Rule Ignored |\n| Worker | Same Zone | Rule Respected |\n| Worker | Other Zone | Rule Ignored |\n\n| Source | Target | Behavior |\n| - | - | - |\n| Client | Worker | Rule Ignored |\n| Worker | Same Zone | Rule Respected |\n| Worker | Other Zone | Rule Ignored |\n\n### IP Geolocation Header\n\n| Source | Target | Behavior |\n| - | - | - |\n| Client | Worker | Rule Respected |\n| Worker | Same Zone | Rule Respected |\n| Worker | Other Zone | Rule Ignored |\n\n### Origin Cache Control\n\n| Source | Target | Behavior |\n| - | - | - |\n| Client | Worker | Rule Respected |\n| Worker | Same Zone | Rule Respected |\n| Worker | Other Zone | Rule Ignored |\n\n| Source | Target | Behavior |\n| - | - | - |\n| Client | Worker | Rule Ignored |\n| Worker | Same Zone | Rule Ignored |\n| Worker | Other Zone | Rule Ignored |\n\n| Source | Target | Behavior |\n| - | - | - |\n| Client | Worker | Rule Respected |\n| Worker | Same Zone | Rule Ignored |\n| Worker | Other Zone | Rule Ignored |\n\n| Source | Target | Behavior |\n| - | - | - |\n| Client | Worker | Rule Respected |\n| Worker | Same Zone | Rule Respected |\n| Worker | Other Zone | Rule Ignored |\n\n<page>\n---\ntitle: Analytics Engine · Cloudflare Workers docs\ndescription: Use Workers to receive performance analytics about your\n  applications, products and projects.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/databases/analytics-engine/\n  md: https://developers.cloudflare.com/workers/databases/analytics-engine/index.md\n---\n\n<page>\n---\ntitle: Connect to databases · Cloudflare Workers docs\ndescription: Learn about the different kinds of database integrations Cloudflare supports.\nlastUpdated: 2025-11-12T15:17:36.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/databases/connecting-to-databases/\n  md: https://developers.cloudflare.com/workers/databases/connecting-to-databases/index.md\n---\n\nCloudflare Workers can connect to and query your data in both SQL and NoSQL databases, including:\n\n* Cloudflare's own [D1](https://developers.cloudflare.com/d1/), a serverless SQL-based database.\n* Traditional hosted relational databases, including Postgres and MySQL, using [Hyperdrive](https://developers.cloudflare.com/hyperdrive/) (recommended) to significantly speed up access.\n* Serverless databases, including Supabase, MongoDB Atlas, PlanetScale, and Prisma.\n\nD1 is Cloudflare's own SQL-based, serverless database. It is optimized for global access from Workers, and can scale out with multiple, smaller (10GB) databases, such as per-user, per-tenant or per-entity databases. Similar to some serverless databases, D1 pricing is based on query and storage costs.\n\n| Database | Library or Driver | Connection Method |\n| - | - | - |\n| [D1](https://developers.cloudflare.com/d1/) | [Workers binding](https://developers.cloudflare.com/d1/worker-api/), integrates with [Prisma](https://www.prisma.io/), [Drizzle](https://orm.drizzle.team/), and other ORMs | [Workers binding](https://developers.cloudflare.com/d1/worker-api/), [REST API](https://developers.cloudflare.com/api/resources/d1/subresources/database/methods/create/) |\n\n### Traditional SQL databases\n\nTraditional databases use SQL drivers that use [TCP sockets](https://developers.cloudflare.com/workers/runtime-apis/tcp-sockets/) to connect to the database. TCP is the de-facto standard protocol that many databases, such as PostgreSQL and MySQL, use for client connectivity. These drivers are also widely compatible with your preferred ORM libraries and query builders.\n\nThis also includes serverless databases that are PostgreSQL or MySQL-compatible like [Supabase](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/supabase/), [Neon](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/neon/), or PlanetScale (either [MySQL](https://developers.cloudflare.com/hyperdrive/examples/connect-to-mysql/mysql-database-providers/planetscale/) or [PostgreSQL](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/planetscale-postgres/)), which can be connected to using both native [TCP sockets and Hyperdrive](https://developers.cloudflare.com/hyperdrive/) or [serverless HTTP-based drivers](https://developers.cloudflare.com/workers/databases/connecting-to-databases/#serverless-databases) (detailed below).\n\n| Database | Integration | Library or Driver | Connection Method |\n| - | - | - | - |\n| [Postgres](https://developers.cloudflare.com/workers/tutorials/postgres/) | Direct connection | [node-postgres](https://node-postgres.com/),[Postgres.js](https://github.com/porsager/postgres) | [TCP Socket](https://developers.cloudflare.com/workers/runtime-apis/tcp-sockets/) via database driver, using [Hyperdrive](https://developers.cloudflare.com/hyperdrive/) for optimal performance (optional, recommended) |\n| [MySQL](https://developers.cloudflare.com/workers/tutorials/mysql/) | Direct connection | [mysql2](https://github.com/sidorares/node-mysql2), [mysql](https://github.com/mysqljs/mysql) | [TCP Socket](https://developers.cloudflare.com/workers/runtime-apis/tcp-sockets/) via database driver, using [Hyperdrive](https://developers.cloudflare.com/hyperdrive/) for optimal performance (optional, recommended) |\n\nSpeed up database connectivity with Hyperdrive\n\nConnecting to SQL databases with TCP sockets requires multiple roundtrips to establish a secure connection before a query to the database is made. Since a connection must be re-established on every Worker invocation, this adds unnecessary latency.\n\n[Hyperdrive](https://developers.cloudflare.com/hyperdrive/) solves this by pooling database connections globally to eliminate unnecessary roundtrips and speed up your database access. Learn more about [how Hyperdrive works](https://developers.cloudflare.com/hyperdrive/concepts/how-hyperdrive-works/).\n\n### Serverless databases\n\nServerless databases may provide direct connection to the underlying database, or provide HTTP-based proxies and drivers (also known as serverless drivers).\n\nFor PostgreSQL and MySQL serverless databases, you can connect to the underlying database directly using the native database drivers and ORMs you are familiar with, using Hyperdrive (recommended) to speed up connectivity and pool database connections. When you use Hyperdrive, your connection pool is managed across all of Cloudflare regions and optimized for usage from Workers.\n\nYou can also use serverless driver libraries to connect to the HTTP-based proxies managed by the database provider. These may also provide connection pooling for traditional SQL databases and reduce the amount of roundtrips needed to establish a secure connection, similarly to Hyperdrive.\n\n| Database | Library or Driver | Connection Method |\n| - | - | - |\n| [PlanetScale](https://planetscale.com/blog/introducing-the-planetscale-serverless-driver-for-javascript) | [Hyperdrive (MySQL)](https://developers.cloudflare.com/hyperdrive/examples/connect-to-mysql/mysql-database-providers/planetscale), [Hyperdrive (PostgreSQL)](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/planetscale-postgres/), [@planetscale/database](https://github.com/planetscale/database-js) | [mysql2](https://developers.cloudflare.com/hyperdrive/examples/connect-to-mysql/mysql-drivers-and-libraries/mysql2/), [mysql](https://developers.cloudflare.com/hyperdrive/examples/connect-to-mysql/mysql-drivers-and-libraries/mysql/), [node-postgres](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-drivers-and-libraries/node-postgres/), [Postgres.js](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-drivers-and-libraries/postgres-js/), or API via client library |\n| [Supabase](https://github.com/supabase/supabase/tree/master/examples/with-cloudflare-workers) | [Hyperdrive](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/supabase/), [@supabase/supabase-js](https://github.com/supabase/supabase-js) | [node-postgres](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-drivers-and-libraries/node-postgres/),[Postgres.js](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-drivers-and-libraries/postgres-js/), or API via client library |\n| [Prisma](https://www.prisma.io/docs/guides/deployment/deployment-guides/deploying-to-cloudflare-workers) | [prisma](https://github.com/prisma/prisma) | API via client library |\n| [Neon](https://blog.cloudflare.com/neon-postgres-database-from-workers/) | [Hyperdrive](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/neon/), [@neondatabase/serverless](https://neon.tech/blog/serverless-driver-for-postgres/) | [node-postgres](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-drivers-and-libraries/node-postgres/),[Postgres.js](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-drivers-and-libraries/postgres-js/), or API via client library |\n| [Hasura](https://hasura.io/blog/building-applications-with-cloudflare-workers-and-hasura-graphql-engine/) | API | GraphQL API via fetch() |\n| [Upstash Redis](https://blog.cloudflare.com/cloudflare-workers-database-integration-with-upstash/) | [@upstash/redis](https://github.com/upstash/upstash-redis) | API via client library |\n| [TiDB Cloud](https://docs.pingcap.com/tidbcloud/integrate-tidbcloud-with-cloudflare) | [@tidbcloud/serverless](https://github.com/tidbcloud/serverless-js) | API via client library |\n\nOnce you have installed the necessary packages, use the APIs provided by these packages to connect to your database and perform operations on it. Refer to detailed links for service-specific instructions.\n\nIf your database requires authentication, use Wrangler secrets to securely store your credentials. To do this, create a secret in your Cloudflare Workers project using the following [`wrangler secret`](https://developers.cloudflare.com/workers/wrangler/commands/#secret) command:\n\nThen, retrieve the secret value in your code using the following code snippet:\n\nUse the secret value to authenticate with the external service. For example, if the external service requires an API key or database username and password for authentication, include these in using the relevant service's library or API.\n\nFor services that require mTLS authentication, use [mTLS certificates](https://developers.cloudflare.com/workers/runtime-apis/bindings/mtls) to present a client certificate.\n\n* Learn how to connect to [an existing PostgreSQL database](https://developers.cloudflare.com/hyperdrive/) with Hyperdrive.\n* Discover [other storage options available](https://developers.cloudflare.com/workers/platform/storage-options/) for use with Workers.\n* [Create your first database](https://developers.cloudflare.com/d1/get-started/) with Cloudflare D1.\n\n<page>\n---\ntitle: Cloudflare D1 · Cloudflare Workers docs\ndescription: Cloudflare’s native serverless database.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/databases/d1/\n  md: https://developers.cloudflare.com/workers/databases/d1/index.md\n---\n\n<page>\n---\ntitle: Hyperdrive · Cloudflare Workers docs\ndescription: Use Workers to accelerate queries you make to existing databases.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/databases/hyperdrive/\n  md: https://developers.cloudflare.com/workers/databases/hyperdrive/index.md\n---\n\n<page>\n---\ntitle: 3rd Party Integrations · Cloudflare Workers docs\ndescription: Connect to third-party databases such as Supabase, Turso and PlanetScale)\nlastUpdated: 2025-06-25T15:22:01.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/databases/third-party-integrations/\n  md: https://developers.cloudflare.com/workers/databases/third-party-integrations/index.md\n---\n\nConnect to databases by configuring connection strings and credentials as [secrets](https://developers.cloudflare.com/workers/configuration/secrets/) in your Worker.\n\nConnecting to a regional database from a Worker?\n\nIf your Worker is connecting to a regional database, you can reduce your query latency by using [Hyperdrive](https://developers.cloudflare.com/hyperdrive) and [Smart Placement](https://developers.cloudflare.com/workers/configuration/smart-placement/) which are both included in any Workers plan. Hyperdrive will pool your databases connections globally across Cloudflare's network. Smart Placement will monitor your application to run your Workers closest to your backend infrastructure when this reduces the latency of your Worker invocations. Learn more about [how Smart Placement works](https://developers.cloudflare.com/workers/configuration/smart-placement/).\n\n## Database credentials\n\nWhen you rotate or update database credentials, you must update the corresponding [secrets](https://developers.cloudflare.com/workers/configuration/secrets/) in your Worker. Use the [`wrangler secret put`](https://developers.cloudflare.com/workers/wrangler/commands/#secret) command to update secrets securely or update the secret directly in the [Cloudflare dashboard](https://dash.cloudflare.com/?to=/:account/workers/services/view/:worker/production/settings).\n\nYou can connect to multiple databases by configuring separate sets of secrets for each database connection. Use descriptive secret names to distinguish between different database connections (for example, `DATABASE_URL_PROD` and `DATABASE_URL_STAGING`).\n\n* [Neon](https://developers.cloudflare.com/workers/databases/third-party-integrations/neon/)\n* [PlanetScale](https://developers.cloudflare.com/workers/databases/third-party-integrations/planetscale/)\n* [Supabase](https://developers.cloudflare.com/workers/databases/third-party-integrations/supabase/)\n* [Turso](https://developers.cloudflare.com/workers/databases/third-party-integrations/turso/)\n* [Upstash](https://developers.cloudflare.com/workers/databases/third-party-integrations/upstash/)\n* [Xata](https://developers.cloudflare.com/workers/databases/third-party-integrations/xata/)\n\n<page>\n---\ntitle: Vectorize (vector database) · Cloudflare Workers docs\ndescription: A globally distributed vector database that enables you to build\n  full-stack, AI-powered applications with Cloudflare Workers.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/databases/vectorize/\n  md: https://developers.cloudflare.com/workers/databases/vectorize/index.md\n---\n\n<page>\n---\ntitle: Supported bindings per development mode · Cloudflare Workers docs\ndescription: Supported bindings per development mode\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/development-testing/bindings-per-env/\n  md: https://developers.cloudflare.com/workers/development-testing/bindings-per-env/index.md\n---\n\n**Local simulations**: During local development, your Worker code always executes locally and bindings connect to locally simulated resources [by default](https://developers.cloudflare.com/workers/development-testing/#remote-bindings). This is supported in [`wrangler dev`](https://developers.cloudflare.com/workers/wrangler/commands/#dev) and the [Cloudflare Vite plugin](https://developers.cloudflare.com/workers/vite-plugin/).\n\n**Remote binding connections:**: Allows you to connect to remote resources on a [per-binding basis](https://developers.cloudflare.com/workers/development-testing/#remote-bindings). This is supported in [`wrangler dev`](https://developers.cloudflare.com/workers/wrangler/commands/#dev) and the [Cloudflare Vite plugin](https://developers.cloudflare.com/workers/vite-plugin/).\n\n| Binding | Local simulations | Remote binding connections |\n| - | - | - |\n| **AI** | ❌ | ✅ |\n| **Assets** | ✅ | ❌ |\n| **Analytics Engine** | ✅ | ❌ |\n| **Browser Rendering** | ✅ | ✅ |\n| **D1** | ✅ | ✅ |\n| **Durable Objects** | ✅ | ❌ [1](#user-content-fn-1) |\n| **Containers** | ✅ | ❌ |\n| **Email Bindings** | ✅ | ✅ |\n| **Hyperdrive** | ✅ | ❌ |\n| **Images** | ✅ | ✅ |\n| **KV** | ✅ | ✅ |\n| **mTLS** | ❌ | ✅ |\n| **Queues** | ✅ | ✅ |\n| **R2** | ✅ | ✅ |\n| **Rate Limiting** | ✅ | ❌ |\n| **Service Bindings (multiple Workers)** | ✅ | ✅ |\n| **Vectorize** | ❌ | ✅ |\n| **Workflows** | ✅ | ❌ |\n\n## Remote development\n\nDuring remote development, all of your Worker code is uploaded and executed on Cloudflare's infrastructure, and bindings always connect to remote resources. **We recommend using local development with remote binding connections instead** for faster iteration and debugging.\n\nSupported only in [`wrangler dev --remote`](https://developers.cloudflare.com/workers/wrangler/commands/#dev) - there is **no Vite plugin equivalent**.\n\n| Binding | Remote development |\n| - | - |\n| **AI** | ✅ |\n| **Assets** | ✅ |\n| **Analytics Engine** | ✅ |\n| **Browser Rendering** | ✅ |\n| **D1** | ✅ |\n| **Durable Objects** | ✅ |\n| **Containers** | ❌ |\n| **Email Bindings** | ✅ |\n| **Hyperdrive** | ✅ |\n| **Images** | ✅ |\n| **KV** | ✅ |\n| **mTLS** | ✅ |\n| **Queues** | ❌ |\n| **R2** | ✅ |\n| **Rate Limiting** | ✅ |\n| **Service Bindings (multiple Workers)** | ✅ |\n| **Vectorize** | ✅ |\n| **Workflows** | ❌ |\n\n1. Refer to [Using remote resources with Durable Objects and Workflows](https://developers.cloudflare.com/workers/development-testing/#using-remote-resources-with-durable-objects-and-workflows) for recommended workarounds. [↩](#user-content-fnref-1)\n\n<page>\n---\ntitle: Environment variables and secrets · Cloudflare Workers docs\ndescription: Configuring environment variables and secrets for local development\nlastUpdated: 2025-08-08T16:08:21.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/development-testing/environment-variables/\n  md: https://developers.cloudflare.com/workers/development-testing/environment-variables/index.md\n---\n\nDo not use `vars` to store sensitive information in your Worker's Wrangler configuration file. Use secrets instead.\n\nPut secrets for use in local development in either a `.dev.vars` file or a `.env` file, in the same directory as the Wrangler configuration file.\n\nChoose to use either `.dev.vars` or `.env` but not both. If you define a `.dev.vars` file, then values in `.env` files will not be included in the `env` object during local development.\n\nThese files should be formatted using the [dotenv](https://hexdocs.pm/dotenvy/dotenv-file-format.html) syntax. For example:\n\nDo not commit secrets to git\n\nThe `.dev.vars` and `.env` files should not committed to git. Add `.dev.vars*` and `.env*` to your project's `.gitignore` file.\n\nTo set different secrets for each Cloudflare environment, create files named `.dev.vars.<environment-name>` or `.env.<environment-name>`.\n\nWhen you select a Cloudflare environment in your local development, the corresponding environment-specific file will be loaded ahead of the generic `.dev.vars` (or `.env`) file.\n\n* When using `.dev.vars.<environment-name>` files, all secrets must be defined per environment. If `.dev.vars.<environment-name>` exists then only this will be loaded; the `.dev.vars` file will not be loaded.\n\n* In contrast, all matching `.env` files are loaded and the values are merged. For each variable, the value from the most specific file is used, with the following precedence:\n\n* `.env.<environment-name>.local` (most specific)\n  * `.env.local`\n  * `.env.<environment-name>`\n  * `.env` (least specific)\n\nControlling `.env` handling\n\nIt is possible to control how `.env` files are loaded in local development by setting environment variables on the process running the tools.\n\n* To disable loading local dev vars from `.env` files without providing a `.dev.vars` file, set the `CLOUDFLARE_LOAD_DEV_VARS_FROM_DOT_ENV` environment variable to `\"false\"`.\n* To include every environment variable defined in your system's process environment as a local development variable, ensure there is no `.dev.vars` and then set the `CLOUDFLARE_INCLUDE_PROCESS_ENV` environment variable to `\"true\"`.\n\nHere are steps to set up environment variables for local development using either `.dev.vars` or `.env` files.\n\n1. Create a `.dev.vars` / `.env` file in your project root.\n\n2. Add key-value pairs:\n\n3. Run your `dev` command\n\n## Multiple local environments\n\nTo simulate different local environments, you can provide environment-specific files. For example, you might have a `staging` environment that requires different settings than your development environment.\n\n1. Create a file named `.dev.vars.<environment-name>`/`.env.<environment-name>`. For example, we can use `.dev.vars.staging`/`.env.staging`.\n\n2. Add key-value pairs:\n\n3. Specify the environment when running the `dev` command:\n\n- If using `.dev.vars.staging`, only the values from that file will be applied instead of `.dev.vars`.\n   - If using `.env.staging`, the values will be merged with `.env` files, with the most specific file taking precedence.\n\n* To learn how to configure multiple environments in Wrangler configuration, [read the documentation](https://developers.cloudflare.com/workers/wrangler/environments/#_top).\n* To learn how to use Wrangler environments and Vite environments together, [read the Vite plugin documentation](https://developers.cloudflare.com/workers/vite-plugin/reference/cloudflare-environments/)\n\n<page>\n---\ntitle: Adding local data · Cloudflare Workers docs\ndescription: Populating local resources with data\nlastUpdated: 2025-12-12T09:12:57.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/development-testing/local-data/\n  md: https://developers.cloudflare.com/workers/development-testing/local-data/index.md\n---\n\nWhether you are using Wrangler or the [Cloudflare Vite plugin](https://developers.cloudflare.com/workers/vite-plugin/), your workflow for **accessing** data during local development remains the same. However, you can only [populate local resources with data](https://developers.cloudflare.com/workers/development-testing/local-data/#populating-local-resources-with-data) via the Wrangler CLI.\n\nWhen you run either `wrangler dev` or [`vite`](https://vite.dev/guide/cli#dev-server), [Miniflare](https://developers.cloudflare.com/workers/testing/miniflare/) automatically creates **local versions** of your resources (like [KV](https://developers.cloudflare.com/kv), [D1](https://developers.cloudflare.com/d1/), or [R2](https://developers.cloudflare.com/r2)). This means you **don’t** need to manually set up separate local instances for each service. However, newly created local resources **won’t** contain any data — you'll need to use Wrangler commands with the `--local` flag to populate them. Changes made to local resources won’t affect production data.\n\n## Populating local resources with data\n\nWhen you first start developing, your local resources will be empty. You'll need to populate them with data using the Wrangler CLI.\n\nSince version 3.60.0, Wrangler supports the `kv ...` syntax. If you are using versions below 3.60.0, the command follows the `kv:...` syntax. Learn more in the [Wrangler commands for KV page](https://developers.cloudflare.com/kv/reference/kv-commands/).\n\n#### [Add a single key-value pair](https://developers.cloudflare.com/workers/wrangler/commands/#kv-key)\n\n#### [Bulk upload](https://developers.cloudflare.com/workers/wrangler/commands/#kv-bulk)\n\n#### [Upload a file](https://developers.cloudflare.com/workers/wrangler/commands/#r2-object)\n\nYou may also include [other metadata](https://developers.cloudflare.com/workers/wrangler/commands/#r2-object-put).\n\n#### [Execute a SQL statement](https://developers.cloudflare.com/workers/wrangler/commands/#d1-execute)\n\n#### [Execute a SQL file](https://developers.cloudflare.com/workers/wrangler/commands/#d1-execute)\n\nFor Durable Objects, unlike KV, D1, and R2, there are no CLI commands to populate them with local data. To add data to Durable Objects during local development, you must write application code that creates Durable Object instances and [calls methods on them that store state](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/). This typically involves creating development endpoints or test routes that initialize your Durable Objects with the desired data.\n\n## Where local data gets stored\n\nBy default, both Wrangler and the Vite plugin store local binding data in the same location: the `.wrangler/state` folder in your project directory. This folder stores data in subdirectories for all local bindings: KV namespaces, R2 buckets, D1 databases, Durable Objects, etc.\n\n### Clearing local storage\n\nYou can delete the `.wrangler/state` folder at any time to reset your local environment, and Miniflare will recreate it the next time you run your `dev` command. You can also delete specific sub-folders within `.wrangler/state` for more targeted clean-up.\n\n### Changing the local data directory\n\nIf you prefer to specify a different directory for local storage, you can do so through the Wranlger CLI or in the Vite plugin's configuration.\n\nUse the [`--persist-to`](https://developers.cloudflare.com/workers/wrangler/commands/#dev) flag with `wrangler dev`. You need to specify this flag every time you run the `dev` command:\n\nThe local persistence folder (like `.wrangler/state` or any custom folder you set) should be added to your `.gitignore` to avoid committing local development data to version control.\n\nUsing `--local` with `--persist-to`\n\nIf you run `wrangler dev --persist-to <DIRECTORY>` to specify a custom location for local data, you must also include the same `--persist-to <DIRECTORY>` when running other Wrangler commands that modify local data (and be sure to include the `--local` flag).\n\nFor example, to create a KV key named `test` with a value of `12345` in a local KV namespace, run:\n\n* Sets the KV key `test` to `12345` in the binding `MY_KV_NAMESPACE` (defined in your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/)).\n* Uses `--persist-to worker-local` to ensure the data is created in the **worker-local** directory instead of the default `.wrangler/state`.\n* Adds the `--local` flag, indicating you want to modify local data.\n\nIf `--persist-to` is not specified, Wrangler defaults to using `.wrangler/state` for local data.\n\n#### Using the Cloudflare Vite plugin\n\nTo customize where the Vite plugin stores local data, configure the [`persistState` option](https://developers.cloudflare.com/workers/vite-plugin/reference/api/#interface-pluginconfig) in your Vite config file:\n\n#### Sharing state between tools\n\nIf you want Wrangler and the Vite plugin to share the same state, configure them to use the same persistence path.\n\n<page>\n---\ntitle: Developing with multiple Workers · Cloudflare Workers docs\ndescription: Learn how to develop with multiple Workers using different\n  approaches and configurations.\nlastUpdated: 2025-08-21T14:49:21.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/development-testing/multi-workers/\n  md: https://developers.cloudflare.com/workers/development-testing/multi-workers/index.md\n---\n\nWhen building complex applications, you may want to run multiple Workers during development. This guide covers the different approaches for running multiple Workers locally and when to use each approach.\n\n## Single dev command\n\nWe recommend this approach as the default for most development workflows as it ensures the best compatibility with bindings.\n\nYou can run multiple Workers in a single dev command by passing multiple configuration files to your dev server:\n\nThe first config (`./app/wrangler.jsonc`) is treated as the primary Worker, exposed at `http://localhost:8787`. Additional configs (e.g. `./api/wrangler.jsonc`) run as auxiliary Workers, available via service bindings or tail consumers from the primary Worker.\n\n**Using the Vite plugin**\n\nConfigure `auxiliaryWorkers` in your Vite configuration:\n\n**Use this approach when:**\n\n* You want the simplest setup for development\n* Workers are part of the same application or codebase\n* You need to access a Durable Object namespace from another Worker using `script_name`, or setup Queues where the producer and consumer Workers are seperated.\n\n## Multiple dev commands\n\nYou can also run each Worker in a separate dev commands, each with its own terminal and configuration.\n\nThese Workers run in different dev commands but can still communicate with each other via service bindings or tail consumers **regardless of whether they are started with `wrangler dev` or `vite dev`**.\n\nYou can also combine both approaches — for example, run a group of Workers together through `vite dev` using `auxiliaryWorkers`, while running another Worker separately with `wrangler dev`. This allows you to keep tightly coupled Workers running under a single dev command, while keeping independent or shared Workers in separate ones.\n\n**Use this approach when:**\n\n* You want each Worker to be accessible on its own local URL during development, since only the primary Worker is exposed when using a single dev command\n* Each Worker has its own build setup or tooling — for example, one uses Vite with custom plugins while another is a vanilla Wrangler project\n* You need the flexibility to run and develop Workers independently without restructuring your project or consolidating configs\n\nThis setup is especially useful in larger projects where each team maintains a subset of Workers. Running everything in a single dev command might require significant restructuring or build integration that isn't always practical.\n\n<page>\n---\ntitle: Testing · Cloudflare Workers docs\nlastUpdated: 2025-06-18T17:02:32.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/development-testing/testing/\n  md: https://developers.cloudflare.com/workers/development-testing/testing/index.md\n---\n\n<page>\n---\ntitle: Vite Plugin · Cloudflare Workers docs\nlastUpdated: 2025-06-18T17:02:32.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/development-testing/vite-plugin/\n  md: https://developers.cloudflare.com/workers/development-testing/vite-plugin/index.md\n---\n\n<page>\n---\ntitle: Choosing between Wrangler & Vite · Cloudflare Workers docs\ndescription: Choosing between Wrangler and Vite for local development\nlastUpdated: 2025-09-18T22:01:54.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/development-testing/wrangler-vs-vite/\n  md: https://developers.cloudflare.com/workers/development-testing/wrangler-vs-vite/index.md\n---",
  "code_samples": [
    {
      "code": "wrangler versions upload --preview-alias staging",
      "language": "bash"
    },
    {
      "code": "{\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"preview_urls\": true\n  }",
      "language": "jsonc"
    },
    {
      "code": "preview_urls = true",
      "language": "toml"
    },
    {
      "code": "{\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"preview_urls\": false\n  }",
      "language": "jsonc"
    },
    {
      "code": "preview_urls = false",
      "language": "toml"
    },
    {
      "code": "import postgres from \"postgres\";\n\n\nexport default {\n  async fetch(request, env, ctx) {\n    const sql = postgres(env.DB_CONNECTION_STRING);\n\n\n    const result = await sql`SELECT * FROM products;`;\n\n\n    return new Response(JSON.stringify(result), {\n      headers: { \"Content-Type\": \"application/json\" },\n    });\n  },\n};",
      "language": "js"
    },
    {
      "code": "import { env } from \"cloudflare:workers\";\n  import postgres from \"postgres\";\n\n\n  // Initialize the database client at the top level using a secret\n  const sql = postgres(env.DB_CONNECTION_STRING);\n\n\n  export default {\n    async fetch(request) {\n      const result = await sql`SELECT * FROM products;`;\n\n\n      return new Response(JSON.stringify(result), {\n        headers: { \"Content-Type\": \"application/json\" },\n      });\n    },\n  };",
      "language": "js"
    },
    {
      "code": "import { env } from \"cloudflare:workers\";\n  import postgres from \"postgres\";\n\n\n  // Initialize the database client at the top level using a secret\n  const sql = postgres(env.DB_CONNECTION_STRING);\n\n\n  export default {\n    async fetch(request: Request): Promise<Response> {\n      const result = await sql`SELECT * FROM products;`;\n\n\n      return new Response(JSON.stringify(result), {\n        headers: { \"Content-Type\": \"application/json\" },\n      });\n    },\n  };",
      "language": "ts"
    },
    {
      "code": "SECRET_KEY=\"value\"\nAPI_TOKEN=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9\"",
      "language": "bash"
    },
    {
      "code": "npx wrangler secret put <KEY>",
      "language": "sh"
    },
    {
      "code": "npx wrangler versions secret put <KEY>",
      "language": "sh"
    },
    {
      "code": "npx wrangler secret delete <KEY>",
      "language": "sh"
    },
    {
      "code": "npx wrangler versions secret delete <KEY>",
      "language": "sh"
    },
    {
      "code": "{\n       \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n       \"placement\": {\n         \"mode\": \"smart\"\n       }\n     }",
      "language": "jsonc"
    },
    {
      "code": "[placement]\n     mode = \"smart\"",
      "language": "toml"
    },
    {
      "code": "curl -X GET https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/workers/services/{WORKER_NAME} \\\n-H \"Authorization: Bearer <TOKEN>\" \\\n-H \"Content-Type: application/json\" | jq .",
      "language": "bash"
    },
    {
      "code": "wrangler secret put <SECRET_NAME>",
      "language": "sh"
    },
    {
      "code": "const secretValue = env.<SECRET_NAME>;",
      "language": "js"
    },
    {
      "code": "SECRET_KEY=\"value\"\nAPI_TOKEN=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9\"",
      "language": "bash"
    },
    {
      "code": "API_HOST=\"localhost:3000\"\n   DEBUG=\"true\"\n   SECRET_TOKEN=\"my-local-secret-token\"",
      "language": "ini"
    },
    {
      "code": "npx wrangler dev",
      "language": "sh"
    },
    {
      "code": "yarn wrangler dev",
      "language": "sh"
    },
    {
      "code": "pnpm wrangler dev",
      "language": "sh"
    },
    {
      "code": "npx vite dev",
      "language": "sh"
    },
    {
      "code": "yarn vite dev",
      "language": "sh"
    },
    {
      "code": "pnpm vite dev",
      "language": "sh"
    },
    {
      "code": "API_HOST=\"staging.localhost:3000\"\n   DEBUG=\"false\"\n   SECRET_TOKEN=\"staging-token\"",
      "language": "ini"
    },
    {
      "code": "npx wrangler dev --env staging",
      "language": "sh"
    },
    {
      "code": "yarn wrangler dev --env staging",
      "language": "sh"
    },
    {
      "code": "pnpm wrangler dev --env staging",
      "language": "sh"
    },
    {
      "code": "CLOUDFLARE_ENV=staging npx vite dev",
      "language": "sh"
    },
    {
      "code": "CLOUDFLARE_ENV=staging yarn vite dev",
      "language": "sh"
    },
    {
      "code": "CLOUDFLARE_ENV=staging pnpm vite dev",
      "language": "sh"
    },
    {
      "code": "npx wrangler kv key put <KEY> <VALUE> --binding=<BINDING> --local",
      "language": "sh"
    },
    {
      "code": "yarn wrangler kv key put <KEY> <VALUE> --binding=<BINDING> --local",
      "language": "sh"
    },
    {
      "code": "pnpm wrangler kv key put <KEY> <VALUE> --binding=<BINDING> --local",
      "language": "sh"
    },
    {
      "code": "npx wrangler kv bulk put <FILENAME.json> --binding=<BINDING> --local",
      "language": "sh"
    },
    {
      "code": "yarn wrangler kv bulk put <FILENAME.json> --binding=<BINDING> --local",
      "language": "sh"
    },
    {
      "code": "pnpm wrangler kv bulk put <FILENAME.json> --binding=<BINDING> --local",
      "language": "sh"
    },
    {
      "code": "npx wrangler r2 object put <BUCKET>/<KEY> --file=<PATH_TO_FILE> --local",
      "language": "sh"
    },
    {
      "code": "yarn wrangler r2 object put <BUCKET>/<KEY> --file=<PATH_TO_FILE> --local",
      "language": "sh"
    },
    {
      "code": "pnpm wrangler r2 object put <BUCKET>/<KEY> --file=<PATH_TO_FILE> --local",
      "language": "sh"
    },
    {
      "code": "npx wrangler d1 execute <DATABASE_NAME> --command=\"<SQL_QUERY>\" --local",
      "language": "sh"
    },
    {
      "code": "yarn wrangler d1 execute <DATABASE_NAME> --command=\"<SQL_QUERY>\" --local",
      "language": "sh"
    },
    {
      "code": "pnpm wrangler d1 execute <DATABASE_NAME> --command=\"<SQL_QUERY>\" --local",
      "language": "sh"
    },
    {
      "code": "npx wrangler d1 execute <DATABASE_NAME> --file=./schema.sql --local",
      "language": "sh"
    },
    {
      "code": "yarn wrangler d1 execute <DATABASE_NAME> --file=./schema.sql --local",
      "language": "sh"
    },
    {
      "code": "pnpm wrangler d1 execute <DATABASE_NAME> --file=./schema.sql --local",
      "language": "sh"
    },
    {
      "code": "npx wrangler dev --persist-to <DIRECTORY>",
      "language": "sh"
    },
    {
      "code": "yarn wrangler dev --persist-to <DIRECTORY>",
      "language": "sh"
    },
    {
      "code": "pnpm wrangler dev --persist-to <DIRECTORY>",
      "language": "sh"
    },
    {
      "code": "npx wrangler kv key put test 12345 --binding MY_KV_NAMESPACE --local --persist-to worker-local",
      "language": "sh"
    },
    {
      "code": "yarn wrangler kv key put test 12345 --binding MY_KV_NAMESPACE --local --persist-to worker-local",
      "language": "sh"
    },
    {
      "code": "pnpm wrangler kv key put test 12345 --binding MY_KV_NAMESPACE --local --persist-to worker-local",
      "language": "sh"
    },
    {
      "code": "import { defineConfig } from \"vite\";\nimport { cloudflare } from \"@cloudflare/vite-plugin\";\n\n\nexport default defineConfig({\n  plugins: [\n    cloudflare({\n      persistState: { path: \"./my-custom-directory\" },\n    }),\n  ],\n});",
      "language": "js"
    },
    {
      "code": "npx wrangler dev -c ./app/wrangler.jsonc -c ./api/wrangler.jsonc",
      "language": "sh"
    },
    {
      "code": "yarn wrangler dev -c ./app/wrangler.jsonc -c ./api/wrangler.jsonc",
      "language": "sh"
    },
    {
      "code": "pnpm wrangler dev -c ./app/wrangler.jsonc -c ./api/wrangler.jsonc",
      "language": "sh"
    },
    {
      "code": "import { defineConfig } from \"vite\";\nimport { cloudflare } from \"@cloudflare/vite-plugin\";\n\n\nexport default defineConfig({\n  plugins: [\n    cloudflare({\n      configPath: \"./app/wrangler.jsonc\",\n      auxiliaryWorkers: [\n        {\n          configPath: \"./api/wrangler.jsonc\",\n        },\n      ],\n    }),\n  ],\n});",
      "language": "js"
    },
    {
      "code": "npx vite dev",
      "language": "sh"
    },
    {
      "code": "yarn vite dev",
      "language": "sh"
    },
    {
      "code": "pnpm vite dev",
      "language": "sh"
    },
    {
      "code": "# Terminal 1\n  npx wrangler dev -c ./app/wrangler.jsonc",
      "language": "sh"
    },
    {
      "code": "# Terminal 1\n  yarn wrangler dev -c ./app/wrangler.jsonc",
      "language": "sh"
    },
    {
      "code": "# Terminal 1\n  pnpm wrangler dev -c ./app/wrangler.jsonc",
      "language": "sh"
    },
    {
      "code": "# Terminal 2\n  npx wrangler dev -c ./api/wrangler.jsonc",
      "language": "sh"
    },
    {
      "code": "# Terminal 2\n  yarn wrangler dev -c ./api/wrangler.jsonc",
      "language": "sh"
    },
    {
      "code": "# Terminal 2\n  pnpm wrangler dev -c ./api/wrangler.jsonc",
      "language": "sh"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Types of Preview URLs",
      "id": "types-of-preview-urls"
    },
    {
      "level": "h3",
      "text": "Versioned Preview URLs",
      "id": "versioned-preview-urls"
    },
    {
      "level": "h3",
      "text": "Aliased preview URLs",
      "id": "aliased-preview-urls"
    },
    {
      "level": "h2",
      "text": "Manage access to Preview URLs",
      "id": "manage-access-to-preview-urls"
    },
    {
      "level": "h2",
      "text": "Toggle Preview URLs (Enable or Disable)",
      "id": "toggle-preview-urls-(enable-or-disable)"
    },
    {
      "level": "h3",
      "text": "From the Dashboard",
      "id": "from-the-dashboard"
    },
    {
      "level": "h3",
      "text": "From the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/)",
      "id": "from-the-[wrangler-configuration-file](https://developers.cloudflare.com/workers/wrangler/configuration/)"
    },
    {
      "level": "h2",
      "text": "Limitations",
      "id": "limitations"
    },
    {
      "level": "h2",
      "text": "What is best for me?",
      "id": "what-is-best-for-me?"
    },
    {
      "level": "h2",
      "text": "Background",
      "id": "background"
    },
    {
      "level": "h2",
      "text": "Access your secrets with Workers",
      "id": "access-your-secrets-with-workers"
    },
    {
      "level": "h2",
      "text": "Local Development with Secrets",
      "id": "local-development-with-secrets"
    },
    {
      "level": "h2",
      "text": "Secrets on deployed Workers",
      "id": "secrets-on-deployed-workers"
    },
    {
      "level": "h3",
      "text": "Adding secrets to your project",
      "id": "adding-secrets-to-your-project"
    },
    {
      "level": "h3",
      "text": "Delete secrets from your project",
      "id": "delete-secrets-from-your-project"
    },
    {
      "level": "h2",
      "text": "Compare secrets and environment variables",
      "id": "compare-secrets-and-environment-variables"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "1. Start from scratch",
      "id": "1.-start-from-scratch"
    },
    {
      "level": "h2",
      "text": "2. Deploy an existing static site",
      "id": "2.-deploy-an-existing-static-site"
    },
    {
      "level": "h2",
      "text": "3. Add static assets to an existing Workers project",
      "id": "3.-add-static-assets-to-an-existing-workers-project"
    },
    {
      "level": "h2",
      "text": "Background",
      "id": "background"
    },
    {
      "level": "h2",
      "text": "Understand how Smart Placement works",
      "id": "understand-how-smart-placement-works"
    },
    {
      "level": "h2",
      "text": "Enable Smart Placement",
      "id": "enable-smart-placement"
    },
    {
      "level": "h3",
      "text": "Enable Smart Placement via Wrangler",
      "id": "enable-smart-placement-via-wrangler"
    },
    {
      "level": "h3",
      "text": "Enable Smart Placement via the dashboard",
      "id": "enable-smart-placement-via-the-dashboard"
    },
    {
      "level": "h2",
      "text": "Observability",
      "id": "observability"
    },
    {
      "level": "h3",
      "text": "Placement Status",
      "id": "placement-status"
    },
    {
      "level": "h3",
      "text": "Request Duration Analytics",
      "id": "request-duration-analytics"
    },
    {
      "level": "h3",
      "text": "`cf-placement` header",
      "id": "`cf-placement`-header"
    },
    {
      "level": "h2",
      "text": "Best practices",
      "id": "best-practices"
    },
    {
      "level": "h2",
      "text": "Give feedback on Smart Placement",
      "id": "give-feedback-on-smart-placement"
    },
    {
      "level": "h2",
      "text": "Versions",
      "id": "versions"
    },
    {
      "level": "h2",
      "text": "Deployments",
      "id": "deployments"
    },
    {
      "level": "h2",
      "text": "Use versions and deployments",
      "id": "use-versions-and-deployments"
    },
    {
      "level": "h3",
      "text": "Create a new version",
      "id": "create-a-new-version"
    },
    {
      "level": "h3",
      "text": "View versions and deployments",
      "id": "view-versions-and-deployments"
    },
    {
      "level": "h2",
      "text": "Limits",
      "id": "limits"
    },
    {
      "level": "h3",
      "text": "First upload",
      "id": "first-upload"
    },
    {
      "level": "h3",
      "text": "Service worker syntax",
      "id": "service-worker-syntax"
    },
    {
      "level": "h3",
      "text": "Durable Object migrations",
      "id": "durable-object-migrations"
    },
    {
      "level": "h2",
      "text": "Page Rules with Workers",
      "id": "page-rules-with-workers"
    },
    {
      "level": "h2",
      "text": "Affected Page Rules",
      "id": "affected-page-rules"
    },
    {
      "level": "h3",
      "text": "Always Use HTTPS",
      "id": "always-use-https"
    },
    {
      "level": "h3",
      "text": "Automatic HTTPS Rewrites",
      "id": "automatic-https-rewrites"
    },
    {
      "level": "h3",
      "text": "Browser Cache TTL",
      "id": "browser-cache-ttl"
    },
    {
      "level": "h3",
      "text": "Browser Integrity Check",
      "id": "browser-integrity-check"
    },
    {
      "level": "h3",
      "text": "Cache Deception Armor",
      "id": "cache-deception-armor"
    },
    {
      "level": "h3",
      "text": "Cache Level",
      "id": "cache-level"
    },
    {
      "level": "h3",
      "text": "Disable Zaraz",
      "id": "disable-zaraz"
    },
    {
      "level": "h3",
      "text": "Edge Cache TTL",
      "id": "edge-cache-ttl"
    },
    {
      "level": "h3",
      "text": "Email Obfuscation",
      "id": "email-obfuscation"
    },
    {
      "level": "h3",
      "text": "Forwarding URL",
      "id": "forwarding-url"
    },
    {
      "level": "h3",
      "text": "IP Geolocation Header",
      "id": "ip-geolocation-header"
    },
    {
      "level": "h3",
      "text": "Origin Cache Control",
      "id": "origin-cache-control"
    },
    {
      "level": "h3",
      "text": "Rocket Loader",
      "id": "rocket-loader"
    },
    {
      "level": "h3",
      "text": "Security Level",
      "id": "security-level"
    },
    {
      "level": "h3",
      "text": "SSL",
      "id": "ssl"
    },
    {
      "level": "h3",
      "text": "D1 SQL database",
      "id": "d1-sql-database"
    },
    {
      "level": "h3",
      "text": "Traditional SQL databases",
      "id": "traditional-sql-databases"
    },
    {
      "level": "h3",
      "text": "Serverless databases",
      "id": "serverless-databases"
    },
    {
      "level": "h2",
      "text": "Authentication",
      "id": "authentication"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "Background",
      "id": "background"
    },
    {
      "level": "h2",
      "text": "Database credentials",
      "id": "database-credentials"
    },
    {
      "level": "h2",
      "text": "Database limits",
      "id": "database-limits"
    },
    {
      "level": "h2",
      "text": "Popular providers",
      "id": "popular-providers"
    },
    {
      "level": "h2",
      "text": "Local development",
      "id": "local-development"
    },
    {
      "level": "h2",
      "text": "Remote development",
      "id": "remote-development"
    },
    {
      "level": "h2",
      "text": "Footnotes",
      "id": "footnotes"
    },
    {
      "level": "h3",
      "text": "Basic setup",
      "id": "basic-setup"
    },
    {
      "level": "h2",
      "text": "Multiple local environments",
      "id": "multiple-local-environments"
    },
    {
      "level": "h2",
      "text": "Learn more",
      "id": "learn-more"
    },
    {
      "level": "h3",
      "text": "How it works",
      "id": "how-it-works"
    },
    {
      "level": "h2",
      "text": "Populating local resources with data",
      "id": "populating-local-resources-with-data"
    },
    {
      "level": "h3",
      "text": "KV namespaces",
      "id": "kv-namespaces"
    },
    {
      "level": "h3",
      "text": "R2 buckets",
      "id": "r2-buckets"
    },
    {
      "level": "h3",
      "text": "D1 databases",
      "id": "d1-databases"
    },
    {
      "level": "h3",
      "text": "Durable Objects",
      "id": "durable-objects"
    },
    {
      "level": "h2",
      "text": "Where local data gets stored",
      "id": "where-local-data-gets-stored"
    },
    {
      "level": "h3",
      "text": "Clearing local storage",
      "id": "clearing-local-storage"
    },
    {
      "level": "h3",
      "text": "Changing the local data directory",
      "id": "changing-the-local-data-directory"
    },
    {
      "level": "h2",
      "text": "Single dev command",
      "id": "single-dev-command"
    },
    {
      "level": "h2",
      "text": "Multiple dev commands",
      "id": "multiple-dev-commands"
    }
  ],
  "url": "llms-txt#overview",
  "links": []
}