{
  "title": "Note: This is the value that was successfully PUT above",
  "content": "jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"r2_buckets\": [\n      {\n        \"binding\": \"MY_BUCKET\",\n        \"bucket_name\": \"<YOUR_BUCKET_NAME>\"\n      }\n    ]\n  }\n  toml\n  [[r2_buckets]]\n  binding = 'MY_BUCKET' # <~ valid JavaScript variable name\n  bucket_name = '<YOUR_BUCKET_NAME>'\n  js\nexport default {\n  async fetch(request, env) {\n    const url = new URL(request.url);\n    const key = url.pathname.slice(1);\n\nswitch (request.method) {\n      case \"PUT\":\n        await env.MY_BUCKET.put(key, request.body);\n        return new Response(`Put ${key} successfully!`);\n\ndefault:\n        return new Response(`${request.method} is not allowed.`, {\n          status: 405,\n          headers: {\n            Allow: \"PUT\",\n          },\n        });\n    }\n  },\n};\njs\nconst options = {\n  limit: 500,\n  include: [\"customMetadata\"],\n};\n\nconst listed = await env.MY_BUCKET.list(options);\n\nlet truncated = listed.truncated;\nlet cursor = truncated ? listed.cursor : undefined;\n\n// ❌ - if your limit can't fit into a single response or your\n// bucket has less objects than the limit, it will get stuck here.\nwhile (listed.objects.length < options.limit) {\n  // ...\n}\n\n// ✅ - use the truncated property to check if there are more\n// objects to be returned\nwhile (truncated) {\n  const next = await env.MY_BUCKET.list({\n    ...options,\n    cursor: cursor,\n  });\n  listed.objects.push(...next.objects);\n\ntruncated = next.truncated;\n  cursor = next.cursor;\n}\njs\ninterface Env {\n  MY_BUCKET: R2Bucket;\n}\n\nexport default {\n  async fetch(\n    request,\n    env,\n    ctx\n  ): Promise<Response> {\n    const bucket = env.MY_BUCKET;\n\nconst url = new URL(request.url);\n    const key = url.pathname.slice(1);\n    const action = url.searchParams.get(\"action\");\n\nif (action === null) {\n      return new Response(\"Missing action type\", { status: 400 });\n    }\n\n// Route the request based on the HTTP method and action type\n    switch (request.method) {\n      case \"POST\":\n        switch (action) {\n          case \"mpu-create\": {\n            const multipartUpload = await bucket.createMultipartUpload(key);\n            return new Response(\n              JSON.stringify({\n                key: multipartUpload.key,\n                uploadId: multipartUpload.uploadId,\n              })\n            );\n          }\n          case \"mpu-complete\": {\n            const uploadId = url.searchParams.get(\"uploadId\");\n            if (uploadId === null) {\n              return new Response(\"Missing uploadId\", { status: 400 });\n            }\n\nconst multipartUpload = env.MY_BUCKET.resumeMultipartUpload(\n              key,\n              uploadId\n            );\n\ninterface completeBody {\n              parts: R2UploadedPart[];\n            }\n            const completeBody: completeBody = await request.json();\n            if (completeBody === null) {\n              return new Response(\"Missing or incomplete body\", {\n                status: 400,\n              });\n            }\n\n// Error handling in case the multipart upload does not exist anymore\n            try {\n              const object = await multipartUpload.complete(completeBody.parts);\n              return new Response(null, {\n                headers: {\n                  etag: object.httpEtag,\n                },\n              });\n            } catch (error: any) {\n              return new Response(error.message, { status: 400 });\n            }\n          }\n          default:\n            return new Response(`Unknown action ${action} for POST`, {\n              status: 400,\n            });\n        }\n      case \"PUT\":\n        switch (action) {\n          case \"mpu-uploadpart\": {\n            const uploadId = url.searchParams.get(\"uploadId\");\n            const partNumberString = url.searchParams.get(\"partNumber\");\n            if (partNumberString === null || uploadId === null) {\n              return new Response(\"Missing partNumber or uploadId\", {\n                status: 400,\n              });\n            }\n            if (request.body === null) {\n              return new Response(\"Missing request body\", { status: 400 });\n            }\n\nconst partNumber = parseInt(partNumberString);\n            const multipartUpload = env.MY_BUCKET.resumeMultipartUpload(\n              key,\n              uploadId\n            );\n            try {\n              const uploadedPart: R2UploadedPart =\n                await multipartUpload.uploadPart(partNumber, request.body);\n              return new Response(JSON.stringify(uploadedPart));\n            } catch (error: any) {\n              return new Response(error.message, { status: 400 });\n            }\n          }\n          default:\n            return new Response(`Unknown action ${action} for PUT`, {\n              status: 400,\n            });\n        }\n      case \"GET\":\n        if (action !== \"get\") {\n          return new Response(`Unknown action ${action} for GET`, {\n            status: 400,\n          });\n        }\n        const object = await env.MY_BUCKET.get(key);\n        if (object === null) {\n          return new Response(\"Object Not Found\", { status: 404 });\n        }\n        const headers = new Headers();\n        object.writeHttpMetadata(headers);\n        headers.set(\"etag\", object.httpEtag);\n        return new Response(object.body, { headers });\n      case \"DELETE\":\n        switch (action) {\n          case \"mpu-abort\": {\n            const uploadId = url.searchParams.get(\"uploadId\");\n            if (uploadId === null) {\n              return new Response(\"Missing uploadId\", { status: 400 });\n            }\n            const multipartUpload = env.MY_BUCKET.resumeMultipartUpload(\n              key,\n              uploadId\n            );\n\ntry {\n              multipartUpload.abort();\n            } catch (error: any) {\n              return new Response(error.message, { status: 400 });\n            }\n            return new Response(null, { status: 204 });\n          }\n          case \"delete\": {\n            await env.MY_BUCKET.delete(key);\n            return new Response(null, { status: 204 });\n          }\n          default:\n            return new Response(`Unknown action ${action} for DELETE`, {\n              status: 400,\n            });\n        }\n      default:\n        return new Response(\"Method Not Allowed\", {\n          status: 405,\n          headers: { Allow: \"PUT, POST, GET, DELETE\" },\n        });\n    }\n  },\n} satisfies ExportedHandler<Env>;\npython\nimport math\nimport os\nimport requests\nfrom requests.adapters import HTTPAdapter, Retry\nimport sys\nimport concurrent.futures",
  "code_samples": [
    {
      "code": "By completing this guide, you have successfully installed Wrangler and deployed your R2 bucket to Cloudflare.\n\n## Related resources\n\n1. [Workers Tutorials](https://developers.cloudflare.com/workers/tutorials/)\n2. [Workers Examples](https://developers.cloudflare.com/workers/examples/)\n\n</page>\n\n<page>\n---\ntitle: Workers API reference · Cloudflare R2 docs\ndescription: The in-Worker R2 API is accessed by binding an R2 bucket to a\n  Worker. The Worker you write can expose external access to buckets via a route\n  or manipulate R2 objects internally.\nlastUpdated: 2025-01-29T12:28:42.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/r2/api/workers/workers-api-reference/\n  md: https://developers.cloudflare.com/r2/api/workers/workers-api-reference/index.md\n---\n\nThe in-Worker R2 API is accessed by binding an R2 bucket to a [Worker](https://developers.cloudflare.com/workers). The Worker you write can expose external access to buckets via a route or manipulate R2 objects internally.\n\nThe R2 API includes some extensions and semantic differences from the S3 API. If you need S3 compatibility, consider using the [S3-compatible API](https://developers.cloudflare.com/r2/api/s3/).\n\n## Concepts\n\nR2 organizes the data you store, called objects, into containers, called buckets. Buckets are the fundamental unit of performance, scaling, and access within R2.\n\n## Create a binding\n\nBindings\n\nA binding is how your Worker interacts with external resources such as [KV Namespaces](https://developers.cloudflare.com/kv/concepts/kv-namespaces/), [Durable Objects](https://developers.cloudflare.com/durable-objects/), or [R2 Buckets](https://developers.cloudflare.com/r2/buckets/). A binding is a runtime variable that the Workers runtime provides to your code. You can declare a variable name in your Wrangler file that will be bound to these resources at runtime, and interact with them through this variable. Every binding's variable name and behavior is determined by you when deploying the Worker. Refer to [Environment Variables](https://developers.cloudflare.com/workers/configuration/environment-variables/) for more information.\n\nA binding is defined in the Wrangler file of your Worker project's directory.\n\nTo bind your R2 bucket to your Worker, add the following to your Wrangler file. Update the `binding` property to a valid JavaScript variable identifier and `bucket_name` to the name of your R2 bucket:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Within your Worker, your bucket binding is now available under the `MY_BUCKET` variable and you can begin interacting with it using the [bucket methods](#bucket-method-definitions) described below.\n\n## Bucket method definitions\n\nThe following methods are available on the bucket binding object injected into your code.\n\nFor example, to issue a `PUT` object request using the binding above:",
      "language": "unknown"
    },
    {
      "code": "* `head` (key: string): Promise\\<R2Object | null>\n\n  * Retrieves the `R2Object` for the given key containing only object metadata, if the key exists, and `null` if the key does not exist.\n\n* `get` (key: string, options?: R2GetOptions): Promise\\<R2ObjectBody | R2Object | null>\n\n  * Retrieves the `R2ObjectBody` for the given key containing object metadata and the object body as a `ReadableStream`, if the key exists, and `null` if the key does not exist.\n  * In the event that a precondition specified in `options` fails, `get()` returns an `R2Object` with `body` undefined.\n\n* `put` (key: string, value: ReadableStream | ArrayBuffer | ArrayBufferView | string | null | Blob, options?: R2PutOptions): Promise\\<R2Object | null>\n\n  * Stores the given `value` and metadata under the associated `key`. Once the write succeeds, returns an `R2Object` containing metadata about the stored Object.\n  * In the event that a precondition specified in `options` fails, `put()` returns `null`, and the object will not be stored.\n  * R2 writes are strongly consistent. Once the Promise resolves, all subsequent read operations will see this key value pair globally.\n\n* `delete` (key: string | string\\[]): Promise\\<void>\n\n  * Deletes the given `values` and metadata under the associated `keys`. Once the delete succeeds, returns `void`.\n  * R2 deletes are strongly consistent. Once the Promise resolves, all subsequent read operations will no longer see the provided key value pairs globally.\n  * Up to 1000 keys may be deleted per call.\n\n* `list` (options?: R2ListOptions): Promise\\<R2Objects>\n\n  * Returns an `R2Objects` containing a list of `R2Object` contained within the bucket.\n  * The returned list of objects is ordered lexicographically.\n  * Returns up to 1000 entries, but may return less in order to minimize memory pressure within the Worker.\n  * To explicitly set the number of objects to list, provide an [R2ListOptions](https://developers.cloudflare.com/r2/api/workers/workers-api-reference/#r2listoptions) object with the `limit` property set.\n\n- `createMultipartUpload` (key: string, options?: R2MultipartOptions): Promise\\<R2MultipartUpload>\n\n  * Creates a multipart upload.\n  * Returns Promise which resolves to an `R2MultipartUpload` object representing the newly created multipart upload. Once the multipart upload has been created, the multipart upload can be immediately interacted with globally, either through the Workers API, or through the S3 API.\n\n* `resumeMultipartUpload` (key: string, uploadId: string): R2MultipartUpload\n\n  * Returns an object representing a multipart upload with the given key and uploadId.\n  * The resumeMultipartUpload operation does not perform any checks to ensure the validity of the uploadId, nor does it verify the existence of a corresponding active multipart upload. This is done to minimize latency before being able to call subsequent operations on the `R2MultipartUpload` object.\n\n## `R2Object` definition\n\n`R2Object` is created when you `PUT` an object into an R2 bucket. `R2Object` represents the metadata of an object based on the information provided by the uploader. Every object that you `PUT` into an R2 bucket will have an `R2Object` created.\n\n* `key` string\n\n  * The object's key.\n\n* `version` string\n\n  * Random unique string associated with a specific upload of a key.\n\n* `size` number\n\n  * Size of the object in bytes.\n\n* `etag` string\n\nNote\n\nCloudflare recommends using the `httpEtag` field when returning an etag in a response header. This ensures the etag is quoted and conforms to [RFC 9110](https://www.rfc-editor.org/rfc/rfc9110#section-8.8.3).\n\n* The etag associated with the object upload.\n\n* `httpEtag` string\n\n  * The object's etag, in quotes so as to be returned as a header.\n\n* `uploaded` Date\n\n  * A Date object representing the time the object was uploaded.\n\n* `httpMetadata` R2HTTPMetadata\n\n  * Various HTTP headers associated with the object. Refer to [HTTP Metadata](#http-metadata).\n\n* `customMetadata` Record\\<string, string>\n\n  * A map of custom, user-defined metadata associated with the object.\n\n* `range` R2Range\n\n  * A `R2Range` object containing the returned range of the object.\n\n* `checksums` R2Checksums\n\n  * A `R2Checksums` object containing the stored checksums of the object. Refer to [checksums](#checksums).\n\n* `writeHttpMetadata` (headers: Headers): void\n\n  * Retrieves the `httpMetadata` from the `R2Object` and applies their corresponding HTTP headers to the `Headers` input object. Refer to [HTTP Metadata](#http-metadata).\n\n* `storageClass` 'Standard' | 'InfrequentAccess'\n\n  * The storage class associated with the object. Refer to [Storage Classes](#storage-class).\n\n* `ssecKeyMd5` string\n\n  * Hex-encoded MD5 hash of the [SSE-C](https://developers.cloudflare.com/r2/examples/ssec) key used for encryption (if one was provided). Hash can be used to identify which key is needed to decrypt object.\n\n## `R2ObjectBody` definition\n\n`R2ObjectBody` represents an object's metadata combined with its body. It is returned when you `GET` an object from an R2 bucket. The full list of keys for `R2ObjectBody` includes the list below and all keys inherited from [`R2Object`](#r2object-definition).\n\n* `body` ReadableStream\n\n  * The object's value.\n\n* `bodyUsed` boolean\n\n  * Whether the object's value has been consumed or not.\n\n* `arrayBuffer` (): Promise\\<ArrayBuffer>\n\n  * Returns a Promise that resolves to an `ArrayBuffer` containing the object's value.\n\n* `text` (): Promise\\<string>\n\n  * Returns a Promise that resolves to an string containing the object's value.\n\n* `json` \\<T>() : Promise\\<T>\n\n  * Returns a Promise that resolves to the given object containing the object's value.\n\n* `blob` (): Promise\\<Blob>\n\n  * Returns a Promise that resolves to a binary Blob containing the object's value.\n\n## `R2MultipartUpload` definition\n\nAn `R2MultipartUpload` object is created when you call `createMultipartUpload` or `resumeMultipartUpload`. `R2MultipartUpload` is a representation of an ongoing multipart upload.\n\nUncompleted multipart uploads will be automatically aborted after 7 days.\n\nNote\n\nAn `R2MultipartUpload` object does not guarantee that there is an active underlying multipart upload corresponding to that object.\n\nA multipart upload can be completed or aborted at any time, either through the S3 API, or by a parallel invocation of your Worker. Therefore it is important to add the necessary error handling code around each operation on a `R2MultipartUpload` object in case the underlying multipart upload no longer exists.\n\n* `key` string\n\n  * The `key` for the multipart upload.\n\n* `uploadId` string\n\n  * The `uploadId` for the multipart upload.\n\n* `uploadPart` (partNumber: number, value: ReadableStream | ArrayBuffer | ArrayBufferView | string | Blob, options?: R2MultipartOptions): Promise\\<R2UploadedPart>\n\n  * Uploads a single part with the specified part number to this multipart upload. Each part must be uniform in size with an exception for the final part which can be smaller.\n  * Returns an `R2UploadedPart` object containing the `etag` and `partNumber`. These `R2UploadedPart` objects are required when completing the multipart upload.\n\n* `abort` (): Promise\\<void>\n\n  * Aborts the multipart upload. Returns a Promise that resolves when the upload has been successfully aborted.\n\n* `complete` (uploadedParts: R2UploadedPart\\[]): Promise\\<R2Object>\n\n  * Completes the multipart upload with the given parts.\n  * Returns a Promise that resolves when the complete operation has finished. Once this happens, the object is immediately accessible globally by any subsequent read operation.\n\n## Method-specific types\n\n### R2GetOptions\n\n* `onlyIf` R2Conditional | Headers\n\n  * Specifies that the object should only be returned given satisfaction of certain conditions in the `R2Conditional` or in the conditional Headers. Refer to [Conditional operations](#conditional-operations).\n\n* `range` R2Range\n\n  * Specifies that only a specific length (from an optional offset) or suffix of bytes from the object should be returned. Refer to [Ranged reads](#ranged-reads).\n\n* `ssecKey` ArrayBuffer | string\n\n  * Specifies a key to be used for [SSE-C](https://developers.cloudflare.com/r2/examples/ssec). Key must be 32 bytes in length, in the form of a hex-encoded string or an ArrayBuffer.\n\n#### Ranged reads\n\n`R2GetOptions` accepts a `range` parameter, which can be used to restrict the data returned in `body`.\n\nThere are 3 variations of arguments that can be used in a range:\n\n* An offset with an optional length.\n\n* An optional offset with a length.\n\n* A suffix.\n\n* `offset` number\n\n  * The byte to begin returning data from, inclusive.\n\n* `length` number\n\n  * The number of bytes to return. If more bytes are requested than exist in the object, fewer bytes than this number may be returned.\n\n* `suffix` number\n\n  * The number of bytes to return from the end of the file, starting from the last byte. If more bytes are requested than exist in the object, fewer bytes than this number may be returned.\n\n### R2PutOptions\n\n* `onlyIf` R2Conditional | Headers\n\n  * Specifies that the object should only be stored given satisfaction of certain conditions in the `R2Conditional`. Refer to [Conditional operations](#conditional-operations).\n\n* `httpMetadata` R2HTTPMetadata | Headers optional\n\n  * Various HTTP headers associated with the object. Refer to [HTTP Metadata](#http-metadata).\n\n* `customMetadata` Record\\<string, string> optional\n\n  * A map of custom, user-defined metadata that will be stored with the object.\n\nNote\n\nOnly a single hashing algorithm can be specified at once.\n\n* `md5` ArrayBuffer | string optional\n\n  * A md5 hash to use to check the received object's integrity.\n\n* `sha1` ArrayBuffer | string optional\n\n  * A SHA-1 hash to use to check the received object's integrity.\n\n* `sha256` ArrayBuffer | string optional\n\n  * A SHA-256 hash to use to check the received object's integrity.\n\n* `sha384` ArrayBuffer | string optional\n\n  * A SHA-384 hash to use to check the received object's integrity.\n\n* `sha512` ArrayBuffer | string optional\n\n  * A SHA-512 hash to use to check the received object's integrity.\n\n* `storageClass` 'Standard' | 'InfrequentAccess'\n\n  * Sets the storage class of the object if provided. Otherwise, the object will be stored in the default storage class associated with the bucket. Refer to [Storage Classes](#storage-class).\n\n* `ssecKey` ArrayBuffer | string\n\n  * Specifies a key to be used for [SSE-C](https://developers.cloudflare.com/r2/examples/ssec). Key must be 32 bytes in length, in the form of a hex-encoded string or an ArrayBuffer.\n\n### R2MultipartOptions\n\n* `httpMetadata` R2HTTPMetadata | Headers optional\n\n  * Various HTTP headers associated with the object. Refer to [HTTP Metadata](#http-metadata).\n\n* `customMetadata` Record\\<string, string> optional\n\n  * A map of custom, user-defined metadata that will be stored with the object.\n\n* `storageClass` string\n\n  * Sets the storage class of the object if provided. Otherwise, the object will be stored in the default storage class associated with the bucket. Refer to [Storage Classes](#storage-class).\n\n* `ssecKey` ArrayBuffer | string\n\n  * Specifies a key to be used for [SSE-C](https://developers.cloudflare.com/r2/examples/ssec). Key must be 32 bytes in length, in the form of a hex-encoded string or an ArrayBuffer.\n\n### R2ListOptions\n\n* `limit` number optional\n\n  * The number of results to return. Defaults to `1000`, with a maximum of `1000`.\n\n  * If `include` is set, you may receive fewer than `limit` results in your response to accommodate metadata.\n\n* `prefix` string optional\n\n  * The prefix to match keys against. Keys will only be returned if they start with given prefix.\n\n* `cursor` string optional\n\n  * An opaque token that indicates where to continue listing objects from. A cursor can be retrieved from a previous list operation.\n\n* `delimiter` string optional\n\n  * The character to use when grouping keys.\n\n* `include` Array\\<string> optional\n\n  * Can include `httpMetadata` and/or `customMetadata`. If included, items returned by the list will include the specified metadata.\n\n  * Note that there is a limit on the total amount of data that a single `list` operation can return. If you request data, you may receive fewer than `limit` results in your response to accommodate metadata.\n\n  * The [compatibility date](https://developers.cloudflare.com/workers/configuration/compatibility-dates/) must be set to `2022-08-04` or later in your Wrangler file. If not, then the `r2_list_honor_include` compatibility flag must be set. Otherwise it is treated as `include: ['httpMetadata', 'customMetadata']` regardless of what the `include` option provided actually is.\n\n  This means applications must be careful to avoid comparing the amount of returned objects against your `limit`. Instead, use the `truncated` property to determine if the `list` request has more data to be returned.",
      "language": "unknown"
    },
    {
      "code": "### R2Objects\n\nAn object containing an `R2Object` array, returned by `BUCKET_BINDING.list()`.\n\n* `objects` Array\\<R2Object>\n\n  * An array of objects matching the `list` request.\n\n* `truncated` boolean\n\n  * If true, indicates there are more results to be retrieved for the current `list` request.\n\n* `cursor` string optional\n\n  * A token that can be passed to future `list` calls to resume listing from that point. Only present if truncated is true.\n\n* `delimitedPrefixes` Array\\<string>\n\n  * If a delimiter has been specified, contains all prefixes between the specified prefix and the next occurrence of the delimiter.\n\n  * For example, if no prefix is provided and the delimiter is '/', `foo/bar/baz` would return `foo` as a delimited prefix. If `foo/` was passed as a prefix with the same structure and delimiter, `foo/bar` would be returned as a delimited prefix.\n\n### Conditional operations\n\nYou can pass an `R2Conditional` object to `R2GetOptions` and `R2PutOptions`. If the condition check for `get()` fails, the body will not be returned. This will make `get()` have lower latency.\n\nIf the condition check for `put()` fails, `null` will be returned instead of the `R2Object`.\n\n* `etagMatches` string optional\n\n  * Performs the operation if the object's etag matches the given string.\n\n* `etagDoesNotMatch` string optional\n\n  * Performs the operation if the object's etag does not match the given string.\n\n* `uploadedBefore` Date optional\n\n  * Performs the operation if the object was uploaded before the given date.\n\n* `uploadedAfter` Date optional\n\n  * Performs the operation if the object was uploaded after the given date.\n\nAlternatively, you can pass a `Headers` object containing conditional headers to `R2GetOptions` and `R2PutOptions`. For information on these conditional headers, refer to [the MDN docs on conditional requests](https://developer.mozilla.org/en-US/docs/Web/HTTP/Conditional_requests#conditional_headers). All conditional headers aside from `If-Range` are supported.\n\nFor more specific information about conditional requests, refer to [RFC 7232](https://datatracker.ietf.org/doc/html/rfc7232).\n\n### HTTP Metadata\n\nGenerally, these fields match the HTTP metadata passed when the object was created. They can be overridden when issuing `GET` requests, in which case, the given values will be echoed back in the response.\n\n* `contentType` string optional\n\n* `contentLanguage` string optional\n\n* `contentDisposition` string optional\n\n* `contentEncoding` string optional\n\n* `cacheControl` string optional\n\n* `cacheExpiry` Date optional\n\n### Checksums\n\nIf a checksum was provided when using the `put()` binding, it will be available on the returned object under the `checksums` property. The MD5 checksum will be included by default for non-multipart objects.\n\n* `md5` ArrayBuffer optional\n\n  * The MD5 checksum of the object.\n\n* `sha1` ArrayBuffer optional\n\n  * The SHA-1 checksum of the object.\n\n* `sha256` ArrayBuffer optional\n\n  * The SHA-256 checksum of the object.\n\n* `sha384` ArrayBuffer optional\n\n  * The SHA-384 checksum of the object.\n\n* `sha512` ArrayBuffer optional\n\n  * The SHA-512 checksum of the object.\n\n### `R2UploadedPart`\n\nAn `R2UploadedPart` object represents a part that has been uploaded. `R2UploadedPart` objects are returned from `uploadPart` operations and must be passed to `completeMultipartUpload` operations.\n\n* `partNumber` number\n\n  * The number of the part.\n\n* `etag` string\n\n  * The `etag` of the part.\n\n### Storage Class\n\nThe storage class where an `R2Object` is stored. The available storage classes are `Standard` and `InfrequentAccess`. Refer to [Storage classes](https://developers.cloudflare.com/r2/buckets/storage-classes/) for more information.\n\n</page>\n\n<page>\n---\ntitle: Use the R2 multipart API from Workers · Cloudflare R2 docs\ndescription: >-\n  By following this guide, you will create a Worker through which your\n  applications can perform multipart uploads.\n\n  This example worker could serve as a basis for your own use case where you can\n  add authentication to the worker, or even add extra validation logic when\n  uploading each part.\n\n  This guide also contains an example Python application that uploads files to\n  this worker.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/r2/api/workers/workers-multipart-usage/\n  md: https://developers.cloudflare.com/r2/api/workers/workers-multipart-usage/index.md\n---\n\nBy following this guide, you will create a Worker through which your applications can perform multipart uploads. This example worker could serve as a basis for your own use case where you can add authentication to the worker, or even add extra validation logic when uploading each part. This guide also contains an example Python application that uploads files to this worker.\n\nThis guide assumes you have set up the [R2 binding](https://developers.cloudflare.com/workers/runtime-apis/bindings/) for your Worker. Refer to [Use R2 from Workers](https://developers.cloudflare.com/r2/api/workers/workers-api-usage) for instructions on setting up an R2 binding.\n\n## An example Worker using the multipart API\n\nThe following example Worker exposes an HTTP API which enables applications to use the multipart API through the Worker.\n\nIn this example, each request is routed based on the HTTP method and the action request parameter. As your Worker becomes more complicated, consider utilizing a serverless web framework such as [Hono](https://honojs.dev/) to handle the routing for you.\n\nThe following example Worker includes any new information about the state of the multipart upload in the response to each request. For the request which creates the multipart upload, the `uploadId` is returned. For requests uploading a part, the part number and `etag` are returned. In turn, the client keeps track of this state, and includes the uploadId in subsequent requests, and the `etag` and part number of each part when completing a multipart upload.\n\nAdd the following code to your project's `index.js` file and replace `MY_BUCKET` with your bucket's name:",
      "language": "unknown"
    },
    {
      "code": "After you have updated your Worker with the above code, run `npx wrangler deploy`.\n\nYou can now use this Worker to perform multipart uploads. You can either send requests from your existing application to this Worker to perform uploads or use a script to upload files through this Worker.\n\nThe next section is optional and shows an example of a Python script which uploads a chosen file on your machine to your Worker.\n\n## Perform a multipart upload with your Worker (optional)\n\nThis example application uploads a local file to the Worker in multiple parts. It uses Python's built-in `ThreadPoolExecutor` to parallelize the uploading of parts to the Worker, which increases upload speeds. HTTP requests to the Worker are made with the [requests](https://pypi.org/project/requests/) library.\n\nUtilizing the multipart API in this way also allows you to use your Worker to upload files larger than the [Workers request body size limit](https://developers.cloudflare.com/workers/platform/limits#request-limits). The uploading of individual parts is still subject to this limit.\n\nSave the following code in a file named `mpuscript.py` on your local machine. Change the `worker_endpoint variable` to where your worker is deployed. Pass the file you want to upload as an argument when running this script: `python3 mpuscript.py myfile`. This will upload the file `myfile` from your machine to your bucket through the Worker.",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Concepts",
      "id": "concepts"
    },
    {
      "level": "h2",
      "text": "Create a binding",
      "id": "create-a-binding"
    },
    {
      "level": "h2",
      "text": "Bucket method definitions",
      "id": "bucket-method-definitions"
    },
    {
      "level": "h2",
      "text": "`R2Object` definition",
      "id": "`r2object`-definition"
    },
    {
      "level": "h2",
      "text": "`R2ObjectBody` definition",
      "id": "`r2objectbody`-definition"
    },
    {
      "level": "h2",
      "text": "`R2MultipartUpload` definition",
      "id": "`r2multipartupload`-definition"
    },
    {
      "level": "h2",
      "text": "Method-specific types",
      "id": "method-specific-types"
    },
    {
      "level": "h3",
      "text": "R2GetOptions",
      "id": "r2getoptions"
    },
    {
      "level": "h3",
      "text": "R2PutOptions",
      "id": "r2putoptions"
    },
    {
      "level": "h3",
      "text": "R2MultipartOptions",
      "id": "r2multipartoptions"
    },
    {
      "level": "h3",
      "text": "R2ListOptions",
      "id": "r2listoptions"
    },
    {
      "level": "h3",
      "text": "R2Objects",
      "id": "r2objects"
    },
    {
      "level": "h3",
      "text": "Conditional operations",
      "id": "conditional-operations"
    },
    {
      "level": "h3",
      "text": "HTTP Metadata",
      "id": "http-metadata"
    },
    {
      "level": "h3",
      "text": "Checksums",
      "id": "checksums"
    },
    {
      "level": "h3",
      "text": "`R2UploadedPart`",
      "id": "`r2uploadedpart`"
    },
    {
      "level": "h3",
      "text": "Storage Class",
      "id": "storage-class"
    },
    {
      "level": "h2",
      "text": "An example Worker using the multipart API",
      "id": "an-example-worker-using-the-multipart-api"
    },
    {
      "level": "h2",
      "text": "Perform a multipart upload with your Worker (optional)",
      "id": "perform-a-multipart-upload-with-your-worker-(optional)"
    }
  ],
  "url": "llms-txt#note:-this-is-the-value-that-was-successfully-put-above",
  "links": []
}