{
  "title": "Webhook secret (use the same value from .dev.vars)",
  "content": "npx wrangler secret put WEBHOOK_SECRET\nsh\n  npm create cloudflare@latest -- data-pipeline --template=cloudflare/sandbox-sdk/examples/minimal\n  sh\n  yarn create cloudflare data-pipeline --template=cloudflare/sandbox-sdk/examples/minimal\n  sh\n  pnpm create cloudflare@latest data-pipeline --template=cloudflare/sandbox-sdk/examples/minimal\n  sh\ncd data-pipeline\njson\n{\n  \"name\": \"data-pipeline\",\n  \"compatibility_date\": \"2025-11-09\",\n  \"durable_objects\": {\n    \"bindings\": [\n      { \"name\": \"Sandbox\", \"class_name\": \"Sandbox\" }\n    ]\n  },\n  \"r2_buckets\": [\n    {\n      \"binding\": \"DATA_BUCKET\",\n      \"bucket_name\": \"my-data-bucket\"\n    }\n  ]\n}\njs\n  import { getSandbox } from \"@cloudflare/sandbox\";\n\nexport { Sandbox } from \"@cloudflare/sandbox\";\n\nexport default {\n    async fetch(request, env) {\n      const url = new URL(request.url);\n      const sandbox = getSandbox(env.Sandbox, \"data-processor\");\n\n// Mount R2 bucket to /data directory\n      await sandbox.mountBucket(\"my-data-bucket\", \"/data\", {\n        endpoint: \"https://YOUR_ACCOUNT_ID.r2.cloudflarestorage.com\",\n      });\n\nif (url.pathname === \"/process\") {\n        // Process data and save to mounted R2\n        const result = await sandbox.exec(\"python\", {\n          args: [\n            \"-c\",\n            `\n  import json\n  import os\n  from datetime import datetime\n\n# Read input (or create sample data)\n  data = [\n      {'id': 1, 'value': 42},\n      {'id': 2, 'value': 87},\n      {'id': 3, 'value': 15}\n  ]\n\n# Process: calculate sum and average\n  total = sum(item['value'] for item in data)\n  avg = total / len(data)\n\n# Save results to mounted R2 (/data is the mounted bucket)\n  result = {\n      'timestamp': datetime.now().isoformat(),\n      'total': total,\n      'average': avg,\n      'processed_count': len(data)\n  }\n\nos.makedirs('/data/results', exist_ok=True)\n  with open('/data/results/latest.json', 'w') as f:\n      json.dump(result, f, indent=2)\n\nprint(json.dumps(result))\n          `,\n          ],\n        });\n\nreturn Response.json({\n          message: \"Data processed and saved to R2\",\n          result: JSON.parse(result.stdout),\n        });\n      }\n\nif (url.pathname === \"/results\") {\n        // Read results from mounted R2\n        const result = await sandbox.exec(\"cat\", {\n          args: [\"/data/results/latest.json\"],\n        });\n\nif (!result.success) {\n          return Response.json(\n            { error: \"No results found yet\" },\n            { status: 404 },\n          );\n        }\n\nreturn Response.json({\n          message: \"Results retrieved from R2\",\n          data: JSON.parse(result.stdout),\n        });\n      }\n\nif (url.pathname === \"/destroy\") {\n        // Destroy sandbox to demonstrate persistence\n        await sandbox.destroy();\n        return Response.json({\n          message: \"Sandbox destroyed. Data persists in R2!\",\n        });\n      }\n\nreturn new Response(\n        `\n  Data Pipeline with Persistent Storage\n\nEndpoints:\n  - POST /process  - Process data and save to R2\n  - GET /results   - Retrieve results from R2\n  - POST /destroy  - Destroy sandbox (data survives!)\n\nTry this flow:\n  1. POST /process  (processes and saves to R2)\n  2. POST /destroy  (destroys sandbox)\n  3. GET /results   (data still accessible from R2)\n      `,\n        { headers: { \"Content-Type\": \"text/plain\" } },\n      );\n    },\n  };\n  ts\n  import { getSandbox, type Sandbox } from '@cloudflare/sandbox';\n\nexport { Sandbox } from '@cloudflare/sandbox';\n\ninterface Env {\n    Sandbox: DurableObjectNamespace<Sandbox>;\n    DATA_BUCKET: R2Bucket;\n  }\n\nexport default {\n    async fetch(request: Request, env: Env): Promise<Response> {\n      const url = new URL(request.url);\n      const sandbox = getSandbox(env.Sandbox, 'data-processor');\n\n// Mount R2 bucket to /data directory\n      await sandbox.mountBucket('my-data-bucket', '/data', {\n        endpoint: 'https://YOUR_ACCOUNT_ID.r2.cloudflarestorage.com'\n      });\n\nif (url.pathname === '/process') {\n        // Process data and save to mounted R2\n        const result = await sandbox.exec('python', {\n          args: ['-c', `\n  import json\n  import os\n  from datetime import datetime\n\n# Read input (or create sample data)\n  data = [\n      {'id': 1, 'value': 42},\n      {'id': 2, 'value': 87},\n      {'id': 3, 'value': 15}\n  ]\n\n# Process: calculate sum and average\n  total = sum(item['value'] for item in data)\n  avg = total / len(data)\n\n# Save results to mounted R2 (/data is the mounted bucket)\n  result = {\n      'timestamp': datetime.now().isoformat(),\n      'total': total,\n      'average': avg,\n      'processed_count': len(data)\n  }\n\nos.makedirs('/data/results', exist_ok=True)\n  with open('/data/results/latest.json', 'w') as f:\n      json.dump(result, f, indent=2)\n\nprint(json.dumps(result))\n          `]\n        });\n\nreturn Response.json({\n          message: 'Data processed and saved to R2',\n          result: JSON.parse(result.stdout)\n        });\n      }\n\nif (url.pathname === '/results') {\n        // Read results from mounted R2\n        const result = await sandbox.exec('cat', {\n          args: ['/data/results/latest.json']\n        });\n\nif (!result.success) {\n          return Response.json({ error: 'No results found yet' }, { status: 404 });\n        }\n\nreturn Response.json({\n          message: 'Results retrieved from R2',\n          data: JSON.parse(result.stdout)\n        });\n      }\n\nif (url.pathname === '/destroy') {\n        // Destroy sandbox to demonstrate persistence\n        await sandbox.destroy();\n        return Response.json({ message: 'Sandbox destroyed. Data persists in R2!' });\n      }\n\nreturn new Response(`\n  Data Pipeline with Persistent Storage\n\nEndpoints:\n  - POST /process  - Process data and save to R2\n  - GET /results   - Retrieve results from R2\n  - POST /destroy  - Destroy sandbox (data survives!)\n\nTry this flow:\n  1. POST /process  (processes and saves to R2)\n  2. POST /destroy  (destroys sandbox)\n  3. GET /results   (data still accessible from R2)\n      `, { headers: { 'Content-Type': 'text/plain' } });\n    }\n  };\n  sh\nnpx wrangler secret put AWS_ACCESS_KEY_ID",
  "code_samples": [
    {
      "code": "## 9. Update webhook for production\n\n1. Go to your repository **Settings** > **Webhooks**\n2. Click on your existing webhook\n3. Update **Payload URL** to your deployed Worker URL: `https://code-review-bot.YOUR_SUBDOMAIN.workers.dev/webhook`\n4. Click **Update webhook**\n\nYour bot is now running in production and will review all new pull requests automatically.\n\n## What you built\n\nA GitHub code review bot that:\n\n* Receives webhook events from GitHub\n* Clones repositories in isolated sandboxes\n* Uses Claude to analyze code changes\n* Posts review comments automatically\n\n## Next steps\n\n* [Git operations](https://developers.cloudflare.com/sandbox/api/files/#gitcheckout) - Advanced repository handling\n* [Sessions API](https://developers.cloudflare.com/sandbox/api/sessions/) - Manage long-running sandbox operations\n* [GitHub Apps](https://docs.github.com/en/apps) - Build a proper GitHub App\n\n</page>\n\n<page>\n---\ntitle: Data persistence with R2 Â· Cloudflare Sandbox SDK docs\ndescription: Mount R2 buckets as local filesystem paths to persist data across\n  sandbox lifecycles.\nlastUpdated: 2025-11-18T19:18:00.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/sandbox/tutorials/persistent-storage/\n  md: https://developers.cloudflare.com/sandbox/tutorials/persistent-storage/index.md\n---\n\nMount object storage buckets as local filesystem paths to persist data across sandbox lifecycles. This tutorial uses Cloudflare R2, but the same approach works with any S3-compatible provider.\n\n**Time to complete:** 20 minutes\n\n## What you'll build\n\nA Worker that processes data, stores results in an R2 bucket mounted as a local directory, and demonstrates that data persists even after the sandbox is destroyed and recreated.\n\n**Key concepts you'll learn**:\n\n* Mounting R2 buckets as filesystem paths\n* Automatic data persistence across sandbox lifecycles\n* Working with mounted storage using standard file operations\n\n## Prerequisites\n\n1. Sign up for a [Cloudflare account](https://dash.cloudflare.com/sign-up/workers-and-pages).\n2. Install [`Node.js`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm).\n\nNode.js version manager\n\nUse a Node version manager like [Volta](https://volta.sh/) or [nvm](https://github.com/nvm-sh/nvm) to avoid permission issues and change Node.js versions. [Wrangler](https://developers.cloudflare.com/workers/wrangler/install-and-update/), discussed later in this guide, requires a Node version of `16.17.0` or later.\n\nYou'll also need:\n\n* [Docker](https://www.docker.com/) running locally\n* An R2 bucket (create one in the [Cloudflare dashboard](https://dash.cloudflare.com/?to=/:account/r2))\n\n## 1. Create your project\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "## 2. Configure R2 binding\n\nAdd an R2 bucket binding to your `wrangler.json`:",
      "language": "unknown"
    },
    {
      "code": "Replace `my-data-bucket` with your R2 bucket name. Create the bucket first in the [Cloudflare dashboard](https://dash.cloudflare.com/?to=/:account/r2).\n\n## 3. Build the data processor\n\nReplace `src/index.ts` with code that mounts R2 and processes data:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Replace YOUR\\_ACCOUNT\\_ID\n\nReplace `YOUR_ACCOUNT_ID` in the endpoint URL with your Cloudflare account ID. Find it in the [dashboard](https://dash.cloudflare.com/) under **R2** > **Overview**.\n\n## 4. Local development limitation\n\nRequires production deployment\n\nBucket mounting does not work with `wrangler dev` because it requires FUSE support that wrangler does not currently provide. You must deploy to production to test this feature. All other Sandbox SDK features work locally - only `mountBucket()` and `unmountBucket()` require production deployment.\n\n## 5. Deploy to production\n\n**Generate R2 API tokens:**\n\n1. Go to **R2** > **Overview** in the [Cloudflare dashboard](https://dash.cloudflare.com/)\n2. Select **Manage R2 API Tokens**\n3. Create a token with **Object Read & Write** permissions\n4. Copy the **Access Key ID** and **Secret Access Key**\n\n**Set up credentials as Worker secrets:**",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "9. Update webhook for production",
      "id": "9.-update-webhook-for-production"
    },
    {
      "level": "h2",
      "text": "What you built",
      "id": "what-you-built"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "What you'll build",
      "id": "what-you'll-build"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "1. Create your project",
      "id": "1.-create-your-project"
    },
    {
      "level": "h2",
      "text": "2. Configure R2 binding",
      "id": "2.-configure-r2-binding"
    },
    {
      "level": "h2",
      "text": "3. Build the data processor",
      "id": "3.-build-the-data-processor"
    },
    {
      "level": "h2",
      "text": "4. Local development limitation",
      "id": "4.-local-development-limitation"
    },
    {
      "level": "h2",
      "text": "5. Deploy to production",
      "id": "5.-deploy-to-production"
    }
  ],
  "url": "llms-txt#webhook-secret-(use-the-same-value-from-.dev.vars)",
  "links": []
}