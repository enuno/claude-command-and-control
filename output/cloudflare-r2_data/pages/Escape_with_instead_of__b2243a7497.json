{
  "title": "Escape with ` instead of \\",
  "content": "npx wrangler d1 execute prisma-demo-db --command \"INSERT INTO  `\"User`\" (`\"email`\", `\"name`\") VALUES\n('jane@prisma.io', 'Jane Doe (Local)');\" --<FLAG>\njs\n  import { PrismaClient } from \"./generated/prisma/\";\n  import { PrismaD1 } from \"@prisma/adapter-d1\";\n\nexport default {\n    async fetch(request, env, ctx) {\n      const adapter = new PrismaD1(env.DB);\n      const prisma = new PrismaClient({ adapter });\n\nconst users = await prisma.user.findMany();\n      const result = JSON.stringify(users);\n      return new Response(result);\n    },\n  };\n  ts\n  import { PrismaClient } from './generated/prisma/';\n  import { PrismaD1 } from '@prisma/adapter-d1';\n\nexport interface Env {\n    DB: D1Database;\n  }\n\nexport default {\n    async fetch(request, env, ctx): Promise<Response> {\n      const adapter = new PrismaD1(env.DB);\n      const prisma = new PrismaClient({ adapter });\n\nconst users = await prisma.user.findMany();\n      const result = JSON.stringify(users);\n      return new Response(result);\n    },\n  } satisfies ExportedHandler<Env>;\n  sh\nnpx prisma generate\nsh\nnpm run dev\njson\n[{ \"id\": 1, \"email\": \"jane@prisma.io\", \"name\": \"Jane Doe (Local)\" }]\nsh\nnpm run deploy\njson\n[{ \"id\": 1, \"email\": \"jane@prisma.io\", \"name\": \"Jane Doe (Remote)\" }]\nsql\n   DROP TABLE IF EXISTS TargetD1Table;\n   CREATE TABLE IF NOT EXISTS TargetD1Table (id INTEGER PRIMARY KEY, text TEXT, date_added TEXT);\n   bash\n   # Create a D1 database\n   npx wrangler d1 create d1-import-tutorial\n\n# Create a D1 table\n   npx wrangler d1 execute d1-import-tutorial --command=\"DROP TABLE IF EXISTS TargetD1Table; CREATE TABLE IF NOT EXISTS TargetD1Table (id INTEGER PRIMARY KEY, text TEXT, date_added TEXT);\" --remote\n   bash\n   mkdir d1-import-tutorial\n   cd d1-import-tutorial\n   npm init -y\n   js\n   const TARGET_TABLE = \" \"; // for the tutorial, `TargetD1Table`\n   const ACCOUNT_ID = \" \";\n   const DATABASE_ID = \" \";\n   const D1_API_KEY = \" \";\n   const D1_URL = `https://api.cloudflare.com/client/v4/accounts/${ACCOUNT_ID}/d1/database/${DATABASE_ID}/import`;\n   const filename = crypto.randomUUID(); // create a random filename\n   const uploadSize = 500;\n   const headers = {\n     \"Content-Type\": \"application/json\",\n     Authorization: `Bearer ${D1_API_KEY}`,\n   };\n   sh\n     npm i @faker-js/faker\n     sh\n     yarn add @faker-js/faker\n     sh\n     pnpm add @faker-js/faker\n     js\n   import crypto from \"crypto\";\n   import { faker } from \"@faker-js/faker\";\n\n// Generate Fake data\n   const data = Array.from({ length: uploadSize }, () => ({\n     id: Math.floor(Math.random() * 1000000),\n     text: faker.lorem.paragraph(),\n     date_added: new Date().toISOString().slice(0, 19).replace(\"T\", \" \"),\n   }));\n   js\n   function makeSqlInsert(data, tableName, skipCols = []) {\n     const columns = Object.keys(data[0]).join(\",\");\n     const values = data\n       .map((row) => {\n         return (\n           \"(\" +\n           Object.values(row)\n             .map((val) => {\n               if (skipCols.includes(val) || val === null || val === \"\") {\n                 return \"NULL\";\n               }\n               return `'${String(val).replace(/'/g, \"\").replace(/\"/g, \"'\")}'`;\n             })\n             .join(\",\") +\n           \")\"\n         );\n       })\n       .join(\",\");\n\nreturn `INSERT INTO ${tableName} (${columns}) VALUES ${values};`;\n   }\n   js\n   async function uploadToD1() {\n     // 1. Init upload\n     const hashStr = crypto.createHash(\"md5\").update(sqlInsert).digest(\"hex\");\n\ntry {\n       const initResponse = await fetch(D1_URL, {\n         method: \"POST\",\n         headers,\n         body: JSON.stringify({\n           action: \"init\",\n           etag: hashStr,\n         }),\n       });\n\nconst uploadData = await initResponse.json();\n       const uploadUrl = uploadData.result.upload_url;\n       const filename = uploadData.result.filename;\n\n// 2. Upload to R2\n       const r2Response = await fetch(uploadUrl, {\n         method: \"PUT\",\n         body: sqlInsert,\n       });\n\nconst r2Etag = r2Response.headers.get(\"ETag\").replace(/\"/g, \"\");\n\n// Verify etag\n       if (r2Etag !== hashStr) {\n         throw new Error(\"ETag mismatch\");\n       }\n\n// 3. Start ingestion\n       const ingestResponse = await fetch(D1_URL, {\n         method: \"POST\",\n         headers,\n         body: JSON.stringify({\n           action: \"ingest\",\n           etag: hashStr,\n           filename,\n         }),\n       });\n\nconst ingestData = await ingestResponse.json();\n       console.log(\"Ingestion Response:\", ingestData);\n\n// 4. Polling\n       await pollImport(ingestData.result.at_bookmark);\n\nreturn \"Import completed successfully\";\n     } catch (e) {\n       console.error(\"Error:\", e);\n       return \"Import failed\";\n     }\n   }\n   js\n   async function pollImport(bookmark) {\n     const payload = {\n       action: \"poll\",\n       current_bookmark: bookmark,\n     };\n\nwhile (true) {\n       const pollResponse = await fetch(D1_URL, {\n         method: \"POST\",\n         headers,\n         body: JSON.stringify(payload),\n       });\n\nconst result = await pollResponse.json();\n       console.log(\"Poll Response:\", result.result);\n\nconst { success, error } = result.result;\n\nif (\n         success ||\n         (!success && error === \"Not currently importing anything.\")\n       ) {\n         break;\n       }\n\nawait new Promise((resolve) => setTimeout(resolve, 1000));\n     }\n   }\n   js\n   async function runImport() {\n     const result = await uploadToD1();\n     console.log(result);\n   }\n\nrunImport();\n   js\n   import crypto from \"crypto\";\n   import { faker } from \"@faker-js/faker\";\n\nconst TARGET_TABLE = \"\";\n   const ACCOUNT_ID = \"\";\n   const DATABASE_ID = \"\";\n   const D1_API_KEY = \"\";\n   const D1_URL = `https://api.cloudflare.com/client/v4/accounts/${ACCOUNT_ID}/d1/database/${DATABASE_ID}/import`;\n   const uploadSize = 500;\n   const headers = {\n     \"Content-Type\": \"application/json\",\n     Authorization: `Bearer ${D1_API_KEY}`,\n   };\n\n// Generate Fake data\n   const data = Array.from({ length: uploadSize }, () => ({\n     id: Math.floor(Math.random() * 1000000),\n     text: faker.lorem.paragraph(),\n     date_added: new Date().toISOString().slice(0, 19).replace(\"T\", \" \"),\n   }));\n\n// Make SQL insert statements\n   function makeSqlInsert(data, tableName, skipCols = []) {\n     const columns = Object.keys(data[0]).join(\",\");\n     const values = data\n       .map((row) => {\n         return (\n           \"(\" +\n           Object.values(row)\n             .map((val) => {\n               if (skipCols.includes(val) || val === null || val === \"\") {\n                 return \"NULL\";\n               }\n               return `'${String(val).replace(/'/g, \"\").replace(/\"/g, \"'\")}'`;\n             })\n             .join(\",\") +\n           \")\"\n         );\n       })\n       .join(\",\");\n\nreturn `INSERT INTO ${tableName} (${columns}) VALUES ${values};`;\n   }\n\nconst sqlInsert = makeSqlInsert(data, TARGET_TABLE);\n\nasync function pollImport(bookmark) {\n     const payload = {\n       action: \"poll\",\n       current_bookmark: bookmark,\n     };\n\nwhile (true) {\n       const pollResponse = await fetch(D1_URL, {\n         method: \"POST\",\n         headers,\n         body: JSON.stringify(payload),\n       });\n\nconst result = await pollResponse.json();\n       console.log(\"Poll Response:\", result.result);\n\nconst { success, error } = result.result;\n\nif (\n         success ||\n         (!success && error === \"Not currently importing anything.\")\n       ) {\n         break;\n       }\n\nawait new Promise((resolve) => setTimeout(resolve, 1000));\n     }\n   }\n\n// Upload to D1\n   async function uploadToD1() {\n     // 1. Init upload\n     const hashStr = crypto.createHash(\"md5\").update(sqlInsert).digest(\"hex\");\n\ntry {\n       const initResponse = await fetch(D1_URL, {\n         method: \"POST\",\n         headers,\n         body: JSON.stringify({\n           action: \"init\",\n           etag: hashStr,\n         }),\n       });\n\nconst uploadData = await initResponse.json();\n       const uploadUrl = uploadData.result.upload_url;\n       const filename = uploadData.result.filename;\n\n// 2. Upload to R2\n       const r2Response = await fetch(uploadUrl, {\n         method: \"PUT\",\n         body: sqlInsert,\n       });\n\nconst r2Etag = r2Response.headers.get(\"ETag\").replace(/\"/g, \"\");\n\n// Verify etag\n       if (r2Etag !== hashStr) {\n         throw new Error(\"ETag mismatch\");\n       }\n\n// 3. Start ingestion\n       const ingestResponse = await fetch(D1_URL, {\n         method: \"POST\",\n         headers,\n         body: JSON.stringify({\n           action: \"ingest\",\n           etag: hashStr,\n           filename,\n         }),\n       });\n\nconst ingestData = await ingestResponse.json();\n       console.log(\"Ingestion Response:\", ingestData);\n\n// 4. Polling\n       await pollImport(ingestData.result.at_bookmark);\n\nreturn \"Import completed successfully\";\n     } catch (e) {\n       console.error(\"Error:\", e);\n       return \"Import failed\";\n     }\n   }\n\nasync function runImport() {\n     const result = await uploadToD1();\n     console.log(result);\n   }\n\nrunImport();\n   sh\n   node index.js\n   sh\n  npm create cloudflare@latest -- fast-commerce\n  sh\n  yarn create cloudflare fast-commerce\n  sh\n  pnpm create cloudflare@latest fast-commerce\n  sh\n  npm i hono\n  sh\n  yarn add hono\n  sh\n  pnpm add hono\n  sh\ncd fast-commerce\nhtml\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"UTF-8\" />\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    <title>E-commerce Store</title>\n    <style>\n      * {\n        margin: 0;\n        padding: 0;\n        box-sizing: border-box;\n        font-family: Arial, sans-serif;\n      }\n\nbody {\n          background-color: #f9fafb;\n          min-height: 100vh;\n          display: flex;\n          flex-direction: column;\n        }\n\nheader {\n          background-color: white;\n          padding: 1rem 2rem;\n          display: flex;\n          justify-content: space-between;\n          align-items: center;\n          border-bottom: 1px solid #e5e7eb;\n        }\n\n.store-title {\n          font-weight: bold;\n          font-size: 1.25rem;\n        }\n\n.cart-button {\n          padding: 0.5rem 1rem;\n          cursor: pointer;\n          background: none;\n          border: none;\n        }\n\n.products-grid {\n          display: grid;\n          grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));\n          gap: 1.5rem;\n          padding: 2rem;\n        }\n\n.product-card {\n          background-color: white;\n          border-radius: 0.5rem;\n          overflow: hidden;\n          box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);\n        }\n\n.product-info {\n          padding: 1rem;\n        }\n\n.product-title {\n          font-size: 1.125rem;\n          font-weight: 600;\n          margin-bottom: 0.5rem;\n        }\n\n.product-description {\n          color: #4b5563;\n          font-size: 0.875rem;\n          margin-bottom: 1rem;\n        }\n\n.product-price {\n          font-size: 1.25rem;\n          font-weight: bold;\n          margin-bottom: 0.5rem;\n        }\n\n.product-stock {\n          color: #4b5563;\n          font-size: 0.875rem;\n          margin-bottom: 1rem;\n        }\n\n.view-details-btn {\n          display: block;\n          width: 100%;\n          padding: 0.5rem 0;\n          background-color: #2563eb;\n          color: white;\n          border: none;\n          border-radius: 0.375rem;\n          cursor: pointer;\n          text-align: center;\n          text-decoration: none;\n          font-size: 0.875rem;\n        }\n\n.view-details-btn:hover {\n          background-color: #1d4ed8;\n        }\n\nfooter {\n          background-color: white;\n          padding: 1rem 2rem;\n          text-align: center;\n          border-top: 1px solid #e5e7eb;\n          color: #4b5563;\n          font-size: 0.875rem;\n        }\n\n/* Basic Responsiveness */\n        @media (max-width: 768px) {\n          .products-grid {\n            grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));\n          }\n        }\n\n@media (max-width: 480px) {\n          .products-grid {\n            grid-template-columns: 1fr;\n          }\n        }\n      </style>\n    </head>\n    <body>\n      <header>\n        <h1 class=\"store-title\">E-commerce Store</h1>\n        <button class=\"cart-button\">Cart</button>\n      </header>\n\n<main class=\"products-grid\" id=\"products-container\">\n        <!-- Products will be loaded here by JavaScript -->\n      </main>\n\n<footer>\n        <p>© 2025 E-commerce Store. All rights reserved.</p>\n      </footer>\n\n<script>\n        document.addEventListener('DOMContentLoaded', () => {\n          let products = [];\n          let d1Duration,\n            queryDuration = 0;\n          let dbLocation;\n          let isPrimary = true;\n\n// Function to create product HTML\n          function createProductCard(product) {\n            return `\n                <div class=\"product-card\" data-category=\"${product.category}\">\n                    <div class=\"product-info\">\n                        <h3 class=\"product-title\">${product.name}</h3>\n                        <p class=\"product-description\">${product.description}</p>\n                        <p class=\"product-price\">$${product.price.toFixed(2)}</p>\n                        <p class=\"product-stock\">${product.inventory} in stock</p>\n                        <a href=\"product-details.html?id=${product.id}\" class=\"view-details-btn\">View Details</a>\n                    </div>\n                </div>\n            `;\n          }\n\n// Function to render content\n          function renderContent() {\n            try {\n              const productsContainer = document.getElementById('products-container');\n              if (!productsContainer) return;\n              productsContainer.innerHTML = '';\n\nproducts.forEach((product) => {\n                productsContainer.innerHTML += createProductCard(product);\n              });\n            } catch (error) {\n              console.error('Error rendering content:', error);\n            }\n          }\n\n// Fetch products\n          fetch('/api/products')\n            .then((response) => response.json())\n            .then((data) => {\n              products = data;\n              renderContent();\n            })\n            .catch((error) => console.error('Error fetching products:', error));\n        });\n      </script>\n    </body>\n\n</html>\nhtml\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"UTF-8\" />\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    <title>Product Details - E-commerce Store</title>\n    <style>\n      * {\n        margin: 0;\n        padding: 0;\n        box-sizing: border-box;\n        font-family: Arial, sans-serif;\n      }\n\nbody {\n        background-color: #f9fafb;\n        min-height: 100vh;\n        display: flex;\n        flex-direction: column;\n      }\n\nheader {\n        background-color: white;\n        padding: 1rem 2rem;\n        display: flex;\n        justify-content: space-between;\n        align-items: center;\n        border-bottom: 1px solid #e5e7eb;\n      }\n\n.store-title {\n        font-weight: bold;\n        font-size: 1.25rem;\n        text-decoration: none;\n        color: black;\n      }\n\n.cart-button {\n        padding: 0.5rem 1rem;\n        cursor: pointer;\n        background: none;\n        border: none;\n      }\n\n.product-container {\n        max-width: 800px;\n        margin: 2rem auto;\n        background-color: white;\n        border-radius: 0.5rem;\n        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);\n        padding: 2rem;\n      }\n\n.product-title {\n        font-size: 1.875rem;\n        font-weight: bold;\n        margin-bottom: 0.5rem;\n      }\n\n.product-description {\n        color: #4b5563;\n        margin-bottom: 1.5rem;\n      }\n\n.product-price {\n        font-size: 1.875rem;\n        font-weight: bold;\n        margin-bottom: 0.5rem;\n      }\n\n.product-stock {\n        font-size: 0.875rem;\n        color: #4b5563;\n        text-align: right;\n      }\n\n.add-to-cart-btn {\n        display: block;\n        width: 100%;\n        padding: 0.75rem;\n        background-color: #2563eb;\n        color: white;\n        border: none;\n        border-radius: 0.375rem;\n        cursor: pointer;\n        text-align: center;\n        font-size: 1rem;\n        margin-top: 1.5rem;\n      }\n\n.add-to-cart-btn:hover {\n        background-color: #1d4ed8;\n      }\n\n.price-stock-container {\n        display: flex;\n        justify-content: space-between;\n        align-items: center;\n        margin-bottom: 1rem;\n      }\n\nfooter {\n        background-color: white;\n        padding: 1rem 2rem;\n        text-align: center;\n        border-top: 1px solid #e5e7eb;\n        color: #4b5563;\n        font-size: 0.875rem;\n        margin-top: auto;\n      }\n\n/* Back button */\n      .back-button {\n        display: inline-block;\n        margin-bottom: 1.5rem;\n        color: #2563eb;\n        text-decoration: none;\n        font-size: 0.875rem;\n      }\n\n.back-button:hover {\n        text-decoration: underline;\n      }\n\n/* Notification */\n      .notification {\n        position: fixed;\n        top: 1rem;\n        right: 1rem;\n        background-color: #10b981;\n        color: white;\n        padding: 0.75rem 1rem;\n        border-radius: 0.375rem;\n        box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);\n        transform: translateX(150%);\n        transition: transform 0.3s ease;\n      }\n\n.notification.show {\n        transform: translateX(0);\n      }\n    </style>\n  </head>\n  <body>\n    <header>\n      <a href=\"index.html\" class=\"store-title\">E-commerce Store</a>\n      <button class=\"cart-button\">Cart</button>\n    </header>\n\n<main class=\"product-container\">\n      <a href=\"index.html\" class=\"back-button\">← Back to products</a>\n      <h1 class=\"product-title\" id=\"product-title\">Product Name</h1>\n      <p class=\"product-description\" id=\"product-description\">\n        Product description goes here.\n      </p>\n\n<div class=\"price-stock-container\">\n        <p class=\"product-price\" id=\"product-price\">$0.00</p>\n        <p class=\"product-stock\" id=\"product-stock\">0 in stock</p>\n      </div>\n\n<button class=\"add-to-cart-btn\" id=\"add-to-cart\">Add to Cart</button>\n    </main>\n\n<div class=\"notification\" id=\"notification\">Added to cart!</div>\n\n<footer>\n      <p>© 2025 E-commerce Store. All rights reserved.</p>\n    </footer>\n\n<script>\n      // Get query parameter from URL\n      const url = new URL(window.location.href);\n      const searchParams = new URLSearchParams(url.search);\n      const productId = searchParams.get(\"id\");\n\n// Fetch product details\n      fetch(`/api/products/${productId}`)\n        .then((response) => response.json())\n        .then((product) => displayContent(product))\n        .catch((error) =>\n          console.error(\"Error fetching product details:\", error),\n        );\n\n// Function to display product details\n      function displayContent(product) {\n        document.title = `${product[0].name} - E-commerce Store`;\n        document.getElementById(\"product-title\").textContent = product[0].name;\n        document.getElementById(\"product-description\").textContent =\n          product[0].description;\n        document.getElementById(\"product-price\").textContent =\n          `$${product[0].price.toFixed(2)}`;\n        document.getElementById(\"product-stock\").textContent =\n          `${product[0].inventory} in stock`;\n      }\n    </script>\n  </body>\n</html>\nsh\nnpx wrangler d1 create fast-commerce\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"d1_databases\": [\n      {\n        \"binding\": \"DB\",\n        \"database_name\": \"fast-commerce\",\n        \"database_id\": \"YOUR_DATABASE_ID\"\n      }\n    ]\n  }\n  toml\n  [[d1_databases]]\n  binding = \"DB\"\n  database_name = \"fast-commerce\"\n  database_id = \"YOUR_DATABASE_ID\"\n  sh\nnpm run cf-typegen\nts\nimport { Hono } from \"hono\";\n// Set db session bookmark in the cookie\nimport { getCookie, setCookie } from \"hono/cookie\";\n\nconst app = new Hono<{ Bindings: Env }>();\n\n// Get all products\napp.get(\"/api/products\", async (c) => {\n  return c.json({ message: \"get list of products\" });\n});\n\n// Get a single product\napp.get(\"/api/products/:id\", async (c) => {\n  return c.json({ message: \"get a single product\" });\n});\n\n// Upsert a product\napp.post(\"/api/product\", async (c) => {\n  return c.json({ message: \"create or update a product\" });\n});\n\nexport default app;\nsh\nnpx wrangler d1 execute fast-commerce --command \"CREATE TABLE IF NOT EXISTS products (id INTEGER PRIMARY KEY, name TEXT NOT NULL, description TEXT, price DECIMAL(10, 2) NOT NULL, inventory INTEGER NOT NULL DEFAULT 0, category TEXT NOT NULL, created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP, last_updated TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP)\"\nsh\nnpx wrangler d1 execute fast-commerce --command \"CREATE INDEX IF NOT EXISTS idx_products_id ON products (id)\"\nsh\nnpx wrangler d1 execute fast-commerce --command \"INSERT INTO products (id, name, description, price, inventory, category) VALUES (1, 'Fast Ergonomic Chair', 'A comfortable chair for your home or office', 100.00, 10, 'Furniture'), (2, 'Fast Organic Cotton T-shirt', 'A comfortable t-shirt for your home or office', 20.00, 100, 'Clothing'), (3, 'Fast Wooden Desk', 'A wooden desk for your home or office', 150.00, 5, 'Furniture'), (4, 'Fast Leather Sofa', 'A leather sofa for your home or office', 300.00, 3, 'Furniture'), (5, 'Fast Organic Cotton T-shirt', 'A comfortable t-shirt for your home or office', 20.00, 100, 'Clothing')\"\nts\nexport interface RetryConfig {\n  maxRetries: number;\n  initialDelay: number;\n  maxDelay: number;\n  backoffFactor: number;\n}\n\nconst shouldRetry = (error: unknown): boolean => {\n  const errMsg = error instanceof Error ? error.message : String(error);\n  return (\n    errMsg.includes(\"Network connection lost\") ||\n    errMsg.includes(\"storage caused object to be reset\") ||\n    errMsg.includes(\"reset because its code was updated\")\n  );\n};\n\n// Helper function for sleeping\nconst sleep = (ms: number): Promise<void> => {\n  return new Promise((resolve) => setTimeout(resolve, ms));\n};\n\nexport const defaultRetryConfig: RetryConfig = {\n  maxRetries: 3,\n  initialDelay: 100,\n  maxDelay: 1000,\n  backoffFactor: 2,\n};\n\nexport async function withRetry<T>(\n  operation: () => Promise<T>,\n  config: Partial<RetryConfig> = defaultRetryConfig,\n): Promise<T> {\n  const maxRetries = config.maxRetries ?? defaultRetryConfig.maxRetries;\n  const initialDelay = config.initialDelay ?? defaultRetryConfig.initialDelay;\n  const maxDelay = config.maxDelay ?? defaultRetryConfig.maxDelay;\n  const backoffFactor =\n    config.backoffFactor ?? defaultRetryConfig.backoffFactor;\n\nlet lastError: Error | unknown;\n  let delay = initialDelay;\n\nfor (let attempt = 0; attempt <= maxRetries; attempt++) {\n    try {\n      const result = await operation();\n      return result;\n    } catch (error) {\n      lastError = error;\n\nif (!shouldRetry(error) || attempt === maxRetries) {\n        throw error;\n      }\n\n// Add randomness to avoid synchronizing retries\n      // Wait for a random delay between delay and delay*2\n      await sleep(delay * (1 + Math.random()));\n\n// Calculate next delay with exponential backoff\n      delay = Math.min(delay * backoffFactor, maxDelay);\n    }\n  }\n\nthrow lastError;\n}\nts\nimport { withRetry } from \"./retry\";\nts\napp.post(\"/api/product\", async (c) => {\n  const product = await c.req.json();\n\nif (!product) {\n    return c.json({ message: \"No data passed\" }, 400);\n  }\n\nconst db = c.env.DB;\n  const session = db.withSession(\"first-primary\");\n\nconst { id } = product;\n\ntry {\n    return await withRetry(async () => {\n      // Check if the product exists\n      const { results } = await session\n        .prepare(\"SELECT * FROM products where id = ?\")\n        .bind(id)\n        .run();\n      if (results.length === 0) {\n        const fields = [...Object.keys(product)];\n        const values = [...Object.values(product)];\n        // Insert the product\n        await session\n          .prepare(\n            `INSERT INTO products (${fields.join(\", \")}) VALUES (${fields.map(() => \"?\").join(\", \")})`,\n          )\n          .bind(...values)\n          .run();\n        const latestBookmark = session.getBookmark();\n        latestBookmark &&\n          setCookie(c, \"product_bookmark\", latestBookmark, {\n            maxAge: 60 * 60, // 1 hour\n          });\n        return c.json({ message: \"Product inserted\" });\n      }\n\n// Update the product\n      const updates = Object.entries(product)\n        .filter(([_, value]) => value !== undefined)\n        .map(([key, _]) => `${key} = ?`)\n        .join(\", \");\n\nif (!updates) {\n        throw new Error(\"No valid fields to update\");\n      }\n\nconst values = Object.entries(product)\n        .filter(([_, value]) => value !== undefined)\n        .map(([_, value]) => value);\n\nawait session\n        .prepare(`UPDATE products SET ${updates} WHERE id = ?`)\n        .bind(...[...values, id])\n        .run();\n      const latestBookmark = session.getBookmark();\n      latestBookmark &&\n        setCookie(c, \"product_bookmark\", latestBookmark, {\n          maxAge: 60 * 60, // 1 hour\n        });\n      return c.json({ message: \"Product updated\" });\n    });\n  } catch (e) {\n    console.error(e);\n    return c.json({ message: \"Error upserting product\" }, 500);\n  }\n});\nts\napp.get(\"/api/products\", async (c) => {\n  const db = c.env.DB;\n\n// Get bookmark from the cookie\n  const bookmark = getCookie(c, \"product_bookmark\") || \"first-unconstrained\";\n\nconst session = db.withSession(bookmark);\n\ntry {\n    return await withRetry(async () => {\n      const { results } = await session.prepare(\"SELECT * FROM products\").run();\n\nconst latestBookmark = session.getBookmark();\n\n// Set the bookmark in the cookie\n      latestBookmark &&\n        setCookie(c, \"product_bookmark\", latestBookmark, {\n          maxAge: 60 * 60, // 1 hour\n        });\n\nreturn c.json(results);\n    });\n  } catch (e) {\n    console.error(e);\n    return c.json([]);\n  }\n});\nts\napp.get(\"/api/products/:id\", async (c) => {\n  const id = c.req.param(\"id\");\n\nif (!id) {\n    return c.json({ message: \"Invalid id\" }, 400);\n  }\n\n// Get bookmark from the cookie\n  const bookmark = getCookie(c, \"product_bookmark\") || \"first-unconstrained\";\n\nconst session = db.withSession(bookmark);\n\ntry {\n    return await withRetry(async () => {\n      const { results } = await session\n        .prepare(\"SELECT * FROM products where id = ?\")\n        .bind(id)\n        .run();\n\nconst latestBookmark = session.getBookmark();\n\n// Set the bookmark in the cookie\n      latestBookmark &&\n        setCookie(c, \"product_bookmark\", latestBookmark, {\n          maxAge: 60 * 60, // 1 hour\n        });\n\nconsole.log(results);\n\nreturn c.json(results);\n    });\n  } catch (e) {\n    console.error(e);\n    return c.json([]);\n  }\n});\nsh\nnpm run dev\nsh\ncurl -X POST http://localhost:8787/api/product \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"id\": 6, \"name\": \"Fast Computer\", \"description\": \"A computer for your home or office\", \"price\": 1000.00, \"inventory\": 10, \"category\": \"Electronics\"}'\nsh\ncurl -X POST http://localhost:8787/api/product \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"id\": 6, \"name\": \"Fast Computer\", \"description\": \"A computer for your home or office\", \"price\": 1050.00, \"inventory\": 10, \"category\": \"Electronics\"}'\nsh\nnpx wrangler d1 execute fast-commerce --remote --command \"CREATE TABLE IF NOT EXISTS products (id INTEGER PRIMARY KEY, name TEXT NOT NULL, description TEXT, price DECIMAL(10, 2) NOT NULL, inventory INTEGER NOT NULL DEFAULT 0, category TEXT NOT NULL, created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP, last_updated TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP)\"\nsh\nnpx wrangler d1 execute fast-commerce --remote --command \"CREATE INDEX IF NOT EXISTS idx_products_id ON products (id)\"\nsh\nnpx wrangler d1 execute fast-commerce --remote --command \"INSERT INTO products (id, name, description, price, inventory, category) VALUES (1, 'Fast Ergonomic Chair', 'A comfortable chair for your home or office', 100.00, 10, 'Furniture'), (2, 'Fast Organic Cotton T-shirt', 'A comfortable t-shirt for your home or office', 20.00, 100, 'Clothing'), (3, 'Fast Wooden Desk', 'A wooden desk for your home or office', 150.00, 5, 'Furniture'), (4, 'Fast Leather Sofa', 'A leather sofa for your home or office', 300.00, 3, 'Furniture'), (5, 'Fast Organic Cotton T-shirt', 'A comfortable t-shirt for your home or office', 20.00, 100, 'Clothing')\"\nsh\nnpm run deploy\njs\n  async fetch(request, env) {\n    // D1 database is 'env.DB', where \"DB\" is the binding name from the Wrangler configuration file.\n  }\n  py\n  from workers import WorkerEntrypoint\n\nclass Default(WorkerEntrypoint):\n      async def fetch(self, request):\n          # D1 database is 'self.env.DB', where \"DB\" is the binding name from the Wrangler configuration file.\n          pass\n  js\n  const someVariable = `Bs Beverages`;\n  const stmt = env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(someVariable);\n  py\n  some_variable = \"Bs Beverages\"\n  stmt = self.env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(some_variable)\n  js\n    const stmt = db\n      .prepare(\"SELECT * FROM Customers WHERE CompanyName = Alfreds Futterkiste AND CustomerId = 1\")\n    py\n    stmt = db.prepare(\"SELECT * FROM Customers WHERE CompanyName = Alfreds Futterkiste AND CustomerId = 1\")\n    js\n    const stmt = db\n      .prepare(\"SELECT * FROM Customers WHERE CompanyName = ? AND CustomerId = ?\")\n      .bind(\"Alfreds Futterkiste\", 1);\n    py\n    stmt = db.prepare(\"SELECT * FROM Customers WHERE CompanyName = ? AND CustomerId = ?\").bind(\"Alfreds Futterkiste\", 1)\n    js\n  const companyName1 = `Bs Beverages`;\n  const companyName2 = `Around the Horn`;\n  const stmt = env.DB.prepare(`SELECT * FROM Customers WHERE CompanyName = ?`);\n  const batchResult = await env.DB.batch([\n    stmt.bind(companyName1),\n    stmt.bind(companyName2)\n  ]);\n  py\n  from pyodide.ffi import to_js\n\ncompany_name1 = \"Bs Beverages\"\n  company_name2 = \"Around the Horn\"\n  stmt = self.env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\")\n  batch_result = await self.env.DB.batch(to_js([\n      stmt.bind(company_name1),\n      stmt.bind(company_name2)\n  ]))\n  js\n  const companyName1 = `Bs Beverages`;\n  const companyName2 = `Around the Horn`;\n  const stmt = await env.DB.batch([\n    env.DB.prepare(`SELECT * FROM Customers WHERE CompanyName = ?`).bind(companyName1),\n    env.DB.prepare(`SELECT * FROM Customers WHERE CompanyName = ?`).bind(companyName2)\n  ]);\n  return Response.json(stmt)\n  py\n  from pyodide.ffi import to_js\n  from workers import Response\n\ncompany_name1 = \"Bs Beverages\"\n  company_name2 = \"Around the Horn\"\n  stmt = await self.env.DB.batch(to_js([\n      self.env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(company_name1),\n      self.env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(company_name2)\n  ]))\n  return Response.json(stmt)\n  json\n[\n  {\n    \"success\": true,\n    \"meta\": {\n      \"served_by\": \"miniflare.db\",\n      \"duration\": 0,\n      \"changes\": 0,\n      \"last_row_id\": 0,\n      \"changed_db\": false,\n      \"size_after\": 8192,\n      \"rows_read\": 4,\n      \"rows_written\": 0\n    },\n    \"results\": [\n      {\n        \"CustomerId\": 11,\n        \"CompanyName\": \"Bs Beverages\",\n        \"ContactName\": \"Victoria Ashworth\"\n      },\n      {\n        \"CustomerId\": 13,\n        \"CompanyName\": \"Bs Beverages\",\n        \"ContactName\": \"Random Name\"\n      }\n    ]\n  },\n  {\n    \"success\": true,\n    \"meta\": {\n      \"served_by\": \"miniflare.db\",\n      \"duration\": 0,\n      \"changes\": 0,\n      \"last_row_id\": 0,\n      \"changed_db\": false,\n      \"size_after\": 8192,\n      \"rows_read\": 4,\n      \"rows_written\": 0\n    },\n    \"results\": [\n      {\n        \"CustomerId\": 4,\n        \"CompanyName\": \"Around the Horn\",\n        \"ContactName\": \"Thomas Hardy\"\n      }\n    ]\n  }\n]\njs\n  console.log(stmt[1].results);\n  py\n  print(stmt[1].results.to_py())\n  json\n[\n  {\n    \"CustomerId\": 4,\n    \"CompanyName\": \"Around the Horn\",\n    \"ContactName\": \"Thomas Hardy\"\n  }\n]\njs\n    const companyName1 = `Bs Beverages`;\n    const companyName2 = `Around the Horn`;\n    const stmt = env.DB.prepare(`SELECT * FROM Customers WHERE CompanyName = ?`);\n    const batchResult = await env.DB.batch([\n      stmt.bind(companyName1),\n      stmt.bind(companyName2)\n    ]);\n    return Response.json(batchResult);\n    py\n    from pyodide.ffi import to_js\n    from workers import Response\n\ncompany_name1 = \"Bs Beverages\"\n    company_name2 = \"Around the Horn\"\n    stmt = self.env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\")\n    batch_result = await self.env.DB.batch(to_js([\n        stmt.bind(company_name1),\n        stmt.bind(company_name2)\n    ]))\n    return Response.json(batch_result)\n    js\n  const returnValue = await env.DB.exec(`SELECT * FROM Customers WHERE CompanyName = \"Bs Beverages\"`);\n  py\n  return_value = await self.env.DB.exec('SELECT * FROM Customers WHERE CompanyName = \"Bs Beverages\"')\n  js\n  const returnValue = await env.DB.exec(`SELECT * FROM Customers WHERE CompanyName = \"Bs Beverages\"`);\n  return Response.json(returnValue);\n  py\n  from workers import Response\n\nreturn_value = await self.env.DB.exec('SELECT * FROM Customers WHERE CompanyName = \"Bs Beverages\"')\n  return Response.json(return_value)\n  json\n{\n  \"count\": 1,\n  \"duration\": 1\n}\njs\n  const dump = await db.dump();\n  return new Response(dump, {\n    status: 200,\n    headers: {\n      \"Content-Type\": \"application/octet-stream\",\n    },\n  });\n  py\n  from workers import Response\n\ndump = await db.dump()\n  return Response(dump, status=200, headers={\"Content-Type\": \"application/octet-stream\"})\n  js\n  const session = env.DB.withSession(\"<parameter>\");\n  py\n  session = self.env.DB.withSession(\"<parameter>\")\n  js\n  const session = env.DB.withSession(\"first-primary\");\n  const result = await session\n    .prepare(`SELECT * FROM Customers WHERE CompanyName = 'Bs Beverages'`)\n    .run()\n  return { bookmark } = session.getBookmark();\n  py\n  session = self.env.DB.withSession(\"first-primary\")\n  result = await session.prepare(\n      \"SELECT * FROM Customers WHERE CompanyName = 'Bs Beverages'\"\n  ).run()\n\nbookmark = session.getBookmark()\n  js\n  const someVariable = `Bs Beverages`;\n  const stmt = env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(someVariable);\n  py\n  some_variable = \"Bs Beverages\"\n  stmt = self.env.DB.prepare(\n    \"SELECT * FROM Customers WHERE CompanyName = ?\"\n  ).bind(some_variable)\n  js\n    const stmt = db.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(\"\");\n    py\n    stmt = db.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(\"\")\n    js\n    const stmt = db\n      .prepare(\"SELECT * FROM Customers WHERE CompanyName = ? AND CustomerId = ?\")\n      .bind(\"Alfreds Futterkiste\", 1);\n    py\n    stmt = db.prepare(\n    \"SELECT * FROM Customers WHERE CompanyName = ? AND CustomerId = ?\"\n    ).bind(\"Alfreds Futterkiste\", 1)\n    js\n    const stmt = db\n      .prepare(\n      \"SELECT * FROM Customers WHERE CompanyName = ?2 AND CustomerId = ?1\"\n    ).bind(1, \"Alfreds Futterkiste\");\n    py\n    stmt = db.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?2 AND CustomerId = ?1\").bind(1, \"Alfreds Futterkiste\")\n    js\n  const someVariable = `Bs Beverages`;\n  const stmt = env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(someVariable);\n  // A variable (someVariable) will replace the placeholder '?' in the query.\n  // `stmt` is a prepared statement.\n  py\n  some_variable = \"Bs Beverages\"\n  stmt = self.env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(some_variable)\n  # A variable (some_variable) will replace the placeholder '?' in the query.\n  # `stmt` is a prepared statement.\n  js\n  const stmt = env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = Bs Beverages\");\n  // \"Bs Beverages\" is hard-coded into the query.\n  // `stmt` is a static statement.\n  py\n  stmt = self.env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = Bs Beverages\")\n  # \"Bs Beverages\" is hard-coded into the query.\n  # `stmt` is a static statement.\n  js\n  const returnValue = await stmt.run();\n  py\n  return_value = await stmt.run()\n  js\n  const someVariable = `Bs Beverages`;\n  const stmt = env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(someVariable);\n  const returnValue = await stmt.run();\n  return Response.json(returnValue);\n  py\n  from workers import Response\n\nsome_variable = \"Bs Beverages\"\n  stmt = self.env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(some_variable)\n  return_value = await stmt.run()\n  return Response.json(return_value)\n  json\n{\n  \"success\": true,\n  \"meta\": {\n    \"served_by\": \"miniflare.db\",\n    \"duration\": 1,\n    \"changes\": 0,\n    \"last_row_id\": 0,\n    \"changed_db\": false,\n    \"size_after\": 8192,\n    \"rows_read\": 4,\n    \"rows_written\": 0\n  },\n  \"results\": [\n    {\n      \"CustomerId\": 11,\n      \"CompanyName\": \"Bs Beverages\",\n      \"ContactName\": \"Victoria Ashworth\"\n    },\n    {\n      \"CustomerId\": 13,\n      \"CompanyName\": \"Bs Beverages\",\n      \"ContactName\": \"Random Name\"\n    }\n  ]\n}\njs\n  return Response.json(returnValue.results);\n  py\n  from workers import Response\n\nreturn Response.json(return_value.results)\n  json\n[\n  {\n    \"CustomerId\": 11,\n    \"CompanyName\": \"Bs Beverages\",\n    \"ContactName\": \"Victoria Ashworth\"\n  },\n  {\n    \"CustomerId\": 13,\n    \"CompanyName\": \"Bs Beverages\",\n    \"ContactName\": \"Random Name\"\n  }\n]\njs\n  const returnValue = await stmt.raw();\n  py\n  return_value = await stmt.raw()\n  js\n  const someVariable = `Bs Beverages`;\n  const stmt = env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(someVariable);\n  const returnValue = await stmt.raw();\n  return Response.json(returnValue);\n  py\n  from workers import Response\n\nsome_variable = \"Bs Beverages\"\n  stmt = self.env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(some_variable)\n  return_value = await stmt.raw()\n  return Response.json(return_value)\n  json\n[\n  [11, \"Bs Beverages\",\n    \"Victoria Ashworth\"\n  ],\n  [13, \"Bs Beverages\",\n    \"Random Name\"\n  ]\n]\njs\n  const someVariable = `Bs Beverages`;\n  const stmt = env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(someVariable);\n  const returnValue = await stmt.raw({columnNames:true});\n  return Response.json(returnValue)\n  py\n  from pyodide.ffi import to_js\n  from workers import Response\n\nsome_variable = \"Bs Beverages\"\n  stmt = self.env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(some_variable)\n  return_value = await stmt.raw(columnNames=True)\n  return Response.json(return_value)\n  json\n[\n  [\n    \"CustomerId\",\n    \"CompanyName\",\n    \"ContactName\"\n  ],\n  [11, \"Bs Beverages\",\n    \"Victoria Ashworth\"\n  ],\n  [13, \"Bs Beverages\",\n    \"Random Name\"\n  ]\n]\njs\n  const values = await stmt.first();\n  py\n  values = await stmt.first()\n  js\n  const someVariable = `Bs Beverages`;\n  const stmt = env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(someVariable);\n  const returnValue = await stmt.first();\n  return Response.json(returnValue)\n  py\n  from workers import Response\n\nsome_variable = \"Bs Beverages\"\n  stmt = self.env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(some_variable)\n  return_value = await stmt.first()\n  return Response.json(return_value)\n  json\n{\n  \"CustomerId\": 11,\n  \"CompanyName\": \"Bs Beverages\",\n  \"ContactName\": \"Victoria Ashworth\"\n}\njs\n  const someVariable = `Bs Beverages`;\n  const stmt = env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(someVariable);\n  const returnValue = await stmt.first(CustomerId);\n  return Response.json(returnValue)\n  py\n  from workers import Response\n\nsome_variable = \"Bs Beverages\"\n  stmt = self.env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(some_variable)\n  return_value = await stmt.first(\"CustomerId\")\n  return Response.json(return_value)\n  json\n11\njs\n{\n  success: boolean, // true if the operation was successful, false otherwise\n  meta: {\n    served_by: string // the version of Cloudflare's backend Worker that returned the result\n    served_by_region: string // the region of the database instance that executed the query\n    served_by_primary: boolean // true if (and only if) the database instance that executed the query was the primary\n    timings: {\n      sql_duration_ms: number // the duration of the SQL query execution by the database instance (not including any network time)\n    }\n    duration: number, // the duration of the SQL query execution only, in milliseconds\n    changes: number, // the number of changes made to the database\n    last_row_id: number, // the last inserted row ID, only applies when the table is defined without the `WITHOUT ROWID` option\n    changed_db: boolean, // true if something on the database was changed\n    size_after: number, // the size of the database after the query is successfully applied\n    rows_read: number, // the number of rows read (scanned) by this query\n    rows_written: number // the number of rows written by this query\n    total_attempts: number //the number of total attempts to successfully execute the query, including retries\n  }\n  results: array | null, // [] if empty, or null if it does not apply\n}\njs\n  const someVariable = `Bs Beverages`;\n  const stmt = env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(someVariable);\n  const returnValue = await stmt.run();\n  return Response.json(returnValue)\n  py\n  from workers import Response\n\nsome_variable = \"Bs Beverages\"\n  stmt = self.env.DB.prepare(\"SELECT * FROM Customers WHERE CompanyName = ?\").bind(some_variable)\n  return_value = await stmt.run()\n  return Response.json(return_value)\n  json\n{\n  \"success\": true,\n  \"meta\": {\n    \"served_by\": \"miniflare.db\",\n    \"served_by_region\": \"WEUR\",\n    \"served_by_primary\": true,\n    \"timings\": {\n      \"sql_duration_ms\": 0.2552\n    },\n    \"duration\": 0.2552,\n    \"changes\": 0,\n    \"last_row_id\": 0,\n    \"changed_db\": false,\n    \"size_after\": 16384,\n    \"rows_read\": 4,\n    \"rows_written\": 0\n  },\n  \"results\": [\n    {\n      \"CustomerId\": 11,\n      \"CompanyName\": \"Bs Beverages\",\n      \"ContactName\": \"Victoria Ashworth\"\n    },\n    {\n      \"CustomerId\": 13,\n      \"CompanyName\": \"Bs Beverages\",\n      \"ContactName\": \"Random Name\"\n    }\n  ]\n}\njs\n{\n  \"count\": number, // the number of executed queries\n  \"duration\": number // the duration of the operation, in milliseconds\n}\njs\n  const returnValue = await env.DB.exec(`SELECT * FROM Customers WHERE CompanyName = \"Bs Beverages\"`);\n  return Response.json(returnValue);\n  py\n  from workers import Response\n\nreturn_value = await self.env.DB.exec('SELECT * FROM Customers WHERE CompanyName = \"Bs Beverages\"')\n  return Response.json(return_value)\n  json\n{\n  \"count\": 1,\n  \"duration\": 1\n}\nbash\ncurl \"https://api.cloudflare.com/client/v4/user/tokens/verify\" \\\n--header \"Authorization: Bearer <API_TOKEN>\"\njson\n{\n  \"result\": {\n    \"id\": \"325xxxxcd\",\n    \"status\": \"active\"\n  },\n  \"success\": true,\n  \"errors\": [],\n  \"messages\": [\n    {\n      \"code\": 10000,\n      \"message\": \"This API Token is valid and active\",\n      \"type\": null\n    }\n  ]\n}\nbash\necho -n \"<token>\" | shasum -a 256\nbash\ncurl \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/logs/control/cmb/config\" \\\n  --request GET \\\n  --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\"\nbash\ncurl \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/logs/control/cmb/config\" \\\n  --request POST \\\n  --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\" \\\n  --json '{\n    \"regions\": \"eu\",\n    \"allow_out_of_region_access\": false\n  }'\nbash\ncurl \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/logs/control/cmb/config\" \\\n  --request DELETE \\\n  --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\"\nbash\ncurl \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/addressing/regional_hostnames/regions\" \\\n  --request GET \\\n  --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\"\njson\n{\n  \"success\": true,\n  \"errors\": [],\n  \"result\": [\n    {\n      \"key\": \"ca\",\n      \"label\": \"Canada\"\n    },\n    {\n      \"key\": \"eu\",\n      \"label\": \"Europe\"\n    }\n  ],\n  \"messages\": []\n}\nbash\ncurl \"https://api.cloudflare.com/client/v4/zones/$ZONE_ID/addressing/regional_hostnames\" \\\n  --request POST \\\n  --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\" \\\n  --json '{\n    \"hostname\": \"ca.regional.ipam.rocks\",\n    \"region_key\": \"ca\"\n  }'\njson\n{\n  \"success\": true,\n  \"errors\": [],\n  \"result\": {\n    \"hostname\": \"ca.regional.ipam.rocks\",\n    \"region_key\": \"ca\",\n    \"created_on\": \"2023-01-13T23:59:45.276558Z\"\n  },\n  \"messages\": []\n}\nbash\ncurl \"https://api.cloudflare.com/client/v4/zones/$ZONE_ID/addressing/regional_hostnames\" \\\n  --request GET \\\n  --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\"\njson\n{\n  \"success\": true,\n  \"errors\": [],\n  \"result\": [\n    {\n      \"hostname\": \"ca.regional.ipam.rocks\",\n      \"region_key\": \"ca\",\n      \"created_on\": \"2023-01-14T00:47:57.060267Z\"\n    }\n  ],\n  \"messages\": []\n}\nbash\ncurl \"https://api.cloudflare.com/client/v4/zones/$ZONE_ID/addressing/regional_hostnames/$HOSTNAME\" \\\n  --request GET \\\n  --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\"\njson\n{\n  \"success\": true,\n  \"errors\": [],\n  \"result\": {\n    \"hostname\": \"ca.regional.ipam.rocks\",\n    \"region_key\": \"ca\",\n    \"created_on\": \"2023-01-13T23:59:45.276558Z\"\n  },\n  \"messages\": []\n}\nbash\ncurl \"https://api.cloudflare.com/client/v4/zones/$ZONE_ID/addressing/regional_hostnames/$HOSTNAME\" \\\n  --request PATCH \\\n  --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\" \\\n  --json '{\n    \"region_key\": \"eu\"\n  }'\njson\n{\n  \"success\": true,\n  \"errors\": [],\n  \"result\": {\n    \"hostname\": \"ca.regional.ipam.rocks\",\n    \"region_key\": \"eu\",\n    \"created_on\": \"2023-01-13T23:59:45.276558Z\"\n  },\n  \"messages\": []\n}\nbash\ncurl \"https://api.cloudflare.com/client/v4/zones/$ZONE_ID/addressing/regional_hostnames/$HOSTNAME\" \\\n  --request DELETE \\\n  --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\"\njson\n{\n  \"success\": true,\n  \"errors\": [],\n  \"result\": null,\n  \"messages\": []\n}\ngraphql\nquery GetLastNXDOMAINResponses {\n  viewer {\n    accounts(filter: { accountTag: \"83a4527361bcdec24566fd7f837b6de5\" }) {\n      dnsAnalyticsAdaptive(\n        limit: 10000\n        filter: {\n          date_geq: \"2025-06-16\",\n          responseCode: \"NXDOMAIN\",\n          date_leq: \"2025-06-18\"\n        }\n        orderBy: [datetime_DESC]\n      ) {\n        zoneTag\n        queryName\n        responseCode\n        queryType\n        datetime\n      }\n    }\n  }\n}\ngraphql\nquery GetTotalDNSQueryCount {\n  viewer {\n    accounts(filter: { accountTag: \"83a4527361bcdec24566fd7f837b6de5\" }) {\n      dnsAnalyticsAdaptiveGroups(\n        filter: {\n          date_geq: \"2025-05-01\"\n          date_leq: \"2025-05-30\"\n        }\n        limit: 1\n      ) {\n        count\n      }\n    }\n  }\n}\nmermaid\nflowchart BT\naccTitle: CNAME flattening diagram\naccDescr: Diagram of CNAME flattening process when there is a request for a domain in Cloudflare and the zone has a CNAME record at apex that points to an external A record.\n  A((User)) <--query for <code>domain.test</code>--> B[Resolver] --> C\n  C[\"Question:\n  <code>domain.test IN A</code>\"]\n subgraph Y[Cloudflare DNS]\n direction RL\n  D{{Look up record}} --> G[\"Answer:\n  <code>domain.test 3600 CNAME external-origin.test</code>\n\nThis means that <code>domain.test</code> is a <code>CNAME</code> at the zone apex.\n  Forced <code>CNAME</code> flattening is enabled.\"] --- H{{Resolve <code>external-origin.test</code>}}\n  K{{Append answer with overwritten query name}} --> L[\"Answer:\n  <code>domain.test 7200 IN A 192.0.2.1</code>\"] --- M{Proxy status}\n  M --Proxied--> O[\"Answer:\n  <code>domain.test 300 IN A {$Cloudflare IP 1}</code>\n  <code>domain.test 300 IN A {$Cloudflare IP 2}</code>\"]\n  M --DNS only--> N[\"Answer:\n  <code>domain.test 3600 IN A 192.0.2.1</code>\"]\n end\n\nsubgraph Z [External DNS provider]\n  J[\"Answer:\n  <code>external-origin.test 7200 IN A 192.0.2.1</code>\"]\n end\n\nC --> D\n H --- J --- K\n O --> B\n N --> B\ntxt\n  \"settings\": {\n    \"flatten_cname\": true\n  }\n  bash\ncurl \"https://api.cloudflare.com/client/v4/zones/$ZONE_ID/dnssec\" \\\n  --request PATCH \\\n  --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\" \\\n  --json '{\n    \"status\": \"active\"\n  }'\nbash\ncurl \"https://api.cloudflare.com/client/v4/zones/$ZONE_ID/dnssec\" \\\n  --request PATCH \\\n  --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\" \\\n  --json '{\n    \"dnssec_multi_signer\": true\n  }'\nbash\ncurl \"https://api.cloudflare.com/client/v4/zones/$ZONE_ID/dns_records\" \\\n  --request POST \\\n  --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\" \\\n  --json '{\n    \"type\": \"DNSKEY\",\n    \"name\": \"<ZONE_NAME>\",\n    \"data\": {\n        \"flags\": 256,\n        \"protocol\": 3,\n        \"algorithm\": 13,\n        \"public_key\": \"<PUBLIC_KEY>\"\n    },\n    \"ttl\": 3600\n  }'\nbash\ncurl https://api.cloudflare.com/client/v4/zones/{zone_id}/dnssec/zsk \\\n--header \"X-Auth-Email: <EMAIL>\" \\\n--header \"X-Auth-Key: <API_KEY>\"\nsh\ndig <ZONE_NAME> dnskey @<CLOUDFLARE_NAMESERVER> +noall +answer | grep 256\nsh\ndig <ZONE_NAME> dnskey @<PREVIOUS_PROVIDER_NAMESERVER> +noall +answer\ndig <ZONE_NAME> dnskey @<CLOUDFLARE_NAMESERVER> +noall +answer\nsh\ndig multisigner.info dnskey @dns1.p01.nsone.net. +noall +answer\nsh\nmultisigner.info.    3600    IN    DNSKEY    257 3 13 t+4D<bla_bla_bla>JBmA==\nmultisigner.info.    3600    IN    DNSKEY    256 3 13 pxEU<bla_bla_bla>0xOg==\nmultisigner.info.    3600    IN    DNSKEY    256 3 13 oJM<bla_bla_bla>XhSA==\nsh\ndig multisigner.info dnskey @ashley.ns.cloudflare.com +noall +answer\nsh\nmultisigner.info.    3600    IN    DNSKEY    257 3 13 mdss<bla_bla_bla>eKGQ==\nmultisigner.info.    3600    IN    DNSKEY    256 3 13 oJM<bla_bla_bla>XhSA==\nmultisigner.info.    3600    IN    DNSKEY    256 3 13 pxEU<bla_bla_bla>0xOg==\nsh\ndig multisigner.info ds +noall +answer\nsh\nmultisigner.info. 3600 IN DS 2371 13 2 227B4C7FF3E1D49D59BAF39BDA54CA0839DE700DD9896076AA3E6AD7 19A0CF55\nmultisigner.info. 3600 IN DS 48553 13 2 893709B51A9C53D011A4054B15FC5454BEDF68E739BB3B3FA1E333DA 7B8DACFE\nbash\ncurl \"https://api.cloudflare.com/client/v4/zones/$ZONE_ID/dnssec\" \\\n  --request PATCH \\\n  --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\" \\\n  --json '{\n    \"dnssec_use_nsec3\": true,\n    \"status\": \"active\"\n  }'\nsh\ndig +dnssec doesnotexist.example.com\nsh\ndig +dnssec www.example.com TXT\nsh\ndig www.cloudflare.com +short\nsh\n198.41.215.162\n198.41.214.162\nsh\ndig www.cloudflare.com +dnssec +short\nsh\n198.41.214.162\n198.41.215.162\nA 13 3 300 20180927180434 20180925160434 35273 cloudflare.com. DYYZ/bhHSAIlpvu/HEUsxlzkC9NsswbCQ7dcfcuiNBrbhYV7k3AI8t46 QMnOlfhwT6jqsfN7ePV6Fwpym3B0pg==\nsh\ndig DNSKEY cloudflare.com +short\nsh\n257 3 13 mdsswUyr3DPW132mOi8V9xESWE8jTo0dxCjjnopKl+GqJxpVXckHAeF+ KkxLbxILfDLUT0rAK9iUzy1L53eKGQ==\n256 3 13 koPbw9wmYZ7ggcjnQ6ayHyhHaDNMYELKTqT+qRGrZpWSccr/lBcrm10Z 1PuQHB3Azhii+sb0PYFkH1ruxLhe5g==\nsh\ndig www.cloudflare.com\nsh\n[...]\n;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 65326\n;; flags: qr rd ra ad; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1\n[...]\n;; QUESTION SECTION:\n;www.cloudflare.com.        IN  A\n[...]\n;; ANSWER SECTION:\nwww.cloudflare.com. 15  IN  A   198.41.215.162\nwww.cloudflare.com. 15  IN  A   198.41.214.162\nsh\ndig +short DS cloudflare.com\nsh\n2371 13 2 32996839A6D808AFE3EB4A795A0E6A7A39A76FC52FF228B22B76F6D6 3826F2B9\nsh\ndig DS cloudflare.com +trace\nsh\n[...]\ncloudflare.com.     86400   IN  DS  2371 13 2 32996839A6D808AFE3EB4A795A0E6A7A39A76FC52FF228B22B76F6D6 3826F2B9\n[...]\ncom.            172800  IN  NS  e.gtld-servers.net.\n[...]\n;; Received 1213 bytes from 2001:502:1ca1::30#53(e.gtld-servers.net) in 37 ms\nsh\ndig A brokendnssec.net @1.0.0.1\nsh\n;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 0, ADDITIONAL: 0\n;; ->>HEADER<<- opcode: QUERY, status: SERVFAIL, id: 10663\nsh\ndig A brokendnssec.net @1.0.0.1 +dnssec +cd +short\nsh\n104.20.49.61\n104.20.48.61\nbash\n     curl \"https://api.cloudflare.com/client/v4/zones/$ZONE_ID/dns_settings\" \\\n       --request PATCH \\\n       --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\" \\\n       --json '{\n         \"foundation_dns\": true\n       }'\n     bash\n  curl \"https://api.cloudflare.com/client/v4/zones\" \\\n    --request POST \\\n    --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\" \\\n    --json '{\n      \"account\": {\n          \"id\": \"<ACCOUNT_ID>\"\n      },\n      \"name\": \"<ZONE_NAME>\",\n      \"type\": \"internal\"\n    }'\n  bash\n  curl \"https://api.cloudflare.com/client/v4/zones/8a904aeb565c42cfa207d98f6edea2f3/dns_settings\" \\\n    --request PATCH \\\n    --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\" \\\n    --json '{\n      \"internal_dns\": {\n          \"reference_zone_id\": \"8e64c6fb4b514f3faf64de81efc11e51\"\n      }\n    }'\n  sh\ndig @alex.ns.cloudflare.com chaos txt myip.cloudflare +short\nsh\ndig @alex.ns.cloudflare.com chaos txt id.server +short\nsh\ndig @alex.ns.cloudflare.com chaos txt version.bind +short\nsh\ndig @alex.ns.cloudflare.com txt whoami.cloudflare.net +short\nsh\ndig kate.ns.cloudflare.com\nsh\nkate.ns.cloudflare.com.    68675    IN    A    173.245.58.124.\njs\nimport { DurableObject } from \"cloudflare:workers\";\n\nexport class AgentServer extends DurableObject {\n  // Schedule a one-time or recurring event\n  async scheduleEvent(id, runAt, repeatMs = null) {\n    await this.ctx.storage.put(`event:${id}`, { id, runAt, repeatMs });\n    const currentAlarm = await this.ctx.storage.getAlarm();\n    if (!currentAlarm || runAt < currentAlarm) {\n      await this.ctx.storage.setAlarm(runAt);\n    }\n  }\n\nasync alarm() {\n    const now = Date.now();\n    const events = await this.ctx.storage.list({ prefix: \"event:\" });\n    let nextAlarm = null;\n\nfor (const [key, event] of events) {\n      if (event.runAt <= now) {\n        await this.processEvent(event);\n        if (event.repeatMs) {\n          event.runAt = now + event.repeatMs;\n          await this.ctx.storage.put(key, event);\n        } else {\n          await this.ctx.storage.delete(key);\n        }\n      }\n      // Track the next event time\n      if (event.runAt > now && (!nextAlarm || event.runAt < nextAlarm)) {\n        nextAlarm = event.runAt;\n      }\n    }\n\nif (nextAlarm) await this.ctx.storage.setAlarm(nextAlarm);\n  }\n\nasync processEvent(event) {\n    // Your event handling logic here\n  }\n}\njs\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport default {\n    async fetch(request, env) {\n      return await env.ALARM_EXAMPLE.getByName(\"foo\").fetch(request);\n    },\n  };\n\nconst SECONDS = 1000;\n\nexport class AlarmExample extends DurableObject {\n    constructor(ctx, env) {\n      super(ctx, env);\n      this.storage = ctx.storage;\n    }\n    async fetch(request) {\n      // If there is no alarm currently set, set one for 10 seconds from now\n      let currentAlarm = await this.storage.getAlarm();\n      if (currentAlarm == null) {\n        this.storage.setAlarm(Date.now() + 10 * SECONDS);\n      }\n    }\n    async alarm() {\n      // The alarm handler will be invoked whenever an alarm fires.\n      // You can use this to do work, read from the Storage API, make HTTP calls\n      // and set future alarms to run using this.storage.setAlarm() from within this handler.\n    }\n  }\n  python\n  import time\n\nfrom workers import DurableObject, WorkerEntrypoint\n\nclass Default(WorkerEntrypoint):\n      async def fetch(self, request):\n          return await self.env.ALARM_EXAMPLE.getByName(\"foo\").fetch(request)\n\nclass AlarmExample(DurableObject):\n      def __init__(self, ctx, env):\n          super().__init__(ctx, env)\n          self.storage = ctx.storage\n\nasync def fetch(self, request):\n          # If there is no alarm currently set, set one for 10 seconds from now\n          current_alarm = await self.storage.getAlarm()\n          if current_alarm is None:\n              self.storage.setAlarm(int(time.time() * 1000) + 10 * SECONDS)\n\nasync def alarm(self):\n          # The alarm handler will be invoked whenever an alarm fires.\n          # You can use this to do work, read from the Storage API, make HTTP calls\n          # and set future alarms to run using self.storage.setAlarm() from within this handler.\n          pass\n  js\n  class MyDurableObject extends DurableObject {\n    async alarm(alarmInfo) {\n      if (alarmInfo?.retryCount != 0) {\n        console.log(\n          \"This alarm event has been attempted ${alarmInfo?.retryCount} times before.\",\n        );\n      }\n    }\n  }\n  python\n  class MyDurableObject(DurableObject):\n      async def alarm(self, alarm_info):\n          if alarm_info and alarm_info.get('retryCount', 0) != 0:\n              print(f\"This alarm event has been attempted {alarm_info.get('retryCount')} times before.\")\n  js\n  export class MyDurableObject extends DurableObject {\n    constructor(ctx, env) {\n      super(ctx, env);\n    }\n\nasync fetch(request) {\n      return new Response(\"Hello, World!\");\n    }\n  }\n  ts\n  export class MyDurableObject extends DurableObject {\n    constructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n    }\n\nasync fetch(request: Request) {\n      return new Response(\"Hello, World!\");\n    }\n  }\n  python\n  from workers import DurableObject, Response\n\nclass MyDurableObject(DurableObject):\n    def __init__(self, ctx, env):\n      super().__init__(ctx, env)\n\nasync def fetch(self, request):\n      return Response(\"Hello, World!\")\n  js\n  export class MyDurableObject extends DurableObject {\n    constructor(ctx, env) {\n      super(ctx, env);\n\n// boot the container when starting the DO\n      this.ctx.blockConcurrencyWhile(async () => {\n        this.ctx.container.start();\n      });\n    }\n  }\n  ts\n  export class MyDurableObject extends DurableObject {\n    constructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n\n// boot the container when starting the DO\n        this.ctx.blockConcurrencyWhile(async () => {\n          this.ctx.container.start();\n      });\n      }\n\n}\n  js\n  this.ctx.container.running;\njs\nthis.ctx.container.start({\n  env: {\n    FOO: \"bar\",\n  },\n  enableInternet: false,\n  entrypoint: [\"node\", \"server.js\"],\n});\njs\nthis.ctx.container.destroy(\"Manually Destroyed\");\njs\nconst SIGTERM = 15;\nthis.ctx.container.signal(SIGTERM);\njs\nconst port = this.ctx.container.getTcpPort(8080);\nconst res = await port.fetch(\"http://container/set-state\", {\n  body: initialState,\n  method: \"POST\",\n});\njs\nconst conn = this.ctx.container.getTcpPort(8080).connect('10.0.0.1:8080');\nawait conn.opened;\n\ntry {\n  if (request.body) {\n    await request.body.pipeTo(conn.writable);\n  }\n  return new Response(conn.readable);\n} catch (err) {\n  console.error(\"Request body piping failed:\", err);\n  return new Response(\"Failed to proxy request body\", { status: 502 });\n}\njs\nclass MyContainer extends DurableObject {\n  constructor(ctx, env) {\n    super(ctx, env);\n    function onContainerExit() {\n      console.log(\"Container exited\");\n    }\n\n// the \"err\" value can be customized by the destroy() method\n    async function onContainerError(err) {\n      console.log(\"Container errored\", err);\n    }\n\nthis.ctx.container.start();\n    this.ctx.container.monitor().then(onContainerExit).catch(onContainerError);\n  }\n}\njs\n// Create a new unique ID\nconst id = env.MY_DURABLE_OBJECT.newUniqueId();\n// Convert the ID to a string to be saved elsewhere, e.g. a session cookie\nconst session_id = id.toString();\n\n...\n// Recreate the ID from the string\nconst id = env.MY_DURABLE_OBJECT.idFromString(session_id);\njs\n  const id1 = env.MY_DURABLE_OBJECT.newUniqueId();\n  const id2 = env.MY_DURABLE_OBJECT.newUniqueId();\n  console.assert(!id1.equals(id2), \"Different unique ids should never be equal.\");\n  python\n  id1 = env.MY_DURABLE_OBJECT.newUniqueId()\n  id2 = env.MY_DURABLE_OBJECT.newUniqueId()\n  assert not id1.equals(id2), \"Different unique ids should never be equal.\"\n  js\n  const uniqueId = env.MY_DURABLE_OBJECT.newUniqueId();\n  const fromNameId = env.MY_DURABLE_OBJECT.idFromName(\"foo\");\n  console.assert(uniqueId.name === undefined, \"unique ids have no name\");\n  console.assert(\n    fromNameId.name === \"foo\",\n    \"name matches parameter to idFromName\",\n  );\n  python\n  unique_id = env.MY_DURABLE_OBJECT.newUniqueId()\n  from_name_id = env.MY_DURABLE_OBJECT.idFromName(\"foo\")\n  assert unique_id.name is None, \"unique ids have no name\"\n  assert from_name_id.name == \"foo\", \"name matches parameter to idFromName\"\n  js\n  export class Counter extends DurableObject {\n    constructor(ctx, env) {\n      super(ctx, env);\n    }\n\nasync increment() {\n      let value = (await this.ctx.storage.get(\"value\")) || 0;\n      value += 1;\n      await this.ctx.storage.put(\"value\", value);\n      return value;\n    }\n  }\n  ts\n  export class Counter extends DurableObject {\n    constructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n    }\n\nasync increment(): Promise<number> {\n      let value: number = (await this.ctx.storage.get(\"value\")) || 0;\n      value += 1;\n      await this.ctx.storage.put(\"value\", value);\n      return value;\n    }\n  }\n  python\n  from workers import DurableObject\n\nclass Counter(DurableObject):\n    def __init__(self, ctx, env):\n      super().__init__(ctx, env)\n\nasync def increment(self):\n      value = (await self.ctx.storage.get(\"value\")) or 0\n      value += 1\n      await self.ctx.storage.put(\"value\", value)\n      return value\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Durable Object\n  export class MyDurableObject extends DurableObject {\n    ...\n  }\n\n// Worker\n  export default {\n    async fetch(request, env) {\n      // A stub is a client Object used to invoke methods defined by the Durable Object\n      const stub = env.MY_DURABLE_OBJECT.getByName(\"foo\");\n      ...\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    MY_DURABLE_OBJECT: DurableObjectNamespace<MyDurableObject>;\n  }\n\n// Durable Object\n  export class MyDurableObject extends DurableObject {\n    ...\n  }\n\n// Worker\n  export default {\n    async fetch(request, env) {\n      // A stub is a client Object used to invoke methods defined by the Durable Object\n      const stub = env.MY_DURABLE_OBJECT.getByName(\"foo\");\n      ...\n    }\n  } satisfies ExportedHandler<Env>;\n  python\n  from workers import DurableObject, WorkerEntrypoint\n\n# Durable Object\n  class MyDurableObject(DurableObject):\n    pass\n\n# Worker\n  class Default(WorkerEntrypoint):\n    async def fetch(self, request):\n      # A stub is a client Object used to invoke methods defined by the Durable Object\n      stub = self.env.MY_DURABLE_OBJECT.getByName(\"foo\")\n      # ...\n  js\nconst fooId = env.MY_DURABLE_OBJECT.idFromName(\"foo\");\nconst barId = env.MY_DURABLE_OBJECT.idFromName(\"bar\");\njs\nconst id = env.MY_DURABLE_OBJECT.newUniqueId();\nconst euId = env.MY_DURABLE_OBJECT.newUniqueId({ jurisdiction: \"eu\" });\njs\n// Create a new unique ID\nconst id = env.MY_DURABLE_OBJECT.newUniqueId();\n// Convert the ID to a string to be saved elsewhere, e.g. a session cookie\nconst session_id = id.toString();\n\n...\n// Recreate the ID from the string\nconst id = env.MY_DURABLE_OBJECT.idFromString(session_id);\njs\nconst id = env.MY_DURABLE_OBJECT.newUniqueId();\nconst stub = env.MY_DURABLE_OBJECT.get(id);\njs\nconst fooStub = env.MY_DURABLE_OBJECT.getByName(\"foo\");\nconst barStub = env.MY_DURABLE_OBJECT.getByName(\"bar\");\njs\nconst subnamespace = env.MY_DURABLE_OBJECT.jurisdiction(\"eu\");\nconst euStub = subnamespace.getByName(\"foo\");\njs\n  export class Counter extends DurableObject {\n    constructor(ctx, env) {\n      super(ctx, env);\n    }\n\nasync increment() {\n      let value = (await this.ctx.storage.get(\"value\")) || 0;\n      value += 1;\n      await this.ctx.storage.put(\"value\", value);\n      return value;\n    }\n  }\n  ts\n  export class Counter extends DurableObject {\n    constructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n    }\n\nasync increment(): Promise<number> {\n        let value: number = (await this.ctx.storage.get('value')) || 0;\n        value += 1;\n        await this.ctx.storage.put('value', value);\n        return value;\n      }\n\n}\n  python\n  from workers import DurableObject\n\nclass Counter(DurableObject):\n    def __init__(self, ctx, env):\n      super().__init__(ctx, env)\n\nasync def increment(self):\n      value = (await self.ctx.storage.get('value')) or 0\n      value += 1\n      await self.ctx.storage.put('value', value)\n      return value\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class MyDurableObject extends DurableObject {\n    sql: SqlStorage;\n    constructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n      this.sql = ctx.storage.sql;\n\nthis.sql.exec(`\n        CREATE TABLE IF NOT EXISTS artist(\n          artistid    INTEGER PRIMARY KEY,\n          artistname  TEXT\n        );\n        INSERT INTO artist (artistid, artistname) VALUES\n          (123, 'Alice'),\n          (456, 'Bob'),\n          (789, 'Charlie');\n      `);\n    }\n  }\n  python\n  from workers import DurableObject\n\nclass MyDurableObject(DurableObject):\n    def __init__(self, ctx, env):\n      super().__init__(ctx, env)\n      self.sql = ctx.storage.sql\n\nself.sql.exec(\"\"\"\n        CREATE TABLE IF NOT EXISTS artist(\n          artistid    INTEGER PRIMARY KEY,\n          artistname  TEXT\n        );\n        INSERT INTO artist (artistid, artistname) VALUES\n          (123, 'Alice'),\n          (456, 'Bob'),\n          (789, 'Charlie');\n      \"\"\")\n  ts\n  let cursor = this.sql.exec(\"SELECT * FROM artist ORDER BY artistname ASC;\");\n  let rawResult = cursor.raw().next();\n\nif (!rawResult.done) {\n    console.log(rawResult.value); // prints [ 123, 'Alice' ]\n  } else {\n    // query returned zero results\n  }\n\nconsole.log(cursor.toArray()); // prints [{ artistid: 456, artistname: 'Bob' },{ artistid: 789, artistname: 'Charlie' }]\n  python\n  cursor = self.sql.exec(\"SELECT * FROM artist ORDER BY artistname ASC;\")\n  raw_result = cursor.raw().next()\n\nif not raw_result.done:\n    print(raw_result.value)  # prints [ 123, 'Alice' ]\n  else:\n    # query returned zero results\n    pass\n\nprint(cursor.toArray())  # prints [{ artistid: 456, artistname: 'Bob' },{ artistid: 789, artistname: 'Charlie' }]\n  ts\nimport { DurableObject } from \"cloudflare:workers\";\n\nexport class MyDurableObject extends DurableObject {\n  sql: SqlStorage\n  constructor(ctx: DurableObjectState, env: Env) {\n    super(ctx, env);\n    this.sql = ctx.storage.sql;\n\nthis.sql.exec(`CREATE TABLE IF NOT EXISTS artist(\n      artistid    INTEGER PRIMARY KEY,\n      artistname  TEXT\n    );INSERT INTO artist (artistid, artistname) VALUES\n      (123, 'Alice'),\n      (456, 'Bob'),\n      (789, 'Charlie');`\n    );\n  }\n}\nts\n  let cursor = this.sql.exec(\"SELECT * FROM artist;\");\n\nfor (let row of cursor) {\n    // Iterate over row object and do something\n  }\nts\n  // Return array of row objects: [{\"artistid\":123,\"artistname\":\"Alice\"},{\"artistid\":456,\"artistname\":\"Bob\"},{\"artistid\":789,\"artistname\":\"Charlie\"}]\n  let resultsArray1 = this.sql.exec(\"SELECT * FROM artist;\").toArray();\n  // OR\n  let resultsArray2 = Array.from(this.sql.exec(\"SELECT * FROM artist;\"));\n  // OR\n  let resultsArray3 = [...this.sql.exec(\"SELECT * FROM artist;\")]; // JavaScript spread syntax\nts\n  // Returns [[123,\"Alice\"],[456,\"Bob\"],[789,\"Charlie\"]]\n  let cursor = this.sql.exec(\"SELECT * FROM artist;\");\n  let resultsArray = cursor.raw().toArray();\n\n// Returns [\"artistid\",\"artistname\"]\n  let columnNameArray = this.sql.exec(\"SELECT * FROM artist;\").columnNames.toArray();\nts\n  // Returns {\"artistid\":123,\"artistname\":\"Alice\"}\n  let firstRow = this.sql.exec(\"SELECT * FROM artist ORDER BY artistname DESC;\").toArray()[0];\nts\n  // returns error\n  this.sql.exec(\"SELECT * FROM artist ORDER BY artistname ASC;\").one();\n\n// returns { artistid: 123, artistname: 'Alice' }\n  let oneRow = this.sql.exec(\"SELECT * FROM artist WHERE artistname = ?;\", \"Alice\").one()\nts\n  let cursor = this.sql.exec(\"SELECT * FROM artist ORDER BY artistname ASC;\");\n  let result = cursor.next();\n  if (!result.done) {\n    console.log(result.value); // prints { artistid: 123, artistname: 'Alice' }\n  } else {\n    // query returned zero results\n  }\n\nlet remainingRows = cursor.toArray();\n  console.log(remainingRows); // prints [{ artistid: 456, artistname: 'Bob' },{ artistid: 789, artistname: 'Charlie' }]\nts\n  let cursor = this.sql.exec(\"SELECT * FROM artist ORDER BY artistname ASC;\");\n  let result = cursor.raw().next();\n\nif (!result.done) {\n    console.log(result.value); // prints [ 123, 'Alice' ]\n  } else {\n    // query returned zero results\n  }\n\nconsole.log(cursor.toArray()); // prints [{ artistid: 456, artistname: 'Bob' },{ artistid: 789, artistname: 'Charlie' }]\nts\n  let cursor = this.sql.exec(\"SELECT * FROM artist;\");\n  cursor.next()\n  console.log(cursor.rowsRead); // prints 1\n\ncursor.toArray(); // consumes remaining cursor\n  console.log(cursor.rowsRead); // prints 3\nts\n  let size = ctx.storage.sql.databaseSize;\n  python\n  size = ctx.storage.sql.databaseSize\n  ts\n  let now = new Date();\n  // restore to 2 days ago\n  let bookmark = ctx.storage.getBookmarkForTime(now - 2);\n  ctx.storage.onNextSessionRestoreBookmark(bookmark);\n  python\n  from datetime import datetime, timedelta\n\nnow = datetime.now()\n  # restore to 2 days ago\n  bookmark = ctx.storage.getBookmarkForTime(now - timedelta(days=2))\n  ctx.storage.onNextSessionRestoreBookmark(bookmark)\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Durable Object\n  export class MyDurableObject extends DurableObject {\n    // DurableObjectState is accessible via the ctx instance property\n    constructor(ctx, env) {\n      super(ctx, env);\n    }\n    ...\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    MY_DURABLE_OBJECT: DurableObjectNamespace<MyDurableObject>;\n  }\n\n// Durable Object\n  export class MyDurableObject extends DurableObject {\n    // DurableObjectState is accessible via the ctx instance property\n    constructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n    }\n    ...\n  }\n  python\n  from workers import DurableObject\n\n# Durable Object\n  class MyDurableObject(DurableObject):\n    # DurableObjectState is accessible via the ctx instance property\n    def __init__(self, ctx, env):\n      super().__init__(ctx, env)\n    # ...\n  js\n  // Durable Object\n  export class MyDurableObject extends DurableObject {\n    initialized = false;\n\nconstructor(ctx, env) {\n      super(ctx, env);\n\n// blockConcurrencyWhile will ensure that initialized will always be true\n      this.ctx.blockConcurrencyWhile(async () => {\n        this.initialized = true;\n      });\n    }\n    ...\n  }\n  python\n  # Durable Object\n  class MyDurableObject(DurableObject):\n    def __init__(self, ctx, env):\n      super().__init__(ctx, env)\n      self.initialized = False\n\n# blockConcurrencyWhile will ensure that initialized will always be true\n      async def set_initialized():\n        self.initialized = True\n      self.ctx.blockConcurrencyWhile(set_initialized)\n    # ...\n  js\n  // Durable Object\n  export class MyDurableObject extends DurableObject {\n    constructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n    }\n\nasync sayHello() {\n      // Error: Hello, World! will be logged\n      this.ctx.abort(\"Hello, World!\");\n    }\n  }\n  python\n  # Durable Object\n  class MyDurableObject(DurableObject):\n    def __init__(self, ctx, env):\n      super().__init__(ctx, env)\n\nasync def say_hello(self):\n      # Error: Hello, World! will be logged\n      self.ctx.abort(\"Hello, World!\")\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Durable Object\n  export class MyDurableObject extends DurableObject {\n    constructor(ctx, env) {\n      super(ctx, env);\n    }\n\nasync sayHello() {\n      return \"Hello, World!\";\n    }\n  }\n\n// Worker\n  export default {\n    async fetch(request, env) {\n      // A stub is a client used to invoke methods on the Durable Object\n      const stub = env.MY_DURABLE_OBJECT.getByName(\"foo\");\n\n// Methods on the Durable Object are invoked via the stub\n      const rpcResponse = await stub.sayHello();\n\nreturn new Response(rpcResponse);\n    },\n  };\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    MY_DURABLE_OBJECT: DurableObjectNamespace<MyDurableObject>;\n  }\n\n// Durable Object\n  export class MyDurableObject extends DurableObject {\n    constructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n    }\n\nasync sayHello(): Promise<string> {\n      return \"Hello, World!\";\n    }\n  }\n\n// Worker\n  export default {\n    async fetch(request, env) {\n      // A stub is a client used to invoke methods on the Durable Object\n      const stub = env.MY_DURABLE_OBJECT.getByName(\"foo\");\n\n// Methods on the Durable Object are invoked via the stub\n      const rpcResponse = await stub.sayHello();\n\nreturn new Response(rpcResponse);\n    },\n  } satisfies ExportedHandler<Env>;\n  js\n  const id = env.MY_DURABLE_OBJECT.newUniqueId();\n  const stub = env.MY_DURABLE_OBJECT.get(id);\n  console.assert(id.equals(stub.id), \"This should always be true\");\n  python\n  id = env.MY_DURABLE_OBJECT.newUniqueId()\n  stub = env.MY_DURABLE_OBJECT.get(id)\n  assert id.equals(stub.id), \"This should always be true\"\n  js\n  const stub = env.MY_DURABLE_OBJECT.getByName(\"foo\");\n  console.assert(stub.name === \"foo\", \"This should always be true\");\n  python\n  stub = env.MY_DURABLE_OBJECT.getByName(\"foo\")\n  assert stub.name == \"foo\", \"This should always be true\"\n  plaintext\ncompatibility_flags = [\"experimental\", \"webgpu\"]\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"migrations\": [\n      {\n        \"tag\": \"v1\",\n        \"new_sqlite_classes\": [\n          \"MyDurableObject\"\n        ]\n      }\n    ]\n  }\n  toml\n  [[migrations]]\n  tag = \"v1\" # Should be unique for each entry\n  new_sqlite_classes = [\"MyDurableObject\"] # Array of new classes\n  ts\nimport { DurableObject } from \"cloudflare:workers\";\n\nexport class Counter extends DurableObject {\n  value: number;\n\nconstructor(ctx: DurableObjectState, env: Env) {\n    super(ctx, env);\n\n// `blockConcurrencyWhile()` ensures no requests are delivered until\n    // initialization completes.\n    ctx.blockConcurrencyWhile(async () => {\n      // After initialization, future reads do not need to access storage.\n      this.value = (await ctx.storage.get(\"value\")) || 0;\n    });\n  }\n\nasync getCounterValue() {\n    return this.value;\n  }\n}\nts\nexport class MyDurableObject extends DurableObject<Env> {\n  constructor(ctx: DurableObjectState, env: Env) {\n    super(ctx, env);\n  }\n\n// Clears Durable Object storage\n  async clearDo(): Promise<void> {\n    // If you've configured a Durable Object alarm\n    await this.ctx.storage.deleteAlarm();\n\n// This will delete all the storage associated with this Durable Object instance\n    // This will also delete the Durable Object instance itself\n    await this.ctx.storage.deleteAll();\n  }\n}\nts\nimport { DurableObject } from \"cloudflare:workers\";\n\nexport class MyDurableObject extends DurableObject {\n  sql: SqlStorage\n  constructor(ctx: DurableObjectState, env: Env) {\n    super(ctx, env);\n    this.sql = ctx.storage.sql;\n\nthis.sql.exec(`CREATE TABLE IF NOT EXISTS artist(\n      artistid    INTEGER PRIMARY KEY,\n      artistname  TEXT\n    );INSERT INTO artist (artistid, artistname) VALUES\n      (123, 'Alice'),\n      (456, 'Bob'),\n      (789, 'Charlie');`\n    );\n  }\n}\nts\n  let cursor = this.sql.exec(\"SELECT * FROM artist;\");\n\nfor (let row of cursor) {\n    // Iterate over row object and do something\n  }\nts\n  // Return array of row objects: [{\"artistid\":123,\"artistname\":\"Alice\"},{\"artistid\":456,\"artistname\":\"Bob\"},{\"artistid\":789,\"artistname\":\"Charlie\"}]\n  let resultsArray1 = this.sql.exec(\"SELECT * FROM artist;\").toArray();\n  // OR\n  let resultsArray2 = Array.from(this.sql.exec(\"SELECT * FROM artist;\"));\n  // OR\n  let resultsArray3 = [...this.sql.exec(\"SELECT * FROM artist;\")]; // JavaScript spread syntax\nts\n  // Returns [[123,\"Alice\"],[456,\"Bob\"],[789,\"Charlie\"]]\n  let cursor = this.sql.exec(\"SELECT * FROM artist;\");\n  let resultsArray = cursor.raw().toArray();\n\n// Returns [\"artistid\",\"artistname\"]\n  let columnNameArray = this.sql.exec(\"SELECT * FROM artist;\").columnNames.toArray();\nts\n  // Returns {\"artistid\":123,\"artistname\":\"Alice\"}\n  let firstRow = this.sql.exec(\"SELECT * FROM artist ORDER BY artistname DESC;\").toArray()[0];\nts\n  // returns error\n  this.sql.exec(\"SELECT * FROM artist ORDER BY artistname ASC;\").one();\n\n// returns { artistid: 123, artistname: 'Alice' }\n  let oneRow = this.sql.exec(\"SELECT * FROM artist WHERE artistname = ?;\", \"Alice\").one()\nts\n  let cursor = this.sql.exec(\"SELECT * FROM artist ORDER BY artistname ASC;\");\n  let result = cursor.next();\n  if (!result.done) {\n    console.log(result.value); // prints { artistid: 123, artistname: 'Alice' }\n  } else {\n    // query returned zero results\n  }\n\nlet remainingRows = cursor.toArray();\n  console.log(remainingRows); // prints [{ artistid: 456, artistname: 'Bob' },{ artistid: 789, artistname: 'Charlie' }]\nts\n  let cursor = this.sql.exec(\"SELECT * FROM artist ORDER BY artistname ASC;\");\n  let result = cursor.raw().next();\n\nif (!result.done) {\n    console.log(result.value); // prints [ 123, 'Alice' ]\n  } else {\n    // query returned zero results\n  }\n\nconsole.log(cursor.toArray()); // prints [{ artistid: 456, artistname: 'Bob' },{ artistid: 789, artistname: 'Charlie' }]\nts\n  let cursor = this.sql.exec(\"SELECT * FROM artist;\");\n  cursor.next()\n  console.log(cursor.rowsRead); // prints 1\n\ncursor.toArray(); // consumes remaining cursor\n  console.log(cursor.rowsRead); // prints 3\nts\ntype User = {\n  id: string;\n  name: string;\n  email_address: string;\n  version: number;\n};\nts\n// The type parameter is passed between angle brackets before the function argument:\nconst result = this.ctx.storage.sql\n  .exec<User>(\n    \"SELECT id, name, email_address, version FROM users WHERE id = ?\",\n    user_id,\n  )\n  .one();\n// result will now have a type of \"User\"\n\n// Alternatively, if you are iterating over results using a cursor\nlet cursor = this.sql.exec<User>(\n  \"SELECT id, name, email_address, version FROM users WHERE id = ?\",\n  user_id,\n);\nfor (let row of cursor) {\n  // Each row object will be of type User\n}\n\n// Or, if you are using raw() to convert results into an array, define an array type:\ntype UserRow = [\n  id: string,\n  name: string,\n  email_address: string,\n  version: number,\n];\n\n// ... and then pass it as the type argument to the raw() method:\nlet cursor = sql\n  .exec(\n    \"SELECT id, name, email_address, version FROM users WHERE id = ?\",\n    user_id,\n  )\n  .raw<UserRow>();\n\nfor (let row of cursor) {\n  // row is of type User\n}\njs\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Durable Object\n  export class MyDurableObject extends DurableObject {\n    constructor(ctx, env) {\n      super(ctx, env);\n    }\n\nasync sayHello() {\n      return \"Hello, World!\";\n    }\n  }\n\n// Worker\n  export default {\n    async fetch(request, env) {\n      // A stub is a client used to invoke methods on the Durable Object\n      const stub = env.MY_DURABLE_OBJECT.getByName(\"foo\");\n\n// Methods on the Durable Object are invoked via the stub\n      const rpcResponse = await stub.sayHello();\n\nreturn new Response(rpcResponse);\n    },\n  };\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    MY_DURABLE_OBJECT: DurableObjectNamespace<MyDurableObject>;\n  }\n\n// Durable Object\n  export class MyDurableObject extends DurableObject {\n    constructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n    }\n\nasync sayHello(): Promise<string> {\n      return \"Hello, World!\";\n    }\n  }\n\n// Worker\n  export default {\n    async fetch(request, env) {\n      // A stub is a client used to invoke methods on the Durable Object\n      const stub = env.MY_DURABLE_OBJECT.getByName(\"foo\");\n\n// Methods on the Durable Object are invoked via the stub\n      const rpcResponse = await stub.sayHello();\n\nreturn new Response(rpcResponse);\n    },\n  } satisfies ExportedHandler<Env>;\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Durable Object\n  export class MyDurableObject extends DurableObject {\n    constructor(ctx, env) {\n      super(ctx, env);\n    }\n\nasync fetch(request) {\n      return new Response(\"Hello, World!\");\n    }\n  }\n\n// Worker\n  export default {\n    async fetch(request, env) {\n      // A stub is a client used to invoke methods on the Durable Object\n      const stub = env.MY_DURABLE_OBJECT.getByName(\"foo\");\n\n// Methods on the Durable Object are invoked via the stub\n      const response = await stub.fetch(request);\n\nreturn response;\n    },\n  };\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    MY_DURABLE_OBJECT: DurableObjectNamespace<MyDurableObject>;\n  }\n\n// Durable Object\n  export class MyDurableObject extends DurableObject {\n    constructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n    }\n\nasync fetch(request: Request): Promise<Response> {\n      return new Response(\"Hello, World!\");\n    }\n  }\n\n// Worker\n  export default {\n    async fetch(request, env) {\n      // A stub is a client used to invoke methods on the Durable Object\n      const stub = env.MY_DURABLE_OBJECT.getByName(\"foo\");\n\n// Methods on the Durable Object are invoked via the stub\n      const response = await stub.fetch(request);\n\nreturn response;\n    },\n  } satisfies ExportedHandler<Env>;\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Durable Object\n  export class MyDurableObject extends DurableObject {\n    constructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n    }\n\nprivate hello(name) {\n      return new Response(`Hello, ${name}!`);\n    }\n\nprivate goodbye(name) {\n      return new Response(`Goodbye, ${name}!`);\n    }\n\nasync fetch(request) {\n      const url = new URL(request.url);\n      let name = url.searchParams.get(\"name\");\n      if (!name) {\n        name = \"World\";\n      }\n\nswitch (url.pathname) {\n        case \"/hello\":\n          return this.hello(name);\n        case \"/goodbye\":\n          return this.goodbye(name);\n        default:\n          return new Response(\"Bad Request\", { status: 400 });\n      }\n    }\n  }\n\n// Worker\n  export default {\n    async fetch(_request, env, _ctx) {\n      // A stub is a client used to invoke methods on the Durable Object\n      const stub = env.MY_DURABLE_OBJECT.getByName(\"foo\");\n\n// Invoke the fetch handler on the Durable Object stub\n      let response = await stub.fetch(\"http://do/hello?name=World\");\n\nreturn response;\n    },\n  };\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    MY_DURABLE_OBJECT: DurableObjectNamespace<MyDurableObject>;\n  }\n\n// Durable Object\n  export class MyDurableObject extends DurableObject {\n    constructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n    }\n\nprivate hello(name: string) {\n      return new Response(`Hello, ${name}!`);\n    }\n\nprivate goodbye(name: string) {\n      return new Response(`Goodbye, ${name}!`);\n    }\n\nasync fetch(request: Request): Promise<Response> {\n      const url = new URL(request.url);\n      let name = url.searchParams.get(\"name\");\n      if (!name) {\n        name = \"World\";\n      }\n\nswitch (url.pathname) {\n        case \"/hello\":\n          return this.hello(name);\n        case \"/goodbye\":\n          return this.goodbye(name);\n        default:\n          return new Response(\"Bad Request\", { status: 400 });\n      }\n    }\n  }\n\n// Worker\n  export default {\n    async fetch(_request, env, _ctx) {\n      // A stub is a client used to invoke methods on the Durable Object\n      const stub = env.MY_DURABLE_OBJECT.getByName(\"foo\");\n\n// Invoke the fetch handler on the Durable Object stub\n      let response = await stub.fetch(\"http://do/hello?name=World\");\n\nreturn response;\n    },\n  } satisfies ExportedHandler<Env>;\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\n// ✅ Good use of Durable Objects: Seat booking requires coordination\n  // All booking requests for a venue must be serialized to prevent double-booking\n  export class SeatBooking extends DurableObject {\n    async bookSeat(seatId, userId) {\n      // Check if seat is already booked\n      const existing = this.ctx.storage.sql\n        .exec(\"SELECT user_id FROM bookings WHERE seat_id = ?\", seatId)\n        .toArray();\n\nif (existing.length > 0) {\n        return { success: false, message: \"Seat already booked\" };\n      }\n\n// Book the seat - this is safe because Durable Objects are single-threaded\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO bookings (seat_id, user_id, booked_at) VALUES (?, ?, ?)\",\n        seatId,\n        userId,\n        Date.now(),\n      );\n\nreturn { success: true, message: \"Seat booked successfully\" };\n    }\n  }\n\nexport default {\n    async fetch(request, env) {\n      const url = new URL(request.url);\n      const eventId = url.searchParams.get(\"event\") ?? \"default\";\n\n// Route to a Durable Object by event ID\n      // All bookings for the same event go to the same instance\n      const id = env.BOOKING.idFromName(eventId);\n      const booking = env.BOOKING.get(id);\n\nconst { seatId, userId } = await request.json();\n      const result = await booking.bookSeat(seatId, userId);\n\nreturn Response.json(result, {\n        status: result.success ? 200 : 409,\n      });\n    },\n  };\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    BOOKING: DurableObjectNamespace<SeatBooking>;\n  }\n\n// ✅ Good use of Durable Objects: Seat booking requires coordination\n  // All booking requests for a venue must be serialized to prevent double-booking\n  export class SeatBooking extends DurableObject<Env> {\n    async bookSeat(\n      seatId: string,\n      userId: string\n    ): Promise<{ success: boolean; message: string }> {\n      // Check if seat is already booked\n      const existing = this.ctx.storage.sql\n        .exec<{ user_id: string }>(\n          \"SELECT user_id FROM bookings WHERE seat_id = ?\",\n          seatId\n        )\n        .toArray();\n\nif (existing.length > 0) {\n        return { success: false, message: \"Seat already booked\" };\n      }\n\n// Book the seat - this is safe because Durable Objects are single-threaded\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO bookings (seat_id, user_id, booked_at) VALUES (?, ?, ?)\",\n        seatId,\n        userId,\n        Date.now()\n      );\n\nreturn { success: true, message: \"Seat booked successfully\" };\n    }\n  }\n\nexport default {\n    async fetch(request: Request, env: Env): Promise<Response> {\n      const url = new URL(request.url);\n      const eventId = url.searchParams.get(\"event\") ?? \"default\";\n\n// Route to a Durable Object by event ID\n      // All bookings for the same event go to the same instance\n      const id = env.BOOKING.idFromName(eventId);\n      const booking = env.BOOKING.get(id);\n\nconst { seatId, userId } = await request.json<{\n        seatId: string;\n        userId: string;\n      }>();\n      const result = await booking.bookSeat(seatId, userId);\n\nreturn Response.json(result, {\n        status: result.success ? 200 : 409,\n      });\n    },\n  };\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Each chat room is its own Durable Object instance\n  export class ChatRoom extends DurableObject {\n    async sendMessage(userId, message) {\n      // All messages to this room are processed sequentially by this single instance.\n      // No race conditions, no distributed locks needed.\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO messages (user_id, content, created_at) VALUES (?, ?, ?)\",\n        userId,\n        message,\n        Date.now(),\n      );\n    }\n  }\n\nexport default {\n    async fetch(request, env) {\n      const url = new URL(request.url);\n      const roomId = url.searchParams.get(\"room\") ?? \"lobby\";\n\n// Each room ID maps to exactly one Durable Object instance globally\n      const id = env.CHAT_ROOM.idFromName(roomId);\n      const stub = env.CHAT_ROOM.get(id);\n\nawait stub.sendMessage(\"user-123\", \"Hello, room!\");\n      return new Response(\"Message sent\");\n    },\n  };\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    CHAT_ROOM: DurableObjectNamespace<ChatRoom>;\n  }\n\n// Each chat room is its own Durable Object instance\n  export class ChatRoom extends DurableObject<Env> {\n    async sendMessage(userId: string, message: string) {\n      // All messages to this room are processed sequentially by this single instance.\n      // No race conditions, no distributed locks needed.\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO messages (user_id, content, created_at) VALUES (?, ?, ?)\",\n        userId,\n        message,\n        Date.now()\n      );\n    }\n  }\n\nexport default {\n    async fetch(request: Request, env: Env): Promise<Response> {\n      const url = new URL(request.url);\n      const roomId = url.searchParams.get(\"room\") ?? \"lobby\";\n\n// Each room ID maps to exactly one Durable Object instance globally\n      const id = env.CHAT_ROOM.idFromName(roomId);\n      const stub = env.CHAT_ROOM.get(id);\n\nawait stub.sendMessage(\"user-123\", \"Hello, room!\");\n      return new Response(\"Message sent\");\n    },\n  };\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\n// 🔴 Bad: A single Durable Object handling ALL chat rooms\n  export class ChatRoom extends DurableObject {\n    async sendMessage(roomId, userId, message) {\n      // All messages for ALL rooms go through this single instance.\n      // This becomes a bottleneck as traffic grows.\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO messages (room_id, user_id, content) VALUES (?, ?, ?)\",\n        roomId,\n        userId,\n        message,\n      );\n    }\n  }\n\nexport default {\n    async fetch(request, env) {\n      // 🔴 Bad: Always using the same ID means one global instance\n      const id = env.CHAT_ROOM.idFromName(\"global\");\n      const stub = env.CHAT_ROOM.get(id);\n\nawait stub.sendMessage(\"room-123\", \"user-456\", \"Hello!\");\n      return new Response(\"Sent\");\n    },\n  };\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    CHAT_ROOM: DurableObjectNamespace<ChatRoom>;\n  }\n\n// 🔴 Bad: A single Durable Object handling ALL chat rooms\n  export class ChatRoom extends DurableObject<Env> {\n    async sendMessage(roomId: string, userId: string, message: string) {\n      // All messages for ALL rooms go through this single instance.\n      // This becomes a bottleneck as traffic grows.\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO messages (room_id, user_id, content) VALUES (?, ?, ?)\",\n        roomId,\n        userId,\n        message\n      );\n    }\n  }\n\nexport default {\n    async fetch(request: Request, env: Env): Promise<Response> {\n      // 🔴 Bad: Always using the same ID means one global instance\n      const id = env.CHAT_ROOM.idFromName(\"global\");\n      const stub = env.CHAT_ROOM.get(id);\n\nawait stub.sendMessage(\"room-123\", \"user-456\", \"Hello!\");\n      return new Response(\"Sent\");\n    },\n  };\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class GameSession extends DurableObject {\n    async join(playerId) {\n      // Game logic here\n    }\n  }\n\nexport default {\n    async fetch(request, env) {\n      const url = new URL(request.url);\n      const gameId = url.searchParams.get(\"game\");\n\nif (!gameId) {\n        return new Response(\"Missing game ID\", { status: 400 });\n      }\n\n// ✅ Good: Deterministic ID from a meaningful string\n      // All requests for \"game-abc123\" go to the same Durable Object\n      const stub = env.GAME_SESSION.getByName(gameId);\n\nawait stub.join(\"player-xyz\");\n      return new Response(\"Joined game\");\n    },\n  };\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    GAME_SESSION: DurableObjectNamespace<GameSession>;\n  }\n\nexport class GameSession extends DurableObject<Env> {\n    async join(playerId: string) {\n      // Game logic here\n    }\n  }\n\nexport default {\n    async fetch(request: Request, env: Env): Promise<Response> {\n      const url = new URL(request.url);\n      const gameId = url.searchParams.get(\"game\");\n\nif (!gameId) {\n        return new Response(\"Missing game ID\", { status: 400 });\n      }\n\n// ✅ Good: Deterministic ID from a meaningful string\n      // All requests for \"game-abc123\" go to the same Durable Object\n      const stub = env.GAME_SESSION.getByName(gameId);\n\nawait stub.join(\"player-xyz\");\n      return new Response(\"Joined game\");\n    },\n  };\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class GameSession extends DurableObject {\n    async join(playerId) {\n      // Game logic here\n    }\n  }\n\nexport default {\n    async fetch(request, env) {\n      // newUniqueId() creates a random ID - useful when creating new instances\n      // You must store this ID somewhere (e.g., D1) to find it again later\n      const id = env.GAME_SESSION.newUniqueId();\n      const stub = env.GAME_SESSION.get(id);\n\n// Store the mapping: gameCode -> id.toString()\n      // await env.DB.prepare(\"INSERT INTO games (code, do_id) VALUES (?, ?)\").bind(gameCode, id.toString()).run();\n\nreturn Response.json({ gameId: id.toString() });\n    },\n  };\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    GAME_SESSION: DurableObjectNamespace<GameSession>;\n  }\n\nexport class GameSession extends DurableObject<Env> {\n    async join(playerId: string) {\n      // Game logic here\n    }\n  }\n\nexport default {\n    async fetch(request: Request, env: Env): Promise<Response> {\n      // newUniqueId() creates a random ID - useful when creating new instances\n      // You must store this ID somewhere (e.g., D1) to find it again later\n      const id = env.GAME_SESSION.newUniqueId();\n      const stub = env.GAME_SESSION.get(id);\n\n// Store the mapping: gameCode -> id.toString()\n      // await env.DB.prepare(\"INSERT INTO games (code, do_id) VALUES (?, ?)\").bind(gameCode, id.toString()).run();\n\nreturn Response.json({ gameId: id.toString() });\n    },\n  };\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Parent: Coordinates matches, but doesn't store match data\n  export class GameServer extends DurableObject {\n    async createMatch(matchName) {\n      const matchId = crypto.randomUUID();\n\n// Store reference to the child in parent's database\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO matches (id, name, created_at) VALUES (?, ?, ?)\",\n        matchId,\n        matchName,\n        Date.now(),\n      );\n\n// Initialize the child Durable Object\n      const childId = this.env.GAME_MATCH.idFromName(matchId);\n      const childStub = this.env.GAME_MATCH.get(childId);\n      await childStub.init(matchId, matchName);\n\nreturn matchId;\n    }\n\nasync listMatches() {\n      // Parent knows about all matches without waking up each child\n      const cursor = this.ctx.storage.sql.exec(\n        \"SELECT id, name FROM matches ORDER BY created_at DESC\",\n      );\n      return cursor.toArray();\n    }\n  }\n\n// Child: Handles its own game state independently\n  export class GameMatch extends DurableObject {\n    async init(matchId, matchName) {\n      await this.ctx.storage.put(\"matchId\", matchId);\n      await this.ctx.storage.put(\"matchName\", matchName);\n      this.ctx.storage.sql.exec(`\n        CREATE TABLE IF NOT EXISTS players (\n          id TEXT PRIMARY KEY,\n          name TEXT NOT NULL,\n          score INTEGER DEFAULT 0\n        )\n      `);\n    }\n\nasync addPlayer(playerId, playerName) {\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO players (id, name, score) VALUES (?, ?, 0)\",\n        playerId,\n        playerName,\n      );\n    }\n\nasync updateScore(playerId, score) {\n      this.ctx.storage.sql.exec(\n        \"UPDATE players SET score = ? WHERE id = ?\",\n        score,\n        playerId,\n      );\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    GAME_SERVER: DurableObjectNamespace<GameServer>;\n    GAME_MATCH: DurableObjectNamespace<GameMatch>;\n  }\n\n// Parent: Coordinates matches, but doesn't store match data\n  export class GameServer extends DurableObject<Env> {\n    async createMatch(matchName: string): Promise<string> {\n      const matchId = crypto.randomUUID();\n\n// Store reference to the child in parent's database\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO matches (id, name, created_at) VALUES (?, ?, ?)\",\n        matchId,\n        matchName,\n        Date.now()\n      );\n\n// Initialize the child Durable Object\n      const childId = this.env.GAME_MATCH.idFromName(matchId);\n      const childStub = this.env.GAME_MATCH.get(childId);\n      await childStub.init(matchId, matchName);\n\nreturn matchId;\n    }\n\nasync listMatches(): Promise<{ id: string; name: string }[]> {\n      // Parent knows about all matches without waking up each child\n      const cursor = this.ctx.storage.sql.exec<{ id: string; name: string }>(\n        \"SELECT id, name FROM matches ORDER BY created_at DESC\"\n      );\n      return cursor.toArray();\n    }\n  }\n\n// Child: Handles its own game state independently\n  export class GameMatch extends DurableObject<Env> {\n    async init(matchId: string, matchName: string) {\n      await this.ctx.storage.put(\"matchId\", matchId);\n      await this.ctx.storage.put(\"matchName\", matchName);\n      this.ctx.storage.sql.exec(`\n        CREATE TABLE IF NOT EXISTS players (\n          id TEXT PRIMARY KEY,\n          name TEXT NOT NULL,\n          score INTEGER DEFAULT 0\n        )\n      `);\n    }\n\nasync addPlayer(playerId: string, playerName: string) {\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO players (id, name, score) VALUES (?, ?, 0)\",\n        playerId,\n        playerName\n      );\n    }\n\nasync updateScore(playerId: string, score: number) {\n      this.ctx.storage.sql.exec(\n        \"UPDATE players SET score = ? WHERE id = ?\",\n        score,\n        playerId\n      );\n    }\n  }\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class GameSession extends DurableObject {\n    // Game session logic\n  }\n\nexport default {\n    async fetch(request, env) {\n      const url = new URL(request.url);\n      const gameId = url.searchParams.get(\"game\") ?? \"default\";\n      const region = url.searchParams.get(\"region\") ?? \"wnam\"; // Western North America\n\n// Provide a location hint for where this Durable Object should be created\n      const id = env.GAME_SESSION.idFromName(gameId, {\n        locationHint: region,\n      });\n      const stub = env.GAME_SESSION.get(id);\n\nreturn new Response(\"Connected to game session\");\n    },\n  };\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    GAME_SESSION: DurableObjectNamespace<GameSession>;\n  }\n\nexport class GameSession extends DurableObject<Env> {\n    // Game session logic\n  }\n\nexport default {\n    async fetch(request: Request, env: Env): Promise<Response> {\n      const url = new URL(request.url);\n      const gameId = url.searchParams.get(\"game\") ?? \"default\";\n      const region = url.searchParams.get(\"region\") ?? \"wnam\"; // Western North America\n\n// Provide a location hint for where this Durable Object should be created\n      const id = env.GAME_SESSION.idFromName(gameId, {\n        locationHint: region,\n      });\n      const stub = env.GAME_SESSION.get(id);\n\nreturn new Response(\"Connected to game session\");\n    },\n  };\n  jsonc\n  {\n    \"migrations\": [\n      { \"tag\": \"v1\", \"new_sqlite_classes\": [\"ChatRoom\"] }\n    ]\n  }\n  toml\n  [[migrations]]\n  tag = \"v1\"\n  new_sqlite_classes = [ \"ChatRoom\" ]\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class ChatRoom extends DurableObject {\n    constructor(ctx, env) {\n      super(ctx, env);\n\n// Create tables on first instantiation\n      this.ctx.storage.sql.exec(`\n        CREATE TABLE IF NOT EXISTS messages (\n          id INTEGER PRIMARY KEY AUTOINCREMENT,\n          user_id TEXT NOT NULL,\n          content TEXT NOT NULL,\n          created_at INTEGER NOT NULL\n        )\n      `);\n    }\n\nasync addMessage(userId, content) {\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO messages (user_id, content, created_at) VALUES (?, ?, ?)\",\n        userId,\n        content,\n        Date.now(),\n      );\n    }\n\nasync getRecentMessages(limit = 50) {\n      // Use type parameter for typed results\n      const cursor = this.ctx.storage.sql.exec(\n        \"SELECT * FROM messages ORDER BY created_at DESC LIMIT ?\",\n        limit,\n      );\n      return cursor.toArray();\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    CHAT_ROOM: DurableObjectNamespace<ChatRoom>;\n  }\n\ntype Message = {\n    id: number;\n    user_id: string;\n    content: string;\n    created_at: number;\n  };\n\nexport class ChatRoom extends DurableObject<Env> {\n    constructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n\n// Create tables on first instantiation\n      this.ctx.storage.sql.exec(`\n        CREATE TABLE IF NOT EXISTS messages (\n          id INTEGER PRIMARY KEY AUTOINCREMENT,\n          user_id TEXT NOT NULL,\n          content TEXT NOT NULL,\n          created_at INTEGER NOT NULL\n        )\n      `);\n    }\n\nasync addMessage(userId: string, content: string) {\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO messages (user_id, content, created_at) VALUES (?, ?, ?)\",\n        userId,\n        content,\n        Date.now()\n      );\n    }\n\nasync getRecentMessages(limit: number = 50): Promise<Message[]> {\n      // Use type parameter for typed results\n      const cursor = this.ctx.storage.sql.exec<Message>(\n        \"SELECT * FROM messages ORDER BY created_at DESC LIMIT ?\",\n        limit\n      );\n      return cursor.toArray();\n    }\n  }\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class ChatRoom extends DurableObject {\n    constructor(ctx, env) {\n      super(ctx, env);\n\n// blockConcurrencyWhile() ensures no requests are processed until this completes\n      ctx.blockConcurrencyWhile(async () => {\n        await this.migrate();\n      });\n    }\n\nasync migrate() {\n      // Check current schema version\n      const version =\n        this.ctx.storage.sql.exec(\"PRAGMA user_version\").one()?.version ?? 0;\n\nif (version < 1) {\n        this.ctx.storage.sql.exec(`\n          CREATE TABLE IF NOT EXISTS messages (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            user_id TEXT NOT NULL,\n            content TEXT NOT NULL,\n            created_at INTEGER NOT NULL\n          );\n          CREATE INDEX IF NOT EXISTS idx_messages_created_at ON messages(created_at);\n          PRAGMA user_version = 1;\n        `);\n      }\n\nif (version < 2) {\n        // Future migration: add a new column\n        this.ctx.storage.sql.exec(`\n          ALTER TABLE messages ADD COLUMN edited_at INTEGER;\n          PRAGMA user_version = 2;\n        `);\n      }\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    CHAT_ROOM: DurableObjectNamespace<ChatRoom>;\n  }\n\nexport class ChatRoom extends DurableObject<Env> {\n    constructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n\n// blockConcurrencyWhile() ensures no requests are processed until this completes\n      ctx.blockConcurrencyWhile(async () => {\n        await this.migrate();\n      });\n    }\n\nprivate async migrate() {\n      // Check current schema version\n      const version =\n        this.ctx.storage.sql\n          .exec<{ version: number }>(\"PRAGMA user_version\")\n          .one()?.version ?? 0;\n\nif (version < 1) {\n        this.ctx.storage.sql.exec(`\n          CREATE TABLE IF NOT EXISTS messages (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            user_id TEXT NOT NULL,\n            content TEXT NOT NULL,\n            created_at INTEGER NOT NULL\n          );\n          CREATE INDEX IF NOT EXISTS idx_messages_created_at ON messages(created_at);\n          PRAGMA user_version = 1;\n        `);\n      }\n\nif (version < 2) {\n        // Future migration: add a new column\n        this.ctx.storage.sql.exec(`\n          ALTER TABLE messages ADD COLUMN edited_at INTEGER;\n          PRAGMA user_version = 2;\n        `);\n      }\n    }\n  }\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class ChatRoom extends DurableObject {\n    // In-memory cache - fast but NOT preserved across evictions or crashes\n    messageCache = null;\n\nasync getRecentMessages() {\n      // Return from cache if available (only valid while DO is in memory)\n      if (this.messageCache !== null) {\n        return this.messageCache;\n      }\n\n// Otherwise, load from durable storage\n      const cursor = this.ctx.storage.sql.exec(\n        \"SELECT * FROM messages ORDER BY created_at DESC LIMIT 100\",\n      );\n      this.messageCache = cursor.toArray();\n      return this.messageCache;\n    }\n\nasync addMessage(userId, content) {\n      // ✅ Always persist to durable storage first\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO messages (user_id, content, created_at) VALUES (?, ?, ?)\",\n        userId,\n        content,\n        Date.now(),\n      );\n\n// Then update the cache (if it exists)\n      // If the DO crashes here, the message is still saved in SQLite\n      this.messageCache = null; // Invalidate cache\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    CHAT_ROOM: DurableObjectNamespace<ChatRoom>;\n  }\n\ntype Message = {\n    id: number;\n    user_id: string;\n    content: string;\n    created_at: number;\n  };\n\nexport class ChatRoom extends DurableObject<Env> {\n    // In-memory cache - fast but NOT preserved across evictions or crashes\n    private messageCache: Message[] | null = null;\n\nasync getRecentMessages(): Promise<Message[]> {\n      // Return from cache if available (only valid while DO is in memory)\n      if (this.messageCache !== null) {\n        return this.messageCache;\n      }\n\n// Otherwise, load from durable storage\n      const cursor = this.ctx.storage.sql.exec<Message>(\n        \"SELECT * FROM messages ORDER BY created_at DESC LIMIT 100\"\n      );\n      this.messageCache = cursor.toArray();\n      return this.messageCache;\n    }\n\nasync addMessage(userId: string, content: string) {\n      // ✅ Always persist to durable storage first\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO messages (user_id, content, created_at) VALUES (?, ?, ?)\",\n        userId,\n        content,\n        Date.now()\n      );\n\n// Then update the cache (if it exists)\n      // If the DO crashes here, the message is still saved in SQLite\n      this.messageCache = null; // Invalidate cache\n    }\n  }\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class ChatRoom extends DurableObject {\n    constructor(ctx, env) {\n      super(ctx, env);\n\nctx.blockConcurrencyWhile(async () => {\n        this.ctx.storage.sql.exec(`\n          CREATE TABLE IF NOT EXISTS messages (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            user_id TEXT NOT NULL,\n            content TEXT NOT NULL,\n            created_at INTEGER NOT NULL\n          );\n\n-- Index for queries filtering by user\n          CREATE INDEX IF NOT EXISTS idx_messages_user_id ON messages(user_id);\n\n-- Index for time-based queries (recent messages)\n          CREATE INDEX IF NOT EXISTS idx_messages_created_at ON messages(created_at);\n\n-- Composite index for user + time queries\n          CREATE INDEX IF NOT EXISTS idx_messages_user_time ON messages(user_id, created_at);\n        `);\n      });\n    }\n\n// This query benefits from idx_messages_user_time\n    async getUserMessages(userId, since) {\n      return this.ctx.storage.sql\n        .exec(\n          \"SELECT * FROM messages WHERE user_id = ? AND created_at > ? ORDER BY created_at\",\n          userId,\n          since,\n        )\n        .toArray();\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    CHAT_ROOM: DurableObjectNamespace<ChatRoom>;\n  }\n\nexport class ChatRoom extends DurableObject<Env> {\n    constructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n\nctx.blockConcurrencyWhile(async () => {\n        this.ctx.storage.sql.exec(`\n          CREATE TABLE IF NOT EXISTS messages (\n            id INTEGER PRIMARY KEY AUTOINCREMENT,\n            user_id TEXT NOT NULL,\n            content TEXT NOT NULL,\n            created_at INTEGER NOT NULL\n          );\n\n-- Index for queries filtering by user\n          CREATE INDEX IF NOT EXISTS idx_messages_user_id ON messages(user_id);\n\n-- Index for time-based queries (recent messages)\n          CREATE INDEX IF NOT EXISTS idx_messages_created_at ON messages(created_at);\n\n-- Composite index for user + time queries\n          CREATE INDEX IF NOT EXISTS idx_messages_user_time ON messages(user_id, created_at);\n        `);\n      });\n    }\n\n// This query benefits from idx_messages_user_time\n    async getUserMessages(userId: string, since: number) {\n      return this.ctx.storage.sql\n        .exec(\n          \"SELECT * FROM messages WHERE user_id = ? AND created_at > ? ORDER BY created_at\",\n          userId,\n          since\n        )\n        .toArray();\n    }\n  }\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class Counter extends DurableObject {\n    // This code is safe due to input gates\n    async increment() {\n      // While these storage operations execute, no other requests\n      // can interleave - input gate blocks new events\n      const value = (await this.ctx.storage.get(\"count\")) ?? 0;\n      await this.ctx.storage.put(\"count\", value + 1);\n      return value + 1;\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    COUNTER: DurableObjectNamespace<Counter>;\n  }\n\nexport class Counter extends DurableObject<Env> {\n    // This code is safe due to input gates\n    async increment(): Promise<number> {\n      // While these storage operations execute, no other requests\n      // can interleave - input gate blocks new events\n      const value = (await this.ctx.storage.get<number>(\"count\")) ?? 0;\n      await this.ctx.storage.put(\"count\", value + 1);\n      return value + 1;\n    }\n  }\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class ChatRoom extends DurableObject {\n    async sendMessage(userId, content) {\n      // Write to storage - don't need to await for correctness\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO messages (user_id, content, created_at) VALUES (?, ?, ?)\",\n        userId,\n        content,\n        Date.now(),\n      );\n\n// This response is held by the output gate until the write completes.\n      // The client only receives \"Message sent\" after data is safely persisted.\n      return \"Message sent\";\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    CHAT_ROOM: DurableObjectNamespace<ChatRoom>;\n  }\n\nexport class ChatRoom extends DurableObject<Env> {\n    async sendMessage(userId: string, content: string): Promise<string> {\n      // Write to storage - don't need to await for correctness\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO messages (user_id, content, created_at) VALUES (?, ?, ?)\",\n        userId,\n        content,\n        Date.now()\n      );\n\n// This response is held by the output gate until the write completes.\n      // The client only receives \"Message sent\" after data is safely persisted.\n      return \"Message sent\";\n    }\n  }\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class Account extends DurableObject {\n    async transfer(fromId, toId, amount) {\n      // ✅ Good: These writes are coalesced into one atomic transaction\n      this.ctx.storage.sql.exec(\n        \"UPDATE accounts SET balance = balance - ? WHERE id = ?\",\n        amount,\n        fromId,\n      );\n      this.ctx.storage.sql.exec(\n        \"UPDATE accounts SET balance = balance + ? WHERE id = ?\",\n        amount,\n        toId,\n      );\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO transfers (from_id, to_id, amount, created_at) VALUES (?, ?, ?, ?)\",\n        fromId,\n        toId,\n        amount,\n        Date.now(),\n      );\n      // All three writes commit together atomically\n    }\n\n// 🔴 Bad: await on KV operations breaks coalescing\n    async transferBrokenKV(fromId, toId, amount) {\n      const fromBalance = (await this.ctx.storage.get(`balance:${fromId}`)) ?? 0;\n      await this.ctx.storage.put(`balance:${fromId}`, fromBalance - amount);\n      // If the next write fails, the debit already committed!\n      const toBalance = (await this.ctx.storage.get(`balance:${toId}`)) ?? 0;\n      await this.ctx.storage.put(`balance:${toId}`, toBalance + amount);\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    ACCOUNT: DurableObjectNamespace<Account>;\n  }\n\nexport class Account extends DurableObject<Env> {\n    async transfer(fromId: string, toId: string, amount: number) {\n      // ✅ Good: These writes are coalesced into one atomic transaction\n      this.ctx.storage.sql.exec(\n        \"UPDATE accounts SET balance = balance - ? WHERE id = ?\",\n        amount,\n        fromId\n      );\n      this.ctx.storage.sql.exec(\n        \"UPDATE accounts SET balance = balance + ? WHERE id = ?\",\n        amount,\n        toId\n      );\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO transfers (from_id, to_id, amount, created_at) VALUES (?, ?, ?, ?)\",\n        fromId,\n        toId,\n        amount,\n        Date.now()\n      );\n      // All three writes commit together atomically\n    }\n\n// 🔴 Bad: await on KV operations breaks coalescing\n    async transferBrokenKV(fromId: string, toId: string, amount: number) {\n      const fromBalance = (await this.ctx.storage.get<number>(`balance:${fromId}`)) ?? 0;\n      await this.ctx.storage.put(`balance:${fromId}`, fromBalance - amount);\n      // If the next write fails, the debit already committed!\n      const toBalance = (await this.ctx.storage.get<number>(`balance:${toId}`)) ?? 0;\n      await this.ctx.storage.put(`balance:${toId}`, toBalance + amount);\n    }\n  }\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class Processor extends DurableObject {\n    // ⚠️ Potential race condition: fetch() allows interleaving\n    async processItem(id) {\n      const item = await this.ctx.storage.get(`item:${id}`);\n\nif (item?.status === \"pending\") {\n        // During this fetch, other requests CAN execute and modify storage\n        const result = await fetch(\"https://api.example.com/process\");\n\n// Another request may have already processed this item!\n        await this.ctx.storage.put(`item:${id}`, { status: \"completed\" });\n      }\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    PROCESSOR: DurableObjectNamespace<Processor>;\n  }\n\nexport class Processor extends DurableObject<Env> {\n    // ⚠️ Potential race condition: fetch() allows interleaving\n    async processItem(id: string) {\n      const item = await this.ctx.storage.get<{ status: string }>(`item:${id}`);\n\nif (item?.status === \"pending\") {\n        // During this fetch, other requests CAN execute and modify storage\n        const result = await fetch(\"https://api.example.com/process\");\n\n// Another request may have already processed this item!\n        await this.ctx.storage.put(`item:${id}`, { status: \"completed\" });\n      }\n    }\n  }\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class ChatRoom extends DurableObject {\n    constructor(ctx, env) {\n      super(ctx, env);\n\n// ✅ Good: Use blockConcurrencyWhile for one-time initialization\n      ctx.blockConcurrencyWhile(async () => {\n        this.ctx.storage.sql.exec(`\n          CREATE TABLE IF NOT EXISTS messages (\n            id INTEGER PRIMARY KEY,\n            content TEXT\n          )\n        `);\n      });\n    }\n\n// 🔴 Bad: Don't use blockConcurrencyWhile on every request\n    async sendMessageSlow(content) {\n      await this.ctx.blockConcurrencyWhile(async () => {\n        this.ctx.storage.sql.exec(\n          \"INSERT INTO messages (content) VALUES (?)\",\n          content,\n        );\n      });\n      // If this takes ~5ms, you're limited to ~200 requests/second\n    }\n\n// ✅ Good: Let output gates handle consistency\n    async sendMessageFast(content) {\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO messages (content) VALUES (?)\",\n        content,\n      );\n      // Output gate ensures write completes before response is sent\n      // Other requests can be processed concurrently\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    CHAT_ROOM: DurableObjectNamespace<ChatRoom>;\n  }\n\nexport class ChatRoom extends DurableObject<Env> {\n    constructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n\n// ✅ Good: Use blockConcurrencyWhile for one-time initialization\n      ctx.blockConcurrencyWhile(async () => {\n        this.ctx.storage.sql.exec(`\n          CREATE TABLE IF NOT EXISTS messages (\n            id INTEGER PRIMARY KEY,\n            content TEXT\n          )\n        `);\n      });\n    }\n\n// 🔴 Bad: Don't use blockConcurrencyWhile on every request\n    async sendMessageSlow(content: string) {\n      await this.ctx.blockConcurrencyWhile(async () => {\n        this.ctx.storage.sql.exec(\n          \"INSERT INTO messages (content) VALUES (?)\",\n          content\n        );\n      });\n      // If this takes ~5ms, you're limited to ~200 requests/second\n    }\n\n// ✅ Good: Let output gates handle consistency\n    async sendMessageFast(content: string) {\n      this.ctx.storage.sql.exec(\n        \"INSERT INTO messages (content) VALUES (?)\",\n        content\n      );\n      // Output gate ensures write completes before response is sent\n      // Other requests can be processed concurrently\n    }\n  }\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class ChatRoom extends DurableObject {\n    // Public methods are automatically exposed as RPC endpoints\n    async sendMessage(userId, content) {\n      const createdAt = Date.now();\n      const result = this.ctx.storage.sql.exec(\n        \"INSERT INTO messages (user_id, content, created_at) VALUES (?, ?, ?) RETURNING id\",\n        userId,\n        content,\n        createdAt,\n      );\n      const { id } = result.one();\n      return { id, userId, content, createdAt };\n    }\n\nasync getMessages(limit = 50) {\n      const cursor = this.ctx.storage.sql.exec(\n        \"SELECT * FROM messages ORDER BY created_at DESC LIMIT ?\",\n        limit,\n      );\n\nreturn cursor.toArray().map((row) => ({\n        id: row.id,\n        userId: row.user_id,\n        content: row.content,\n        createdAt: row.created_at,\n      }));\n    }\n  }\n\nexport default {\n    async fetch(request, env) {\n      const url = new URL(request.url);\n      const roomId = url.searchParams.get(\"room\") ?? \"lobby\";\n\nconst id = env.CHAT_ROOM.idFromName(roomId);\n      // stub is typed as DurableObjectStub<ChatRoom>\n      const stub = env.CHAT_ROOM.get(id);\n\nif (request.method === \"POST\") {\n        const { userId, content } = await request.json();\n        // Direct method call with full type checking\n        const message = await stub.sendMessage(userId, content);\n        return Response.json(message);\n      }\n\n// TypeScript knows getMessages() returns Promise<Message[]>\n      const messages = await stub.getMessages(100);\n      return Response.json(messages);\n    },\n  };\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    // Type parameter provides typed method calls on the stub\n    CHAT_ROOM: DurableObjectNamespace<ChatRoom>;\n  }\n\ntype Message = {\n    id: number;\n    userId: string;\n    content: string;\n    createdAt: number;\n  };\n\nexport class ChatRoom extends DurableObject<Env> {\n    // Public methods are automatically exposed as RPC endpoints\n    async sendMessage(userId: string, content: string): Promise<Message> {\n      const createdAt = Date.now();\n      const result = this.ctx.storage.sql.exec<{ id: number }>(\n        \"INSERT INTO messages (user_id, content, created_at) VALUES (?, ?, ?) RETURNING id\",\n        userId,\n        content,\n        createdAt\n      );\n      const { id } = result.one();\n      return { id, userId, content, createdAt };\n    }\n\nasync getMessages(limit: number = 50): Promise<Message[]> {\n      const cursor = this.ctx.storage.sql.exec<{\n        id: number;\n        user_id: string;\n        content: string;\n        created_at: number;\n      }>(\"SELECT * FROM messages ORDER BY created_at DESC LIMIT ?\", limit);\n\nreturn cursor.toArray().map((row) => ({\n        id: row.id,\n        userId: row.user_id,\n        content: row.content,\n        createdAt: row.created_at,\n      }));\n    }\n  }\n\nexport default {\n    async fetch(request: Request, env: Env): Promise<Response> {\n      const url = new URL(request.url);\n      const roomId = url.searchParams.get(\"room\") ?? \"lobby\";\n\nconst id = env.CHAT_ROOM.idFromName(roomId);\n      // stub is typed as DurableObjectStub<ChatRoom>\n      const stub = env.CHAT_ROOM.get(id);\n\nif (request.method === \"POST\") {\n        const { userId, content } = await request.json<{\n          userId: string;\n          content: string;\n        }>();\n        // Direct method call with full type checking\n        const message = await stub.sendMessage(userId, content);\n        return Response.json(message);\n      }\n\n// TypeScript knows getMessages() returns Promise<Message[]>\n      const messages = await stub.getMessages(100);\n      return Response.json(messages);\n    },\n  };\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class ChatRoom extends DurableObject {\n    roomId = null;\n\n// Call this after creating the Durable Object for the first time\n    async init(roomId, createdBy) {\n      // Check if already initialized\n      const existing = await this.ctx.storage.get(\"roomId\");\n      if (existing) {\n        return; // Already initialized\n      }\n\n// Store the identity\n      await this.ctx.storage.put(\"roomId\", roomId);\n      await this.ctx.storage.put(\"createdBy\", createdBy);\n      await this.ctx.storage.put(\"createdAt\", Date.now());\n\n// Cache in memory for this session\n      this.roomId = roomId;\n    }\n\nasync getRoomId() {\n      if (this.roomId) {\n        return this.roomId;\n      }\n\nconst stored = await this.ctx.storage.get(\"roomId\");\n      if (!stored) {\n        throw new Error(\"ChatRoom not initialized. Call init() first.\");\n      }\n\nthis.roomId = stored;\n      return stored;\n    }\n  }\n\nexport default {\n    async fetch(request, env) {\n      const url = new URL(request.url);\n      const roomId = url.searchParams.get(\"room\") ?? \"lobby\";\n\nconst id = env.CHAT_ROOM.idFromName(roomId);\n      const stub = env.CHAT_ROOM.get(id);\n\n// Initialize on first access\n      await stub.init(roomId, \"system\");\n\nreturn new Response(`Room ${await stub.getRoomId()} ready`);\n    },\n  };\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    CHAT_ROOM: DurableObjectNamespace<ChatRoom>;\n  }\n\nexport class ChatRoom extends DurableObject<Env> {\n    private roomId: string | null = null;\n\n// Call this after creating the Durable Object for the first time\n    async init(roomId: string, createdBy: string) {\n      // Check if already initialized\n      const existing = await this.ctx.storage.get(\"roomId\");\n      if (existing) {\n        return; // Already initialized\n      }\n\n// Store the identity\n      await this.ctx.storage.put(\"roomId\", roomId);\n      await this.ctx.storage.put(\"createdBy\", createdBy);\n      await this.ctx.storage.put(\"createdAt\", Date.now());\n\n// Cache in memory for this session\n      this.roomId = roomId;\n    }\n\nasync getRoomId(): Promise<string> {\n      if (this.roomId) {\n        return this.roomId;\n      }\n\nconst stored = await this.ctx.storage.get<string>(\"roomId\");\n      if (!stored) {\n        throw new Error(\"ChatRoom not initialized. Call init() first.\");\n      }\n\nthis.roomId = stored;\n      return stored;\n    }\n  }\n\nexport default {\n    async fetch(request: Request, env: Env): Promise<Response> {\n      const url = new URL(request.url);\n      const roomId = url.searchParams.get(\"room\") ?? \"lobby\";\n\nconst id = env.CHAT_ROOM.idFromName(roomId);\n      const stub = env.CHAT_ROOM.get(id);\n\n// Initialize on first access\n      await stub.init(roomId, \"system\");\n\nreturn new Response(`Room ${await stub.getRoomId()} ready`);\n    },\n  };\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class ChatRoom extends DurableObject {\n    async sendMessage(userId, content) {\n      const result = this.ctx.storage.sql.exec(\n        \"INSERT INTO messages (user_id, content, created_at) VALUES (?, ?, ?) RETURNING id\",\n        userId,\n        content,\n        Date.now(),\n      );\n      return result.one().id;\n    }\n  }\n\nexport default {\n    async fetch(request, env) {\n      const id = env.CHAT_ROOM.idFromName(\"lobby\");\n      const stub = env.CHAT_ROOM.get(id);\n\n// 🔴 Bad: Not awaiting the call\n      // The message ID is lost, and any errors are swallowed\n      stub.sendMessage(\"user-123\", \"Hello\");\n\n// ✅ Good: Properly awaited\n      const messageId = await stub.sendMessage(\"user-123\", \"Hello\");\n\nreturn Response.json({ messageId });\n    },\n  };\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    CHAT_ROOM: DurableObjectNamespace<ChatRoom>;\n  }\n\nexport class ChatRoom extends DurableObject<Env> {\n    async sendMessage(userId: string, content: string): Promise<number> {\n      const result = this.ctx.storage.sql.exec<{ id: number }>(\n        \"INSERT INTO messages (user_id, content, created_at) VALUES (?, ?, ?) RETURNING id\",\n        userId,\n        content,\n        Date.now()\n      );\n      return result.one().id;\n    }\n  }\n\nexport default {\n    async fetch(request: Request, env: Env): Promise<Response> {\n      const id = env.CHAT_ROOM.idFromName(\"lobby\");\n      const stub = env.CHAT_ROOM.get(id);\n\n// 🔴 Bad: Not awaiting the call\n      // The message ID is lost, and any errors are swallowed\n      stub.sendMessage(\"user-123\", \"Hello\");\n\n// ✅ Good: Properly awaited\n      const messageId = await stub.sendMessage(\"user-123\", \"Hello\");\n\nreturn Response.json({ messageId });\n    },\n  };\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class ChatRoom extends DurableObject {\n    async processMessage(userId, content) {\n      // ✅ Good: Wrap risky operations in try/catch\n      try {\n        // Validate input before processing\n        if (!content || content.length > 10000) {\n          throw new Error(\"Invalid message content\");\n        }\n\nthis.ctx.storage.sql.exec(\n          \"INSERT INTO messages (user_id, content, created_at) VALUES (?, ?, ?)\",\n          userId,\n          content,\n          Date.now(),\n        );\n\n// External call that might fail\n        await this.notifySubscribers(content);\n      } catch (error) {\n        // Log the error for debugging\n        console.error(\"Failed to process message:\", error);\n\n// Re-throw if it's a validation error (don't retry)\n        if (error instanceof Error && error.message.includes(\"Invalid\")) {\n          throw error;\n        }\n\n// For transient errors, you might want to handle differently\n        throw error;\n      }\n    }\n\nasync notifySubscribers(content) {\n      // External notification logic\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    CHAT_ROOM: DurableObjectNamespace<ChatRoom>;\n  }\n\nexport class ChatRoom extends DurableObject<Env> {\n    async processMessage(userId: string, content: string) {\n      // ✅ Good: Wrap risky operations in try/catch\n      try {\n        // Validate input before processing\n        if (!content || content.length > 10000) {\n          throw new Error(\"Invalid message content\");\n        }\n\nthis.ctx.storage.sql.exec(\n          \"INSERT INTO messages (user_id, content, created_at) VALUES (?, ?, ?)\",\n          userId,\n          content,\n          Date.now()\n        );\n\n// External call that might fail\n        await this.notifySubscribers(content);\n      } catch (error) {\n        // Log the error for debugging\n        console.error(\"Failed to process message:\", error);\n\n// Re-throw if it's a validation error (don't retry)\n        if (error instanceof Error && error.message.includes(\"Invalid\")) {\n          throw error;\n        }\n\n// For transient errors, you might want to handle differently\n        throw error;\n      }\n    }\n\nprivate async notifySubscribers(content: string) {\n      // External notification logic\n    }\n  }\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class ChatRoom extends DurableObject {\n    async fetch(request) {\n      const url = new URL(request.url);\n\nif (url.pathname === \"/websocket\") {\n        // Check for WebSocket upgrade\n        if (request.headers.get(\"Upgrade\") !== \"websocket\") {\n          return new Response(\"Expected WebSocket\", { status: 400 });\n        }\n\nconst pair = new WebSocketPair();\n        const [client, server] = Object.values(pair);\n\n// Accept the WebSocket with Hibernation API\n        this.ctx.acceptWebSocket(server);\n\nreturn new Response(null, { status: 101, webSocket: client });\n      }\n\nreturn new Response(\"Not found\", { status: 404 });\n    }\n\n// Called when a message is received (even after hibernation)\n    async webSocketMessage(ws, message) {\n      const data = typeof message === \"string\" ? message : \"binary data\";\n\n// Broadcast to all connected clients\n      for (const client of this.ctx.getWebSockets()) {\n        if (client !== ws && client.readyState === WebSocket.OPEN) {\n          client.send(data);\n        }\n      }\n    }\n\n// Called when a WebSocket is closed\n    async webSocketClose(ws, code, reason, wasClean) {\n      console.log(`WebSocket closed: ${code} ${reason}`);\n    }\n\n// Called when a WebSocket error occurs\n    async webSocketError(ws, error) {\n      console.error(\"WebSocket error:\", error);\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    CHAT_ROOM: DurableObjectNamespace<ChatRoom>;\n  }\n\nexport class ChatRoom extends DurableObject<Env> {\n    async fetch(request: Request): Promise<Response> {\n      const url = new URL(request.url);\n\nif (url.pathname === \"/websocket\") {\n        // Check for WebSocket upgrade\n        if (request.headers.get(\"Upgrade\") !== \"websocket\") {\n          return new Response(\"Expected WebSocket\", { status: 400 });\n        }\n\nconst pair = new WebSocketPair();\n        const [client, server] = Object.values(pair);\n\n// Accept the WebSocket with Hibernation API\n        this.ctx.acceptWebSocket(server);\n\nreturn new Response(null, { status: 101, webSocket: client });\n      }\n\nreturn new Response(\"Not found\", { status: 404 });\n    }\n\n// Called when a message is received (even after hibernation)\n    async webSocketMessage(ws: WebSocket, message: string | ArrayBuffer) {\n      const data = typeof message === \"string\" ? message : \"binary data\";\n\n// Broadcast to all connected clients\n      for (const client of this.ctx.getWebSockets()) {\n        if (client !== ws && client.readyState === WebSocket.OPEN) {\n          client.send(data);\n        }\n      }\n    }\n\n// Called when a WebSocket is closed\n    async webSocketClose(\n      ws: WebSocket,\n      code: number,\n      reason: string,\n      wasClean: boolean\n    ) {\n      console.log(`WebSocket closed: ${code} ${reason}`);\n    }\n\n// Called when a WebSocket error occurs\n    async webSocketError(ws: WebSocket, error: unknown) {\n      console.error(\"WebSocket error:\", error);\n    }\n  }\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class ChatRoom extends DurableObject {\n    async fetch(request) {\n      const url = new URL(request.url);\n\nif (url.pathname === \"/websocket\") {\n        if (request.headers.get(\"Upgrade\") !== \"websocket\") {\n          return new Response(\"Expected WebSocket\", { status: 400 });\n        }\n\nconst userId = url.searchParams.get(\"userId\") ?? \"anonymous\";\n        const username = url.searchParams.get(\"username\") ?? \"Anonymous\";\n\nconst pair = new WebSocketPair();\n        const [client, server] = Object.values(pair);\n\nthis.ctx.acceptWebSocket(server);\n\n// Store per-connection state that survives hibernation\n        const state = {\n          userId,\n          username,\n          joinedAt: Date.now(),\n        };\n        server.serializeAttachment(state);\n\n// Broadcast join message\n        this.broadcast(`${username} joined the chat`);\n\nreturn new Response(null, { status: 101, webSocket: client });\n      }\n\nreturn new Response(\"Not found\", { status: 404 });\n    }\n\nasync webSocketMessage(ws, message) {\n      // Retrieve the connection state (works even after hibernation)\n      const state = ws.deserializeAttachment();\n\nconst chatMessage = JSON.stringify({\n        userId: state.userId,\n        username: state.username,\n        content: message,\n        timestamp: Date.now(),\n      });\n\nthis.broadcast(chatMessage);\n    }\n\nasync webSocketClose(ws) {\n      const state = ws.deserializeAttachment();\n      this.broadcast(`${state.username} left the chat`);\n    }\n\nbroadcast(message) {\n      for (const client of this.ctx.getWebSockets()) {\n        if (client.readyState === WebSocket.OPEN) {\n          client.send(message);\n        }\n      }\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    CHAT_ROOM: DurableObjectNamespace<ChatRoom>;\n  }\n\ntype ConnectionState = {\n    userId: string;\n    username: string;\n    joinedAt: number;\n  };\n\nexport class ChatRoom extends DurableObject<Env> {\n    async fetch(request: Request): Promise<Response> {\n      const url = new URL(request.url);\n\nif (url.pathname === \"/websocket\") {\n        if (request.headers.get(\"Upgrade\") !== \"websocket\") {\n          return new Response(\"Expected WebSocket\", { status: 400 });\n        }\n\nconst userId = url.searchParams.get(\"userId\") ?? \"anonymous\";\n        const username = url.searchParams.get(\"username\") ?? \"Anonymous\";\n\nconst pair = new WebSocketPair();\n        const [client, server] = Object.values(pair);\n\nthis.ctx.acceptWebSocket(server);\n\n// Store per-connection state that survives hibernation\n        const state: ConnectionState = {\n          userId,\n          username,\n          joinedAt: Date.now(),\n        };\n        server.serializeAttachment(state);\n\n// Broadcast join message\n        this.broadcast(`${username} joined the chat`);\n\nreturn new Response(null, { status: 101, webSocket: client });\n      }\n\nreturn new Response(\"Not found\", { status: 404 });\n    }\n\nasync webSocketMessage(ws: WebSocket, message: string | ArrayBuffer) {\n      // Retrieve the connection state (works even after hibernation)\n      const state = ws.deserializeAttachment() as ConnectionState;\n\nconst chatMessage = JSON.stringify({\n        userId: state.userId,\n        username: state.username,\n        content: message,\n        timestamp: Date.now(),\n      });\n\nthis.broadcast(chatMessage);\n    }\n\nasync webSocketClose(ws: WebSocket) {\n      const state = ws.deserializeAttachment() as ConnectionState;\n      this.broadcast(`${state.username} left the chat`);\n    }\n\nprivate broadcast(message: string) {\n      for (const client of this.ctx.getWebSockets()) {\n        if (client.readyState === WebSocket.OPEN) {\n          client.send(message);\n        }\n      }\n    }\n  }\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class GameMatch extends DurableObject {\n    async startGame(durationMs = 60000) {\n      await this.ctx.storage.put(\"gameStarted\", Date.now());\n      await this.ctx.storage.put(\"gameActive\", true);\n\n// Schedule the game to end after the duration\n      await this.ctx.storage.setAlarm(Date.now() + durationMs);\n    }\n\n// Called when the alarm fires\n    async alarm() {\n      const isActive = await this.ctx.storage.get(\"gameActive\");\n\nif (!isActive) {\n        return; // Game was already ended\n      }\n\n// End the game\n      await this.ctx.storage.put(\"gameActive\", false);\n      await this.ctx.storage.put(\"gameEnded\", Date.now());\n\n// Calculate final scores, notify players, etc.\n      await this.calculateFinalScores();\n\n// Schedule the next alarm only if there's more work to do\n      // In this case, schedule cleanup in 24 hours\n      await this.ctx.storage.setAlarm(Date.now() + 24 * 60 * 60 * 1000);\n    }\n\nasync calculateFinalScores() {\n      // Game ending logic\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    GAME_MATCH: DurableObjectNamespace<GameMatch>;\n  }\n\nexport class GameMatch extends DurableObject<Env> {\n    async startGame(durationMs: number = 60000) {\n      await this.ctx.storage.put(\"gameStarted\", Date.now());\n      await this.ctx.storage.put(\"gameActive\", true);\n\n// Schedule the game to end after the duration\n      await this.ctx.storage.setAlarm(Date.now() + durationMs);\n    }\n\n// Called when the alarm fires\n    async alarm() {\n      const isActive = await this.ctx.storage.get<boolean>(\"gameActive\");\n\nif (!isActive) {\n        return; // Game was already ended\n      }\n\n// End the game\n      await this.ctx.storage.put(\"gameActive\", false);\n      await this.ctx.storage.put(\"gameEnded\", Date.now());\n\n// Calculate final scores, notify players, etc.\n      await this.calculateFinalScores();\n\n// Schedule the next alarm only if there's more work to do\n      // In this case, schedule cleanup in 24 hours\n      await this.ctx.storage.setAlarm(Date.now() + 24 * 60 * 60 * 1000);\n    }\n\nprivate async calculateFinalScores() {\n      // Game ending logic\n    }\n  }\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class Subscription extends DurableObject {\n    async alarm() {\n      // ✅ Good: Check state before performing the action\n      const lastRenewal = await this.ctx.storage.get(\"lastRenewal\");\n      const renewalPeriod = 30 * 24 * 60 * 60 * 1000; // 30 days\n\n// If we already renewed recently, don't do it again\n      if (lastRenewal && Date.now() - lastRenewal < renewalPeriod - 60000) {\n        console.log(\"Already renewed recently, skipping\");\n        return;\n      }\n\n// Perform the renewal\n      const success = await this.processRenewal();\n\nif (success) {\n        // Record the renewal time\n        await this.ctx.storage.put(\"lastRenewal\", Date.now());\n\n// Schedule the next renewal\n        await this.ctx.storage.setAlarm(Date.now() + renewalPeriod);\n      } else {\n        // Retry in 1 hour\n        await this.ctx.storage.setAlarm(Date.now() + 60 * 60 * 1000);\n      }\n    }\n\nasync processRenewal() {\n      // Payment processing logic\n      return true;\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    SUBSCRIPTION: DurableObjectNamespace<Subscription>;\n  }\n\nexport class Subscription extends DurableObject<Env> {\n    async alarm() {\n      // ✅ Good: Check state before performing the action\n      const lastRenewal = await this.ctx.storage.get<number>(\"lastRenewal\");\n      const renewalPeriod = 30 * 24 * 60 * 60 * 1000; // 30 days\n\n// If we already renewed recently, don't do it again\n      if (lastRenewal && Date.now() - lastRenewal < renewalPeriod - 60000) {\n        console.log(\"Already renewed recently, skipping\");\n        return;\n      }\n\n// Perform the renewal\n      const success = await this.processRenewal();\n\nif (success) {\n        // Record the renewal time\n        await this.ctx.storage.put(\"lastRenewal\", Date.now());\n\n// Schedule the next renewal\n        await this.ctx.storage.setAlarm(Date.now() + renewalPeriod);\n      } else {\n        // Retry in 1 hour\n        await this.ctx.storage.setAlarm(Date.now() + 60 * 60 * 1000);\n      }\n    }\n\nprivate async processRenewal(): Promise<boolean> {\n      // Payment processing logic\n      return true;\n    }\n  }\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class ChatRoom extends DurableObject {\n    async clearStorage() {\n      // If you have an alarm set, delete it first\n      await this.ctx.storage.deleteAlarm();\n\n// Delete all storage\n      await this.ctx.storage.deleteAll();\n\n// The Durable Object instance still exists, but with empty storage\n      // A subsequent request will find no data\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    CHAT_ROOM: DurableObjectNamespace<ChatRoom>;\n  }\n\nexport class ChatRoom extends DurableObject<Env> {\n    async clearStorage() {\n      // If you have an alarm set, delete it first\n      await this.ctx.storage.deleteAlarm();\n\n// Delete all storage\n      await this.ctx.storage.deleteAll();\n\n// The Durable Object instance still exists, but with empty storage\n      // A subsequent request will find no data\n    }\n  }\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\n// 🔴 Bad: Global rate limiter - ALL requests go through one instance\n  export class RateLimiter extends DurableObject {\n    async checkLimit(ip) {\n      const key = `rate:${ip}`;\n      const count = (await this.ctx.storage.get(key)) ?? 0;\n      await this.ctx.storage.put(key, count + 1);\n      return count < 100;\n    }\n  }\n\n// 🔴 Bad: Always using the same ID creates a global bottleneck\n  export default {\n    async fetch(request, env) {\n      // Every single request to your application goes through this one DO\n      const limiter = env.RATE_LIMITER.get(env.RATE_LIMITER.idFromName(\"global\"));\n\nconst ip = request.headers.get(\"CF-Connecting-IP\") ?? \"unknown\";\n      const allowed = await limiter.checkLimit(ip);\n\nif (!allowed) {\n        return new Response(\"Rate limited\", { status: 429 });\n      }\n\nreturn new Response(\"OK\");\n    },\n  };\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    RATE_LIMITER: DurableObjectNamespace<RateLimiter>;\n  }\n\n// 🔴 Bad: Global rate limiter - ALL requests go through one instance\n  export class RateLimiter extends DurableObject<Env> {\n    async checkLimit(ip: string): Promise<boolean> {\n      const key = `rate:${ip}`;\n      const count = (await this.ctx.storage.get<number>(key)) ?? 0;\n      await this.ctx.storage.put(key, count + 1);\n      return count < 100;\n    }\n  }\n\n// 🔴 Bad: Always using the same ID creates a global bottleneck\n  export default {\n    async fetch(request: Request, env: Env): Promise<Response> {\n      // Every single request to your application goes through this one DO\n      const limiter = env.RATE_LIMITER.get(\n        env.RATE_LIMITER.idFromName(\"global\")\n      );\n\nconst ip = request.headers.get(\"CF-Connecting-IP\") ?? \"unknown\";\n      const allowed = await limiter.checkLimit(ip);\n\nif (!allowed) {\n        return new Response(\"Rate limited\", { status: 429 });\n      }\n\nreturn new Response(\"OK\");\n    },\n  };\n  js\n  import {\n    env,\n    runInDurableObject,\n    runDurableObjectAlarm,\n  } from \"cloudflare:test\";\n  import { describe, it, expect } from \"vitest\";\n\ndescribe(\"ChatRoom\", () => {\n    // Each test gets isolated storage automatically\n    it(\"should send and retrieve messages\", async () => {\n      const id = env.CHAT_ROOM.idFromName(\"test-room\");\n      const stub = env.CHAT_ROOM.get(id);\n\n// Call RPC methods directly on the stub\n      await stub.sendMessage(\"user-1\", \"Hello!\");\n      await stub.sendMessage(\"user-2\", \"Hi there!\");\n\nconst messages = await stub.getMessages(10);\n      expect(messages).toHaveLength(2);\n    });\n\nit(\"can access instance internals and trigger alarms\", async () => {\n      const id = env.CHAT_ROOM.idFromName(\"test-room\");\n      const stub = env.CHAT_ROOM.get(id);\n\n// Access storage directly for verification\n      await runInDurableObject(stub, async (instance, state) => {\n        const count = state.storage.sql\n          .exec(\"SELECT COUNT(*) as count FROM messages\")\n          .one();\n        expect(count.count).toBe(0); // Fresh instance due to test isolation\n      });\n\n// Trigger alarms immediately without waiting\n      const alarmRan = await runDurableObjectAlarm(stub);\n      expect(alarmRan).toBe(false); // No alarm was scheduled\n    });\n  });\n  ts\n  import {\n    env,\n    runInDurableObject,\n    runDurableObjectAlarm,\n  } from \"cloudflare:test\";\n  import { describe, it, expect } from \"vitest\";\n\ndescribe(\"ChatRoom\", () => {\n    // Each test gets isolated storage automatically\n    it(\"should send and retrieve messages\", async () => {\n      const id = env.CHAT_ROOM.idFromName(\"test-room\");\n      const stub = env.CHAT_ROOM.get(id);\n\n// Call RPC methods directly on the stub\n      await stub.sendMessage(\"user-1\", \"Hello!\");\n      await stub.sendMessage(\"user-2\", \"Hi there!\");\n\nconst messages = await stub.getMessages(10);\n      expect(messages).toHaveLength(2);\n    });\n\nit(\"can access instance internals and trigger alarms\", async () => {\n      const id = env.CHAT_ROOM.idFromName(\"test-room\");\n      const stub = env.CHAT_ROOM.get(id);\n\n// Access storage directly for verification\n      await runInDurableObject(stub, async (instance, state) => {\n        const count = state.storage.sql\n          .exec<{ count: number }>(\"SELECT COUNT(*) as count FROM messages\")\n          .one();\n        expect(count.count).toBe(0); // Fresh instance due to test isolation\n      });\n\n// Trigger alarms immediately without waiting\n      const alarmRan = await runDurableObjectAlarm(stub);\n      expect(alarmRan).toBe(false); // No alarm was scheduled\n    });\n  });\n  ts\nimport { defineWorkersConfig } from \"@cloudflare/vitest-pool-workers/config\";\n\nexport default defineWorkersConfig({\n  test: {\n    poolOptions: {\n      workers: {\n        wrangler: { configPath: \"./wrangler.toml\" },\n      },\n    },\n  },\n});\njsonc\n  {\n    \"migrations\": [\n      // Rename a class\n      { \"tag\": \"v2\", \"renamed_classes\": [{ \"from\": \"OldChatRoom\", \"to\": \"ChatRoom\" }] },\n      // Delete a class (removes all data!)\n      { \"tag\": \"v3\", \"deleted_classes\": [\"DeprecatedRoom\"] }\n    ]\n  }\n  toml\n  [[migrations]]\n  tag = \"v2\"\n\n[[migrations.renamed_classes]]\n    from = \"OldChatRoom\"\n    to = \"ChatRoom\"\n\n[[migrations]]\n  tag = \"v3\"\n  deleted_classes = [ \"DeprecatedRoom\" ]\n  ts\nimport { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n  ErrorThrowingObject: DurableObjectNamespace;\n}\n\nexport default {\n  async fetch(request, env, ctx) {\n    let userId = new URL(request.url).searchParams.get(\"userId\") || \"\";\n\n// Retry behavior can be adjusted to fit your application.\n    let maxAttempts = 3;\n    let baseBackoffMs = 100;\n    let maxBackoffMs = 20000;\n\nlet attempt = 0;\n    while (true) {\n      // Try sending the request\n      try {\n        // Create a Durable Object stub for each attempt, because certain types of\n        // errors will break the Durable Object stub.\n        const doStub = env.ErrorThrowingObject.getByName(userId);\n        const resp = await doStub.fetch(\"http://your-do/\");\n\nreturn Response.json(resp);\n      } catch (e: any) {\n        if (!e.retryable) {\n          // Failure was not a transient internal error, so don't retry.\n          break;\n        }\n      }\n      let backoffMs = Math.min(\n        maxBackoffMs,\n        baseBackoffMs * Math.random() * Math.pow(2, attempt),\n      );\n      attempt += 1;\n      if (attempt >= maxAttempts) {\n        // Reached max attempts, so don't retry.\n        break;\n      }\n      await scheduler.wait(backoffMs);\n    }\n    return new Response(\"server error\", { status: 500 });\n  },\n} satisfies ExportedHandler<Env>;\n\nexport class ErrorThrowingObject extends DurableObject {\n  constructor(state: DurableObjectState, env: Env) {\n    super(state, env);\n\n// Any exceptions that are raised in your constructor will also set the\n    // .remote property to True\n    throw new Error(\"no good\");\n  }\n\nasync fetch(req: Request) {\n    // Generate an uncaught exception\n    // A .remote property will be added to the exception propagated to the caller\n    // and will be set to True\n    throw new Error(\"example error\");\n\n// We never reach this\n    return Response.json({});\n  }\n}\njs\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Durable Object\n  export class WebSocketHibernationServer extends DurableObject {\n    async fetch(request) {\n      // Creates two ends of a WebSocket connection.\n      const webSocketPair = new WebSocketPair();\n      const [client, server] = Object.values(webSocketPair);\n\n// Calling `acceptWebSocket()` connects the WebSocket to the Durable Object, allowing the WebSocket to send and receive messages.\n      // Unlike `ws.accept()`, `state.acceptWebSocket(ws)` allows the Durable Object to be hibernated\n      // When the Durable Object receives a message during Hibernation, it will run the `constructor` to be re-initialized\n      this.ctx.acceptWebSocket(server);\n\nreturn new Response(null, {\n        status: 101,\n        webSocket: client,\n      });\n    }\n\nasync webSocketMessage(ws, message) {\n      // Upon receiving a message from the client, reply with the same message,\n      // but will prefix the message with \"[Durable Object]: \" and return the number of connections.\n      ws.send(\n        `[Durable Object] message: ${message}, connections: ${this.ctx.getWebSockets().length}`,\n      );\n    }\n\nasync webSocketClose(ws, code, reason, wasClean) {\n      // If the client closes the connection, the runtime will invoke the webSocketClose() handler.\n      ws.close(code, \"Durable Object is closing WebSocket\");\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    WEBSOCKET_HIBERNATION_SERVER: DurableObjectNamespace<WebSocketHibernationServer>;\n  }\n\n// Durable Object\n  export class WebSocketHibernationServer extends DurableObject {\n    async fetch(request: Request): Promise<Response> {\n      // Creates two ends of a WebSocket connection.\n      const webSocketPair = new WebSocketPair();\n      const [client, server] = Object.values(webSocketPair);\n\n// Calling `acceptWebSocket()` connects the WebSocket to the Durable Object, allowing the WebSocket to send and receive messages.\n      // Unlike `ws.accept()`, `state.acceptWebSocket(ws)` allows the Durable Object to be hibernated\n      // When the Durable Object receives a message during Hibernation, it will run the `constructor` to be re-initialized\n      this.ctx.acceptWebSocket(server);\n\nreturn new Response(null, {\n        status: 101,\n        webSocket: client,\n      });\n    }\n\nasync webSocketMessage(ws: WebSocket, message: ArrayBuffer | string) {\n      // Upon receiving a message from the client, reply with the same message,\n      // but will prefix the message with \"[Durable Object]: \" and return the number of connections.\n      ws.send(\n        `[Durable Object] message: ${message}, connections: ${this.ctx.getWebSockets().length}`,\n      );\n    }\n\nasync webSocketClose(\n      ws: WebSocket,\n      code: number,\n      reason: string,\n      wasClean: boolean,\n    ) {\n      // If the client closes the connection, the runtime will invoke the webSocketClose() handler.\n      ws.close(code, \"Durable Object is closing WebSocket\");\n    }\n  }\n  python\n  from workers import Response, DurableObject\n  from js import WebSocketPair\n\n# Durable Object\n  class WebSocketHibernationServer(DurableObject):\n      def __init__(self, state, env):\n          super().__init__(state, env)\n          self.ctx = state\n\nasync def fetch(self, request):\n          # Creates two ends of a WebSocket connection.\n          client, server = WebSocketPair.new().object_values()\n\n# Calling `acceptWebSocket()` connects the WebSocket to the Durable Object, allowing the WebSocket to send and receive messages.\n          # Unlike `ws.accept()`, `state.acceptWebSocket(ws)` allows the Durable Object to be hibernated\n          # When the Durable Object receives a message during Hibernation, it will run the `__init__` to be re-initialized\n          self.ctx.acceptWebSocket(server)\n\nreturn Response(\n              None,\n              status=101,\n              web_socket=client\n          )\n\nasync def webSocketMessage(self, ws, message):\n          # Upon receiving a message from the client, reply with the same message,\n          # but will prefix the message with \"[Durable Object]: \" and return the number of connections.\n          ws.send(\n              f\"[Durable Object] message: {message}, connections: {len(self.ctx.get_websockets())}\"\n          )\n\nasync def webSocketClose(self, ws, code, reason, was_clean):\n          # If the client closes the connection, the runtime will invoke the webSocketClose() handler.\n          ws.close(code, \"Durable Object is closing WebSocket\")\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"websocket-hibernation-server\",\n    \"durable_objects\": {\n      \"bindings\": [\n        {\n          \"name\": \"WEBSOCKET_HIBERNATION_SERVER\",\n          \"class_name\": \"WebSocketHibernationServer\"\n        }\n      ]\n    },\n    \"migrations\": [\n      {\n        \"tag\": \"v1\",\n        \"new_sqlite_classes\": [\n          \"WebSocketHibernationServer\"\n        ]\n      }\n    ]\n  }\n  toml\n  name = \"websocket-hibernation-server\"\n\n[[durable_objects.bindings]]\n  name = \"WEBSOCKET_HIBERNATION_SERVER\"\n  class_name = \"WebSocketHibernationServer\"\n\n[[migrations]]\n  tag = \"v1\"\n  new_sqlite_classes = [\"WebSocketHibernationServer\"]\n  js\n  // Worker\n  export default {\n    async fetch(request, env, ctx) {\n      if (request.method === \"GET\" && request.url.endsWith(\"/websocket\")) {\n        // Expect to receive a WebSocket Upgrade request.\n        // If there is one, accept the request and return a WebSocket Response.\n        const upgradeHeader = request.headers.get(\"Upgrade\");\n        if (!upgradeHeader || upgradeHeader !== \"websocket\") {\n          return new Response(null, {\n            status: 426,\n            statusText: \"Durable Object expected Upgrade: websocket\",\n            headers: {\n              \"Content-Type\": \"text/plain\",\n            },\n          });\n        }\n\n// This example will refer to a single Durable Object instance, since the name \"foo\" is\n        // hardcoded\n        let stub = env.WEBSOCKET_SERVER.getByName(\"foo\");\n\n// The Durable Object's fetch handler will accept the server side connection and return\n        // the client\n        return stub.fetch(request);\n      }\n\nreturn new Response(null, {\n        status: 400,\n        statusText: \"Bad Request\",\n        headers: {\n          \"Content-Type\": \"text/plain\",\n        },\n      });\n    },\n  };\n  ts\n  // Worker\n  export default {\n    async fetch(request, env, ctx): Promise<Response> {\n      if (request.method === \"GET\" && request.url.endsWith(\"/websocket\")) {\n        // Expect to receive a WebSocket Upgrade request.\n        // If there is one, accept the request and return a WebSocket Response.\n        const upgradeHeader = request.headers.get(\"Upgrade\");\n        if (!upgradeHeader || upgradeHeader !== \"websocket\") {\n          return new Response(null, {\n            status: 426,\n            statusText: \"Durable Object expected Upgrade: websocket\",\n            headers: {\n              \"Content-Type\": \"text/plain\",\n            },\n          });\n        }\n\n// This example will refer to a single Durable Object instance, since the name \"foo\" is\n        // hardcoded\n        let stub = env.WEBSOCKET_SERVER.getByName(\"foo\");\n\n// The Durable Object's fetch handler will accept the server side connection and return\n        // the client\n        return stub.fetch(request);\n      }\n\nreturn new Response(null, {\n        status: 400,\n        statusText: \"Bad Request\",\n        headers: {\n          \"Content-Type\": \"text/plain\",\n        },\n      });\n    },\n  } satisfies ExportedHandler<Env>;\n  python\n  from workers import Response, WorkerEntrypoint\n\n# Worker\n  class Default(WorkerEntrypoint):\n      async def fetch(self, request):\n          if request.method == \"GET\" and request.url.endswith(\"/websocket\"):\n              # Expect to receive a WebSocket Upgrade request.\n              # If there is one, accept the request and return a WebSocket Response.\n              upgrade_header = request.headers.get(\"Upgrade\")\n              if not upgrade_header or upgrade_header != \"websocket\":\n                  return Response(\n                      None,\n                      status=426,\n                      status_text=\"Durable Object expected Upgrade: websocket\",\n                      headers={\n                          \"Content-Type\": \"text/plain\",\n                      },\n                  )\n\n# This example will refer to a single Durable Object instance, since the name \"foo\" is\n              # hardcoded\n              stub = self.env.WEBSOCKET_SERVER.getByName(\"foo\")\n\n# The Durable Object's fetch handler will accept the server side connection and return\n              # the client\n              return await stub.fetch(request)\n\nreturn Response(\n              None,\n              status=400,\n              status_text=\"Bad Request\",\n              headers={\n                  \"Content-Type\": \"text/plain\",\n              },\n          )\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Durable Object\n  export class WebSocketServer extends DurableObject {\n    currentlyConnectedWebSockets;\n\nconstructor(ctx, env) {\n      super(ctx, env);\n      this.currentlyConnectedWebSockets = 0;\n    }\n\nasync fetch(request) {\n      // Creates two ends of a WebSocket connection.\n      const webSocketPair = new WebSocketPair();\n      const [client, server] = Object.values(webSocketPair);\n\n// Calling `accept()` connects the WebSocket to this Durable Object\n      server.accept();\n      this.currentlyConnectedWebSockets += 1;\n\n// Upon receiving a message from the client, the server replies with the same message,\n      // and the total number of connections with the \"[Durable Object]: \" prefix\n      server.addEventListener(\"message\", (event) => {\n        server.send(\n          `[Durable Object] currentlyConnectedWebSockets: ${this.currentlyConnectedWebSockets}`,\n        );\n      });\n\n// If the client closes the connection, the runtime will close the connection too.\n      server.addEventListener(\"close\", (cls) => {\n        this.currentlyConnectedWebSockets -= 1;\n        server.close(cls.code, \"Durable Object is closing WebSocket\");\n      });\n\nreturn new Response(null, {\n        status: 101,\n        webSocket: client,\n      });\n    }\n  }\n  ts\n  // Durable Object\n  export class WebSocketServer extends DurableObject {\n    currentlyConnectedWebSockets: number;\n\nconstructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n      this.currentlyConnectedWebSockets = 0;\n    }\n\nasync fetch(request: Request): Promise<Response> {\n      // Creates two ends of a WebSocket connection.\n      const webSocketPair = new WebSocketPair();\n      const [client, server] = Object.values(webSocketPair);\n\n// Calling `accept()` connects the WebSocket to this Durable Object\n      server.accept();\n      this.currentlyConnectedWebSockets += 1;\n\n// Upon receiving a message from the client, the server replies with the same message,\n      // and the total number of connections with the \"[Durable Object]: \" prefix\n      server.addEventListener(\"message\", (event: MessageEvent) => {\n        server.send(\n          `[Durable Object] currentlyConnectedWebSockets: ${this.currentlyConnectedWebSockets}`,\n        );\n      });\n\n// If the client closes the connection, the runtime will close the connection too.\n      server.addEventListener(\"close\", (cls: CloseEvent) => {\n        this.currentlyConnectedWebSockets -= 1;\n        server.close(cls.code, \"Durable Object is closing WebSocket\");\n      });\n\nreturn new Response(null, {\n        status: 101,\n        webSocket: client,\n      });\n    }\n  }\n  python\n  from workers import Response, DurableObject\n  from js import WebSocketPair\n  from pyodide.ffi import create_proxy\n\n# Durable Object\n  class WebSocketServer(DurableObject):\n      def __init__(self, ctx, env):\n          super().__init__(ctx, env)\n          self.currently_connected_websockets = 0\n\nasync def fetch(self, request):\n          # Creates two ends of a WebSocket connection.\n          client, server = WebSocketPair.new().object_values()\n\n# Calling `accept()` connects the WebSocket to this Durable Object\n          server.accept()\n          self.currently_connected_websockets += 1\n\n# Upon receiving a message from the client, the server replies with the same message,\n          # and the total number of connections with the \"[Durable Object]: \" prefix\n          def on_message(event):\n              server.send(\n                  f\"[Durable Object] currentlyConnectedWebSockets: {self.currently_connected_websockets}\"\n              )\n\nserver.addEventListener(\"message\", create_proxy(on_message))\n\n# If the client closes the connection, the runtime will close the connection too.\n          def on_close(event):\n              self.currently_connected_websockets -= 1\n              server.close(event.code, \"Durable Object is closing WebSocket\")\n\nserver.addEventListener(\"close\", create_proxy(on_close))\n\nreturn Response(\n              None,\n              status=101,\n              web_socket=client,\n          )\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"websocket-server\",\n    \"durable_objects\": {\n      \"bindings\": [\n        {\n          \"name\": \"WEBSOCKET_SERVER\",\n          \"class_name\": \"WebSocketServer\"\n        }\n      ]\n    },\n    \"migrations\": [\n      {\n        \"tag\": \"v1\",\n        \"new_sqlite_classes\": [\n          \"WebSocketServer\"\n        ]\n      }\n    ]\n  }\n  toml\n  name = \"websocket-server\"\n\n[[durable_objects.bindings]]\n  name = \"WEBSOCKET_SERVER\"\n  class_name = \"WebSocketServer\"\n\n[[migrations]]\n  tag = \"v1\"\n  new_sqlite_classes = [\"WebSocketServer\"]\n  js\nconst stub = env.MY_DURABLE_OBJECT.getByName(\"foo\");\n// Now the request is sent to the remote Durable Object.\nconst rpcResponse = await stub.sayHello();\njs\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Worker\n  export default {\n    async fetch(request, env) {\n      return await env.BATCHER.getByName(\"foo\").fetch(request);\n    },\n  };\n\n// Durable Object\n  export class Batcher extends DurableObject {\n    constructor(ctx, env) {\n      super(ctx, env);\n      this.storage = ctx.storage;\n      this.ctx.blockConcurrencyWhile(async () => {\n        let vals = await this.storage.list({ reverse: true, limit: 1 });\n        this.count = vals.size == 0 ? 0 : parseInt(vals.keys().next().value);\n      });\n    }\n\nasync fetch(request) {\n      this.count++;\n\n// If there is no alarm currently set, set one for 10 seconds from now\n      // Any further POSTs in the next 10 seconds will be part of this batch.\n      let currentAlarm = await this.storage.getAlarm();\n      if (currentAlarm == null) {\n        this.storage.setAlarm(Date.now() + 1000 * 10);\n      }\n\n// Add the request to the batch.\n      await this.storage.put(this.count, await request.text());\n      return new Response(JSON.stringify({ queued: this.count }), {\n        headers: {\n          \"content-type\": \"application/json;charset=UTF-8\",\n        },\n      });\n    }\n\nasync alarm() {\n      let vals = await this.storage.list();\n      await fetch(\"http://example.com/some-upstream-service\", {\n        method: \"POST\",\n        body: Array.from(vals.values()),\n      });\n      await this.storage.deleteAll();\n      this.count = 0;\n    }\n  }\n  py\n  from workers import DurableObject, Response, WorkerEntrypoint, fetch\n  import time\n\n# Worker\n  class Default(WorkerEntrypoint):\n    async def fetch(self, request):\n      stub = self.env.BATCHER.getByName(\"foo\")\n      return await stub.fetch(request)\n\n# Durable Object\n  class Batcher(DurableObject):\n    def __init__(self, ctx, env):\n      super().__init__(ctx, env)\n      self.storage = ctx.storage\n\n@self.ctx.blockConcurrencyWhile\n      async def initialize():\n        vals = await self.storage.list(reverse=True, limit=1)\n        self.count = 0\n        if len(vals) > 0:\n            self.count = int(vals.keys().next().value)\n\nasync def fetch(self, request):\n      self.count += 1\n\n# If there is no alarm currently set, set one for 10 seconds from now\n      # Any further POSTs in the next 10 seconds will be part of this batch.\n      current_alarm = await self.storage.getAlarm()\n      if current_alarm is None:\n        self.storage.setAlarm(int(time.time() * 1000) + 1000 * 10)\n\n# Add the request to the batch.\n      await self.storage.put(self.count, await request.text())\n      return Response.json(\n        {\"queued\": self.count}\n      )\n\nasync def alarm(self):\n      vals = await self.storage.list()\n      await fetch(\n        \"http://example.com/some-upstream-service\",\n        method=\"POST\",\n        body=list(vals.values())\n      )\n      await self.storage.deleteAll()\n      self.count = 0\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"durable-object-alarm\",\n    \"main\": \"src/index.ts\",\n    \"durable_objects\": {\n      \"bindings\": [\n        {\n          \"name\": \"BATCHER\",\n          \"class_name\": \"Batcher\"\n        }\n      ]\n    },\n    \"migrations\": [\n      {\n        \"tag\": \"v1\",\n        \"new_sqlite_classes\": [\n          \"Batcher\"\n        ]\n      }\n    ]\n  }\n  toml\n  name = \"durable-object-alarm\"\n  main = \"src/index.ts\"\n\n[[durable_objects.bindings]]\n  name = \"BATCHER\"\n  class_name = \"Batcher\"\n\n[[migrations]]\n  tag = \"v1\"\n  new_sqlite_classes = [\"Batcher\"]\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Worker\n  export default {\n    async fetch(request, env) {\n      let url = new URL(request.url);\n      let name = url.searchParams.get(\"name\");\n      if (!name) {\n        return new Response(\n          \"Select a Durable Object to contact by using\" +\n            \" the `name` URL query string parameter, for example, ?name=A\",\n        );\n      }\n\n// A stub is a client Object used to send messages to the Durable Object.\n      let stub = env.COUNTERS.getByName(name);\n\n// Send a request to the Durable Object using RPC methods, then await its response.\n      let count = null;\n      switch (url.pathname) {\n        case \"/increment\":\n          count = await stub.increment();\n          break;\n        case \"/decrement\":\n          count = await stub.decrement();\n          break;\n        case \"/\":\n          // Serves the current value.\n          count = await stub.getCounterValue();\n          break;\n        default:\n          return new Response(\"Not found\", { status: 404 });\n      }\n\nreturn new Response(`Durable Object '${name}' count: ${count}`);\n    },\n  };\n\n// Durable Object\n  export class Counter extends DurableObject {\n    async getCounterValue() {\n      let value = (await this.ctx.storage.get(\"value\")) || 0;\n      return value;\n    }\n\nasync increment(amount = 1) {\n      let value = (await this.ctx.storage.get(\"value\")) || 0;\n      value += amount;\n      // You do not have to worry about a concurrent request having modified the value in storage.\n      // \"input gates\" will automatically protect against unwanted concurrency.\n      // Read-modify-write is safe.\n      await this.ctx.storage.put(\"value\", value);\n      return value;\n    }\n\nasync decrement(amount = 1) {\n      let value = (await this.ctx.storage.get(\"value\")) || 0;\n      value -= amount;\n      await this.ctx.storage.put(\"value\", value);\n      return value;\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    COUNTERS: DurableObjectNamespace<Counter>;\n  }\n\n// Worker\n  export default {\n    async fetch(request, env) {\n      let url = new URL(request.url);\n      let name = url.searchParams.get(\"name\");\n      if (!name) {\n        return new Response(\n          \"Select a Durable Object to contact by using\" +\n            \" the `name` URL query string parameter, for example, ?name=A\",\n        );\n      }\n\n// A stub is a client Object used to send messages to the Durable Object.\n      let stub = env.COUNTERS.get(name);\n\nlet count = null;\n      switch (url.pathname) {\n        case \"/increment\":\n          count = await stub.increment();\n          break;\n        case \"/decrement\":\n          count = await stub.decrement();\n          break;\n        case \"/\":\n          // Serves the current value.\n          count = await stub.getCounterValue();\n          break;\n        default:\n          return new Response(\"Not found\", { status: 404 });\n      }\n\nreturn new Response(`Durable Object '${name}' count: ${count}`);\n    },\n  } satisfies ExportedHandler<Env>;\n\n// Durable Object\n  export class Counter extends DurableObject {\n    async getCounterValue() {\n      let value = (await this.ctx.storage.get(\"value\")) || 0;\n      return value;\n    }\n\nasync increment(amount = 1) {\n      let value: number = (await this.ctx.storage.get(\"value\")) || 0;\n      value += amount;\n      // You do not have to worry about a concurrent request having modified the value in storage.\n      // \"input gates\" will automatically protect against unwanted concurrency.\n      // Read-modify-write is safe.\n      await this.ctx.storage.put(\"value\", value);\n      return value;\n    }\n\nasync decrement(amount = 1) {\n      let value: number = (await this.ctx.storage.get(\"value\")) || 0;\n      value -= amount;\n      await this.ctx.storage.put(\"value\", value);\n      return value;\n    }\n  }\n  py\n  from workers import DurableObject, Response, WorkerEntrypoint\n  from urllib.parse import urlparse, parse_qs\n\n# Worker\n  class Default(WorkerEntrypoint):\n    async def fetch(self, request):\n      parsed_url = urlparse(request.url)\n      query_params = parse_qs(parsed_url.query)\n      name = query_params.get('name', [None])[0]\n\nif not name:\n        return Response(\n          \"Select a Durable Object to contact by using\"\n          + \" the `name` URL query string parameter, for example, ?name=A\"\n        )\n\n# A stub is a client Object used to send messages to the Durable Object.\n      stub = self.env.COUNTERS.getByName(name)\n\n# Send a request to the Durable Object using RPC methods, then await its response.\n      count = None\n\nif parsed_url.path == \"/increment\":\n        count = await stub.increment()\n      elif parsed_url.path == \"/decrement\":\n        count = await stub.decrement()\n      elif parsed_url.path == \"\" or parsed_url.path == \"/\":\n        # Serves the current value.\n        count = await stub.getCounterValue()\n      else:\n        return Response(\"Not found\", status=404)\n\nreturn Response(f\"Durable Object '{name}' count: {count}\")\n\n# Durable Object\n  class Counter(DurableObject):\n    def __init__(self, ctx, env):\n      super().__init__(ctx, env)\n\nasync def getCounterValue(self):\n      value = await self.ctx.storage.get(\"value\")\n      return value if value is not None else 0\n\nasync def increment(self, amount=1):\n      value = await self.ctx.storage.get(\"value\")\n      value = (value if value is not None else 0) + amount\n      # You do not have to worry about a concurrent request having modified the value in storage.\n      # \"input gates\" will automatically protect against unwanted concurrency.\n      # Read-modify-write is safe.\n      await self.ctx.storage.put(\"value\", value)\n      return value\n\nasync def decrement(self, amount=1):\n      value = await self.ctx.storage.get(\"value\")\n      value = (value if value is not None else 0) - amount\n      await self.ctx.storage.put(\"value\", value)\n      return value\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"my-counter\",\n    \"main\": \"src/index.ts\",\n    \"durable_objects\": {\n      \"bindings\": [\n        {\n          \"name\": \"COUNTERS\",\n          \"class_name\": \"Counter\"\n        }\n      ]\n    },\n    \"migrations\": [\n      {\n        \"tag\": \"v1\",\n        \"new_sqlite_classes\": [\n          \"Counter\"\n        ]\n      }\n    ]\n  }\n  toml\n  name = \"my-counter\"\n  main = \"src/index.ts\"\n\n[[durable_objects.bindings]]\n  name = \"COUNTERS\"\n  class_name = \"Counter\"\n\n[[migrations]]\n  tag = \"v1\"\n  new_sqlite_classes = [\"Counter\"]\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Worker\n  export default {\n    async fetch(request, env, _ctx) {\n      // Determine the IP address of the client\n      const ip = request.headers.get(\"CF-Connecting-IP\");\n      if (ip === null) {\n        return new Response(\"Could not determine client IP\", { status: 400 });\n      }\n\ntry {\n        const stub = env.RATE_LIMITER.getByName(ip);\n        const milliseconds_to_next_request =\n          await stub.getMillisecondsToNextRequest();\n        if (milliseconds_to_next_request > 0) {\n          // Alternatively one could sleep for the necessary length of time\n          return new Response(\"Rate limit exceeded\", { status: 429 });\n        }\n      } catch (error) {\n        return new Response(\"Could not connect to rate limiter\", { status: 502 });\n      }\n\n// TODO: Implement me\n      return new Response(\"Call some upstream resource...\");\n    },\n  };\n\n// Durable Object\n  export class RateLimiter extends DurableObject {\n    static milliseconds_per_request = 1;\n    static milliseconds_for_updates = 5000;\n    static capacity = 10000;\n\nconstructor(ctx, env) {\n      super(ctx, env);\n      this.tokens = RateLimiter.capacity;\n    }\n\nasync getMillisecondsToNextRequest() {\n      this.checkAndSetAlarm();\n\nlet milliseconds_to_next_request = RateLimiter.milliseconds_per_request;\n      if (this.tokens > 0) {\n        this.tokens -= 1;\n        milliseconds_to_next_request = 0;\n      }\n\nreturn milliseconds_to_next_request;\n    }\n\nasync checkAndSetAlarm() {\n      let currentAlarm = await this.ctx.storage.getAlarm();\n      if (currentAlarm == null) {\n        this.ctx.storage.setAlarm(\n          Date.now() +\n            RateLimiter.milliseconds_for_updates *\n              RateLimiter.milliseconds_per_request,\n        );\n      }\n    }\n\nasync alarm() {\n      if (this.tokens < RateLimiter.capacity) {\n        this.tokens = Math.min(\n          RateLimiter.capacity,\n          this.tokens + RateLimiter.milliseconds_for_updates,\n        );\n        this.checkAndSetAlarm();\n      }\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    RATE_LIMITER: DurableObjectNamespace<RateLimiter>;\n  }\n\n// Worker\n  export default {\n    async fetch(request, env, _ctx): Promise<Response> {\n      // Determine the IP address of the client\n      const ip = request.headers.get(\"CF-Connecting-IP\");\n      if (ip === null) {\n        return new Response(\"Could not determine client IP\", { status: 400 });\n      }\n\ntry {\n        const stub = env.RATE_LIMITER.getByName(ip);\n        const milliseconds_to_next_request =\n          await stub.getMillisecondsToNextRequest();\n        if (milliseconds_to_next_request > 0) {\n          // Alternatively one could sleep for the necessary length of time\n          return new Response(\"Rate limit exceeded\", { status: 429 });\n        }\n      } catch (error) {\n        return new Response(\"Could not connect to rate limiter\", { status: 502 });\n      }\n\n// TODO: Implement me\n      return new Response(\"Call some upstream resource...\");\n    },\n  } satisfies ExportedHandler<Env>;\n\n// Durable Object\n  export class RateLimiter extends DurableObject {\n    static readonly milliseconds_per_request = 1;\n    static readonly milliseconds_for_updates = 5000;\n    static readonly capacity = 10000;\n\nconstructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n      this.tokens = RateLimiter.capacity;\n    }\n\nasync getMillisecondsToNextRequest(): Promise<number> {\n      this.checkAndSetAlarm();\n\nlet milliseconds_to_next_request = RateLimiter.milliseconds_per_request;\n      if (this.tokens > 0) {\n        this.tokens -= 1;\n        milliseconds_to_next_request = 0;\n      }\n\nreturn milliseconds_to_next_request;\n    }\n\nprivate async checkAndSetAlarm() {\n      let currentAlarm = await this.ctx.storage.getAlarm();\n      if (currentAlarm == null) {\n        this.ctx.storage.setAlarm(\n          Date.now() +\n            RateLimiter.milliseconds_for_updates *\n              RateLimiter.milliseconds_per_request,\n        );\n      }\n    }\n\nasync alarm() {\n      if (this.tokens < RateLimiter.capacity) {\n        this.tokens = Math.min(\n          RateLimiter.capacity,\n          this.tokens + RateLimiter.milliseconds_for_updates,\n        );\n        this.checkAndSetAlarm();\n      }\n    }\n  }\n  py\n  from workers import DurableObject, Response, WorkerEntrypoint\n  import time\n\n# Worker\n  class Default(WorkerEntrypoint):\n    async def fetch(self, request):\n      # Determine the IP address of the client\n      ip = request.headers.get(\"CF-Connecting-IP\")\n      if ip is None:\n        return Response(\"Could not determine client IP\", status=400)\n\ntry:\n        stub = self.env.RATE_LIMITER.getByName(ip)\n        milliseconds_to_next_request = await stub.getMillisecondsToNextRequest()\n        if milliseconds_to_next_request > 0:\n          # Alternatively one could sleep for the necessary length of time\n          return Response(\"Rate limit exceeded\", status=429)\n      except Exception as error:\n        return Response(\"Could not connect to rate limiter\", status=502)\n\n# TODO: Implement me\n      return Response(\"Call some upstream resource...\")\n\n# Durable Object\n  class RateLimiter(DurableObject):\n    milliseconds_per_request = 1\n    milliseconds_for_updates = 5000\n    capacity = 10000\n\ndef __init__(self, ctx, env):\n      super().__init__(ctx, env)\n      self.tokens = RateLimiter.capacity\n\nasync def getMillisecondsToNextRequest(self):\n      await self.checkAndSetAlarm()\n\nmilliseconds_to_next_request = RateLimiter.milliseconds_per_request\n      if self.tokens > 0:\n        self.tokens -= 1\n        milliseconds_to_next_request = 0\n\nreturn milliseconds_to_next_request\n\nasync def checkAndSetAlarm(self):\n      current_alarm = await self.ctx.storage.getAlarm()\n      if current_alarm is None:\n        self.ctx.storage.setAlarm(\n          int(time.time() * 1000)\n          + RateLimiter.milliseconds_for_updates\n          * RateLimiter.milliseconds_per_request\n        )\n\nasync def alarm(self):\n      if self.tokens < RateLimiter.capacity:\n        self.tokens = min(\n          RateLimiter.capacity,\n          self.tokens + RateLimiter.milliseconds_for_updates,\n        )\n        await self.checkAndSetAlarm()\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Durable Object\n  export class RateLimiter extends DurableObject {\n    static milliseconds_per_request = 1;\n    static milliseconds_for_grace_period = 5000;\n\nconstructor(ctx, env) {\n      super(ctx, env);\n      this.nextAllowedTime = 0;\n    }\n\nasync getMillisecondsToNextRequest() {\n      const now = Date.now();\n\nthis.nextAllowedTime = Math.max(now, this.nextAllowedTime);\n      this.nextAllowedTime += RateLimiter.milliseconds_per_request;\n\nconst value = Math.max(\n        0,\n        this.nextAllowedTime - now - RateLimiter.milliseconds_for_grace_period,\n      );\n      return value;\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Durable Object\n  export class RateLimiter extends DurableObject {\n    static milliseconds_per_request = 1;\n    static milliseconds_for_grace_period = 5000;\n\nnextAllowedTime: number;\n\nconstructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n      this.nextAllowedTime = 0;\n    }\n\nasync getMillisecondsToNextRequest(): Promise<number> {\n      const now = Date.now();\n\nthis.nextAllowedTime = Math.max(now, this.nextAllowedTime);\n      this.nextAllowedTime += RateLimiter.milliseconds_per_request;\n\nconst value = Math.max(\n        0,\n        this.nextAllowedTime - now - RateLimiter.milliseconds_for_grace_period,\n      );\n      return value;\n    }\n  }\n  py\n  from workers import DurableObject\n  import time\n\n# Durable Object\n  class RateLimiter(DurableObject):\n    milliseconds_per_request = 1\n    milliseconds_for_grace_period = 5000\n\ndef __init__(self, ctx, env):\n      super().__init__(ctx, env)\n      self.nextAllowedTime = 0\n\nasync def getMillisecondsToNextRequest(self):\n      now = int(time.time() * 1000)\n\nself.nextAllowedTime = max(now, self.nextAllowedTime)\n      self.nextAllowedTime += RateLimiter.milliseconds_per_request\n\nvalue = max(\n        0,\n        self.nextAllowedTime - now - RateLimiter.milliseconds_for_grace_period,\n      )\n      return value\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"my-counter\",\n    \"main\": \"src/index.ts\",\n    \"durable_objects\": {\n      \"bindings\": [\n        {\n          \"name\": \"RATE_LIMITER\",\n          \"class_name\": \"RateLimiter\"\n        }\n      ]\n    },\n    \"migrations\": [\n      {\n        \"tag\": \"v1\",\n        \"new_sqlite_classes\": [\n          \"RateLimiter\"\n        ]\n      }\n    ]\n  }\n  toml\n  name = \"my-counter\"\n  main = \"src/index.ts\"\n\n[[durable_objects.bindings]]\n  name = \"RATE_LIMITER\"\n  class_name = \"RateLimiter\"\n\n[[migrations]]\n  tag = \"v1\"\n  new_sqlite_classes = [\"RateLimiter\"]\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Worker\n  export default {\n    async fetch(request, env) {\n      return await handleRequest(request, env);\n    },\n  };\n\nasync function handleRequest(request, env) {\n    let stub = env.LOCATION.getByName(\"A\");\n    // Forward the request to the remote Durable Object.\n    let resp = await stub.fetch(request);\n    // Return the response to the client.\n    return new Response(await resp.text());\n  }\n\n// Durable Object\n  export class Location extends DurableObject {\n    constructor(state, env) {\n      super(state, env);\n      // Upon construction, you do not have a location to provide.\n      // This value will be updated as people access the Durable Object.\n      // When the Durable Object is evicted from memory, this will be reset.\n      this.location = null;\n    }\n\n// Handle HTTP requests from clients.\n    async fetch(request) {\n      let response = null;\n\nif (this.location == null) {\n        response = new String(`\n  This is the first request, you called the constructor, so this.location was null.\n  You will set this.location to be your city: (${request.cf.city}). Try reloading the page.`);\n      } else {\n        response = new String(`\n  The Durable Object was already loaded and running because it recently handled a request.\n\nPrevious Location: ${this.location}\n  New Location: ${request.cf.city}`);\n      }\n\n// You set the new location to be the new city.\n      this.location = request.cf.city;\n      console.log(response);\n      return new Response(response);\n    }\n  }\n  py\n  from workers import DurableObject, Response, WorkerEntrypoint\n\n# Worker\n  class Default(WorkerEntrypoint):\n    async def fetch(self, request):\n      return await handle_request(request, self.env)\n\nasync def handle_request(request, env):\n    stub = env.LOCATION.getByName(\"A\")\n    # Forward the request to the remote Durable Object.\n    resp = await stub.fetch(request)\n    # Return the response to the client.\n    return Response(await resp.text())\n\n# Durable Object\n  class Location(DurableObject):\n    def __init__(self, ctx, env):\n      super().__init__(ctx, env)\n      # Upon construction, you do not have a location to provide.\n      # This value will be updated as people access the Durable Object.\n      # When the Durable Object is evicted from memory, this will be reset.\n      self.location = None\n\n# Handle HTTP requests from clients.\n    async def fetch(self, request):\n      response = None\n\nif self.location is None:\n        response = f\"\"\"\n  This is the first request, you called the constructor, so this.location was null.\n  You will set this.location to be your city: ({request.js_object.cf.city}). Try reloading the page.\"\"\"\n      else:\n        response = f\"\"\"\n  The Durable Object was already loaded and running because it recently handled a request.\n\nPrevious Location: {self.location}\n  New Location: {request.js_object.cf.city}\"\"\"\n\n# You set the new location to be the new city.\n      self.location = request.js_object.cf.city\n      print(response)\n      return Response(response)\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"durable-object-in-memory-state\",\n    \"main\": \"src/index.ts\",\n    \"durable_objects\": {\n      \"bindings\": [\n        {\n          \"name\": \"LOCATION\",\n          \"class_name\": \"Location\"\n        }\n      ]\n    },\n    \"migrations\": [\n      {\n        \"tag\": \"v1\",\n        \"new_sqlite_classes\": [\n          \"Location\"\n        ]\n      }\n    ]\n  }\n  toml\n  name = \"durable-object-in-memory-state\"\n  main = \"src/index.ts\"\n\n[[durable_objects.bindings]]\n  name = \"LOCATION\"\n  class_name = \"Location\"\n\n[[migrations]]\n  tag = \"v1\"\n  new_sqlite_classes = [\"Location\"]\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Durable Object\n  export class MyDurableObject extends DurableObject {\n    // Time To Live (TTL) in milliseconds\n    timeToLiveMs = 1000;\n\nconstructor(ctx, env) {\n      super(ctx, env);\n    }\n\nasync fetch(_request) {\n      // Extend the TTL immediately following every fetch request to a Durable Object.\n      await this.ctx.storage.setAlarm(Date.now() + this.timeToLiveMs);\n      ...\n     }\n\nasync alarm() {\n      await this.ctx.storage.deleteAll();\n    }\n  }\n\n// Worker\n  export default {\n    async fetch(request, env) {\n      const stub = env.MY_DURABLE_OBJECT.getByName(\"foo\");\n      return await stub.fetch(request);\n    },\n  };\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    MY_DURABLE_OBJECT: DurableObjectNamespace<MyDurableObject>;\n  }\n\n// Durable Object\n  export class MyDurableObject extends DurableObject {\n    // Time To Live (TTL) in milliseconds\n    timeToLiveMs = 1000;\n\nconstructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n    }\n\nasync fetch(_request: Request) {\n      // Extend the TTL immediately following every fetch request to a Durable Object.\n      await this.ctx.storage.setAlarm(Date.now() + this.timeToLiveMs);\n      ...\n     }\n\nasync alarm() {\n      await this.ctx.storage.deleteAll();\n    }\n  }\n\n// Worker\n  export default {\n    async fetch(request, env) {\n      const stub = env.MY_DURABLE_OBJECT.getByName(\"foo\");\n      return await stub.fetch(request);\n    },\n  } satisfies ExportedHandler<Env>;\n  py\n  from workers import DurableObject, Response, WorkerEntrypoint\n  import time\n\n# Durable Object\n  class MyDurableObject(DurableObject):\n    # Time To Live (TTL) in milliseconds\n    timeToLiveMs = 1000\n\ndef __init__(self, ctx, env):\n      super().__init__(ctx, env)\n\nasync def fetch(self, _request):\n      # Extend the TTL immediately following every fetch request to a Durable Object.\n      await self.ctx.storage.setAlarm(int(time.time() * 1000) + self.timeToLiveMs)\n      ...\n\nasync def alarm(self):\n      await self.ctx.storage.deleteAll()\n\n# Worker\n  class Default(WorkerEntrypoint):\n    async def fetch(self, request):\n      stub = self.env.MY_DURABLE_OBJECT.getByName(\"foo\")\n      return await stub.fetch(request)\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"durable-object-ttl\",\n    \"main\": \"src/index.ts\",\n    \"durable_objects\": {\n      \"bindings\": [\n        {\n          \"name\": \"MY_DURABLE_OBJECT\",\n          \"class_name\": \"MyDurableObject\"\n        }\n      ]\n    },\n    \"migrations\": [\n      {\n        \"tag\": \"v1\",\n        \"new_sqlite_classes\": [\n          \"MyDurableObject\"\n        ]\n      }\n    ]\n  }\n  toml\n  name = \"durable-object-ttl\"\n  main = \"src/index.ts\"\n\n[[durable_objects.bindings]]\n  name = \"MY_DURABLE_OBJECT\"\n  class_name = \"MyDurableObject\"\n\n[[migrations]]\n  tag = \"v1\"\n  new_sqlite_classes = [\"MyDurableObject\"]\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Send incremented counter value every second\n  async function* dataSource(signal) {\n    let counter = 0;\n    while (!signal.aborted) {\n      yield counter++;\n      await new Promise((resolve) => setTimeout(resolve, 1_000));\n    }\n\nconsole.log(\"Data source cancelled\");\n  }\n\nexport class MyDurableObject extends DurableObject {\n    async fetch(request) {\n      const abortController = new AbortController();\n\nconst stream = new ReadableStream({\n        async start(controller) {\n          if (request.signal.aborted) {\n            controller.close();\n            abortController.abort();\n            return;\n          }\n\nfor await (const value of dataSource(abortController.signal)) {\n            controller.enqueue(new TextEncoder().encode(String(value)));\n          }\n        },\n        cancel() {\n          console.log(\"Stream cancelled\");\n          abortController.abort();\n        },\n      });\n\nconst headers = new Headers({\n        \"Content-Type\": \"application/octet-stream\",\n      });\n\nreturn new Response(stream, { headers });\n    }\n  }\n\nexport default {\n    async fetch(request, env, ctx) {\n      const stub = env.MY_DURABLE_OBJECT.getByName(\"foo\");\n      const response = await stub.fetch(request, { ...request });\n      if (!response.ok || !response.body) {\n        return new Response(\"Invalid response\", { status: 500 });\n      }\n\nconst reader = response.body\n        .pipeThrough(new TextDecoderStream())\n        .getReader();\n\nlet data = [];\n      let i = 0;\n      while (true) {\n        // Cancel the stream after 5 messages\n        if (i > 5) {\n          reader.cancel();\n          break;\n        }\n        const { value, done } = await reader.read();\n\nif (value) {\n          console.log(`Got value ${value}`);\n          data = [...data, value];\n        }\n\nif (done) {\n          break;\n        }\n        i++;\n      }\n\nreturn Response.json(data);\n    },\n  };\n  ts\n  import { DurableObject } from 'cloudflare:workers';\n\n// Send incremented counter value every second\n  async function* dataSource(signal: AbortSignal) {\n      let counter = 0;\n      while (!signal.aborted) {\n          yield counter++;\n          await new Promise((resolve) => setTimeout(resolve, 1_000));\n      }\n\nconsole.log('Data source cancelled');\n  }\n\nexport class MyDurableObject extends DurableObject<Env> {\n      async fetch(request: Request): Promise<Response> {\n          const abortController = new AbortController();\n\nconst stream = new ReadableStream({\n              async start(controller) {\n                  if (request.signal.aborted) {\n                      controller.close();\n                      abortController.abort();\n                      return;\n                  }\n\nfor await (const value of dataSource(abortController.signal)) {\n                      controller.enqueue(new TextEncoder().encode(String(value)));\n                  }\n              },\n              cancel() {\n                  console.log('Stream cancelled');\n                  abortController.abort();\n              },\n          });\n\nconst headers = new Headers({\n              'Content-Type': 'application/octet-stream',\n          });\n\nreturn new Response(stream, { headers });\n      }\n\nexport default {\n      async fetch(request, env, ctx): Promise<Response> {\n          const stub = env.MY_DURABLE_OBJECT.getByName(\"foo\");\n          const response = await stub.fetch(request, { ...request });\n          if (!response.ok || !response.body) {\n              return new Response('Invalid response', { status: 500 });\n          }\n\nconst reader = response.body.pipeThrough(new TextDecoderStream()).getReader();\n\nlet data = [] as string[];\n          let i = 0;\n          while (true) {\n              // Cancel the stream after 5 messages\n              if (i > 5) {\n                  reader.cancel();\n                  break;\n              }\n              const { value, done } = await reader.read();\n\nif (value) {\n                  console.log(`Got value ${value}`);\n                  data = [...data, value];\n              }\n\nif (done) {\n                  break;\n              }\n              i++;\n          }\n\nreturn Response.json(data);\n      },\n\n} satisfies ExportedHandler<Env>;\n  sh\n  npm i -D vitest@~3.2.0 @cloudflare/vitest-pool-workers\n  sh\n  pnpm add -D vitest@~3.2.0 @cloudflare/vitest-pool-workers\n  sh\n  yarn add -D vitest@~3.2.0 @cloudflare/vitest-pool-workers\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class Counter extends DurableObject {\n    constructor(ctx, env) {\n      super(ctx, env);\n\nctx.blockConcurrencyWhile(async () => {\n        this.ctx.storage.sql.exec(`\n          CREATE TABLE IF NOT EXISTS counters (\n            name TEXT PRIMARY KEY,\n            value INTEGER NOT NULL DEFAULT 0\n          )\n        `);\n      });\n    }\n\nasync increment(name = \"default\") {\n      this.ctx.storage.sql.exec(\n        `INSERT INTO counters (name, value) VALUES (?, 1)\n         ON CONFLICT(name) DO UPDATE SET value = value + 1`,\n        name,\n      );\n      const result = this.ctx.storage.sql\n        .exec(\"SELECT value FROM counters WHERE name = ?\", name)\n        .one();\n      return result.value;\n    }\n\nasync getCount(name = \"default\") {\n      const result = this.ctx.storage.sql\n        .exec(\"SELECT value FROM counters WHERE name = ?\", name)\n        .toArray();\n      return result[0]?.value ?? 0;\n    }\n\nasync reset(name = \"default\") {\n      this.ctx.storage.sql.exec(\"DELETE FROM counters WHERE name = ?\", name);\n    }\n  }\n\nexport default {\n    async fetch(request, env) {\n      const url = new URL(request.url);\n      const counterId = url.searchParams.get(\"id\") ?? \"default\";\n\nconst id = env.COUNTER.idFromName(counterId);\n      const stub = env.COUNTER.get(id);\n\nif (request.method === \"POST\") {\n        const count = await stub.increment();\n        return Response.json({ count });\n      }\n\nconst count = await stub.getCount();\n      return Response.json({ count });\n    },\n  };\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport interface Env {\n    COUNTER: DurableObjectNamespace<Counter>;\n  }\n\nexport class Counter extends DurableObject<Env> {\n    constructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n\nctx.blockConcurrencyWhile(async () => {\n        this.ctx.storage.sql.exec(`\n          CREATE TABLE IF NOT EXISTS counters (\n            name TEXT PRIMARY KEY,\n            value INTEGER NOT NULL DEFAULT 0\n          )\n        `);\n      });\n    }\n\nasync increment(name: string = \"default\"): Promise<number> {\n      this.ctx.storage.sql.exec(\n        `INSERT INTO counters (name, value) VALUES (?, 1)\n         ON CONFLICT(name) DO UPDATE SET value = value + 1`,\n        name\n      );\n      const result = this.ctx.storage.sql\n        .exec<{ value: number }>(\"SELECT value FROM counters WHERE name = ?\", name)\n        .one();\n      return result.value;\n    }\n\nasync getCount(name: string = \"default\"): Promise<number> {\n      const result = this.ctx.storage.sql\n        .exec<{ value: number }>(\"SELECT value FROM counters WHERE name = ?\", name)\n        .toArray();\n      return result[0]?.value ?? 0;\n    }\n\nasync reset(name: string = \"default\"): Promise<void> {\n      this.ctx.storage.sql.exec(\"DELETE FROM counters WHERE name = ?\", name);\n    }\n  }\n\nexport default {\n    async fetch(request: Request, env: Env): Promise<Response> {\n      const url = new URL(request.url);\n      const counterId = url.searchParams.get(\"id\") ?? \"default\";\n\nconst id = env.COUNTER.idFromName(counterId);\n      const stub = env.COUNTER.get(id);\n\nif (request.method === \"POST\") {\n        const count = await stub.increment();\n        return Response.json({ count });\n      }\n\nconst count = await stub.getCount();\n      return Response.json({ count });\n    },\n  };\n  ts\nimport { defineWorkersConfig } from \"@cloudflare/vitest-pool-workers/config\";\n\nexport default defineWorkersConfig({\n  test: {\n    poolOptions: {\n      workers: {\n        wrangler: { configPath: \"./wrangler.toml\" },\n      },\n    },\n  },\n});\njsonc\n  {\n    \"name\": \"counter-worker\",\n    \"main\": \"src/index.ts\",\n    \"compatibility_date\": \"2024-12-01\",\n    \"durable_objects\": {\n      \"bindings\": [\n        { \"name\": \"COUNTER\", \"class_name\": \"Counter\" }\n      ]\n    },\n    \"migrations\": [\n      { \"tag\": \"v1\", \"new_sqlite_classes\": [\"Counter\"] }\n    ]\n  }\n  toml\n  name = \"counter-worker\"\n  main = \"src/index.ts\"\n  compatibility_date = \"2024-12-01\"\n\n[[durable_objects.bindings]]\n  name = \"COUNTER\"\n  class_name = \"Counter\"\n\n[[migrations]]\n  tag = \"v1\"\n  new_sqlite_classes = [ \"Counter\" ]\n  jsonc\n{\n  \"extends\": \"../tsconfig.json\",\n  \"compilerOptions\": {\n    \"moduleResolution\": \"bundler\",\n    \"types\": [\"@cloudflare/vitest-pool-workers\"]\n  },\n  \"include\": [\"./**/*.ts\", \"../src/worker-configuration.d.ts\"]\n}\nts\ndeclare module \"cloudflare:test\" {\n  interface ProvidedEnv extends Env {}\n}\njs\n  import { env } from \"cloudflare:test\";\n  import { describe, it, expect, beforeEach } from \"vitest\";\n\ndescribe(\"Counter Durable Object\", () => {\n    // Each test gets isolated storage automatically\n    it(\"should increment the counter\", async () => {\n      const id = env.COUNTER.idFromName(\"test-counter\");\n      const stub = env.COUNTER.get(id);\n\n// Call RPC methods directly on the stub\n      const count1 = await stub.increment();\n      expect(count1).toBe(1);\n\nconst count2 = await stub.increment();\n      expect(count2).toBe(2);\n\nconst count3 = await stub.increment();\n      expect(count3).toBe(3);\n    });\n\nit(\"should track separate counters independently\", async () => {\n      const id = env.COUNTER.idFromName(\"test-counter\");\n      const stub = env.COUNTER.get(id);\n\nawait stub.increment(\"counter-a\");\n      await stub.increment(\"counter-a\");\n      await stub.increment(\"counter-b\");\n\nexpect(await stub.getCount(\"counter-a\")).toBe(2);\n      expect(await stub.getCount(\"counter-b\")).toBe(1);\n      expect(await stub.getCount(\"counter-c\")).toBe(0);\n    });\n\nit(\"should reset a counter\", async () => {\n      const id = env.COUNTER.idFromName(\"test-counter\");\n      const stub = env.COUNTER.get(id);\n\nawait stub.increment(\"my-counter\");\n      await stub.increment(\"my-counter\");\n      expect(await stub.getCount(\"my-counter\")).toBe(2);\n\nawait stub.reset(\"my-counter\");\n      expect(await stub.getCount(\"my-counter\")).toBe(0);\n    });\n\nit(\"should isolate different Durable Object instances\", async () => {\n      const id1 = env.COUNTER.idFromName(\"counter-1\");\n      const id2 = env.COUNTER.idFromName(\"counter-2\");\n\nconst stub1 = env.COUNTER.get(id1);\n      const stub2 = env.COUNTER.get(id2);\n\nawait stub1.increment();\n      await stub1.increment();\n      await stub2.increment();\n\n// Each Durable Object instance has its own storage\n      expect(await stub1.getCount()).toBe(2);\n      expect(await stub2.getCount()).toBe(1);\n    });\n  });\n  ts\n  import { env } from \"cloudflare:test\";\n  import { describe, it, expect, beforeEach } from \"vitest\";\n\ndescribe(\"Counter Durable Object\", () => {\n    // Each test gets isolated storage automatically\n    it(\"should increment the counter\", async () => {\n      const id = env.COUNTER.idFromName(\"test-counter\");\n      const stub = env.COUNTER.get(id);\n\n// Call RPC methods directly on the stub\n      const count1 = await stub.increment();\n      expect(count1).toBe(1);\n\nconst count2 = await stub.increment();\n      expect(count2).toBe(2);\n\nconst count3 = await stub.increment();\n      expect(count3).toBe(3);\n    });\n\nit(\"should track separate counters independently\", async () => {\n      const id = env.COUNTER.idFromName(\"test-counter\");\n      const stub = env.COUNTER.get(id);\n\nawait stub.increment(\"counter-a\");\n      await stub.increment(\"counter-a\");\n      await stub.increment(\"counter-b\");\n\nexpect(await stub.getCount(\"counter-a\")).toBe(2);\n      expect(await stub.getCount(\"counter-b\")).toBe(1);\n      expect(await stub.getCount(\"counter-c\")).toBe(0);\n    });\n\nit(\"should reset a counter\", async () => {\n      const id = env.COUNTER.idFromName(\"test-counter\");\n      const stub = env.COUNTER.get(id);\n\nawait stub.increment(\"my-counter\");\n      await stub.increment(\"my-counter\");\n      expect(await stub.getCount(\"my-counter\")).toBe(2);\n\nawait stub.reset(\"my-counter\");\n      expect(await stub.getCount(\"my-counter\")).toBe(0);\n    });\n\nit(\"should isolate different Durable Object instances\", async () => {\n      const id1 = env.COUNTER.idFromName(\"counter-1\");\n      const id2 = env.COUNTER.idFromName(\"counter-2\");\n\nconst stub1 = env.COUNTER.get(id1);\n      const stub2 = env.COUNTER.get(id2);\n\nawait stub1.increment();\n      await stub1.increment();\n      await stub2.increment();\n\n// Each Durable Object instance has its own storage\n      expect(await stub1.getCount()).toBe(2);\n      expect(await stub2.getCount()).toBe(1);\n    });\n  });\n  js\n  import { SELF } from \"cloudflare:test\";\n  import { describe, it, expect } from \"vitest\";\n\ndescribe(\"Counter Worker integration\", () => {\n    it(\"should increment via HTTP POST\", async () => {\n      const response = await SELF.fetch(\"http://example.com?id=http-test\", {\n        method: \"POST\",\n      });\n\nexpect(response.status).toBe(200);\n      const data = await response.json();\n      expect(data.count).toBe(1);\n    });\n\nit(\"should get count via HTTP GET\", async () => {\n      // First increment the counter\n      await SELF.fetch(\"http://example.com?id=get-test\", { method: \"POST\" });\n      await SELF.fetch(\"http://example.com?id=get-test\", { method: \"POST\" });\n\n// Then get the count\n      const response = await SELF.fetch(\"http://example.com?id=get-test\");\n      const data = await response.json();\n      expect(data.count).toBe(2);\n    });\n\nit(\"should use different counters for different IDs\", async () => {\n      await SELF.fetch(\"http://example.com?id=counter-a\", { method: \"POST\" });\n      await SELF.fetch(\"http://example.com?id=counter-a\", { method: \"POST\" });\n      await SELF.fetch(\"http://example.com?id=counter-b\", { method: \"POST\" });\n\nconst responseA = await SELF.fetch(\"http://example.com?id=counter-a\");\n      const responseB = await SELF.fetch(\"http://example.com?id=counter-b\");\n\nconst dataA = await responseA.json();\n      const dataB = await responseB.json();\n\nexpect(dataA.count).toBe(2);\n      expect(dataB.count).toBe(1);\n    });\n  });\n  ts\n  import { SELF } from \"cloudflare:test\";\n  import { describe, it, expect } from \"vitest\";\n\ndescribe(\"Counter Worker integration\", () => {\n    it(\"should increment via HTTP POST\", async () => {\n      const response = await SELF.fetch(\"http://example.com?id=http-test\", {\n        method: \"POST\",\n      });\n\nexpect(response.status).toBe(200);\n      const data = await response.json<{ count: number }>();\n      expect(data.count).toBe(1);\n    });\n\nit(\"should get count via HTTP GET\", async () => {\n      // First increment the counter\n      await SELF.fetch(\"http://example.com?id=get-test\", { method: \"POST\" });\n      await SELF.fetch(\"http://example.com?id=get-test\", { method: \"POST\" });\n\n// Then get the count\n      const response = await SELF.fetch(\"http://example.com?id=get-test\");\n      const data = await response.json<{ count: number }>();\n      expect(data.count).toBe(2);\n    });\n\nit(\"should use different counters for different IDs\", async () => {\n      await SELF.fetch(\"http://example.com?id=counter-a\", { method: \"POST\" });\n      await SELF.fetch(\"http://example.com?id=counter-a\", { method: \"POST\" });\n      await SELF.fetch(\"http://example.com?id=counter-b\", { method: \"POST\" });\n\nconst responseA = await SELF.fetch(\"http://example.com?id=counter-a\");\n      const responseB = await SELF.fetch(\"http://example.com?id=counter-b\");\n\nconst dataA = await responseA.json<{ count: number }>();\n      const dataB = await responseB.json<{ count: number }>();\n\nexpect(dataA.count).toBe(2);\n      expect(dataB.count).toBe(1);\n    });\n  });\n  js\n  import { env, runInDurableObject, listDurableObjectIds } from \"cloudflare:test\";\n  import { describe, it, expect } from \"vitest\";\n  import { Counter } from \"../src\";\n\ndescribe(\"Direct Durable Object access\", () => {\n    it(\"can access instance internals and storage\", async () => {\n      const id = env.COUNTER.idFromName(\"direct-test\");\n      const stub = env.COUNTER.get(id);\n\n// First, interact normally via RPC\n      await stub.increment();\n      await stub.increment();\n\n// Then use runInDurableObject to inspect internals\n      await runInDurableObject(stub, async (instance, state) => {\n        // Access the exact same class instance\n        expect(instance).toBeInstanceOf(Counter);\n\n// Access storage directly for verification\n        const result = state.storage.sql\n          .exec(\"SELECT value FROM counters WHERE name = ?\", \"default\")\n          .one();\n        expect(result.value).toBe(2);\n      });\n    });\n\nit(\"can list all Durable Object IDs in a namespace\", async () => {\n      // Create some Durable Objects\n      const id1 = env.COUNTER.idFromName(\"list-test-1\");\n      const id2 = env.COUNTER.idFromName(\"list-test-2\");\n\nawait env.COUNTER.get(id1).increment();\n      await env.COUNTER.get(id2).increment();\n\n// List all IDs in the namespace\n      const ids = await listDurableObjectIds(env.COUNTER);\n      expect(ids.length).toBe(2);\n      expect(ids.some((id) => id.equals(id1))).toBe(true);\n      expect(ids.some((id) => id.equals(id2))).toBe(true);\n    });\n  });\n  ts\n  import {\n    env,\n    runInDurableObject,\n    listDurableObjectIds,\n  } from \"cloudflare:test\";\n  import { describe, it, expect } from \"vitest\";\n  import { Counter } from \"../src\";\n\ndescribe(\"Direct Durable Object access\", () => {\n    it(\"can access instance internals and storage\", async () => {\n      const id = env.COUNTER.idFromName(\"direct-test\");\n      const stub = env.COUNTER.get(id);\n\n// First, interact normally via RPC\n      await stub.increment();\n      await stub.increment();\n\n// Then use runInDurableObject to inspect internals\n      await runInDurableObject(stub, async (instance: Counter, state) => {\n        // Access the exact same class instance\n        expect(instance).toBeInstanceOf(Counter);\n\n// Access storage directly for verification\n        const result = state.storage.sql\n          .exec<{ value: number }>(\n            \"SELECT value FROM counters WHERE name = ?\",\n            \"default\"\n          )\n          .one();\n        expect(result.value).toBe(2);\n      });\n    });\n\nit(\"can list all Durable Object IDs in a namespace\", async () => {\n      // Create some Durable Objects\n      const id1 = env.COUNTER.idFromName(\"list-test-1\");\n      const id2 = env.COUNTER.idFromName(\"list-test-2\");\n\nawait env.COUNTER.get(id1).increment();\n      await env.COUNTER.get(id2).increment();\n\n// List all IDs in the namespace\n      const ids = await listDurableObjectIds(env.COUNTER);\n      expect(ids.length).toBe(2);\n      expect(ids.some((id) => id.equals(id1))).toBe(true);\n      expect(ids.some((id) => id.equals(id2))).toBe(true);\n    });\n  });\n  js\n  import { env, listDurableObjectIds } from \"cloudflare:test\";\n  import { describe, it, expect } from \"vitest\";\n\ndescribe(\"Test isolation\", () => {\n    it(\"first test: creates a Durable Object\", async () => {\n      const id = env.COUNTER.idFromName(\"isolated-counter\");\n      const stub = env.COUNTER.get(id);\n\nawait stub.increment();\n      await stub.increment();\n      expect(await stub.getCount()).toBe(2);\n    });\n\nit(\"second test: previous Durable Object does not exist\", async () => {\n      // The Durable Object from the previous test is automatically cleaned up\n      const ids = await listDurableObjectIds(env.COUNTER);\n      expect(ids.length).toBe(0);\n\n// Creating the same ID gives a fresh instance\n      const id = env.COUNTER.idFromName(\"isolated-counter\");\n      const stub = env.COUNTER.get(id);\n      expect(await stub.getCount()).toBe(0);\n    });\n  });\n  ts\n  import { env, listDurableObjectIds } from \"cloudflare:test\";\n  import { describe, it, expect } from \"vitest\";\n\ndescribe(\"Test isolation\", () => {\n    it(\"first test: creates a Durable Object\", async () => {\n      const id = env.COUNTER.idFromName(\"isolated-counter\");\n      const stub = env.COUNTER.get(id);\n\nawait stub.increment();\n      await stub.increment();\n      expect(await stub.getCount()).toBe(2);\n    });\n\nit(\"second test: previous Durable Object does not exist\", async () => {\n      // The Durable Object from the previous test is automatically cleaned up\n      const ids = await listDurableObjectIds(env.COUNTER);\n      expect(ids.length).toBe(0);\n\n// Creating the same ID gives a fresh instance\n      const id = env.COUNTER.idFromName(\"isolated-counter\");\n      const stub = env.COUNTER.get(id);\n      expect(await stub.getCount()).toBe(0);\n    });\n  });\n  js\n  import { env, runInDurableObject } from \"cloudflare:test\";\n  import { describe, it, expect } from \"vitest\";\n\ndescribe(\"SQLite in Durable Objects\", () => {\n    it(\"can query and verify SQLite storage\", async () => {\n      const id = env.COUNTER.idFromName(\"sqlite-test\");\n      const stub = env.COUNTER.get(id);\n\n// Increment the counter a few times via RPC\n      await stub.increment(\"page-views\");\n      await stub.increment(\"page-views\");\n      await stub.increment(\"api-calls\");\n\n// Verify the data directly in SQLite\n      await runInDurableObject(stub, async (instance, state) => {\n        // Query the database directly\n        const rows = state.storage.sql\n          .exec(\"SELECT name, value FROM counters ORDER BY name\")\n          .toArray();\n\nexpect(rows).toEqual([\n          { name: \"api-calls\", value: 1 },\n          { name: \"page-views\", value: 2 },\n        ]);\n\n// Check database size is non-zero\n        expect(state.storage.sql.databaseSize).toBeGreaterThan(0);\n      });\n    });\n  });\n  ts\n  import { env, runInDurableObject } from \"cloudflare:test\";\n  import { describe, it, expect } from \"vitest\";\n\ndescribe(\"SQLite in Durable Objects\", () => {\n    it(\"can query and verify SQLite storage\", async () => {\n      const id = env.COUNTER.idFromName(\"sqlite-test\");\n      const stub = env.COUNTER.get(id);\n\n// Increment the counter a few times via RPC\n      await stub.increment(\"page-views\");\n      await stub.increment(\"page-views\");\n      await stub.increment(\"api-calls\");\n\n// Verify the data directly in SQLite\n      await runInDurableObject(stub, async (instance, state) => {\n        // Query the database directly\n        const rows = state.storage.sql\n          .exec<{ name: string; value: number }>(\"SELECT name, value FROM counters ORDER BY name\")\n          .toArray();\n\nexpect(rows).toEqual([\n          { name: \"api-calls\", value: 1 },\n          { name: \"page-views\", value: 2 },\n        ]);\n\n// Check database size is non-zero\n        expect(state.storage.sql.databaseSize).toBeGreaterThan(0);\n      });\n    });\n  });\n  js\n  import {\n    env,\n    runInDurableObject,\n    runDurableObjectAlarm,\n  } from \"cloudflare:test\";\n  import { describe, it, expect } from \"vitest\";\n  import { Counter } from \"../src\";\n\ndescribe(\"Durable Object alarms\", () => {\n    it(\"can trigger alarms immediately\", async () => {\n      const id = env.COUNTER.idFromName(\"alarm-test\");\n      const stub = env.COUNTER.get(id);\n\n// Increment counter and schedule a reset alarm\n      await stub.increment();\n      await stub.increment();\n      expect(await stub.getCount()).toBe(2);\n\n// Schedule an alarm (in a real app, this might be hours in the future)\n      await runInDurableObject(stub, async (instance, state) => {\n        await state.storage.setAlarm(Date.now() + 60_000); // 1 minute from now\n      });\n\n// Immediately execute the alarm without waiting\n      const alarmRan = await runDurableObjectAlarm(stub);\n      expect(alarmRan).toBe(true); // Alarm was scheduled and executed\n\n// Verify the alarm handler ran (assuming it resets the counter)\n      // Note: You'll need an alarm() method in your Durable Object that handles resets\n      // expect(await stub.getCount()).toBe(0);\n\n// Trying to run the alarm again returns false (no alarm scheduled)\n      const alarmRanAgain = await runDurableObjectAlarm(stub);\n      expect(alarmRanAgain).toBe(false);\n    });\n  });\n  ts\n  import {\n    env,\n    runInDurableObject,\n    runDurableObjectAlarm,\n  } from \"cloudflare:test\";\n  import { describe, it, expect } from \"vitest\";\n  import { Counter } from \"../src\";\n\ndescribe(\"Durable Object alarms\", () => {\n    it(\"can trigger alarms immediately\", async () => {\n      const id = env.COUNTER.idFromName(\"alarm-test\");\n      const stub = env.COUNTER.get(id);\n\n// Increment counter and schedule a reset alarm\n      await stub.increment();\n      await stub.increment();\n      expect(await stub.getCount()).toBe(2);\n\n// Schedule an alarm (in a real app, this might be hours in the future)\n      await runInDurableObject(stub, async (instance, state) => {\n        await state.storage.setAlarm(Date.now() + 60_000); // 1 minute from now\n      });\n\n// Immediately execute the alarm without waiting\n      const alarmRan = await runDurableObjectAlarm(stub);\n      expect(alarmRan).toBe(true); // Alarm was scheduled and executed\n\n// Verify the alarm handler ran (assuming it resets the counter)\n      // Note: You'll need an alarm() method in your Durable Object that handles resets\n      // expect(await stub.getCount()).toBe(0);\n\n// Trying to run the alarm again returns false (no alarm scheduled)\n      const alarmRanAgain = await runDurableObjectAlarm(stub);\n      expect(alarmRanAgain).toBe(false);\n    });\n  });\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class Counter extends DurableObject {\n    // ... other methods ...\n\nasync alarm() {\n      // This method is called when the alarm fires\n      // Reset all counters\n      this.ctx.storage.sql.exec(\"DELETE FROM counters\");\n    }\n\nasync scheduleReset(afterMs) {\n      await this.ctx.storage.setAlarm(Date.now() + afterMs);\n    }\n  }\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\nexport class Counter extends DurableObject {\n    // ... other methods ...\n\nasync alarm() {\n      // This method is called when the alarm fires\n      // Reset all counters\n      this.ctx.storage.sql.exec(\"DELETE FROM counters\");\n    }\n\nasync scheduleReset(afterMs: number) {\n      await this.ctx.storage.setAlarm(Date.now() + afterMs);\n    }\n  }\n  sh\nnpx vitest\njson\n{\n  \"scripts\": {\n    \"test\": \"vitest\"\n  }\n}\nts\nimport { DurableObject, RpcTarget } from \"cloudflare:workers\";\n\n//  * Create an RpcDO class that extends RpcTarget\n//  * Use this class to set the Durable Object metadata\n//  * Pass the metadata in the Durable Object methods\n//  * @param mainDo - The main Durable Object class\n//  * @param doIdentifier - The identifier of the Durable Object\n\nexport class RpcDO extends RpcTarget {\n  constructor(\n    private mainDo: MyDurableObject,\n    private doIdentifier: string,\n  ) {\n    super();\n  }\n\n//  * Pass the user's name to the Durable Object method\n  //  * @param userName - The user's name to pass to the Durable Object method\n\nasync computeMessage(userName: string): Promise<string> {\n    // Call the Durable Object method and pass the user's name and the Durable Object identifier\n    return this.mainDo.computeMessage(userName, this.doIdentifier);\n  }\n\n//  * Call the Durable Object method without using the Durable Object identifier\n  //  * @param userName - The user's name to pass to the Durable Object method\n\nasync simpleGreeting(userName: string) {\n    return this.mainDo.simpleGreeting(userName);\n  }\n}\n\n//  * Create a Durable Object class\n//  * You can use the RpcDO class to set the Durable Object metadata\n\nexport class MyDurableObject extends DurableObject<Env> {\n  constructor(ctx: DurableObjectState, env: Env) {\n    super(ctx, env);\n  }\n\n//  * Initialize the RpcDO class\n  //  * You can set the Durable Object metadata here\n  //  * It returns an instance of the RpcDO class\n  //  * @param doIdentifier - The identifier of the Durable Object\n\nasync setMetaData(doIdentifier: string) {\n    return new RpcDO(this, doIdentifier);\n  }\n\n//  * Function that computes a greeting message using the user's name and DO identifier\n  //  * @param userName - The user's name to include in the greeting\n  //  * @param doIdentifier - The identifier of the Durable Object\n\nasync computeMessage(\n    userName: string,\n    doIdentifier: string,\n  ): Promise<string> {\n    console.log({\n      userName: userName,\n      durableObjectIdentifier: doIdentifier,\n    });\n    return `Hello, ${userName}! The identifier of this DO is ${doIdentifier}`;\n  }\n\n//  * Function that is not in the RpcTarget\n  //  * Not every function has to be in the RpcTarget\n\nprivate async notInRpcTarget() {\n    return \"This is not in the RpcTarget\";\n  }\n\n//  * Function that takes the user's name and does not use the Durable Object identifier\n  //  * @param userName - The user's name to include in the greeting\n\nasync simpleGreeting(userName: string) {\n    // Call the private function that is not in the RpcTarget\n    console.log(this.notInRpcTarget());\n\nreturn `Hello, ${userName}! This doesn't use the DO identifier.`;\n  }\n}\n\nexport default {\n  async fetch(request, env, ctx): Promise<Response> {\n    let id: DurableObjectId = env.MY_DURABLE_OBJECT.idFromName(\n      new URL(request.url).pathname,\n    );\n    let stub = env.MY_DURABLE_OBJECT.get(id);\n\n//  * Set the Durable Object metadata using the RpcTarget\n    //  * Notice that no await is needed here\n\nconst rpcTarget = stub.setMetaData(id.name ?? \"default\");\n\n// Call the Durable Object method using the RpcTarget.\n    // The DO identifier is passed in the RpcTarget\n    const greeting = await rpcTarget.computeMessage(\"world\");\n\n// Call the Durable Object method that does not use the Durable Object identifier\n    const simpleGreeting = await rpcTarget.simpleGreeting(\"world\");\n\n// Clean up the RpcTarget.\n    try {\n      (await rpcTarget)[Symbol.dispose]?.();\n      console.log(\"RpcTarget cleaned up.\");\n    } catch (e) {\n      console.error({\n        message: \"RpcTarget could not be cleaned up.\",\n        error: String(e),\n        errorProperties: e,\n      });\n    }\n\nreturn new Response(greeting, { status: 200 });\n  },\n} satisfies ExportedHandler<Env>;\nts\nimport { DurableObject, RpcTarget } from \"cloudflare:workers\";\n\n//  * Create an RpcDO class that extends RpcTarget\n//  * Use this class to set the Durable Object metadata\n//  * Pass the metadata in the Durable Object methods\n//  * @param mainDo - The main Durable Object class\n//  * @param doIdentifier - The identifier of the Durable Object\n\nexport class RpcDO extends RpcTarget {\n  constructor(\n    private mainDo: MyDurableObject,\n    private doIdentifier: string,\n  ) {\n    super();\n  }\n\n//  * Pass the user's name to the Durable Object method\n  //  * @param userName - The user's name to pass to the Durable Object method\n\nasync computeMessage(userName: string): Promise<string> {\n    // Call the Durable Object method and pass the user's name and the Durable Object identifier\n    return this.mainDo.computeMessage(userName, this.doIdentifier);\n  }\n\n//  * Call the Durable Object method without using the Durable Object identifier\n  //  * @param userName - The user's name to pass to the Durable Object method\n\nasync simpleGreeting(userName: string) {\n    return this.mainDo.simpleGreeting(userName);\n  }\n}\n\n//  * Create a Durable Object class\n//  * You can use the RpcDO class to set the Durable Object metadata\n\nexport class MyDurableObject extends DurableObject<Env> {\n  constructor(ctx: DurableObjectState, env: Env) {\n    super(ctx, env);\n  }\n\n//  * Initialize the RpcDO class\n  //  * You can set the Durable Object metadata here\n  //  * It returns an instance of the RpcDO class\n  //  * @param doIdentifier - The identifier of the Durable Object\n\nasync setMetaData(doIdentifier: string) {\n    // Use DO storage to store the Durable Object identifier\n    await this.ctx.storage.put(\"doIdentifier\", doIdentifier);\n    return new RpcDO(this, doIdentifier);\n  }\n\n//  * Function that computes a greeting message using the user's name and DO identifier\n  //  * @param userName - The user's name to include in the greeting\n\nasync computeMessage(userName: string): Promise<string> {\n    // Get the DO identifier from storage\n    const doIdentifier = await this.ctx.storage.get(\"doIdentifier\");\n    console.log({\n      userName: userName,\n      durableObjectIdentifier: doIdentifier,\n    });\n    return `Hello, ${userName}! The identifier of this DO is ${doIdentifier}`;\n  }\n\n//  * Function that is not in the RpcTarget\n  //  * Not every function has to be in the RpcTarget\n\nprivate async notInRpcTarget() {\n    return \"This is not in the RpcTarget\";\n  }\n\n//  * Function that takes the user's name and does not use the Durable Object identifier\n  //  * @param userName - The user's name to include in the greeting\n\nasync simpleGreeting(userName: string) {\n    // Call the private function that is not in the RpcTarget\n    console.log(this.notInRpcTarget());\n\nreturn `Hello, ${userName}! This doesn't use the DO identifier.`;\n  }\n}\n\nexport default {\n  async fetch(request, env, ctx): Promise<Response> {\n    let id: DurableObjectId = env.MY_DURABLE_OBJECT.idFromName(\n      new URL(request.url).pathname,\n    );\n    let stub = env.MY_DURABLE_OBJECT.get(id);\n\n//  * Set the Durable Object metadata using the RpcTarget\n    //  * Notice that no await is needed here\n\nconst rpcTarget = stub.setMetaData(id.name ?? \"default\");\n\n// Call the Durable Object method using the RpcTarget.\n    // The DO identifier is stored in the Durable Object's storage\n    const greeting = await rpcTarget.computeMessage(\"world\");\n\n// Call the Durable Object method that does not use the Durable Object identifier\n    const simpleGreeting = await rpcTarget.simpleGreeting(\"world\");\n\n// Clean up the RpcTarget.\n    try {\n      (await rpcTarget)[Symbol.dispose]?.();\n      console.log(\"RpcTarget cleaned up.\");\n    } catch (e) {\n      console.error({\n        message: \"RpcTarget could not be cleaned up.\",\n        error: String(e),\n        errorProperties: e,\n      });\n    }\n\nreturn new Response(greeting, { status: 200 });\n  },\n} satisfies ExportedHandler<Env>;\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"my-worker\",\n    \"main\": \"src/index.ts\",\n    \"kv_namespaces\": [\n      {\n        \"binding\": \"YOUR_KV_NAMESPACE\",\n        \"id\": \"<id_of_your_namespace>\"\n      }\n    ],\n    \"durable_objects\": {\n      \"bindings\": [\n        {\n          \"name\": \"YOUR_DO_CLASS\",\n          \"class_name\": \"YourDurableObject\"\n        }\n      ]\n    }\n  }\n  toml\n  name = \"my-worker\"\n  main = \"src/index.ts\"\n\nkv_namespaces = [\n    { binding = \"YOUR_KV_NAMESPACE\", id = \"<id_of_your_namespace>\" }\n  ]\n\n[durable_objects]\n  bindings = [\n    { name = \"YOUR_DO_CLASS\", class_name = \"YourDurableObject\" }\n  ]\n  ts\n  import { DurableObject } from \"cloudflare:workers\";\n\ninterface Env {\n    YOUR_KV_NAMESPACE: KVNamespace;\n    YOUR_DO_CLASS: DurableObjectNamespace;\n  }\n\nexport default {\n    async fetch(req: Request, env: Env): Promise<Response> {\n      // Assume each Durable Object is mapped to a roomId in a query parameter\n      // In a production application, this will likely be a roomId defined by your application\n      // that you validate (and/or authenticate) first.\n      let url = new URL(req.url);\n      let roomIdParam = url.searchParams.get(\"roomId\");\n\nif (roomIdParam) {\n        // Get a stub that allows you to call that Durable Object\n        let durableObjectStub = env.YOUR_DO_CLASS.getByName(roomIdParam);\n\n// Pass the request to that Durable Object and await the response\n        // This invokes the constructor once on your Durable Object class (defined further down)\n        // on the first initialization, and the fetch method on each request.\n        //\n        // You could pass the original Request to the Durable Object's fetch method\n        // or a simpler URL with just the roomId.\n        let response = await durableObjectStub.fetch(`http://do/${roomId}`);\n\n// This would return the value you read from KV *within* the Durable Object.\n        return response;\n      }\n    },\n  };\n\nexport class YourDurableObject extends DurableObject {\n    constructor(\n      public state: DurableObjectState,\n      env: Env,\n    ) {\n      super(state, env);\n    }\n\nasync fetch(request: Request) {\n      // Error handling elided for brevity.\n      // Write to KV\n      await this.env.YOUR_KV_NAMESPACE.put(\"some-key\");\n\n// Fetch from KV\n      let val = await this.env.YOUR_KV_NAMESPACE.get(\"some-other-key\");\n\nreturn Response.json(val);\n    }\n  }\n  py\n  from workers import DurableObject, Response, WorkerEntrypoint\n  from urllib.parse import urlparse, parse_qs\n\nclass Default(WorkerEntrypoint):\n    async def fetch(self, req):\n      # Assume each Durable Object is mapped to a roomId in a query parameter\n      # In a production application, this will likely be a roomId defined by your application\n      # that you validate (and/or authenticate) first.\n      url = req.url\n      parsed_url = urlparse(url)\n      room_id_param = parse_qs(parsed_url.query).get('roomId', [None])[0]\n\nif room_id_param:\n        # Get a stub that allows you to call that Durable Object\n        durable_object_stub = self.env.YOUR_DO_CLASS.getByName(room_id_param)\n\n# Pass the request to that Durable Object and await the response\n        # This invokes the constructor once on your Durable Object class (defined further down)\n        # on the first initialization, and the fetch method on each request.\n        #\n        # You could pass the original Request to the Durable Object's fetch method\n        # or a simpler URL with just the roomId.\n        response = await durable_object_stub.fetch(f\"http://do/{room_id_param}\")\n\n# This would return the value you read from KV *within* the Durable Object.\n        return response\n\nclass YourDurableObject(DurableObject):\n    def __init__(self, state, env):\n      super().__init__(state, env)\n\nasync def fetch(self, request):\n      # Error handling elided for brevity.\n      # Write to KV\n      await self.env.YOUR_KV_NAMESPACE.put(\"some-key\", \"some-value\")\n\n# Fetch from KV\n      val = await self.env.YOUR_KV_NAMESPACE.get(\"some-other-key\")\n\nreturn Response.json(val)\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Worker\n  export default {\n    async fetch(request, env, ctx) {\n      if (request.url.endsWith(\"/websocket\")) {\n        // Expect to receive a WebSocket Upgrade request.\n        // If there is one, accept the request and return a WebSocket Response.\n        const upgradeHeader = request.headers.get(\"Upgrade\");\n        if (!upgradeHeader || upgradeHeader !== \"websocket\") {\n          return new Response(\"Worker expected Upgrade: websocket\", {\n            status: 426,\n          });\n        }\n\nif (request.method !== \"GET\") {\n          return new Response(\"Worker expected GET method\", {\n            status: 400,\n          });\n        }\n\n// Since we are hard coding the Durable Object ID by providing the constant name 'foo',\n        // all requests to this Worker will be sent to the same Durable Object instance.\n        let stub = env.WEBSOCKET_HIBERNATION_SERVER.getByName(\"foo\");\n\nreturn stub.fetch(request);\n      }\n\nreturn new Response(\n        `Supported endpoints:\n  /websocket: Expects a WebSocket upgrade request`,\n        {\n          status: 200,\n          headers: {\n            \"Content-Type\": \"text/plain\",\n          },\n        },\n      );\n    },\n  };\n\n// Durable Object\n  export class WebSocketHibernationServer extends DurableObject {\n    // Keeps track of all WebSocket connections\n    // When the DO hibernates, gets reconstructed in the constructor\n    sessions;\n\nconstructor(ctx, env) {\n      super(ctx, env);\n      this.sessions = new Map();\n\n// As part of constructing the Durable Object,\n      // we wake up any hibernating WebSockets and\n      // place them back in the `sessions` map.\n\n// Get all WebSocket connections from the DO\n      this.ctx.getWebSockets().forEach((ws) => {\n        let attachment = ws.deserializeAttachment();\n        if (attachment) {\n          // If we previously attached state to our WebSocket,\n          // let's add it to `sessions` map to restore the state of the connection.\n          this.sessions.set(ws, { ...attachment });\n        }\n      });\n\n// Sets an application level auto response that does not wake hibernated WebSockets.\n      this.ctx.setWebSocketAutoResponse(\n        new WebSocketRequestResponsePair(\"ping\", \"pong\"),\n      );\n    }\n\nasync fetch(request) {\n      // Creates two ends of a WebSocket connection.\n      const webSocketPair = new WebSocketPair();\n      const [client, server] = Object.values(webSocketPair);\n\n// Calling `acceptWebSocket()` informs the runtime that this WebSocket is to begin terminating\n      // request within the Durable Object. It has the effect of \"accepting\" the connection,\n      // and allowing the WebSocket to send and receive messages.\n      // Unlike `ws.accept()`, `this.ctx.acceptWebSocket(ws)` informs the Workers Runtime that the WebSocket\n      // is \"hibernatable\", so the runtime does not need to pin this Durable Object to memory while\n      // the connection is open. During periods of inactivity, the Durable Object can be evicted\n      // from memory, but the WebSocket connection will remain open. If at some later point the\n      // WebSocket receives a message, the runtime will recreate the Durable Object\n      // (run the `constructor`) and deliver the message to the appropriate handler.\n      this.ctx.acceptWebSocket(server);\n\n// Generate a random UUID for the session.\n      const id = crypto.randomUUID();\n\n// Attach the session ID to the WebSocket connection and serialize it.\n      // This is necessary to restore the state of the connection when the Durable Object wakes up.\n      server.serializeAttachment({ id });\n\n// Add the WebSocket connection to the map of active sessions.\n      this.sessions.set(server, { id });\n\nreturn new Response(null, {\n        status: 101,\n        webSocket: client,\n      });\n    }\n\nasync webSocketMessage(ws, message) {\n      // Get the session associated with the WebSocket connection.\n      const session = this.sessions.get(ws);\n\n// Upon receiving a message from the client, the server replies with the same message, the session ID of the connection,\n      // and the total number of connections with the \"[Durable Object]: \" prefix\n      ws.send(\n        `[Durable Object] message: ${message}, from: ${session.id}, to: the initiating client. Total connections: ${this.sessions.size}`,\n      );\n\n// Send a message to all WebSocket connections, loop over all the connected WebSockets.\n      this.sessions.forEach((attachment, connectedWs) => {\n        connectedWs.send(\n          `[Durable Object] message: ${message}, from: ${session.id}, to: all clients. Total connections: ${this.sessions.size}`,\n        );\n      });\n\n// Send a message to all WebSocket connections except the connection (ws),\n      // loop over all the connected WebSockets and filter out the connection (ws).\n      this.sessions.forEach((attachment, connectedWs) => {\n        if (connectedWs !== ws) {\n          connectedWs.send(\n            `[Durable Object] message: ${message}, from: ${session.id}, to: all clients except the initiating client. Total connections: ${this.sessions.size}`,\n          );\n        }\n      });\n    }\n\nasync webSocketClose(ws, code, reason, wasClean) {\n      // If the client closes the connection, the runtime will invoke the webSocketClose() handler.\n      this.sessions.delete(ws);\n      ws.close(code, \"Durable Object is closing WebSocket\");\n    }\n  }\n  ts\n  import { DurableObject } from 'cloudflare:workers';\n\n// Worker\n  export default {\n    async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {\n      if (request.url.endsWith('/websocket')) {\n        // Expect to receive a WebSocket Upgrade request.\n        // If there is one, accept the request and return a WebSocket Response.\n        const upgradeHeader = request.headers.get('Upgrade');\n        if (!upgradeHeader || upgradeHeader !== 'websocket') {\n          return new Response('Worker expected Upgrade: websocket', {\n            status: 426,\n          });\n        }\n\nif (request.method !== 'GET') {\n          return new Response('Worker expected GET method', {\n            status: 400,\n          });\n        }\n\n// Since we are hard coding the Durable Object ID by providing the constant name 'foo',\n        // all requests to this Worker will be sent to the same Durable Object instance.\n        let stub = env.WEBSOCKET_HIBERNATION_SERVER.getByName(\"foo\");\n\nreturn stub.fetch(request);\n      }\n\nreturn new Response(\n        `Supported endpoints:\n  /websocket: Expects a WebSocket upgrade request`,\n        {\n          status: 200,\n          headers: {\n            'Content-Type': 'text/plain',\n          },\n        }\n      );\n    },\n  };\n\n// Durable Object\n  export class WebSocketHibernationServer extends DurableObject {\n    // Keeps track of all WebSocket connections\n    // When the DO hibernates, gets reconstructed in the constructor\n    sessions: Map<WebSocket, { [key: string]: string }>;\n\nconstructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n      this.sessions = new Map();\n\n// As part of constructing the Durable Object,\n      // we wake up any hibernating WebSockets and\n      // place them back in the `sessions` map.\n\n// Get all WebSocket connections from the DO\n      this.ctx.getWebSockets().forEach((ws) => {\n        let attachment = ws.deserializeAttachment();\n        if (attachment) {\n          // If we previously attached state to our WebSocket,\n          // let's add it to `sessions` map to restore the state of the connection.\n          this.sessions.set(ws, { ...attachment });\n        }\n      });\n\n// Sets an application level auto response that does not wake hibernated WebSockets.\n      this.ctx.setWebSocketAutoResponse(new WebSocketRequestResponsePair('ping', 'pong'));\n    }\n\nasync fetch(request: Request): Promise<Response> {\n      // Creates two ends of a WebSocket connection.\n      const webSocketPair = new WebSocketPair();\n      const [client, server] = Object.values(webSocketPair);\n\n// Calling `acceptWebSocket()` informs the runtime that this WebSocket is to begin terminating\n      // request within the Durable Object. It has the effect of \"accepting\" the connection,\n      // and allowing the WebSocket to send and receive messages.\n      // Unlike `ws.accept()`, `this.ctx.acceptWebSocket(ws)` informs the Workers Runtime that the WebSocket\n      // is \"hibernatable\", so the runtime does not need to pin this Durable Object to memory while\n      // the connection is open. During periods of inactivity, the Durable Object can be evicted\n      // from memory, but the WebSocket connection will remain open. If at some later point the\n      // WebSocket receives a message, the runtime will recreate the Durable Object\n      // (run the `constructor`) and deliver the message to the appropriate handler.\n      this.ctx.acceptWebSocket(server);\n\n// Generate a random UUID for the session.\n      const id = crypto.randomUUID();\n\n// Attach the session ID to the WebSocket connection and serialize it.\n      // This is necessary to restore the state of the connection when the Durable Object wakes up.\n      server.serializeAttachment({ id });\n\n// Add the WebSocket connection to the map of active sessions.\n      this.sessions.set(server, { id });\n\nreturn new Response(null, {\n        status: 101,\n        webSocket: client,\n      });\n    }\n\nasync webSocketMessage(ws: WebSocket, message: ArrayBuffer | string) {\n      // Get the session associated with the WebSocket connection.\n      const session = this.sessions.get(ws)!;\n\n// Upon receiving a message from the client, the server replies with the same message, the session ID of the connection,\n      // and the total number of connections with the \"[Durable Object]: \" prefix\n      ws.send(`[Durable Object] message: ${message}, from: ${session.id}, to: the initiating client. Total connections: ${this.sessions.size}`);\n\n// Send a message to all WebSocket connections, loop over all the connected WebSockets.\n      this.sessions.forEach((attachment, connectedWs) => {\n        connectedWs.send(`[Durable Object] message: ${message}, from: ${session.id}, to: all clients. Total connections: ${this.sessions.size}`);\n      });\n\n// Send a message to all WebSocket connections except the connection (ws),\n      // loop over all the connected WebSockets and filter out the connection (ws).\n      this.sessions.forEach((attachment, connectedWs) => {\n        if (connectedWs !== ws) {\n            connectedWs.send(`[Durable Object] message: ${message}, from: ${session.id}, to: all clients except the initiating client. Total connections: ${this.sessions.size}`);\n        }\n      });\n    }\n\nasync webSocketClose(ws: WebSocket, code: number, reason: string, wasClean: boolean) {\n      // If the client closes the connection, the runtime will invoke the webSocketClose() handler.\n      this.sessions.delete(ws);\n      ws.close(code, 'Durable Object is closing WebSocket');\n    }\n  }\n  py\n  from workers import DurableObject, Response, WorkerEntrypoint\n  from js import WebSocketPair, WebSocketRequestResponsePair\n  import uuid\n\nclass Session:\n    def __init__(self, *, ws):\n      self.ws = ws\n\n# Worker\n  class Default(WorkerEntrypoint):\n    async def fetch(self, request):\n      if request.url.endswith('/websocket'):\n        # Expect to receive a WebSocket Upgrade request.\n        # If there is one, accept the request and return a WebSocket Response.\n        upgrade_header = request.headers.get('Upgrade')\n        if not upgrade_header or upgrade_header != 'websocket':\n          return Response('Worker expected Upgrade: websocket', status=426)\n\nif request.method != 'GET':\n          return Response('Worker expected GET method', status=400)\n\n# Since we are hard coding the Durable Object ID by providing the constant name 'foo',\n        # all requests to this Worker will be sent to the same Durable Object instance.\n        stub = self.env.WEBSOCKET_HIBERNATION_SERVER.getByName(\"foo\")\n\nreturn await stub.fetch(request)\n\nreturn Response(\n        \"\"\"Supported endpoints:\n  /websocket: Expects a WebSocket upgrade request\"\"\",\n        status=200,\n        headers={'Content-Type': 'text/plain'}\n      )\n\n# Durable Object\n  class WebSocketHibernationServer(DurableObject):\n    def __init__(self, ctx, env):\n      super().__init__(ctx, env)\n      # Keeps track of all WebSocket connections, keyed by session ID\n      # When the DO hibernates, gets reconstructed in the constructor\n      self.sessions = {}\n\n# As part of constructing the Durable Object,\n      # we wake up any hibernating WebSockets and\n      # place them back in the `sessions` map.\n\n# Get all WebSocket connections from the DO\n      for ws in self.ctx.getWebSockets():\n        attachment = ws.deserializeAttachment()\n        if attachment:\n          # If we previously attached state to our WebSocket,\n          # let's add it to `sessions` map to restore the state of the connection.\n          # Use the session ID as the key\n          self.sessions[attachment] = Session(ws=ws)\n\n# Sets an application level auto response that does not wake hibernated WebSockets.\n      self.ctx.setWebSocketAutoResponse(WebSocketRequestResponsePair.new('ping', 'pong'))\n\nasync def fetch(self, request):\n      # Creates two ends of a WebSocket connection.\n      client, server = WebSocketPair.new().object_values()\n\n# Calling `acceptWebSocket()` informs the runtime that this WebSocket is to begin terminating\n      # request within the Durable Object. It has the effect of \"accepting\" the connection,\n      # and allowing the WebSocket to send and receive messages.\n      # Unlike `ws.accept()`, `this.ctx.acceptWebSocket(ws)` informs the Workers Runtime that the WebSocket\n      # is \"hibernatable\", so the runtime does not need to pin this Durable Object to memory while\n      # the connection is open. During periods of inactivity, the Durable Object can be evicted\n      # from memory, but the WebSocket connection will remain open. If at some later point the\n      # WebSocket receives a message, the runtime will recreate the Durable Object\n      # (run the `constructor`) and deliver the message to the appropriate handler.\n      self.ctx.acceptWebSocket(server)\n\n# Generate a random UUID for the session.\n      id = str(uuid.uuid4())\n\n# Attach the session ID to the WebSocket connection and serialize it.\n      # This is necessary to restore the state of the connection when the Durable Object wakes up.\n      server.serializeAttachment(id)\n\n# Add the WebSocket connection to the map of active sessions, keyed by session ID.\n      self.sessions[id] = Session(ws=server)\n\nreturn Response(None, status=101, web_socket=client)\n\nasync def webSocketMessage(self, ws, message):\n      # Get the session ID associated with the WebSocket connection.\n      session_id = ws.deserializeAttachment()\n\n# Upon receiving a message from the client, the server replies with the same message, the session ID of the connection,\n      # and the total number of connections with the \"[Durable Object]: \" prefix\n      ws.send(f\"[Durable Object] message: {message}, from: {session_id}, to: the initiating client. Total connections: {len(self.sessions)}\")\n\n# Send a message to all WebSocket connections, loop over all the connected WebSockets.\n      for session in self.sessions.values():\n        session.ws.send(f\"[Durable Object] message: {message}, from: {session_id}, to: all clients. Total connections: {len(self.sessions)}\")\n\n# Send a message to all WebSocket connections except the connection (ws),\n      # loop over all the connected WebSockets and filter out the connection (ws).\n      for session in self.sessions.values():\n        if session.ws != ws:\n          session.ws.send(f\"[Durable Object] message: {message}, from: {session_id}, to: all clients except the initiating client. Total connections: {len(self.sessions)}\")\n\nasync def webSocketClose(self, ws, code, reason, wasClean):\n      # If the client closes the connection, the runtime will invoke the webSocketClose() handler.\n      # Get the session ID from the WebSocket attachment to remove it from sessions\n      session_id = ws.deserializeAttachment()\n      if session_id:\n        self.sessions.pop(session_id, None)\n      ws.close(code, 'Durable Object is closing WebSocket')\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"websocket-hibernation-server\",\n    \"main\": \"src/index.ts\",\n    \"durable_objects\": {\n      \"bindings\": [\n        {\n          \"name\": \"WEBSOCKET_HIBERNATION_SERVER\",\n          \"class_name\": \"WebSocketHibernationServer\"\n        }\n      ]\n    },\n    \"migrations\": [\n      {\n        \"tag\": \"v1\",\n        \"new_sqlite_classes\": [\n          \"WebSocketHibernationServer\"\n        ]\n      }\n    ]\n  }\n  toml\n  name = \"websocket-hibernation-server\"\n  main = \"src/index.ts\"\n\n[[durable_objects.bindings]]\n  name = \"WEBSOCKET_HIBERNATION_SERVER\"\n  class_name = \"WebSocketHibernationServer\"\n\n[[migrations]]\n  tag = \"v1\"\n  new_sqlite_classes = [\"WebSocketHibernationServer\"]\n  js\n  import { DurableObject } from \"cloudflare:workers\";\n\n// Worker\n  export default {\n    async fetch(request, env, ctx) {\n      if (request.url.endsWith(\"/websocket\")) {\n        // Expect to receive a WebSocket Upgrade request.\n        // If there is one, accept the request and return a WebSocket Response.\n        const upgradeHeader = request.headers.get(\"Upgrade\");\n        if (!upgradeHeader || upgradeHeader !== \"websocket\") {\n          return new Response(\"Worker expected Upgrade: websocket\", {\n            status: 426,\n          });\n        }\n\nif (request.method !== \"GET\") {\n          return new Response(\"Worker expected GET method\", {\n            status: 400,\n          });\n        }\n\n// Since we are hard coding the Durable Object ID by providing the constant name 'foo',\n        // all requests to this Worker will be sent to the same Durable Object instance.\n        let id = env.WEBSOCKET_SERVER.idFromName(\"foo\");\n        let stub = env.WEBSOCKET_SERVER.get(id);\n\nreturn stub.fetch(request);\n      }\n\nreturn new Response(\n        `Supported endpoints:\n  /websocket: Expects a WebSocket upgrade request`,\n        {\n          status: 200,\n          headers: {\n            \"Content-Type\": \"text/plain\",\n          },\n        },\n      );\n    },\n  };\n\n// Durable Object\n  export class WebSocketServer extends DurableObject {\n    // Keeps track of all WebSocket connections\n    sessions;\n\nconstructor(ctx, env) {\n      super(ctx, env);\n      this.sessions = new Map();\n    }\n\nasync fetch(request) {\n      // Creates two ends of a WebSocket connection.\n      const webSocketPair = new WebSocketPair();\n      const [client, server] = Object.values(webSocketPair);\n\n// Calling `accept()` tells the runtime that this WebSocket is to begin terminating\n      // request within the Durable Object. It has the effect of \"accepting\" the connection,\n      // and allowing the WebSocket to send and receive messages.\n      server.accept();\n\n// Generate a random UUID for the session.\n      const id = crypto.randomUUID();\n      // Add the WebSocket connection to the map of active sessions.\n      this.sessions.set(server, { id });\n\nserver.addEventListener(\"message\", (event) => {\n        this.handleWebSocketMessage(server, event.data);\n      });\n\n// If the client closes the connection, the runtime will close the connection too.\n      server.addEventListener(\"close\", () => {\n        this.handleConnectionClose(server);\n      });\n\nreturn new Response(null, {\n        status: 101,\n        webSocket: client,\n      });\n    }\n\nasync handleWebSocketMessage(ws, message) {\n      const connection = this.sessions.get(ws);\n\n// Reply back with the same message to the connection\n      ws.send(\n        `[Durable Object] message: ${message}, from: ${connection.id}, to: the initiating client. Total connections: ${this.sessions.size}`,\n      );\n\n// Broadcast the message to all the connections,\n      // except the one that sent the message.\n      this.sessions.forEach((_, session) => {\n        if (session !== ws) {\n          session.send(\n            `[Durable Object] message: ${message}, from: ${connection.id}, to: all clients except the initiating client. Total connections: ${this.sessions.size}`,\n          );\n        }\n      });\n\n// Broadcast the message to all the connections,\n      // including the one that sent the message.\n      this.sessions.forEach((_, session) => {\n        session.send(\n          `[Durable Object] message: ${message}, from: ${connection.id}, to: all clients. Total connections: ${this.sessions.size}`,\n        );\n      });\n    }\n\nasync handleConnectionClose(ws) {\n      this.sessions.delete(ws);\n      ws.close(1000, \"Durable Object is closing WebSocket\");\n    }\n  }\n  ts\n  import { DurableObject } from 'cloudflare:workers';\n\n// Worker\n  export default {\n      async fetch(request: Request, env: Env, ctx: ExecutionContext): Promise<Response> {\n          if (request.url.endsWith('/websocket')) {\n              // Expect to receive a WebSocket Upgrade request.\n              // If there is one, accept the request and return a WebSocket Response.\n              const upgradeHeader = request.headers.get('Upgrade');\n              if (!upgradeHeader || upgradeHeader !== 'websocket') {\n                  return new Response('Worker expected Upgrade: websocket', {\n                      status: 426,\n                  });\n              }\n\nif (request.method !== 'GET') {\n                  return new Response('Worker expected GET method', {\n                      status: 400,\n                  });\n              }\n\n// Since we are hard coding the Durable Object ID by providing the constant name 'foo',\n              // all requests to this Worker will be sent to the same Durable Object instance.\n              let id = env.WEBSOCKET_SERVER.idFromName('foo');\n              let stub = env.WEBSOCKET_SERVER.get(id);\n\nreturn stub.fetch(request);\n          }\n\nreturn new Response(\n              `Supported endpoints:\n  /websocket: Expects a WebSocket upgrade request`,\n              {\n                  status: 200,\n                  headers: {\n                      'Content-Type': 'text/plain',\n                  },\n              }\n          );\n      },\n  };\n\n// Durable Object\n  export class WebSocketServer extends DurableObject {\n      // Keeps track of all WebSocket connections\n      sessions: Map<WebSocket, { [key: string]: string }>;\n\nconstructor(ctx: DurableObjectState, env: Env) {\n          super(ctx, env);\n          this.sessions = new Map();\n      }\n\nasync fetch(request: Request): Promise<Response> {\n          // Creates two ends of a WebSocket connection.\n          const webSocketPair = new WebSocketPair();\n          const [client, server] = Object.values(webSocketPair);\n\n// Calling `accept()` tells the runtime that this WebSocket is to begin terminating\n          // request within the Durable Object. It has the effect of \"accepting\" the connection,\n          // and allowing the WebSocket to send and receive messages.\n          server.accept();\n\n// Generate a random UUID for the session.\n          const id = crypto.randomUUID();\n          // Add the WebSocket connection to the map of active sessions.\n          this.sessions.set(server, { id });\n\nserver.addEventListener('message', (event) => {\n              this.handleWebSocketMessage(server, event.data);\n          });\n\n// If the client closes the connection, the runtime will close the connection too.\n          server.addEventListener('close', () => {\n              this.handleConnectionClose(server);\n          });\n\nreturn new Response(null, {\n              status: 101,\n              webSocket: client,\n          });\n      }\n\nasync handleWebSocketMessage(ws: WebSocket, message: string | ArrayBuffer) {\n          const connection = this.sessions.get(ws)!;\n\n// Reply back with the same message to the connection\n          ws.send(`[Durable Object] message: ${message}, from: ${connection.id}, to: the initiating client. Total connections: ${this.sessions.size}`);\n\n// Broadcast the message to all the connections,\n          // except the one that sent the message.\n          this.sessions.forEach((_, session) => {\n              if (session !== ws) {\n                  session.send(`[Durable Object] message: ${message}, from: ${connection.id}, to: all clients except the initiating client. Total connections: ${this.sessions.size}`);\n              }\n          });\n\n// Broadcast the message to all the connections,\n          // including the one that sent the message.\n          this.sessions.forEach((_, session) => {\n              session.send(`[Durable Object] message: ${message}, from: ${connection.id}, to: all clients. Total connections: ${this.sessions.size}`);\n          });\n      }\n\nasync handleConnectionClose(ws: WebSocket) {\n          this.sessions.delete(ws);\n          ws.close(1000, 'Durable Object is closing WebSocket');\n      }\n  }\n  py\n  from workers import DurableObject, Response, WorkerEntrypoint\n  from js import WebSocketPair\n  from pyodide.ffi import create_proxy\n  import uuid\n\nclass Session:\n    def __init__(self, *, ws):\n      self.ws = ws\n\n# Worker\n  class Default(WorkerEntrypoint):\n    async def fetch(self, request):\n      if request.url.endswith('/websocket'):\n        # Expect to receive a WebSocket Upgrade request.\n        # If there is one, accept the request and return a WebSocket Response.\n        upgrade_header = request.headers.get('Upgrade')\n        if not upgrade_header or upgrade_header != 'websocket':\n          return Response('Worker expected Upgrade: websocket', status=426)\n\nif request.method != 'GET':\n          return Response('Worker expected GET method', status=400)\n\n# Since we are hard coding the Durable Object ID by providing the constant name 'foo',\n        # all requests to this Worker will be sent to the same Durable Object instance.\n        id = self.env.WEBSOCKET_SERVER.idFromName('foo')\n        stub = self.env.WEBSOCKET_SERVER.get(id)\n\nreturn await stub.fetch(request)\n\nreturn Response(\n        \"\"\"Supported endpoints:\n  /websocket: Expects a WebSocket upgrade request\"\"\",\n        status=200,\n        headers={'Content-Type': 'text/plain'}\n      )\n\n# Durable Object\n  class WebSocketServer(DurableObject):\n    def __init__(self, ctx, env):\n      super().__init__(ctx, env)\n      # Keeps track of all WebSocket connections, keyed by session ID\n      self.sessions = {}\n\nasync def fetch(self, request):\n      # Creates two ends of a WebSocket connection.\n      client, server = WebSocketPair.new().object_values()\n\n# Calling `accept()` tells the runtime that this WebSocket is to begin terminating\n      # request within the Durable Object. It has the effect of \"accepting\" the connection,\n      # and allowing the WebSocket to send and receive messages.\n      server.accept()\n\n# Generate a random UUID for the session.\n      id = str(uuid.uuid4())\n\n# Create proxies for event handlers (must be destroyed when socket closes)\n      async def on_message(event):\n        await self.handleWebSocketMessage(id, event.data)\n\nmessage_proxy = create_proxy(on_message)\n      server.addEventListener('message', message_proxy)\n\n# If the client closes the connection, the runtime will close the connection too.\n      async def on_close(event):\n        await self.handleConnectionClose(id)\n        # Clean up proxies\n        message_proxy.destroy()\n        close_proxy.destroy()\n\nclose_proxy = create_proxy(on_close)\n      server.addEventListener('close', close_proxy)\n\n# Add the WebSocket connection to the map of active sessions, keyed by session ID.\n      self.sessions[id] = Session(ws=server)\n\nreturn Response(None, status=101, web_socket=client)\n\nasync def handleWebSocketMessage(self, session_id, message):\n      session = self.sessions[session_id]\n\n# Reply back with the same message to the connection\n      session.ws.send(f\"[Durable Object] message: {message}, from: {session_id}, to: the initiating client. Total connections: {len(self.sessions)}\")\n\n# Broadcast the message to all the connections,\n      # except the one that sent the message.\n      for id, conn in self.sessions.items():\n        if id != session_id:\n          conn.ws.send(f\"[Durable Object] message: {message}, from: {session_id}, to: all clients except the initiating client. Total connections: {len(self.sessions)}\")\n\n# Broadcast the message to all the connections,\n      # including the one that sent the message.\n      for id, conn in self.sessions.items():\n        conn.ws.send(f\"[Durable Object] message: {message}, from: {session_id}, to: all clients. Total connections: {len(self.sessions)}\")\n\nasync def handleConnectionClose(self, session_id):\n      session = self.sessions.pop(session_id, None)\n      if session:\n        session.ws.close(1000, 'Durable Object is closing WebSocket')\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"websocket-server\",\n    \"main\": \"src/index.ts\",\n    \"durable_objects\": {\n      \"bindings\": [\n        {\n          \"name\": \"WEBSOCKET_SERVER\",\n          \"class_name\": \"WebSocketServer\"\n        }\n      ]\n    },\n    \"migrations\": [\n      {\n        \"tag\": \"v1\",\n        \"new_sqlite_classes\": [\n          \"WebSocketServer\"\n        ]\n      }\n    ]\n  }\n  toml\n  name = \"websocket-server\"\n  main = \"src/index.ts\"\n\n[[durable_objects.bindings]]\n  name = \"WEBSOCKET_SERVER\"\n  class_name = \"WebSocketServer\"\n\n[[migrations]]\n  tag = \"v1\"\n  new_sqlite_classes = [\"WebSocketServer\"]\n  jsonc\n     {\n         \"observability\": {\n             \"enabled\": true\n         }\n     }\n     toml\n     [observability]\n     enabled = true\n     js\n  viewer {\n    /*\n    Replace with your account tag, the 32 hex character id visible at the beginning of any url\n    when logged in to dash.cloudflare.com or under \"Account ID\" on the sidebar of the Workers & Pages Overview\n    */\n    accounts(filter: {accountTag: \"your account tag here\"}) {\n      // Replace dates with a recent date\n      durableObjectsInvocationsAdaptiveGroups(filter: {date_gt: \"2023-05-23\"}, limit: 1000) {\n        sum {\n          // Any other fields found through introspection can be added here\n          requests\n          responseBodySize\n        }\n      }\n      durableObjectsPeriodicGroups(filter: {date_gt: \"2023-05-23\"}, limit: 1000) {\n        sum {\n          cpuTime\n        }\n      }\n      durableObjectsStorageGroups(filter: {date_gt: \"2023-05-23\"}, limit: 1000) {\n        max {\n          storedBytes\n        }\n      }\n    }\n  }\njsonc\n  {\n    // ...rest of your configuration...\n    \"limits\": {\n      \"cpu_ms\": 300000, // 300,000 milliseconds = 5 minutes\n    },\n    // ...rest of your configuration...\n  }\n  toml\n  [limits]\n  cpu_ms = 300_000\n  js\nlet durableObjectStub = OBJECT_NAMESPACE.get(id); // retrieve Durable Object stub\nusing foo = await durableObjectStub.bar(); // billed as a request\nawait foo.baz(); // treated as part of the same RPC session created by calling bar(), not billed as a request\nawait durableObjectStub.cat(); // billed as a request\njs\nconst euSubnamespace = env.MY_DURABLE_OBJECT.jurisdiction(\"eu\");\nconst euId = euSubnamespace.newUniqueId();\njs\n  const euId1 = env.MY_DURABLE_OBJECT.idFromName(\"my-name\");\n  const euId2 = env.MY_DURABLE_OBJECT.jurisdiction(\"eu\").idFromName(\"my-name\");\n  console.assert(!euId1.equal(euId2), \"This should always be true\");\n  js\n  const euSubnamespace = env.MY_DURABLE_OBJECT.jurisdiction(\"eu\");\n  const euId = euSubnamespace.idFromName(name);\n  const stub = env.MY_DURABLE_OBJECT.get(euId);\n  js\nlet durableObjectStub = OBJECT_NAMESPACE.get(id, { locationHint: \"enam\" });\njsonc\n     {\n       \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n       \"migrations\": [\n         {\n           \"tag\": \"<v1>\",\n           \"new_sqlite_classes\": [\n             \"<NewDurableObjectClass>\"\n           ]\n         }\n       ]\n     }\n     toml\n     [[migrations]]\n     tag = \"<v1>\" # Migration identifier. This should be unique for each migration entry\n     new_sqlite_classes = [\"<NewDurableObjectClass>\"] # Array of new classes\n     # For SQLite storage backend use new_sqlite_classes=[\"<NewDurableObjectClass>\"] instead\n     jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"durable_objects\": {\n      \"bindings\": [\n        {\n          \"name\": \"DURABLE_OBJECT_A\",\n          \"class_name\": \"DurableObjectAClass\"\n        }\n      ]\n    },\n    \"migrations\": [\n      {\n        \"tag\": \"v1\",\n        \"new_sqlite_classes\": [\n          \"DurableObjectAClass\"\n        ]\n      }\n    ]\n  }\n  toml\n  # Creating a new Durable Object class\n  [[durable_objects.bindings]]\n  name = \"DURABLE_OBJECT_A\"\n  class_name = \"DurableObjectAClass\"\n\n# Add the lines below for a Create migration.\n\n[[migrations]]\n  tag = \"v1\"\n  new_sqlite_classes = [\"DurableObjectAClass\"]\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"migrations\": [\n      {\n        \"tag\": \"v1\",\n        \"new_classes\": [\n          \"MyDurableObject\"\n        ]\n      }\n    ]\n  }\n  toml\n  [[migrations]]\n  tag = \"v1\" # Should be unique for each entry\n  new_classes = [\"MyDurableObject\"] # Array of new classes\n  jsonc\n     {\n       \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n       \"migrations\": [\n         {\n           \"tag\": \"<v2>\",\n           \"deleted_classes\": [\n             \"<ClassToDelete>\"\n           ]\n         }\n       ]\n     }\n     toml\n     [[migrations]]\n     tag = \"<v2>\" # Migration identifier. This should be unique for each migration entry\n     deleted_classes = [\"<ClassToDelete>\"] # Array of deleted class names\n     jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"migrations\": [\n      {\n        \"tag\": \"v3\",\n        \"deleted_classes\": [\n          \"DeprecatedObjectClass\"\n        ]\n      }\n    ]\n  }\n  toml\n  # Remove the binding for the DeprecatedObjectClass DO\n  #[[durable_objects.bindings]]\n  #name = \"DEPRECATED_OBJECT\"\n  #class_name = \"DeprecatedObjectClass\"\n\n[[migrations]]\n  tag = \"v3\" # Should be unique for each entry\n  deleted_classes = [\"DeprecatedObjectClass\"] # Array of deleted classes\n  jsonc\n     {\n       \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n       \"durable_objects\": {\n         \"bindings\": [\n           {\n             \"name\": \"<MY_DURABLE_OBJECT>\",\n             \"class_name\": \"<UpdatedDurableObject>\"\n           }\n         ]\n       },\n       \"migrations\": [\n         {\n           \"tag\": \"<v3>\",\n           \"renamed_classes\": [\n             {\n               \"from\": \"<OldDurableObject>\",\n               \"to\": \"<UpdatedDurableObject>\"\n             }\n           ]\n         }\n       ]\n     }\n     toml\n     [[durable_objects.bindings]]\n     name = \"<MY_DURABLE_OBJECT>\"\n     class_name = \"<UpdatedDurableObject>\" # Update the class name to the new class name\n\n[[migrations]]\n     tag = \"<v3>\" # Migration identifier. This should be unique for each migration entry\n     renamed_classes = [{from = \"<OldDurableObject>\", to = \"<UpdatedDurableObject>\" }] # Array of rename directives\n     jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"durable_objects\": {\n      \"bindings\": [\n        {\n          \"name\": \"MY_DURABLE_OBJECT\",\n          \"class_name\": \"UpdatedName\"\n        }\n      ]\n    },\n    \"migrations\": [\n      {\n        \"tag\": \"v3\",\n        \"renamed_classes\": [\n          {\n            \"from\": \"OldName\",\n            \"to\": \"UpdatedName\"\n          }\n        ]\n      }\n    ]\n  }\n  toml\n  # Before deleting the `DeprecatedClass` remove the binding for the `DeprecatedClass`.\n  # Update the binding for the `DurableObjectExample` to the new class name `UpdatedName`.\n  [[durable_objects.bindings]]\n  name = \"MY_DURABLE_OBJECT\"\n  class_name = \"UpdatedName\"\n\n# Renaming classes\n  [[migrations]]\n  tag = \"v3\"\n  renamed_classes = [{from = \"OldName\", to = \"UpdatedName\" }] # Array of rename directives\n  jsonc\n     {\n       \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n       \"durable_objects\": {\n         \"bindings\": [\n           {\n             \"name\": \"<MY_DURABLE_OBJECT>\",\n             \"class_name\": \"<DestinationDurableObjectClass>\"\n           }\n         ]\n       },\n       \"migrations\": [\n         {\n           \"tag\": \"<v4>\",\n           \"transferred_classes\": [\n             {\n               \"from\": \"<SourceDurableObjectClass>\",\n               \"from_script\": \"<SourceWorkerScript>\",\n               \"to\": \"<DestinationDurableObjectClass>\"\n             }\n           ]\n         }\n       ]\n     }\n     toml\n     [[durable_objects.bindings]]\n     name = \"<MY_DURABLE_OBJECT>\"\n     class_name = \"<DestinationDurableObjectClass>\"\n\n[[migrations]]\n     tag = \"<v4>\" # Migration identifier. This should be unique for each migration entry\n     transferred_classes = [{from = \"<SourceDurableObjectClass>\", from_script = \"<SourceWorkerScript>\", to = \"<DestinationDurableObjectClass>\" }]\n     jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"durable_objects\": {\n      \"bindings\": [\n        {\n          \"name\": \"MY_DURABLE_OBJECT\",\n          \"class_name\": \"TransferredClass\"\n        }\n      ]\n    },\n    \"migrations\": [\n      {\n        \"tag\": \"v4\",\n        \"transferred_classes\": [\n          {\n            \"from\": \"DurableObjectExample\",\n            \"from_script\": \"OldWorkerScript\",\n            \"to\": \"TransferredClass\"\n          }\n        ]\n      }\n    ]\n  }\n  toml\n  # destination worker\n  [[durable_objects.bindings]]\n  name = \"MY_DURABLE_OBJECT\"\n  class_name = \"TransferredClass\"\n\n[[migrations]]\n  tag = \"v4\"\n  transferred_classes = [{from = \"DurableObjectExample\", from_script = \"OldWorkerScript\", to = \"TransferredClass\" }]\n  jsonc\n    {\n    // top-level default migrations\n    \"migrations\": [{ ... }],\n    \"env\": {\n    \"staging\": {\n      // migration override for staging\n      \"migrations\": [{...}]\n      }\n     }\n    }\n    plaintext\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"env\": {\n      \"staging\": {\n        \"durable_objects\": {\n          \"bindings\": [\n            {\n              \"name\": \"EXAMPLE_CLASS\",\n              \"class_name\": \"DurableObjectExample\"\n            }\n          ]\n        }\n      }\n    }\n  }\n  toml\n  [env.staging]\n  durable_objects.bindings = [\n    {name = \"EXAMPLE_CLASS\", class_name = \"DurableObjectExample\"}\n  ]\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"env\": {\n      \"staging\": {\n        \"durable_objects\": {\n          \"bindings\": [\n            {\n              \"name\": \"EXAMPLE_CLASS\",\n              \"class_name\": \"DurableObjectExample\",\n              \"script_name\": \"worker-name-staging\"\n            }\n          ]\n        }\n      }\n    }\n  }\n  toml\n  [env.staging]\n  durable_objects.bindings = [\n    {name = \"EXAMPLE_CLASS\", class_name = \"DurableObjectExample\", script_name = \"worker-name-staging\"}\n  ]\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"env\": {\n      \"another\": {\n        \"durable_objects\": {\n          \"bindings\": [\n            {\n              \"name\": \"EXAMPLE_CLASS\",\n              \"class_name\": \"DurableObjectExample\",\n              \"script_name\": \"worker-name\"\n            }\n          ]\n        }\n      }\n    }\n  }\n  toml\n  [env.another]\n  durable_objects.bindings = [\n    {name = \"EXAMPLE_CLASS\", class_name = \"DurableObjectExample\", script_name = \"worker-name\"}\n  ]\n  jsonc\n  {\n    // ...rest of your configuration...\n    \"limits\": {\n      \"cpu_ms\": 300000, // 300,000 milliseconds = 5 minutes\n    },\n    // ...rest of your configuration...\n  }\n  toml\n  [limits]\n  cpu_ms = 300_000\n  js\nimport { DurableObject } from \"cloudflare:workers\";\n\nexport class Counter extends DurableObject {\n  constructor(ctx, env) {\n    super(ctx, env);\n    // `blockConcurrencyWhile()` ensures no requests are delivered until\n    // initialization completes.\n    this.ctx.blockConcurrencyWhile(async () => {\n      let stored = await this.ctx.storage.get(\"value\");\n      // After initialization, future reads do not need to access storage.\n      this.value = stored || 0;\n    });\n  }\n\n// Handle HTTP requests from clients.\n  async fetch(request) {\n    // use this.value rather than storage\n  }\n}\nsh\n     npm create cloudflare@latest -- seat-booking\n     sh\n     yarn create cloudflare seat-booking\n     sh\n     pnpm create cloudflare@latest seat-booking\n     sh\ncd seat-booking\nhtml\n<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"UTF-8\" />\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    <title>Flight Seat Booking</title>\n    <style>\n      body {\n        font-family: Arial, sans-serif;\n        display: flex;\n        justify-content: center;\n        align-items: center;\n        height: 100vh;\n        margin: 0;\n        background-color: #f0f0f0;\n      }\n      .booking-container {\n        background-color: white;\n        padding: 20px;\n        border-radius: 8px;\n        box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);\n      }\n      .seat-grid {\n        display: grid;\n        grid-template-columns: repeat(7, 1fr);\n        gap: 10px;\n        margin-top: 20px;\n      }\n      .aisle {\n        grid-column: 4;\n      }\n      .seat {\n        width: 40px;\n        height: 40px;\n        display: flex;\n        justify-content: center;\n        align-items: center;\n        border: 1px solid #ccc;\n        cursor: pointer;\n      }\n      .seat.available {\n        background-color: #5dbf61ba;\n        color: white;\n      }\n      .seat.unavailable {\n        background-color: #f4433673;\n        color: white;\n        cursor: not-allowed;\n      }\n      .airplane {\n        display: flex;\n        flex-direction: column;\n        align-items: center;\n        background-color: #f0f0f0;\n        padding: 20px;\n        border-radius: 20px;\n      }\n    </style>\n  </head>\n  <body>\n    <div class=\"booking-container\">\n      <h2 id=\"title\"></h2>\n      <div class=\"airplane\">\n        <div id=\"seatGrid\" class=\"seat-grid\"></div>\n      </div>\n    </div>\n\n<script>\n        const seatGrid = document.getElementById(\"seatGrid\");\n        const title = document.getElementById(\"title\");\n\nconst flightId = window.location.search.split(\"=\")[1];\n\nconst hostname = window.location.hostname;\n\nif (flightId === undefined) {\n          title.textContent = \"No Flight ID provided\";\n          seatGrid.innerHTML = \"<p>Add `flightId` to the query string</p>\";\n        } else {\n          handleBooking();\n        }\n\nfunction handleBooking() {\n          let ws;\n          if (hostname === 'localhost') {\n            const port = window.location.port;\n            ws = new WebSocket(`ws://${hostname}:${port}/ws?flightId=${flightId}`);\n          } else {\n            ws = new WebSocket(`wss://${hostname}/ws?flightId=${flightId}`);\n          }\n\ntitle.textContent = `Book seat for flight ${flightId}`;\n\nws.onopen = () => {\n            console.log(\"Connected to WebSocket server\");\n          };\n\nfunction createSeatGrid(seats) {\n            seatGrid.innerHTML = \"\";\n            for (let row = 1; row <= 10; row++) {\n              for (let col = 0; col < 6; col++) {\n                if (col === 3) {\n                  const aisle = document.createElement(\"div\");\n                  aisle.className = \"aisle\";\n                  seatGrid.appendChild(aisle);\n                }\n\nconst seatNumber = `${row}${String.fromCharCode(65 + col)}`;\n                const seat = seats.find((s) => s.seatNumber === seatNumber);\n                const seatElement = document.createElement(\"div\");\n                seatElement.className = `seat ${seat && seat.occupant ? \"unavailable\" : \"available\"}`;\n                seatElement.textContent = seatNumber;\n                seatElement.onclick = () => bookSeat(seatNumber);\n                seatGrid.appendChild(seatElement);\n              }\n            }\n          }\n\nasync function fetchSeats() {\n            const response = await fetch(`/seats?flightId=${flightId}`);\n            const seats = await response.json();\n            createSeatGrid(seats);\n          }\n\nasync function bookSeat(seatNumber) {\n            const name = prompt(\"Please enter your name:\");\n            if (!name) {\n              return; // User canceled the prompt\n            }\n\nconst response = await fetch(`book-seat?flightId=${flightId}`, {\n              method: \"POST\",\n              headers: { \"Content-Type\": \"application/json\" },\n              body: JSON.stringify({ seatNumber, name }),\n            });\n            const result = await response.text();\n            fetchSeats();\n          }\n\nws.onmessage = (event) => {\n            try {\n              const seats = JSON.parse(event.data);\n              createSeatGrid(seats);\n            } catch (error) {\n              console.error(\"Error parsing WebSocket message:\", error);\n            }\n          };\n\nws.onerror = (error) => {\n            console.error(\"WebSocket error:\", error);\n          };\n\nws.onclose = (event) => {\n            console.log(\"WebSocket connection closed:\", event);\n          };\n\nfetchSeats();\n        }\n      </script>\n    </body>\n\n</html>\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"assets\": {\n      \"directory\": \"public\"\n    }\n  }\n  toml\n  [assets]\n  directory = \"public\"\n  bash\nnpm run dev\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"durable_objects\": {\n      \"bindings\": [\n        {\n          \"name\": \"FLIGHT\",\n          \"class_name\": \"Flight\"\n        }\n      ]\n    },\n    \"migrations\": [\n      {\n        \"tag\": \"v1\",\n        \"new_sqlite_classes\": [\n          \"Flight\"\n        ]\n      }\n    ]\n  }\n  toml\n  [[durable_objects.bindings]]\n  name = \"FLIGHT\"\n  class_name = \"Flight\"\n\n# Durable Object migrations.\n  # Docs: https://developers.cloudflare.com/workers/wrangler/configuration/#migrations\n  [[migrations]]\n  tag = \"v1\"\n  new_sqlite_classes = [\"Flight\"]\n  ts\nimport { DurableObject } from \"cloudflare:workers\";\n\nexport class Flight extends DurableObject {\n  sql = this.ctx.storage.sql;\n\nconstructor(ctx: DurableObjectState, env: Env) {\n    super(ctx, env);\n    this.initializeSeats();\n  }\n\nprivate initializeSeats() {\n    const cursor = this.sql.exec(`PRAGMA table_list`);\n\n// Check if a table exists.\n    if ([...cursor].find((t) => t.name === \"seats\")) {\n      console.log(\"Table already exists\");\n      return;\n    }\n\nthis.sql.exec(`\n          CREATE TABLE IF NOT EXISTS seats (\n          seatId TEXT PRIMARY KEY,\n          occupant TEXT\n          )\n        `);\n\n// For this demo, we populate the table with 60 seats.\n    // Since SQLite in DOs is fast, we can do a query per INSERT instead of batching them in a transaction.\n    for (let row = 1; row <= 10; row++) {\n      for (let col = 0; col < 6; col++) {\n        const seatNumber = `${row}${String.fromCharCode(65 + col)}`;\n        this.sql.exec(`INSERT INTO seats VALUES (?, null)`, seatNumber);\n      }\n    }\n  }\n}\nts\nimport { DurableObject } from \"cloudflare:workers\";\n\nexport class Flight extends DurableObject {\n  ...\n  async fetch(request: Request): Promise<Response> {\n    return new Response(\"Hello from Durable Object!\", { status: 200 });\n  }\n}\nts\nexport default {\n  async fetch(request, env, ctx): Promise<Response> {\n    // Get flight id from the query parameter\n    const url = new URL(request.url);\n    const flightId = url.searchParams.get(\"flightId\");\n\nif (!flightId) {\n      return new Response(\n        \"Flight ID not found. Provide flightId in the query parameter\",\n        { status: 404 },\n      );\n    }\n\nconst stub = env.FLIGHT.getByName(flightId);\n    return stub.fetch(request);\n  },\n} satisfies ExportedHandler<Env>;\nts\nimport { DurableObject } from \"cloudflare:workers\";\n\nexport class Flight extends DurableObject {\n    ...\n\nprivate initializeSeats() {\n    ...\n  }\n\n// Get all seats.\n  getSeats() {\n    let results = [];\n\n// Query returns a cursor.\n    let cursor = this.sql.exec(`SELECT seatId, occupant FROM seats`);\n\n// Cursors are iterable.\n    for (let row of cursor) {\n      // Each row is an object with a property for each column.\n      results.push({ seatNumber: row.seatId, occupant: row.occupant });\n    }\n\nreturn results;\n  }\n}\nts\nimport { DurableObject } from \"cloudflare:workers\";\n\nexport class Flight extends DurableObject {\n  ...\n\nprivate initializeSeats() {\n    ...\n  }\n\n// Get all seats.\n  getSeats() {\n    ...\n  }\n\n// Assign a seat to a passenger.\n  assignSeat(seatId: string, occupant: string) {\n    // Check that seat isn't occupied.\n    let cursor = this.sql.exec(\n      `SELECT occupant FROM seats WHERE seatId = ?`,\n      seatId,\n    );\n    let result = cursor.toArray()[0]; // Get the first result from the cursor.\n\nif (!result) {\n      return {message: 'Seat not available',  status: 400 };\n    }\n    if (result.occupant !== null) {\n      return {message: 'Seat not available',  status: 400 };\n    }\n\n// If the occupant is already in a different seat, remove them.\n    this.sql.exec(\n      `UPDATE seats SET occupant = null WHERE occupant = ?`,\n      occupant,\n    );\n\n// Assign the seat. Note: We don't have to worry that a concurrent request may\n    // have grabbed the seat between the two queries, because the code is synchronous\n    // (no `await`s) and the database is private to this Durable Object. Nothing else\n    // could have changed since we checked that the seat was available earlier!\n    this.sql.exec(\n      `UPDATE seats SET occupant = ? WHERE seatId = ?`,\n      occupant,\n      seatId,\n    );\n\n// Broadcast the updated seats.\n    this.broadcastSeats();\n    return {message: `Seat ${seatId} booked successfully`, status: 200 };\n  }\n}\nts\nimport { DurableObject } from \"cloudflare:workers\";\n\nexport class Flight extends DurableObject {\n  ...\n\nprivate initializeSeats() {\n    ...\n  }\n\n// Get all seats.\n  getSeats() {\n    ...\n  }\n\n// Assign a seat to a passenger.\n  assignSeat(seatId: string, occupant: string) {\n    ...\n  }\n\nprivate handleWebSocket(request: Request) {\n    console.log('WebSocket connection requested');\n    const [client, server] = Object.values(new WebSocketPair());\n\nthis.ctx.acceptWebSocket(server);\n    console.log('WebSocket connection established');\n\nreturn new Response(null, { status: 101, webSocket: client });\n  }\n}\nts\nimport { DurableObject } from \"cloudflare:workers\";\n\nexport class Flight extends DurableObject {\n  ...\n\nprivate initializeSeats() {\n    ...\n  }\n\n// Get all seats.\n  getSeats() {\n    ...\n  }\n\n// Assign a seat to a passenger.\n  assignSeat(seatId: string, occupant: string) {\n    ...\n  }\n\nprivate handleWebSocket(request: Request) {\n    ...\n  }\n\nprivate broadcastSeats() {\n    this.ctx.getWebSockets().forEach((ws) => ws.send(this.getSeats()));\n  }\n}\nts\nimport { DurableObject } from \"cloudflare:workers\";\n\nexport class Flight extends DurableObject {\n  ...\n\nprivate initializeSeats() {\n    ...\n  }\n\n// Get all seats.\n  getSeats() {\n    ...\n  }\n\n// Assign a seat to a passenger.\n  assignSeat(seatId: string, occupant: string) {\n    ...\n  }\n\nprivate handleWebSocket(request: Request) {\n    ...\n  }\n\nprivate broadcastSeats() {\n    ...\n  }\n\nasync fetch(request: Request) {\n    return this.handleWebSocket(request);\n  }\n}\nts\nexport default {\n  ...\n\nasync fetch(request, env, ctx): Promise<Response> {\n    // Get flight id from the query parameter\n    ...\n\nif (request.method === \"GET\" && url.pathname === \"/seats\") {\n      return new Response(JSON.stringify(await stub.getSeats()), {\n        headers: { 'Content-Type': 'application/json' },\n      });\n    } else if (request.method === \"POST\" && url.pathname === \"/book-seat\") {\n      const { seatNumber, name } = (await request.json()) as {\n        seatNumber: string;\n        name: string;\n      };\n      const result = await stub.assignSeat(seatNumber, name);\n      return new Response(JSON.stringify(result));\n    } else if (request.headers.get(\"Upgrade\") === \"websocket\") {\n      return stub.fetch(request);\n    }\n\nreturn new Response(\"Not found\", { status: 404 });\n  },\n} satisfies ExportedHandler<Env>;\nsh\nnpm run dev\nsh\nnpm run deploy\nsh\n ⛅️ wrangler 3.78.8\n-------------------\n\n🌀 Building list of assets...\n🌀 Starting asset upload...\n🌀 Found 1 new or modified file to upload. Proceeding with upload...\n+ /index.html\nUploaded 1 of 1 assets\n✨ Success! Uploaded 1 file (1.93 sec)\n\nTotal Upload: 3.45 KiB / gzip: 1.39 KiB\nYour worker has access to the following bindings:\n- Durable Objects:\n  - FLIGHT: Flight\nUploaded seat-book (12.12 sec)\nDeployed seat-book triggers (5.54 sec)\n  [DEPLOYED_APP_LINK]\nCurrent Version ID: [BINDING_ID]\njsonc\n  {\n    \"send_email\": [\n      {\n        \"name\": \"EMAIL\"\n      }\n    ]\n  }\n  toml\n  [[send_email]]\n  name = \"EMAIL\"\n  ts\nimport * as PostalMime from 'postal-mime';\n\nexport default {\n  async email(message, env, ctx) {\n    const parser = new PostalMime.default();\n    const rawEmail = new Response(message.raw);\n    const email = await parser.parse(await rawEmail.arrayBuffer());\n    console.log(email);\n  },\n};\nbash\ncurl --request POST 'http://localhost:8787/cdn-cgi/handler/email' \\\n  --url-query 'from=sender@example.com' \\\n  --url-query 'to=recipient@example.com' \\\n  --header 'Content-Type: application/json' \\\n  --data-raw 'Received: from smtp.example.com (127.0.0.1)\n        by cloudflare-email.com (unknown) id 4fwwffRXOpyR\n        for <recipient@example.com>; Tue, 27 Aug 2024 15:50:20 +0000\nFrom: \"John\" <sender@example.com>\nReply-To: sender@example.com\nTo: recipient@example.com\nSubject: Testing Email Workers Local Dev\nContent-Type: text/html; charset=\"windows-1252\"\nX-Mailer: Curl\nDate: Tue, 27 Aug 2024 08:49:44 -0700\nMessage-ID: <6114391943504294873000@ZSH-GHOSTTY>\n\nHi there'\njson\n{\n  headers: [\n    {\n      key: 'received',\n      value: 'from smtp.example.com (127.0.0.1) by cloudflare-email.com (unknown) id 4fwwffRXOpyR for <recipient@example.com>; Tue, 27 Aug 2024 15:50:20 +0000'\n    },\n    { key: 'from', value: '\"John\" <sender@example.com>' },\n    { key: 'reply-to', value: 'sender@example.com' },\n    { key: 'to', value: 'recipient@example.com' },\n    { key: 'subject', value: 'Testing Email Workers Local Dev' },\n    { key: 'content-type', value: 'text/html; charset=\"windows-1252\"' },\n    { key: 'x-mailer', value: 'Curl' },\n    { key: 'date', value: 'Tue, 27 Aug 2024 08:49:44 -0700' },\n    {\n      key: 'message-id',\n      value: '<6114391943504294873000@ZSH-GHOSTTY>'\n    }\n  ],\n  from: { address: 'sender@example.com', name: 'John' },\n  to: [ { address: 'recipient@example.com', name: '' } ],\n  replyTo: [ { address: 'sender@example.com', name: '' } ],\n  subject: 'Testing Email Workers Local Dev',\n  messageId: '<6114391943504294873000@ZSH-GHOSTTY>',\n  date: '2024-08-27T15:49:44.000Z',\n  html: 'Hi there\\n',\n  attachments: []\n}\nts\nimport { EmailMessage } from \"cloudflare:email\";\nimport { createMimeMessage } from 'mimetext';\n\nexport default {\n  async fetch(request, env, ctx) {\n    const msg = createMimeMessage();\n    msg.setSender({ name: 'Sending email test', addr: 'sender@example.com' });\n    msg.setRecipient('recipient@example.com');\n    msg.setSubject('An email generated in a worker');\n    msg.addMessage({\n      contentType: 'text/plain',\n      data: `Congratulations, you just sent an email from a worker.`,\n    });\n\nvar message = new EmailMessage('sender@example.com', 'recipient@example.com', msg.asRaw());\n    await env.EMAIL.send(message);\n    return Response.json({ ok: true });\n  }\n};\ntxt\n⎔ Starting local server...\n[wrangler:inf] Ready on http://localhost:8787\n[wrangler:inf] GET / 200 OK (19ms)\n[wrangler:inf] send_email binding called with the following message:\n  /var/folders/33/pn86qymd0w50htvsjp93rys40000gn/T/miniflare-f9be031ff417b2e67f2ac4cf94cb1b40/files/email/33e0a255-a7df-4f40-b712-0291806ed2b3.eml\nplaintext\nDate: Fri, 04 Apr 2025 12:27:08 +0000\nFrom: =?utf-8?B?U2VuZGluZyBlbWFpbCB0ZXN0?= <sender@example.com>\nTo: <recipient@example.com>\nMessage-ID: <2s95plkazox@example.com>\nSubject: =?utf-8?B?QW4gZW1haWwgZ2VuZXJhdGVkIGluIGEgd29ya2Vy?=\nMIME-Version: 1.0\nContent-Type: text/plain; charset=UTF-8\nContent-Transfer-Encoding: 7bit\n\nCongratulations, you just sent an email from a worker.\nts\nimport * as PostalMime from 'postal-mime';\nimport { createMimeMessage } from 'mimetext';\nimport { EmailMessage } from 'cloudflare:email';\n\nexport default {\n  async email(message, env: any, ctx: any) {\n    // parses incoming message\n    const parser = new PostalMime.default();\n    const rawEmail = new Response(message.raw);\n    const email = await parser.parse(await rawEmail.arrayBuffer());\n\n// creates some ticket\n    // const ticket = await createTicket(email);\n\n// creates reply message\n    const msg = createMimeMessage();\n    msg.setSender({ name: 'Thank you for your contact', addr: 'sender@example.com' });\n    msg.setRecipient(message.from);\n    msg.setHeader('In-Reply-To', message.headers.get('Message-ID'));\n    msg.setSubject('An email generated in a worker');\n    msg.addMessage({\n      contentType: 'text/plain',\n      data: `This is an automated reply. We received you email with the subject \"${email.subject}\", and will handle it as soon as possible.`,\n    });\n\nconst replyMessage = new EmailMessage('sender@example.com', message.from, msg.asRaw());\n\nawait message.reply(replyMessage);\n    await message.forward(\"recipient@example.com\");\n  },\n};\ntxt\n⎔ Starting local server...\n[wrangler:inf] Ready on http://localhost:8787\n[wrangler:inf] Email handler replied to sender with the following message:\n  /var/folders/33/pn86qymd0w50htvsjp93rys40000gn/T/miniflare-381a79d7efa4e991607b30a079f6b17d/files/email/a1db7ebb-ccb4-45ef-b315-df49c6d820c0.eml\n[wrangler:inf] Email handler forwarded message with\n  rcptTo: recipient@example.com\njs\nimport { EmailMessage } from \"cloudflare:email\";\nimport { createMimeMessage } from \"mimetext\";\n\nexport default {\n  async email(message, env, ctx) {\n\nconst ticket = createTicket(message);\n\nconst msg = createMimeMessage();\n    msg.setHeader(\"In-Reply-To\", message.headers.get(\"Message-ID\"));\n    msg.setSender({ name: \"Thank you for your contact\", addr: \"<SENDER>@example.com\" });\n    msg.setRecipient(message.from);\n    msg.setSubject(\"Email Routing Auto-reply\");\n    msg.addMessage({\n      contentType: 'text/plain',\n      data: `We got your message, your ticket number is ${ ticket.id }`\n    });\n\nconst replyMessage = new EmailMessage(\n      \"<SENDER>@example.com\",\n      message.from,\n      msg.asRaw()\n    );\n\nawait message.reply(replyMessage);\n  }\n}\njs\nexport default {\n  async email(message, env, ctx) {\n    await message.forward(\"<YOUR_EMAIL>\");\n  },\n};\njs\naddEventListener(\"email\", async (event) => {\n  await event.message.forward(\"<YOUR_EMAIL>\");\n});\nts\n interface ForwardableEmailMessage<Body = unknown> {\n  readonly from: string;\n  readonly to: string;\n  readonly headers: Headers;\n  readonly raw: ReadableStream;\n  readonly rawSize: number;\n\npublic constructor(from: string, to: string, raw: ReadableStream | string);\n\nsetReject(reason: string): void;\n  forward(rcptTo: string, headers?: Headers): Promise<void>;\n  reply(message: EmailMessage): Promise<void>;\n}\nts\ninterface EmailMessage {\n    readonly from: string;\n    readonly to: string;\n}\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"send_email\": [\n      {\n        \"name\": \"<NAME_FOR_BINDING>\",\n        \"destination_address\": \"<YOUR_EMAIL>@example.com\"\n      }\n    ]\n  }\n  toml\n  send_email = [\n      {name = \"<NAME_FOR_BINDING>\", destination_address = \"<YOUR_EMAIL>@example.com\"},\n  ]\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"send_email\": [\n      {\n        \"name\": \"<NAME_FOR_BINDING1>\"\n      },\n      {\n        \"name\": \"<NAME_FOR_BINDING2>\",\n        \"destination_address\": \"<YOUR_EMAIL>@example.com\"\n      },\n      {\n        \"name\": \"<NAME_FOR_BINDING3>\",\n        \"allowed_destination_addresses\": [\n          \"<YOUR_EMAIL>@example.com\",\n          \"<YOUR_EMAIL2>@example.com\"\n        ]\n      }\n    ]\n  }\n  toml\n  send_email = [\n      {name = \"<NAME_FOR_BINDING1>\"},\n       {name = \"<NAME_FOR_BINDING2>\", destination_address = \"<YOUR_EMAIL>@example.com\"},\n       {name = \"<NAME_FOR_BINDING3>\", allowed_destination_addresses = [\"<YOUR_EMAIL>@example.com\", \"<YOUR_EMAIL2>@example.com\"]},\n  ]\n  js\nimport { EmailMessage } from \"cloudflare:email\";\nimport { createMimeMessage } from \"mimetext\";\n\nexport default {\n  async fetch(request, env) {\n    const msg = createMimeMessage();\n    msg.setSender({ name: \"GPT-4\", addr: \"<SENDER>@example.com\" });\n    msg.setRecipient(\"<RECIPIENT>@example.com\");\n    msg.setSubject(\"An email generated in a worker\");\n    msg.addMessage({\n      contentType: \"text/plain\",\n      data: `Congratulations, you just sent an email from a worker.`,\n    });\n\nvar message = new EmailMessage(\n      \"<SENDER>@example.com\",\n      \"<RECIPIENT>@example.com\",\n      msg.asRaw(),\n    );\n    try {\n      await env.SEB.send(message);\n    } catch (e) {\n      return new Response(e.message);\n    }\n\nreturn new Response(\"Hello Send Email World!\");\n  },\n};\nsh\ndig txt _mta-sts.example.com\nsh\n_mta-sts.example.com. 300 IN  CNAME _mta-sts.mx.cloudflare.net.\n_mta-sts.mx.cloudflare.net. 300 IN  TXT \"v=STSv1; id=20230615T153000;\"\njs\nexport default {\n  async fetch(request, env, ctx) {\n    return await fetch(\n      \"https://mta-sts.mx.cloudflare.net/.well-known/mta-sts.txt\",\n    );\n  },\n};\nsh\ncurl https://mta-sts.example.com/.well-known/mta-sts.txt\nsh\nversion: STSv1\nmode: enforce\nmx: *.mx.cloudflare.net\nmax_age: 86400\ntxt\nX-Area1Security-Disposition: [Value]\ntxt\nX-Area1Security-Disposition: UCE\ntxt\nX-Area1Security-Attribute: [Value]\nX-Area1Security-Attribute: [Value2]\ntxt\n<<FIELD_NAME>>:<<VALUE>>\ntxt\nbilling statement message_id:<Amazon aws Support@email.amazonses.com>\nbash\ncurl \"https://api.cloudflare.com/client/v4/zones/{zone_id}/firewall/rules\" \\\n--header \"X-Auth-Email: <EMAIL>\" \\\n--header \"X-Auth-Key: <API_KEY>\" \\\n--header \"Content-Type: application/json\" \\\n--data '[\n  {\n    \"filter\": {\n      \"expression\": \"http.request.uri.path contains \\\"/api/\\\" and ip.src eq 93.184.216.34\"\n    },\n    \"action\": \"block\"\n  }\n]'\njson\n{\n  \"result\": [\n    {\n      \"id\": \"<RULE_ID>\",\n      \"paused\": false,\n      \"action\": \"block\",\n      \"priority\": null,\n      \"filter\": {\n        \"id\": \"<FILTER_ID>\",\n        \"expression\": \"http.request.uri.path contains \\\"/api/\\\" and ip.src eq 93.184.216.34\",\n        \"paused\": false\n      }\n    }\n  ],\n  \"success\": true,\n  \"errors\": [],\n  \"messages\": []\n}\nbash\ncurl \"https://api.cloudflare.com/client/v4/user/tokens/verify\" \\\n--header \"Authorization: Bearer <API_TOKEN>\"\njson\n{\n  \"success\": true,\n  \"errors\": [],\n  \"messages\": [],\n  \"result\": {\n    \"id\": \"f267e341f3dd4697bd3b9f71dd96247f\",\n    \"status\": \"active\",\n    \"not_before\": \"2018-07-01T05:20:00Z\",\n    \"expires_on\": \"2020-01-01T00:00:00Z\"\n  }\n}\nmermaid\nflowchart LR\naccTitle: Accounts contain zones and user profiles contain user settings\nsubgraph Account\n    subgraph Zone - example.com\n        A[WAF]\n        B[DNS]\n    end\n    subgraph Zone - example2.com\n        C[Cache rules]\n        D[Waiting Room]\n    end\n    Workers\n    K[Account members]\nend\nsubgraph User profile\n    G[Email address]\n    H[Language]\n    I[Communication preferences]\nend\nbash",
  "code_samples": [
    {
      "code": "## 5. Query your database from the Worker\n\nTo query your database from the Worker using Prisma ORM, you need to:\n\n1. Add `DB` to the `Env` interface.\n2. Instantiate `PrismaClient` using the `PrismaD1` driver adapter.\n3. Send a query using Prisma Client and return the result.\n\nOpen `src/index.ts` and replace the entire content with the following:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Before running the Worker, generate Prisma Client with the following command:",
      "language": "unknown"
    },
    {
      "code": "## 6. Run the Worker locally\n\nNow that you have the database query in place and Prisma Client generated, run the Worker locally:",
      "language": "unknown"
    },
    {
      "code": "Open your browser at [`http://localhost:8787`](http://localhost:8787/) to check the result of the database query:",
      "language": "unknown"
    },
    {
      "code": "## 7. Deploy the Worker\n\nTo deploy the Worker, run the following command:",
      "language": "unknown"
    },
    {
      "code": "Access your Worker at `https://prisma-d1-example.USERNAME.workers.dev`. Your browser should display the following data queried from your remote D1 database:",
      "language": "unknown"
    },
    {
      "code": "By finishing this tutorial, you have deployed a Cloudflare Worker using D1 as a database and querying it via Prisma ORM.\n\n## Related resources\n\n* [Prisma documentation](https://www.prisma.io/docs/getting-started).\n* To get help, open a new [GitHub Discussion](https://github.com/prisma/prisma/discussions/), or [ask the AI bot in the Prisma docs](https://www.prisma.io/docs).\n* [Ready-to-run examples using Prisma ORM](https://github.com/prisma/prisma-examples/).\n* Check out the [Prisma community](https://www.prisma.io/community), follow [Prisma on X](https://www.x.com/prisma) and join the [Prisma Discord](https://pris.ly/discord).\n* [Developer Experience Redefined: Prisma & Cloudflare Lead the Way to Data DX](https://www.prisma.io/blog/cloudflare-partnership-qerefgvwirjq).\n\n</page>\n\n<page>\n---\ntitle: Bulk import to D1 using REST API · Cloudflare D1 docs\ndescription: This tutorial uses the REST API to import a database into D1.\nlastUpdated: 2025-10-09T15:47:46.000Z\nchatbotDeprioritize: false\ntags: JavaScript,TypeScript,SQL\nsource_url:\n  html: https://developers.cloudflare.com/d1/tutorials/import-to-d1-with-rest-api/\n  md: https://developers.cloudflare.com/d1/tutorials/import-to-d1-with-rest-api/index.md\n---\n\nIn this tutorial, you will learn how to import a database into D1 using the [REST API](https://developers.cloudflare.com/api/resources/d1/subresources/database/methods/import/).\n\n## Prerequisites\n\n1. Sign up for a [Cloudflare account](https://dash.cloudflare.com/sign-up/workers-and-pages).\n2. Install [`Node.js`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm).\n\nNode.js version manager\n\nUse a Node version manager like [Volta](https://volta.sh/) or [nvm](https://github.com/nvm-sh/nvm) to avoid permission issues and change Node.js versions. [Wrangler](https://developers.cloudflare.com/workers/wrangler/install-and-update/), discussed later in this guide, requires a Node version of `16.17.0` or later.\n\n## 1. Create a D1 API token\n\nTo use REST APIs, you need to generate an API token to authenticate your API requests. You can do this through the Cloudflare dashboard.\n\n1. In the Cloudflare dashboard, go to the **API Tokens** page.\n\n   [Go to **Account API tokens**](https://dash.cloudflare.com/?to=/:account/api-tokens)\n\n2. Under **API Tokens**, select **Create Token**.\n\n3. Scroll to **Custom token** > **Create custom token**, then select **Get started**.\n\n4. Under **Token name**, enter a descriptive token name. For example, `Name-D1-Import-API-Token`.\n\n5. Under **Permissions**:\n\n   * Select **Account**.\n   * Select **D1**.\n   * Select **Edit**.\n\n6. Select **Continue to summary**.\n\n7. Select **Create token**.\n\n8. Copy the API token and save it in a secure file.\n\n* Refer to [Create API token](https://developers.cloudflare.com/fundamentals/api/get-started/create-token/) for more information on creating API tokens through the Cloudflare dashboard.\n* Refer to [Create tokens via API](https://developers.cloudflare.com/fundamentals/api/how-to/create-via-api/) for more information on creating API tokens through API.\n\n## 2. Create the target table\n\nYou must have an existing D1 table which matches the schema of the data you wish to import.\n\nThis tutorial uses the following:\n\n* A database called `d1-import-tutorial`.\n* A table called `TargetD1Table`\n* Within `TargetD1Table`, three columns called `id`, `text`, and `date_added`.\n\nTo create the table, follow these steps:\n\n1. In the Cloudflare dashboard, go to the **D1** page.\n\n   [Go to **D1 SQL database**](https://dash.cloudflare.com/?to=/:account/workers/d1)\n\n2. Select **Create database**.\n\n3. Name your database. For this tutorial, name your D1 database `d1-import-tutorial`.\n\n4. (Optional) Provide a location hint. Location hint is an optional parameter you can provide to indicate your desired geographical location for your database. Refer to [Provide a location hint](https://developers.cloudflare.com/d1/configuration/data-location/#provide-a-location-hint) for more information.\n\n5. Select **Create**.\n\n6. Go to **Console**, then paste the following SQL snippet. This creates a table named `TargetD1Table`.",
      "language": "unknown"
    },
    {
      "code": "Alternatively, you can use the [Wrangler CLI](https://developers.cloudflare.com/workers/wrangler/install-and-update/).",
      "language": "unknown"
    },
    {
      "code": "## 3. Create an `index.js` file\n\n1. Create a new directory and initialize a new Node.js project.",
      "language": "unknown"
    },
    {
      "code": "2. In this repository, create a new file called `index.js`. This file will contain the code which uses REST API to import your data to your D1 database.\n\n3. In your `index.js` file, define the following variables:\n\n   * `TARGET_TABLE`: The target table name\n   * `ACCOUNT_ID`: The account ID. Refer to **Account Details** in **Workers & Pages**.\n   * `DATABASE_ID`: The D1 database ID. Go to your data base to see your database ID.\n   * `D1_API_KEY`: The D1 API token generated in [step 1](https://developers.cloudflare.com/d1/tutorials/import-to-d1-with-rest-api#1-create-a-d1-api-token)\n\n   Warning\n\n   In production, you should use environment variables to store sensitive information.",
      "language": "unknown"
    },
    {
      "code": "## 4. Generate example data (optional)\n\nIn practice, you may already have the data you wish to import to a D1 database.\n\nThis tutorial generates example data to demonstrate the import process.\n\n1. Install the `@faker-js/faker` module.\n\n   * npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "2. Add the following code at the beginning of the `index.js` file. This code creates an array called `data` with 2500 (`uploadSize`) array elements, where each array element contains an object with `id`, `text`, and `date_added`. Each array element corresponds to a table row.",
      "language": "unknown"
    },
    {
      "code": "## 5. Generate the SQL command\n\n1. Create a function that will generate the SQL command to insert the data into the target table. This function uses the `data` array generated in the previous step.",
      "language": "unknown"
    },
    {
      "code": "## 6. Import the data to D1\n\nThe import process consists of four steps:\n\n1. **Init upload**: This step initializes the upload process. It sends the hash of the SQL command to the D1 API and receives an upload URL.\n2. **Upload to R2**: This step uploads the SQL command to the upload URL.\n3. **Start ingestion**: This step starts the ingestion process.\n4. **Polling**: This step polls the import process until it completes.\n\n1) Create a function called `uploadToD1` which executes the four steps of the import process.",
      "language": "unknown"
    },
    {
      "code": "In the above code:\n\n   * An `md5` hash of the SQL command is generated.\n   * `initResponse` initializes the upload process and receives the upload URL.\n   * `r2Response` uploads the SQL command to the upload URL.\n   * Before starting ingestion, the ETag is verified.\n   * `ingestResponse` starts the ingestion process.\n   * `pollImport` polls the import process until it completes.\n\n2) Add the `pollImport` function to the `index.js` file.",
      "language": "unknown"
    },
    {
      "code": "The code above does the following:\n\n   * Sends a `poll` action to the D1 API.\n   * Polls the import process until it completes.\n\n3) Finally, add the `runImport` function to the `index.js` file to run the import process.",
      "language": "unknown"
    },
    {
      "code": "## 7. Write the final code\n\nIn the previous steps, you have created functions to execute various processes involved in importing data into D1. The final code executes those functions to import the example data into the target D1 table.\n\n1. Copy the final code of your `index.js` file as shown below, with your variables defined at the top of the code.",
      "language": "unknown"
    },
    {
      "code": "## 8. Run the code\n\n1. Run your code.",
      "language": "unknown"
    },
    {
      "code": "You will now see your target D1 table populated with the example data.\n\nNote\n\nIf you encounter the `statement too long` error, you would need to break your SQL command into smaller chunks and upload them in batches. You can learn more about this error in the [D1 documentation](https://developers.cloudflare.com/d1/best-practices/import-export-data/#resolve-statement-too-long-error).\n\n## Summary\n\nBy completing this tutorial, you have\n\n1. Created an API token.\n2. Created a target database and table.\n3. Generated example data.\n4. Created SQL command for the example data.\n5. Imported your example data into the D1 target table using REST API.\n\n</page>\n\n<page>\n---\ntitle: Using D1 Read Replication for your e-commerce website · Cloudflare D1 docs\ndescription: D1 Read Replication is a feature that allows you to replicate your\n  D1 database to multiple regions. This is useful for your e-commerce website,\n  as it reduces read latencies and improves read throughput.\nlastUpdated: 2025-10-09T15:47:46.000Z\nchatbotDeprioritize: false\ntags: JavaScript,TypeScript,SQL\nsource_url:\n  html: https://developers.cloudflare.com/d1/tutorials/using-read-replication-for-e-com/\n  md: https://developers.cloudflare.com/d1/tutorials/using-read-replication-for-e-com/index.md\n---\n\n[D1 Read Replication](https://developers.cloudflare.com/d1/best-practices/read-replication/) is a feature that allows you to replicate your D1 database to multiple regions. This is useful for your e-commerce website, as it reduces read latencies and improves read throughput. In this tutorial, you will learn how to use D1 read replication for your e-commerce website.\n\nWhile this tutorial uses a fictional e-commerce website, the principles can be applied to any use-case that requires low read latencies and scaling reads, such as a news website, a social media platform, or a marketing website.\n\n## Quick start\n\nIf you want to skip the steps and get started quickly, click on the below button:\n\n[![Deploy to Cloudflare](https://deploy.workers.cloudflare.com/button)](https://deploy.workers.cloudflare.com/?url=https://github.com/harshil1712/e-com-d1-hono)\n\nThis will create a repository in your GitHub account and deploy the application to Cloudflare Workers. It will also create and bind a D1 database, create the required tables, add some sample data. During deployment, tick the `Enable read replication` box to activate read replication.\n\nYou can then visit the deployed application.\n\n## Prerequisites\n\n1. Sign up for a [Cloudflare account](https://dash.cloudflare.com/sign-up/workers-and-pages).\n2. Install [`Node.js`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm).\n\nNode.js version manager\n\nUse a Node version manager like [Volta](https://volta.sh/) or [nvm](https://github.com/nvm-sh/nvm) to avoid permission issues and change Node.js versions. [Wrangler](https://developers.cloudflare.com/workers/wrangler/install-and-update/), discussed later in this guide, requires a Node version of `16.17.0` or later.\n\n## Step 1: Create a Workers project\n\nCreate a new Workers project by running the following command:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "For setup, select the following options:\n\n* For *What would you like to start with?*, choose `Hello World example`.\n* For *Which template would you like to use?*, choose `SSR / full-stack app`.\n* For *Which language do you want to use?*, choose `TypeScript`.\n* For *Do you want to use git for version control?*, choose `Yes`.\n* For *Do you want to deploy your application?*, choose `No` (we will be making some changes before deploying).\n\nFor creating the API routes, you will use [Hono](https://hono.dev/). You need to install Hono by running the following command:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "## Step 2: Update the frontend\n\nThe above step creates a new Workers project with a default frontend and installs Hono. You will update the frontend to list the products. You will also add a new page to the frontend to display a single product.\n\nNavigate to the newly created Worker project folder.",
      "language": "unknown"
    },
    {
      "code": "Update the `public/index.html` file to list the products. Use the below code as a reference.\n\npublic/index.html",
      "language": "unknown"
    },
    {
      "code": "Create a new `public/product-details.html` file to display a single product.\n\npublic/product-details.html",
      "language": "unknown"
    },
    {
      "code": "You now have a frontend that lists products and displays a single product. However, the frontend is not yet connected to the D1 database. If you start the development server now, you will see no products. In the next steps, you will create a D1 database and create APIs to fetch products and display them on the frontend.\n\n## Step 3: Create a D1 database and enable read replication\n\nCreate a new D1 database by running the following command:",
      "language": "unknown"
    },
    {
      "code": "Add the D1 bindings returned in the terminal to the `wrangler` file:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Run the following command to update the `Env` interface in the `worker-configuration.d.ts` file.",
      "language": "unknown"
    },
    {
      "code": "Next, enable read replication for the D1 database. Navigate to [**Workers & Pages** > **D1**](https://dash.cloudflare.com/?to=/:account/workers/d1), then select an existing database > **Settings** > **Enable Read Replication**.\n\n## Step 4: Create the API routes\n\nUpdate the `src/index.ts` file to import the Hono library and create the API routes.",
      "language": "unknown"
    },
    {
      "code": "The above code creates three API routes:\n\n* `GET /api/products`: Returns a list of products.\n* `GET /api/products/:id`: Returns a single product.\n* `POST /api/product`: Creates or updates a product.\n\nHowever, the API routes are not connected to the D1 database yet. In the next steps, you will create a products table in the D1 database, and update the API routes to connect to the D1 database.\n\n## Step 5: Create local D1 database schema\n\nCreate a products table in the D1 database by running the following command:",
      "language": "unknown"
    },
    {
      "code": "Next, create an index on the products table by running the following command:",
      "language": "unknown"
    },
    {
      "code": "For development purposes, you can also execute the insert statements on the local D1 database by running the following command:",
      "language": "unknown"
    },
    {
      "code": "## Step 6: Add retry logic\n\nTo make the application more resilient, you can add retry logic to the API routes. Create a new file called `retry.ts` in the `src` directory.",
      "language": "unknown"
    },
    {
      "code": "The `withRetry` function is a utility function that retries a given operation with exponential backoff. It takes a configuration object as an argument, which allows you to customize the number of retries, initial delay, maximum delay, and backoff factor. It will only retry the operation if the error is due to a network connection loss, storage reset, or code update.\n\nWarning\n\nIn a distrubed system, retry mechanisms can have certain risks. Read the article [Retry Strategies in Distributed Systems: Identifying and Addressing Key Pitfalls](https://www.computer.org/publications/tech-news/trends/retry-strategies-avoiding-pitfalls) to learn more about the risks of retry mechanisms and how to avoid them.\n\nRetries can sometimes lead to data inconsistency. Make sure to handle the retry logic carefully.\n\nNext, update the `src/index.ts` file to import the `withRetry` function and use it in the API routes.",
      "language": "unknown"
    },
    {
      "code": "## Step 7: Update the API routes\n\nUpdate the API routes to connect to the D1 database.\n\n### 1. POST /api/product",
      "language": "unknown"
    },
    {
      "code": "In the above code:\n\n* You get the product data from the request body.\n\n* You then check if the product exists in the database.\n\n  * If it does, you update the product.\n  * If it doesn't, you insert the product.\n\n* You then set the bookmark in the cookie.\n\n* Finally, you return the response.\n\nSince you want to start the session with the latest data, you use the `first-primary` constraint. Even if you use the `first-unconstrained` constraint or pass a bookmark, the write request will always be routed to the primary database.\n\nThe bookmark set in the cookie can be used to guarantee that a new session reads a database version that is at least as up-to-date as the provided bookmark.\n\nIf you are using an external platform to manage your products, you can connect this API to the external platform, such that, when a product is created or updated in the external platform, the D1 database automatically updates the product details.\n\n### 2. GET /api/products",
      "language": "unknown"
    },
    {
      "code": "In the above code:\n\n* You get the database session bookmark from the cookie.\n  * If the bookmark is not set, you use the `first-unconstrained` constraint.\n* You then create a database session with the bookmark.\n* You fetch all the products from the database and get the latest bookmark.\n* You then set this bookmark in the cookie.\n* Finally, you return the results.\n\n### 3. GET /api/products/:id",
      "language": "unknown"
    },
    {
      "code": "In the above code:\n\n* You get the product ID from the request parameters.\n* You then create a database session with the bookmark.\n* You fetch the product from the database and get the latest bookmark.\n* You then set this bookmark in the cookie.\n* Finally, you return the results.\n\n## Step 8: Test the application\n\nYou have now updated the API routes to connect to the D1 database. You can now test the application by starting the development server and navigating to the frontend.",
      "language": "unknown"
    },
    {
      "code": "Navigate to \\`<http://localhost:8787>. You should see the products listed. Click on a product to view the product details.\n\nTo insert a new product, use the following command (while the development server is running):",
      "language": "unknown"
    },
    {
      "code": "Navigate to `http://localhost:8787/product-details?id=6`. You should see the new product.\n\nUpdate the product using the following command, and navigate to `http://localhost:8787/product-details?id=6` again. You will see the updated product.",
      "language": "unknown"
    },
    {
      "code": "Note\n\nRead replication is only used when the application has been [deployed](https://developers.cloudflare.com/d1/tutorials/using-read-replication-for-e-com/#step-9-deploy-the-application). D1 does not create read replicas when you develop locally.\n\nTo test it locally, you can set `\"remote\" : true` in the D1 binding configuration. Refer to the [remote bindings documentation](https://developers.cloudflare.com/workers/development-testing/#remote-bindings) for more information.\n\n## Step 9: Deploy the application\n\nSince the database you used in the previous steps is local, you need to create the products table in the remote database. Execute the following D1 commands to create the products table in the remote database.",
      "language": "unknown"
    },
    {
      "code": "Next, create an index on the products table by running the following command:",
      "language": "unknown"
    },
    {
      "code": "Optionally, you can insert the products into the remote database by running the following command:",
      "language": "unknown"
    },
    {
      "code": "Now, you can deploy the application with the following command:",
      "language": "unknown"
    },
    {
      "code": "This will deploy the application to Workers and the D1 database will be replicated to the remote regions. If a user requests the application from any region, the request will be redirected to the nearest region where the database is replicated.\n\n## Conclusion\n\nIn this tutorial, you learned how to use D1 Read Replication for your e-commerce website. You created a D1 database and enabled read replication for it. You then created an API to create and update products in the database. You also learned how to use the bookmark to get the latest data from the database.\n\nYou then created the products table in the remote database and deployed the application.\n\nYou can use the same approach for your existing read heavy application to reduce read latencies and improve read throughput. If you are using an external platform to manage the content, you can connect the external platform to the D1 database, so that the content is automatically updated in the database.\n\nYou can find the complete code for this tutorial in the [GitHub repository](https://github.com/harshil1712/e-com-d1-hono).\n\n</page>\n\n<page>\n---\ntitle: D1 Database · Cloudflare D1 docs\ndescription: To interact with your D1 database from your Worker, you need to\n  access it through the environment bindings provided to the Worker (env).\nlastUpdated: 2025-12-02T18:27:05.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/d1/worker-api/d1-database/\n  md: https://developers.cloudflare.com/d1/worker-api/d1-database/index.md\n---\n\nTo interact with your D1 database from your Worker, you need to access it through the environment bindings provided to the Worker (`env`).\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "A D1 binding has the type `D1Database`, and supports a number of methods, as listed below.\n\n## Methods\n\n### `prepare()`\n\nPrepares a query statement to be later executed.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* `query`: String Required\n  * The SQL query you wish to execute on the database.\n\n#### Return values\n\n* `D1PreparedStatement`: Object\n  * An object which only contains methods. Refer to [Prepared statement methods](https://developers.cloudflare.com/d1/worker-api/prepared-statements/).\n\n#### Guidance\n\nYou can use the `bind` method to dynamically bind a value into the query statement, as shown below.\n\n* Example of a static statement without using `bind`:\n\n  * JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "* Example of an ordered statement using `bind`:\n\n  * JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "Refer to the [`bind` method documentation](https://developers.cloudflare.com/d1/worker-api/prepared-statements/#bind) for more information.\n\n### `batch()`\n\nSends multiple SQL statements inside a single call to the database. This can have a huge performance impact as it reduces latency from network round trips to D1. D1 operates in auto-commit. Our implementation guarantees that each statement in the list will execute and commit, sequentially, non-concurrently.\n\nBatched statements are [SQL transactions](https://www.sqlite.org/lang_transaction.html). If a statement in the sequence fails, then an error is returned for that specific statement, and it aborts or rolls back the entire sequence.\n\nTo send batch statements, provide `D1Database::batch` a list of prepared statements and get the results in the same order.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* `statements`: Array\n  * An array of [`D1PreparedStatement`](#prepare)s.\n\n#### Return values\n\n* `results`: Array\n\n  * An array of `D1Result` objects containing the results of the [`D1Database::prepare`](#prepare) statements. Each object is in the array position corresponding to the array position of the initial [`D1Database::prepare`](#prepare) statement within the `statements`.\n  * Refer to [`D1Result`](https://developers.cloudflare.com/d1/worker-api/return-object/#d1result) for more information about this object.\n\nExample of return values\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "#### Guidance\n\n* You can construct batches reusing the same prepared statement:\n\n  * JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "### `exec()`\n\nExecutes one or more queries directly without prepared statements or parameter bindings.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* `query`: String Required\n  * The SQL query statement without parameter binding.\n\n#### Return values\n\n* `D1ExecResult`: Object\n\n  * The `count` property contains the number of executed queries.\n  * The `duration` property contains the duration of operation in milliseconds.\n    * Refer to [`D1ExecResult`](https://developers.cloudflare.com/d1/worker-api/return-object/#d1execresult) for more information.\n\nExample of return values\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "#### Guidance\n\n* If an error occurs, an exception is thrown with the query and error messages, execution stops and further statements are not executed. Refer to [Errors](https://developers.cloudflare.com/d1/observability/debug-d1/#errors) to learn more.\n* This method can have poorer performance (prepared statements can be reused in some cases) and, more importantly, is less safe.\n* Only use this method for maintenance and one-shot tasks (for example, migration jobs).\n* The input can be one or multiple queries separated by `\\n`.\n\n### `dump`\n\nWarning\n\nThis API only works on databases created during D1's alpha period. Check which version your database uses with `wrangler d1 info <DATABASE_NAME>`.\n\nDumps the entire D1 database to an SQLite compatible file inside an ArrayBuffer.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* None.\n\n#### Return values\n\n* None.\n\n### `withSession()`\n\nStarts a D1 session which maintains sequential consistency among queries executed on the returned `D1DatabaseSession` object.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* `first-primary`: StringOptional\n\n  * Directs the first query in the Session (whether read or write) to the primary database instance. Use this option if you need to start the Session with the most up-to-date data from the primary database instance.\n  * Subsequent queries in the Session may use read replicas.\n  * Subsequent queries in the Session have sequential consistency.\n\n* `first-unconstrained`: StringOptional\n\n  * Directs the first query in the Session (whether read or write) to any database instance. Use this option if you do not need to start the Session with the most up-to-date data, and wish to prioritize minimizing query latency from the very start of the Session.\n  * Subsequent queries in the Session have sequential consistency.\n  * This is the default behavior when no parameter is provided.\n\n* `bookmark`: StringOptional\n\n  * A [`bookmark`](https://developers.cloudflare.com/d1/reference/time-travel/#bookmarks) from a previous D1 Session. This allows you to start a new Session from at least the provided `bookmark`.\n  * Subsequent queries in the Session have sequential consistency.\n\n#### Return values\n\n* `D1DatabaseSession`: Object\n  * An object which contains the methods [`prepare()`](https://developers.cloudflare.com/d1/worker-api/d1-database#prepare) and [`batch()`](https://developers.cloudflare.com/d1/worker-api/d1-database#batch) similar to `D1Database`, along with the additional [`getBookmark`](https://developers.cloudflare.com/d1/worker-api/d1-database#getbookmark) method.\n\n#### Guidance\n\n* To use read replication, you have to use the D1 Sessions API, otherwise all queries will continue to be executed only by the primary database.\n* You can return the last encountered `bookmark` for a given Session using [`session.getBookmark()`](https://developers.cloudflare.com/d1/worker-api/d1-database/#getbookmark).\n\n## `D1DatabaseSession` methods\n\n### `getBookmark`\n\nRetrieves the latest `bookmark` from the D1 Session.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* None\n\n#### Return values\n\n* `bookmark`: String | null\n\n  * A [`bookmark`](https://developers.cloudflare.com/d1/reference/time-travel/#bookmarks) which identifies the latest version of the database seen by the last query executed within the Session.\n  * Returns `null` if no query is executed within a Session.\n\n### `prepare()`\n\nThis method is equivalent to [`D1Database::prepare`](https://developers.cloudflare.com/d1/worker-api/d1-database/#prepare).\n\n### `batch()`\n\nThis method is equivalent to [`D1Database::batch`](https://developers.cloudflare.com/d1/worker-api/d1-database/#batch).\n\n</page>\n\n<page>\n---\ntitle: Prepared statement methods · Cloudflare D1 docs\ndescription: This chapter documents the various ways you can run and retrieve\n  the results of a query after you have prepared your statement.\nlastUpdated: 2025-12-02T18:27:05.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/d1/worker-api/prepared-statements/\n  md: https://developers.cloudflare.com/d1/worker-api/prepared-statements/index.md\n---\n\nThis chapter documents the various ways you can run and retrieve the results of a query after you have [prepared your statement](https://developers.cloudflare.com/d1/worker-api/d1-database/#prepare).\n\n## Methods\n\n### `bind()`\n\nBinds a parameter to the prepared statement.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "#### Parameter\n\n* `Variable`: string\n  * The variable to be appended into the prepared statement. See [guidance](#guidance) below.\n\n#### Return values\n\n* `D1PreparedStatement`: Object\n  * A `D1PreparedStatement` where the input parameter has been included in the statement.\n\n#### Guidance\n\n* D1 follows the [SQLite convention](https://www.sqlite.org/lang_expr.html#varparam) for prepared statements parameter binding. Currently, D1 only supports Ordered (`?NNNN`) and Anonymous (`?`) parameters. In the future, D1 will support named parameters as well.\n\n  | Syntax | Type | Description |\n  | - | - | - |\n  | `?NNN` | Ordered | A question mark followed by a number `NNN` holds a spot for the `NNN`-th parameter. `NNN` must be between `1` and `SQLITE_MAX_VARIABLE_NUMBER` |\n  | `?` | Anonymous | A question mark that is not followed by a number creates a parameter with a number one greater than the largest parameter number already assigned. If this means the parameter number is greater than `SQLITE_MAX_VARIABLE_NUMBER`, it is an error. This parameter format is provided for compatibility with other database engines. But because it is easy to miscount the question marks, the use of this parameter format is discouraged. Programmers are encouraged to use one of the symbolic formats below or the `?NNN` format above instead. |\n\n  To bind a parameter, use the `.bind` method.\n\n  Order and anonymous examples:\n\n  * JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "- JavaScript",
      "language": "unknown"
    },
    {
      "code": "- Python",
      "language": "unknown"
    },
    {
      "code": "* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "#### Static statements\n\nD1 API supports static statements. Static statements are SQL statements where the variables have been hard coded. When writing a static statement, you manually type the variable within the statement string.\n\nAdvantages of prepared statements\n\nThe recommended approach is to use [prepared statements](https://developers.cloudflare.com/d1/worker-api/d1-database/#prepare) to run the SQL and bind parameters to them. Binding parameters using [`bind()`](https://developers.cloudflare.com/d1/worker-api/prepared-statements/#bind) to prepared statements allows you to reuse the prepared statements in your code, and prevents SQL injection attacks.\n\nExample of a prepared statement with dynamically bound value:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "Example of a static statement:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "### `run()`\n\nRuns the prepared query (or queries) and returns results. The returned results includes metadata.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "#### Parameter\n\n* None.\n\n#### Return values\n\n* `D1Result`: Object\n\n  * An object containing the success status, a meta object, and an array of objects containing the query results.\n  * For more information on the object, refer to [`D1Result`](https://developers.cloudflare.com/d1/worker-api/return-object/#d1result).\n\nExample of return values\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "#### Guidance\n\n* `results` is empty for write operations such as `UPDATE`, `DELETE`, or `INSERT`.\n* When using TypeScript, you can pass a [type parameter](https://developers.cloudflare.com/d1/worker-api/#typescript-support) to [`D1PreparedStatement::run`](#run) to return a typed result object.\n* [`D1PreparedStatement::run`](#run) is functionally equivalent to `D1PreparedStatement::all`, and can be treated as an alias.\n* You can choose to extract only the results you expect from the statement by simply returning the `results` property of the return object.\n\nExample of returning only the `results`\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "### `raw()`\n\nRuns the prepared query (or queries), and returns the results as an array of arrays. The returned results do not include metadata.\n\nColumn names are not included in the result set by default. To include column names as the first row of the result array, set `.raw({columnNames: true})`.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* `columnNames`: Object Optional\n  * A boolean object which includes column names as the first row of the result array.\n\n#### Return values\n\n* `Array`: Array\n  * An array of arrays. Each sub-array represents a row.\n\nExample of return values\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "With parameter `columnNames: true`:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "#### Guidance\n\n* When using TypeScript, you can pass a [type parameter](https://developers.cloudflare.com/d1/worker-api/#typescript-support) to [`D1PreparedStatement::raw`](#raw) to return a typed result array.\n\n### `first()`\n\nRuns the prepared query (or queries), and returns the first row of the query result as an object. This does not return any metadata. Instead, it directly returns the object.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* `columnName`: String Optional\n  * Specify a `columnName` to return a value from a specific column in the first row of the query result.\n* None.\n  * Do not pass a parameter to obtain all columns from the first row.\n\n#### Return values\n\n* `firstRow`: Object Optional\n\n  * An object containing the first row of the query result.\n  * The return value will be further filtered to a specific attribute if `columnName` was specified.\n\n* `null`: null\n\n  * If the query returns no rows.\n\nExample of return values\n\nGet all the columns from the first row:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "Get a specific column from the first row:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "#### Guidance\n\n* If the query returns rows but `column` does not exist, then [`D1PreparedStatement::first`](#first) throws the `D1_ERROR` exception.\n* [`D1PreparedStatement::first`](#first) does not alter the SQL query. To improve performance, consider appending `LIMIT 1` to your statement.\n* When using TypeScript, you can pass a [type parameter](https://developers.cloudflare.com/d1/worker-api/#typescript-support) to [`D1PreparedStatement::first`](#first) to return a typed result object.\n\n</page>\n\n<page>\n---\ntitle: Return objects · Cloudflare D1 docs\ndescription: Some D1 Worker Binding APIs return a typed object.\nlastUpdated: 2025-12-02T18:27:05.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/d1/worker-api/return-object/\n  md: https://developers.cloudflare.com/d1/worker-api/return-object/index.md\n---\n\nSome D1 Worker Binding APIs return a typed object.\n\n| D1 Worker Binding API | Return object |\n| - | - |\n| [`D1PreparedStatement::run`](https://developers.cloudflare.com/d1/worker-api/prepared-statements/#run), [`D1Database::batch`](https://developers.cloudflare.com/d1/worker-api/d1-database/#batch) | `D1Result` |\n| [`D1Database::exec`](https://developers.cloudflare.com/d1/worker-api/d1-database/#exec) | `D1ExecResult` |\n\n## `D1Result`\n\nThe methods [`D1PreparedStatement::run`](https://developers.cloudflare.com/d1/worker-api/prepared-statements/#run) and [`D1Database::batch`](https://developers.cloudflare.com/d1/worker-api/d1-database/#batch) return a typed [`D1Result`](#d1result) object for each query statement. This object contains:\n\n* The success status\n* A meta object with the internal duration of the operation in milliseconds\n* The results (if applicable) as an array",
      "language": "unknown"
    },
    {
      "code": "### Example\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "## `D1ExecResult`\n\nThe method [`D1Database::exec`](https://developers.cloudflare.com/d1/worker-api/d1-database/#exec) returns a typed [`D1ExecResult`](#d1execresult) object for each query statement. This object contains:\n\n* The number of executed queries\n* The duration of the operation in milliseconds",
      "language": "unknown"
    },
    {
      "code": "### Example\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "Storing large numbers\n\nAny numeric value in a column is affected by JavaScript's 52-bit precision for numbers. If you store a very large number (in `int64`), then retrieve the same value, the returned value may be less precise than your original number.\n\n</page>\n\n<page>\n---\ntitle: Cache · Cloudflare Data Localization Suite docs\ndescription: In the following sections, we will give you some details about how\n  to configure Cache with Regional Services and Customer Metadata Boundary.\nlastUpdated: 2025-10-06T13:41:54.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/data-localization/how-to/cache/\n  md: https://developers.cloudflare.com/data-localization/how-to/cache/index.md\n---\n\nIn the following sections, we will give you some details about how to configure Cache with Regional Services and Customer Metadata Boundary.\n\n## Regional Services\n\nTo configure Regional Services for hostnames [proxied](https://developers.cloudflare.com/dns/proxy-status/) through Cloudflare and ensure that [eligible assets](https://developers.cloudflare.com/cache/concepts/default-cache-behavior/) are cached only in-region, follow these steps for the dashboard or API configuration:\n\n* Dashboard\n\n  1. In the Cloudflare dashboard, go to the **Records** page.\n\n     [Go to **Records**](https://dash.cloudflare.com/?to=/:account/:zone/dns/records)\n\n  2. Follow these steps to [create a DNS record](https://developers.cloudflare.com/dns/manage-dns-records/how-to/create-dns-records/).\n\n  3. From the **Region** dropdown, select the region you would like to use on your domain.\n\n  4. Select **Save**.\n\n* API\n\n  1. To create records with the API, use the [API POST](https://developers.cloudflare.com/api/resources/dns/subresources/records/methods/create/) command.\n  2. Run the [API POST](https://developers.cloudflare.com/data-localization/regional-services/get-started/#configure-regional-services-via-api) command on the hostname to create a `regional_hostnames` with a specific region.\n\nNote\n\nTake into consideration that only [Generic Global Tiered Cache](https://developers.cloudflare.com/cache/how-to/tiered-cache/#generic-global-tiered-cache) and [Custom Tiered Cache](https://developers.cloudflare.com/cache/how-to/tiered-cache/#custom-tiered-cache) respect Regional Services. [Smart Tiered Cache](https://developers.cloudflare.com/cache/how-to/tiered-cache/#smart-tiered-cache) is incompatible with Regional Services.\n\n## Customer Metadata Boundary\n\n[Cache Analytics](https://developers.cloudflare.com/cache/performance-review/cache-analytics/), Generic Global Tiered Cache and Custom Tiered Cache are compatible with Customer Metadata Boundary. With Customer Metadata Boundary set to EU, the **Caching** > **Tiered Cache** tab in the zone dashboard will not be populated.\n\nFor more information on CDN and caching, refer to the [Cache documentation](https://developers.cloudflare.com/cache/).\n\n</page>\n\n<page>\n---\ntitle: Cloudflare for SaaS · Cloudflare Data Localization Suite docs\ndescription: In the following sections, we will give you some details about how\n  to configure Cloudflare for SaaS with Regional Services and Customer Metadata\n  Boundary.\nlastUpdated: 2025-10-09T07:47:46.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/data-localization/how-to/cloudflare-for-saas/\n  md: https://developers.cloudflare.com/data-localization/how-to/cloudflare-for-saas/index.md\n---\n\nIn the following sections, we will give you some details about how to configure Cloudflare for SaaS with Regional Services and Customer Metadata Boundary.\n\n## Regional Services\n\nTo configure Regional Services for both hostnames [proxied](https://developers.cloudflare.com/dns/proxy-status/) through Cloudflare and the fallback origin, follow these steps for the dashboard or API configuration:\n\n* Dashboard\n\n  1. In the Cloudflare dashboard, go to the **Custom Hostnames** page.\n\n     [Go to **Custom Hostnames**](https://dash.cloudflare.com/?to=/:account/:zone/ssl-tls/custom-hostnames)\n\n  2. Follow these steps to [configure Cloudflare for SaaS](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/start/getting-started/).\n\n* API\n\n  1. Set the [fallback record](https://developers.cloudflare.com/api/resources/custom_hostnames/subresources/fallback_origin/methods/update/).\n  2. Create a [Custom Hostname](https://developers.cloudflare.com/api/resources/custom_hostnames/methods/create/).\n  3. Run the [API POST](https://developers.cloudflare.com/data-localization/regional-services/get-started/#configure-regional-services-via-api) command on the Custom Hostname to create a `regional_hostnames` with a specific region.\n\nThe Regional Services functionality can be extended to Custom Hostnames and this is dependent on the target of the alias.\n\nConsider the following example.\n\nNote\n\nAs a SaaS provider, I might want all of my customers to connect to the nearest data center to them and for all the processing and Cloudflare features to be applied there; however, I might have a few exceptions where I want the processing to only be done in the US.\n\nIn this case, I can just keep my fallback record with `Earth` as the processing region and have all my Custom Hostnames create a CNAME record and use the fallback record as the CNAME target. For any Custom Hostnames that need to be processed in the US, I will create a DNS record for example, `us.saasprovider.com` and set the processing region to `United States of America`. In order for the US processing region to be applied, my customers must create a CNAME record and use the `us.saasprovider.com` as the CNAME target. The origin associated with the Custom Hostname is not used to set the processing region, but instead to route the traffic to the right server.\n\nBelow you can find a breakdown of the different ways that you might configure Cloudflare for SaaS and the corresponding processing regions:\n\n* No processing region: `fallback.saasprovider.com`\n* Processing region is the `US`: `us.saasprovider.com`\n* User location: `UK` (closest datacenter: `LHR`)\n\n| Test | Custom Hostname | Target | Origin | Location |\n| - | - | - | - | - |\n| 1 | ​​`regionalservices-default.example.com` | `fallback.saasprovider.com` | default (fallback) | `LHR` |\n| 2 | `regionalservices-default2.example.com` | `us.saasprovider.com` | default (fallback) | `EWR` |\n| 3 | `regionalservices-custom.example.com` | `fallback.saasprovider.com` | `us.saasprovider.com` (custom) | `LHR` |\n| 4 | `regionalservices-custom2.example.com` | `us.saasprovider.com` | `us.saasprovider.com` (custom) | `EWR` |\n\n* In order to set a processing region for the fallback record to any of the available regions for Regional Services, create a new regional hostname entry for the fallback via a [POST](https://developers.cloudflare.com/data-localization/regional-services/get-started/#configure-regional-services-via-api) request.\n\n* To update the existing region (for example, from `EU` to `US`), make a [PATCH](https://developers.cloudflare.com/data-localization/regional-services/get-started/#configure-regional-services-via-api) request for the fallback to update the processing region accordingly.\n\n* To remove the regional services processing region and set it back to `Earth`, make a [DELETE](https://developers.cloudflare.com/data-localization/regional-services/get-started/#configure-regional-services-via-api) request to delete the region configuration.\n\n## Customer Metadata Boundary\n\nCloudflare for SaaS [Analytics](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/hostname-analytics/) based on [HTTP requests](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/zone/http_requests/) are fully supported by Customer Metadata Boundary.\n\nRefer to [Cloudflare for SaaS documentation](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/) for more information.\n\n</page>\n\n<page>\n---\ntitle: Durable Objects · Cloudflare Data Localization Suite docs\ndescription: In the following sections, we will give you some details about how\n  to configure Durable Objects with Regional Services and Customer Metadata\n  Boundary.\nlastUpdated: 2025-02-11T10:50:09.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/data-localization/how-to/durable-objects/\n  md: https://developers.cloudflare.com/data-localization/how-to/durable-objects/index.md\n---\n\nIn the following sections, we will give you some details about how to configure Durable Objects with Regional Services and Customer Metadata Boundary.\n\n## Regional Services\n\nTo configure Regional Services for hostnames [proxied](https://developers.cloudflare.com/dns/proxy-status/) through Cloudflare and ensure that processing of a Durable Object (DO) occurs only in-region, follow these steps:\n\n1. Follow the steps in the Durable Objects [Get Started](https://developers.cloudflare.com/durable-objects/get-started/) guide.\n2. [Restrict Durable Objects to a jurisdiction](https://developers.cloudflare.com/durable-objects/reference/data-location/#restrict-durable-objects-to-a-jurisdiction), in order to control where the DO itself runs and persists data, by creating a jurisidictional subnamespace in your Worker’s code.\n3. Follow the [Workers guide](https://developers.cloudflare.com/data-localization/how-to/workers/#regional-services) to configure a custom domain with Regional Services, in order to control the regions from which Cloudflare responds to requests.\n\n## Customer Metadata Boundary\n\nDO Logs and Analytics are not available outside the US region when using Customer Metadata Boundary. With Customer Metadata Boundary set to `EU`, **Workers & Pages** > **Workers** > **Metrics** tab related to DO in the zone dashboard will not be populated.\n\nRefer to the [Durable Objects documentation](https://developers.cloudflare.com/durable-objects/) for more information.\n\n</page>\n\n<page>\n---\ntitle: Load Balancing · Cloudflare Data Localization Suite docs\ndescription: In the following sections, we will give you some details about how\n  to configure Load Balancing with Regional Services and Customer Metadata\n  Boundary.\nlastUpdated: 2025-10-06T13:41:54.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/data-localization/how-to/load-balancing/\n  md: https://developers.cloudflare.com/data-localization/how-to/load-balancing/index.md\n---\n\nIn the following sections, we will give you some details about how to configure Load Balancing with Regional Services and Customer Metadata Boundary.\n\n## Regional Services\n\nYou can load balance traffic at different levels of the networking stack depending on the [proxy mode](https://developers.cloudflare.com/load-balancing/understand-basics/proxy-modes/): Layer 7 (`HTTP/S`) and Layer 4 (`TCP`) are supported; however, `DNS-only` is not supported, as it is not [proxied](https://developers.cloudflare.com/dns/proxy-status/).\n\nTo configure Regional Services for hostnames [proxied](https://developers.cloudflare.com/dns/proxy-status/) through Cloudflare and ensure that the Load Balancer is available only in-region, follow these steps for the dashboard or API configuration:\n\n* Dashboard\n\n  1. In the Cloudflare dashboard, go to the **Load balancing** page.\n\n     [Go to **Load Balancing**](https://dash.cloudflare.com/?to=/:account/:zone/traffic/load-balancing)\n\n  2. Follow the steps to [create a load balancer](https://developers.cloudflare.com/load-balancing/load-balancers/create-load-balancer/#create-a-load-balancer).\n\n  3. From the **Data Localization** dropdown, select the region you would like to use on your domain.\n\n  4. Select **Next** and continue with the regular setup.\n\n  5. Select **Save**.\n\n* API\n\n  1. Follow the instructions outlined to [create a load balancer](https://developers.cloudflare.com/load-balancing/load-balancers/create-load-balancer/#create-a-load-balancer) via API.\n  2. Run the [API POST](https://developers.cloudflare.com/data-localization/regional-services/get-started/#configure-regional-services-via-api) command on the Load Balancer hostname to create a `regional_hostnames` with a specific region.\n\n## Customer Metadata Boundary\n\n[Load Balancing Analytics](https://developers.cloudflare.com/load-balancing/reference/load-balancing-analytics/) are not available outside the US region when using Customer Metadata Boundary.\n\nWith Customer Metadata Boundary set to `EU`, **Traffic** > **Load Balancing Analytics** > **Overview and Latency** tab in the zone dashboard will not be populated.\n\nRefer to the [Load Balancing documentation](https://developers.cloudflare.com/load-balancing/) for more information.\n\n</page>\n\n<page>\n---\ntitle: Pages · Cloudflare Data Localization Suite docs\ndescription: In the following sections, we will give you some details about how\n  to configure Pages with Regional Services and Customer Metadata Boundary.\nlastUpdated: 2025-09-03T10:05:39.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/data-localization/how-to/pages/\n  md: https://developers.cloudflare.com/data-localization/how-to/pages/index.md\n---\n\nIn the following sections, we will give you some details about how to configure Pages with Regional Services and Customer Metadata Boundary.\n\n## Regional Services\n\nTo configure Regional Services for hostnames [proxied](https://developers.cloudflare.com/dns/proxy-status/) through Cloudflare and ensure that processing of a Pages project occurs only in-region, follow these steps for the dashboard or API configuration:\n\n* Dashboard\n\n  1. In the Cloudflare dashboard, go to the **Workers & Pages** page.\n\n     [Go to **Workers & Pages**](https://dash.cloudflare.com/?to=/:account/workers-and-pages)\n\n  2. Select your Pages project.\n\n  3. Follow these steps to [create a Custom Domain](https://developers.cloudflare.com/pages/configuration/custom-domains/).\n\n  4. Go to the **DNS** of the zone you configured the Custom Domain for.\n\n  5. From the **Region** dropdown, select the region you would like to use on your domain.\n\n  6. Select **Save**.\n\n* API\n\n  1. Use the [API POST](https://developers.cloudflare.com/api/resources/pages/subresources/projects/subresources/domains/methods/create/) command to add a Custom Domain to a Pages project.\n  2. Run the [API POST](https://developers.cloudflare.com/data-localization/regional-services/get-started/#configure-regional-services-via-api) command on the Pages Custom Domain to create a `regional_hostnames` with a specific Region.\n\nNote\n\nRegional Services only applies to the Custom Domain configured for a Pages project.\n\n## Customer Metadata Boundary\n\nCustomer Metadata Boundary applies to the Custom Domain configured, as well as the [\\*.pages.dev](https://developers.cloudflare.com/pages/configuration/preview-deployments/) subdomain. You also have the option to disable access to the [`.dev` domain](https://developers.cloudflare.com/pages/configuration/custom-domains/#disable-access-to-pagesdev-subdomain).\n\nFor information on available Analytics and Metrics, review the [Cloudflare product compatibility](https://developers.cloudflare.com/data-localization/compatibility/) page.\n\nIt is recommended not to store any Personally Identifiable Information (PII) in the Pages project's static assets.\n\nNote\n\nPage [Functions](https://developers.cloudflare.com/pages/functions/) are implemented as Cloudflare Workers. Refer to the Workers section for more information.\n\nRefer to the [Pages documentation](https://developers.cloudflare.com/pages) for more information.\n\n</page>\n\n<page>\n---\ntitle: R2 Object Storage · Cloudflare Data Localization Suite docs\ndescription: In the following sections, we will give you some details about how\n  to configure R2 with Regional Services and Customer Metadata Boundary.\nlastUpdated: 2025-09-03T10:05:39.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/data-localization/how-to/r2/\n  md: https://developers.cloudflare.com/data-localization/how-to/r2/index.md\n---\n\nIn the following sections, we will give you some details about how to configure R2 with Regional Services and Customer Metadata Boundary.\n\n## Regional Services\n\nTo configure Regional Services for hostnames [proxied](https://developers.cloudflare.com/dns/proxy-status/) through Cloudflare and ensure that processing of requesting objects from a [R2 Bucket](https://developers.cloudflare.com/r2/buckets/) occurs only in-region, follow these steps:\n\n1. In the Cloudflare dashboard, go to the **R2** page.\n\n   [Go to **Overview**](https://dash.cloudflare.com/?to=/:account/r2/overview)\n\n2. Follow the steps to [create a Bucket](https://developers.cloudflare.com/r2/buckets/create-buckets/).\n\n3. [Connect a bucket to a custom domain](https://developers.cloudflare.com/r2/buckets/public-buckets/#connect-a-bucket-to-a-custom-domain).\n\n4. Run the [API POST](https://developers.cloudflare.com/data-localization/regional-services/get-started/#configure-regional-services-via-api) command on the configured bucket custom domain to create a `regional_hostnames` with a specific region.\n\nRegional Services only applies to the custom domain configured for an R2 Bucket.\n\n### Send logs to R2 via S3-Compatible endpoint\n\nThe following instructions will show you how to set up a Logpush job using an S3-compatible endpoint to store logs in an R2 bucket in the jurisdiction of your choice.\n\n1. Create an [R2 bucket](https://developers.cloudflare.com/r2/get-started/) in your Cloudflare account and select the [jurisdiction](https://developers.cloudflare.com/r2/reference/data-location/#set-jurisdiction-via-the-cloudflare-dashboard) you would like to use.\n\n2. Generate an API token for your R2 bucket. You have the following two options:\n\nGenerate a token for a specific bucket (recommended)\n\nGo to the R2 section of your Cloudflare dashboard and select **Manage R2 API Tokens** to generate a token directly tied to your specific bucket. You can follow the instructions in the [Authentication](https://developers.cloudflare.com/r2/api/tokens/) section.\n\nGenerate a token for all buckets\n\nYou can generate a API token in **Manage Account** > **Account API Tokens** or you can create a user-specific token:\n\n1. Go to **My Profile** > **API Tokens**\n2. Select **Create Token** > **Create Custom Token**\n3. Choose **Account** > **Workers R2 Storage** > **Edit** to set permissions.\n4. To test your token, copy the `curl` command and paste it into a terminal.",
      "language": "unknown"
    },
    {
      "code": "The result:",
      "language": "unknown"
    },
    {
      "code": "1. Generate a SHA-256 hash of the token:",
      "language": "unknown"
    },
    {
      "code": "This command will output a hash similar to `dxxxx391b`.\n\n1. Set up a Logpush destination using [S3-compatible endpoint](https://developers.cloudflare.com/logs/logpush/logpush-job/enable-destinations/s3-compatible-endpoints/) and fill in the following fields:\n\n* **Bucket**: Enter the name of the R2 bucket you created with the jurisdiction you would like to use.\n* **Path** (optional): If you want, you can specify a folder path to organize your logs.\n* **Endpoint URL**: Provide the S3 API endpoint for your bucket in the format `<account-id>.eu.r2.cloudflarestorage.com`. Do not include the bucket name, as it was set in the first field.\n* **Bucket Region**: For instance, use `WEUR` to specify the EU region.\n* **Access Key ID**: Enter the Token ID created previously (`325xxxxcd`).\n* **Secret Access Key**: Use the SHA-256 hash of the token (`dxxxx391b`).\n\nComplete the configuration by selecting the fields you want to push to your R2 bucket.\n\n## Customer Metadata Boundary\n\nWith Customer Metadata Boundary set to `EU`, **R2** > **Bucket** > [**Metrics**](https://developers.cloudflare.com/r2/platform/metrics-analytics/) tab in the account dashboard will be populated.\n\nNote\n\nAdditionally, customers can create R2 buckets with [jurisdictional restrictions set to EU](https://developers.cloudflare.com/r2/reference/data-location/#jurisdictional-restrictions). In this case, we recommend [using jurisdictions with the S3 API](https://developers.cloudflare.com/r2/reference/data-location/#using-jurisdictions-with-the-s3-api).\n\nRefer to the [R2 documentation](https://developers.cloudflare.com/r2/) for more information.\n\n</page>\n\n<page>\n---\ntitle: Workers · Cloudflare Data Localization Suite docs\ndescription: In the following sections, we will give you some details about how\n  to configure Workers with Regional Services and Customer Metadata Boundary.\nlastUpdated: 2025-09-03T10:05:39.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/data-localization/how-to/workers/\n  md: https://developers.cloudflare.com/data-localization/how-to/workers/index.md\n---\n\nIn the following sections, we will give you some details about how to configure Workers with Regional Services and Customer Metadata Boundary.\n\n## Regional Services\n\nTo configure Regional Services for hostnames [proxied](https://developers.cloudflare.com/dns/proxy-status/) through Cloudflare and ensure that processing of a Workers project occurs only in-region, follow these steps:\n\n1. In the Cloudflare dashboard, go to the **Workers & Pages** page.\n\n   [Go to **Workers & Pages**](https://dash.cloudflare.com/?to=/:account/workers-and-pages)\n\n2. Select your Workers project.\n\n3. Follow the steps to [create a custom domain](https://developers.cloudflare.com/workers/configuration/routing/custom-domains/).\n\n4. Run the [API POST](https://developers.cloudflare.com/data-localization/regional-services/get-started/#configure-regional-services-via-api) command on the configured Workers Custom Domain to create a `regional_hostnames` with a specific region.\n\n### Caveats\n\nRegional Services only applies to the custom domain configured for a Workers project. Therefore, it will run only in-region Cloudflare locations.\n\nRegional Services does not apply to [subrequests](https://developers.cloudflare.com/workers/platform/limits/#subrequests).\n\nRegional Services does not apply to other Worker triggers, like [Queues](https://developers.cloudflare.com/queues/) or [Cron Triggers](https://developers.cloudflare.com/workers/configuration/cron-triggers/).\n\n## Customer Metadata Boundary\n\nCustomer Metadata Boundary applies to the custom domain configured, as well as the [`*.workers.dev`](https://developers.cloudflare.com/workers/configuration/routing/workers-dev/) subdomain.\n\nWorkers [Metrics and Analytics](https://developers.cloudflare.com/workers/observability/metrics-and-analytics/) are not available outside the US region when using Customer Metadata Boundary.\n\nWith Customer Metadata Boundary set to `EU`, **Workers & Pages** > **Workers** > **Metrics** tab the zone dashboard will not be populated.\n\nNote\n\nIt is recommended to not store any Personally Identifiable Information (PII) in the Workers code. If sensitive information needs to be used, it is recommended to use [Secrets](https://developers.cloudflare.com/workers/configuration/secrets/).\n\nRefer to the [Workers documentation](https://developers.cloudflare.com/workers/) for more information.\n\n</page>\n\n<page>\n---\ntitle: Zero Trust · Cloudflare Data Localization Suite docs\ndescription: In the following sections, we will give you some details about how\n  different Zero Trust products can be used with the Data Localization Suite.\nlastUpdated: 2025-12-23T00:33:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/data-localization/how-to/zero-trust/\n  md: https://developers.cloudflare.com/data-localization/how-to/zero-trust/index.md\n---\n\nIn the following sections, we will give you some details about how different Zero Trust products can be used with the Data Localization Suite.\n\n## Gateway\n\nRegional Services can be used with Gateway in all [supported regions](https://developers.cloudflare.com/data-localization/region-support/). Be aware that Regional Services only apply when using the WARP client in Gateway with WARP mode.\n\n### Egress policies\n\nEnterprise customers can purchase a [dedicated egress IP](https://developers.cloudflare.com/cloudflare-one/traffic-policies/egress-policies/dedicated-egress-ips/) (IPv4 and IPv6) or range of IPs geolocated to one or more Cloudflare network locations. This allows your egress traffic to geolocate to the city selected in your [egress policies](https://developers.cloudflare.com/cloudflare-one/traffic-policies/egress-policies/).\n\n### HTTP policies\n\nAs part of Regional Services, Cloudflare Gateway will only perform [TLS decryption](https://developers.cloudflare.com/cloudflare-one/traffic-policies/http-policies/tls-decryption/) when using the [WARP client](https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/warp/) (in default [Gateway with WARP mode](https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/warp/configure-warp/warp-modes/)).\n\n#### Data Loss Prevention (DLP)\n\nYou are able to [log the payload of matched DLP rules](https://developers.cloudflare.com/cloudflare-one/data-loss-prevention/dlp-policies/logging-options/#log-the-payload-of-matched-rules) and encrypt them with your public key so that only you can examine them later.\n\n[Cloudflare cannot decrypt encrypted payloads](https://developers.cloudflare.com/cloudflare-one/data-loss-prevention/dlp-policies/logging-options/#data-privacy).\n\n### Network policies\n\nYou are able to [configure SSH proxy and command logs](https://developers.cloudflare.com/cloudflare-one/traffic-policies/network-policies/ssh-logging/). Generate a Hybrid Public Key Encryption (HPKE) key pair and upload the public key `sshkey.pub` to your dashboard. All proxied SSH commands are immediately encrypted using this public key. The matching private key – which is in your possession – is required to view logs.\n\n### DNS policies\n\nRegional Services controls where Cloudflare decrypts traffic; because most DNS traffic is not encrypted, Gateway DNS cannot be regionalized using Regional Services.\n\nRefer to the [WARP Settings](https://developers.cloudflare.com/data-localization/how-to/zero-trust/#warp-settings) section below for more information.\n\n### Custom certificates\n\nYou can [bring your own certificate](https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/user-side-certificates/custom-certificate/) to Gateway but these cannot yet be restricted to a specific region.\n\n### Logs and Analytics\n\nBy default, Cloudflare will store and deliver logs from data centers across our global network. To maintain regional control over your data, you can use [Customer Metadata Boundary](https://developers.cloudflare.com/data-localization/metadata-boundary/) and restrict data storage to a specific geographic region. For more information refer to the section about [Logpush datasets supported](https://developers.cloudflare.com/data-localization/metadata-boundary/logpush-datasets/).\n\nCustomers also have the option to reduce the logs that Cloudflare stores:\n\n* You can [exclude PII from logs](https://developers.cloudflare.com/cloudflare-one/insights/logs/gateway-logs/manage-pii/)\n* You can [disable logging, or only log blocked requests](https://developers.cloudflare.com/cloudflare-one/insights/logs/gateway-logs/#selective-logging).\n\n#### Verify regional map application\n\nTo verify that your regional map is being applied correctly, check the `IngressColoName` field in your [Zero Trust Network Session logs](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/zero_trust_network_sessions/#ingresscoloname). This field shows the name of the Cloudflare data center where traffic ingressed. Since regionalization is applied upstream from Gateway, the ingress data center will be located within your configured regional map, confirming that traffic is being processed in the correct region.\n\n## Access\n\nTo ensure that all reverse proxy requests for applications protected by Cloudflare Access will only occur in FedRAMP-compliant data centers, you should use [Regional Services](https://developers.cloudflare.com/data-localization/regional-services/get-started/) with the region set to FedRAMP.\n\n## Cloudflare Tunnel\n\nYou can [configure Cloudflare Tunnel](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/configure-tunnels/cloudflared-parameters/run-parameters/#region) to only connect to data centers within the United States, regardless of where the software was deployed.\n\n## WARP settings\n\n### Local Domain Fallback\n\nYou can use the WARP setting [Local Domain Fallback](https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/warp/configure-warp/route-traffic/local-domains/) in order to use a private DNS resolver, which you can manage yourself.\n\n### Split Tunnels\n\n[Split Tunnels](https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/warp/configure-warp/route-traffic/split-tunnels/) allow you to decide which IP addresses/ranges and/or domains are routed through or excluded from Cloudflare.\n\nWarning\n\nGateway policies will not apply for excluded traffic.\n\n</page>\n\n<page>\n---\ntitle: FAQs · Cloudflare Data Localization Suite docs\ndescription: Commonly asked questions about Cloudflare's Customer Metadata Boundary.\nlastUpdated: 2025-06-03T08:54:49.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/data-localization/metadata-boundary/faq/\n  md: https://developers.cloudflare.com/data-localization/metadata-boundary/faq/index.md\n---\n\n## What data is covered by the Customer Metadata Boundary?\n\nNearly all end user metadata is covered by the Customer Metadata Boundary. This includes all of the end user data for which Cloudflare is a processor, as defined in the [Cloudflare Privacy Policy](https://www.cloudflare.com/privacypolicy/). Cloudflare is a data processor of Customer Logs, which are defined as end user logs that we make available to our customers via the dashboard or other online interfaces. End users are those who access or use our customers' domains, networks, websites, application programming interfaces, and applications.\n\nSpecific examples of this data include all of the analytics in our dashboard and APIs on requests, responses, and security products associated and all of the logs received through Logpush.\n\n## What data is not covered by the Customer Metadata Boundary?\n\nSome of the data for which Cloudflare is a controller, as defined in the [Cloudflare Privacy Policy](https://www.cloudflare.com/privacypolicy/).\n\nSome examples:\n\n* Customer account data (for example, name and billing information).\n\n* Customer configuration data (for example, the content of WAF custom rules).\n\n* Metadata that is “operational” in nature — data needed for Cloudflare to properly operate our network. This includes metadata such as:\n\n  * System data generated for debugging (for example, application logs from internal systems, core dumps).\n  * Networking flow data (for example, sFlow from our routers), including data on DDoS attacks.\n\n## Who can use the Customer Metadata Boundary?\n\nCurrently, this is available for Enterprise customers as part of the Data Localization Suite.\n\nThe Customer Metadata Boundary is for customers who want to limit personal data transfer outside the EU or the US (depending on the customer's selected region). These customers should already be using Regional Services, which ensures that traffic content is only ever decrypted within the geographic region specified by the customer.\n\n## What are the analytics products available for Metadata Boundary?\n\nHTTP and Firewall analytics are available.\n\nAt the moment, there are no analytics available for Workers, DNS, and Load Balancing. Additionally, there are no dashboard logs or analytics for [Gateway](https://developers.cloudflare.com/cloudflare-one/insights/logs/gateway-logs/#limitations). Enterprise users can still export Gateway logs via [Logpush](https://developers.cloudflare.com/cloudflare-one/insights/logs/logpush/).\n\n</page>\n\n<page>\n---\ntitle: Get started · Cloudflare Data Localization Suite docs\ndescription: You can configure the Metadata Boundary to select the region where\n  your logs and analytics are stored via API or dashboard.\nlastUpdated: 2025-10-09T07:47:46.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/data-localization/metadata-boundary/get-started/\n  md: https://developers.cloudflare.com/data-localization/metadata-boundary/get-started/index.md\n---\n\nYou can configure the Metadata Boundary to select the region where your logs and analytics are stored via API or dashboard.\n\nCurrently, this can only be applied at the account-level. If you only want the Metadata Boundary to be applied on a portion of zones beneath the same account, you will have to [move the rest of zones to a new account](https://developers.cloudflare.com/fundamentals/manage-domains/move-domain/).\n\n## Configure Customer Metadata Boundary in the dashboard\n\nTo configure Customer Metadata Boundary in the dashboard:\n\n1. In the Cloudflare dashboard, go to the **Settings** page.\n\n   [Go to **Settings**](https://dash.cloudflare.com/?to=/:account/configurations)\n\n2. In **Customer Metadata Boundary**, select the region you want to use. You have the option to select `EU` or `US`. If you want to select both regions, select `Global` instead.\n\n## Configure Customer Metadata Boundary via API\n\nYou can also configure Customer Metadata Boundary via API.\n\nCurrently, only SuperAdmins and Admin roles can edit DLS configurations. Use the **Account-level Logs:Read/Write** API permissions for the `/logs/control/cmb` endpoint to read/write Customer Metadata Boundary configurations.\n\nThese are some examples of API requests.\n\nGet current regions\n\nHere is an example request using cURL to get current regions (if any):\n\nRequired API token permissions\n\nAt least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n* `Logs Write`\n* `Logs Read`",
      "language": "unknown"
    },
    {
      "code": "Setting regions\n\nHere is an example request using cURL to set regions:\n\nRequired API token permissions\n\nAt least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n* `Logs Write`",
      "language": "unknown"
    },
    {
      "code": "This will overwrite any previous regions. Change will be in effect after several minutes.\n\nDelete regions\n\nHere is an example request using cURL to delete regions:\n\nRequired API token permissions\n\nAt least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n* `Logs Write`",
      "language": "unknown"
    },
    {
      "code": "## View or change settings\n\nTo view or change your Customer Metadata Boundary setting:\n\n1. In the Cloudflare dashboard, go to the **Settings** page.\n\n   [Go to **Settings**](https://dash.cloudflare.com/?to=/:account/configurations)\n\n2. Go to **Preferences**.\n\n3. Locate the **Customer Metadata Boundary** section.\n\n</page>\n\n<page>\n---\ntitle: GraphQL datasets · Cloudflare Data Localization Suite docs\ndescription: The table below shows a non-exhaustive list of GraphQL Analytics\n  API fields that respect CMB configuration and are available in both the US and\n  the EU or only in the US.\nlastUpdated: 2025-09-17T14:35:09.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/data-localization/metadata-boundary/graphql-datasets/\n  md: https://developers.cloudflare.com/data-localization/metadata-boundary/graphql-datasets/index.md\n---\n\nThe table below shows a non-exhaustive list of GraphQL Analytics API fields that respect CMB configuration and are available in both the US and the EU or only in the US.\n\n| Suite/Category | Product | GraphQL Analytics API Field(s) supported in |\n| - | - | - |\n| Application Performance | Caching/CDN | US and EU `httpRequestsAdaptive` `httpRequestsAdaptiveGroups` `httpRequestsOverviewAdaptiveGroups` US only `httpRequests1mGroups` `httpRequests1hGroups` `httpRequests1dGroups` |\n| Cache Reserve | | US and EU `cacheReserveOperationsAdaptiveGroups` `cacheReserveRequestsAdaptiveGroups` `cacheReserveStorageAdaptiveGroups` |\n| DNS | | US only `dnsAnalyticsAdaptive` `dnsAnalyticsAdaptiveGroups` |\n| Image Resizing | | US only `imageResizingRequests1mGroups` `imagesRequestsAdaptiveGroups` `imagesUniqueTransformations` |\n| Load Balancing | | US only [`loadBalancingRequestsAdaptive`](https://developers.cloudflare.com/load-balancing/reference/load-balancing-analytics/#graphql-analytics) [`loadBalancingRequestsAdaptiveGroups`](https://developers.cloudflare.com/load-balancing/reference/load-balancing-analytics/#graphql-analytics) `healthCheckEventsAdaptive` `healthCheckEventsAdaptiveGroups` |\n| Stream Delivery | Same as Caching/CDN | |\n| Tiered Caching | | US and EU Only the field `upperTierColoName` part of `httpRequestsAdaptive` and `httpRequestsAdaptiveGroups` |\n| Secondary DNS | Same as DNS | |\n| Waiting Room | | US and EU [`waitingRoomAnalyticsAdaptive`](https://developers.cloudflare.com/waiting-room/waiting-room-analytics/#graphql-analytics) [`waitingRoomAnalyticsAdaptiveGroups`](https://developers.cloudflare.com/waiting-room/waiting-room-analytics/#graphql-analytics) |\n| Web Analytics / Real User Monitoring (RUM) | | US only `rumWebVitalsEventsAdaptive` `rumWebVitalsEventsAdaptiveGroups` `rumPerformanceEventsAdaptiveGroups` `rumPageloadEventsAdaptiveGroups` |\n| Zaraz | | US and EU `zarazActionsAdaptiveGroups` `zarazTrackAdaptiveGroups` `zarazTriggersAdaptiveGroups` |\n| Application Security | Advanced Certificate Manager | US and EU Only the fields `clientSSLProtocol` and `ja3Hash` part of `httpRequestsAdaptive` and `httpRequestsAdaptiveGroups` |\n| Advanced DDoS Protection | | US and EU [`dosdAttackAnalyticsGroups`](https://developers.cloudflare.com/analytics/graphql-api/migration-guides/network-analytics-v2/node-reference/) [`dosdNetworkAnalyticsAdaptiveGroups`](https://developers.cloudflare.com/analytics/graphql-api/migration-guides/network-analytics-v2/node-reference/) [`flowtrackdNetworkAnalyticsAdaptiveGroups`](https://developers.cloudflare.com/analytics/graphql-api/migration-guides/network-analytics-v2/node-reference/) `advancedTcpProtectionNetworkAnalyticsAdaptiveGroups` `advancedDnsProtectionNetworkAnalyticsAdaptiveGroups` |\n| API Shield | | US and EU [`apiGatewayGraphqlQueryAnalyticsGroups`](https://developers.cloudflare.com/api-shield/security/graphql-protection/api/#gather-graphql-statistics) `apiGatewayMatchedSessionIDsAdaptiveGroups` US only `apiRequestSequencesGroups` |\n| Bot Management | | US and EU `httpRequestsAdaptive` [`httpRequestsAdaptiveGroups`](https://developers.cloudflare.com/analytics/graphql-api/migration-guides/graphql-api-analytics/) [`firewallEventsAdaptive`](https://developers.cloudflare.com/analytics/graphql-api/tutorials/querying-firewall-events/) [`firewallEventsAdaptiveGroups`](https://blog.cloudflare.com/how-we-used-our-new-graphql-api-to-build-firewall-analytics/) |\n| DNS Firewall | Same as DNS | |\n| DMARC Management | | US and EU `dmarcReportsAdaptive` `dmarcReportsSourcesAdaptiveGroups` |\n| Page Shield | | US and EU [`pageShieldReportsAdaptiveGroups`](https://developers.cloudflare.com/page-shield/policies/violations/#get-policy-violations-via-graphql-api) |\n| SSL | | US and EU Only the fields `clientSSLProtocol` and `ja3Hash` part of `httpRequestsAdaptive` and `httpRequestsAdaptiveGroups` |\n| SSL 4 SaaS | | US and EU [clientRequestHTTPHost](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/hostname-analytics/#explore-customer-usage) Refer to [GraphQL Tutorial on querying HTTP events by hostname](https://developers.cloudflare.com/analytics/graphql-api/tutorials/end-customer-analytics/) |\n| Turnstile | | US and EU [`turnstileAdaptiveGroups`](https://developers.cloudflare.com/turnstile/turnstile-analytics/#graphql) |\n| WAF/L7 Firewall | | US and EU [`firewallEventsAdaptive`](https://developers.cloudflare.com/analytics/graphql-api/tutorials/querying-firewall-events/) [`firewallEventsAdaptiveGroups`](https://blog.cloudflare.com/how-we-used-our-new-graphql-api-to-build-firewall-analytics/) `firewallEventsAdaptiveByTimeGroups` |\n| Developer Platform | Cloudflare Images | US only `imagesRequestsAdaptiveGroups` |\n| Cloudflare Pages | | US only `pagesFunctionsInvocationsAdaptiveGroups`  |\n| Durable Objects | | US only [`durableObjectsInvocationsAdaptiveGroups`](https://developers.cloudflare.com/durable-objects/observability/metrics-and-analytics/) [`durableObjectsPeriodicGroups`](https://developers.cloudflare.com/durable-objects/observability/metrics-and-analytics/) [`durableObjectsStorageGroups`](https://developers.cloudflare.com/durable-objects/observability/metrics-and-analytics/) [`durableObjectsSubrequestsAdaptiveGroups`](https://developers.cloudflare.com/durable-objects/observability/metrics-and-analytics/) |\n| Email Routing | | US and EU `emailRoutingAdaptive` `emailRoutingAdaptiveGroups` |\n| R2 | | US and EU `r2OperationsAdaptiveGroups` `r2StorageAdaptiveGroups` |\n| Stream | | US only [`streamMinutesViewedAdaptiveGroups`](https://developers.cloudflare.com/stream/getting-analytics/fetching-bulk-analytics/) [`videoPlaybackEventsAdaptiveGroups`](https://developers.cloudflare.com/stream/getting-analytics/fetching-bulk-analytics/) [`videoBufferEventsAdaptiveGroups`](https://developers.cloudflare.com/stream/getting-analytics/fetching-bulk-analytics/) [`videoQualityEventsAdaptiveGroups`](https://developers.cloudflare.com/stream/getting-analytics/fetching-bulk-analytics/) |\n| Workers (deployed on a Zone) | | US and EU `workerPlacementAdaptiveGroups` US only `workersAnalyticsEngineAdaptiveGroups` `workersZoneInvocationsAdaptiveGroups` `workersZoneSubrequestsAdaptiveGroups` `workersOverviewRequestsAdaptiveGroups` `workersOverviewDataAdaptiveGroups` [`workersInvocationsAdaptive`](https://developers.cloudflare.com/analytics/graphql-api/tutorials/querying-workers-metrics/) `workersInvocationsScheduled` `workersSubrequestsAdaptiveGroups` |\n| Network Services | Network Error Logging (NEL) / Edge Reachability / Last Mile Insights | US only `nelReportsAdaptiveGroups` |\n| Magic Firewall | | US only [`magicFirewallSamplesAdaptiveGroups`](https://developers.cloudflare.com/magic-firewall/tutorials/graphql-analytics/) [`magicFirewallNetworkAnalyticsAdaptiveGroups`](https://developers.cloudflare.com/magic-firewall/tutorials/graphql-analytics/#example-queries-for-magic-firewall) |\n| Magic Network Monitoring | | US only [`mnmFlowDataAdaptiveGroups`](https://developers.cloudflare.com/magic-network-monitoring/tutorials/graphql-analytics/) |\n| Magic Transit | | US and EU [`magicTransitNetworkAnalyticsAdaptiveGroups`](https://developers.cloudflare.com/analytics/graphql-api/migration-guides/network-analytics-v2/node-reference/) [`flowtrackdNetworkAnalyticsAdaptiveGroups`](https://developers.cloudflare.com/analytics/graphql-api/migration-guides/network-analytics-v2/node-reference/) `magicTransitTunnelHealthCheckSLOsAdaptiveGroups` [`magicTransitTunnelHealthChecksAdaptiveGroups`](https://developers.cloudflare.com/analytics/graphql-api/tutorials/querying-magic-transit-tunnel-healthcheck-results/) [`magicTransitTunnelTrafficAdaptiveGroups`](https://developers.cloudflare.com/magic-transit/analytics/query-bandwidth/) |\n| Magic WAN | | US only `MagicWANConnectorMetricsAdaptiveGroups` |\n| Spectrum | | US and EU [`spectrumNetworkAnalyticsAdaptiveGroups`](https://developers.cloudflare.com/analytics/graphql-api/migration-guides/network-analytics-v2/node-reference/) |\n| Platform | GraphQL Analytics API | US and EU [All GraphQL Analytics API datasets](https://developers.cloudflare.com/analytics/graphql-api/features/discovery/introspection/) |\n| Logpush | | US only [`logpushHealthAdaptiveGroups`](https://developers.cloudflare.com/logs/logpush/alerts-and-analytics/#enable-logpush-health-analytics)  |\n| Zero Trust | Access | US and EU [`accessLoginRequestsAdaptiveGroups`](https://developers.cloudflare.com/analytics/graphql-api/tutorials/querying-access-login-events/) |\n| Browser Isolation | | US and EU Only the field `isIsolated` part of `gatewayL7RequestsAdaptiveGroups` |\n| DLP | Part of Gateway HTTP / Gateway L7 | |\n| Gateway | | US and EU `gatewayL7RequestsAdaptiveGroups` `gatewayL4SessionsAdaptiveGroups` `gatewayResolverQueriesAdaptiveGroups` `gatewayResolverByCategoryAdaptiveGroups` `gatewayResolverByRuleExecutionPerformanceAdaptiveGroups` US only `gatewayL4DownstreamSessionsAdaptiveGroups` `gatewayL4UpstreamSessionsAdaptiveGroups` |\n| WARP | | US and EU `warpDeviceAdaptiveGroups` |\n\n</page>\n\n<page>\n---\ntitle: Logpush datasets · Cloudflare Data Localization Suite docs\ndescription: The table below lists the Logpush datasets that support zones or\n  accounts with Customer Metadata Boundary (CMB) enabled. The column Respects\n  CMB indicates whether enabling CMB impacts the dataset (yes/no). The last two\n  columns inform you if CMB is available with US and EU.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/data-localization/metadata-boundary/logpush-datasets/\n  md: https://developers.cloudflare.com/data-localization/metadata-boundary/logpush-datasets/index.md\n---\n\nThe table below lists the [Logpush datasets](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/) that support zones or accounts with Customer Metadata Boundary (CMB) enabled. The column **Respects CMB** indicates whether enabling CMB impacts the dataset (yes/no). The last two columns inform you if CMB is available with US and EU.\n\nBe aware that if you enable CMB for a dataset that does not support your region, no data will be pushed to your destination.\n\n| Dataset name | Level | Respects CMB | Available with US CMB region | Available with EU CMB region |\n| - | - | - | - | - |\n| HTTP requests | Zone | ✅ | ✅ | ✅ |\n| Firewall events | Zone | ✅ | ✅ | ✅ |\n| DNS logs | Zone | ✅ | ✅ | ✅ |\n| DNS Firewall logs | Account | ✅ | ✅ | ✅ |\n| Spectrum events | Zone | ✅ | ✅ | ✅ |\n| Magic IDS Detections | Account | ✅ | ✅ | ✅ |\n| Workers Trace Events | Account | ✅ | ✅ | ✅ |\n| Zero Trust Sessions | Account | ✅ | ✅ | ✅ |\n| Gateway DNS | Account | ✅ | ✅ | ✅ |\n| Gateway Network | Account | ✅ | ✅ | ✅ |\n| Gateway HTTP | Account | ✅ | ✅ | ✅ |\n| Page Shield | Zone | ✅ | ✅ | ✅ |\n| Sinkhole Events | Account | ✅ | ✅ | ✅ |\n| AI Gateway Events | Account | ✅ | ✅ | ✅ |\n| DLP Forensic Copies | Account | N/A[1](#user-content-fn-1) | ✘ | ✘ |\n| Email security Alerts | Account | ✅ | ✅ | ✅ |\n| Zaraz Events | Zone | ✅ | ✅ | ✅ |\n| Browser Isolation User Actions | Account | ✅ | ✅ | ✅ |\n| NEL reports | Zone | ✘ | ✅ | ✘ |\n| CASB Findings | Account | ✘ | ✅ | ✘ |\n| Network Analytics Logs | Account | ✅ | ✅ | ✅ |\n| Device Posture Results | Account | ✘ | ✅ | ✘ |\n| Audit Logs | Account | ✘ | ✅ | ✘ |\n| Access Requests | Account | ✅ | ✅ | ✅ |\n| IPSec Logs | Account | ✅ | ✅ | ✅ |\n\n## Footnotes\n\n1. Customer Metadata Boundary does not apply in this case, as these logs are sent directly from the processing location to your configured destination. [↩](#user-content-fnref-1)\n\n</page>\n\n<page>\n---\ntitle: Out of region access · Cloudflare Data Localization Suite docs\ndescription: With the default configuration for Customer Metadata Boundary,\n  users outside the configured region will not have access to view analytics on\n  the dashboard or the default API endpoint. When Allow out-of-region access is\n  enabled, Customer Logs will still be stored exclusively within the configured\n  region but will be made available to users outside the region as well.\nlastUpdated: 2025-12-16T09:42:19.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/data-localization/metadata-boundary/out-of-region-access/\n  md: https://developers.cloudflare.com/data-localization/metadata-boundary/out-of-region-access/index.md\n---\n\nWith the default configuration for Customer Metadata Boundary, users outside the configured region will not have access to view analytics on the dashboard or the default API endpoint. When **Allow out-of-region access** is enabled, Customer Logs will still be stored exclusively within the configured region but will be made available to users outside the region as well.\n\nFor example, when **Allow out-of-region access** is **disabled** on an account configured for Customer Metadata Boundary in the US, users in Europe will not be able to see any analytics or Customer Logs on the dashboard.\n\nWhen **Allow out-of-region access** is enabled on an account configured for Customer Metadata Boundary in the US, users in both Europe and the US will be able to see analytics on the dashboard even though the Customer Logs are stored exclusively in the US.\n\n</page>\n\n<page>\n---\ntitle: Get Started — Regional Services · Cloudflare Data Localization Suite docs\ndescription: You can use Regional Services through the dashboard or via API.\nlastUpdated: 2025-12-23T00:33:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/data-localization/regional-services/get-started/\n  md: https://developers.cloudflare.com/data-localization/regional-services/get-started/index.md\n---\n\nNote\n\nInterested customers need to contact their account team to enable DNS Regionalisation.\n\nYou can use Regional Services through the dashboard or via API.\n\n## Configure Regional Services in the dashboard\n\nTo use Regional Services, you need to first create a DNS record in the dashboard:\n\n1. In the Cloudflare dashboard, go to the **Records** page.\n\n   [Go to **Records**](https://dash.cloudflare.com/?to=/:account/:zone/dns/records)\n\n2. Follow these steps to [create a DNS record](https://developers.cloudflare.com/dns/manage-dns-records/how-to/create-dns-records/).\n\n3. From the **Region** dropdown, select the region you would like to use on your domain. This value will be applied to all DNS records on the same hostname. This means that if you have two DNS records of the same hostname and change the region for one of them, both records will have the same region.\n\nNote\n\nSome regions may not appear on the dropdown because newly announced regions mentioned in the [blog post](https://blog.cloudflare.com/expanding-regional-services-configuration-flexibility-for-customers) are subject to approval by Cloudflare's internal team. For more information and entitlement reach out to your account team.\n\nRefer to the table on [Available regions and product support](https://developers.cloudflare.com/data-localization/region-support/) for the complete list of available regions, their definitions and product support\n\n## Configure Regional Services via API\n\nYou can also use Regional Services via API.\n\nCurrently, only SuperAdmins and Admin roles can edit DLS configurations. Use the Zone-level **DNS: Read/Write** API permission for the `/addressing/` endpoint to read or write Regional Services configurations.\n\nThese are some examples of API requests.\n\nList all the available regions\n\nRequired API token permissions\n\nAt least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n* `DNS Read`\n* `DNS Write`",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "Create a new regional hostname entry\n\nRequired API token permissions\n\nAt least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n* `DNS Write`",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "List all regional hostnames for a zone or get a specific one\n\nRequired API token permissions\n\nAt least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n* `DNS Read`\n* `DNS Write`",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "List all regional hostnames for a specific zone\n\nRequired API token permissions\n\nAt least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n* `DNS Read`\n* `DNS Write`",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "Patch the region for a specific hostname\n\nRequired API token permissions\n\nAt least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n* `DNS Write`",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "Delete the region configuration\n\nRequired API token permissions\n\nAt least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n* `DNS Write`",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "## Verify regional map for Zero Trust\n\nTo verify that your regional map is being applied correctly, check the `IngressColoName` field in your [Zero Trust Network Session logs](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/zero_trust_network_sessions/#ingresscoloname). This field shows the name of the Cloudflare data center where traffic ingressed. Since regionalization is applied upstream from Gateway, the ingress data center will be located within your configured regional map, confirming that traffic is being processed in the correct region.\n\n## Terraform support\n\nYou can also configure Regional Services using Terraform. For more details, refer to the [`cloudflare_regional_hostname` resource](https://registry.terraform.io/providers/cloudflare/cloudflare/latest/docs/resources/regional_hostname) in the Terraform documentation.\n\n</page>\n\n<page>\n---\ntitle: Default HTTP Privacy · Cloudflare Data Localization Suite docs\ndescription: Cloudflare runs one of the largest global anycast networks in the\n  world, with all current data center locations accessible on the network map.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/data-localization/regional-services/http-requests/\n  md: https://developers.cloudflare.com/data-localization/regional-services/http-requests/index.md\n---\n\nCloudflare runs one of the largest global anycast networks in the world, with all current data center locations accessible on the [network map](https://www.cloudflare.com/network/).\n\nWithin the Cloudflare data centers, and between the Cloudflare network and a customer's origin, traffic is encrypted during transit. Customers have the flexibility to select which [encryption mode](https://developers.cloudflare.com/ssl/origin-configuration/ssl-modes/) and which [Cipher Suites](https://developers.cloudflare.com/ssl/edge-certificates/additional-options/cipher-suites/) they want to use.\n\nAdditionally, all request and response processing within a Cloudflare data center occurs in memory, with machine inspection used to prevent human access. Nothing is written to disk except for eligible content for caching or Cache Rules configured by the customer. Moreover, all cache disks are encrypted at rest.\n\n![HTTP requests flow](https://developers.cloudflare.com/_astro/http-requests-flow.BQhq9Ov4_1rFIQl.webp)\n\nAt a high level, when an end user's device connects to any Cloudflare data center, the request is processed in the following way:\n\n1. Certain types of requests that can be used for cyber attacks are immediately dropped based on the addressing information (layer 3 / network layer).\n\n2. Next, the encrypted request is decrypted and inspected using the customer's chosen business logic, for example, the products Configuration Rules, WAF Custom Rules, Rate Limiting Rules, following the [traffic sequence](https://blog.cloudflare.com/traffic-sequence-which-product-runs-first/) and phases. This process enables the detection and prevention of a variety of different types of cyber attacks and malicious traffic, including layer 7 / application layer DDoS attacks, automated bot traffic, credential stuffing, and SQL injection, among others.\n\n3. The inspected request is then passed to the cache module. If the cache can fulfill the request with a cached copy of the content, it does so; if not, it forwards the request to the customer's origin server. Traffic between the Cloudflare data center and the origin server is encrypted, unless the customer decides to use a different encryption mode.\n\n4. When the response comes from the customer's origin server, any static and eligible content is cached onto encrypted disks. The response then goes back through the business logic to the user across the Internet.\n\nBy default, Cloudflare performs TLS termination globally in every data center, where the Internet end user connects to a website or application behind Cloudflare. However, customers can configure Regional Services to specify in which regions the processing and TLS termination occurs.\n\n</page>\n\n<page>\n---\ntitle: DDoS attack coverage · Cloudflare DDoS Protection docs\ndescription: The DDoS Attack Protection managed rulesets provide protection\n  against a variety of DDoS attacks across L3/4 (layers 3/4) and L7 of the OSI\n  model. Cloudflare constantly updates these managed rulesets to improve the\n  attack coverage, increase the mitigation consistency, cover new and emerging\n  threats, and ensure cost-efficient mitigations.\nlastUpdated: 2025-08-18T14:27:42.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/about/attack-coverage/\n  md: https://developers.cloudflare.com/ddos-protection/about/attack-coverage/index.md\n---\n\nThe [DDoS Attack Protection managed rulesets](https://developers.cloudflare.com/ddos-protection/managed-rulesets/) provide protection against a variety of DDoS attacks across L3/4 (layers 3/4) and L7 of the OSI model. Cloudflare constantly updates these managed rulesets to improve the attack coverage, increase the mitigation consistency, cover new and emerging threats, and ensure cost-efficient mitigations.\n\n[Advanced TCP Protection](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/overview/advanced-tcp-protection/) and [Advanced DNS Protection](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/overview/advanced-dns-protection/), available to [Magic Transit](https://developers.cloudflare.com/magic-transit/) customers, provide additional protection against sophisticated TCP-based DDoS attacks and sophisticated and fully randomized DNS attacks, respectively.\n\nAs a general guideline, various Cloudflare products operate on different open systems interconnection (OSI) layers and you are protected up to the layer on which your service operates. You can customize the DDoS settings on the layer in which you onboarded. For example, since the CDN/WAF service is a Layer 7 (HTTP/HTTPS) service, Cloudflare provides protection from DDoS attacks on L7 downwards, including L3/4 attacks.\n\nNote\n\nFor Magic Transit customers, Cloudflare provides some L7 protection with a L3 service (like the Advanced DNS Protection system that is available for Magic Transit customers. DNS is considered a L7 protocol).\n\nThe following table includes a sample of covered attack vectors:\n\n| OSI Layer | Ruleset / Feature | Example of covered DDoS attack vectors |\n| - | - | - |\n| L3/4 | [Network-layer DDoS Attack Protection](https://developers.cloudflare.com/ddos-protection/managed-rulesets/network/) | ACK floods BitTorrent reflection attack Carpet Bombing attacks CHARGEN reflection attacks DNS amplification attack DNS Garbage Flood DNS NXDOMAIN flood DNS Query flood DTLS amplification attacks ESP flood GRE floods ICMP flood attack Jenkins amplification attacks Lantronix reflection attacks mDNS DDoS attacks Memcached amplification attacks Mirai and Mirai-variant L3/4 attacks MSSQL reflection attacks NetBios DDoS attacks Out of state TCP attacks Protocol violation attacks QUIC flood attack Quote of the Day (QOTD) reflection attacks RST flood SIP attacks SNMP flood attack SPSS reflection attacks SSDP reflection attacks SYN floods SYN-ACK reflection attack TeamSpeak 3 floods Ubiquity reflection attacks UDP flood attack VxWorks DDoS attacks For more DNS protection options, refer to [Getting additional DNS protection](https://developers.cloudflare.com/ddos-protection/about/attack-coverage/#getting-additional-dns-protection). |\n| L3/4 | [Advanced TCP Protection](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/overview/advanced-tcp-protection/) [1](#user-content-fn-1) | Fully randomized and spoofed ACK floods, SYN floods, SYN-ACK reflection attacks, and other sophisticated TCP-based DDoS attacks |\n| L7 (DNS) | [Advanced DNS Protection](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/overview/advanced-dns-protection/) [1](#user-content-fn-1) | Sophisticated and fully randomized DNS attacks, including Water Torture attacks, Random-prefix attacks, and DNS laundering attacks. |\n| L7 (HTTP/S) | [HTTP DDoS Attack Protection](https://developers.cloudflare.com/ddos-protection/managed-rulesets/http/) | Cache busting attacks Carpet Bombing attacks HTTP Continuation flood HTTP flood attack HTTP/2 MadeYouReset HTTP/2 Rapid Reset HULK attack Known DDoS botnets LOIC attack Mirai and Mirai-variant HTTP attacks Slowloris attack TLS/SSL exhaustion attacks TLS/SSL negotiation attacks WordPress pingback attack  |\n\n## Footnotes\n\n1. Available to Magic Transit customers. [↩](#user-content-fnref-1) [↩2](#user-content-fnref-1-2)\n\n## Getting additional DNS protection\n\nThe Network-layer DDoS Attack Protection managed ruleset provides protection against some types of DNS attacks.\n\nMagic Transit customers have access to [Advanced DNS Protection](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/overview/advanced-dns-protection/) Beta. Other customers might consider the following options:\n\n* Use Cloudflare as your authoritative DNS provider ([primary DNS](https://developers.cloudflare.com/dns/zone-setups/full-setup/) or [secondary DNS](https://developers.cloudflare.com/dns/zone-setups/zone-transfers/cloudflare-as-secondary/)).\n* If you are running your own nameservers, use [DNS Firewall](https://developers.cloudflare.com/dns/dns-firewall/) to get additional protection against DNS attacks like random prefix attacks.\n\n</page>\n\n<page>\n---\ntitle: Main components · Cloudflare DDoS Protection docs\ndescription: The Cloudflare Autonomous Edge is powered by the denial-of-service\n  daemon (dosd), which is a home-grown software-defined system. The flow\n  tracking daemon, flowtrackd, is our stateful mitigation platform alongside\n  dosd. A dosd instance runs in every single server in every one of Cloudflare\n  global network's data centers around the world. These dosd instances can\n  detect and mitigate DDoS attacks autonomously without requiring centralized\n  consensus. Cloudflare users can configure this system through DDoS Attack\n  Protection managed rulesets.\nlastUpdated: 2025-08-19T15:06:40.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/about/components/\n  md: https://developers.cloudflare.com/ddos-protection/about/components/index.md\n---\n\n![Diagram with the main components providing protection against DDoS attacks at Cloudflare](https://developers.cloudflare.com/_astro/ddos-diagram.DygBAs9m_Z1krDYl.webp)\n\n## Autonomous Edge\n\nThe Cloudflare Autonomous Edge is powered by the denial-of-service daemon (`dosd`), which is a home-grown software-defined system. The flow tracking daemon, `flowtrackd`, is our stateful mitigation platform alongside `dosd`. A `dosd` instance runs in every single server in every one of [Cloudflare global network's data centers](https://www.cloudflare.com/network/) around the world. These `dosd` instances can detect and mitigate DDoS attacks autonomously without requiring centralized consensus. Cloudflare users can configure this system through [DDoS Attack Protection managed rulesets](https://developers.cloudflare.com/ddos-protection/managed-rulesets/).\n\nAnother component of Cloudflare's Autonomous Edge includes the [Advanced TCP Protection](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/overview/advanced-tcp-protection/) system. This is Cloudflare's TCP state tracking machine for detecting and mitigating the most randomized and sophisticated TCP-based DDoS attacks in unidirectional routing topologies — such as the case of [Magic Transit](https://developers.cloudflare.com/magic-transit/). Advanced TCP Protection is able to identify the state of a TCP connection and then drops, challenges, or rate-limits packets that do not belong to a legitimate connection.\n\nFor more information, refer to our blog post [A deep-dive into Cloudflare's autonomous edge DDoS protection](https://blog.cloudflare.com/deep-dive-cloudflare-autonomous-edge-ddos-protection/).\n\n## Centralized DDoS protection system\n\nComplementary to the Autonomous Edge, Cloudflare's entire global network is overwatched by a global version of `dosd`. This component protects Cloudflare's entire global network by detecting and mitigating globally distributed volumetric DDoS attacks.\n\nThe centralized systems run in Cloudflare's core data centers. They receive samples from every global network data center, analyze them, and automatically send mitigation instructions when detecting an attack. The system is also synchronized to each of our customers' web servers to identify their health and trigger any required mitigation actions.\n\n</page>\n\n<page>\n---\ntitle: How DDoS protection works · Cloudflare DDoS Protection docs\ndescription: To detect and mitigate DDoS attacks, Cloudflare's autonomous edge\n  and centralized DDoS systems analyze traffic samples out of path, which allows\n  Cloudflare to asynchronously detect DDoS attacks without causing latency or\n  impacting performance.\nlastUpdated: 2025-08-19T15:06:40.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/about/how-ddos-protection-works/\n  md: https://developers.cloudflare.com/ddos-protection/about/how-ddos-protection-works/index.md\n---\n\nTo detect and mitigate DDoS attacks, Cloudflare's autonomous edge and centralized DDoS systems analyze traffic samples out of path, which allows Cloudflare to asynchronously detect DDoS attacks without causing latency or impacting performance.\n\nThe analyzed samples include:\n\n* **Packet fields** such as the source IP, source port, destination IP, destination port, protocol, TCP flags, sequence number, options, and packet rate.\n* **HTTP request metadata** such as HTTP headers, user agent, query-string, path, host, HTTP method, HTTP version, TLS cipher version, and request rate.\n* **HTTP response metrics** such as error codes returned by customers' origin servers and their rates.\n\nCloudflare uses a set of dynamic rules that scan for attack patterns, known attack tools, suspicious patterns, protocol violations, requests causing large amounts of origin errors, excessive traffic hitting the origin or cache, and additional attack vectors. Each rule has a predefined sensitivity level and default action that varies based on the rule's confidence that the traffic is indeed part of an attack.\n\nNote\n\nYou can set an override expression for the [HTTP DDoS Attack Protection](https://developers.cloudflare.com/ddos-protection/managed-rulesets/http/http-overrides/override-expressions/) or [Network-layer DDoS Attack Protection](https://developers.cloudflare.com/ddos-protection/managed-rulesets/network/network-overrides/override-expressions/) managed ruleset to define a specific scope for sensitivity level or action adjustments.\n\nOnce attack traffic matches a rule, Cloudflare's systems will track that traffic and generate a real-time signature to surgically match against the attack pattern and mitigate the attack without impacting legitimate traffic. The rules are able to generate different signatures based on various properties of the attacks and the signal strength of each attribute. For example, if the attack is distributed — that is, originating from many source IPs — then the source IP field will not serve as a strong indicator, and the rule will not choose the source IP field as part of the attack signature. Once generated, the fingerprint is propagated as a mitigation rule to the most optimal location on the Cloudflare global network for cost-efficient mitigation. These mitigation rules are ephemeral and will expire shortly after the attack has ended, which happens when no additional traffic has been matched to the rule.\n\n| Actions | Description |\n| - | - |\n| Block | Matching requests are denied access to the site. |\n| Interactive Challenge | The client that made the request must pass an interactive Challenge. |\n| Managed Challenge | Depending on the characteristics of a request, Cloudflare will choose an appropriate type of challenge. |\n| Log | Records matching requests in the Cloudflare Logs. |\n| Use rule defaults | Uses the default action that is pre-defined for each rule. |\n\n## Thresholds\n\nThresholds vary for each rule and there are different thresholds globally and per colocation. Within a rule, the traffic is fingerprinted and the thresholds are per fingerprint, and it is difficult to know ahead of time which rules, colocations, or fingerprints your traffic generates, so the threshold numbers are not necessarily valuable.\n\nInstead, Cloudflare's DDoS Protection system provides the sensitivity adjustment. If you experience a false positive, you can decrease the sensitivity. You can also use the `Log` action to help find an appropriate sensitivity level. You can decrease the sensitivity while in `Log` mode until the rule no longer matches.\n\n## Time to mitigate\n\n* Immediate mitigation for Advanced TCP and DNS Protection systems.\n* Up to three seconds on average for the detection and mitigation of L3/4 DDoS attacks at the edge using the Network-layer DDoS Protection Managed rules.\n* Up to three seconds on average for the detection and mitigation of HTTP DDoS attacks at the edge using the HTTP DDoS Protection Managed rules.\n\n## Data localization\n\nTo learn more about how DDoS protection works with data localization, refer to the Data Localization Suite [product compatibility](https://developers.cloudflare.com/data-localization/compatibility/).\n\n</page>\n\n<page>\n---\ntitle: Configure Advanced TCP Protection and Advanced DNS Protection via the API\n  · Cloudflare DDoS Protection docs\ndescription: Refer to the following pages to configure Advanced TCP Protection\n  and Advanced DNS Protection via the API.\nlastUpdated: 2024-11-04T15:20:19.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/api/\n  md: https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/api/index.md\n---\n\nRefer to the following pages to configure Advanced TCP Protection and Advanced DNS Protection via the API.\n\n* [Advanced DNS Protection](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/api/dns-protection/)\n* [Advanced TCP Protection](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/api/tcp-protection/)\n\n</page>\n\n<page>\n---\ntitle: Create an Advanced TCP Protection filter · Cloudflare DDoS Protection docs\ndescription: Advanced DDoS Protection protects the IP prefixes you select from\n  sophisticated DDoS attacks. A prefix can be an IP address or an IP range in\n  CIDR format. You must add prefixes to Advanced DDoS Protection so that\n  Cloudflare can analyze incoming packets and offer protection against\n  sophisticated TCP DDoS attacks.\nlastUpdated: 2025-09-22T16:52:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/concepts/\n  md: https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/concepts/index.md\n---\n\n## Prefixes\n\nAdvanced DDoS Protection protects the IP prefixes you select from sophisticated DDoS attacks. A prefix can be an IP address or an IP range in CIDR format. You must add prefixes to Advanced DDoS Protection so that Cloudflare can analyze incoming packets and offer protection against sophisticated TCP DDoS attacks.\n\nPrefixes added to Advanced DDoS Protection must be one of the following:\n\n* A prefix [onboarded to Magic Transit](https://developers.cloudflare.com/magic-transit/how-to/advertise-prefixes/).\n* A subset of a prefix [onboarded to Magic Transit](https://developers.cloudflare.com/magic-transit/how-to/advertise-prefixes/).\n\nYou cannot add a prefix (or a subset of a prefix) that you have not onboarded to Magic Transit or whose status is still *Unapproved*. Contact your account team to get help with prefix approvals.\n\n## Allowlist\n\nThe Advanced DDoS Protection allowlist is a list of prefixes that will bypass all configured Advanced DDoS Protection rules.\n\nFor example, you could add prefixes used only by partners of your company to the allowlist so that they are exempt from packet inspection and mitigation actions performed by Advanced DDoS Protection.\n\nImportant\n\nPrefixes in the allowlist will be vulnerable to IP spoofing attacks. If an attacker can guess the source IP addresses you have allowlisted, their packets will be allowlisted.\n\n## Rule\n\nA rule configures Advanced DDoS Protection for a given [scope](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/concepts/#scope), according to several [settings](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/concepts/#rule-settings): execution mode, burst sensitivity, and rate sensitivity.\n\nEach system component (SYN flood protection and out-of-state TCP protection) has its own list of rules, and it should have at least one rule.\n\n### Rule settings\n\nEach rule type has the following settings: scope, mode, burst sensitivity, and rate sensitivity.\n\nYou may need to adjust the burst or rate sensitivity of a rule in case of false positives or due to specific traffic patterns.\n\n#### Scope\n\nAdvanced TCP Protection rules can have one of the following scopes:\n\n* **Global**: The rule will apply to all incoming packets.\n* **Region**: The rule will apply to incoming packets in a selected region.\n* **Data center**: The rule will apply to incoming packets in the selected Cloudflare data center.\n\nThe rule scope allows you to adjust the system's tolerance for out-of-state packets in locations where you may have more or less traffic than usual, or due to any other networking reasons.\n\nBesides defining rules with one of the above scopes, you must also select the [prefixes](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/concepts/#prefixes) that you wish to protect with Advanced TCP Protection.\n\n#### Mode\n\nThe Advanced TCP Protection system constantly learns your TCP connections to mitigate DDoS attacks. Advanced TCP Protection rules can have one of the following execution modes: monitoring, mitigation (enabled), or disabled.\n\n* **Monitoring**\n\n  * In this mode, Advanced TCP Protection will not impact any packets. Instead, the protection system will learn your legitimate TCP connections and show you what it would have mitigated. Check Network Analytics to visualize what actions Advanced TCP Protection would have taken on incoming packets, according to the current configuration.\n\n    Refer to the [Analytics documentation](https://developers.cloudflare.com/analytics/network-analytics/configure/displayed-data/#view-logged-or-monitored-traffic) for more information on how to view logged or monitored traffic.\n\n* **​​Mitigation (Enabled)**\n\n  * In this mode, Advanced TCP Protection will learn your legitimate TCP connections and perform mitigation actions on incoming TCP DDoS attacks based on the rule configuration (burst and rate sensitivity) and your [allowlist](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/concepts/#allowlist).\n\n* **Disabled**\n\n  * In this mode, a rule will not evaluate any incoming packets.\n\n#### Burst sensitivity\n\nThe burst sensitivity is the rule's sensitivity to short-term bursts in the packet rate:\n\n* A low sensitivity means that bigger spikes in the packet rate may trigger a mitigation action.\n* A high sensitivity means that smaller spikes in the packet rate may trigger a mitigation action.\n\nThe default burst sensitivity is *Medium*.\n\n#### Rate sensitivity\n\nThe rate sensitivity is the rule's sensitivity to the sustained packet rate:\n\n* A low sensitivity means that higher sustained packet rates can trigger a mitigation action.\n* A high sensitivity means that lower sustained packet rates may trigger a mitigation action. A high sensitivity offers increased protection, but you may get more false positives (that is, mitigated packets that belong to legitimate traffic).\n\nThe default rate sensitivity is *Medium*.\n\n#### Profile sensitivity\n\nNote\n\nProfile sensitivity is available for [Advanced DNS Protection](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/overview/advanced-dns-protection/) only.\n\nThe sensitivity to DNS queries that have not been recently seen.\n\n* A higher sensitivity level means that the mitigation system will begin mitigating faster.\n* A lower sensitivity provides more tolerance for potentially suspicious DNS queries.\n\nThe default rate sensitivity and recommended setting is *Low*. You should only increase sensitivity if it is needed based on observed attacks.\n\n## Filter\n\nA filter modifies Advanced TCP Protection's [execution mode](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/concepts/#mode) — monitoring, mitigation (enabled), or disabled — for all incoming packets matching an expression.\n\nThe filter expression can reference source and destination IP addresses and ports. Each system component (SYN flood protection and out-of-state TCP protection) should have one or more [rules](#rule), but filters are optional.\n\nEach system component has its own filters. You can configure a filter for each execution mode:\n\n* **Mitigation Filter**: The system will drop packets matching the filter expression.\n* **Monitoring Filter**: The system will log packets matching the filter expression.\n* **Off Filter**: The system will ignore packets matching the filter expression.\n\nWhen there is a match, a filter will alter the execution mode for all configured rules in a given system component (SYN flood protection or out-of-state TCP protection), including disabled rules.\n\nFor instructions on creating filters in the Cloudflare dashboard, refer to [Create a filter](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/how-to/create-filter/). For API examples, refer to [Common API calls](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/api/tcp-protection/examples/).\n\n### Example use case\n\nYou can create a monitor filter for a new prefix that you are onboarding by using the expression to match against the prefix.\n\nYour already onboarded prefixes can remain protected with one or more configured rules in mitigation mode.\n\nWhen onboarding a new prefix, you would configure a monitoring filter for this prefix and then add it to Advanced TCP Protection.\n\n***\n\n## Determining the execution mode\n\nWhen you have both rules and filters configured, the execution mode is determined according to the following:\n\n1. If there is a match for one of the configured filters, use the filter's execution mode. The filter evaluation order is based on their mode, in the following order:\n\n   1. Mitigation filter (filter with `enabled` mode)\n   2. Monitoring filter (filter with `monitoring` mode)\n   3. Off filter (filter with `disabled` mode)\n\n2. If no filter matched, use the execution mode determined by existing rules.\n\n3. If no rules match, disable Advanced TCP Protection.\n\n***\n\n## Mitigation reasons\n\nThe Advanced TCP Protection system applies mitigation actions for different reasons based on the connection states. The **Mitigation reason** field shown in the **Advanced TCP Protection** tab of the [Network Analytics](https://developers.cloudflare.com/analytics/network-analytics/) dashboard will contain more information on why a given packet was dropped by the system.\n\nThe connection states are the following:\n\n* **New**: A SYN or SYN-ACK packet has been sent to attempt to open a new connection.\n* **Open**: The three-way TCP handshake has been completed and the TCP connection is open.\n* **Closing**: A FIN or FIN-ACK packet has been seen attempting to close a connection.\n* **Closed**: The closing three-way handshake has been completed, or an RST packet has closed the connection.\n\nThe mitigation reasons are the following:\n\n| Reason | Description |\n| - | - |\n| **Unexpected** | Packet dropped because it was not expected given the current state of the TCP connection it was associated with. |\n| **Challenge needed** | Packet challenged because the system determined that the packet is most likely part of a packet flood. |\n| **Challenge passed** | Packet dropped because it belongs to a solved challenge. |\n| **Not found** | Packet dropped because it is not part of an existing TCP connection and it is not establishing a new connection. |\n| **Out of sequence** | Packet dropped because its properties (for example, TCP flags or sequence numbers) do not match the expected values for the existing connection. |\n| **Already closed** | Packet dropped because it belongs to a connection that is already closed. |\n\nMitigation will only occur based on your Advanced TCP Protection configuration (rule sensitivities, configured allowlists and prefixes). The protection system will provide some tolerance to out-of-state packets to accommodate for the natural randomness of Internet routing.\n\n</page>\n\n<page>\n---\ntitle: How-to guides · Cloudflare DDoS Protection docs\ndescription: How-to guides for configuring Advanced TCP Protection.\nlastUpdated: 2024-11-04T15:20:19.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/how-to/\n  md: https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/how-to/index.md\n---\n\n* [Add a prefix](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/how-to/add-prefix/)\n* [Add an IP or prefix to the allowlist](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/how-to/add-prefix-allowlist/)\n* [Create a rule](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/how-to/create-rule/)\n* [Create a filter](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/how-to/create-filter/)\n* [Exclude a prefix](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/how-to/exclude-prefix/)\n\n</page>\n\n<page>\n---\ntitle: Advanced DDoS Protection systems · Cloudflare DDoS Protection docs\ndescription: The Advanced DDoS Protection system includes Advanced TCP\n  Protection and Advanced DNS Protection. Both systems are configured using the\n  general settings, but also comprise of their own dedicated settings.\nlastUpdated: 2025-09-03T18:12:42.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/overview/\n  md: https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/overview/index.md\n---\n\nThe Advanced DDoS Protection system includes [Advanced TCP Protection](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/overview/advanced-tcp-protection/) and [Advanced DNS Protection](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/overview/advanced-dns-protection/). Both systems are configured using the general settings, but also comprise of their own dedicated settings.\n\nAdvanced DDoS Protection systems is available to [Magic Transit](https://developers.cloudflare.com/magic-transit/) customers.\n\nProtection for simpler TCP or DNS-based DDoS attacks is included as part of the [Network-layer DDoS Attack Protection managed ruleset](https://developers.cloudflare.com/ddos-protection/managed-rulesets/network/).\n\nGeneral settings enable and control the use of the Advanced TCP Protection and the Advanced DNS Protection systems, and are composed of thresholds, prefixes, rules, and enablement.\n\n## Thresholds\n\nThresholds are based on your network's unique traffic and are configured by Cloudflare. The sensitivity levels manipulate the thresholds.\n\nWhen you get access to Advanced DDoS Protection systems, you are [automatically provisioned](#automatic-thresholds) with default settings in monitoring mode.\n\nThresholds are based on your network's individual behavior, derived from your traffic profile as monitored by Cloudflare. Defining the thresholds will effectively determine what the *High*, *Medium*, and *Low* [sensitivities](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/concepts/#burst-sensitivity) will be for your specific case.\n\nIf needed, you can change the sensitivity levels that will manipulate the thresholds for Advanced TCP Protection and Advanced DNS Protection from the default settings.\n\nOnce thresholds are configured, the Advanced DDoS Protection systems have been initialized and enabled in monitoring mode.\n\n### Automatic thresholds\n\nAutomatic thresholds for Cloudflare's Advanced DDoS Protection system optimizes the detection and mitigation of DDoS attacks by automatically calculating appropriate traffic thresholds for each system for each customer account. This system applies to Advanced TCP Protection (specifically SYN Flood Protection and Out-of-State TCP Flood Protection) and Advanced DNS Protection.\n\nMake sure that you have properly onboarded to the Advanced DDoS Protection system to benefit from automatic thresholds.\n\n#### Process\n\nThe automatic threshold system calculates thresholds every 10 minutes for both new and existing Magic Transit accounts, provided they meet the requirements outlined in the process below.\n\n* The `flowtrackd` account was created within the past 7 to 10 days.\n* The account has at least one configured global threshold (rate and burst). This can be a threshold that was automatically provisioned by the system or manually provisioned by Cloudflare.\n\nThese checks are performed independently for SYN Flood Protection, Out-of-State TCP Flood Protection, and Advanced DNS Protection. The criteria does not require the presence of any rules to be configured. Accounts initially provisioned by the automatic system will have default thresholds. Otherwise, thresholds may be unconfigured if they are not set by Cloudflare.\n\nAfter seven days, the system calculates a rate and burst threshold for each of the protection components. However, they are not applied. Cloudflare must review the draft thresholds produced by the automatic calculation system before creating real thresholds for your traffic.\n\nThresholds are applied globally per account. There is no minimum packets-per-second (pps) requirement for threshold calculation, but for those under 100 pps, the system will default to a reasonable non-zero rate and burst.\n\nThresholds are derived using the 95th percentile (P95) of observed traffic over the preceding seven days:\n\n* SYN Flood Protection: Based on SYN and SYN-ACK traffic.\n* Out-of-State TCP Flood Protection: Based on all other TCP flag traffic.\n* Advanced DNS Protection: Based on DNS over UDP traffic.\n\nWhile the calculation typically occurs automatically after seven days, Cloudflare can force an earlier calculation if you want to enable the system in protective mode in advance.\n\nThe automatic threshold calculation system does not differentiate between legitimate and attack traffic. If you are onboarded or experience attacks during the seven day observation period, the calculated thresholds may be inaccurate, depending on the attack's size, duration, and frequency relative to legitimate traffic. In such cases, Cloudflare will likely need to trigger a recalculation. Future improvements will allow you to run a recalculation without the assistance of your Cloudflare account team.\n\n#### Implementation\n\nYou should enable the automatically provisioned rules. Initially, these rules will have default values and operate in Monitor mode. After seven days, once thresholds are calculated, you can use the Network Analytics dashboard to observe what packets would have been dropped or allowed, then safely enable the rules in mitigation mode. Depending on what is observed in the Network Analytics dashboard (for example, legitimate traffic is being flagged in Monitor mode), you may want to change the sensitivity level and continue observation before enabling in mitigation mode. Rules and Filters, where supported, can also be scoped to allow for additional granularity.\n\n#### Recalculation\n\nAutomatic thresholds are calculated only once. Cloudflare can manually trigger a recalculation. Adding, approving, removing, delegating, advertising, or withdrawing prefixes after initial onboarding does not automatically re-trigger the calculation. It is recommended to move the relevant systems to Monitor mode before making changes that impact traffic levels and requesting a recalculation from Cloudflare. Future improvements will take these events into consideration.\n\n#### Overrides\n\nAutomatically calculated thresholds can be overridden. Cloudflare can help manually define thresholds.\n\n#### Considerations\n\nIf you are actively under attack and diverting traffic to Cloudflare, the automatic threshold calculation is unlikely to be effective as it will incorporate attack traffic. In these scenarios, Cloudflare will still need to manually configure thresholds. If you are not under attack while diverting traffic, Cloudflare can force a threshold calculation with available data. However, less data, such as fewer days or hours of observation, will result in less accurate thresholds.\n\n#### Limitations\n\nCustomers currently do not have visibility into the calculated thresholds or an indication of whether thresholds have been configured. Future improvements aim to indicate when thresholds have been configured and when they were last updated.\n\nThe auto-threshold calculation component currently runs only in PDX. Therefore, this feature is not compatible if you have enabled Data Localization Services (DLS) and are located outside of the US, such as EU CMB. Future improvements will address this limitation.\n\n***\n\n## Prefixes\n\nThe prefixes that you have [onboarded](https://developers.cloudflare.com/magic-transit/how-to/advertise-prefixes/) to and approved by Cloudflare instruct the system on which traffic to route through the system.\n\n[Add the prefixes](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/how-to/add-prefix/) you would like to use with Advanced TCP and DNS Protection. You will be able to register prefixes that you previously [onboarded to Magic Transit](https://developers.cloudflare.com/magic-transit/how-to/advertise-prefixes/) or a subset of these prefixes.\n\nYou cannot add unapproved prefixes to Advanced DDoS Protection systems. Contact your account team to get help with prefix approvals.\n\nOptionally, you can [add prefixes to the allowlist](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/how-to/add-prefix-allowlist/) if your traffic should bypass Advanced DDoS Protection rules.\n\nThe allowlist only applies to source IPs — it does not apply to your own IPs or prefixes. You can also [exclude a subset of an onboarded prefix](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/how-to/exclude-prefix/) from Advanced TCP Protection.\n\nRefer to [Concepts](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/concepts/) for more information.\n\n***\n\n## Rules\n\n[Create a rule](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/how-to/create-rule/) for Advanced TCP and Advanced DNS Protection (as needed) to enable mitigation.\n\nYou can create a rule for SYN Flood Protection and another rule for Out-of-state TCP Protection, both with global scope and in monitoring mode. These rules will apply to all received packets.\n\nOptionally, you can create [filters](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/concepts/#filter) for each protection system component (SYN flood protection and out-of-state TCP protection).\n\nA filter modifies Advanced TCP Protection's [execution mode](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/concepts/#mode) — monitoring, mitigation (enabled), or disabled — for all incoming packets matching an expression.\n\n***\n\n## Enablement\n\nEnable the Advanced DDoS system and begin routing traffic through it.\n\n1. In the Cloudflare dashboard, go to the **L3/4 DDoS protection** page.\n\n   [Go to **DDoS Managed Rules**](https://dash.cloudflare.com/?to=/:account/network-security/ddos)\n\n2. Go to **Advanced Protection** > **General settings**.\n\n3. Under **General settings**, toggle the feature status **On**.\n\n</page>\n\n<page>\n---\ntitle: Prevent DDoS attacks · Cloudflare DDoS Protection docs\nlastUpdated: 2025-12-23T20:53:47.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/best-practices/prevent-ddos-attacks-external/\n  md: https://developers.cloudflare.com/ddos-protection/best-practices/prevent-ddos-attacks-external/index.md\n---\n\n\n</page>\n\n<page>\n---\ntitle: Proactive DDoS defense · Cloudflare DDoS Protection docs\ndescription: Cloudflare's network automatically mitigates large DDoS attacks,\n  but these attacks can still affect your application.\nlastUpdated: 2025-12-23T20:53:47.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/best-practices/proactive-defense/\n  md: https://developers.cloudflare.com/ddos-protection/best-practices/proactive-defense/index.md\n---\n\nCloudflare's network automatically mitigates large [DDoS attacks](https://www.cloudflare.com/learning/ddos/what-is-a-ddos-attack/), but these attacks can still affect your application.\n\n## All customers\n\nAll customers should perform the following steps to better secure their application:\n\n1. Make sure all [DDoS managed rulesets](https://developers.cloudflare.com/ddos-protection/managed-rulesets/) are set to default settings (*High* sensitivity level and mitigation actions) for optimal DDoS activation.\n\n2. Deploy [WAF custom rules](https://developers.cloudflare.com/waf/custom-rules/) and [rate limiting rules](https://developers.cloudflare.com/waf/rate-limiting-rules/) to enforce a combined positive and negative security model. Reduce the traffic allowed to your website based on your known usage.\n\n3. Make sure your origin is not exposed to the public Internet, meaning that access is only possible from [Cloudflare IP addresses](https://developers.cloudflare.com/fundamentals/concepts/cloudflare-ip-addresses/). As an extra security precaution, we recommend contacting your hosting provider and requesting new origin server IPs if they have been targeted directly in the past.\n\n4. If you have [Managed IP Lists](https://developers.cloudflare.com/waf/tools/lists/managed-lists/#managed-ip-lists) or [Bot Management](https://developers.cloudflare.com/bots/plans/bm-subscription/), consider using these in WAF custom rules.\n\n5. Enable [caching](https://developers.cloudflare.com/cache/) as much as possible to reduce the strain on your origin servers, and when using [Workers](https://developers.cloudflare.com/workers/), avoid overwhelming your origin server with more subrequests than necessary.\n\n   To help counter attack randomization, Cloudflare recommends to update your cache settings to exclude the query string as a cache key. When the query string is excluded as a cache key, Cloudflare's cache will take in unmitigated attack requests instead of forwarding them to the origin. The cache can be a useful mechanism as part of a multilayered security posture.\n\n## Enterprise customers\n\nIn addition to the steps for all customers, Cloudflare Enterprise customers subscribed to the Advanced DDoS Protection service should consider enabling [Adaptive DDoS Protection](https://developers.cloudflare.com/ddos-protection/managed-rulesets/adaptive-protection/), which mitigates attacks more intelligently based on your unique traffic patterns.\n\n## Magic Transit customers\n\nIn addition to the steps for all customers, Cloudflare Magic Transit customers should ensure that the [Advanced TCP Protection](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/overview/advanced-tcp-protection/) and [Advanced DNS Protection](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/overview/advanced-dns-protection/) are enabled and that their configurations are optimized.\n\n</page>\n\n<page>\n---\ntitle: Third-party services and Cloudflare DDoS protection · Cloudflare DDoS\n  Protection docs\ndescription: Some Cloudflare customers choose to use a Content Delivery Network\n  (CDN) in front of Cloudflare to cache and serve their resources.\nlastUpdated: 2025-12-30T19:20:11.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/best-practices/third-party/\n  md: https://developers.cloudflare.com/ddos-protection/best-practices/third-party/index.md\n---\n\n## Using a third-party CDN in front of Cloudflare\n\nSome Cloudflare customers choose to use a Content Delivery Network (CDN) in front of Cloudflare to cache and serve their resources.\n\nCloudflare recommends that you **do not use a third-party CDN in front of Cloudflare**. Some CDN providers may introduce subtleties into HTTP requests that deviate from protocol standards and/or protocol best practices. Additionally, because traffic to Cloudflare will originate from a limited set of IP addresses of the third-party CDN, in rare occasions — such as when using the Akamai CDN in front of Cloudflare — it may appear as if the CDN is launching a DDoS attack against Cloudflare due to the amount of traffic from these limited IP addresses.\n\nTherefore, it is recommended that you **use the [Cloudflare CDN](https://developers.cloudflare.com/cache/)**, which provides the following benefits:\n\n* You remove an additional hop between vendor data centers, thus reducing latency for your users.\n* You perform DDoS filtering in the first point of contact from the Internet, which is a recommended best practice.\n\nL3/4 DDoS mitigation accuracy\n\nUsing a third-party WAF or CDN service in front of Cloudflare can negatively impact the accuracy of L3/4 DDoS mitigation.\n\nWhen traffic is proxied through another vendor, the vendor's IP addresses are available to Cloudflare's network-layer protection systems rather than the true client IP addresses. This lack of visibility into the original source can lead to less effective automated mitigation and potential false positives.\n\nIf you require specific architectures involving third-party vendors, refer to our [Deployment architectures for Magic Transit](https://developers.cloudflare.com/reference-architecture/architectures/magic-transit/#deployment-architectures-for-magic-transit) for detailed guidance on maintaining security posture in complex environments.\n\nIf you are using a third-party CDN in front of Cloudflare and Cloudflare mitigates a DDoS attack, you will still pay your first-hop CDN provider for the attack traffic that they processed before it was mitigated by Cloudflare.\n\n### Recommended DDoS configuration adjustments\n\nIf you are using a CDN or proxy in front of Cloudflare, it is recommended that you change the action and/or sensitivity level of the following DDoS rules named:\n\n* `HTTP requests with unusual HTTP headers or URI path (signature #1)` with the rule ID 0b1e17bd25c74e38834f19043486aee1\n* `HTTP requests with unusual HTTP headers or URI path (signature #56)` with the rule ID 466d6c2e8ba74459a2670e91e269dfd6\n* `HTTP requests with unusual HTTP headers or URI path (signature #57)` with the rule ID 12b9aecf1f6245b29d7e842bf35a42a0\n* `Requests coming from known bad sources` with the rule ID 6e3ccc23900c428e8ec0fb8a3a679c52\n\nYou should change the rule's action to *Log* (only available on Enterprise plans) to view the flagged traffic in the [analytics dashboard](https://developers.cloudflare.com/ddos-protection/reference/analytics/). Alternatively, change the rule's **Sensitivity Level** to *Essentially Off* to prevent the rule from being triggered.\n\nFor more information, refer to [HTTP DDoS Attack Protection managed ruleset: Ruleset configuration](https://developers.cloudflare.com/ddos-protection/managed-rulesets/http/#ruleset-configuration).\n\n## Using VPNs, NATs, and other third-party services\n\nSome Cloudflare Magic Transit customers operate Virtual Private Networks (VPN) so that their remote employees can connect securely to the organization's services. Additionally, larger organizations have Network Addressing Translation (NAT) systems that manage connections in and out of their network.\n\nCloudflare Magic Transit customers may also use third-party services such as Zoom, Webex, Microsoft Teams, and others for their internal organization communication. Because traffic to Cloudflare will be originating from a limited set of IP addresses belonging to these third-party services, it may appear as if the services are launching a DDoS attack against Cloudflare due to the amount of traffic from limited IP addresses.\n\nAdditionally, since this traffic may also be targeting a limited set of destinations (for example, the same designated service ports, VPN endpoints, or NAT IP addresses), it may appear as if the CDN is launching a DDoS attack against Cloudflare due to the amount of traffic from a limited set of IPs *to* a limited set of IPs.\n\n### Recommended DDoS configuration adjustments\n\nIf your organization uses VPNs, NATs, or third-party services at high rates of over 100 Mbps, it is recommended that you one of the following:\n\n* Change the **Sensitivity Level** of the relevant rules to a lower level. Changing the level to *Essentially Off* will prevent the rules from being triggered. Refer to [HTTP DDoS Attack Protection managed ruleset](https://developers.cloudflare.com/ddos-protection/managed-rulesets/http/) and [Network-layer DDoS Attack Protection managed ruleset](https://developers.cloudflare.com/ddos-protection/managed-rulesets/network/) for more information on the available adjustments per ruleset and how to perform them.\n* Exclude the desired traffic from the Managed DDoS rule using expression filters. You can exclude a combination of source ports, source IP addresses, destination ports, destination IP addresses, and protocol. For more information, refer to [Configure Network-layer DDoS Attack Protection via API](https://developers.cloudflare.com/ddos-protection/managed-rulesets/network/network-overrides/configure-api/).\n\nIf you are on an Enterprise plan, you can change a rule's action to *Log* to view the flagged traffic in the [analytics dashboard](https://developers.cloudflare.com/ddos-protection/reference/analytics/). After gathering this information, you can later define rule adjustments as previously described.\n\n</page>\n\n<page>\n---\ntitle: Changelog for general updates to DDoS protection · Cloudflare DDoS\n  Protection docs\ndescription: Subscribe to RSS\nlastUpdated: 2025-03-28T13:07:11.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/change-log/general-updates/\n  md: https://developers.cloudflare.com/ddos-protection/change-log/general-updates/index.md\n---\n\n[Subscribe to RSS](https://developers.cloudflare.com/ddos-protection/change-log/general-updates/index.xml)\n\n## 2024-06-03\n\n**DDoS alerts now available for EU CMB customers**\n\n[DDoS alerts](https://developers.cloudflare.com/ddos-protection/reference/alerts/) are now available for EU Customer Metadata Boundary (CMB) customers. This includes all DDoS alert type (Standard and Advanced) for both HTTP DDoS attacks and L3/4 DDoS attacks.\n\n## 2024-04-17\n\n**Network Analytics now supported for EU CMB customers**\n\nThe Network Analytics dashboard is available to customers that have opted in to the EU [Customer Metadata Boundary](https://developers.cloudflare.com/data-localization/metadata-boundary/) (CMB) solution. This also includes Network Analytics Logs (Logpush) and GraphQL API.\n\nAPI users can ensure they are routed properly by directing their API requests at `eu.api.cloudflare.com`.\n\n</page>\n\n<page>\n---\ntitle: Adaptive DDoS Protection · Cloudflare DDoS Protection docs\ndescription: Explore Cloudflare's Adaptive DDoS Protection, which learns traffic\n  patterns to defend against sophisticated DDoS attacks on layers 3/4 and 7.\nlastUpdated: 2025-12-12T22:27:50.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/managed-rulesets/adaptive-protection/\n  md: https://developers.cloudflare.com/ddos-protection/managed-rulesets/adaptive-protection/index.md\n---\n\nAdaptive DDoS Protection learns your unique traffic patterns and adapts to them to provide better protection against sophisticated DDoS attacks on layer 7 and layers 3/4, depending on your subscribed Cloudflare services.\n\nAdaptive DDoS Protection provides the following types of protection:\n\n* **Adaptive DDoS Protection for Origins**: Detects and mitigates traffic that deviates from your site's origin errors profile.\n* **Adaptive DDoS Protection for User-Agents**: Detects and mitigates traffic that deviates from the top User Agents seen by Cloudflare on the network. The User Agent profile is built from the entire Cloudflare network and not only from the customer's zone.\n* **Adaptive DDoS Protection for Locations**: Detects and mitigates traffic that deviates from your site's geo-distribution profile. The profile is calculated from the rate for every client country and region, using the rates from the past seven days.\n* **Adaptive DDoS Protection for Protocols**: Detects and mitigates traffic that deviates from your traffic's IP protocol profile. The profile is calculated as a global rate for each of your prefixes.\n\n## Availability\n\nCloudflare Adaptive DDoS Protection is available to Enterprise customers according to the following table:\n\n| Feature | Profiling dimension | WAF/CDN1 | Magic Transit / Spectrum BYOIP2 |\n| - | - | - | - |\n| **HTTP Adaptive DDoS Protection** | | | |\n| For Origins | Origin errors | Yes | — |\n| For User-Agents | User Agent (entire Cloudflare network) | Yes | — |\n| For Locations | Client IP country and region | Yes | — |\n| **L3/4 Adaptive DDoS Protection** | | | |\n| For Protocols | IP protocol | — | Yes |\n| For Protocols | Client IP country and Region for UDP | — | Yes |\n\n1 *WAF/CDN customers on the Enterprise plan with the Advanced DDoS Protection subscription.*\\\n2 *Magic Transit and Spectrum BYOIP customers on an Enterprise plan.*\n\n## How it works\n\nAdaptive DDoS Protection creates a traffic profile by looking at the maximum rates of traffic every day, for the past seven days. These profiles are recalculated every day, keeping the seven-day time window. Adaptive DDoS Protection stores the maximal traffic rates seen for every predefined dimension value (the profiling dimension varies for each rule). Every profile uses one dimension, such as the source country of the request, the user agent, and the IP protocol. Incoming traffic that deviates from your profile may be malicious.\n\nTo eliminate outliers, rate calculations only consider the 95th percentile rates (discarding the top 5% of the highest rates). Cloudflare requires a minimum amount of requests per second (rps) to build traffic profiles. HTTP Adaptive DDoS Protection rules also take into account Cloudflare's [Machine Learning (ML) models](https://developers.cloudflare.com/bots/concepts/bot-score/#machine-learning) to identify traffic that is likely automated.\n\nCloudflare may change the logic of these protection rules from time to time to improve them.\n\nNote\n\nHTTP Adaptive DDoS Protection rules calculate the traffic profile at the zone-level. Therefore, the HTTP Adaptive rules may be ineffective for an [SSL for SaaS](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/) zone shared by many of your customers' [custom hostnames](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/domain-support/). The traffic profile would be created based on the varied and aggregated traffic of all of the various custom hostnames. It will not be accurate for an individual customer's hostname.\n\n***\n\n## View flagged traffic\n\nTo view traffic flagged by HTTP Adaptive DDoS Protection rules:\n\n* Old dashboard\n\n  1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com/), and select your account and domain.\n  2. Go to **Security** > **Events**.\n  3. Filter by `Service equals HTTP DDoS` and by rule ID.\n\n* New dashboard\n\n  1. In the Cloudflare dashboard, go to the **Security Analytics** page.\n\n     [Go to **Analytics**](https://dash.cloudflare.com/?to=/:account/:zone/security/analytics)\n\n  2. Go to **Events**.\n\n  3. Filter by `Service equals HTTP DDoS` and by rule ID.\n\nTo view traffic flagged by L3/4 Adaptive DDoS Protection rules:\n\n* Old dashboard\n\n  1. In the Cloudflare dashboard, go to the Network analytics page.\n\n     [Go to **Network analytics**](https://dash.cloudflare.com/?to=/:account/network-analytics)\n\n  2. Filter by rule ID.\n\n* New dashboard\n\n  1. In the Cloudflare dashboard, go to the **Security Analytics** page.\n\n     [Go to **Analytics**](https://dash.cloudflare.com/?to=/:account/:zone/security/analytics)\n\n  2. Go to **Events**.\n\n  3. Filter by rule ID.\n\nYou may also obtain information about flagged traffic through [Logpush](https://developers.cloudflare.com/logs/logpush/) or the [GraphQL API](https://developers.cloudflare.com/analytics/graphql-api/).\n\nTo determine if an adaptive rule fits your traffic in a way that will only mitigate attack traffic and will not cause false positives, review the traffic that is *Logged* by the adaptive rules.\n\nNote\n\nYou may not see any traffic matching the adaptive rules. This can be because there was no deviation from your traffic profile, so you may want to increase the time range and look for any *Logged* traffic. Another reason why you may not see *Logged* traffic by the adaptive rules is that there was not sufficient traffic volume to generate a traffic profile for your zone.\n\nIf you do see traffic that was *Logged* by the adaptive rules, use the dashboard to determine if the traffic matches the characteristics of legitimate users or that of attack traffic. As each Internet property is unique, understanding if the traffic is legitimate requires your understanding of how your legitimate traffic looks. For example, the user agent, source country, headers, query string for HTTP requests, and protocols and ports for L3/4 traffic.\n\n* In cases where you are certain that the rule is only flagging attack traffic, you should consider creating an override and enabling that rule with a [Managed Challenge](https://developers.cloudflare.com/cloudflare-challenges/challenge-types/challenge-pages/#managed-challenge-recommended) or `Block` action.\n* In cases where you see legitimate traffic being flagged, you should lower the sensitivity level of the rule and observe the flagged traffic. You can continue reducing the sensitivity level until you reach a point where legitimate traffic is not flagged. Then, you should create an override to enable the rule with a mitigation action.\n* If the rule is still flagging legitimate traffic you can consider using the expression filters to condition the rules to exclude certain types of traffic.\n\nThe default rule action for `log` with a sensitivity set to `high` will only show packets or requests with suspected attack traffic over internal `high` thresholds in your logs. For instance, if you set the threshold to `medium` or `low`, then only packets over those thresholds will be logged.\n\n## Configure the rules\n\nYou can adjust the action and sensitivity of the Adaptive DDoS Protection rules. The default action is *Log*. Use this action to first observe what traffic is flagged before deciding on a mitigation action.\n\nTo configure a rule, refer to the instructions in the following pages:\n\n* [Configure HTTP DDoS Attack Protection in the dashboard](https://developers.cloudflare.com/ddos-protection/managed-rulesets/http/http-overrides/configure-dashboard/) (for L7 rules)\n* [Configure Network-layer DDoS Attack Protection in the dashboard](https://developers.cloudflare.com/ddos-protection/managed-rulesets/network/network-overrides/configure-dashboard/) (for L3/4 rules)\n\nFor more information on the available configuration parameters, refer to the following pages:\n\n* For the (L7) DDoS protection rules for Origins, User-Agents, and Locations:\\\n  [HTTP DDoS Attack Protection parameters](https://developers.cloudflare.com/ddos-protection/managed-rulesets/http/override-parameters/)\n* For the (L3/4) DDoS protection rules for Protocols:\\\n  [Network-layer DDoS Attack Protection parameters](https://developers.cloudflare.com/ddos-protection/managed-rulesets/network/override-parameters/)\n\n</page>\n\n<page>\n---\ntitle: Changelog for the Network-layer DDoS managed ruleset · Cloudflare DDoS\n  Protection docs\ndescription: This section contains past and upcoming changes to the\n  Network-layer DDoS Attack Protection managed ruleset.\nlastUpdated: 2025-03-28T13:07:11.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/change-log/network/\n  md: https://developers.cloudflare.com/ddos-protection/change-log/network/index.md\n---\n\nThis section contains past and upcoming changes to the [Network-layer DDoS Attack Protection managed ruleset](https://developers.cloudflare.com/ddos-protection/managed-rulesets/network/).\n\nNote\n\nThe Network-layer DDoS Attack Protection managed ruleset protects Cloudflare customers on all plans. However, only [Magic transit](https://developers.cloudflare.com/magic-transit/) and [Spectrum](https://developers.cloudflare.com/spectrum/) customers on an Enterprise plan can customize the managed ruleset.\n\n[View scheduled changes](https://developers.cloudflare.com/ddos-protection/change-log/network/scheduled-changes/)\n\n[Subscribe to RSS](https://developers.cloudflare.com/ddos-protection/change-log/network/index.xml)\n\n</page>\n\n<page>\n---\ntitle: Changelog for the HTTP DDoS managed ruleset · Cloudflare DDoS Protection docs\ndescription: This section contains past and upcoming changes to the HTTP DDoS\n  Attack Protection managed ruleset.\nlastUpdated: 2025-03-28T13:07:11.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/change-log/http/\n  md: https://developers.cloudflare.com/ddos-protection/change-log/http/index.md\n---\n\nThis section contains past and upcoming changes to the [HTTP DDoS Attack Protection managed ruleset](https://developers.cloudflare.com/ddos-protection/managed-rulesets/http/).\n\n[View scheduled changes](https://developers.cloudflare.com/ddos-protection/change-log/http/scheduled-changes/)\n\n[Subscribe to RSS](https://developers.cloudflare.com/ddos-protection/change-log/http/index.xml)\n\n</page>\n\n<page>\n---\ntitle: HTTP DDoS Attack Protection managed ruleset · Cloudflare DDoS Protection docs\ndescription: Explore HTTP DDoS Attack Protection rule categories, including\n  botnets, unusual requests, and advanced features, to enhance your Cloudflare\n  security.\nlastUpdated: 2025-07-16T21:04:12.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/managed-rulesets/http/\n  md: https://developers.cloudflare.com/ddos-protection/managed-rulesets/http/index.md\n---\n\nThe Cloudflare HTTP DDoS Attack Protection managed ruleset is a set of pre-configured rules used to match [known DDoS attack vectors](https://developers.cloudflare.com/ddos-protection/about/attack-coverage/) at layer 7 (application layer) on the Cloudflare global network. The rules match known attack patterns and tools, suspicious patterns, protocol violations, requests causing large amounts of origin errors, excessive traffic hitting the origin/cache, and additional attack vectors at the application layer.\n\nCloudflare updates the list of rules in the managed ruleset on a regular basis. Refer to the [changelog](https://developers.cloudflare.com/ddos-protection/change-log/http/) for more information on recent and upcoming changes.\n\nThe HTTP DDoS Attack Protection managed ruleset is always enabled — you can only customize its behavior.\n\nThe HTTP DDoS Attack Protection managed ruleset provides users with increased observability into L7 DDoS attacks mitigated by Cloudflare, informing users of ongoing or past attacks. The [Security Events dashboard](https://developers.cloudflare.com/waf/analytics/security-events/), available at **Security** > **Events**, will display information about the top HTTP DDoS managed rules.\n\n## Ruleset configuration\n\nIf you are expecting large spikes of legitimate traffic, consider customizing your DDoS protection settings to avoid [false positives](https://developers.cloudflare.com/ddos-protection/managed-rulesets/http/http-overrides/override-examples/#legitimate-traffic-is-incorrectly-identified-as-an-attack-and-causes-a-false-positive), where legitimate traffic is falsely identified as attack traffic and blocked/challenged.\n\nYou can adjust the behavior of the rules in the managed ruleset by modifying the following parameters:\n\n* The performed **action** when an attack is detected.\n* The **sensitivity level** of attack detection mechanisms.\n\nNotes\n\n* Certain actions or sensitivity levels may not be available to all Cloudflare plans.\n* Currently, you can only define account-level configurations (or overrides) for the HTTP DDoS Attack Protection managed ruleset via API.\n\nTo adjust rule behavior, do one of the following:\n\n* [Configure the managed ruleset in the Cloudflare dashboard](https://developers.cloudflare.com/ddos-protection/managed-rulesets/http/http-overrides/configure-dashboard/).\n* [Configure the managed ruleset via API](https://developers.cloudflare.com/ddos-protection/managed-rulesets/http/http-overrides/configure-api/).\n* [Configure the managed ruleset using Terraform](https://developers.cloudflare.com/terraform/additional-configurations/ddos-managed-rulesets/#example-configure-http-ddos-attack-protection).\n\nFor more information on the available configuration parameters, refer to [Managed ruleset parameters](https://developers.cloudflare.com/ddos-protection/managed-rulesets/http/override-parameters/).\n\n## Origin Protect rules\n\nCloudflare HTTP DDoS Protection can also initiate mitigation based on the origin health. [Adaptive DDoS Protection for Origins](https://developers.cloudflare.com/ddos-protection/managed-rulesets/adaptive-protection/) detects and mitigates traffic that deviates from your site's origin errors profile. Floods of requests that cause a high number of zone errors (default sensitivity level is 1,000 errors per second) can initiate mitigation to alleviate the strain on the zone.\n\n| Rule ID | Description |\n| - | - |\n| `dd42da7baabe4e518eaf11c393596a9d` | HTTP requests causing a high number of origin errors. |\n\nNote\n\nThis rule is available for zones on any plan.\n\nWhile Cloudflare's network is built to automatically monitor and mitigate large DDoS attacks, Cloudflare also helps mitigate smaller DDoS attacks, based on the following general rules:\n\n* For zones on any plan, Cloudflare will apply mitigations when the HTTP error rate is above the *High* (default) sensitivity level of 1,000 errors-per-second rate threshold. You can decrease the sensitivity level by configuring the HTTP DDoS Attack Protection managed ruleset.\n\n* For zones on Pro, Business, and Enterprise plans, Cloudflare performs an additional check for better detection accuracy: the errors-per-second rate must also be at least five times the normal origin traffic levels before applying DDoS mitigations.\n\nAll HTTP errors in the `52x` range (Internal Server Error) and all errors in the `53x` range excluding [`530`](https://developers.cloudflare.com/support/troubleshooting/http-status-codes/cloudflare-5xx-errors/error-530) are considered when factoring in the error rate. For DDoS mitigations based on HTTP error rate, you cannot exclude specific HTTP error codes.\n\nFor more information on the types of DDoS attacks covered by Cloudflare's DDoS protection, refer to [DDoS attack coverage](https://developers.cloudflare.com/ddos-protection/about/attack-coverage/).\n\n## Availability\n\nThe HTTP DDoS Attack Protection managed ruleset protects Cloudflare customers on all plans for zones [onboarded to Cloudflare](https://developers.cloudflare.com/dns/zone-setups/full-setup/). All customers can customize the ruleset both at the zone level and at the account level.\n\nCustomers on Enterprise plans with the Advanced DDoS Protection subscription can create up to 10 overrides (or up to 10 rules, for API users) with custom [expressions](https://developers.cloudflare.com/ddos-protection/managed-rulesets/http/http-overrides/override-expressions/), to customize the DDoS protection for different incoming requests.\n\nOther customers can only create one override (or rule) and they cannot customize the rule expression. In this case, the single override, containing one or more configurations, will always apply to all incoming traffic.\n\n## Related Cloudflare products\n\nTo block additional L7 attacks you can use other Cloudflare products like the [Cloudflare WAF](https://developers.cloudflare.com/waf/).\n\n</page>\n\n<page>\n---\ntitle: Network-layer DDoS Attack Protection managed ruleset · Cloudflare DDoS\n  Protection docs\ndescription: The Cloudflare Network-layer DDoS Attack Protection managed ruleset\n  is a set of pre-configured rules used to match known DDoS attack vectors at\n  levels 3 and 4 of the OSI model.\nlastUpdated: 2025-12-23T17:05:23.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/managed-rulesets/network/\n  md: https://developers.cloudflare.com/ddos-protection/managed-rulesets/network/index.md\n---\n\nThe Cloudflare Network-layer DDoS Attack Protection managed ruleset is a set of pre-configured rules used to match [known DDoS attack vectors](https://developers.cloudflare.com/ddos-protection/about/attack-coverage/) at levels 3 and 4 of the OSI model.\n\nCloudflare updates the list of rules in the managed ruleset on a regular basis. Refer to the [changelog](https://developers.cloudflare.com/ddos-protection/change-log/network/) for more information on recent and upcoming changes.\n\nThe Network-layer DDoS Attack Protection managed ruleset is always enabled — you can only customize its behavior.\n\n## Ruleset configuration\n\nYou may need to adjust the behavior of specific rules in case of false positives or due to specific traffic patterns.\n\nAdjust the behavior of the rules in the managed ruleset by modifying the following parameters:\n\n* The performed **action** when an attack is detected\n* The **sensitivity level** of attack detection mechanisms\n\nTo adjust rule behavior, use one of the following methods:\n\n* [Configure the managed ruleset in the Cloudflare dashboard](https://developers.cloudflare.com/ddos-protection/managed-rulesets/network/network-overrides/configure-dashboard/).\n* [Configure the managed ruleset via Cloudflare API](https://developers.cloudflare.com/ddos-protection/managed-rulesets/network/network-overrides/configure-api/).\n* [Configure the managed ruleset using Terraform](https://developers.cloudflare.com/terraform/additional-configurations/ddos-managed-rulesets/#example-configure-network-layer-ddos-attack-protection).\n\nYou can only configure the behavior of the managed ruleset to set a stronger or weaker mitigation action (depending on the default action of a specific rule, you can change it to `Block` if the default action is `DDoS Dynamic` or `Log`.), or a lower default sensitivity for all rules. Refer to [Managed ruleset parameters](https://developers.cloudflare.com/ddos-protection/managed-rulesets/network/override-parameters/) for more information.\n\nOverrides can apply to all packets or to a subset of incoming packets, depending on the override expression. Refer to [Override expressions](https://developers.cloudflare.com/ddos-protection/managed-rulesets/network/network-overrides/override-expressions/) for more information.\n\n### Network Analytics rule display\n\nCloudflare regularly deploys new detection rules to the Network-layer DDoS managed ruleset. To ensure high accuracy and minimize false positives, these rules undergo a testing phase before they are fully promoted.\n\nWhen a rule is in its testing phase, you may notice specific behaviors in the Cloudflare dashboard.\n\nNew rules often default to `Log` (visible in **DDoS Managed Rules** > **Browse Rules**). This allows Cloudflare to evaluate the rule's performance against real-world traffic without impacting legitimate packets.\n\nIn the [Network Analytics](https://developers.cloudflare.com/analytics/network-analytics/) dashboard, traffic matched by these testing-phase rules is labeled as `Log (rule disabled)`. This is a reporting convention indicating the rule is in a pre-production monitoring state.\n\nWhile you can manually override a rule from `Log` to `Block`, consider the following before doing so:\n\n* Rules in the testing phase have not yet been fully tuned for broad deployment. Overriding them to a mitigation action (like `Block`) may increase the risk of dropping legitimate traffic.\n\n* The default action of a rule is decided during the testing period. Cloudflare may set its default action to **DDoS Dynamic**, which may use rate-limiting or a multi-step mitigation combination based on traffic factors. By applying a manual `Block` override, you prevent your configuration from automatically inheriting the more nuanced DDoS Dynamic action once it is released.\n\nIf you choose to override a testing rule to mitigate an active attack, Cloudflare recommends reviewing that override periodically to see if the rule has been promoted to a permanent default action.\n\n## Availability\n\nThe Network-layer DDoS Attack Protection managed ruleset is available in all Cloudflare plans for:\n\n* Zones [onboarded to Cloudflare](https://developers.cloudflare.com/dns/zone-setups/full-setup/) (zones with their traffic routed through the Cloudflare network)\n* IP applications onboarded to [Spectrum](https://developers.cloudflare.com/spectrum/)\n* IP prefixes onboarded to [Magic Transit](https://developers.cloudflare.com/magic-transit/)\n\nHowever, only Magic Transit and Spectrum customers on an Enterprise plan can customize the managed ruleset.\n\n## Related Cloudflare products\n\nMagic Transit customers can configure the following additional products:\n\n* Enable [Advanced TCP Protection](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/overview/advanced-tcp-protection/) to detect and mitigate sophisticated out-of-state TCP attacks such as randomized and spoofed ACK floods or SYN and SYN-ACK floods.\n* Create custom [Magic Firewall](https://developers.cloudflare.com/magic-firewall/) rules to block additional network-layer attacks.\n\nSpectrum customers can use [IP Access](https://developers.cloudflare.com/waf/tools/ip-access-rules/) rules to block additional network-layer attacks.\n\n</page>\n\n<page>\n---\ntitle: DDoS alerts · Cloudflare DDoS Protection docs\ndescription: Configure notifications to receive real-time alerts (within ~1\n  minute) about L3/4 and L7 DDoS attacks on your Internet properties, depending\n  on your plan and services. You can choose from different delivery methods.\nlastUpdated: 2025-09-03T18:12:42.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/reference/alerts/\n  md: https://developers.cloudflare.com/ddos-protection/reference/alerts/index.md\n---\n\nConfigure notifications to receive real-time alerts (within \\~1 minute) about L3/4 and L7 DDoS attacks on your Internet properties, depending on your plan and services. You can choose from different delivery methods.\n\nEach notification email includes the following information:\n\n* Description\n* Detection and mitigation time of attack\n* Attack type\n* Maximum rate of attack\n* Attack target (zone, host, or IP address)\n* Rule that matched the attack (ID and description)\n* Rule override, if any\n\nCloudflare automatically sends weekly summaries of detected and mitigated DDoS attacks to Magic Transit and Spectrum BYOIP customers. Monthly application security reports are available for WAF/CDN customers. For more information, refer to [DDoS reports](https://developers.cloudflare.com/ddos-protection/reference/reports/).\n\nNote\n\nDDoS reports and DDoS alerts are independent: DDoS reports will include information about any attacks for which you received DDoS alerts.\n\n## Set up a notification for DDoS alerts\n\nTo set up a notification:\n\n1. In the Cloudflare dashboard, go to the **Notifications** page.\n\n   [Go to **Notifications**](https://dash.cloudflare.com/?to=/:account/notifications)\n\n2. Select **Add**.\n\n3. Select one of the [available DDoS alerts](https://developers.cloudflare.com/ddos-protection/reference/alerts/#alert-types) depending on your plan and services:\n\n   * HTTP DDoS Attack Alert\n   * Layer 3/4 DDoS Attack Alert\n   * Advanced HTTP DDoS Attack Alert\n   * Advanced Layer 3/4 DDoS Attack Alert\n\n4. Enter a notification name and (optionally) a description.\n\n5. Configure a delivery method for the notification. The available delivery methods depend on your Cloudflare plan. For more information, refer to [Cloudflare Notifications](https://developers.cloudflare.com/notifications/).\n\n6. If you are creating a notification for one of the advanced DDoS attack alerts, select **Next** and define the parameters that will filter the notifications you will receive.\n\n7. Select **Save**.\n\n## Edit an existing notification\n\nTo edit, delete, or disable a notification, go to your [account notifications](https://dash.cloudflare.com/?to=/:account/notifications).\n\n***\n\n## Alert types\n\nCloudflare can issue notifications for different types of DDoS attack alerts.\n\n### Standard alerts\n\nHTTP DDoS Attack Alert\n\n**Who is it for?**\n\n[WAF](https://developers.cloudflare.com/waf/) or [CDN](https://developers.cloudflare.com/cache/) customers who want to receive a notification when Cloudflare has mitigated HTTP attacks that generate more than 100 requests per second.\n\n**Other options / filters**\n\nNone.\n\n**Included with**\n\nAll Cloudflare plans.\n\n**What should you do if you receive one?**\n\nNo action needed. Refer to [DDoS alerts](https://developers.cloudflare.com/ddos-protection/reference/alerts/) for more information.\n\nLayer 3/4 DDoS Attack Alert\n\n**Who is it for?**\n\n[BYOIP](https://developers.cloudflare.com/byoip/) and [Spectrum](https://developers.cloudflare.com/spectrum/) customers with [Network Analytics](https://developers.cloudflare.com/analytics/network-analytics/) who want to receive a notification when Cloudflare has mitigated attacks that generate an average of at least 12,000 packets per second over a five-second period, with a duration of one minute or more.\n\n**Other options / filters**\n\nNone.\n\n**Included with**\n\nPurchase of Magic Transit and/or BYOIP.\n\n**What should you do if you receive one?**\n\nNo action needed. Refer to [DDoS alerts](https://developers.cloudflare.com/ddos-protection/reference/alerts/) for more information.\n\n### Advanced alerts\n\nNote\n\nThe availability of advanced DDoS attack alerts depends on your Cloudflare plan and subscribed services. Refer to [Availability](#availability) for details.\n\nAdvanced DDoS attack alerts support additional configuration, allowing you to filter the notifications you wish to receive.\n\nAdvanced HTTP DDoS Attack Alert\n\n**Who is it for?**\n\n[WAF](https://developers.cloudflare.com/waf/) or [CDN](https://developers.cloudflare.com/cache/) customers with the [Advanced DDoS Protection](https://developers.cloudflare.com/ddos-protection/) subscription who want to receive a notification when Cloudflare has mitigated attacks that generate more than the configured number of requests per second (100 rps by default).\n\n**Other options / filters**\n\nYou can choose when to trigger a notification.\n\nAvailable filters include:\n\n* The zones in the account for which you wish to receive notifications.\n* The specific hostnames for which you wish to receive notifications.\n* The minimum requests-per-second rate that will trigger the alert (100 rps by default).\n\n**Included with**\n\nEnterprise plans with the Advanced DDoS Protection add-on.\n\n**What should you do if you receive one?**\n\nNo action needed. Refer to [DDoS alerts](https://developers.cloudflare.com/ddos-protection/reference/alerts/) for more information.\n\nAdvanced Layer 3/4 DDoS Attack Alert\n\n**Who is it for?**\n\n[BYOIP](https://developers.cloudflare.com/byoip/) and [Magic Transit](https://developers.cloudflare.com/magic-transit/) customers with [Network Analytics](https://developers.cloudflare.com/analytics/network-analytics/) who want to receive a notification when Cloudflare has mitigated attacks that generate more than the configured number of packets per second (12,000 pps by default).\n\n**Other options / filters**\n\nYou can choose when to trigger a notification.\n\nAvailable filters include:\n\n* The IP prefixes for which you wish to receive notifications.\n* The specific IP addresses for which you wish to receive notifications.\n* The minimum packets-per-second rate that will trigger the alert (12,000 pps by default).\n* The minimum megabits-per-second rate that will trigger the alert.\n* The protocols for which you wish to receive notifications (all protocols by default).\n\nIf you specify multiple filters, Cloudflare applies an `AND` logic. This means the alert will only trigger if all filters you set are true. Keep this in mind when setting up this alert with more than one filter.\n\n**Included with**\n\nPurchase of Magic Transit and/or BYOIP (Enterprise plans).\n\n**What should you do if you receive one?**\n\nNo action needed. Refer to [DDoS alerts](https://developers.cloudflare.com/ddos-protection/reference/alerts/) for more information.\n\nYou will also receive alerts for rules with a *Log* action, containing information on what triggered the alert.\n\n## Availability\n\nThe available alerts depend on your Cloudflare plan and subscribed services:\n\n| Alert type | WAF/CDN | Spectrum | Spectrum BYOIP | Magic Transit |\n| - | - | - | - | - |\n| HTTP DDoS Attack Alert | Yes | – | – | – |\n| Advanced HTTP DDoS Attack Alert | Yes1 | – | – | – |\n| Layer 3/4 DDoS Attack Alert | – | Yes2, 3 | Yes | Yes3 |\n| Advanced Layer 3/4 DDoS Attack Alert | – | – | Yes2 | Yes2 |\n\n1 *Only available to Enterprise customers with the Advanced DDoS Protection subscription.*\\\n2 *Only available on an Enterprise plan.*\\\n3 *Refer to [Final remarks](#final-remarks) for additional notes.*\n\n## Example notification\n\nThe following image shows an example notification delivered via email:\n\n![Example notification email of a DDoS attack](https://developers.cloudflare.com/_astro/ddos-notification-example.c2rVlJvC_1sWwm8.webp)\n\nTo investigate a possibly ongoing attack, select **View Dashboard**. To go to the rule details in the Cloudflare dashboard, select **View Rule**.\n\n## Final remarks\n\n* Spectrum and Magic Transit customers using [assigned Cloudflare IP addresses](https://developers.cloudflare.com/magic-transit/cloudflare-ips/) will receive layer 3/4 DDoS attack alerts where the attacked target is the Cloudflare IP or prefix. If you have [brought your own IP (BYOIP)](https://developers.cloudflare.com/byoip/) to Cloudflare Spectrum or Magic Transit, you will see your own IP addresses or prefixes as the attacked target.\n* In some cases, HTTP DDoS attack alerts will reference the attacked zone name instead of the attacked hostname. This occurs when the attack signature does not include information on the attacked hostname because it is not a strong indicator for identifying attack requests. For more information on attack signatures, refer to [How DDoS protection works](https://developers.cloudflare.com/ddos-protection/about/how-ddos-protection-works/).\n* DDoS alerts are currently only available for DDoS attacks detected and mitigated by the [DDoS managed rulesets](https://developers.cloudflare.com/ddos-protection/managed-rulesets/). Alerts are not yet available for DDoS attacks detected and mitigated by the [Advanced TCP Protection](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/overview/advanced-tcp-protection/) and the [Advanced DNS Protection](https://developers.cloudflare.com/ddos-protection/advanced-ddos-systems/overview/advanced-dns-protection/) system.\n* You will not receive duplicate DDoS alerts within the same one-hour time frame.\n* If you configure more than one alert type for the same kind of attack (for example, both an HTTP DDoS Attack Alert and an Advanced HTTP DDoS Attack Alert) you may get more than one notification when an attack occurs. To avoid receiving duplicate notifications, delete one of the configured alerts.\n\n</page>\n\n<page>\n---\ntitle: DDoS analytics · Cloudflare DDoS Protection docs\ndescription: \"You can view DDoS analytics in different dashboards, depending on\n  your service and plan:\"\nlastUpdated: 2025-02-20T15:42:50.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/reference/analytics/\n  md: https://developers.cloudflare.com/ddos-protection/reference/analytics/index.md\n---\n\nYou can view DDoS analytics in different dashboards, depending on your service and plan:\n\n* The [Security Events dashboard](https://developers.cloudflare.com/waf/analytics/security-events/) provides you with visibility into L7 security events that target your zone, including HTTP DDoS attacks and TCP attacks. The dashboard displays mitigations of HTTP DDoS attacks as HTTP DDoS events. These events are also available via [Cloudflare Logs](https://developers.cloudflare.com/logs/).\n\n* The [Network Analytics dashboard](https://developers.cloudflare.com/analytics/network-analytics/) provides you with visibility into L3/4 traffic and DDoS attacks that target your IP ranges or Spectrum applications.\n\n## Availability\n\n| Service | Free | Pro | Business | Enterprise |\n| - | - | - | - | - |\n| WAF/CDN | Sampled logs only | Security Events | Security Events | Security Events |\n| Spectrum/BYOIP | – | – | – | Network Analytics |\n| Magic Transit | – | – | – | Network Analytics |\n\n## Remarks\n\nIn some situations, the analytics dashboards will not show you the ID of the DDoS managed rule that handled a packet/request. This means that an internal DDoS rule, which Cloudflare does not currently expose publicly, applied an action to the packet/request. These internal DDoS rules have a very low false positive rate and should always be enabled to protect your properties against DDoS attacks. For the same reason, DDoS rule IDs may also be unavailable in Cloudflare logs and API responses.\n\n</page>\n\n<page>\n---\ntitle: DDoS logs · Cloudflare DDoS Protection docs\ndescription: Retrieve HTTP events using Cloudflare Logs to integrate them into\n  your SIEM systems.\nlastUpdated: 2025-07-25T16:42:51.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/reference/logs/\n  md: https://developers.cloudflare.com/ddos-protection/reference/logs/index.md\n---\n\nRetrieve HTTP events using [Cloudflare Logs](https://developers.cloudflare.com/logs/) to integrate them into your SIEM systems.\n\nAdditionally, if you are a Magic Transit or a Spectrum customer on an Enterprise plan, you can export L3/4 traffic and DDoS attack logs using the [Network Analytics logs](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/network_analytics_logs/).\n\n</page>\n\n<page>\n---\ntitle: DDoS reports · Cloudflare DDoS Protection docs\ndescription: To download an ad-hoc DDoS report, generate a PDF report file by\n  selecting Print report in your analytics dashboard.\nlastUpdated: 2025-08-20T21:45:15.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/reference/reports/\n  md: https://developers.cloudflare.com/ddos-protection/reference/reports/index.md\n---\n\nTo download an ad-hoc DDoS report, generate a PDF report file by selecting **Print report** in your [analytics dashboard](https://developers.cloudflare.com/ddos-protection/reference/analytics/).\n\nWAF/CDN customers can download a monthly report in Account Home > **Security Center**, by selecting [Security Reports](https://developers.cloudflare.com/security-center/app-security-reports/) and downloading the desired monthly report.\n\nAdditionally, if you are a Magic Transit or Spectrum BYOIP customer, you will receive weekly DDoS reports by email with a snapshot of the DDoS attacks that Cloudflare detected and mitigated in the previous week.\n\nNote\n\nTo receive DDoS reports by email you must have opted in to the **Analytics** category in the [communication preferences](https://developers.cloudflare.com/fundamentals/user-profiles/customize-account/#notifications) for your profile.\n\n## Weekly DDoS reports\n\nCloudflare sends DDoS reports via email from `no-reply@notify.cloudflare.com` to users with the Super Administrator role on accounts with prefixes advertised by Cloudflare.\n\nReports contain the following information:\n\n* Total number of DDoS attacks\n* Largest DDoS attack in packets per second (pps) and bits per second (bps)\n* Changes in DDoS attacks compared to the previous report\n* Top attack protocols\n* Top targeted IP addresses\n* Top targeted destination ports\n* Total potential downtime prevented (a sum of the duration of all attacks in that week)\n* Total bytes mitigated (a sum of all the mitigated attack traffic)\n\nCloudflare issues DDoS reports via email each Tuesday. Reports summarize the attacks that occurred from Monday of the previous week to Sunday of the current week. For example, a report issued on 2020-11-10 (Tuesday) summarizes activity from 2020-11-02 (Monday) to 2020-11-08 (Sunday).\n\nTo receive real-time attack alerts, configure [DDoS alerts](https://developers.cloudflare.com/ddos-protection/reference/alerts/).\n\nNotes\n\n* Information about top attack protocols, IP addresses, and destination ports is temporarily unavailable in weekly DDoS reports. Use the [Network Analytics dashboard](https://developers.cloudflare.com/analytics/network-analytics/) to get this information.\n\n* DDoS reports and DDoS alerts are independent: DDoS reports will include information about any attacks for which you received DDoS alerts.\n\n### Example report\n\nThe following image shows an example DDoS report:\n\n![Example email sent with a weekly DDoS report](https://developers.cloudflare.com/_astro/ddos-report-email.meVYnmIT_9PefS.webp)\n\nWhen Cloudflare does not detect any L3/4 DDoS attacks in the prior week, Cloudflare sends a confirmation report:\n\n![Example report email sent when Cloudflare does not detect any DDoS attack in the previous week](https://developers.cloudflare.com/_astro/ddos-report-no-attacks.DOx1yQA2_ZyhHbJ.webp)\n\n### Manage reporting subscriptions\n\nMagic Transit and Spectrum BYOIP customers will receive the weekly DDoS report automatically.\n\nTo stop receiving DDoS reports, select the unsubscribe link at the bottom of the report email. To resubscribe after opting out, contact Cloudflare support.\n\n</page>\n\n<page>\n---\ntitle: Simulating test DDoS attacks · Cloudflare DDoS Protection docs\ndescription: After onboarding to Cloudflare, you may want to simulate DDoS\n  attacks against your Internet properties to test the protection, reporting,\n  and alerting mechanisms. Follow the guidelines in this section to simulate a\n  DDoS attack.\nlastUpdated: 2025-09-10T19:14:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ddos-protection/reference/simulate-ddos-attack/\n  md: https://developers.cloudflare.com/ddos-protection/reference/simulate-ddos-attack/index.md\n---\n\nAfter onboarding to Cloudflare, you may want to simulate DDoS attacks against your Internet properties to test the protection, [reporting](https://developers.cloudflare.com/ddos-protection/reference/reports/), and [alerting](https://developers.cloudflare.com/ddos-protection/reference/alerts/) mechanisms. Follow the guidelines in this section to simulate a DDoS attack.\n\nYou can only launch DDoS attacks against your own Internet properties — your zone, Spectrum application, or IP range (depending on your Cloudflare services) — and provided that:\n\n* The Internet properties are not shared with other organizations or individuals.\n* The Internet properties have been onboarded to Cloudflare in an account under your name or ownership.\n\n## Before you start\n\nYou do not have to obtain permission from Cloudflare to launch a DDoS attack simulation against your own Internet properties.\n\nIt is recommended that you choose the right service and enable the correct features to test against the corresponding DDoS attacks. For example, if you want to test Cloudflare against an HTTP DDoS attack and you are only using Magic Transit, the test is going to fail because you need to onboard your HTTP application to Cloudflare's reverse proxy service to test our HTTP DDoS Protection.\n\n</page>\n\n<page>\n---\ntitle: Analytics and logs · Cloudflare DNS docs\ndescription: When you use Cloudflare DNS, you can access data about DNS queries\n  through a variety of sources.\nlastUpdated: 2025-10-23T07:57:47.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/additional-options/analytics/\n  md: https://developers.cloudflare.com/dns/additional-options/analytics/index.md\n---\n\nWhen you use Cloudflare DNS, you can access data about DNS queries through a variety of sources.\n\n***\n\n## Analytics\n\nDNS analytics allow you to evaluate data about DNS queries to your zone.\n\nYou can [use the dashboard](#view-on-the-dashboard) to get insights quickly based on a [predefined set of dimensions](#available-dimensions), or [use the API](#explore-with-the-api) to have access to all fields available in the GraphQL DNS analytics schemas.\n\nWhen using GraphQL, you also have the option to get data for DNS queries across all zones within a given Cloudflare account.\n\n### Availability and limits\n\n| | Free | Pro | Business | Enterprise |\n| - | - | - | - | - |\n| Availability | Yes | Yes | Yes | Yes |\n| Maximum time interval (zone) | 7 days | 31 days | 31 days | 62 days |\n| Maximum time interval (account) | 7 days | 7 days | 7 days | 62 days |\n| Historical data (zone) | 8 days | 31 days | 31 days | 62 days |\n| Historical data (account) | 8 days | 8 days | 8 days | 62 days |\n\n### View on the dashboard\n\nFor a quick summary, view your DNS analytics on the dashboard:\n\n[Go to **Analytics**](https://dash.cloudflare.com/?to=/:account/:zone/dns/analytics)\n\nThe DNS analytics dashboard contains [four main panels](#dns-analytics-panels). The filters and time frame that you specify at the top of the page apply to all of them.\n\n#### Available dimensions\n\n* Query name\n* Query type (same as DNS record type)\n* Response code\n* Data center\n* Source IP\n* Destination IP\n* Protocol\n* IP version\n\n#### Panels\n\n* **Query overview**: the number of queries and their distribution over time. This information is segmented by each of the [available dimensions](#available-dimensions) and the graph displays the top five values. You can select the dimensions through the different tabs above the graph and quickly filter for or exclude a certain value from the results by hovering over it and selecting **Filter** or **Exclude**.\n\n* **Query statistics**: an overview of query metrics based on your filters and selected time frame. Namely, **Total queries**, **Average queries per second**, and **Average processing time**. The average processing time is displayed in milliseconds and includes upstream queries in the case of [flattened CNAME records](https://developers.cloudflare.com/dns/cname-flattening/).\n\n  Note\n\n  Processing time is different from response time. Response time would have to include information that is not available to Cloudflare, such as how long the query takes from the client to the resolver and from the resolver to Cloudflare (as your authoritative DNS provider).\n\n* **DNS queries by data center**: a map indicating which Cloudflare data centers have handled DNS queries to your zone in the selected time period. You can also find a list of the ten top results and quickly filter for or exclude a certain data center from the results by hovering over it and selecting **Filter** or **Exclude**.\n\n* **Queries by source**: a breakdown of the top five, ten, or fifteen results - based on your selection - and grouped by the [available dimensions](#available-dimensions).\n\n### Explore with the API\n\nFor more detailed metrics, use the [GraphQL API](https://developers.cloudflare.com/analytics/graphql-api/). Refer to the GraphQL Analytics API documentation for guidance on how to [get started](https://developers.cloudflare.com/analytics/graphql-api/getting-started/).\n\nThe DNS analytics has two [schemas](https://developers.cloudflare.com/analytics/graphql-api/getting-started/querying-basics/):\n\n* `dnsAnalyticsAdaptive`: Retrieve information about individual DNS queries.\n* `dnsAnalyticsAdaptiveGroups`: Get reports on aggregate information only.\n\nTo get account-level data, you can set up queries similar to the following:\n\nGet the last 10,000 queries resulting in NXDOMAIN",
      "language": "unknown"
    },
    {
      "code": "[Run in GraphQL API Explorer](https://graphql.cloudflare.com/explorer?query=I4VwpgTgngBA4mALgGQIYGdEDkAaARAeQFkBBASSwCUx0AHAewDt0aYBvAKBhgDcBLMAHdI7LtxioAxpPohGidAAoAZnwA2iSAC52E6bPkAVVAHMdAIgAcAZlQAWAKwAmAOzWAbAEYARpIAmYJJOju7uyn4uyjYu3u4BDuYwAL4AlKLi4n7MJIyoalCIfJLoJH6otIU8YIpiGdxqfAC2fIg6ngAMne21daoa2ul1GWWaAPomYMAWTu1ODgC07e7znu7mADQ9QxA0DMxgAML0ARa4hKQUG1t1I2CjapPTswtLK5bm19xJnzD0EAEQABCUB0AG1boVGnc8ABRADKBwAutc0pwhtwAF5MMDGEw-UCQKBYVBQn47OhMFhHAL48DQQxQWhgH4QprMobfDKc5IcJJAA\\&variables=N4XyA)\n\nGet the overall query count per account",
      "language": "unknown"
    },
    {
      "code": "[Run in GraphQL API Explorer](https://graphql.cloudflare.com/explorer?query=I4VwpgTgngBA4mALgFQPaIIYBsAiA5AZQEVxoBhVEAO0RgG8AoGGANwEswB3Sep5mDAGNBlGgGcAFADM2WRJABc9AcNEoMAcyUAiABwBmDABYArACYA7PoBsARgBGggCZhBZ09etSnFqQYv21i4m2jAAvgCUvPz8TlRiAIJU2FCIbIKJThgADmksYHAQlNmSfDHMMnKK0eUxWfIA+hpgwDpmAAxmJgC07T3tttpltTD1YA1YLW2d-T367UMj4cMxWGwAtmyISrYrMFGMSyLUiHthw+fM52FAA\\&variables=N4XyA)\n\n***\n\n## Logs\n\nLogs let Enterprise customers view [detailed information](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/zone/dns_logs/) about individual DNS queries.\n\nFor help setting up Logpush, refer to [Logpush](https://developers.cloudflare.com/logs/logpush/) documentation.\n\n</page>\n\n<page>\n---\ntitle: Configure DNS zone defaults · Cloudflare DNS docs\ndescription: While there are default values for DNS settings that Cloudflare\n  applies to all new zones, Enterprise accounts have the option to configure\n  their own DNS zone defaults according to their preference.\nlastUpdated: 2025-12-29T18:48:32.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/additional-options/dns-zone-defaults/\n  md: https://developers.cloudflare.com/dns/additional-options/dns-zone-defaults/index.md\n---\n\nWhile there are default values for DNS settings that Cloudflare applies to all new zones, Enterprise accounts have the option to configure their own DNS zone defaults according to their preference.\n\nWarning\n\nDNS zone defaults are only applied at the moment a new zone is created and will not impact already existing zones, nor zones that existed previously and are being revived.\n\nAny of the values specified as default can later be adjusted within each zone, on the respective [**DNS Settings**](https://dash.cloudflare.com/?to=/:account/:zone/dns/settings) or [**DNS Records**](https://dash.cloudflare.com/?to=/:account/:zone/dns/records) page.\n\n## Steps\n\n1. In the Cloudflare dashboard, go to the account **Settings** page.\n\n   [Go to **Settings**](https://dash.cloudflare.com/?to=/:account/configurations)\n\n2. Go to **DNS Settings**. If these options are not displayed on your Cloudflare dashboard, you may need to reach out to your account team to have them added.\n\n3. For **DNS zone defaults**, select **Configure defaults**.\n\nThe values you select for the listed settings will be automatically applied to new zones as you add them to your Cloudflare account.\n\n## Available settings\n\n* [Nameserver assignment](https://developers.cloudflare.com/dns/nameservers/nameserver-options/#assignment-method): Select your preferred nameserver type or assignment method that you want Cloudflare to use for your new zones. This setting applies both to primary zones ([full setup](https://developers.cloudflare.com/dns/zone-setups/full-setup/)) and [secondary zones](https://developers.cloudflare.com/dns/zone-setups/zone-transfers/cloudflare-as-secondary/).\n\nFor primary zones:\n\n* [Multi-provider DNS](https://developers.cloudflare.com/dns/nameservers/nameserver-options/#multi-provider-dns): Control whether or not Cloudflare will consider `NS` records you add on the zone apex and if zones that contain external nameservers listed in the registrar will be activated.\n* [Nameserver TTL](https://developers.cloudflare.com/dns/nameservers/nameserver-options/#nameserver-ttl): Control how long, in seconds, your nameserver (`NS`) records are cached. The default time-to-live (TTL) is 24 hours. This setting applies both to Cloudflare nameservers and [custom nameservers](https://developers.cloudflare.com/dns/nameservers/custom-nameservers/).\n* [SOA record](https://developers.cloudflare.com/dns/manage-dns-records/reference/dns-record-types/#soa): Adjust values for the start of authority (SOA) record that Cloudflare creates for your zone.\n\nFor secondary zones:\n\n* [Secondary DNS override](https://developers.cloudflare.com/dns/zone-setups/zone-transfers/cloudflare-as-secondary/proxy-traffic/): Enable the options to use Cloudflare [proxy](https://developers.cloudflare.com/dns/proxy-status/) and add `CNAME` records at your zone apex.\n\n  Multi-provider DNS does not apply as a setting for secondary zones, as this is already a required behavior for this setup. `SOA` record and the `NS` record TTL are defined on your external DNS provider and only transferred into Cloudflare.\n\n</page>\n\n<page>\n---\ntitle: Reverse zones and PTR records · Cloudflare DNS docs\ndescription: If you control your own IP prefix(es), you can set up reverse zones\n  with PTR records to allow reverse DNS lookups.\nlastUpdated: 2025-12-16T09:55:00.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/additional-options/reverse-zones/\n  md: https://developers.cloudflare.com/dns/additional-options/reverse-zones/index.md\n---\n\nIf you control your own IP prefix(es), you can set up reverse zones with PTR records to allow reverse DNS lookups.\n\n## PTR records\n\nPTR records specify the allowed hosts for a given IP address. They are the opposite of [A records](https://www.cloudflare.com/learning/dns/dns-records/dns-a-record) and used for reverse DNS lookups.\n\nHistorically, PTR records prevented outbound SMTP servers from being blocked by spam filters. However, more modern DNS records — [SPF, DKIM, and DMARC](https://developers.cloudflare.com/dns/manage-dns-records/how-to/email-records/#prevent-domain-spoofing) — provide better verifications of domain ownership.\n\nNow, PTR records are primarily useful for those who own a dedicated IP space. They can help populate trace routes and security tools with human-readable domain names.\n\nAs PTR records are mainly used for reverse DNS lookups, they should preferably be added to reverse zones.\n\n## Availability\n\nThe following Cloudflare customers can create reverse zones.\n\n* Customers with an IPv4 or IPv6 address space can add the IPv4 or IPv6 reverse zone for their IP space to their account, and create the required PTR records for forward resolution.\n* DNS Firewall customers need to contact their account team to add PTR records for the IPs used for their DNS Firewall clusters.\n\nIf your account does not meet these qualifications and you do not own the IP prefix you want to add PTR records on, contact the owner of the IP address based on a [whois lookup](https://lookup.icann.org/).\n\n## Set up a reverse zone\n\nTo set up a reverse zone, you need to create a reverse DNS zone and add PTR records for forward resolution.\n\n### 1. Create a reverse DNS zone\n\n1. Within your account, click **Add** > **Connect a domain**.\n\n2. For your site name, use the reverse IP address:\n\n   * For IPv4 /24 prefixes, the pattern is:\n\n     * **IP prefix**: `<octet_1>.<octet_2>.<octet_3>.0/24`\n     * **Reverse zone address**: `<octet_3>.<octet_2>.<octet_1>.in-addr.arpa`\n\n   * For IPv4 /16 prefixes, the pattern is:\n\n     * **IP prefix**: `<octet_1>.<octet_2>.0.0/16`\n     * **Reverse zone address**: `<octet_2>.<octet_1>.in-addr.arpa`\n\n   Example\n\n   * **IPv4 prefix**: `198.51.100.0/24`\n   * **Reverse zone**: `100.51.198.in-addr.arpa`\n\n   - For IPv6, consider the following examples:\n\n   * **IPv6 prefix**: `2001:DB8::0/32`\n   * **Reverse zone**: `8.b.d.0.1.0.0.2.ip6.arpa`\n\n   - **IPv6 prefix**: `2001:DB8::0/48`\n   - **Reverse zone**: `0.0.0.0.8.b.d.0.1.0.0.2.ip6.arpa`\n\n3. If you are adding less than 200 PTR records, select the **Free** plan. If you are adding more, select a paid plan.\n\n4. Skip the rest of the onboarding process.\n\n### 2. Add PTR records\n\n1. In the Cloudflare dashboard, go to the **DNS Records** page.\n\n   [Go to **Records**](https://dash.cloudflare.com/?to=/:account/:zone/dns/records)\n\n2. For each IP within the prefix, add a PTR record using the least significant octet(s) as the subdomain.\n\nIPv4 example\n\nSuppose you have the following configuration:\n\n* **Reverse zone**: `100.51.198.in-addr.arpa`\n* **IP address**: `198.51.100.123`\n\nThe subdomain for the PTR record would be `123`, making the full domain for forward lookup `123.100.51.198.in-addr.arpa`.\n\n| Type | Name | Domain name | TTL |\n| - | - | - | - |\n| `PTR` | `123` | `example.com` | `Auto` |\n\nIPv6 example\n\nSuppose you have the following configuration:\n\n* **Reverse zone**: `0.0.0.0.8.b.d.0.1.0.0.2.ip6.arpa`\n* **IP address**: `2001:DB8::5`\n\nThe subdomain for the PTR record would be `5.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0`, making the full domain for forward lookup `5.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.8.b.d.0.1.0.0.2.ip6.arpa`.\n\n| Type | Name | Domain name | TTL |\n| - | - | - | - |\n| `PTR` | `5.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0` | `example.com` | `Auto` |\n\n### 3. Set Cloudflare nameservers\n\nAdd the two Cloudflare nameservers provided for the zone at your Regional Internet Registry (RIR). The exact steps to update your nameservers will depend on the registry you are using.\n\nAfter this process, your reverse zone will be activated and you can perform reverse DNS lookups.\n\n## Other resources\n\nWhile setting up reverse zones, the following third-party tools may be useful:\n\n* [Reverse DNS record generator](https://www.whatsmydns.net/reverse-dns-generator)\n* [IPv6 subnet calculator](https://www.internex.at/de/toolbox/ipv6)\n\n</page>\n\n<page>\n---\ntitle: CNAME flattening diagram · Cloudflare DNS docs\ndescription: Consider an example use case and the main steps involved in CNAME flattening.\nlastUpdated: 2025-01-14T14:12:46.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/cname-flattening/cname-flattening-diagram/\n  md: https://developers.cloudflare.com/dns/cname-flattening/cname-flattening-diagram/index.md\n---\n\nWith CNAME flattening, Cloudflare returns an IP address instead of the target hostname that a CNAME record points to. This process supports a few features and delivers better performance and flexibility, as mentioned in the [CNAME flattening concept page](https://developers.cloudflare.com/dns/cname-flattening/).\n\nConsider the diagram below to have an overview of the steps that may be involved in CNAME flattening.\n\nNote\n\nNote that this is a simpler scenario. Cases where CNAME flattening is optional and/or the target hostname is not external to Cloudflare work differently.\n\n## Example use case\n\n* `domain.test` is a zone on Cloudflare and has the following CNAME record:\n\n| Type | Name | Content | TTL |\n| - | - | - | - |\n| `CNAME` | `domain.test` | `external-origin.test` | `3600` |\n\n* `external-origin.test` is a zone on a different DNS provider and has the following A record:\n\n| Type | Name | Content | TTL |\n| - | - | - | - |\n| `A` | `external-origin.test` | `192.0.2.1` | `7200` |\n\nIn this case, the process to respond to queries for `domain.test` directly with the IP address can be represented by the following diagram:",
      "language": "unknown"
    },
    {
      "code": "## Aspects to consider\n\n* If the CNAME record is proxied in Cloudflare, the answer is made up of multiple [Cloudflare IPs](https://www.cloudflare.com/ips/) and its Time to Live (TTL) is set to `300`.\n* If the CNAME record in Cloudflare is not proxied, the flattened answer consists of the IP address from the external DNS provider and its TTL corresponds to the lower value between the external record and the Cloudflare CNAME record.\n\n</page>\n\n<page>\n---\ntitle: Set up CNAME flattening · Cloudflare DNS docs\ndescription: CNAME flattening occurs by default for all plans when your domain\n  uses a CNAME record for its zone apex (example.com, meaning the record Name is\n  set to @).\nlastUpdated: 2025-10-23T07:57:47.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/cname-flattening/set-up-cname-flattening/\n  md: https://developers.cloudflare.com/dns/cname-flattening/set-up-cname-flattening/index.md\n---\n\nNote\n\nIf the CNAME target is on the same zone as the CNAME record, Cloudflare proceeds with CNAME flattening and ignores the **CNAME Flattening** setting.\n\n## For your zone apex\n\nCNAME flattening occurs by default for all plans when your domain uses a CNAME record for its zone apex (`example.com`, meaning the record **Name** is set to `@`).\n\n## For all CNAME records\n\nFor zones on paid plans, you can choose to flatten all CNAME records. This option is useful for DNS-only (unproxied) CNAME records. [Proxied records](https://developers.cloudflare.com/dns/proxy-status/) are flattened by default as they return Cloudflare anycast IPs.\n\n* Dashboard\n\n  1. In the Cloudflare dashboard, go to the **DNS Settings** page.\n\n     [Go to **Settings**](https://dash.cloudflare.com/?to=/:account/:zone/dns/settings)\n\n  2. Turn on the option **CNAME flattening for all CNAME records**.\n\n* API\n\n  Make a `PATCH` request to the [Update DNS Settings](https://developers.cloudflare.com/api/resources/dns/subresources/settings/subresources/zone/methods/edit/) endpoint and set `flatten_all_cnames` to `true` in the request body.\n\nWarning\n\nIf a CNAME target is being used to verify a domain for a third-party service, turning on [CNAME flattening for all CNAME records](https://developers.cloudflare.com/dns/cname-flattening/set-up-cname-flattening/#for-all-cname-records) may cause the verification to fail since the CNAME record itself will not be returned directly.\n\n## Per record\n\nPaid zones also have the option of flattening specific CNAME records.\n\nIf you use this option, a special [tag](https://developers.cloudflare.com/dns/manage-dns-records/reference/record-attributes/) `cf-flatten-cname` will be added to the respective flattened CNAME records in your zone file, allowing you to [export and import records](https://developers.cloudflare.com/dns/manage-dns-records/how-to/import-and-export/) without losing this configuration.\n\n* Dashboard\n\n  1. On the [**DNS Settings**](https://dash.cloudflare.com/?to=/:account/:zone/dns/settings) page, make sure that **CNAME flattening for all CNAME records** is turned off.\n  2. Go to the [**DNS Records**](https://dash.cloudflare.com/?to=/:account/:zone/dns/records) page and find the CNAME record you would like to flatten.\n  3. Select **Edit** and turn on the **Flatten** option.\n  4. Select **Save** to confirm.\n\n  Unavailable flatten option\n\n  For the following cases, **Flatten** will not be available:\n\n  * The record is at the [zone apex](#for-your-zone-apex).\n  * The record is already proxied, which means it will be flattened by default.\n  * **CNAME flattening for all CNAME records** is turned on, which means you cannot override it per record.\n\n* API\n\n  With the available [API endpoints](https://developers.cloudflare.com/api/resources/dns/subresources/records/methods/create/), specify the following for each CNAME record in the request body:",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Analytics and logs · Cloudflare DNS docs\ndescription: Consider the sections below to learn how to access analytics and\n  logs for your DNS Firewall.\nlastUpdated: 2025-11-17T14:08:01.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/dns-firewall/analytics/\n  md: https://developers.cloudflare.com/dns/dns-firewall/analytics/index.md\n---\n\nConsider the sections below to learn how to access analytics and logs for your DNS Firewall.\n\n## Analytics\n\nDNS Firewall analytics allow you to evaluate data about DNS queries to your account.\n\n### Availability and limits\n\nThe historical data available covers 62 days and the maximum time interval you can get data for is also 62 days.\n\n### Dashboard\n\nFor a quick summary, view your DNS Firewall analytics on the dashboard. The DNS analytics dashboard contains [four main panels](#panels). The filters and time frame that you specify at the top of the page apply to all of them.\n\nIn the Cloudflare dashboard, go to the **DNS Firewall Analytics** page.\n\n[Go to **Analytics**](https://dash.cloudflare.com/?to=/:account/dns-firewall/analytics)\n\n#### Available dimensions\n\n* Query name\n* Query type (same as DNS record type)\n* Cluster\n* Cluster IP\n* Response code\n* Response reason (refer to [descriptions](#response-reasons) below)\n* Response cached (cached or uncached)\n* Response stale (stale or fresh)\n* Data center\n* Source IP\n* Upstream nameserver IP\n* Protocol (UDP or TCP)\n* IP version (IPv4 or IPv6)\n\n#### Panels\n\nThe filters and time frame that you specify at the top of the page apply to all of the available panels.\n\n* **Query summary**: the number of queries and their distribution over time. This information is segmented by each of the [available dimensions](#available-dimensions). You can select the dimensions through the different tabs above the graph and quickly filter for or exclude a certain value from the results by hovering over it and selecting **Filter** or **Exclude**.\n\n* **Query statistics**: an overview of query metrics. Namely, **Total queries**, **Cached queries**, **Uncached queries**, and **Stale cache queries**.\n\n  Processing time and response time\n\n  Processing time refers to the total time taken to handle a query within DNS Firewall, meaning cached queries served directly from Cloudflare's servers. For uncached queries, the metric used is response time, which considers the time to get the answers from your upstream nameservers. The processing and response times are displayed in milliseconds.\n\n  90th percentile (p90)\n\n  Aside from the average for both processing and response times, `p90` values show you the maximum time that 90% of queries took to resolve. For example, if the p90 is 1 millisecond, it means 90% of the queries were resolved in 1 millisecond or less.\n\n* **DNS queries by data center**: a map indicating which Cloudflare data centers have handled DNS queries to your account. You can also find a list of the top ten results and quickly filter for or exclude a certain data center from the results by hovering over it and selecting **Filter** or **Exclude**.\n\n* **Top query statistics**: a breakdown of the top queries grouped by the [available dimensions](#available-dimensions). You can expand each card to list more results and search for specific values.\n\n### GraphQL\n\nUse the [GraphQL API](https://developers.cloudflare.com/analytics/graphql-api/) to access DNS Firewall analytics. Refer to the GraphQL Analytics API documentation for guidance on how to [get started](https://developers.cloudflare.com/analytics/graphql-api/getting-started/).\n\nThe DNS Firewall analytics has two [schemas](https://developers.cloudflare.com/analytics/graphql-api/getting-started/querying-basics/):\n\n* `dnsFirewallAnalyticsAdaptive`: Retrieve information about individual DNS Firewall queries.\n* `dnsFirewallAnalyticsAdaptiveGroups`: Get reports on aggregate information only.\n\n### API Legacy\n\nYou can also use the DNS Firewall API [reports endpoint](https://developers.cloudflare.com/api/resources/dns_firewall/subresources/analytics/subresources/reports/).\n\n***\n\n## Logs\n\nYou can [set up Logpush](https://developers.cloudflare.com/logs/logpush/) to deliver [DNS Firewall logs](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/dns_firewall_logs/) to a storage service, SIEM, or log management provider.\n\n## Response reasons\n\nWhen analyzing why Cloudflare DNS Firewall responded in one way or another to a specific query, consider the `responseReason` log field.\n\nThe following table provides a description for each of the values that might be returned as a response reason:\n\n| Value | Description |\n| - | - |\n| `success` | Response was successfully served, either from Cloudflare cache or forwarded from the upstream. |\n| `upstream_failure` | Response could not be fetched from the upstream due to the upstream failing to respond. |\n| `upstream_servfail` | Response could not be fetched from the upstream due to the upstream responding with `SERVFAIL`. |\n| `invalid_query` | Query is invalid and cannot be processed. |\n| `any_type_blocked` | Query of type `ANY` was blocked according to your [DNS Firewall settings](https://developers.cloudflare.com/dns/dns-firewall/setup/) ([RFC 8482](https://www.rfc-editor.org/rfc/rfc8482.html)). |\n| `rate_limit` | Query was rate limited according to your [DNS Firewall settings](https://developers.cloudflare.com/dns/dns-firewall/setup/). |\n| `chaos_success` | Response for [Chaos class](https://en.wikipedia.org/wiki/Chaosnet) was successfully served. |\n| `attack_mitigation_block` | Query was blocked as part of [random prefix attack mitigation](https://developers.cloudflare.com/dns/dns-firewall/random-prefix-attacks/). |\n| `unknown` | There was an unknown error. |\n\n</page>\n\n<page>\n---\ntitle: FAQs — DNS Firewall · Cloudflare DNS docs\ndescription: Find answers to common questions about Cloudflare's DNS Firewall,\n  including cache behavior, EDNS support, and setting PTR records.\nlastUpdated: 2025-03-06T11:29:38.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/dns-firewall/faq/\n  md: https://developers.cloudflare.com/dns/dns-firewall/faq/index.md\n---\n\nHow does DNS Firewall choose a backend nameserver to query upstream?\n\nDNS Firewall alternates between a customer's nameservers, using an algorithm is more likely to send queries to the faster upstream nameservers than slower nameservers.\n\nHow long does DNS Firewall cache a stale object?\n\nDNS Firewall sets cache longevity according to allocated memory.\n\nAs long as there is enough allocated memory, Cloudflare does not clear items from the cache forcefully, even when the TTL expires. This feature allows Cloudflare to serve stale objects from cache if your nameservers are offline.\n\nDoes the DNS Firewall cache SERVFAIL?\n\nYes. `SERVFAIL` is treated like any other negative answer for caching purposes. The default TTL is 30 seconds. You can use the [API](https://developers.cloudflare.com/api/resources/dns_firewall/methods/edit/) to set a different `negative_cache_ttl`.\n\nDoes DNS Firewall support EDNS Client Subnet (ECS)?\n\nYes. Often, DNS providers want to see a client's IP via EDNS Client Subnet (ECS) ([RFC 7871](https://www.rfc-editor.org/rfc/rfc7871.html)) because they serve geographically specific DNS answers based on the client's IP. With EDNS Client Subnet enabled, the DNS Firewall will forward the client's IP subnet along with the DNS query to the upstream nameserver.\n\nWhen EDNS is enabled, the DNS Firewall gives out the geographically correct answer in cache based on the client IP subnet. To do this, the DNS Firewall segments its cache. For example:\n\n1. A resolver says it is looking for an answer for client `192.0.2.0/24`.\n2. The DNS Firewall will proxy the request to the upstream nameserver for the answer.\n3. The DNS Firewall will cache the answer from the upstream nameserver, but only for that `/24`.\n4. `203.0.113.0/24` now asks the same DNS question and the answer is again returned from the upstream nameserver instead of the cache.\n\nNote\n\nEDNS limits the effectiveness of the DNS cache.\n\nSome resolvers might not be sending any EDNS data. When you set the `ecs_fallback` parameter to `true` via the [API](https://developers.cloudflare.com/api/resources/dns_firewall/methods/edit/), DNS Firewall will forward the IP subnet of the resolver instead only if there is no EDNS data present in incoming the DNS query.\n\nDoes DNS Firewall cache negative answers?\n\nYes. The default TTL is 30 seconds. You can set `negative_cache_ttl` via the [API](https://developers.cloudflare.com/api/resources/dns_firewall/methods/edit/). This will affect the TTL of responses with status `REFUSED`, `NXDOMAIN`, or `SERVFAIL`.\n\nHow can I set PTR records for nameserver hostnames?\n\nTo set up PTR records for the DNS Firewall cluster IPs that point to your nameserver hostnames, use the following API endpoints:\n\n* [Show DNS Firewall Cluster Reverse DNS](https://developers.cloudflare.com/api/resources/dns_firewall/subresources/reverse_dns/methods/get/)\n* [Update DNS Firewall Cluster Reverse DNS](https://developers.cloudflare.com/api/resources/dns_firewall/subresources/reverse_dns/methods/edit/)\n\n</page>\n\n<page>\n---\ntitle: Random prefix attack mitigation · Cloudflare DNS docs\ndescription: Random prefix attacks are when someone sends a lot of traffic to\n  subdomains that are highly unlikely to exist (12345.example.com,\n  abcdefg.example.com), but are still associated with your main domain\n  (example.com).\nlastUpdated: 2025-11-04T11:57:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/dns-firewall/random-prefix-attacks/\n  md: https://developers.cloudflare.com/dns/dns-firewall/random-prefix-attacks/index.md\n---\n\nRandom prefix attacks are when someone sends a lot of traffic to subdomains that are highly unlikely to exist (`12345.example.com`, `abcdefg.example.com`), but are still associated with your main domain (`example.com`).\n\nUsually, a DNS query to each random subdomain (or prefix) is not repeated, so it cannot be cached by resolvers or any other proxies and always reaches the authoritative nameservers. Rate limiting or blocking queries based on source IP can introduce a high amount of false positives, since random prefix attacks commonly are conducted via public resolvers. This makes these attacks particularly effective and hard to mitigate.\n\nAs part of [DNS Firewall](https://developers.cloudflare.com/dns/dns-firewall/), Cloudflare can protect your upstream authoritative nameservers from these attacks by blocking DNS queries that are determined to be part of an attack and thus preventing them from reaching your authoritative nameservers, where they could cause harm by overloading resources. This protection is an opt-in feature because of the potential for false positives.\n\n## Resources\n\n* [Background information](https://developers.cloudflare.com/dns/dns-firewall/random-prefix-attacks/about/)\n* [Setup](https://developers.cloudflare.com/dns/dns-firewall/random-prefix-attacks/setup/)\n\n## Limitations\n\nTo reduce the impact of false positives, Cloudflare does not block entire [public suffixes](https://publicsuffix.org/) (such as `com`). However, it can block domains directly under them (such as `example.com`).\n\nIn addition, the default setting for the automatic mitigation ensures that it will only be deployed if upstream authoritative nameservers are determined to be unresponsive (and likely overloaded by an attack). This means that, as long as your authoritative nameservers can handle the traffic during a random prefix attack, Cloudflare will not actively block queries in order to avoid false positives. This setting is called `\"only_when_upstream_unhealthy\"` and is always true if not explicitly disabled during [Setup](https://developers.cloudflare.com/dns/dns-firewall/random-prefix-attacks/setup/).\n\nBecause Cloudflare does not know which domains and subdomains exist as DNS records on an upstream nameserver, this feature takes a best effort approach by blocking DNS queries to affected subdomains in order to allow upstream nameservers to keep responding to DNS queries to unaffected subdomains.\n\n</page>\n\n<page>\n---\ntitle: Set up DNS Firewall · Cloudflare DNS docs\ndescription: Set up DNS Firewall to protect upstream nameservers from DDoS\n  attacks and reduce load by caching DNS responses.\nlastUpdated: 2025-11-17T14:08:01.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/dns-firewall/setup/\n  md: https://developers.cloudflare.com/dns/dns-firewall/setup/index.md\n---\n\n## Prerequisites\n\nPrior to setting up DNS Firewall, you need:\n\n* Account access to DNS Firewall (provided by your Enterprise account team).\n* Access to **DNS Administrator** or **Super Administrator** privileges on your account.\n* Newly updated IP addresses for your nameservers (protects against previously compromised IP addresses).\n\n## Configure DNS Firewall\n\n### Create a DNS Firewall cluster\n\n* Dashboard\n\n  1. In the Cloudflare dashboard, go to the **DNS Firewall Clusters** page.\n\n     [Go to **Clusters**](https://dash.cloudflare.com/?to=/:account/dns-firewall/clusters)\n\n  2. Select **Add Firewall Cluster**.\n\n  3. Fill out the required fields, including:\n\n     * **IP Addresses**: The upstream IPv4 and/or IPv6 addresses of your authoritative nameservers.\n     * **Minimum Cache TTL**: Recommended setting of **30 seconds**.\n     * **Maximum Cache TTL**: Recommended setting of **4 hours**. Larger values increase the cache hit ratio, but also increase the time required for DNS changes to propagate.\n     * **ANY queries**: Recommended setting is **Off** because these are often used as part of DDoS attacks. Also refer to this [blog post](https://blog.cloudflare.com/rfc8482-saying-goodbye-to-any/).\n\n  4. Click **Continue**.\n\n  5. On the following screen, save the values for **Your new DNS Firewall IP Addresses**.\n\n  Note:\n\n  If you forget to save your new IP addresses, find your cluster and click **IP Addresses**.\n\n  If you delete your cluster, the assigned set of IPs will be lost. If you recreate the cluster you will get a different set of IPs.\n\n* API\n\n  You can also create a DNS Firewall cluster by sending a [POST request](https://developers.cloudflare.com/api/resources/dns_firewall/methods/create/) to the API.\n\n### Update registrar settings\n\nUpdate the `A/AAAA` glue records for your nameserver hostnames at your registrar with your DNS Firewall cluster IP addresses.\n\n### Update DNS servers\n\nAt your DNS servers, update the `A/AAAA` records for your nameserver hostnames in your DNS zone file with your DNS Firewall cluster IP addresses.\n\n### Test DNS resolution\n\nConfirm that your nameservers are functioning correctly by running a `dig` command.\n\n### Update security policies\n\nConfigure security policy in your DNS servers and Firewall to allow only [Cloudflare IPs](https://cloudflare.com/ips) and TCP/UDP port 53.\n\n## Additional options\n\nWhen you use the API, you can also specify other parameters, such as rate limit (in queries per second per data center). You can find the parameters descriptions and examples in the [API documentation](https://developers.cloudflare.com/api/resources/dns_firewall/methods/create/).\n\nTo configure rate limiting and other options for already existing clusters, use the [Update DNS Firewall Cluster](https://developers.cloudflare.com/api/resources/dns_firewall/methods/edit/) endpoint.\n\n</page>\n\n<page>\n---\ntitle: DNSSEC migration tutorial · Cloudflare DNS docs\ndescription: Follow this tutorial to migrate an existing DNS zone to Cloudflare\n  without having to disable DNSSEC.\nlastUpdated: 2025-10-23T07:57:47.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/dnssec/dnssec-active-migration/\n  md: https://developers.cloudflare.com/dns/dnssec/dnssec-active-migration/index.md\n---\n\nFollow this tutorial to migrate an existing DNS zone to Cloudflare without having to disable DNSSEC.\n\nWarning\n\nThis procedure involves cross-importing the [zone signing keys (ZSKs)](https://www.cloudflare.com/learning/dns/dns-records/dnskey-ds-records/) from one provider to the other. To learn more about this, consider this article [about multi-signer DNSSEC](https://developers.cloudflare.com/dns/dnssec/multi-signer-dnssec/about/) or refer to [RFC 8901](https://www.rfc-editor.org/rfc/rfc8901.html).\n\nThis is an advanced procedure and assume some familiarity with [DNS concepts](https://developers.cloudflare.com/dns/concepts/), [API operations](https://developers.cloudflare.com/fundamentals/api/), and basic setup steps. Assumed knowledge that is not detailed in this tutorial can be referenced through the linked content in each of the steps.\n\n## Requirement\n\nThe provider you are migrating from must allow you to add DNSKEY records on the zone apex and use these records in responses to DNS queries.\n\n## 1. Set up Cloudflare\n\n1. [Add your zone to Cloudflare](https://developers.cloudflare.com/fundamentals/manage-domains/add-site/).\n\n   To add your zone using the API, refer to the [Create Zone endpoint](https://developers.cloudflare.com/api/resources/zones/methods/create/).\n\n2. [Review the records found by the automatic scan](https://developers.cloudflare.com/dns/manage-dns-records/how-to/create-dns-records/) or [import your zone file](https://developers.cloudflare.com/dns/manage-dns-records/how-to/import-and-export/).\n\n   To import the zone file using the API, refer to the [Import DNS Records endpoint](https://developers.cloudflare.com/api/resources/dns/subresources/records/methods/import/).\n\n3. On the [**DNS Settings**](https://dash.cloudflare.com/?to=/:account/:zone/dns/settings) page, select **Enable DNSSEC**. Or use the following [API request](https://developers.cloudflare.com/api/resources/dns/subresources/dnssec/methods/edit/).\n\nRequired API token permissions\n\nAt least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n* `DNS Write`",
      "language": "unknown"
    },
    {
      "code": "1. On the [**DNS Settings**](https://dash.cloudflare.com/?to=/:account/:zone/dns/settings) page, enable **Multi-signer DNSSEC**. Or use the following [API request](https://developers.cloudflare.com/api/resources/dns/subresources/dnssec/methods/edit/).\n\nRequired API token permissions\n\nAt least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n* `DNS Write`",
      "language": "unknown"
    },
    {
      "code": "## 2. Cross-import ZSKs\n\n1. Add the [ZSK](https://www.cloudflare.com/learning/dns/dns-records/dnskey-ds-records/) of your previous provider to Cloudflare by creating a DNSKEY record on your zone.\n\nYou can do this [on the dashboard](https://developers.cloudflare.com/dns/manage-dns-records/how-to/create-dns-records/#create-dns-records) or through the [Create DNS Record endpoint](https://developers.cloudflare.com/api/resources/dns/subresources/records/methods/create/), as in the following example.\n\nRequired API token permissions\n\nAt least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n* `DNS Write`",
      "language": "unknown"
    },
    {
      "code": "1. Get Cloudflare's ZSK using either the API or a query from one of the assigned Cloudflare nameservers.\n\nAPI example:",
      "language": "unknown"
    },
    {
      "code": "Command line query example:",
      "language": "unknown"
    },
    {
      "code": "1. Add Cloudflare's ZSK that you fetched in the last step to your previous provider.\n\nNote\n\nYou can check if both providers are responding with both ZSKs by running one `dig` command for each, as in the following example. You can also use [Dig Web Interface](https://www.digwebinterface.com/?type=DNSKEY).",
      "language": "unknown"
    },
    {
      "code": "Both queries should return both ZSKs (identified with tag `256`).\n\nExample",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "## 3. Set up registrar\n\n1. Add Cloudflare DS record to your registrar. You can see your Cloudflare DS record on the [**DNS Settings**](https://dash.cloudflare.com/?to=/:account/:zone/dns/settings) page, under **DS Record**.\n2. Add Cloudflare assigned nameservers to your registrar. You can see your Cloudflare nameservers on the [**DNS Records**](https://dash.cloudflare.com/?to=/:account/:zone/dns/records) page\n\nAt this point your zone is in a [multi-signer DNSSEC setup](https://developers.cloudflare.com/dns/dnssec/multi-signer-dnssec/).\n\n## 4. Remove previous provider\n\n1. Remove your previous provider's DS record from your registrar.\n2. Remove your previous provider's nameservers from your registrar.\n3. After waiting at least one and a half times the [TTL](https://www.cloudflare.com/learning/cdn/glossary/time-to-live-ttl/) of your previous provider DS record, you can remove the DNSKEY record (containing your previous provider ZSK) that you added to your Cloudflare zone in [step 2](#2-cross-import-zsks).\n\nNote\n\nYou can find out the TTL of your previous provider DS record by running a `dig` command, as in the following example, or by using this [Dig Web Interface link](https://www.digwebinterface.com/?type=DS).",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "In this example, both DS records have a TTL of `3600` seconds. Cloudflare's DS record always has the key tag set to `2371`, so the second line of the response is the DS record of the other provider.\n\n</page>\n\n<page>\n---\ntitle: DNSSEC states · Cloudflare DNS docs\ndescription: This page describes different DNSSEC states and how they relate to\n  the responses you get from the DNSSEC details API endpoint.\nlastUpdated: 2025-01-14T14:12:46.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/dnssec/dnssec-states/\n  md: https://developers.cloudflare.com/dns/dnssec/dnssec-states/index.md\n---\n\nThis page describes different DNSSEC states and how they relate to the responses you get from the [DNSSEC details API endpoint](https://developers.cloudflare.com/api/resources/dns/subresources/dnssec/methods/get/).\n\n| State | API response | Description |\n| - | - | - |\n| Pending | `\"status\":\"pending\"` `\"modified_on\":<TIME_STAMP>` | DNSSEC has been enabled but the Cloudflare DS record has not been added at the registrar. |\n| Active | `\"status\":\"active\"` `\"modified_on\":<TIME_STAMP>` | DNSSEC has been enabled and the Cloudflare DS record is present at the registrar. |\n| Pending-disabled | `\"status\":\"pending-disabled\"` `\"modified_on\":<TIME_STAMP>` | DNSSEC has been disabled but the Cloudflare DS record is still added at the registrar. |\n| Disabled | `\"status\":\"disabled\"` `\"modified_on\":<TIME_STAMP>` | DNSSEC has been disabled and the Cloudflare DS record has been removed from the registrar. |\n| Deleted | `\"status\":\"disabled\"` `\"modified_on\": null` | DNSSEC has never been enabled for the zone or DNSSEC has been disabled and then deleted using the [Delete DNSSEC records endpoint](https://developers.cloudflare.com/api/resources/dns/subresources/dnssec/methods/delete/). |\n\nWarning\n\nOnce you have enabled DNSSEC on a zone for the first time, you cannot transition directly from an `active` state to a `deleted` state. You can only [delete DNSSEC records](https://developers.cloudflare.com/api/resources/dns/subresources/dnssec/methods/delete/) once your zone DNSSEC is in a `disabled` state. Cloudflare prevents you from deleting DNSSEC records before removing the DS record from the registrar to avoid DNS resolution issues.\n\nIn both `pending` and `active` states, Cloudflare signs the zone and responds with RRSIG, NSEC, DNSKEY, CDS, and CDNSKEY record types.\n\nIn `pending-disabled` and `disabled` states, Cloudflare still signs the zone and serves RRSIG, NSEC, and DNSKEY record types, but the CDS and CDNSKEY records are set to zero ([RFC 8078](https://www.rfc-editor.org/rfc/rfc8078.html#section-4)), signaling to the registrar that DNSSEC should be disabled.\n\nIn `deleted` state, Cloudflare does **not** sign the zone and does **not** respond with RRSIG, NSEC, DNSKEY, CDS, and CDNSKEY record types.\n\nRefer to [How DNSSEC works](https://www.cloudflare.com/dns/dnssec/how-dnssec-works/) to learn more about the authentication process and records involved.\n\n</page>\n\n<page>\n---\ntitle: NSEC3 support · Cloudflare DNS docs\ndescription: Learn how to enable NSEC3 support with Cloudflare to meet\n  compliance requirements.\nlastUpdated: 2025-11-04T10:04:19.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/dnssec/enable-nsec3/\n  md: https://developers.cloudflare.com/dns/dnssec/enable-nsec3/index.md\n---\n\nAs explained in [our blog](https://blog.cloudflare.com/black-lies/), Cloudflare's implementation of negative answers with NSEC is protected against zone walking[1](#user-content-fn-1). This implementation, also referred to as Compact Denial of Existance ([RFC 9824](https://www.rfc-editor.org/rfc/rfc9824.html)), removes the need for NSEC3 and is significantly more efficient.\n\nHowever, if you must use NSEC3 for compliance reasons, you can enable it as explained below.\n\n## Enable NSEC3\n\nUse the [Edit DNSSEC Status endpoint](https://developers.cloudflare.com/api/resources/dns/subresources/dnssec/methods/edit/), setting `status` to `active` and `dnssec_use_nsec3` to `true`. You should replace the values started by `$` with your zone ID and authentication credentials. To learn more about using the Cloudflare API, refer to [Fundamentals](https://developers.cloudflare.com/fundamentals/api/get-started/).\n\nRequired API token permissions\n\nAt least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n* `DNS Write`",
      "language": "unknown"
    },
    {
      "code": "### Pre-signed DNSSEC\n\nIf you use Cloudflare as a secondary DNS provider with [pre-signed DNSSEC](https://developers.cloudflare.com/dns/zone-setups/zone-transfers/cloudflare-as-secondary/dnssec-for-secondary/), setting `dnssec_use_nsec3` to `true` means that Cloudflare will use NSEC3 records as transferred in from your primary DNS provider.\n\nOtherwise, NSEC3 records will be generated and signed at request time.\n\n## Verify NSEC3 is in use\n\nTo validate that NSEC3 is being used, consider the following scenarios:\n\n### Non-existent zone name\n\nA command like the following would trigger a signed negative response using NSEC3 for proof of non-existence. Look for NSEC3 records under the `Authority Section` of the response.",
      "language": "unknown"
    },
    {
      "code": "### Non-existent record type at an existing name\n\nIf the name `www` exists but the type TXT does not, the example below would trigger a signed NODATA response using NSEC3. Look for NSEC3 records under the `Authority Section` of the response.",
      "language": "unknown"
    },
    {
      "code": "## Availability\n\nNSEC3 is only available for zones on the Enterprise plan.\n\n## Footnotes\n\n1. A method where an attacker exploits NSEC negative answers to obtain all names in a given zone. This is possible when such negative answers provide information on the previous and next names in a chain. [↩](#user-content-fnref-1)\n\n</page>\n\n<page>\n---\ntitle: Troubleshooting DNSSEC · Cloudflare DNS docs\ndescription: Learn how to troubleshoot issues with DNSSEC\nlastUpdated: 2025-08-12T17:54:27.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/dnssec/troubleshooting/\n  md: https://developers.cloudflare.com/dns/dnssec/troubleshooting/index.md\n---\n\nLearn more about how to troubleshoot issues with DNSSEC.\n\n## Test DNSSEC with Dig\n\n`Dig` is a command-line tool to query a nameserver for DNS records.\n\nFor instance, `dig` can ask a DNS resolver for the IP address of `www.cloudflare.com`:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "The option `+short` outputs the result only.\n\nUse `+dnssec` to verify that the DNS records are signed:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "In this example, the last line of output is the `RRSIG` record. `RRSIG` is the DNSSEC signature attached to the record. With the `RRSIG`, a DNS resolver determines whether a DNS response is trusted.\n\n`Dig` can also retrieve the public key used to verify the DNS record, `DNSKEY`:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "A domain's DNS records are all signed with the same public key. Therefore, query for the apex domain (`cloudflare.com`) public key, not the subdomain (`www.cloudflare.com`) public key.\n\nThe DNS response includes two records:\n\n* `DNSKEY` record **256** is the public key called zone signing key (ZSK). ZSKs are used to verify the DNS record signatures for `A`, `MX`, `CNAME`, `SRV`, etc.\n* `DNSKEY` record **257** is called the key signing key (KSK). KSKs are used to verify the signatures of the `DNSKEY`, `CDS`, and `CDNSKEY` records.\n\nNote\n\nDetails on how to verify the signatures with the public key are beyond the scope of this article.\n\nWhen not using the `+short` option with `dig`, a DNS response is DNSSEC authenticated if the `ad` flag appears in the response header:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "***\n\n## Troubleshoot DNSSEC validation using DNSViz\n\nNote\n\nDNSViz is a public, free online tool to visualize and help discover issues with your DNSSEC configuration and is **not** associated Cloudflare.\n\nTo visualize and discover potential issues with DNSSEC:\n\n1. Browse to <http://dnsviz.net/>\n2. Enter a domain name in the text field that appears.\n3. If DNSViz has never analyzed the site before, click the **Analyze** button that appears.\n4. If the site has been analyzed by DNSViz before, click the **Update Now** button that appears.\n\n### Example with missing or incorrect RRSIG record on authoritative nameserver\n\nBelow is an example of how dnsviz.net will display incorrect delegation when no valid DNSKEY records are provided by the authoritative nameserver to match the DS record published by the TLD nameserver:\n\n![Incorrect delegation when no valid DNSKEY records are provided](https://developers.cloudflare.com/_astro/troubleshoot_dnssec-example_no_rrsig.PZ_zKLVg_2bvpzX.webp)\n\n***\n\n## View the DNSSEC chain of trust with Dig\n\nFull verification of domain signatures (for example, `cloudflare.com`) involves verifying the key signing key at the top-level domain (for example, `.com`).\n\nSimilar verification is then performed by checking the key-signing key of `.com` at the root server level. DNSSEC root keys are distributed to DNS clients to complete the chain of trust.\n\nWhen DNSSEC is enabled, a `DS` record is required at the registrar's DNS. The `DS` record contains a hash of the public key signing key as well as metadata about the key.\n\nUse `dig` to find a `DS` record:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "When using the `+trace` option, `dig` confirms whether an answer is returned by the nameserver for `cloudflare.com` or the nameserver for `.com`.  In this example, the `DS` record for `cloudflare.com` is returned by `e.gtld-servers.net`:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "An easier alternative to manually running the steps above is to use the third-party tool [DNSViz](#troubleshoot-dnssec-validation-using-dnsviz).\n\n***\n\n## Troubleshoot DNSSEC validation with Dig\n\nIssues occur if authoritative DNS providers are changed without updating or removing old DNSSEC records at the registrar:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "Confirm whether a `SERVFAIL` response is related to DNSSEC by running `dig` with the `+cd` option. The `+cd` option provides DNS results without any DNSSEC validation in place.",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "In this example, DNSSEC is misconfigured if a proper DNS response is received when using the `+cd` option but queries using DNSSEC return a `SERVFAIL` response. This issue often happens when authoritative nameservers are changed but `DS` records are not updated. The issue can also occur if an attacker attempts to forge a response to a query.\n\n***\n\n## Next steps\n\nIf a problem is discovered with DNSSEC implementation, contact the domain's registrar and confirm the `DS` record matches what the authoritative DNS provider has specified. If Cloudflare is the authoritative DNS provider, follow the instructions for [configuring DNSSEC with Cloudflare](https://developers.cloudflare.com/dns/dnssec/).\n\n</page>\n\n<page>\n---\ntitle: Multi-signer DNSSEC · Cloudflare DNS docs\nlastUpdated: 2024-09-20T08:42:16.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/dns/dnssec/multi-signer-dnssec/\n  md: https://developers.cloudflare.com/dns/dnssec/multi-signer-dnssec/index.md\n---\n\n* [About](https://developers.cloudflare.com/dns/dnssec/multi-signer-dnssec/about/)\n* [Set up multi-signer DNSSEC](https://developers.cloudflare.com/dns/dnssec/multi-signer-dnssec/setup/)\n\n</page>\n\n<page>\n---\ntitle: Advanced nameservers · Cloudflare DNS docs\ndescription: Advanced nameservers included with Foundation DNS offer improved\n  resiliency and more consistent nameserver assignment.\nlastUpdated: 2025-12-29T18:47:37.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/foundation-dns/advanced-nameservers/\n  md: https://developers.cloudflare.com/dns/foundation-dns/advanced-nameservers/index.md\n---\n\nAdvanced nameservers included with [Foundation DNS](https://developers.cloudflare.com/dns/foundation-dns/) offer improved resiliency and more consistent nameserver assignment.\n\nConsider the sections below for details about advanced nameservers, and refer to [Set up advanced nameservers](https://developers.cloudflare.com/dns/foundation-dns/setup/) to learn how to enable this feature.\n\nNote\n\nThe advantages that come with Foundation DNS [advanced nameservers](https://developers.cloudflare.com/dns/foundation-dns/advanced-nameservers/) are currently not available for [custom nameservers](https://developers.cloudflare.com/dns/nameservers/custom-nameservers/). Make sure you only use one at a time.\n\nAlso, [some behaviors are different](https://developers.cloudflare.com/dns/foundation-dns/setup/#differences-from-standard-nameservers) when compared to standard nameservers.\n\n## Anycast network groups\n\nTo increase resiliency, the advertisement of advanced nameserver IPs is organized into three anycast network groups.\n\nTwo groups consist of IPs advertised from geographically distributed data centers, and a third group consists of IPs advertised from all data centers in the Cloudflare network.\n\nUnited Kingdom example\n\n| IPs | Group | Data centers |\n| - | - | - |\n| `108.162.198.1` | A | London and Edinburgh |\n| `172.64.40.1` | B | Manchester |\n| `162.159.60.1` | C | Manchester, London, and Edinburgh |\n\nIn DNS resolution, a resolver eventually acquires a list of all IPs where authoritative nameservers for a domain can be reached, and will then usually prefer the IP with the best resolution performance.\n\nWhen, instead of advertising all IPs in all data centers, this group logic is applied, resiliency is improved because, if one of the data centers experiences a localized issue, the resolver can fall back to an IP advertised by the next closest data center. The third group adds another layer of redundancy, further enhancing resiliency.\n\nRefer to [our blog post](https://blog.cloudflare.com/foundation-dns-launch) for an in-depth explanation of the distributed groups logic.\n\nNote\n\nThe IPs assigned to each nameserver are static, meaning they will not change without notification.\n\n## Dedicated release process\n\nZones using advanced nameservers are less exposed to incidents or software regression.\n\nThe dedicated release process means that only changes that have been in production for a while will reach advanced nameservers.\n\n## Nameservers hosting and assignment\n\nWhile standard Cloudflare nameservers are hosted under `ns.cloudflare.com` or `secondary.cloudflare.com`, advanced nameservers use different domains:\n\n* `foundationdns.com`\n* `foundationdns.net`\n* `foundationdns.org`\n\nUsing the different TLDs (`.com`, `.net`, and `.org`) and making these available only to enterprise accounts allows for better predictability and consistency in nameserver assignment.\n\nThere should also be less conflicts when guaranteeing that directly descending zones do not have the same nameserver set.\n\nDescending zones example\n\nConsider the domain `example.com`, and subdomains `abc.example.com` and `123.example.com`:\n\n* `abc.example.com` and `123.example.com` directly descend from `example.com` and cannot have the same nameservers as `example.com`.\n* `abc.example.com` and `123.example.com` are sibling domains and can have the same nameservers.\n* `new.abc.example.com` directly descends from both `abc.example.com` and `example.com`, and cannot have the same nameservers as them, but can have the same nameservers as `123.example.com`.\n\n</page>\n\n<page>\n---\ntitle: DNSSEC keys · Cloudflare DNS docs\ndescription: With Foundation DNS, you can request that the ZSK/KSK pair that is\n  used for DNSSEC is unique to your Cloudflare account. To opt in to this\n  feature, contact your account team.\nlastUpdated: 2025-08-01T07:41:29.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/foundation-dns/dnssec-keys/\n  md: https://developers.cloudflare.com/dns/foundation-dns/dnssec-keys/index.md\n---\n\nWith [Foundation DNS](https://developers.cloudflare.com/dns/foundation-dns/), you can request that the ZSK/KSK pair that is used for [DNSSEC](https://developers.cloudflare.com/dns/dnssec/) is unique to your Cloudflare account. To opt in to this feature, contact your account team.\n\nAll zones within your Cloudflare account - regardless of using [standard](https://developers.cloudflare.com/dns/nameservers/#standard-nameservers) or [advanced nameservers](https://developers.cloudflare.com/dns/foundation-dns/advanced-nameservers/) - will use the dedicated Zone Signing Key (ZSK) and Key Signing Key (KSK) for DNSSEC. These keys are set at the account level.\n\n## Further reading\n\nFor more background information, refer to [How DNSSEC works](https://www.cloudflare.com/learning/dns/dnssec/how-dnssec-works/).\n\nFor details about DNSSEC settings at Cloudflare, refer to the [DNSSEC documentation](https://developers.cloudflare.com/dns/dnssec/).\n\n</page>\n\n<page>\n---\ntitle: Set up advanced nameservers · Cloudflare DNS docs\ndescription: Advanced nameservers included with Foundation DNS are an opt-in configuration.\nlastUpdated: 2025-10-23T07:57:47.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/foundation-dns/setup/\n  md: https://developers.cloudflare.com/dns/foundation-dns/setup/index.md\n---\n\nAdvanced nameservers included with [Foundation DNS](https://developers.cloudflare.com/dns/foundation-dns/) are an opt-in configuration.\n\nNote\n\nAfter enabling advanced nameservers, standard nameservers still respond to DNS queries.\n\n## Before you begin\n\nBefore opting in for advanced nameservers, consider the following:\n\n* The advantages that come with Foundation DNS [advanced nameservers](https://developers.cloudflare.com/dns/foundation-dns/advanced-nameservers/) are currently not available for [custom nameservers](https://developers.cloudflare.com/dns/nameservers/custom-nameservers/). Make sure you only use one at a time.\n\n### Differences from standard nameservers\n\nSome behaviors are different from standard Cloudflare nameservers:\n\n* Wildcard records are still supported but, with advanced nameservers, a wildcard record (`*.example.com`) will not apply to a subdomain that is an empty non-terminal. An empty non-terminal is a node in the DNS tree that has no records associated with it but has descendants that do, as exemplified below. This behavior is in compliance with [RFC 4592](https://www.rfc-editor.org/rfc/rfc4592.html), which defines the role of empty non-terminals in wildcard resolution.\n\nExample\n\nDNS management for **example.com**\n\n| **Type** | **Name** | **Content** |\n| - | - | - |\n| A | \\* | `192.0.2.1` |\n| A | a.b | `192.0.2.5` |\n\nIn this example, `a.b.example.com` is a descendant of `b.example.com`, and `b.example.com` is an empty non-terminal. This means that the wildcard `*.example.com` will not apply to `b.example.com`.\n\n* Subdomain delegation: once a subdomain is delegated via NS records, Cloudflare will not serve any other records (such as A, TXT, or CNAME) on that subdomain from the parent zone, even if those records exist.\n\nExample\n\nDNS management for **example.com**\n\n| **Type** | **Name** | **Content** |\n| - | - | - |\n| NS | www | ns1.externalhost.com |\n| NS | www | ns2.externalhost.com |\n| TXT | www | \"5bb16e6b5a444eedb48ace40c471bcc9\" |\n| A | www | `192.0.2.1` |\n\nIn this example, the TXT record and the A record for `www.example.com` will not be served.\n\n## Enable on a zone\n\nTo enable advanced nameservers on an existing zone:\n\n1. Opt for advanced nameservers on your zone:\n\n   * Dashboard\n\n     1. In the Cloudflare dashboard, go to the **DNS Records** page.\n\n        [Go to **Records**](https://dash.cloudflare.com/?to=/:account/:zone/dns/records)\n\n     2. In the **Cloudflare nameservers** card, enable **Advanced nameservers**.\n\n     3. After you refresh the page, the card will display the values for your advanced nameservers `NS` records.\n\n   * API\n\n     Use the [Update DNS Settings](https://developers.cloudflare.com/api/resources/dns/subresources/settings/subresources/zone/methods/edit/) endpoint to send a PATCH request like the following:\n\n     Required API token permissions\n\n     At least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n     * `Zone DNS Settings Write`\n     * `DNS Write`",
      "language": "unknown"
    },
    {
      "code": "The response body will contain your assigned namservers in the `nameservers` object. You will use these nameservers in the next step.\n\n2. Update the authoritative nameservers at your registrar. This step depends on whether you are using [Cloudflare Registrar](https://developers.cloudflare.com/registrar/):\n\n   * If you are using Cloudflare Registrar, [contact Cloudflare Support](https://developers.cloudflare.com/support/contacting-cloudflare-support/) to have your nameservers updated.\n\n   * If you are using a different registrar or if your zone is delegated to a parent zone, [manually update your nameservers](https://developers.cloudflare.com/dns/nameservers/update-nameservers/#specific-processes).\n\n     Warning\n\n     Make sure the values for your assigned nameservers are copied exactly.\n\n</page>\n\n<page>\n---\ntitle: Analytics and logs · Cloudflare DNS docs\ndescription: Internal DNS leverages Gateway analytics. Below you can find\n  information about specific fields and different methods you can use to access\n  this data.\nlastUpdated: 2025-07-25T16:42:51.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/internal-dns/analytics/\n  md: https://developers.cloudflare.com/dns/internal-dns/analytics/index.md\n---\n\nInternal DNS leverages [Gateway analytics](https://developers.cloudflare.com/cloudflare-one/insights/analytics/gateway/). Below you can find information about specific fields and different methods you can use to access this data.\n\n## GraphQL\n\nFor detailed metrics, use the [GraphQL API](https://developers.cloudflare.com/analytics/graphql-api/). Refer to the GraphQL Analytics API documentation for guidance on how to [get started](https://developers.cloudflare.com/analytics/graphql-api/getting-started/).\n\nThe [fields](https://developers.cloudflare.com/analytics/graphql-api/getting-started/querying-basics/) added to cover Internal DNS are the following:\n\n* `InternalDNSFallbackStrategy`: The fallback strategy applied to the internal DNS response. Empty if no fallback strategy was applied.\n* `InternalDNSRCode`: The response code sent back by the internal DNS service.\n* `InternalDNSViewID`: The view identifier that was sent to the internal DNS service.\n* `InternalDNSZoneID`: The internal zone identifier returned by the internal DNS service.\n\n## Logs\n\nLeverage Logpush jobs for [Gateway DNS](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/gateway_dns/#internaldnsfallbackstrategy). For help setting up Logpush, refer to [Logpush](https://developers.cloudflare.com/logs/logpush/) documentation.\n\nYou can also set up [Logpush filters](https://developers.cloudflare.com/logs/logpush/logpush-job/filters/) to only push logs related to a specific [internal zone](https://developers.cloudflare.com/dns/internal-dns/internal-zones/) or [view](https://developers.cloudflare.com/dns/internal-dns/dns-views/) ID.\n\n</page>\n\n<page>\n---\ntitle: Connect to Gateway resolver · Cloudflare DNS docs\ndescription: \"To connect to Cloudflare Gateway resolver - which is required to\n  reach private resources in Internal DNS - you can use the following options:\"\nlastUpdated: 2025-11-21T18:29:21.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/internal-dns/connectivity/\n  md: https://developers.cloudflare.com/dns/internal-dns/connectivity/index.md\n---\n\nTo connect to Cloudflare Gateway resolver - which is [required to reach private resources in Internal DNS](https://developers.cloudflare.com/dns/internal-dns/#architecture-overview) - you can use the following options:\n\n* DNS endpoints supported with [DNS locations](https://developers.cloudflare.com/cloudflare-one/networks/resolvers-and-proxies/dns/locations/)\n\n  * DNS over UDP/TCP port 53 (IPv4 or IPv6)\n  * DNS over TLS\n  * DNS over HTTPS\n\n* [Proxy Auto-Configuration (PAC) files](https://developers.cloudflare.com/cloudflare-one/networks/resolvers-and-proxies/proxy-endpoints/)\n\n* [WARP device client](https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/warp/)\n\n* [Clientless browser isolation](https://developers.cloudflare.com/cloudflare-one/remote-browser-isolation/setup/clientless-browser-isolation/#filter-dns-queries)\n\n* [Magic WAN](https://developers.cloudflare.com/magic-wan/zero-trust/cloudflare-gateway/)\n\n</page>\n\n<page>\n---\ntitle: Manage DNS views · Cloudflare DNS docs\ndescription: Internal DNS views are logical groupings of internal DNS zones. As\n  explained in the architecture overview, DNS views are referenced by Gateway\n  resolver policies to define how a specific query should be resolved.\nlastUpdated: 2025-10-22T21:11:06.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/internal-dns/dns-views/\n  md: https://developers.cloudflare.com/dns/internal-dns/dns-views/index.md\n---\n\nInternal DNS views are logical groupings of [internal DNS zones](https://developers.cloudflare.com/dns/internal-dns/internal-zones/). As explained in the [architecture overview](https://developers.cloudflare.com/dns/internal-dns/#architecture-overview), DNS views are referenced by [Gateway resolver policies](https://developers.cloudflare.com/cloudflare-one/traffic-policies/resolver-policies/) to define how a specific query should be resolved.\n\nRefer to the sections below for details on how to manage your DNS views, or consider the [get started](https://developers.cloudflare.com/dns/internal-dns/get-started/) for a complete workflow.\n\n## Configuration conditions\n\nWhen setting up DNS views, observe the following conditions:\n\n* DNS views can be empty, with no [internal zones](https://developers.cloudflare.com/dns/internal-dns/internal-zones/) linked to them.\n* A DNS view cannot contain public DNS zones [1](#user-content-fn-1).\n* Each internal DNS zone name must be unique within a given DNS view.\n* Each DNS view name must be unique within a given Cloudflare account.\n\n## Footnotes\n\n1. DNS zones that contain public DNS records and are accessible by public resolvers. [↩](#user-content-fnref-1)\n\n## Create a view\n\n* Dashboard\n\n  1. In the Cloudflare dashboard, go to the **Internal DNS** page.\n\n     [Go to **Internal DNS**](https://dash.cloudflare.com/?to=/:account/internal-dns)\n\n  2. Go to **Internal DNS Views**.\n\n  3. Select **Create a view**.\n\n  4. Give your view a descriptive name.\n\n  1) Select **Manage zones** to add zones to your view. Select the internal zones that should be used to resolve queries sent by Gateway resolver to this view.\n  2) Choose **Save** to confirm.\n\n* API\n\n  Use the [Create Internal DNS View](https://developers.cloudflare.com/api/resources/dns/subresources/settings/subresources/account/subresources/views/methods/create/) endpoint. For each view you create, list all the internal zones that should be grouped under that view.\n\n## Delete a view\n\nDNS views can be deleted even if they still have internal zones linked to them. The internal DNS zones will continue to exist but will be unlinked once the view is deleted.\n\nIt is also possible to delete a DNS view that is being referenced by a Gateway resolver policy. In this case, queries matching the policy will return SERVFAIL.\n\n* Dashboard\n\n  1. In the Cloudflare dashboard, go to the **Internal DNS** page.\n\n     [Go to **Internal DNS**](https://dash.cloudflare.com/?to=/:account/internal-dns)\n\n  2. Go to **Internal DNS Views**.\n\n  3. Find the view you want to delete.\n\n  4. Select the three dots in the corresponding row and choose *Delete*.\n\n  5. In the confirmation dialog, select **Delete** again to proceed.\n\n* API\n\n  Use the [Delete Internal DNS View](https://developers.cloudflare.com/api/resources/dns/subresources/settings/subresources/account/subresources/views/methods/delete/) endpoint.\n\n## Other API actions\n\n* [Update a DNS view](https://developers.cloudflare.com/api/resources/dns/subresources/settings/subresources/account/subresources/views/methods/edit/) (`PATCH`)\n* [Get view details](https://developers.cloudflare.com/api/resources/dns/subresources/settings/subresources/account/subresources/views/methods/get/) (`GET`)\n* [List DNS views](https://developers.cloudflare.com/api/resources/dns/subresources/settings/subresources/account/subresources/views/methods/list/) (`GET`)\n\n</page>\n\n<page>\n---\ntitle: Get started · Cloudflare DNS docs\ndescription: Follow this guide to get started with Internal DNS.\nlastUpdated: 2025-11-20T23:13:05.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/internal-dns/get-started/\n  md: https://developers.cloudflare.com/dns/internal-dns/get-started/index.md\n---\n\nFollow this guide to get started with Internal DNS.\n\nNote\n\nInternal DNS is currently in closed beta. Using it on production traffic is at your own risk. If you are interested in this product, contact your account team.\n\n## Before you begin\n\n* Make sure you have an Enterprise account with access to [Gateway resolver policies](https://developers.cloudflare.com/cloudflare-one/traffic-policies/resolver-policies/) and [Internal DNS](https://developers.cloudflare.com/dns/internal-dns/).\n\n* Consider the different ways in which you can [connect to Gateway resolver](https://developers.cloudflare.com/dns/internal-dns/connectivity/).\n\n  Warning\n\n  If using WARP, make sure your internal DNS zones or their TLDs are not listed in your [Local Domain Fallback configuration](https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/warp/configure-warp/route-traffic/local-domains/). Otherwise, DNS queries for a matching domain will be sent to the local DNS server specified in the fallback, instead of being sent to Cloudflare.\n\n* If you will be using an API token for authentication, make sure you have the following permissions:\n\nAPI token configuration\n\n**Permissions**\n\n* *Account* - *DNS Views* - *Edit*\n* *Zone* - *DNS* - *Edit*\n* *Account* - *Account Settings* - *Edit*\n* *Zone* - *DNS Settings* - *Edit*\n* *Zone* - *Zone* - *Edit*\n\n**Account Resources**\n\n* *Include* - *(Your account)*\n\n**Zone Resources**\n\n* *Include* - *All zones*\n\n## 1. Set up your internal DNS zone\n\n* Dashboard\n\n  1. In the Cloudflare dashboard, go to the **Internal DNS** page.\n\n     [Go to **Internal DNS**](https://dash.cloudflare.com/?to=/:account/internal-dns)\n\n  2. Select **Create an internal zone**.\n\n  3. Give your internal zone a name.\n\n  Internal zone configuration conditions\n\n  * Internal zones can contain the same [DNS record types](https://developers.cloudflare.com/dns/manage-dns-records/reference/dns-record-types/) that Cloudflare supports for public zones.\n  * An internal zone can have the same name as a public zone in the same account.\n  * Each internal zone can be linked to multiple [views](https://developers.cloudflare.com/dns/internal-dns/dns-views/)[1](#user-content-fn-20).\n  * There can be several internal zones with the same name in one account. However, two internal zones with the same name cannot be linked to the same view.\n  * Internal zones are not subject to any top-level domain (TLD) restrictions. This means that an internal zone can be created if its TLD is not registered publicly (for example, `xyz.local`), if it is created on the TLD itself (`local`), or even if on the root (`.`).\n\n  ## Footnotes\n\n  1. Logical groupings of internal DNS zones that are referenced by Gateway resolver policies to define how a specific query should be resolved. [↩](#user-content-fnref-20)\n\n  1) Add DNS records to your internal zone using your preferred option:\n\n  * [Import](https://developers.cloudflare.com/dns/manage-dns-records/how-to/import-and-export/) a formatted BIND file.\n  * Select **Add a record** and choose **Create** under the record type you want to add. Refer to [DNS record types](https://developers.cloudflare.com/dns/manage-dns-records/reference/dns-record-types/) for details.\n\n  1. Repeat this process for each internal zone you wish to add.\n\n  Note\n\n  Creating multiple internal DNS records in batch is currently only supported via API.\n\n* API\n\n  1. Use the [Create Zone](https://developers.cloudflare.com/api/resources/zones/methods/create/) endpoint to create an [internal zone](https://developers.cloudflare.com/dns/internal-dns/internal-zones/). Specify your account ID and set the `type` to `internal`.\n\n  Internal zone configuration conditions\n\n  * Internal zones can contain the same [DNS record types](https://developers.cloudflare.com/dns/manage-dns-records/reference/dns-record-types/) that Cloudflare supports for public zones.\n  * An internal zone can have the same name as a public zone in the same account.\n  * Each internal zone can be linked to multiple [views](https://developers.cloudflare.com/dns/internal-dns/dns-views/)[1](#user-content-fn-20).\n  * There can be several internal zones with the same name in one account. However, two internal zones with the same name cannot be linked to the same view.\n  * Internal zones are not subject to any top-level domain (TLD) restrictions. This means that an internal zone can be created if its TLD is not registered publicly (for example, `xyz.local`), if it is created on the TLD itself (`local`), or even if on the root (`.`).\n\n  ## Footnotes\n\n  1. Logical groupings of internal DNS zones that are referenced by Gateway resolver policies to define how a specific query should be resolved. [↩](#user-content-fnref-20)\n\n  Example\n\n  Required API token permissions\n\n  At least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n  * `Zone Zone Edit`\n  * `Zone DNS Edit`",
      "language": "unknown"
    },
    {
      "code": "1. Add DNS records to your internal zone using your preferred option:\n\n  * [Import](https://developers.cloudflare.com/api/resources/dns/subresources/records/methods/import/) a formatted BIND file. Refer to the [DNS records how-to](https://developers.cloudflare.com/dns/manage-dns-records/how-to/import-and-export/) for guidance.\n  * Use other API endpoints, such as [`/batch`](https://developers.cloudflare.com/api/resources/dns/subresources/records/methods/batch/), to manage DNS records. Refer to [Batch record changes](https://developers.cloudflare.com/dns/manage-dns-records/how-to/batch-record-changes/#use-the-api) for details.\n\n  1. Repeat this process for each internal zone you wish to add.\n\n### (Optional) Reference a zone from another zone\n\nDuring an [internal DNS query resolution](https://developers.cloudflare.com/dns/internal-dns/#architecture-overview), if no internal record is found within a matching internal zone, Cloudflare will check if the matching internal zone is referencing another internal zone. Successive references can be followed with a maximum of five references in a chain.\n\nFor details, refer to [reference zones](https://developers.cloudflare.com/dns/internal-dns/internal-zones/reference-zones/).\n\n* Dashboard\n\n  1. In the Cloudflare dashboard, go to the **Internal DNS** page.\n\n     [Go to **Internal DNS**](https://dash.cloudflare.com/?to=/:account/internal-dns)\n\n  2. Select a zone.\n\n  3. Within the selected zone, go to **Reference zone**.\n\n  4. Select **Add reference zone**.\n\n  5. Find the zone you want to use as reference and choose **Select** in the respective row.\n\n* API\n\n  1. Use the [Update DNS settings](https://developers.cloudflare.com/api/resources/dns/subresources/settings/subresources/zone/methods/edit/) endpoint to add a reference from an internal zone to another internal zone. In `--json`, specify the `internal_dns` object with the parameter `reference_zone_id`.\n\n  In the following example, internal zone A (ID `8a904aeb565c42cfa207d98f6edea2f3`) is referencing internal zone B (ID `8e64c6fb4b514f3faf64de81efc11e51`).\n\n  Required API token permissions\n\n  At least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n  * `Zone DNS Settings Write`\n  * `DNS Write`",
      "language": "unknown"
    },
    {
      "code": "## 2. Link your internal zone to a view\n\nSince the resolver policy will require a [DNS view](https://developers.cloudflare.com/dns/internal-dns/dns-views/), you must have at least one view to be able to route requests to internal zones.\n\n* Dashboard\n\n  1. In the Cloudflare dashboard, go to the **Internal DNS** page.\n\n     [Go to **Internal DNS**](https://dash.cloudflare.com/?to=/:account/internal-dns)\n\n  2. Go to **Internal DNS Views**.\n\n  3. Select **Create a view**.\n\n  4. Give your view a descriptive name.\n\n  DNS view configuration conditions\n\n  * DNS views can be empty, with no [internal zones](https://developers.cloudflare.com/dns/internal-dns/internal-zones/) linked to them.\n  * A DNS view cannot contain public DNS zones [1](#user-content-fn-1).\n  * Each internal DNS zone name must be unique within a given DNS view.\n  * Each DNS view name must be unique within a given Cloudflare account.\n\n  ## Footnotes\n\n  1. DNS zones that contain public DNS records and are accessible by public resolvers. [↩](#user-content-fnref-1)\n\n  1) Select **Manage zones** to add zones to your view. Select the internal zones that should be used to resolve queries sent by Gateway resolver to this view.\n  2) Choose **Save** to confirm.\n\n* API\n\n  1. Use the [Create Internal DNS View](https://developers.cloudflare.com/api/resources/dns/subresources/settings/subresources/account/subresources/views/methods/create/) endpoint. For each view you create, list all the internal zones that should be grouped under that view.\n\n  DNS view configuration conditions\n\n  * DNS views can be empty, with no [internal zones](https://developers.cloudflare.com/dns/internal-dns/internal-zones/) linked to them.\n  * A DNS view cannot contain public DNS zones [1](#user-content-fn-1).\n  * Each internal DNS zone name must be unique within a given DNS view.\n  * Each DNS view name must be unique within a given Cloudflare account.\n\n  ## Footnotes\n\n  1. DNS zones that contain public DNS records and are accessible by public resolvers. [↩](#user-content-fnref-1)\n\n## 3. Configure Gateway policies\n\nNote\n\nThe Gateway configuration must exist within the same Cloudflare account where the internal zone exists.\n\nBesides selecting an internal DNS view when setting up your resolver policies, you can also enable the **fallback through public DNS** option.\n\n* Dashboard\n\n  1. In [Cloudflare One](https://one.dash.cloudflare.com/), go to **Traffic policies** > **Firewall policies** > **Resolver policies**.\n  2. Select **Add a policy** and enter a name and description.\n  3. Create an expression for the traffic you wish to route. For guidance about selectors, operators, and values, refer to [Gateway resolver policies](https://developers.cloudflare.com/cloudflare-one/traffic-policies/resolver-policies/#selectors).\n  4. Select **Use Internal DNS**. Choose the view that queries matching the expression should be sent to.\n  5. (Optional) Adjust the option to **Fallback through public DNS** according to your use case.\n\n  * Off: Gateway DNS resolver returns the response as-is to the client.\n  * On: In case the response from the internal zone is REFUSED, NXDOMAIN, or a response with a CNAME type, Gateway DNS resolver sends the query to Cloudflare 1.1.1.1 public resolver and tries to resolve the query via public DNS.\n\n  1. Select **Create policy** to confirm.\n\n* API\n\n  Use the API endpoints under [Zero Trust > Gateway > Rules](https://developers.cloudflare.com/api/resources/zero_trust/subresources/gateway/subresources/rules/) to set up resolver policies. For guidance about selectors, operators, and values, refer to [Gateway](https://developers.cloudflare.com/cloudflare-one/traffic-policies/resolver-policies/#selectors).\n\n  Use the rule settings object to define `resolve_dns_internally`, specifying `view_id` and `fallback` option. The fallback options behave as follows:\n\n  * `none`: Gateway DNS resolver returns the response as-is to the client.\n  * `public_dns`: In case the response from the internal zone is REFUSED, NXDOMAIN, or a response with a CNAME type, Gateway DNS resolver sends the query to Cloudflare 1.1.1.1 public resolver and tries to resolve the query via public DNS.\n\nOnce you add the Gateway resolver policy, it will be listed in the respective internal view under **Resolver policies referencing this view**.\n\n</page>\n\n<page>\n---\ntitle: Internal zones · Cloudflare DNS docs\ndescription: Explore internal DNS zones in Cloudflare. These zones organize DNS\n  records for resources accessible only within your private network, queried via\n  Cloudflare Gateway.\nlastUpdated: 2025-10-22T21:11:06.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/internal-dns/internal-zones/\n  md: https://developers.cloudflare.com/dns/internal-dns/internal-zones/index.md\n---\n\nInternal DNS zones are groupings of internal DNS records. While [public DNS records](https://developers.cloudflare.com/dns/manage-dns-records/) contain information about resources that you want to make available to the public Internet, [internal DNS records](https://developers.cloudflare.com/dns/internal-dns/internal-zones/internal-dns-records/) allow you to manage resources that should only be available within your private network.\n\nRefer to [Manage internal zones](https://developers.cloudflare.com/dns/internal-dns/internal-zones/setup/) for a full list of configuration conditions and step-by-step instructions.\n\nInternal DNS zones do not get assigned Cloudflare nameservers and can only be queried via [Cloudflare Gateway](https://developers.cloudflare.com/cloudflare-one/traffic-policies/resolver-policies/) when linked to a [DNS view](https://developers.cloudflare.com/dns/internal-dns/dns-views/). The Gateway configuration must exist within the same Cloudflare account where the internal zone exists.\n\n## Resources\n\n* [Manage internal zones](https://developers.cloudflare.com/dns/internal-dns/internal-zones/setup/)\n* [Manage internal DNS records](https://developers.cloudflare.com/dns/internal-dns/internal-zones/internal-dns-records/)\n* [Reference zones](https://developers.cloudflare.com/dns/internal-dns/internal-zones/reference-zones/)\n\n</page>\n\n<page>\n---\ntitle: DNS records - How to · Cloudflare DNS docs\ndescription: Learn how to use Cloudflare DNS to manage your DNS records.\nlastUpdated: 2024-09-20T08:42:16.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/dns/manage-dns-records/how-to/\n  md: https://developers.cloudflare.com/dns/manage-dns-records/how-to/index.md\n---\n\nRefer to the following resources for more information about creating and maintaining DNS records:\n\n* [Manage DNS records](https://developers.cloudflare.com/dns/manage-dns-records/how-to/create-dns-records/)\n* [Create zone apex record](https://developers.cloudflare.com/dns/manage-dns-records/how-to/create-zone-apex/)\n* [Create subdomain records](https://developers.cloudflare.com/dns/manage-dns-records/how-to/create-subdomain/)\n* [Set up email records](https://developers.cloudflare.com/dns/manage-dns-records/how-to/email-records/)\n* [Import and export records](https://developers.cloudflare.com/dns/manage-dns-records/how-to/import-and-export/)\n* [Batch record changes](https://developers.cloudflare.com/dns/manage-dns-records/how-to/batch-record-changes/)\n* [Dynamically update DNS records](https://developers.cloudflare.com/dns/manage-dns-records/how-to/managing-dynamic-ip-addresses/)\n* [Round-robin DNS](https://developers.cloudflare.com/dns/manage-dns-records/how-to/round-robin-dns/)\n* [Delegate subdomains](https://developers.cloudflare.com/dns/manage-dns-records/how-to/subdomains-outside-cloudflare/)\n\n</page>\n\n<page>\n---\ntitle: Reference — DNS records · Cloudflare DNS docs\ndescription: Check information about record types, status and additional options.\nlastUpdated: 2024-09-20T08:42:16.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/dns/manage-dns-records/reference/\n  md: https://developers.cloudflare.com/dns/manage-dns-records/reference/index.md\n---\n\n* [DNS record types](https://developers.cloudflare.com/dns/manage-dns-records/reference/dns-record-types/)\n* [Time to Live (TTL)](https://developers.cloudflare.com/dns/manage-dns-records/reference/ttl/)\n* [Record attributes](https://developers.cloudflare.com/dns/manage-dns-records/reference/record-attributes/)\n* [Vendor-specific DNS records](https://developers.cloudflare.com/dns/manage-dns-records/reference/vendor-specific-records/)\n* [Wildcard DNS records](https://developers.cloudflare.com/dns/manage-dns-records/reference/wildcard-dns-records/)\n\n</page>\n\n<page>\n---\ntitle: Troubleshooting — DNS records · Cloudflare DNS docs\nlastUpdated: 2024-09-20T08:42:16.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/dns/manage-dns-records/troubleshooting/\n  md: https://developers.cloudflare.com/dns/manage-dns-records/troubleshooting/index.md\n---\n\n* [Records with the same name](https://developers.cloudflare.com/dns/manage-dns-records/troubleshooting/records-with-same-name/)\n* [Unexpected \\_acme-challenge TXT records](https://developers.cloudflare.com/dns/manage-dns-records/troubleshooting/acme-challenge-txt-record/)\n* [Exposed IP addresses](https://developers.cloudflare.com/dns/manage-dns-records/troubleshooting/exposed-ip-address/)\n* [Verify a domain with CNAME](https://developers.cloudflare.com/dns/manage-dns-records/troubleshooting/cname-domain-verification/)\n* [NS records already exist](https://developers.cloudflare.com/dns/manage-dns-records/troubleshooting/existing-ns-record/)\n* [Stale response for upstream DNS resolution](https://developers.cloudflare.com/dns/manage-dns-records/troubleshooting/stale-response/)\n\n- [Delete all DNS records](https://developers.cloudflare.com/dns/zone-setups/troubleshooting/delete-all-records/)\n\n</page>\n\n<page>\n---\ntitle: Advanced nameservers · Cloudflare DNS docs\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/nameservers/advanced-nameservers/\n  md: https://developers.cloudflare.com/dns/nameservers/advanced-nameservers/index.md\n---\n\n\n</page>\n\n<page>\n---\ntitle: Custom nameservers · Cloudflare DNS docs\ndescription: With custom (or vanity) nameservers, a domain can use Cloudflare\n  DNS without using Cloudflare-branded nameservers. For instance, you can\n  configure ns1.example.com and ns2.example.com as nameservers for example.com.\nlastUpdated: 2025-12-29T18:48:32.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/nameservers/custom-nameservers/\n  md: https://developers.cloudflare.com/dns/nameservers/custom-nameservers/index.md\n---\n\nWith custom (or vanity) nameservers, a domain can use Cloudflare DNS without using Cloudflare-branded nameservers. For instance, you can configure `ns1.example.com` and `ns2.example.com` as nameservers for `example.com`.\n\nTo use custom nameservers, a zone must be using Cloudflare as [Primary (Full setup)](https://developers.cloudflare.com/dns/zone-setups/full-setup/) or [Secondary](https://developers.cloudflare.com/dns/zone-setups/zone-transfers/cloudflare-as-secondary/) DNS provider.\n\n## Configuration scope\n\n* [Set up zone custom nameservers](https://developers.cloudflare.com/dns/nameservers/custom-nameservers/zone-custom-nameservers/)\n* [Set up account custom nameservers](https://developers.cloudflare.com/dns/nameservers/custom-nameservers/account-custom-nameservers/)\n* [Set up tenant custom nameservers](https://developers.cloudflare.com/dns/nameservers/custom-nameservers/tenant-custom-nameservers/)\n\n## Availability\n\n* Zone custom nameservers are available for zones on Business or Enterprise plans. Via API or on the dashboard.\n* Account custom nameservers are available for customers on Business (after [contacting Cloudflare Support](https://developers.cloudflare.com/support/contacting-cloudflare-support/)) or Enterprise plans. Once configured, account custom nameservers can be used by all zones in the account, regardless of the zone plan. Via API or on the dashboard.\n* Tenant custom nameservers, if created by the tenant owner, will be available to all zones belonging to any account that is part of the tenant. Via API only.\n\n## Restrictions\n\nCustom nameservers are organized in different sets (`ns_set`). Each namesever set must have at least two and no more than five custom nameserver names.\n\nThe advantages that come with Foundation DNS [advanced nameservers](https://developers.cloudflare.com/dns/foundation-dns/advanced-nameservers/) are currently not available for [custom nameservers](https://developers.cloudflare.com/dns/nameservers/custom-nameservers/). Make sure you only use one at a time.\n\n</page>\n\n<page>\n---\ntitle: Nameserver options · Cloudflare DNS docs\ndescription: Refer to the sections below to learn about different nameserver options.\nlastUpdated: 2025-12-29T18:48:32.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/nameservers/nameserver-options/\n  md: https://developers.cloudflare.com/dns/nameservers/nameserver-options/index.md\n---\n\nRefer to the sections below to learn about different nameserver options.\n\n## Assignment method\n\nWhen you add a domain on a [primary (full)](https://developers.cloudflare.com/dns/zone-setups/full-setup/) or [secondary](https://developers.cloudflare.com/dns/zone-setups/zone-transfers/cloudflare-as-secondary/) DNS setup, Cloudflare automatically assigns your nameservers.\n\nThe default assignment method is to use [standard nameservers](https://developers.cloudflare.com/dns/nameservers/#standard-nameservers) and favor consistent nameserver names across all zones within an account. Nonetheless, in case there are conflicts, you may get different nameserver names, even for domains that are within the same account.\n\nWarning\n\nTo prevent domain hijacking, you can no longer preset Cloudflare nameservers at your registrar before creating the respective zone in Cloudflare. If you preset your nameservers and then add the domain, your domain will be assigned a new pair of nameservers.\n\nThese nameserver assignments cannot be changed. However, depending on your subscription, you may have different options for better nameserver consistency.\n\n### Nameserver consistency\n\nThe level of consistency you can expect when adding new zones depends on the configured nameserver type.\n\n* For [standard nameservers](https://developers.cloudflare.com/dns/nameservers/#standard-nameservers), since a conflict can be caused by anyone adding the same zone to any other Cloudflare account, the likelihood of your new zone being assigned different nameserver names than your previously existing zones is higher.\n\n* If you use [account custom nameservers](https://developers.cloudflare.com/dns/nameservers/custom-nameservers/account-custom-nameservers/), the only conflict would be between a parent and a child zone, which makes consistent assignment across new zones more likely.\n\n* With [tenant custom nameservers](https://developers.cloudflare.com/dns/nameservers/custom-nameservers/tenant-custom-nameservers/) or [Foundation DNS advanced nameservers](https://developers.cloudflare.com/dns/foundation-dns/advanced-nameservers/#nameservers-hosting-and-assignment), there can still be conflicts caused by two zones with the same name being added to different accounts, but, since access to these features is more restricted, the likelihood of your new zone being assigned different nameserver names than your previously existing zones is lower.\n\n### DNS zone defaults\n\nIf you have an Enterprise account, you also have the option to [configure your own DNS zone defaults](https://developers.cloudflare.com/dns/additional-options/dns-zone-defaults/) and change how Cloudflare handles nameserver assignment when you add a new zone to your account:\n\n* **Standard nameservers randomized**: instead of attempting consistency, Cloudflare assigns random pairs of nameserver names every time you add a new domain to your account.\n* **Advanced nameservers**: Cloudflare uses the same method as the default - trying to keep nameserver names consistent for different zones within an account - but uses the specific [Foundation DNS nameservers](https://developers.cloudflare.com/dns/foundation-dns/advanced-nameservers/).\n* **Account custom nameservers**: Cloudflare automatically assigns a set of [account custom nameservers](https://developers.cloudflare.com/dns/nameservers/custom-nameservers/account-custom-nameservers/) that you have previously configured for your account. In this method, **Set 1** will be attempted first and, in case of any conflicts, Cloudflare will cycle through the other nameserver sets, in ascending order.\n\nWarning\n\nDNS zone defaults are only applied at the moment a new zone is created and will not impact already existing zones, nor zones that existed previously and are being revived.\n\nAny of the values specified as default can later be adjusted within each zone, on the respective [**DNS Settings**](https://dash.cloudflare.com/?to=/:account/:zone/dns/settings) or [**DNS Records**](https://dash.cloudflare.com/?to=/:account/:zone/dns/records) page.\n\n## Multi-provider DNS\n\nMulti-provider DNS is an optional setting for zones using [full setup](https://developers.cloudflare.com/dns/zone-setups/full-setup/) and is an enforced default behavior for zones using [secondary setup](https://developers.cloudflare.com/dns/zone-setups/zone-transfers/cloudflare-as-secondary/).\n\nWhen you enable multi-provider DNS on a primary (full setup) zone:\n\n* Cloudflare will no longer ignore `NS` records created on the zone apex, as in the example below.\n\n  | Type | Name | Nameserver |\n  | - | - | - |\n  | `NS` | `@` | `ns1.external.com` |\n\nThis means that responses to DNS queries made to the zone apex and requesting `NS` records will contain both Cloudflare's and your other DNS providers' nameservers.\n\n* Cloudflare will activate a primary (full setup) zone even if its [nameservers listed at the registrar](https://developers.cloudflare.com/dns/nameservers/update-nameservers/) include nameservers from other DNS providers.\n\nWarning\n\nIf you choose this option and you also want to use DNSSEC on your zone, make sure to set up [multi-signer DNSSEC](https://developers.cloudflare.com/dns/dnssec/multi-signer-dnssec/).\n\n## Nameserver TTL\n\nFor both Cloudflare nameservers (standard or advanced) and custom nameservers, the `NS` record time-to-live (TTL) is controlled by the specific setting on the **DNS Records** page, under **DNS record options**.\n\nFoundation DNS\n\n**DNS record options** are part of [Foundation DNS](https://developers.cloudflare.com/dns/foundation-dns/). If you are an Enterprise customer and **Nameserver TTL** is not displayed on your Cloudflare dashboard, reach out to your account team.\n\nThe default TTL is 24 hours (or 86,400 seconds), but you have the option to lower this value depending on your needs. For example, shorter TTLs can be useful when you are changing nameservers or migrating a zone. Accepted values range from 30 to 86,400 seconds.\n\nThis setting can also be configured as a [DNS zone default](https://developers.cloudflare.com/dns/additional-options/dns-zone-defaults/), meaning new zones created in your account will automatically start with the value you define.\n\n</page>\n\n<page>\n---\ntitle: Update nameservers · Cloudflare DNS docs\ndescription: To use Cloudflare DNS as an authoritative DNS provider - be it in a\n  primary (full) or secondary setup -, your domain nameservers must point to\n  nameservers that you get from your Cloudflare account. Updating your\n  nameservers is required to activate your domain on Cloudflare and use most of\n  our application services.\nlastUpdated: 2025-09-12T15:58:54.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/nameservers/update-nameservers/\n  md: https://developers.cloudflare.com/dns/nameservers/update-nameservers/index.md\n---\n\nTo use Cloudflare DNS as an authoritative DNS provider - be it in a [primary (full)](https://developers.cloudflare.com/dns/zone-setups/full-setup/) or [secondary](https://developers.cloudflare.com/dns/zone-setups/zone-transfers/cloudflare-as-secondary/) setup -, your domain nameservers must point to nameservers that you get from your Cloudflare account. Updating your nameservers is required to activate your domain on Cloudflare and use most of our [application services](https://developers.cloudflare.com/fundamentals/concepts/how-cloudflare-works/).\n\n## Specific processes\n\nAlthough Cloudflare will [provide you the nameservers](https://developers.cloudflare.com/dns/nameservers/#authoritative-nameservers-offering) or allow you to create your own [custom nameservers](https://developers.cloudflare.com/dns/nameservers/custom-nameservers/), the final step to make Cloudflare an authoritative DNS provider for your domain may have to be done outside of Cloudflare. If you are not using [Cloudflare Registrar](https://developers.cloudflare.com/registrar/), consider which of the following sections correspond to your use case.\n\nCustom or advanced nameservers\n\nIf you are using Cloudflare Registrar with [custom nameservers](https://developers.cloudflare.com/dns/nameservers/custom-nameservers/) or [advanced nameservers](https://developers.cloudflare.com/dns/foundation-dns/setup/), note that you must [reach out to support](https://developers.cloudflare.com/support/contacting-cloudflare-support/) to have the nameservers updated accordingly.\n\n### Your domain uses a different registrar\n\nIf you have acquired your domain from a [registrar](https://www.cloudflare.com/learning/dns/glossary/what-is-a-domain-name-registrar/) other than Cloudflare Registrar - and it has not been [delegated to another zone](#your-domain-is-delegated-to-another-zone) - you need to update your nameservers at your registrar.\n\nProvider-specific instructions\n\nThis is not an exhaustive list of provider-specific instructions, but the following links may be helpful:\n\n* [Ionos](https://www.ionos.com/help/domains/using-your-own-name-servers/using-your-own-name-servers-for-a-domain/)\n* [101Domain](https://help.101domain.com/kb/managing-name-server-records)\n* [Amazon](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/domain-name-servers-glue-records.html#domain-name-servers-glue-records-adding-changing)\n* [Blacknight](https://help.blacknight.com/hc/en-us/articles/212512229-Changing-nameservers-in-cp-blacknight-com)\n* [BlueHost](https://www.bluehost.com/help/article/custom-nameservers)\n* [DirectNIC](https://directnic.com/knowledge/article/33:how%2Bdo%2Bi%2Bmodify%2Bname%2Bservers%2Bfor%2Bmy%2Bdomain%2Bname%253F)\n* [DNSMadeEasy](http://www.dnsmadeeasy.com/support/faq/)\n* [Domain.com](https://www.domain.com/help/article/domain-management-how-to-update-nameservers)\n* [Dotster](https://www.dotster.com/help/article/domain-management-how-to-update-nameservers)\n* [DreamHost](https://help.dreamhost.com/hc/en-us/articles/360038897151)\n* [EasyDNS](https://kb.easydns.com/knowledge/settingchanging-nameservers/)\n* [Enom](https://help.enom.com/hc/en-us/articles/115000486451-Nameservers-NS)\n* [Fast Domain](https://www.fastdomain.com/hosting/help/transfer_client_start)\n* [FlokiNET](https://billing.flokinet.is/index.php?rp=/knowledgebase/57/Nameserver-and-DNS-records.html)\n* [Gandi](https://docs.gandi.net/en/domain_names/common_operations/changing_nameservers.html)\n* [GoDaddy](https://www.godaddy.com/help/change-nameservers-for-your-domain-names-664)\n* [HostGator](https://www.hostgator.com/help/article/changing-name-servers)\n* [Hostico](https://hostico.ro/docs/setarea-nameserverelor-din-contul-de-client-hostico/)\n* [HostMonster](https://my.hostmonster.com/cgi/help/222)\n* [Hover](https://support.hover.com/support/solutions/articles/201000064742-changing-your-domain-nameservers)\n* [Internetdbs](https://faq.internetbs.net/hc/en-gb/articles/4516921367837-How-to-update-Nameservers-for-a-domain)\n* [iPage](https://www.ipage.com/help/article/domain-management-how-to-update-nameservers)\n* [MelbourneIT](https://support.melbourneit.au/docs/how-do-i-manage-my-dns-on-cpanel)\n* [Moniker](https://support.moniker.com/hc/en-gb/articles/10101271418653-How-to-update-Nameservers-for-a-domain)\n* [Name.com](https://www.name.com/support/articles/205934457-registering-custom-nameservers)\n* [Namecheap](https://www.namecheap.com/support/knowledgebase/article.aspx/767/10/how-can-i-change-the-nameservers-for-my-domain)\n* [Network Solutions](https://www.networksolutions.com/manage-it/edit-nameservers.jsp)\n* [OVH](https://docs.ovh.com/gb/en/domains/web_hosting_general_information_about_dns_servers/#step-2-edit-your-domains-dns-servers)\n* [Porkbun](https://kb.porkbun.com/article/22-how-to-change-your-nameservers)\n* [Rackspace](https://support.rackspace.com/how-to/rackspace-name-servers/)\n* [Register](https://www.register.com/knowledge)\n* [Squarespace](https://support.squarespace.com/hc/articles/4404183898125-Nameservers-and-DNSSEC-for-Squarespace-managed-domains#toc-open-the-domain-s-advanced-settings)\n* [Site5](https://kb.site5.com/dns-2/custom-nameservers/)\n* [Softlayer](https://cloud.ibm.com/docs/dns?topic=dns-add-edit-or-delete-custom-name-servers-for-a-domain)\n* [Yola](https://helpcenter.yola.com/hc/articles/360012492660-Changing-your-name-servers)\n\nIf you do not know who your registrar is, you can use a Whois search, such as [ICANN Lookup](https://lookup.icann.org/). If the registrar indicated on your Whois search result is not a service that you have interacted directly with, you may [have acquired your domain from a reseller](#you-have-acquired-your-domain-from-a-reseller).\n\n### You have acquired your domain from a reseller\n\nSome services, such as website builders ([Squarespace](https://support.squarespace.com/hc/articles/115003671428-Who-s-my-domain-provider), for example), are not registrars but act as a [reseller](https://www.icann.org/resources/pages/reseller-2013-05-03-en), allowing you to buy domains directly from them.\n\nIn that case, you may have to update your nameservers in the reseller platform, not at the registrar.\n\nNote\n\nRefer to [Squarespace documentation](https://support.squarespace.com/hc/articles/4404183898125-Nameservers-and-DNSSEC-for-Squarespace-managed-domains#toc-open-the-domain-s-advanced-settings) on how to update nameservers in their platform.\n\n### Your domain is delegated to another zone\n\nIf you are onboarding a subdomain `shop.example.com` as a [child domain](https://developers.cloudflare.com/dns/zone-setups/subdomain-setup/), it is expected that the child domain has been delegated to the parent domain.\n\nDelegation means that `shop.example.com` has specific `NS` records set up for it within the DNS records management of the parent zone (`example.com`).\n\nIf that is the case, when setting up your zone in Cloudflare or opting for a different set of [nameservers](https://developers.cloudflare.com/dns/nameservers/), you have to update the `NS` records in the parent domain, and not at the registrar.\n\n</page>\n\n<page>\n---\ntitle: Proxying limitations · Cloudflare DNS docs\ndescription: This page describes expected limitations when proxying DNS records.\n  For further information about proxying, refer to How Cloudflare works.\nlastUpdated: 2025-12-12T11:59:58.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/proxy-status/limitations/\n  md: https://developers.cloudflare.com/dns/proxy-status/limitations/index.md\n---\n\nThis page describes expected limitations when proxying DNS records. For further information about proxying, refer to [How Cloudflare works](https://developers.cloudflare.com/fundamentals/concepts/how-cloudflare-works/).\n\n## Proxy eligibility\n\nOnly A, AAAA, and CNAME DNS records that serve HTTP or HTTPS traffic can be proxied. Other record types cannot be proxied.\n\nIf you encounter a [CNAME record](https://developers.cloudflare.com/dns/manage-dns-records/reference/dns-record-types/#cname) that you cannot proxy — usually associated with another CDN provider — a proxied version of that record will cause connectivity errors. Cloudflare is purposely preventing that record from being proxied to protect you from a misconfiguration.\n\nNon-proxiable targets\n\n* Exact match:\n\n  * `dkim2.mcsv.net` ([Mailchimp documentation](https://mailchimp.com/help/set-up-email-domain-authentication/))\n  * `dkim3.mcsv.net` ([Mailchimp documentation](https://mailchimp.com/help/set-up-email-domain-authentication/))\n  * `zmverify.zoho.com` ([Zoho documentation](https://www.zoho.com/mail/help/adminconsole/domain-verification.html))\n  * `dkim.infusionmail.com` ([Keap documentation](https://help.keap.com/help/dmarc))\n\n* Exact match or subdomain of:\n  * `dkim.amazonses.com` ([Amazon SES documentation](https://docs.aws.amazon.com/ses/latest/dg/creating-identities.html#just-verify-domain-proc))\n\n* Subdomain of:\n\n  * `onmicrosoft.com` ([Microsoft documentation](https://learn.microsoft.com/defender-office-365/email-authentication-dkim-configure))\n  * `dkim.intercom.io` ([Intercom documentation](https://www.intercom.com/help/articles/9744849-connect-your-email-support-channel))\n  * `acm-validations.aws` ([AWS certificate manager documentation](https://docs.aws.amazon.com/acm/latest/userguide/dns-validation.html))\n\n### Pre-signed DNSSEC\n\nIf you use Cloudflare as your [secondary DNS provider](https://developers.cloudflare.com/dns/zone-setups/zone-transfers/cloudflare-as-secondary/) and leverage [Secondary DNS Overrides](https://developers.cloudflare.com/dns/zone-setups/zone-transfers/cloudflare-as-secondary/proxy-traffic/) to set records to proxied, note that opting for [Pre-signed DNSSEC](https://developers.cloudflare.com/dns/zone-setups/zone-transfers/cloudflare-as-secondary/dnssec-for-secondary/) will cause Cloudflare to treat your records as DNS-only.\n\n## Ports and protocols\n\nTo proxy HTTP/HTTPS traffic on [non-standard ports](https://developers.cloudflare.com/fundamentals/reference/network-ports/) or to proxy a TCP or UDP based application, use [Cloudflare Spectrum](https://developers.cloudflare.com/spectrum/).\n\n## Pending domains\n\nWhen you [add a domain](https://developers.cloudflare.com/fundamentals/manage-domains/add-site/) to Cloudflare, Cloudflare protection will be in a [pending state](https://developers.cloudflare.com/dns/zone-setups/reference/domain-status/) until we can verify ownership. This could take up to 24 hours to complete.\n\nThis means that DNS records — even those set to [proxy traffic through Cloudflare](#proxy-eligibility) — will be [DNS-only](https://developers.cloudflare.com/dns/proxy-status/#dns-only-records) until your zone has been activated and any requests to your DNS records will return your origin server's IP address.\n\nIf this warning is still present after 24 hours, refer to [Troubleshooting](https://developers.cloudflare.com/dns/troubleshooting/).\n\nFor enhanced security, we recommend rolling your origin IP addresses at your hosting provider after your zone has been activated. This action prevents your origin IPs from being leaked during onboarding.\n\n## Windows authentication\n\nBecause Microsoft Integrated Windows Authentication, NTLM, and Kerberos violate HTTP/1.1 specifications, they are not compatible with proxied DNS records.\n\n</page>\n\n<page>\n---\ntitle: Features and plans · Cloudflare DNS docs\ndescription: Review information on all Cloudflare DNS features and their availability.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/reference/all-features/\n  md: https://developers.cloudflare.com/dns/reference/all-features/index.md\n---\n\nCloudflare provides the following features for different [plans](https://www.cloudflare.com/plans/).\n\n## Features\n\n### Advanced nameservers\n\n**Link:** [Advanced nameservers](https://developers.cloudflare.com/dns/foundation-dns/advanced-nameservers/)\n\n**Feature availability**\n\n* **Free:** No\n* **Pro:** No\n* **Business:** No\n* **Enterprise:** Included with [Foundation DNS](https://developers.cloudflare.com/dns/foundation-dns/)\n\n### CNAME flattening\n\n**Link:** [CNAME flattening](https://developers.cloudflare.com/dns/cname-flattening/)\n\n**Feature availability**\n\n* **Free:** Yes\n* **Pro:** Yes\n* **Business:** Yes\n* **Enterprise:** Yes\n\n**Can customize**\n\nPro plans and above can customize\n\n* **Free:** No\n* **Pro:** Yes\n* **Business:** Yes\n* **Enterprise:** Yes\n\n### Custom nameservers\n\n**Link:** [Custom nameservers](https://developers.cloudflare.com/dns/nameservers/custom-nameservers/)\n\n**Feature availability**\n\n* **Free:** No\n* **Pro:** No\n* **Business:** Yes\n* **Enterprise:** Yes\n\n### DNS analytics\n\n**Link:** [DNS analytics](https://developers.cloudflare.com/dns/additional-options/analytics/)\n\n**Feature availability**\n\n* **Free:** Yes\n* **Pro:** Yes\n* **Business:** Yes\n* **Enterprise:** Yes\n\n**Maximum time interval (zone)**\n\n* **Free:** 7 days\n* **Pro:** 31 days\n* **Business:** 31 days\n* **Enterprise:** 62 days\n\n**Maximum time interval (account)**\n\n* **Free:** 7 days\n* **Pro:** 7 days\n* **Business:** 7 days\n* **Enterprise:** 62 days\n\n**Historical data (zone)**\n\n* **Free:** 8 days\n* **Pro:** 31 days\n* **Business:** 31 days\n* **Enterprise:** 62 days\n\n**Historical data (account)**\n\n* **Free:** 8 days\n* **Pro:** 8 days\n* **Business:** 8 days\n* **Enterprise:** 62 days\n\n### DNSSEC\n\n**Link:** [DNSSEC](https://developers.cloudflare.com/dns/dnssec/)\n\n**Feature availability**\n\n* **Free:** Yes\n* **Pro:** Yes\n* **Business:** Yes\n* **Enterprise:** Yes\n\n### DNS Firewall\n\n**Link:** [DNS Firewall](https://developers.cloudflare.com/dns/dns-firewall/)\n\n**Feature availability**\n\n* **Free:** No\n* **Pro:** No\n* **Business:** No\n* **Enterprise:** Paid add-on\n\n**Historical data**\n\n* **Free:** N/A\n* **Pro:** N/A\n* **Business:** N/A\n* **Enterprise:** 62 days\n\n**Maximum time interval**\n\n* **Free:** N/A\n* **Pro:** N/A\n* **Business:** N/A\n* **Enterprise:** 62 days\n\n### Full zone setup\n\n**Link:** [Full zone setup](https://developers.cloudflare.com/dns/zone-setups/full-setup/)\n\n**Feature availability**\n\n* **Free:** Yes\n* **Pro:** Yes\n* **Business:** Yes\n* **Enterprise:** Yes\n\n### Partial zone setup\n\n**Link:** [Partial zone setup](https://developers.cloudflare.com/dns/zone-setups/partial-setup/)\n\n**Feature availability**\n\n* **Free:** No\n* **Pro:** No\n* **Business:** Yes\n* **Enterprise:** Yes\n\n### DNS records management\n\n**Link:** [DNS records management](https://developers.cloudflare.com/dns/manage-dns-records/)\n\n**Feature availability**\n\n* **Free:** Yes\n* **Pro:** Yes\n* **Business:** Yes\n* **Enterprise:** Yes\n\n**Number of records per zone**\n\n* **Free:** 1,000 for zones created before `2024-09-01 00:00:00 UTC`\\\n  200 for zones created on or after `2024-09-01 00:00:00 UTC`\n* **Pro:** 3,500\n* **Business:** 3,500\n* **Enterprise:** 3,500 (can be increased)\n\n### DNS record comments\n\n**Link:** [DNS record comments](https://developers.cloudflare.com/dns/manage-dns-records/reference/record-attributes/)\n\n**Feature availability**\n\n* **Free:** Yes\n* **Pro:** Yes\n* **Business:** Yes\n* **Enterprise:** Yes\n\n**Character limit**\n\n* **Free:** 100\n* **Pro:** 500\n* **Business:** 500\n* **Enterprise:** 500\n\n**Comments per record**\n\n* **Free:** 1\n* **Pro:** 1\n* **Business:** 1\n* **Enterprise:** 1\n\n### DNS record tags\n\n**Link:** [DNS record tags](https://developers.cloudflare.com/dns/manage-dns-records/reference/record-attributes/)\n\n**Feature availability**\n\n* **Free:** No\n* **Pro:** Yes\n* **Business:** Yes\n* **Enterprise:** Yes\n\n**Name character limit (everything before the colon)**\n\n* **Free:** N/A\n* **Pro:** 32\n* **Business:** 32\n* **Enterprise:** 32\n\n**Value character limit (everything after the colon)**\n\n* **Free:** N/A\n* **Pro:** 100\n* **Business:** 100\n* **Enterprise:** 100\n\n**Tags per record**\n\n* **Free:** N/A\n* **Pro:** 20\n* **Business:** 20\n* **Enterprise:** 20\n\n### DNS zone transfers\n\n**Link:** [DNS zone transfers](https://developers.cloudflare.com/dns/zone-setups/zone-transfers/)\n\n**Feature availability**\n\n* **Free:** No\n* **Pro:** No\n* **Business:** No\n* **Enterprise:** Yes\n\n### Subdomain zone setup\n\n**Link:** [Subdomain zone setup](https://developers.cloudflare.com/dns/zone-setups/subdomain-setup/)\n\n**Feature availability**\n\n* **Free:** No\n* **Pro:** No\n* **Business:** No\n* **Enterprise:** Yes\n\n### Subdomain delegation\n\n**Link:** [Subdomain delegation](https://developers.cloudflare.com/dns/manage-dns-records/how-to/subdomains-outside-cloudflare/)\n\n**Feature availability**\n\n* **Free:** Yes\n* **Pro:** Yes\n* **Business:** Yes\n* **Enterprise:** Yes\n\n### Reverse zones\n\n**Link:** [Reverse zones](https://developers.cloudflare.com/dns/additional-options/reverse-zones/)\n\n**Feature availability**\n\n* **Free:** Yes\n* **Pro:** Yes\n* **Business:** Yes\n* **Enterprise:** Yes\n\n</page>\n\n<page>\n---\ntitle: Analytics API properties · Cloudflare DNS docs\ndescription: API properties that you can use in API requests for Cloudflare DNS analytics.\nlastUpdated: 2025-10-23T07:57:47.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/reference/analytics-api-properties/\n  md: https://developers.cloudflare.com/dns/reference/analytics-api-properties/index.md\n---\n\nThis page describes API properties that you can use in requests to the [DNS analytics API](https://developers.cloudflare.com/api/resources/dns/subresources/analytics/subresources/reports/methods/get/).\n\nWarning\n\nThe [DNS analytics API](https://developers.cloudflare.com/api/resources/dns/subresources/analytics/subresources/reports/methods/get/), along with the following [API properties](https://developers.cloudflare.com/dns/reference/analytics-api-properties/), will be deprecated soon.\n\nTo access the new analytics dashboard, go to [**DNS Analytics**](https://dash.cloudflare.com//?to=/:account/:zone/dns/analytics). Refer to [Analytics and logs](https://developers.cloudflare.com/dns/additional-options/analytics/) for details.\n\n## Metrics\n\nA metric is a numerical value based on an attribute of the data, for example a query count.\n\nIn API requests, metrics are set in the `metrics` parameter. If you need to list multiple metrics, separate them with commas.\n\n| Metric | Name | Example | Unit |\n| - | - | - | - |\n| queryCount | Query count | `1000` | Count |\n| uncachedCount | Uncached query count | `1` | Count |\n| staleCount | Stale query count | `1` | Count |\n| responseTimeAvg | Average response time | `1.0` | Time in milliseconds |\n| responseTimeMedian | Median response time | `1.0` | Time in milliseconds |\n| responseTime90th | 90th percentile response time | `1.0` | Time in milliseconds |\n| responseTime99th | 99th percentile response time | `1.0` | Time in milliseconds |\n\n## Dimensions\n\nDimensions can be used to break down the data by given attributes.\n\nIn API requests, dimensions are set in the `dimensions` parameter. If you need to list multiple dimensions, separate them with commas.\n\n| Dimension | Name | Example | Notes |\n| - | - | - | - |\n| queryName | Query Name | `example.com` | |\n| queryType | Query Type | `AAAA` | [Types defined by IANA](http://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml#dns-parameters-4). Unknown types are empty. |\n| responseCode | Response Code | `NOERROR` | [Response codes defined by IANA](http://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml#dns-parameters-6). Always uppercase. |\n| responseCached | Response Cached | `Cached` | Either `Cached` or `Uncached`. |\n| coloName | Colo Name | `SJC` | PoP code. |\n| origin | Origin | `2001:db8::1` | Origin used to resolve the query. Empty if N/A or if the query was answered from cache. |\n| dayOfWeek | Day Of Week | `1` | Break down by day of week. Monday is `1`, and Sunday is `7`. |\n| tcp | TCP | `1` | Either `1` or `0` depending on the protocol used. |\n| ipVersion | IP Version | `6` | IP protocol version used (currently `4` or `6`). |\n| querySizeBucket | Query Size Bucket | `16-31` | Query size bucket by multiples of 16. |\n| responseSizeBucket | Response Size Bucket | `16-31` | Response size bucket by multiples of 16. |\n\n## Filters\n\nFilters use the form `dimension operator expression`, where each part corresponds to the following:\n\n* **Dimension**: Specifies the [dimension](#dimensions) to filter on. For example, `queryName`.\n* **Operator**: Defines the type of filter match to use. Operators are specific to dimensions.\n* **Expression**: States the values to include or exclude from the results. Expressions use regular expression (regex) syntax.\n\n### Filter operators\n\n| Operator | Name | Example | Description | URL Encoded |\n| - | - | - | - | - |\n| `==` | Equals | `queryName==example.com` | Return results where `queryName` is exactly `example.com`. | `%3D%3D` |\n| `!=` | Does not equal | `responseCode!=NOERROR` | Return results where `responseCode` is different from `NOERROR`. | `!%3D` |\n| `>` | Greater than | `dimension>1000` | Return results where a dimension is greater than `1000`. | `%3E` |\n| `<` | Less than | `dimension<1000` | Return results where a dimension is less than `1000`. | `%3C` |\n| `>=` | Greater than or equal to | `dimension>=1000` | Return results where a dimension is greater than or equal to `1000`. | `%3E%3D` |\n| `<=` | Less than or equal to | `dimension<=1000` | Return results where a dimension is less than or equal to `1000`. | `%3C%3D` |\n\n### Combining filters\n\nCombine filters using `OR` and `AND` boolean logic:\n\n* `AND` takes precedence over `OR` in all expressions.\n\n* The `OR` operator is defined using a comma `,` or the `OR` keyword surrounded by whitespace.\n\n* The `AND` operator is defined using a semicolon `;` or the `AND` keyword surrounded by whitespace.\n\n  Note\n\n  Note that the semicolon is a reserved character in URLs ([RFC 1738](https://www.rfc-editor.org/rfc/rfc1738)) and should be percent-encoded as `%3B`.\n\nExamples using OR\n\n* `responseCode==NOERROR,responseCode==NXDOMAIN` indicates that response code is either `NOERROR` or `NXDOMAIN`.\n* `coloName==SJC OR coloName==LAX` indicates queries in either `SJC` or `LAX`.\n\nExamples using AND\n\n* `responseCode==NOERROR;queryType==AAAA` indicates that response code is `NOERROR` and query type is `AAAA`.\n* `queryType==AAAA AND coloName==SJC` indicates `AAAA` queries in `SJC`.\n\n</page>\n\n<page>\n---\ntitle: Analytics MCP server · Cloudflare DNS docs\nlastUpdated: 2025-10-09T17:32:08.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/reference/analytics-mcp-server/\n  md: https://developers.cloudflare.com/dns/reference/analytics-mcp-server/index.md\n---\n\n\n</page>\n\n<page>\n---\ntitle: Domain Connect · Cloudflare DNS docs\ndescription: Learn how to onboard your templates to use Domain Connect with\n  Cloudflare as DNS provider.\nlastUpdated: 2025-07-18T15:49:23.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/reference/domain-connect/\n  md: https://developers.cloudflare.com/dns/reference/domain-connect/index.md\n---\n\nIf you are a service provider, consider this page for information on how Cloudflare supports [Domain Connect](https://www.domainconnect.org/) and how you can onboard your template.\n\n## What is Domain Connect\n\nDomain Connect is an open standard that allows service providers - such as email or web hosting platforms - to make it easier for their end users to configure functionality, without having to manually edit DNS records.\n\nThis is achieved with templates that close the gap between necessary configurations (required by the service provider) and necessary DNS records changes (that must happen at the authoritative DNS provider).\n\nIn practice, this means that when a user that owns `example.com` and has Cloudflare as their authoritative DNS provider wants to use your service, instead of having to manually update their DNS records, they will only have to authenticate themselves and the necessary changes will be applied automatically.\n\n## Setup\n\n### Before you begin\n\n* Note that Cloudflare only supports the [Domain Connect synchronous flow](https://www.domainconnect.org/getting-started/).\n* Domain Connect templates and tools are published on GitHub, so you must have a GitHub account and be familiar with [GitHub forks and pull requests](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks).\n\n### 1. Add templates to the repository\n\nDomain Connect templates are published and maintained on a GitHub repository.\n\n1. Create a fork of the [templates repository](https://github.com/Domain-Connect/Templates).\n\n2. Add your template. You can create a copy of one of the existing templates and edit it according to your needs.\n\n   * Refer to the [Domain Connect Specification](https://github.com/Domain-Connect/spec/blob/master/Domain%20Connect%20Spec%20Draft.adoc) for details on the different available fields.\n\n     Note\n\n     Not all fields (properties) are supported by Cloudflare, and some will be mandatory for onboarding your template. Refer to the [properties support](#properties-support) section below for details.\n\n   * If present, you must set the `syncBlock` field on your template to `false`. This means the template flow will be synchronous, which is the only option supported by Cloudflare.\n\n   * You must also provide a synchronous public key domain (`syncPubKeyDomain` [1](#user-content-fn-1)). When your template is in use, synchronous calls will be digitally signed.\n\n3. Make sure you follow the naming format defined by Domain Connect: `<providerId>.<serviceId>.json`.\n\nTip\n\nYou can use Domain Connect's [linter tool](https://github.com/Domain-Connect/dc-template-linter) with the option `-cloudflare` enabled to check your template against Cloudflare specific rules.\n\n1. Submit a pull request to have your template(s) added to the repository.\n\nOnce your pull request has been reviewed and merged, contact Cloudflare as specified below.\n\n### 2. Contact Cloudflare to onboard your template\n\nWhen your template is onboarded, a graphical user interface flow will be available to your end users.\n\nSend an email to `domain-connect@cloudflare.com`, including the following information:\n\n1. List of template(s) you want to onboard, with their corresponding GitHub hyperlinks.\n\n2. A logo to be displayed as part of the Domain Connect flow. Preferably in `SVG` format.\n\n3. The default [proxy status](https://developers.cloudflare.com/dns/proxy-status/) you would like Cloudflare to set for `A`, `AAAA`, and `CNAME` records that are part of your template(s). Proxying other record types is not supported.\n\n   Note\n\n   Proxy status is applied per template. If needed, organize the records in different templates to specify a different default proxy status per template. Once the records have been created, the domain owner can always change the proxy status for `A`, `AAAA`, and `CNAME` records later.\n\n4. (Optional) A Cloudflare [account ID](https://developers.cloudflare.com/fundamentals/account/find-account-and-zone-ids/) for you to test the flow.\n\n   If you have a [DNS provider discovery](https://github.com/Domain-Connect/spec/blob/master/Domain%20Connect%20Spec%20Draft.adoc#dns-provider-discovery) automation in place and will not list new DNS providers manually, Cloudflare can initially restrict your template to be exposed to the specified account only. Once you confirm everything is working as expected, Cloudflare will publish your template on the discovery endpoint, to be picked up by your automation.\n\n## Properties support\n\nIn the [Domain Connect Specification](https://github.com/Domain-Connect/spec/blob/master/Domain%20Connect%20Spec%20Draft.adoc) you will find the following properties:\n\n* Properties that you can use with your [apply template URL](https://github.com/Domain-Connect/spec/blob/master/Domain%20Connect%20Spec%20Draft.adoc#apply-template).\n* Properties for [defining the template itself](https://github.com/Domain-Connect/spec/blob/master/Domain%20Connect%20Spec%20Draft.adoc#template-definition).\n* Properties for defining the individual [DNS records](https://github.com/Domain-Connect/spec/blob/master/Domain%20Connect%20Spec%20Draft.adoc#template-record).\n\nWhile most of these are supported by Cloudflare, some are required and others are not supported.\n\nLinter tool\n\nUse Domain Connect's [linter tool](https://github.com/Domain-Connect/dc-template-linter) with the option `-cloudflare` enabled to check your template against Cloudflare specific rules.\n\n### Apply template URL\n\nFor the full list, refer to the [Domain Connect Specification](https://github.com/Domain-Connect/spec/blob/master/Domain%20Connect%20Spec%20Draft.adoc). Below are the details specific to Cloudflare.\n\n* **Redirect URI**: Domain Connect's documentation states that it must be scoped to the `syncRedirectDomain` from the template, or the request must be signed. Cloudflare requires the request to be signed and, as such, does not check if the `redirect_uri` is scoped to the `syncRedirectDomain`.\n* **State**: Is not supported and will be ignored.\n* **Service Name**: Is not supported and will be ignored.\n* **Signature**: Required. It also must be the last query parameter.\n* **Key**: Required. You must publish your public key and place it in a DNS TXT record on a domain specified in the template as `syncPubKeyDomain`. To allow for key rotation, the hostname of the TXT record must be appended as another variable on the query string of the form.\n\n### Template definition\n\nFor the full list, refer to the [Domain Connect Specification](https://github.com/Domain-Connect/spec/blob/master/Domain%20Connect%20Spec%20Draft.adoc). Below are the details specific to Cloudflare.\n\n* **Service Provider Name**: Will be displayed on the user interface.\n* **Service Name**: Will **not** be displayed on the user interface.\n* **Logo**: If present, will be displayed on the user interface.\n* **Synchronous Block**: Is not supported and will be ignored. Cloudflare only supports the synchronous flow.\n* **Shared**: Is not supported and will be ignored.\n* **Shared Service Name**: Is not supported and will be ignored.\n* **Synchronous Public Key Domain**: Required. Cloudflare only supports the synchronous flow and always checks for signature.\n* **Synchronous Redirect Domains**: Is not supported and will be ignored. Cloudflare looks at the `redirect_uri` provided in the signed apply template URL.\n* **Multiple Instance**: Is not supported and will be ignored.\n* **Warn Phishing**: Is not supported and will be ignored.\n* **Host Required**: Is not supported and will be ignored.\n\n### DNS records\n\nFor the full list, refer to the [Domain Connect Specification](https://github.com/Domain-Connect/spec/blob/master/Domain%20Connect%20Spec%20Draft.adoc). Below are the details specific to Cloudflare.\n\n* **Essential**: Is not supported and will be ignored.\n* **TXT Conflict Matching Mode**: Is not supported and will be ignored.\n* **TXT Conflict Matching Prefix**: Is not supported and will be ignored.\n\n## Template updates\n\nSince September, 2024, template updates are picked up by an automation.\n\nThe automation compares the template version number in Cloudflare with the authoritative source of the template on the Internet. This check runs multiple times a day. Although Cloudflare cannot guarantee when exactly each update will be picked up, the process is expected to take no longer than eight hours.\n\nNote\n\nThe authoritative source must be in raw `json` format for the automation to work correctly, as in [this example](https://raw.githubusercontent.com/Domain-Connect/Templates/master/exampleservice.domainconnect.org.template1.json).\n\nIf the source template is unavailable, or technically invalid, Cloudflare will keep the previous template in use until the updated version is fixed.\n\nYou can contact Cloudflare to opt out of the automatic updates. Once the automation is disabled, you can request template updates individually, by writing to `domain-connect@cloudflare.com`.\n\n### Troubleshooting\n\nSend an email to `domain-connect@cloudflare.com` with the following information:\n\n1. Detailed description of what is wrong:\n\n   * List the record(s) that the issue is related with.\n   * Describe what the template did.\n   * Describe what you expected the template to do.\n\n2. A [HAR file](https://developers.cloudflare.com/support/troubleshooting/general-troubleshooting/gathering-information-for-troubleshooting-sites/#generate-a-har-file) attachment containing the problematic update.\n\n## Footnotes\n\n1. A domain that can be queried for `TXT` records containing a public key to verify your digital signature. [↩](#user-content-fnref-1)\n\n</page>\n\n<page>\n---\ntitle: Recommended third-party tools · Cloudflare DNS docs\ndescription: List of recommended third-party tools for DNS testing and troubleshooting.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/reference/recommended-third-party-tools/\n  md: https://developers.cloudflare.com/dns/reference/recommended-third-party-tools/index.md\n---\n\nYou can use the third-party tools listed below to test and troubleshoot DNS settings.\n\n* [DNSViz](https://dnsviz.net): A web-based tool for visualizing the status of a DNS zone to understand and troubleshoot the deployment of DNS Security Extensions (DNSSEC).\n\n* [Dig Web Interface](https://digwebinterface.com): An online DNS lookup tool based on the command line interface `dig`. Users can skip the process of entering commands with complicated parameters in the terminal by entering the same information in this web tool and getting the same results.\n\n* [dns.google](https://dns.google): A web-based tool, similar to Dig Web Interface, where users can get DNS responses for specific queries.\n\n* [Mess with DNS](https://messwithdns.net): An educational resource that encourages users to experiment with DNS records by providing users with a domain where they are free to play around and break things during the learning process.\n\n</page>\n\n<page>\n---\ntitle: Available debug endpoints · Cloudflare DNS docs\ndescription: The following debug endpoints are available via dig or other DNS query tools.\nlastUpdated: 2025-12-15T16:07:00.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/troubleshooting/dns-debug-endpoints/\n  md: https://developers.cloudflare.com/dns/troubleshooting/dns-debug-endpoints/index.md\n---\n\nThe following debug endpoints are available via `dig` or other DNS query tools.\n\nNote\n\nFor all commands, you can replace `alex.ns.cloudflare.com` with your Cloudflare assigned nameservers.",
      "language": "unknown"
    },
    {
      "code": "This command gives you your IP address, meaning the public IP address that Cloudflare receives this DNS query from. This is useful for debugging when you need to know your own IP.\n\n***",
      "language": "unknown"
    },
    {
      "code": "This command gives you the Cloudflare data center you are connecting to, for DNS queries sent from where you execute this command.\n\n***",
      "language": "unknown"
    },
    {
      "code": "This command gives you the version of Cloudflare's authoritative DNS software that is running on the data center you are connected to. Usually, the same version would always be present on all of our data centers. But, since we do staged releases, technically there can be different versions on different data centers.\n\n***",
      "language": "unknown"
    },
    {
      "code": "This command gives you your public IP (same as the first command above), your ASN, and the associated country code, all indicating where you are sending this query from.\n\n</page>\n\n<page>\n---\ntitle: General DNS issues · Cloudflare DNS docs\ndescription: \"In web browsers such as Safari or Chrome, there are several\n  commonly observable DNS errors:\"\nlastUpdated: 2025-10-30T14:49:02.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/troubleshooting/dns-issues/\n  md: https://developers.cloudflare.com/dns/troubleshooting/dns-issues/index.md\n---\n\nIn web browsers such as Safari or Chrome, there are several commonly observable DNS errors:\n\n* `This site can’t be reached`\n* `This webpage is not available`\n* `err_name_not_resolved`\n* `Can't find the server`\n* [`Error 1001 DNS resolution error`](https://developers.cloudflare.com/support/troubleshooting/http-status-codes/cloudflare-1xxx-errors/error-1001/)\n\n## Common causes and resolutions\n\nBelow are the most common causes for DNS resolution errors along with suggested solutions.\n\n### Mistyped domain or subdomain\n\nVerify that the domain or subdomain was correctly spelled in the request URL.\n\n### Missing DNS records\n\nEnsure that you have the necessary DNS records in the **DNS** app of your Cloudflare dashboard. This includes having the following records:\n\n* The [zone apex](https://developers.cloudflare.com/dns/manage-dns-records/how-to/create-zone-apex/) (e.g., `example.com`) record.\n* Existing [subdomains](https://developers.cloudflare.com/dns/manage-dns-records/how-to/create-subdomain/) (`www.example.com`, `blog.example.com`) records.\n\nNote\n\nIf you have a [partial (CNAME) setup](https://developers.cloudflare.com/dns/zone-setups/partial-setup), ensure your DNS records also exist in your authoritative nameservers.\n\n### DNSSEC was not disabled before the domain was added to Cloudflare\n\nDNS resolution failures occur if [DNSSEC is not disabled](https://developers.cloudflare.com/dns/dnssec/#disable-dnssec) at your domain provider before you add the domain to Cloudflare.\n\n### Nameservers no longer point to Cloudflare\n\nIf you manage DNS records via the **DNS** app in Cloudflare's Dashboard and your domain stops pointing to Cloudflare's nameservers, DNS resolution will stop functioning.\n\nThis can occur if your domain registrar switches the nameservers for your domain to point to their default nameservers. To confirm if this is the problem, [check whether your domain uses Cloudflare's nameservers](https://developers.cloudflare.com/dns/zone-setups/full-setup/setup/#verify-changes).\n\n### Unresolved IP address\n\nIn rare cases, the DNS resolver in the client requesting the URL might fail to resolve a DNS record to a valid IP address.\n\nReload the page after a short wait to note if the problem disappears. This issue is unrelated to Cloudflare, but using [Cloudflare's DNS resolver](https://developers.cloudflare.com/1.1.1.1/setup/) may help. Contact your hosting provider for additional help with your current DNS resolver.\n\n</page>\n\n<page>\n---\ntitle: Fix DNS_PROBE_FINISHED_NXDOMAIN · Cloudflare DNS docs\ndescription: If you or your visitors experience DNS_PROBE_FINISHED_NXDOMAIN\n  errors after you activate your domain on Cloudflare, review your DNS records\n  in Cloudflare.\nlastUpdated: 2025-10-30T14:49:02.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/troubleshooting/dns-probe-finished-nxdomain/\n  md: https://developers.cloudflare.com/dns/troubleshooting/dns-probe-finished-nxdomain/index.md\n---\n\nIf you or your visitors experience `DNS_PROBE_FINISHED_NXDOMAIN` errors after you [activate your domain on Cloudflare](https://developers.cloudflare.com/dns/zone-setups/full-setup/setup/), review your DNS records in Cloudflare.\n\nNote\n\nIf your domain is added to Cloudflare by a hosting partner, manage your DNS records via the hosting partner.\n\n## Background\n\n`DNS_PROBE_FINISHED` means that the DNS request for a resource timed out and `NXDOMAIN` stands for non-existent domain. Together, these messages mean that the DNS query for a specific resource could not locate an associated domain.\n\nThough visitors sometimes encounter this error — or similarly worded messages from Safari, Edge, or Firefox — because of network or local DNS issues, it might point to an issue with your DNS records in Cloudflare.\n\n## Potential solutions\n\nIf you experience `DNS_PROBE_FINISHED_NXDOMAIN` errors with a newly activated domain, review your DNS settings in the Cloudflare dashboard.\n\nCheck your expected apex domain (`example.com`) and any active subdomains (`www.example.com` or `blog.example.com`). If they do not resolve correctly, you may need to [add a record on the zone apex](https://developers.cloudflare.com/dns/manage-dns-records/how-to/create-zone-apex/) or a [subdomain record](https://developers.cloudflare.com/dns/manage-dns-records/how-to/create-subdomain/) in Cloudflare DNS.\n\nIf you have the correct records set up, make sure those records are also pointing to the correct origin IP address.\n\nAfter making changes to your DNS records, you may need to wait a few minutes for those changes to take effect.\n\nNote\n\nFor additional troubleshooting help, refer to our [Community troubleshooting guide](https://community.cloudflare.com/t/community-tip-fixing-the-dns-probe-finished-nxdomain-error/42818).\n\n</page>\n\n<page>\n---\ntitle: Fix DNS_PROBE_POSSIBLE error · Cloudflare DNS docs\ndescription: If you or your visitors experience DNS_PROBE_POSSIBLE errors after\n  you activate your domain on Cloudflare, review your DNS records in Cloudflare.\nlastUpdated: 2025-10-30T14:49:02.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/troubleshooting/dns-probe-possible/\n  md: https://developers.cloudflare.com/dns/troubleshooting/dns-probe-possible/index.md\n---\n\nIf you or your visitors experience `DNS_PROBE_POSSIBLE` errors after you [activate your domain on Cloudflare](https://developers.cloudflare.com/dns/zone-setups/full-setup/setup/), review your DNS records in Cloudflare.\n\nNote\n\nIf your domain is added to Cloudflare by a hosting partner, manage your DNS records via the hosting partner.\n\n## Background\n\n`DNS_PROBE_POSSIBLE` means that the resolver could not find DNS records for the requested hostname.\n\nThough visitors sometimes encounter this error — or similarly worded messages from Safari, Edge, or Firefox — because of network or local DNS issues, it might point to an issue with your DNS records in Cloudflare.\n\n## Potential solutions\n\nIf you experience `DNS_PROBE_POSSIBLE` errors with a newly activated domain, review your DNS settings in the Cloudflare dashboard.\n\nCheck your expected apex domain (`example.com`) and any active subdomains (`www.example.com` or `blog.example.com`). If they do not resolve correctly, you may need to [add a record on the zone apex](https://developers.cloudflare.com/dns/manage-dns-records/how-to/create-zone-apex/) or a [subdomain record](https://developers.cloudflare.com/dns/manage-dns-records/how-to/create-subdomain/) in Cloudflare DNS.\n\nIf you have the correct records set up, make sure those records are also pointing to the correct origin IP address.\n\nAfter making changes to your DNS records, you may need to wait a few minutes for those changes to take effect.\n\n</page>\n\n<page>\n---\ntitle: Troubleshooting email issues · Cloudflare DNS docs\ndescription: If you have issues sending or receiving mail, follow these\n  troubleshooting steps.\nlastUpdated: 2025-10-30T14:49:02.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/troubleshooting/email-issues/\n  md: https://developers.cloudflare.com/dns/troubleshooting/email-issues/index.md\n---\n\nIf you have issues sending or receiving mail, follow these troubleshooting steps.\n\n## Are your records correct?\n\nConsult with your mail administrator or mail provider to ensure you have valid DNS record content.\n\n## Are DNS records missing?\n\nContact your mail administrator to confirm the DNS records for your domain are correct. Refer to our guide on [managing DNS records in Cloudflare](https://developers.cloudflare.com/dns/manage-dns-records/how-to/create-dns-records) if you need assistance to add or edit DNS records.\n\n## Do you have NS records configured?\n\nNS records are used to delegate the management of a hostname to another DNS provider (refer to [Delegate a subdomain (outgoing)](https://developers.cloudflare.com/dns/manage-dns-records/how-to/subdomains-outside-cloudflare/#delegate-a-subdomain-outgoing) for further context). If you have NS records configured in the DNS tab of your Cloudflare dashboard, confirm that these are expected and not generating conflicts.\n\n## Do you have CNAME Flattening enabled?\n\nWhen set to [Flatten all CNAMEs](https://developers.cloudflare.com/dns/cname-flattening/set-up-cname-flattening/) in your Cloudflare DNS settings, queries to all `CNAME` records will flatten to an `A` record; no `CNAME` records will be returned.\n\nAlso, if `CNAME` records are not returned by the queried nameserver (sometimes nameservers will return TXT records), this may result in nothing being returned when ***Flatten all CNAMEs*** is enabled. Changing to ***Flatten at the root*** should fix any issues with your CNAME records not being returned.\n\n## Is Cloudflare Spectrum enabled on your account?\n\nCloudflare does not proxy traffic on port 25 (SMTP) unless [Cloudflare Spectrum](https://developers.cloudflare.com/spectrum/reference/configuration-options#smtp) is enabled and configured to proxy email traffic across Cloudflare. If you do not have Spectrum enabled, then no email traffic (SMTP) will actually pass through Cloudflare, and we will simply resolve the DNS. This also means that any DNS record used to send email traffic must be DNS-only to bypass the Cloudflare network. Check [Identifying subdomains compatible with Cloudflare's proxy](https://developers.cloudflare.com/dns/proxy-status/) for more details.\n\n## Contact your mail provider for assistance\n\nIf your email does not work shortly after editing DNS records, contact your mail administrator or mail provider for further assistance in troubleshooting so that data about the issue can be provided to Cloudflare support.\n\n## dc-######### subdomain\n\nThe dc-##### subdomain is added to overcome a conflict created when your `SRV` or `MX` record resolves to a domain configured to [proxy](https://developers.cloudflare.com/dns/proxy-status/) to Cloudflare.\n\nTherefore, Cloudflare will create a `dc-#####` DNS record that resolves to the origin IP address. The `dc-#####` record ensures that traffic for your `MX` or `SRV` record is not proxied (it directly resolves to your origin IP) while the Cloudflare proxy works for all other traffic.\n\nFor example, before using Cloudflare, suppose your DNS records for mail are as follows:\n\n`example.com MX example.com` `example.com A 192.0.2.1`\n\nAfter using Cloudflare and proxying the `A` record, Cloudflare will provide DNS responses with a Cloudflare IP (`203.0.113.1` in the example below):\n\n`example.com MX example.com` `example.com A 203.0.113.1`\n\nSince proxying mail traffic to Cloudflare would break your mail services, Cloudflare detects this situation and creates a `dc-#####` record:\n\n`example.com MX dc-1234abcd.example.com` `dc-1234abcd.example.com A 192.0.2.1` `example.com A 203.0.113.1`\n\nRemoving the `dc-######` record is only possible via one of these methods:\n\n* If no mail is received for the domain, delete the `MX` record.\n* If mail is received for the domain, update the `MX` record to resolve to a separate `A` record for a mail subdomain that is not proxied by Cloudflare:\n\n`example.com MX mail.example.com` `mail.example.com A 192.0.2.1` `example.com A 203.0.113.1`\n\nWarning\n\nIf your mail server resides on the same IP as your web server, your MX record will expose your origin IP address.\n\n***\n\n## Best practices for MX records on Cloudflare\n\nIf possible, do not host a mail service on the same server as the web resource you want to protect, since emails sent to non-existent addresses get bounced back to the attacker and reveal the mail server IP address.\n\nCloudflare recommends using non-contiguous IPs from different IP ranges.\n\n</page>\n\n<page>\n---\ntitle: General FAQ · Cloudflare DNS docs\ndescription: \"Yes. Cloudflare offers free DNS services to customers on all\n  plans. Note that:\"\nlastUpdated: 2025-09-12T14:57:41.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/troubleshooting/faq/\n  md: https://developers.cloudflare.com/dns/troubleshooting/faq/index.md\n---\n\n## Is Cloudflare a free DNS (domain nameserver) provider?\n\nYes. Cloudflare offers [free DNS services](https://www.cloudflare.com/dns) to customers on all plans. Note that:\n\n1. You do not need to change your hosting provider to use Cloudflare.\n2. You do not need to move away from your registrar. The only change you make with your registrar is to point the authoritative nameservers to the Cloudflare nameservers.\n\n***\n\n## Does Cloudflare charge for or limit DNS queries?\n\nCloudflare never limits or caps DNS queries, but the pricing depends on your plan level.\n\nFor customers on Free, Pro, or Business plans, Cloudflare does not charge for DNS queries.\n\nFor customers on Enterprise plans, Cloudflare uses the number of monthly DNS queries as a pricing input to generate a custom quote.\n\n***\n\n## Where do I change my nameservers to point to Cloudflare?\n\nMake the change at your registrar, which is where you registered your domain. This may or may not be your hosting provider. If you don't know who your registrar is for the domain, you can find this by doing a WHOIS search. You can use [ICANN Lookup](https://lookup.icann.org/), for example.\n\nWarning\n\nSome country code TLDs may not be supported by ICANN Lookup. If that is the case, use a different WHOIS search tool.\n\nOnce you identify your registrar, follow the instructions in [change nameservers to Cloudflare](https://developers.cloudflare.com/dns/zone-setups/full-setup/setup/#update-your-nameservers).\n\n***\n\n## Does Cloudflare limit the number of DNS records a domain can have?\n\nYes. All customers have a limit on the number of DNS records they can create.\n\n* Free: 200\n* Pro: 3,500\n* Business: 3,500\n* Enterprise: 3,500\n\nFree zones created before 2024-09-01 00:00:00 UTC have an increased limit of 1,000.\n\nFor more DNS records\n\nIf you are an Enterprise customer and require more DNS records, contact your account team. Cloudflare can support millions of DNS records on a single zone.\n\n***\n\n## Which record types can Cloudflare proxy?\n\nOnly `A`, `AAAA`, and `CNAME` records can be proxied. Cloudflare will not proxy any other [DNS record types](https://developers.cloudflare.com/dns/manage-dns-records/reference/dns-record-types/).\n\n***\n\n## How do I add ANAME records on Cloudflare?\n\nANAME or ALIAS are DNS records used by specific DNS providers. If your previous provider was using ANAME or ALIAS, you can recreate these records on Cloudflare as CNAME records. Cloudflare's [CNAME flattening](https://developers.cloudflare.com/dns/cname-flattening/)[1](#user-content-fn-1) allows you to create CNAME records at your [zone apex](https://developers.cloudflare.com/dns/concepts/#zone-apex), removing the need for those other record types.\n\n## Footnotes\n\n1. A process in which Cloudflare returns an IP address instead of the target hostname that a CNAME record points to. [↩](#user-content-fnref-1)\n\n***\n\n## Can I CNAME a domain not on Cloudflare to a domain that is on Cloudflare?\n\nNo. If you would like to do a redirect for a site not on Cloudflare, then set up a traditional `301` or `302` redirect on your origin web server.\n\nRedirecting non-Cloudflare sites via `CNAME` records would cause a DNS resolution error. Since Cloudflare is a reverse proxy for the domain that is on Cloudflare, the `CNAME` redirect for the domain (not on Cloudflare) would not know where to send the traffic to.\n\n***\n\n## Does Cloudflare support wildcard DNS entries?\n\nCloudflare supports wildcard '\\*' DNS records, both proxied and unproxied, on all plans.\n\n***\n\n## How long does it take for a DNS change I made to push out?\n\nBy default, any changes or additions you make to your Cloudflare zone file will take effect globally within 5 minutes, usually much less.\n\nDepending on the Time-to-Live (TTL) set on the previous [DNS record](https://developers.cloudflare.com/dns/manage-dns-records/how-to/create-dns-records/), old data may still remain cached until the TTL expires. Proxied records expire after 5 minutes (\"Automatic\"), but the TTL for unproxied records can be customized.\n\nIf changes to records with large TTLs are anticipated, it may make sense to reduce the TTL ahead of time so that the change takes effect as quickly as possible.\n\n***\n\n## Does Cloudflare offer domain masking?\n\nNo. Cloudflare does not offer domain masking or DNS redirect services (your hosting provider might). However, we do offer URL forwarding through [Bulk Redirects](https://developers.cloudflare.com/rules/url-forwarding/bulk-redirects/).\n\n***\n\n## Why can't I make ANY queries to Cloudflare DNS servers?\n\n`ANY` queries are special and often misunderstood. They are usually used to get all record types available on a DNS name, but what they return is just any type in the cache of recursive resolvers. This can cause confusion when they are used for debugging.\n\nBecause of Cloudflare's many advanced DNS features like CNAME flattening, it can be complex and even impossible to give correct answers to `ANY` queries. For example, when DNS records dynamically come and go or are stored remotely, it can be taxing or even impossible to get all the results at the same time.\n\n`ANY` is rarely used in production, but is often used in DNS reflection attacks, taking advantage of the lengthy answer returned by `ANY`.\n\nInstead of using `ANY` queries to list records, Cloudflare customers can get a better overview of their DNS records by logging in and checking their DNS app settings.\n\nThe decision to block `ANY` queries was implemented for all Authoritative DNS customers in September 2015, and does not affect DNS Firewall customers.\n\nRead [Deprecating the DNS ANY meta-query type](https://blog.cloudflare.com/deprecating-dns-any-meta-query-type/) on the Cloudflare blog.\n\n***\n\n## Why do I have to remove my `DS` record when signing up for Cloudflare?\n\nProvider-specific instructions\n\nThis is not an exhaustive list of how to update DS records in other providers, but the following links may be helpful:\n\n* [DNSimple](https://support.dnsimple.com/articles/cloudflare-ds-record/)\n* [Domaindiscount24](https://support.domaindiscount24.com/hc/articles/4409759478161)\n* [DreamHost](https://help.dreamhost.com/hc/en-us/articles/219539467)\n* [Dynadot](https://www.dynadot.com/help/question/set-DNSSEC)\n* [Enom](https://support.enom.com/support/solutions/articles/201000065386)\n* [Gandi](https://docs.gandi.net/en/domain_names/advanced_users/dnssec.html)\n* [GoDaddy](https://www.godaddy.com/en-ph/help/add-a-ds-record-23865)\n* [Hostinger](https://www.hostinger.com/support/3667267-how-to-use-dnssec-records-at-hostinger/)\n* [Hover](https://support.hover.com/support/solutions/articles/201000064716)\n* [InMotion Hosting](https://www.inmotionhosting.com/support/edu/cpanel/enable-dnssec-cloudflare/)\n* [INWX](https://kb.inwx.com/en-us/3-nameserver/131)\n* [Joker.com](https://joker.com/faq/books/jokercom-faq-en/page/dnssec)\n* [Name.com](https://www.name.com/support/articles/205439058-managing-dnssec)\n* [Namecheap](https://www.namecheap.com/support/knowledgebase/article.aspx/9722/2232/managing-dnssec-for-domains-pointed-to-custom-dns/)\n* [NameISP](https://support.nameisp.com/knowledgebase/dns)\n* [Namesilo](https://www.namesilo.com/support/v2/articles/domain-manager/ds-records)\n* [OVH](https://help.ovhcloud.com/csm/en-dns-secure-domain-dnssec?id=kb_article_view\\&sysparm_article=KB0051637)\n* [Squarespace](https://support.squarespace.com/hc/articles/4404183898125-Nameservers-and-DNSSEC-for-Squarespace-managed-domains#toc-dnssec)\n* [Registro.br](https://registro.br/tecnologia/dnssec/?secao=tutoriais-dns)\n* [Porkbun](https://kb.porkbun.com/article/93-how-to-install-dnssec) (do not fill out **keyData**)\n* [TransIP](https://www.transip.eu/knowledgebase/150-secure-domains-custom-nameservers-dnssec/)\n\nFor more help, refer to [Enabling DNSSEC in Cloudflare](https://developers.cloudflare.com/dns/dnssec/).\n\n***\n\n## What happens when I remove the `DS` record?\n\nWhen you remove your DS record, an invalidation process begins which results in the unsigning of your domain’s DNS records. This will allow your authoritative nameservers to be changed. If you are an existing customer, this will not affect your ability to use Cloudflare. New customers will need to complete this step before Cloudflare can be used successfully.\n\n***\n\n## Does Cloudflare support EDNS0 (extension mechanisms for DNS)?\n\nYes, Cloudflare DNS supports EDNS0. EDNS0 is enabled for all Cloudflare customers. It is a building block for modern DNS implementations that adds support for signaling if the DNS Resolver (recursive DNS provider) supports larger message sizes and DNSSEC.\n\nEDNS0 is the first approved set of mechanisms for [DNS extensions](http://en.wikipedia.org/wiki/Extension_mechanisms_for_DNS), originally published as [RFC 2671](https://datatracker.ietf.org/doc/html/rfc2671).\n\n***\n\n## What should I do if I change my server IP address or hosting provider?\n\nAfter switching hosting providers or server IP addresses, update the IP addresses in your Cloudflare **DNS** app. Your new hosting provider will provide the new IP addresses that your DNS should use.  To modify DNS record content in the **DNS** app, click on the IP address, and enter the new IP address.\n\n***\n\n## Where can I find my Cloudflare nameservers?\n\nUnder the **DNS** app of your Cloudflare account, review the **Cloudflare Nameservers**.\n\nThe IP address associated with a specific Cloudflare nameserver can be retrieved via a dig command or a third-party DNS lookup tool hosted online such as [whatsmydns.net](https://www.whatsmydns.net/):",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "***\n\n## Why are Cloudflare's A or AAAA records / IP addresses for my domain's DNS responses appearing?\n\nFor DNS records proxied to Cloudflare, Cloudflare's IP addresses are returned in DNS queries instead of your original server IP address. This allows Cloudflare to optimize, cache, and protect all requests for your website.\n\n***\n\n## Can subdomains be added directly to Cloudflare?\n\nOnly Enterprise customers can add subdomains directly to Cloudflare via [Subdomain Support](https://developers.cloudflare.com/dns/zone-setups/subdomain-setup/).\n\n***\n\n## 403 Authentication error when creating DNS records using Terraform\n\n**Problem Description**\n\n`Error: failed to create DNS record: HTTP status 403: Authentication error (10000)` is returned when using Terraform with Cloudflare API.\n\n**Root Cause**\n\nError seems to be misleading, as the error was found to be in customer code syntax, specifically: zone\\_id = data.cloudflare\\_zones.example\\_com.id\n\n**Solution**\n\nMake sure the argument `zone_id = data.cloudflare_zones.example_com.zones[0].id`. A more detailed use case can be found in [this](https://github.com/cloudflare/terraform-provider-cloudflare/issues/913) GitHub thread.\n\n***\n\n## Why am I getting hundreds of random DNS records after adding my domain?\n\nThis can happen when you had a wildcard `*` record configured at your previous authoritative DNS, and for some reason the wildcard record wasn't detected. You can remove these records in bulk [using the API](https://developers.cloudflare.com/api/resources/dns/subresources/records/methods/delete/).\n\nAlternatively, you can also:\n\n1. [Remove your domain](https://developers.cloudflare.com/fundamentals/manage-domains/remove-domain/) from Cloudflare.\n2. Delete the wildcard record from your authoritative DNS.\n3. [Re-add](https://developers.cloudflare.com/fundamentals/manage-domains/add-site/) the domain.\n\n***\n\n## What IP should I use for parked domain / redirect-only / originless setup?\n\nIn the case a placeholder address is needed for “originless” setups, use the IPv6 reserved address `100::` or the IPv4 reserved address `192.0.2.0` in your Cloudflare DNS to create a [proxied DNS record](https://developers.cloudflare.com/dns/proxy-status/) that can use Cloudflare [Redirect Rules](https://developers.cloudflare.com/rules/url-forwarding/), [Page Rules](https://developers.cloudflare.com/rules/page-rules/), or [Cloudflare Workers](https://developers.cloudflare.com/workers/).\n\n***\n\n## Why are DNS queries returning incorrect results?\n\nThird-party tools can sometimes fail to return correct DNS results if a recursive DNS cache fails to refresh. In this circumstance, purge your public DNS cache via these methods:\n\n* [Purging your DNS cache at OpenDNS](http://www.opendns.com/support/cache/)\n* [Purging your DNS cache at Google](https://developers.google.com/speed/public-dns/cache)\n* [Purging your DNS cache locally](https://docs.cpanel.net/knowledge-base/dns/how-to-clear-your-dns-cache/)\n\n***\n\n## Why have I received an email: Your Name Servers have Changed?\n\nFor domains where Cloudflare hosts the DNS, Cloudflare continuously checks whether the domain uses Cloudflare’s nameservers for DNS resolution. If Cloudflare's nameservers are not used, the [domain status](https://developers.cloudflare.com/dns/zone-setups/reference/domain-status/) is updated from *Active* to *Moved* in the Cloudflare **Overview** app and an email is sent to the customer.\n\nThis is important because, if a domain is in a *Moved* state for a [long enough period of time](https://developers.cloudflare.com/dns/zone-setups/reference/domain-status/), it will be deleted from Cloudflare.\n\nTo recover a deleted domain, [re-add it in Cloudflare](https://developers.cloudflare.com/fundamentals/manage-domains/add-site/) just like you would for a new domain.\n\nWarning\n\nCloudflare support is unable to restore DNS or settings for deleted domains.\n\n***\n\n## Why am I getting a warning for hostname not covered even if I have a custom certificate?\n\nIf the [custom certificate](https://developers.cloudflare.com/ssl/edge-certificates/custom-certificates/) has been in place before our new certificate management pipeline, the following warning is displayed but can be discarded. `This hostname is not covered by a certificate.`\n\nThe warning will be gone when you upload a new custom certificate, or start using another type of certificate for this hostname.\n\n***\n\n## I've updated my CNAME to a new SaaS provider, but I still see content from the old provider\n\nWhen a SaaS provider is leveraging our [Cloudflare for SaaS](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/) solution, they create a [Custom Hostname](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/domain-support/) on their Cloudflare zone. Then a [CNAME record needs to be created](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/saas-customers/how-it-works/) on the client zone, to point to the SaaS provider service. When changing SaaS providers, if the old SaaS provider provisioned a specific custom hostname for the record (`mystore.example.com`) and the new SaaS provider provisioned a wildcard custom hostname (`*.example.com`), the old custom hostname will still take precedence. This is expected as per the [Certificate and hostname priority](https://developers.cloudflare.com/ssl/reference/certificate-and-hostname-priority/#hostname-priority).\n\nIn this case there are 2 ways forward:\n\n* (*Recommended*) Ask the new SaaS provider to provision a specific custom hostname for you instead of the wildcard (`mystore.example.com` instead of `*.example.com`).\n* Ask the Super Administrator of your account to contact [Cloudflare Support](https://developers.cloudflare.com/support/contacting-cloudflare-support/) to request an update of the SaaS configuration.\n\n</page>\n\n<page>\n---\ntitle: DNS setup conversions · Cloudflare DNS docs\ndescription: \"You can perform the following DNS setup conversions:\"\nlastUpdated: 2025-01-14T14:12:46.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/dns/zone-setups/conversions/\n  md: https://developers.cloudflare.com/dns/zone-setups/conversions/index.md\n---\n\nYou can perform the following DNS setup conversions:\n\n* [Convert full setup to partial setup](https://developers.cloudflare.com/dns/zone-setups/conversions/convert-full-to-partial/)\n* [Convert full setup to secondary setup](https://developers.cloudflare.com/dns/zone-setups/conversions/convert-full-to-secondary/)\n* [Convert partial setup to full setup](https://developers.cloudflare.com/dns/zone-setups/conversions/convert-partial-to-full/)\n* [Convert partial setup to secondary setup](https://developers.cloudflare.com/dns/zone-setups/conversions/convert-partial-to-secondary/)\n* [Convert secondary setup to full setup](https://developers.cloudflare.com/dns/zone-setups/conversions/convert-secondary-to-full/)\n* [Convert secondary setup to partial setup](https://developers.cloudflare.com/dns/zone-setups/conversions/convert-secondary-to-partial/)\n\n</page>\n\n<page>\n---\ntitle: Partial (CNAME) setup · Cloudflare DNS docs\ndescription: A partial (CNAME) setup allows you to use Cloudflare's reverse\n  proxy while maintaining your primary and authoritative DNS provider.\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/zone-setups/partial-setup/\n  md: https://developers.cloudflare.com/dns/zone-setups/partial-setup/index.md\n---\n\nA partial (CNAME) setup allows you to use [Cloudflare's reverse proxy](https://developers.cloudflare.com/fundamentals/concepts/how-cloudflare-works/) while maintaining your primary and authoritative DNS provider.\n\nUse this option to proxy only individual subdomains through Cloudflare when you cannot change your authoritative DNS provider. You will be able to create A, AAAA, and CNAME records, which are the DNS record types that can be [proxied](https://developers.cloudflare.com/dns/proxy-status/).\n\nOnce you are on a partial setup, the actual resolution of your records to Cloudflare depends on CNAME records [added at your authoritative DNS provider](https://developers.cloudflare.com/dns/zone-setups/partial-setup/setup/#3-add-dns-records). Check your authoritative DNS provider to know which records are pointing to `{your-hostname}.cdn.cloudflare.net`.\n\n## How to\n\n* [Set up a partial domain](https://developers.cloudflare.com/dns/zone-setups/partial-setup/setup/)\n* [Convert a partial setup to a full setup](https://developers.cloudflare.com/dns/zone-setups/conversions/convert-partial-to-full/)\n* [Convert a partial setup to a secondary setup](https://developers.cloudflare.com/dns/zone-setups/conversions/convert-partial-to-secondary/)\n* [Create DNS records of other types](https://developers.cloudflare.com/dns/zone-setups/partial-setup/setup/#other-record-types)\n\n## Availability\n\n| | Free | Pro | Business | Enterprise |\n| - | - | - | - | - |\n| Availability | No | No | Yes | Yes |\n\n## Reference\n\n### DNS resolution\n\nWith a partial zone, Cloudflare resolves [DNS records differently](https://developers.cloudflare.com/dns/zone-setups/partial-setup/dns-resolution/) than for full zones.\n\n### CNAME flattening\n\nA partial (CNAME) setup requires the proxied hostname to be pointed to Cloudflare via a CNAME record. Since [CNAME records are not allowed on the zone apex](https://datatracker.ietf.org/doc/html/rfc1912#section-2.4) (`example.com`), you can only proxy your zone apex to Cloudflare if your authoritative DNS provider supports [CNAME Flattening](https://blog.cloudflare.com/introducing-cname-flattening-rfc-compliant-cnames-at-a-domains-root/).\n\nIf your authoritative DNS provider does not support CNAME Flattening, redirect its traffic — for example, with an `.htaccess` file — to a subdomain proxied to Cloudflare. Alternatively, you can use [static IPs or BYOIPs](https://developers.cloudflare.com/fundamentals/concepts/cloudflare-ip-addresses/#customize-cloudflare-ip-addresses).\n\n### DDoS protection\n\n[DDoS protection](https://developers.cloudflare.com/ddos-protection/) for attacks against DNS infrastructure is only available for domains on [full setup](https://developers.cloudflare.com/dns/zone-setups/full-setup/). Domains on the partial setup are not using Cloudflare authoritative nameservers.\n\n### Domain ownership\n\nEnterprise customers can use [zone holds](https://developers.cloudflare.com/fundamentals/account/account-security/zone-holds/) to prevent other teams in the organization from adding zones that are already active in another Cloudflare account. For partial setups, if the same zone is added to different accounts, the last account to complete the setup will gain ownership.\n\n</page>\n\n<page>\n---\ntitle: Full setup · Cloudflare DNS docs\ndescription: If you want to use Cloudflare as your primary DNS provider and\n  manage your DNS records on Cloudflare, your domain should be using a full\n  setup.\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/zone-setups/full-setup/\n  md: https://developers.cloudflare.com/dns/zone-setups/full-setup/index.md\n---\n\nIf you want to use Cloudflare as your primary DNS provider and manage your DNS records on Cloudflare, your domain should be using a full setup.\n\nThis means that you are using Cloudflare for your authoritative DNS nameservers.\n\n## How to\n\nFor more details, refer to [Set up a full domain](https://developers.cloudflare.com/dns/zone-setups/full-setup/setup/).\n\n## Availability\n\n| | Free | Pro | Business | Enterprise |\n| - | - | - | - | - |\n| Availability | Yes | Yes | Yes | Yes |\n\n</page>\n\n<page>\n---\ntitle: Reference — DNS zone setups · Cloudflare DNS docs\nlastUpdated: 2025-01-14T14:12:46.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/dns/zone-setups/reference/\n  md: https://developers.cloudflare.com/dns/zone-setups/reference/index.md\n---\n\n* [Records quick scan](https://developers.cloudflare.com/dns/zone-setups/reference/dns-quick-scan/)\n* [Zone status](https://developers.cloudflare.com/dns/zone-setups/reference/domain-status/)\n\n</page>\n\n<page>\n---\ntitle: Zone removal · Cloudflare DNS docs\ndescription: If domains on Free zones remain in the Pending or Moved status for\n  too long, Cloudflare automatically removes them from your account and the\n  Cloudflare network. Refer to zone statuses for more details.\nlastUpdated: 2025-05-29T18:16:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/zone-setups/removal/\n  md: https://developers.cloudflare.com/dns/zone-setups/removal/index.md\n---\n\nIf domains on Free zones remain in the [Pending](https://developers.cloudflare.com/dns/zone-setups/reference/domain-status/#pending) or [Moved](https://developers.cloudflare.com/dns/zone-setups/reference/domain-status/#moved) status for too long, Cloudflare automatically removes them from your account and the Cloudflare network. Refer to [zone statuses](https://developers.cloudflare.com/dns/zone-setups/reference/domain-status/) for more details.\n\nYou can also [manually remove a domain](https://developers.cloudflare.com/fundamentals/manage-domains/remove-domain/) from Cloudflare.\n\nIf you need to re-add a domain to your account, follow the [regular onboarding flow](https://developers.cloudflare.com/fundamentals/manage-domains/add-site/).\n\nPurged zones\n\nBy default, your zone will be automatically purged seven days after the removal. In this case, even if you re-add the domain to the same Cloudflare account, none of the zone settings are expected to be restored. Refer to [zone statuses](https://developers.cloudflare.com/dns/zone-setups/reference/domain-status/) for more details.\n\n</page>\n\n<page>\n---\ntitle: Troubleshooting — DNS setups · Cloudflare DNS docs\nlastUpdated: 2025-01-14T14:12:46.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/dns/zone-setups/troubleshooting/\n  md: https://developers.cloudflare.com/dns/zone-setups/troubleshooting/index.md\n---\n\n* [Cannot add domain](https://developers.cloudflare.com/dns/zone-setups/troubleshooting/cannot-add-domain/)\n* [Delete all DNS records](https://developers.cloudflare.com/dns/zone-setups/troubleshooting/delete-all-records/)\n* [Domain deleted from Cloudflare](https://developers.cloudflare.com/dns/zone-setups/troubleshooting/domain-deleted/)\n\n</page>\n\n<page>\n---\ntitle: Subdomain setup · Cloudflare DNS docs\ndescription: When you use a subdomain setup, you can manage the Cloudflare\n  configurations for one or more subdomains separately from those associated\n  with your apex domain. This means that, on your account homepage, you would\n  find websites like example.com or blog.example.com listed as separate zones.\nlastUpdated: 2025-12-03T10:55:22.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/zone-setups/subdomain-setup/\n  md: https://developers.cloudflare.com/dns/zone-setups/subdomain-setup/index.md\n---\n\nWhen you use a subdomain setup, you can manage the [Cloudflare configurations](https://developers.cloudflare.com/fundamentals/concepts/how-cloudflare-works/) for one or more subdomains separately from those associated with your apex domain. This means that, on your [account homepage](https://dash.cloudflare.com/?to=/:account/), you would find websites like `example.com` or `blog.example.com` listed as separate zones.\n\nNote\n\nThis is different from simply creating a subdomain for a site you already have in Cloudflare. If you do not need separate Cloudflare configuration for your subdomain, refer to [Create a subdomain record](https://developers.cloudflare.com/dns/manage-dns-records/how-to/create-subdomain/).\n\nYou might use this setup when you want to share access to a specific subdomain's settings with different teams, but have stricter controls on your apex domain. For example, a subdomain setup could allow your documentation team to manage the Cloudflare configuration for `docs.example.com`, while preventing them from adjusting any settings on `example.com`.\n\nSubdomain setups are also useful when different subdomains require entirely different settings. For example, you may have different requirements for `docs.example.com`, `blog.example.com`, and `community.example.com`.\n\n## Availability\n\n| | Free | Pro | Business | Enterprise |\n| - | - | - | - | - |\n| Availability | No | No | No | Yes |\n\nSetup combinations\n\nThe availability of different setups depends on both the parent zone setup and the setup used for the child zone. Review the [available setups](https://developers.cloudflare.com/dns/zone-setups/subdomain-setup/setup/#available-setups) to understand what combinations are supported.\n\n### Access applications\n\nTo use subdomain setups with [Cloudflare Access](https://developers.cloudflare.com/cloudflare-one/access-controls/policies/), note that:\n\n* If the child zone is in a pending state when you create the Access application, your configuration will not automatically apply when you activate the zone. You must also re-save the Access application once your subdomain setup is active.\n\n* If you split out a subdomain which already has an Access application, you will also need to re-save the Access application to associate it with the new child zone.\n\n## Resources\n\n* [Setup](https://developers.cloudflare.com/dns/zone-setups/subdomain-setup/setup/)\n* [Enable DNSSEC](https://developers.cloudflare.com/dns/zone-setups/subdomain-setup/dnssec/)\n* [Migrate to new account](https://developers.cloudflare.com/dns/zone-setups/subdomain-setup/move-to-new-account/)\n* [Rollback](https://developers.cloudflare.com/dns/zone-setups/subdomain-setup/rollback/)\n\n</page>\n\n<page>\n---\ntitle: Zone transfers - Multi-provider DNS · Cloudflare DNS docs\ndescription: To increase availability and fault tolerance, you can use one or\n  more DNS provider(s) alongside Cloudflare in case one provider becomes\n  unavailable (known as a peer DNS server). Your providers will then transfer\n  DNS records between themselves using authoritative (AXFR) or incremental\n  (IXFR) zone transfers.\nlastUpdated: 2025-09-04T10:36:01.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/dns/zone-setups/zone-transfers/\n  md: https://developers.cloudflare.com/dns/zone-setups/zone-transfers/index.md\n---\n\nTo increase availability and fault tolerance, you can use one or more DNS provider(s) alongside Cloudflare in case one provider becomes unavailable (known as a [peer DNS server](#peer-dns-server)). Your providers will then transfer DNS records between themselves using authoritative ([AXFR](https://datatracker.ietf.org/doc/html/rfc5936)) or incremental ([IXFR](https://datatracker.ietf.org/doc/html/rfc1995)) zone transfers.\n\nWith AXFR, the entire zone will be transferred from the primary to the secondary provider, even if only one record changes. With IXFR, only the changes will be transferred. Cloudflare supports both protocols.\n\nWith zone transfers, you have two configuration options:\n\n* [Cloudflare as Primary](https://developers.cloudflare.com/dns/zone-setups/zone-transfers/cloudflare-as-primary/): Cloudflare is your primary DNS provider and performs outgoing zone transfers to your secondary DNS provider(s).\n* [Cloudflare as Secondary](https://developers.cloudflare.com/dns/zone-setups/zone-transfers/cloudflare-as-secondary/): Cloudflare is your secondary DNS provider and initiates incoming zone transfers from your primary DNS provider.\n\n## Peer DNS server\n\nPeer DNS servers can be used as primary and secondary external DNS servers. The same peer can be linked to multiple primary and secondary zones. Each peer can be associated with only one Transaction Signature (TSIG).\n\nThe maximum number of linked peers per zone is 30.\n\nYou can manage peers via the [API](https://developers.cloudflare.com/api/resources/dns/subresources/zone_transfers/subresources/peers/methods/list/) or the dashboard:\n\n1. In the Cloudflare dashboard, go to the account **Settings** page.\n\n   [Go to **Settings**](https://dash.cloudflare.com/?to=/:account/configurations)\n\n2. Refer to **DNS Settings** > **DNS Zone Transfers**.\n\nDepending on the usage of the peer, the fields are interpreted in a different way:\n\n| Field | Cloudflare as Primary (Outgoing) | Cloudflare as Secondary (Incoming) |\n| - | - | - |\n| Name | Human readable name of peer | Human readable name of peer |\n| IP | If configured, where Cloudflare sends the NOTIFY to | Where Cloudflare sends the AXFR/IXFR transfer request to |\n| Port | IP Port for NOTIFY IP | IP Port for transfer IP |\n| TSIG ID | Attached TSIG object | Attached TSIG object |\n| IXFR enabled | Cloudflare always supports IXFR for outgoing zone transfers | Specifies if Cloudflare only sends AXFR or AXFR and IXFR |\n\n## Availability\n\nZone transfers are only available to customers on an Enterprise plan.\n\n</page>\n\n<page>\n---\ntitle: Alarms · Cloudflare Durable Objects docs\ndescription: Durable Objects alarms allow you to schedule the Durable Object to\n  be woken up at a time in the future. When the alarm's scheduled time comes,\n  the alarm() handler method will be called. Alarms are modified using the\n  Storage API, and alarm operations follow the same rules as other storage\n  operations.\nlastUpdated: 2025-12-18T18:32:26.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/api/alarms/\n  md: https://developers.cloudflare.com/durable-objects/api/alarms/index.md\n---\n\n## Background\n\nDurable Objects alarms allow you to schedule the Durable Object to be woken up at a time in the future. When the alarm's scheduled time comes, the `alarm()` handler method will be called. Alarms are modified using the Storage API, and alarm operations follow the same rules as other storage operations.\n\nNotably:\n\n* Each Durable Object is able to schedule a single alarm at a time by calling `setAlarm()`.\n* Alarms have guaranteed at-least-once execution and are retried automatically when the `alarm()` handler throws.\n* Retries are performed using exponential backoff starting at a 2 second delay from the first failure with up to 6 retries allowed.\n\nHow are alarms different from Cron Triggers?\n\nAlarms are more fine grained than [Cron Triggers](https://developers.cloudflare.com/workers/configuration/cron-triggers/). A Worker can have up to three Cron Triggers configured at once, but it can have an unlimited amount of Durable Objects, each of which can have an alarm set.\n\nAlarms are directly scheduled from within your Durable Object. Cron Triggers, on the other hand, are not programmatic. [Cron Triggers](https://developers.cloudflare.com/workers/configuration/cron-triggers/) execute based on their schedules, which have to be configured through the Cloudflare dashboard or API.\n\nAlarms can be used to build distributed primitives, like queues or batching of work atop Durable Objects. Alarms also provide a mechanism to guarantee that operations within a Durable Object will complete without relying on incoming requests to keep the Durable Object alive. For a complete example, refer to [Use the Alarms API](https://developers.cloudflare.com/durable-objects/examples/alarms-api/).\n\n## Scheduling multiple events with a single alarm\n\nAlthough each Durable Object can only have one alarm set at a time, you can manage many scheduled and recurring events by storing your event schedule in storage and having the `alarm()` handler process due events, then reschedule itself for the next one.",
      "language": "unknown"
    },
    {
      "code": "## Storage methods\n\n### `getAlarm`\n\n* `getAlarm()`: number | null\n\n  * If there is an alarm set, then return the currently set alarm time as the number of milliseconds elapsed since the UNIX epoch. Otherwise, return `null`.\n\n  * If `getAlarm` is called while an [`alarm`](https://developers.cloudflare.com/durable-objects/api/alarms/#alarm) is already running, it returns `null` unless `setAlarm` has also been called since the alarm handler started running.\n\n### `setAlarm`\n\n* `setAlarm(scheduledTimeMs number) `: void\n\n  * Set the time for the alarm to run. Specify the time as the number of milliseconds elapsed since the UNIX epoch.\n  * If you call `setAlarm` when there is already one scheduled, it will override the existing alarm.\n\nCalling `setAlarm` inside the constructor\n\nIf you wish to call `setAlarm` inside the constructor of a Durable Object, ensure that you are first checking whether an alarm has already been set.\n\nThis is due to the fact that, if the Durable Object wakes up after being inactive, the constructor is invoked before the [`alarm` handler](https://developers.cloudflare.com/durable-objects/api/alarms/#alarm). Therefore, if the constructor calls `setAlarm`, it could interfere with the next alarm which has already been set.\n\n### `deleteAlarm`\n\n* `deleteAlarm()`: void\n\n  * Unset the alarm if there is a currently set alarm.\n\n  * Calling `deleteAlarm()` inside the `alarm()` handler may prevent retries on a best-effort basis, but is not guaranteed.\n\n## Handler methods\n\n### `alarm`\n\n* `alarm(alarmInfo Object)`: void\n\n  * Called by the system when a scheduled alarm time is reached.\n\n  * The optional parameter `alarmInfo` object has two properties:\n\n    * `retryCount` number: The number of times this alarm event has been retried.\n    * `isRetry` boolean: A boolean value to indicate if the alarm has been retried. This value is `true` if this alarm event is a retry.\n\n  * Only one instance of `alarm()` will ever run at a given time per Durable Object instance.\n\n  * The `alarm()` handler has guaranteed at-least-once execution and will be retried upon failure using exponential backoff, starting at 2 second delays for up to 6 retries. This only applies to the most recent `setAlarm()` call. Retries will be performed if the method fails with an uncaught exception.\n\n  * This method can be `async`.\n\n## Example\n\nThis example shows how to both set alarms with the `setAlarm(timestamp)` method and handle alarms with the `alarm()` handler within your Durable Object.\n\n* The `alarm()` handler will be called once every time an alarm fires.\n* If an unexpected error terminates the Durable Object, the `alarm()` handler may be re-instantiated on another machine.\n* Following a short delay, the `alarm()` handler will run from the beginning on the other machine.\n\n- JavaScript",
      "language": "unknown"
    },
    {
      "code": "- Python",
      "language": "unknown"
    },
    {
      "code": "The following example shows how to use the `alarmInfo` property to identify if the alarm event has been attempted before.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "## Related resources\n\n* Understand how to [use the Alarms API](https://developers.cloudflare.com/durable-objects/examples/alarms-api/) in an end-to-end example.\n* Read the [Durable Objects alarms announcement blog post](https://blog.cloudflare.com/durable-objects-alarms/).\n* Review the [Storage API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/) documentation for Durable Objects.\n\n</page>\n\n<page>\n---\ntitle: Durable Object Base Class · Cloudflare Durable Objects docs\ndescription: The DurableObject base class is an abstract class which all Durable\n  Objects inherit from. This base class provides a set of optional methods,\n  frequently referred to as handler methods, which can respond to events, for\n  example a webSocketMessage when using the WebSocket Hibernation API. To\n  provide a concrete example, here is a Durable Object MyDurableObject which\n  extends DurableObject and implements the fetch handler to return \"Hello,\n  World!\" to the calling Worker.\nlastUpdated: 2025-12-08T15:50:53.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/api/base/\n  md: https://developers.cloudflare.com/durable-objects/api/base/index.md\n---\n\nThe `DurableObject` base class is an abstract class which all Durable Objects inherit from. This base class provides a set of optional methods, frequently referred to as handler methods, which can respond to events, for example a webSocketMessage when using the [WebSocket Hibernation API](https://developers.cloudflare.com/durable-objects/best-practices/websockets/#websocket-hibernation-api). To provide a concrete example, here is a Durable Object `MyDurableObject` which extends `DurableObject` and implements the fetch handler to return \"Hello, World!\" to the calling Worker.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "## Methods\n\n### `fetch`\n\n* `fetch(Request)`: Response | Promise \\<Response>\n\n  * Takes an HTTP request object and returns an HTTP response object. This method allows the Durable Object to emulate an HTTP server where a Worker with a binding to that object is the client.\n\n  * This method can be `async`.\n\n  * Durable Objects support [RPC calls](https://developers.cloudflare.com/durable-objects/best-practices/create-durable-object-stubs-and-send-requests/) as of a compatibility date greater or equal to [2024-04-03](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#durable-object-stubs-and-service-bindings-support-rpc). Users should call RPC methods over `fetch()` if their application design does not follow HTTP request/response flow.\n\n### `alarm`\n\n* `alarm(alarmInfoObject)`: Promise \\<void>\n\n  * Called by the system when a scheduled alarm time is reached.\n\n  * The optional parameter `alarmInfo` object has two properties:\n\n    * `retryCount` number: The number of times this alarm event has been retried.\n    * `isRetry` boolean: A boolean value to indicate if the alarm has been retried. This value is `true` if this alarm event is a retry.\n\n  * The `alarm()` handler has guaranteed at-least-once execution and will be retried upon failure using exponential backoff, starting at two second delays for up to six retries. Retries will be performed if the method fails with an uncaught exception.\n\n  * This method can be `async`.\n\n  * Refer to [`alarm`](https://developers.cloudflare.com/durable-objects/api/alarms/#alarm) for more information.\n\n### `webSocketMessage`\n\n* `webSocketMessage(ws WebSocket, message string | ArrayBuffer)`: void\n\n  * Called by the system when an accepted WebSocket receives a message.\n\n  * This method can be `async`.\n\n  * This method is not called for WebSocket control frames. The system will respond to an incoming [WebSocket protocol ping](https://www.rfc-editor.org/rfc/rfc6455#section-5.5.2) automatically without interrupting hibernation.\n\n### `webSocketClose`\n\n* `webSocketClose(ws WebSocket, code number, reason string, wasClean boolean)`: void\n\n  * Called by the system when a WebSocket is closed. `wasClean()` is true if the connection closed cleanly, false otherwise.\n\n  * This method can be `async`.\n\n### `webSocketError`\n\n* `webSocketError(ws WebSocket, error any)` : void\n\n  * Called by the system when any non-disconnection related errors occur.\n\n  * This method can be `async`.\n\n## Properties\n\n### `DurableObjectState`\n\nSee [`DurableObjectState` documentation](https://developers.cloudflare.com/durable-objects/api/state/).\n\n### `Env`\n\nA list of bindings which are available to the Durable Object.\n\n## Related resources\n\n* Refer to [Use WebSockets](https://developers.cloudflare.com/durable-objects/best-practices/websockets/) for more information on examples of WebSocket methods and best practices.\n\n</page>\n\n<page>\n---\ntitle: Durable Object Container · Cloudflare Durable Objects docs\ndescription: >-\n  When using a Container-enabled Durable Object, you can access the Durable\n  Object's associated container via\n\n  the container object which is on the ctx property. This allows you to start,\n  stop, and interact with the container.\nlastUpdated: 2025-12-08T15:50:53.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/api/container/\n  md: https://developers.cloudflare.com/durable-objects/api/container/index.md\n---\n\n## Description\n\nWhen using a [Container-enabled Durable Object](https://developers.cloudflare.com/containers), you can access the Durable Object's associated container via the `container` object which is on the `ctx` property. This allows you to start, stop, and interact with the container.\n\nNote\n\nIt is likely preferable to use the official `Container` class, which provides helper methods and a more idiomatic API for working with containers on top of Durable Objects.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "## Attributes\n\n### `running`\n\n`running` returns `true` if the container is currently running. It does not ensure that the container has fully started and ready to accept requests.",
      "language": "unknown"
    },
    {
      "code": "## Methods\n\n### `start`\n\n`start` boots a container. This method does not block until the container is fully started. You may want to confirm the container is ready to accept requests before using it.",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* `options` (optional): An object with the following properties:\n\n  * `env`: An object containing environment variables to pass to the container. This is useful for passing configuration values or secrets to the container.\n  * `entrypoint`: An array of strings representing the command to run in the container.\n  * `enableInternet`: A boolean indicating whether to enable internet access for the container.\n\n#### Return values\n\n* None.\n\n### `destroy`\n\n`destroy` stops the container and optionally returns a custom error message to the `monitor()` error callback.",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* `error` (optional): A string that will be sent to the error handler of the `monitor` method. This is useful for logging or debugging purposes.\n\n#### Return values\n\n* A promise that returns once the container is destroyed.\n\n### `signal`\n\n`signal` sends an IPC signal to the container, such as SIGKILL or SIGTERM. This is useful for stopping the container gracefully or forcefully.",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* `signal`: a number representing the signal to send to the container. This is typically a POSIX signal number, such as SIGTERM (15) or SIGKILL (9).\n\n#### Return values\n\n* None.\n\n### `getTcpPort`\n\n`getTcpPort` returns a TCP port from the container. This can be used to communicate with the container over TCP and HTTP.",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* `port` (number): a TCP port number to use for communication with the container.\n\n#### Return values\n\n* `TcpPort`: a `TcpPort` object representing the TCP port. This object can be used to send requests to the container over TCP and HTTP.\n\n### `monitor`\n\n`monitor` returns a promise that resolves when a container exits and errors if a container errors. This is useful for setting up callbacks to handle container status changes in your Workers code.",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* None\n\n#### Return values\n\n* A promise that resolves when the container exits.\n\n## Related resources\n\n* [Containers](https://developers.cloudflare.com/containers)\n* [Get Started With Containers](https://developers.cloudflare.com/containers/get-started)\n\n</page>\n\n<page>\n---\ntitle: Durable Object ID · Cloudflare Durable Objects docs\ndescription: A Durable Object ID is a 64-digit hexadecimal number used to\n  identify a Durable Object. Not all 64-digit hex numbers are valid IDs. Durable\n  Object IDs are constructed indirectly via the DurableObjectNamespace\n  interface.\nlastUpdated: 2025-12-08T15:50:53.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/api/id/\n  md: https://developers.cloudflare.com/durable-objects/api/id/index.md\n---\n\n## Description\n\nA Durable Object ID is a 64-digit hexadecimal number used to identify a Durable Object. Not all 64-digit hex numbers are valid IDs. Durable Object IDs are constructed indirectly via the [`DurableObjectNamespace`](https://developers.cloudflare.com/durable-objects/api/namespace) interface.\n\nThe `DurableObjectId` interface refers to a new or existing Durable Object. This interface is most frequently used by [`DurableObjectNamespace::get`](https://developers.cloudflare.com/durable-objects/api/namespace/#get) to obtain a [`DurableObjectStub`](https://developers.cloudflare.com/durable-objects/api/stub) for submitting requests to a Durable Object. Note that creating an ID for a Durable Object does not create the Durable Object. The Durable Object is created lazily after creating a stub from a `DurableObjectId`. This ensures that objects are not constructed until they are actually accessed.\n\nLogging\n\nIf you are experiencing an issue with a particular Durable Object, you may wish to log the `DurableObjectId` from your Worker and include it in your Cloudflare support request.\n\n## Methods\n\n### `toString`\n\n`toString` converts a `DurableObjectId` to a 64 digit hex string. This string is useful for logging purposes or storing the `DurableObjectId` elsewhere, for example, in a session cookie. This string can be used to reconstruct a `DurableObjectId` via `DurableObjectNamespace::idFromString`.",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* None.\n\n#### Return values\n\n* A 64 digit hex string.\n\n### `equals`\n\n`equals` is used to compare equality between two instances of `DurableObjectId`.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* A required `DurableObjectId` to compare against.\n\n#### Return values\n\n* A boolean. True if equal and false otherwise.\n\n## Properties\n\n### `name`\n\n`name` is an optional property of a `DurableObjectId`, which returns the name that was used to create the `DurableObjectId` via [`DurableObjectNamespace::idFromName`](https://developers.cloudflare.com/durable-objects/api/namespace/#idfromname). This value is undefined if the `DurableObjectId` was constructed using [`DurableObjectNamespace::newUniqueId`](https://developers.cloudflare.com/durable-objects/api/namespace/#newuniqueid). This value is also undefined within the `ctx.id` passed into the Durable Object constructor (refer to [GitHub issue](https://github.com/cloudflare/workerd/issues/2240) for discussion).\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "## Related resources\n\n* [Durable Objects: Easy, Fast, Correct – Choose Three](https://blog.cloudflare.com/durable-objects-easy-fast-correct-choose-three/).\n\n</page>\n\n<page>\n---\ntitle: KV-backed Durable Object Storage (Legacy) · Cloudflare Durable Objects docs\ndescription: The Durable Object Storage API allows Durable Objects to access\n  transactional and strongly consistent storage. A Durable Object's attached\n  storage is private to its unique instance and cannot be accessed by other\n  objects.\nlastUpdated: 2025-12-08T15:50:53.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/api/legacy-kv-storage-api/\n  md: https://developers.cloudflare.com/durable-objects/api/legacy-kv-storage-api/index.md\n---\n\nNote\n\nThis page documents the storage API for legacy KV-backed Durable Objects.\n\nFor the newer SQLite-backed Durable Object storage API, refer to [SQLite-backed Durable Object Storage](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api).\n\nThe Durable Object Storage API allows Durable Objects to access transactional and strongly consistent storage. A Durable Object's attached storage is private to its unique instance and cannot be accessed by other objects.\n\nThe Durable Object Storage API comes with several methods, including SQL, point-in-time recovery (PITR), key-value (KV), and alarm APIs. Available API methods depend on the storage backend for a Durable Objects class, either [SQLite](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#create-sqlite-backed-durable-object-class) or [KV](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/#create-durable-object-class-with-key-value-storage).\n\n| Methods 1 | SQLite-backed Durable Object class | KV-backed Durable Object class |\n| - | - | - |\n| SQL API | ✅ | ❌ |\n| PITR API | ✅ | ❌ |\n| Synchronous KV API | ✅ 2, 3 | ❌ |\n| Asynchronous KV API | ✅ 3 | ✅ |\n| Alarms API | ✅ | ✅ |\n\nFootnotes\n\n1 Each method is implicitly wrapped inside a transaction, such that its results are atomic and isolated from all other storage operations, even when accessing multiple key-value pairs.\n\n2 KV API methods like `get()`, `put()`, `delete()`, or `list()` store data in a hidden SQLite table `__cf_kv`. Note that you will be able to view this table when listing all tables, but you will not be able to access its content through the SQL API.\n\n3 SQLite-backed Durable Objects also use [synchronous KV API methods](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#synchronous-kv-api) using `ctx.storage.kv`, whereas KV-backed Durable Objects only provide [asynchronous KV API methods](https://developers.cloudflare.com/durable-objects/api/legacy-kv-storage-api/#asynchronous-kv-api).\n\nRecommended SQLite-backed Durable Objects\n\nCloudflare recommends all new Durable Object namespaces use the [SQLite storage backend](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#create-sqlite-backed-durable-object-class). These Durable Objects can continue to use storage [key-value API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#synchronous-kv-api).\n\nAdditionally, SQLite-backed Durable Objects allow you to store more types of data (such as tables), and offer Point In Time Recovery API which can restore a Durable Object's embedded SQLite database contents (both SQL data and key-value data) to any point in the past 30 days.\n\nThe [key-value storage backend](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/#create-durable-object-class-with-key-value-storage) remains for backwards compatibility, and a migration path from KV storage backend to SQLite storage backend for existing Durable Object namespaces will be available in the future.\n\n## Access storage\n\nDurable Objects gain access to Storage API via the `DurableObjectStorage` interface and accessed by the `DurableObjectState::storage` property. This is frequently accessed via `this.ctx.storage` with the `ctx` parameter passed to the Durable Object constructor.\n\nThe following code snippet shows you how to store and retrieve data using the Durable Object Storage API.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "JavaScript is a single-threaded and event-driven programming language. This means that JavaScript runtimes, by default, allow requests to interleave with each other which can lead to concurrency bugs. The Durable Objects runtime uses a combination of input gates and output gates to avoid this type of concurrency bug when performing storage operations. Learn more in our [blog post](https://blog.cloudflare.com/durable-objects-easy-fast-correct-choose-three/).\n\n## Asynchronous KV API\n\nKV-backed Durable Objects provide KV API methods which are asynchronous.\n\n### get\n\n* `ctx.storage.get(key string, options Object optional)`: Promise\\<any>\n\n  * Retrieves the value associated with the given key. The type of the returned value will be whatever was previously written for the key, or undefined if the key does not exist.\n\n* `ctx.storage.get(keys Array<string>, options Object optional)`: Promise\\<Map\\<string, any>>\n\n  * Retrieves the values associated with each of the provided keys. The type of each returned value in the [`Map`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map) will be whatever was previously written for the corresponding key. Results in the `Map` will be sorted in increasing order of their UTF-8 encodings, with any requested keys that do not exist being omitted. Supports up to 128 keys at a time.\n\n#### Supported options\n\n* `allowConcurrency`: boolean\n\n  * By default, the system will pause delivery of I/O events to the Object while a storage operation is in progress, in order to avoid unexpected race conditions. Pass `allowConcurrency: true` to opt out of this behavior and allow concurrent events to be delivered.\n\n* `noCache`: boolean\n\n  * If true, then the key/value will not be inserted into the in-memory cache. If the key is already in the cache, the cached value will be returned, but its last-used time will not be updated. Use this when you expect this key will not be used again in the near future. This flag is only a hint. This flag will never change the semantics of your code, but it may affect performance.\n\n### put\n\n* `put(key string, value any, options Object optional)`: Promise\n\n  * Stores the value and associates it with the given key. The value can be any type supported by the [structured clone algorithm](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm), which is true of most types.\n\n    The size of keys and values have different limits depending on the Durable Object storage backend you are using. Refer to either:\n\n    * [SQLite-backed Durable Object limits](https://developers.cloudflare.com/durable-objects/platform/limits/#sqlite-backed-durable-objects-general-limits)\n    * [KV-backed Durable Object limits](https://developers.cloudflare.com/durable-objects/platform/limits/#key-value-backed-durable-objects-general-limits).\n\n* `put(entries Object, options Object optional)`: Promise\n\n  * Takes an Object and stores each of its keys and values to storage.\n\n  * Each value can be any type supported by the [structured clone algorithm](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm), which is true of most types.\n\n  * Supports up to 128 key-value pairs at a time. The size of keys and values have different limits depending on the flavor of Durable Object you are using. Refer to either:\n\n    * [SQLite-backed Durable Object limits](https://developers.cloudflare.com/durable-objects/platform/limits/#sqlite-backed-durable-objects-general-limits)\n    * [KV-backed Durable Object limits](https://developers.cloudflare.com/durable-objects/platform/limits/#key-value-backed-durable-objects-general-limits)\n\n### delete\n\n* `delete(key string, options Object optional)`: Promise\\<boolean>\n\n  * Deletes the key and associated value. Returns `true` if the key existed or `false` if it did not.\n\n* `delete(keys Array<string>, options Object optional)`: Promise\\<number>\n\n  * Deletes the provided keys and their associated values. Supports up to 128 keys at a time. Returns a count of the number of key-value pairs deleted.\n\n#### Supported options\n\n* `put()`, `delete()` and `deleteAll()` support the following options:\n\n* `allowUnconfirmed` boolean\n\n  * By default, the system will pause outgoing network messages from the Durable Object until all previous writes have been confirmed flushed to disk. If the write fails, the system will reset the Object, discard all outgoing messages, and respond to any clients with errors instead.\n\n  * This way, Durable Objects can continue executing in parallel with a write operation, without having to worry about prematurely confirming writes, because it is impossible for any external party to observe the Object's actions unless the write actually succeeds.\n\n  * After any write, subsequent network messages may be slightly delayed. Some applications may consider it acceptable to communicate on the basis of unconfirmed writes. Some programs may prefer to allow network traffic immediately. In this case, set `allowUnconfirmed` to `true` to opt out of the default behavior.\n\n  * If you want to allow some outgoing network messages to proceed immediately but not others, you can use the allowUnconfirmed option to avoid blocking the messages that you want to proceed and then separately call the [`sync()`](#sync) method, which returns a promise that only resolves once all previous writes have successfully been persisted to disk.\n\n* `noCache` boolean\n\n  * If true, then the key/value will be discarded from memory as soon as it has completed writing to disk.\n\n  * Use `noCache` if the key will not be used again in the near future. `noCache` will never change the semantics of your code, but it may affect performance.\n\n  * If you use `get()` to retrieve the key before the write has completed, the copy from the write buffer will be returned, thus ensuring consistency with the latest call to `put()`.\n\nAutomatic write coalescing\n\nIf you invoke `put()` (or `delete()`) multiple times without performing any `await` in the meantime, the operations will automatically be combined and submitted atomically. In case of a machine failure, either all of the writes will have been stored to disk or none of the writes will have been stored to disk.\n\nWrite buffer behavior\n\nThe `put()` method returns a `Promise`, but most applications can discard this promise without using `await`. The `Promise` usually completes immediately, because `put()` writes to an in-memory write buffer that is flushed to disk asynchronously. However, if an application performs a large number of `put()` without waiting for any I/O, the write buffer could theoretically grow large enough to cause the isolate to exceed its 128 MB memory limit. To avoid this scenario, such applications should use `await` on the `Promise` returned by `put()`. The system will then apply backpressure onto the application, slowing it down so that the write buffer has time to flush. Using `await` will disable automatic write coalescing.\n\n### list\n\n* `list(options Object optional)`: Promise\\<Map\\<string, any>>\n\n  * Returns all keys and values associated with the current Durable Object in ascending sorted order based on the keys' UTF-8 encodings.\n\n  * The type of each returned value in the [`Map`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map) will be whatever was previously written for the corresponding key.\n\n  * Be aware of how much data may be stored in your Durable Object before calling this version of `list` without options because all the data will be loaded into the Durable Object's memory, potentially hitting its [limit](https://developers.cloudflare.com/durable-objects/platform/limits/). If that is a concern, pass options to `list` as documented below.\n\n#### Supported options\n\n* `start` string\n\n  * Key at which the list results should start, inclusive.\n\n* `startAfter` string\n\n  * Key after which the list results should start, exclusive. Cannot be used simultaneously with `start`.\n\n* `end` string\n\n  * Key at which the list results should end, exclusive.\n\n* `prefix` string\n\n  * Restricts results to only include key-value pairs whose keys begin with the prefix.\n\n* `reverse` boolean\n\n  * If true, return results in descending order instead of the default ascending order.\n  * Enabling `reverse` does not change the meaning of `start`, `startKey`, or `endKey`. `start` still defines the smallest key in lexicographic order that can be returned (inclusive), effectively serving as the endpoint for a reverse-order list. `end` still defines the largest key in lexicographic order that the list should consider (exclusive), effectively serving as the starting point for a reverse-order list.\n\n* `limit` number\n\n  * Maximum number of key-value pairs to return.\n\n* `allowConcurrency` boolean\n\n  * Same as the option to [`get()`](#do-kv-async-get), above.\n\n* `noCache` boolean\n\n  * Same as the option to [`get()`](#do-kv-async-get), above.\n\n## Alarms\n\n### `getAlarm`\n\n* `getAlarm(options Object optional)`: Promise\\<Number | null>\n  * Retrieves the current alarm time (if set) as integer milliseconds since epoch. The alarm is considered to be set if it has not started, or if it has failed and any retry has not begun. If no alarm is set, `getAlarm()` returns `null`.\n\n#### Supported options\n\n* Same options as [`get()`](#get), but without `noCache`.\n\n### `setAlarm`\n\n* `setAlarm(scheduledTime Date | number, options Object optional)`: Promise\n\n  * Sets the current alarm time, accepting either a JavaScript `Date`, or integer milliseconds since epoch.\n\n  If `setAlarm()` is called with a time equal to or before `Date.now()`, the alarm will be scheduled for asynchronous execution in the immediate future. If the alarm handler is currently executing in this case, it will not be canceled. Alarms can be set to millisecond granularity and will usually execute within a few milliseconds after the set time, but can be delayed by up to a minute due to maintenance or failures while failover takes place.\n\n### `deleteAlarm`\n\n* `deleteAlarm(options Object optional)`: Promise\n  * Deletes the alarm if one exists. Does not cancel the alarm handler if it is currently executing.\n\n#### Supported options\n\n* `setAlarm()` and `deleteAlarm()` support the same options as [`put()`](#put), but without `noCache`.\n\n## Other\n\n### `deleteAll`\n\n* `deleteAll(options Object optional)`: Promise\n\n  * Deletes all stored data, effectively deallocating all storage used by the Durable Object. For Durable Objects with a key-value storage backend, `deleteAll()` removes all keys and associated values for an individual Durable Object. For Durable Objects with a [SQLite storage backend](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#create-sqlite-backed-durable-object-class), `deleteAll()` removes the entire contents of a Durable Object's private SQLite database, including both SQL data and key-value data.\n  * For Durable Objects with a key-value storage backend, an in-progress `deleteAll()` operation can fail, which may leave a subset of data undeleted. Durable Objects with a SQLite storage backend do not have a partial `deleteAll()` issue because `deleteAll()` operations are atomic (all or nothing).\n  * `deleteAll()` does not proactively delete [alarms](https://developers.cloudflare.com/durable-objects/api/alarms/). Use [`deleteAlarm()`](https://developers.cloudflare.com/durable-objects/api/alarms/#deletealarm) to delete an alarm.\n\n### `transactionSync`\n\n* `transactionSync(callback)`: any\n\n  * Only available when using SQLite-backed Durable Objects.\n\n  * Invokes `callback()` wrapped in a transaction, and returns its result.\n\n  * If `callback()` throws an exception, the transaction will be rolled back.\n\n  * The callback must complete synchronously, that is, it should not be declared `async` nor otherwise return a Promise. Only synchronous storage operations can be part of the transaction. This is intended for use with SQL queries using [`ctx.storage.sql.exec()`](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#exec), which complete sychronously.\n\n### `transaction`\n\n* `transaction(closureFunction(txn))`: Promise\n\n  * Runs the sequence of storage operations called on `txn` in a single transaction that either commits successfully or aborts.\n\n  * Explicit transactions are no longer necessary. Any series of write operations with no intervening `await` will automatically be submitted atomically, and the system will prevent concurrent events from executing while `await` a read operation (unless you use `allowConcurrency: true`). Therefore, a series of reads followed by a series of writes (with no other intervening I/O) are automatically atomic and behave like a transaction.\n\n* `txn`\n\n  * Provides access to the `put()`, `get()`, `delete()`, and `list()` methods documented above to run in the current transaction context. In order to get transactional behavior within a transaction closure, you must call the methods on the `txn` Object instead of on the top-level `ctx.storage` Object.\\\n    \\\n    Also supports a `rollback()` function that ensures any changes made during the transaction will be rolled back rather than committed. After `rollback()` is called, any subsequent operations on the `txn` Object will fail with an exception. `rollback()` takes no parameters and returns nothing to the caller.\n\n  * When using [the SQLite-backed storage engine](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#sqlite-storage-backend), the `txn` object is obsolete. Any storage operations performed directly on the `ctx.storage` object, including SQL queries using [`ctx.storage.sql.exec()`](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#exec), will be considered part of the transaction.\n\n### `sync`\n\n* `sync()`: Promise\n\n  * Synchronizes any pending writes to disk.\n\n  * This is similar to normal behavior from automatic write coalescing. If there are any pending writes in the write buffer (including those submitted with [the `allowUnconfirmed` option](#supported-options-1)), the returned promise will resolve when they complete. If there are no pending writes, the returned promise will be already resolved.\n\n## Related resources\n\n* [Durable Objects: Easy, Fast, Correct Choose Three](https://blog.cloudflare.com/durable-objects-easy-fast-correct-choose-three/)\n* [Zero-latency SQLite storage in every Durable Object blog](https://blog.cloudflare.com/sqlite-in-durable-objects/)\n* [WebSockets API](https://developers.cloudflare.com/durable-objects/best-practices/websockets/)\n\n</page>\n\n<page>\n---\ntitle: Durable Object Namespace · Cloudflare Durable Objects docs\ndescription: A Durable Object namespace is a set of Durable Objects that are\n  backed by the same Durable Object class. There is only one Durable Object\n  namespace per class. A Durable Object namespace can contain any number of\n  Durable Objects.\nlastUpdated: 2025-12-08T15:50:53.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/api/namespace/\n  md: https://developers.cloudflare.com/durable-objects/api/namespace/index.md\n---\n\n## Description\n\nA Durable Object namespace is a set of Durable Objects that are backed by the same Durable Object class. There is only one Durable Object namespace per class. A Durable Object namespace can contain any number of Durable Objects.\n\nThe `DurableObjectNamespace` interface is used to obtain a reference to new or existing Durable Objects. The interface is accessible from the fetch handler on a Cloudflare Worker via the `env` parameter, which is the standard interface when referencing bindings declared in the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/).\n\nThis interface defines several [methods](https://developers.cloudflare.com/durable-objects/api/namespace/#methods) that can be used to create an ID for a Durable Object. Note that creating an ID for a Durable Object does not create the Durable Object. The Durable Object is created lazily after calling [`DurableObjectNamespace::get`](https://developers.cloudflare.com/durable-objects/api/namespace/#get) to create a [`DurableObjectStub`](https://developers.cloudflare.com/durable-objects/api/stub) from a `DurableObjectId`. This ensures that objects are not constructed until they are actually accessed.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "## Methods\n\n### `idFromName`\n\n`idFromName` creates a unique [`DurableObjectId`](https://developers.cloudflare.com/durable-objects/api/id) which refers to an individual instance of the Durable Object class. Named Durable Objects are the most common method of referring to Durable Objects.",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* A required string to be used to generate a [`DurableObjectId`](https://developers.cloudflare.com/durable-objects/api/id) corresponding to the name of a Durable Object.\n\n#### Return values\n\n* A [`DurableObjectId`](https://developers.cloudflare.com/durable-objects/api/id) referring to an instance of a Durable Object class.\n\n### `newUniqueId`\n\n`newUniqueId` creates a randomly generated and unique [`DurableObjectId`](https://developers.cloudflare.com/durable-objects/api/id) which refers to an individual instance of the Durable Object class. IDs created using `newUniqueId`, will need to be stored as a string in order to refer to the same Durable Object again in the future. For example, the ID can be stored in Workers KV, another Durable Object, or in a cookie in the user's browser.",
      "language": "unknown"
    },
    {
      "code": "`newUniqueId` results in lower request latency at first use\n\nThe first time you get a Durable Object stub based on an ID derived from a name, the system has to take into account the possibility that a Worker on the opposite side of the world could have coincidentally accessed the same named Durable Object at the same time. To guarantee that only one instance of the Durable Object is created, the system must check that the Durable Object has not been created anywhere else. Due to the inherent limit of the speed of light, this round-the-world check can take up to a few hundred milliseconds. `newUniqueId` can skip this check.\n\nAfter this first use, the location of the Durable Object will be cached around the world so that subsequent lookups are faster.\n\n#### Parameters\n\n* An optional object with the key `jurisdiction` and value of a [jurisdiction](https://developers.cloudflare.com/durable-objects/reference/data-location/#restrict-durable-objects-to-a-jurisdiction) string.\n\n#### Return values\n\n* A [`DurableObjectId`](https://developers.cloudflare.com/durable-objects/api/id) referring to an instance of the Durable Object class.\n\n### `idFromString`\n\n`idFromString` creates a [`DurableObjectId`](https://developers.cloudflare.com/durable-objects/api/id) from a previously generated ID that has been converted to a string. This method throws an exception if the ID is invalid, for example, if the ID was not created from the same `DurableObjectNamespace`.",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* A required string corresponding to a [`DurableObjectId`](https://developers.cloudflare.com/durable-objects/api/id) previously generated either by `newUniqueId` or `idFromName`.\n\n#### Return values\n\n* A [`DurableObjectId`](https://developers.cloudflare.com/durable-objects/api/id) referring to an instance of a Durable Object class.\n\n### `get`\n\n`get` obtains a [`DurableObjectStub`](https://developers.cloudflare.com/durable-objects/api/stub) from a [`DurableObjectId`](https://developers.cloudflare.com/durable-objects/api/id) which can be used to invoke methods on a Durable Object.\n\nThis method returns the stub immediately, often before a connection has been established to the Durable Object. This allows requests to be sent to the instance right away, without waiting for a network round trip.",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* A required [`DurableObjectId`](https://developers.cloudflare.com/durable-objects/api/id)\n* An optional object with the key `locationHint` and value of a [locationHint](https://developers.cloudflare.com/durable-objects/reference/data-location/#provide-a-location-hint) string.\n\n#### Return values\n\n* A [`DurableObjectStub`](https://developers.cloudflare.com/durable-objects/api/stub) referring to an instance of a Durable Object class.\n\n### `getByName`\n\n`getByName` obtains a [`DurableObjectStub`](https://developers.cloudflare.com/durable-objects/api/stub) from a provided name, which can be used to invoke methods on a Durable Object.\n\nThis method returns the stub immediately, often before a connection has been established to the Durable Object. This allows requests to be sent to the instance right away, without waiting for a network round trip.",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* A required string to be used to generate a [`DurableObjectStub`](https://developers.cloudflare.com/durable-objects/api/stub) corresponding to an instance of the Durable Object class with the provided name.\n\n#### Return values\n\n* A [`DurableObjectStub`](https://developers.cloudflare.com/durable-objects/api/stub) referring to an instance of a Durable Object class.\n\n### `jurisdiction`\n\n`jurisdiction` creates a subnamespace from a namespace where all Durable Object IDs and references created from that subnamespace will be restricted to the specified [jurisdiction](https://developers.cloudflare.com/durable-objects/reference/data-location/#restrict-durable-objects-to-a-jurisdiction).",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* A required [jurisdiction](https://developers.cloudflare.com/durable-objects/reference/data-location/#restrict-durable-objects-to-a-jurisdiction) string.\n\n#### Return values\n\n* A `DurableObjectNamespace` scoped to a particular regulatory or geographic jurisdiction. Additional geographic jurisdictions are continuously evaluated, so share requests in the [Durable Objects Discord channel](https://discord.com/channels/595317990191398933/773219443911819284).\n\n## Related resources\n\n* [Durable Objects: Easy, Fast, Correct – Choose Three](https://blog.cloudflare.com/durable-objects-easy-fast-correct-choose-three/).\n\n</page>\n\n<page>\n---\ntitle: SQLite-backed Durable Object Storage · Cloudflare Durable Objects docs\ndescription: The Durable Object Storage API allows Durable Objects to access\n  transactional and strongly consistent storage. A Durable Object's attached\n  storage is private to its unique instance and cannot be accessed by other\n  objects.\nlastUpdated: 2025-12-08T15:50:53.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/\n  md: https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/index.md\n---\n\nNote\n\nThis page documents the storage API for the newer SQLite-backed Durable Objects.\n\nFor the legacy KV-backed Durable Object storage API, refer to [KV-backed Durable Object Storage (Legacy)](https://developers.cloudflare.com/durable-objects/api/legacy-kv-storage-api/).\n\nThe Durable Object Storage API allows Durable Objects to access transactional and strongly consistent storage. A Durable Object's attached storage is private to its unique instance and cannot be accessed by other objects.\n\nThe Durable Object Storage API comes with several methods, including SQL, point-in-time recovery (PITR), key-value (KV), and alarm APIs. Available API methods depend on the storage backend for a Durable Objects class, either [SQLite](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#create-sqlite-backed-durable-object-class) or [KV](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/#create-durable-object-class-with-key-value-storage).\n\n| Methods 1 | SQLite-backed Durable Object class | KV-backed Durable Object class |\n| - | - | - |\n| SQL API | ✅ | ❌ |\n| PITR API | ✅ | ❌ |\n| Synchronous KV API | ✅ 2, 3 | ❌ |\n| Asynchronous KV API | ✅ 3 | ✅ |\n| Alarms API | ✅ | ✅ |\n\nFootnotes\n\n1 Each method is implicitly wrapped inside a transaction, such that its results are atomic and isolated from all other storage operations, even when accessing multiple key-value pairs.\n\n2 KV API methods like `get()`, `put()`, `delete()`, or `list()` store data in a hidden SQLite table `__cf_kv`. Note that you will be able to view this table when listing all tables, but you will not be able to access its content through the SQL API.\n\n3 SQLite-backed Durable Objects also use [synchronous KV API methods](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#synchronous-kv-api) using `ctx.storage.kv`, whereas KV-backed Durable Objects only provide [asynchronous KV API methods](https://developers.cloudflare.com/durable-objects/api/legacy-kv-storage-api/#asynchronous-kv-api).\n\nRecommended SQLite-backed Durable Objects\n\nCloudflare recommends all new Durable Object namespaces use the [SQLite storage backend](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#create-sqlite-backed-durable-object-class). These Durable Objects can continue to use storage [key-value API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#synchronous-kv-api).\n\nAdditionally, SQLite-backed Durable Objects allow you to store more types of data (such as tables), and offer Point In Time Recovery API which can restore a Durable Object's embedded SQLite database contents (both SQL data and key-value data) to any point in the past 30 days.\n\nThe [key-value storage backend](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/#create-durable-object-class-with-key-value-storage) remains for backwards compatibility, and a migration path from KV storage backend to SQLite storage backend for existing Durable Object namespaces will be available in the future.\n\nStorage billing on SQLite-backed Durable Objects\n\nStorage billing for SQLite-backed Durable Objects will be enabled in January 2026, with a target date of January 7, 2026 (no earlier). Only SQLite storage usage on and after the billing target date will incur charges. For more information, refer to [Billing for SQLite Storage](https://developers.cloudflare.com/changelog/2025-12-12-durable-objects-sqlite-storage-billing/).\n\n## Access storage\n\nDurable Objects gain access to Storage API via the `DurableObjectStorage` interface and accessed by the `DurableObjectState::storage` property. This is frequently accessed via `this.ctx.storage` with the `ctx` parameter passed to the Durable Object constructor.\n\nThe following code snippet shows you how to store and retrieve data using the Durable Object Storage API.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "JavaScript is a single-threaded and event-driven programming language. This means that JavaScript runtimes, by default, allow requests to interleave with each other which can lead to concurrency bugs. The Durable Objects runtime uses a combination of input gates and output gates to avoid this type of concurrency bug when performing storage operations. Learn more in our [blog post](https://blog.cloudflare.com/durable-objects-easy-fast-correct-choose-three/).\n\n## SQL API\n\nThe `SqlStorage` interface encapsulates methods that modify the SQLite database embedded within a Durable Object. The `SqlStorage` interface is accessible via the [`sql` property](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#sql) of `DurableObjectStorage` class.\n\nFor example, using `sql.exec()` a user can create a table and insert rows.\n\n* TypeScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "- SQL API methods accessed with `ctx.storage.sql` are only allowed on [Durable Object classes with SQLite storage backend](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#create-sqlite-backed-durable-object-class) and will return an error if called on Durable Object classes with a KV-storage backend.\n- When writing data, every row update of an index counts as an additional row. However, indexes may be beneficial for read-heavy use cases. Refer to [Index for SQLite Durable Objects](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#index-for-sqlite-durable-objects).\n- Writing data to [SQLite virtual tables](https://www.sqlite.org/vtab.html) also counts towards rows written.\n\nDurable Objects support a subset of SQLite extensions for added functionality, including:\n\n* [FTS5 module](https://www.sqlite.org/fts5.html) for full-text search (including `fts5vocab`).\n* [JSON extension](https://www.sqlite.org/json1.html) for JSON functions and operators.\n* [Math functions](https://sqlite.org/lang_mathfunc.html).\n\nRefer to the [source code](https://github.com/cloudflare/workerd/blob/4c42a4a9d3390c88e9bd977091c9d3395a6cd665/src/workerd/util/sqlite.c%2B%2B#L269) for the full list of supported functions.\n\n### `exec`\n\n`exec(query: string, ...bindings: any[])`: SqlStorageCursor\n\n#### Parameters\n\n* `query`: string\n  * The SQL query string to be executed. `query` can contain `?` placeholders for parameter bindings. Multiple SQL statements, separated with a semicolon, can be executed in the `query`. With multiple SQL statements, any parameter bindings are applied to the last SQL statement in the `query`, and the returned cursor is only for the last SQL statement.\n* `...bindings`: any\\[] Optional\n  * Optional variable number of arguments that correspond to the `?` placeholders in `query`.\n\n#### Returns\n\nA cursor (`SqlStorageCursor`) to iterate over query row results as objects. `SqlStorageCursor` is a JavaScript [Iterable](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Iteration_protocols#the_iterable_protocol), which supports iteration using `for (let row of cursor)`. `SqlStorageCursor` is also a JavaScript [Iterator](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Iteration_protocols#the_iterator_protocol), which supports iteration using `cursor.next()`.\n\n`SqlStorageCursor` supports the following methods:\n\n* `next()`\n  * Returns an object representing the next value of the cursor. The returned object has `done` and `value` properties adhering to the JavaScript [Iterator](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Iteration_protocols#the_iterator_protocol). `done` is set to `false` when a next value is present, and `value` is set to the next row object in the query result. `done` is set to `true` when the entire cursor is consumed, and no `value` is set.\n\n* `toArray()`\n  * Iterates through remaining cursor value(s) and returns an array of returned row objects.\n\n* `one()`\n  * Returns a row object if query result has exactly one row. If query result has zero rows or more than one row, `one()` throws an exception.\n\n* `raw()`: Iterator\n\n  * Returns an Iterator over the same query results, with each row as an array of column values (with no column names) rather than an object.\n  * Returned Iterator supports `next()` and `toArray()` methods above.\n  * Returned cursor and `raw()` iterator iterate over the same query results and can be combined. For example:\n\n- TypeScript",
      "language": "unknown"
    },
    {
      "code": "- Python",
      "language": "unknown"
    },
    {
      "code": "`SqlStorageCursor` has the following properties:\n\n* `columnNames`: string\\[]\n  * The column names of the query in the order they appear in each row array returned by the `raw` iterator.\n* `rowsRead`: number\n  * The number of rows read so far as part of this SQL `query`. This may increase as you iterate the cursor. The final value is used for [SQL billing](https://developers.cloudflare.com/durable-objects/platform/pricing/#sqlite-storage-backend).\n* `rowsWritten`: number\n  * The number of rows written so far as part of this SQL `query`. This may increase as you iterate the cursor. The final value is used for [SQL billing](https://developers.cloudflare.com/durable-objects/platform/pricing/#sqlite-storage-backend).\n* Any numeric value in a column is affected by JavaScript's 52-bit precision for numbers. If you store a very large number (in `int64`), then retrieve the same value, the returned value may be less precise than your original number.\n\nSQL transactions\n\nNote that `sql.exec()` cannot execute transaction-related statements like `BEGIN TRANSACTION` or `SAVEPOINT`. Instead, use the [`ctx.storage.transaction()`](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#transaction) or [`ctx.storage.transactionSync()`](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#transactionsync) APIs to start a transaction, and then execute SQL queries in your callback.\n\n#### Examples\n\n[SQL API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#exec) examples below use the following SQL schema:",
      "language": "unknown"
    },
    {
      "code": "Iterate over query results as row objects:",
      "language": "unknown"
    },
    {
      "code": "Convert query results to an array of row objects:",
      "language": "unknown"
    },
    {
      "code": "Convert query results to an array of row values arrays:",
      "language": "unknown"
    },
    {
      "code": "Get first row object of query results:",
      "language": "unknown"
    },
    {
      "code": "Check if query results have exactly one row:",
      "language": "unknown"
    },
    {
      "code": "Returned cursor behavior:",
      "language": "unknown"
    },
    {
      "code": "Returned cursor and `raw()` iterator iterate over the same query results:",
      "language": "unknown"
    },
    {
      "code": "`sql.exec().rowsRead()`:",
      "language": "unknown"
    },
    {
      "code": "### `databaseSize`\n\n`databaseSize`: number\n\n#### Returns\n\nThe current SQLite database size in bytes.\n\n* TypeScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "## PITR (Point In Time Recovery) API\n\nFor [SQLite-backed Durable Objects](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#create-sqlite-backed-durable-object-class), the following point-in-time-recovery (PITR) API methods are available to restore a Durable Object's embedded SQLite database to any point in time in the past 30 days. These methods apply to the entire SQLite database contents, including both the object's stored SQL data and stored key-value data using the key-value `put()` API. The PITR API is not supported in local development because a durable log of data changes is not stored locally.\n\nThe PITR API represents points in time using 'bookmarks'. A bookmark is a mostly alphanumeric string like `0000007b-0000b26e-00001538-0c3e87bb37b3db5cc52eedb93cd3b96b`. Bookmarks are designed to be lexically comparable: a bookmark representing an earlier point in time compares less than one representing a later point, using regular string comparison.\n\n### `getCurrentBookmark`\n\n`ctx.storage.getCurrentBookmark()`: Promise\\<string>\n\n* Returns a bookmark representing the current point in time in the object's history.\n\n### `getBookmarkForTime`\n\n`ctx.storage.getBookmarkForTime(timestamp: number | Date)`: Promise\\<string>\n\n* Returns a bookmark representing approximately the given point in time, which must be within the last 30 days. If the timestamp is represented as a number, it is converted to a date as if using `new Date(timestamp)`.\n\n### `onNextSessionRestoreBookmark`\n\n`ctx.storage.onNextSessionRestoreBookmark(bookmark: string)`: Promise\\<string>\n\n* Configures the Durable Object so that the next time it restarts, it should restore its storage to exactly match what the storage contained at the given bookmark. After calling this, the application should typically invoke `ctx.abort()` to restart the Durable Object, thus completing the point-in-time recovery.\n\nThis method returns a special bookmark representing the point in time immediately before the recovery takes place (even though that point in time is still technically in the future). Thus, after the recovery completes, it can be undone by performing a second recovery to this bookmark.\n\n* TypeScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "## Synchronous KV API\n\n### `get`\n\n* `ctx.storage.kv.get(key string)`: Any, undefined\n  * Retrieves the value associated with the given key. The type of the returned value will be whatever was previously written for the key, or undefined if the key does not exist.\n\n### `put`\n\n* `ctx.storage.kv.put(key string, value any)`: void\n\n  * Stores the value and associates it with the given key. The value can be any type supported by the [structured clone algorithm](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm), which is true of most types.\n\n    For the size of keys and values refer to [SQLite-backed Durable Object limits](https://developers.cloudflare.com/durable-objects/platform/limits/#sqlite-backed-durable-objects-general-limits)\n\n### `delete`\n\n* `ctx.storage.kv.delete(key string)`: boolean\n  * Deletes the key and associated value. Returns `true` if the key existed or `false` if it did not.\n\n### `list`\n\n* `ctx.storage.kv.list(options Object optional)`: Iterable\\<string, any>\n\n  * Returns all keys and values associated with the current Durable Object in ascending sorted order based on the keys' UTF-8 encodings.\n\n  * The type of each returned value in the [`Iterable`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Iteration_protocols#the_iterable_protocol) will be whatever was previously written for the corresponding key.\n\n  * Be aware of how much data may be stored in your Durable Object before calling this version of `list` without options because all the data will be loaded into the Durable Object's memory, potentially hitting its [limit](https://developers.cloudflare.com/durable-objects/platform/limits/). If that is a concern, pass options to `list` as documented below.\n\n#### Supported options\n\n* `start` string\n\n  * Key at which the list results should start, inclusive.\n\n* `startAfter` string\n\n  * Key after which the list results should start, exclusive. Cannot be used simultaneously with `start`.\n\n* `end` string\n\n  * Key at which the list results should end, exclusive.\n\n* `prefix` string\n\n  * Restricts results to only include key-value pairs whose keys begin with the prefix.\n\n* `reverse` boolean\n\n  * If true, return results in descending order instead of the default ascending order.\n  * Enabling `reverse` does not change the meaning of `start`, `startKey`, or `endKey`. `start` still defines the smallest key in lexicographic order that can be returned (inclusive), effectively serving as the endpoint for a reverse-order list. `end` still defines the largest key in lexicographic order that the list should consider (exclusive), effectively serving as the starting point for a reverse-order list.\n\n* `limit` number\n\n  * Maximum number of key-value pairs to return.\n\n## Asynchronous KV API\n\n### get\n\n* `ctx.storage.get(key string, options Object optional)`: Promise\\<any>\n\n  * Retrieves the value associated with the given key. The type of the returned value will be whatever was previously written for the key, or undefined if the key does not exist.\n\n* `ctx.storage.get(keys Array<string>, options Object optional)`: Promise\\<Map\\<string, any>>\n\n  * Retrieves the values associated with each of the provided keys. The type of each returned value in the [`Map`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map) will be whatever was previously written for the corresponding key. Results in the `Map` will be sorted in increasing order of their UTF-8 encodings, with any requested keys that do not exist being omitted. Supports up to 128 keys at a time.\n\n#### Supported options\n\n* `allowConcurrency`: boolean\n\n  * By default, the system will pause delivery of I/O events to the Object while a storage operation is in progress, in order to avoid unexpected race conditions. Pass `allowConcurrency: true` to opt out of this behavior and allow concurrent events to be delivered.\n\n* `noCache`: boolean\n\n  * If true, then the key/value will not be inserted into the in-memory cache. If the key is already in the cache, the cached value will be returned, but its last-used time will not be updated. Use this when you expect this key will not be used again in the near future. This flag is only a hint. This flag will never change the semantics of your code, but it may affect performance.\n\n### put\n\n* `put(key string, value any, options Object optional)`: Promise\n\n  * Stores the value and associates it with the given key. The value can be any type supported by the [structured clone algorithm](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm), which is true of most types.\n\n    The size of keys and values have different limits depending on the Durable Object storage backend you are using. Refer to either:\n\n    * [SQLite-backed Durable Object limits](https://developers.cloudflare.com/durable-objects/platform/limits/#sqlite-backed-durable-objects-general-limits)\n    * [KV-backed Durable Object limits](https://developers.cloudflare.com/durable-objects/platform/limits/#key-value-backed-durable-objects-general-limits).\n\n* `put(entries Object, options Object optional)`: Promise\n\n  * Takes an Object and stores each of its keys and values to storage.\n\n  * Each value can be any type supported by the [structured clone algorithm](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm), which is true of most types.\n\n  * Supports up to 128 key-value pairs at a time. The size of keys and values have different limits depending on the flavor of Durable Object you are using. Refer to either:\n\n    * [SQLite-backed Durable Object limits](https://developers.cloudflare.com/durable-objects/platform/limits/#sqlite-backed-durable-objects-general-limits)\n    * [KV-backed Durable Object limits](https://developers.cloudflare.com/durable-objects/platform/limits/#key-value-backed-durable-objects-general-limits)\n\n### delete\n\n* `delete(key string, options Object optional)`: Promise\\<boolean>\n\n  * Deletes the key and associated value. Returns `true` if the key existed or `false` if it did not.\n\n* `delete(keys Array<string>, options Object optional)`: Promise\\<number>\n\n  * Deletes the provided keys and their associated values. Supports up to 128 keys at a time. Returns a count of the number of key-value pairs deleted.\n\n#### Supported options\n\n* `put()`, `delete()` and `deleteAll()` support the following options:\n\n* `allowUnconfirmed` boolean\n\n  * By default, the system will pause outgoing network messages from the Durable Object until all previous writes have been confirmed flushed to disk. If the write fails, the system will reset the Object, discard all outgoing messages, and respond to any clients with errors instead.\n\n  * This way, Durable Objects can continue executing in parallel with a write operation, without having to worry about prematurely confirming writes, because it is impossible for any external party to observe the Object's actions unless the write actually succeeds.\n\n  * After any write, subsequent network messages may be slightly delayed. Some applications may consider it acceptable to communicate on the basis of unconfirmed writes. Some programs may prefer to allow network traffic immediately. In this case, set `allowUnconfirmed` to `true` to opt out of the default behavior.\n\n  * If you want to allow some outgoing network messages to proceed immediately but not others, you can use the allowUnconfirmed option to avoid blocking the messages that you want to proceed and then separately call the [`sync()`](#sync) method, which returns a promise that only resolves once all previous writes have successfully been persisted to disk.\n\n* `noCache` boolean\n\n  * If true, then the key/value will be discarded from memory as soon as it has completed writing to disk.\n\n  * Use `noCache` if the key will not be used again in the near future. `noCache` will never change the semantics of your code, but it may affect performance.\n\n  * If you use `get()` to retrieve the key before the write has completed, the copy from the write buffer will be returned, thus ensuring consistency with the latest call to `put()`.\n\nAutomatic write coalescing\n\nIf you invoke `put()` (or `delete()`) multiple times without performing any `await` in the meantime, the operations will automatically be combined and submitted atomically. In case of a machine failure, either all of the writes will have been stored to disk or none of the writes will have been stored to disk.\n\nWrite buffer behavior\n\nThe `put()` method returns a `Promise`, but most applications can discard this promise without using `await`. The `Promise` usually completes immediately, because `put()` writes to an in-memory write buffer that is flushed to disk asynchronously. However, if an application performs a large number of `put()` without waiting for any I/O, the write buffer could theoretically grow large enough to cause the isolate to exceed its 128 MB memory limit. To avoid this scenario, such applications should use `await` on the `Promise` returned by `put()`. The system will then apply backpressure onto the application, slowing it down so that the write buffer has time to flush. Using `await` will disable automatic write coalescing.\n\n### list\n\n* `list(options Object optional)`: Promise\\<Map\\<string, any>>\n\n  * Returns all keys and values associated with the current Durable Object in ascending sorted order based on the keys' UTF-8 encodings.\n\n  * The type of each returned value in the [`Map`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map) will be whatever was previously written for the corresponding key.\n\n  * Be aware of how much data may be stored in your Durable Object before calling this version of `list` without options because all the data will be loaded into the Durable Object's memory, potentially hitting its [limit](https://developers.cloudflare.com/durable-objects/platform/limits/). If that is a concern, pass options to `list` as documented below.\n\n#### Supported options\n\n* `start` string\n\n  * Key at which the list results should start, inclusive.\n\n* `startAfter` string\n\n  * Key after which the list results should start, exclusive. Cannot be used simultaneously with `start`.\n\n* `end` string\n\n  * Key at which the list results should end, exclusive.\n\n* `prefix` string\n\n  * Restricts results to only include key-value pairs whose keys begin with the prefix.\n\n* `reverse` boolean\n\n  * If true, return results in descending order instead of the default ascending order.\n  * Enabling `reverse` does not change the meaning of `start`, `startKey`, or `endKey`. `start` still defines the smallest key in lexicographic order that can be returned (inclusive), effectively serving as the endpoint for a reverse-order list. `end` still defines the largest key in lexicographic order that the list should consider (exclusive), effectively serving as the starting point for a reverse-order list.\n\n* `limit` number\n\n  * Maximum number of key-value pairs to return.\n\n* `allowConcurrency` boolean\n\n  * Same as the option to [`get()`](#do-kv-async-get), above.\n\n* `noCache` boolean\n\n  * Same as the option to [`get()`](#do-kv-async-get), above.\n\n## Alarms\n\n### `getAlarm`\n\n* `getAlarm(options Object optional)`: Promise\\<Number | null>\n  * Retrieves the current alarm time (if set) as integer milliseconds since epoch. The alarm is considered to be set if it has not started, or if it has failed and any retry has not begun. If no alarm is set, `getAlarm()` returns `null`.\n\n#### Supported options\n\n* Same options as [`get()`](#get), but without `noCache`.\n\n### `setAlarm`\n\n* `setAlarm(scheduledTime Date | number, options Object optional)`: Promise\n\n  * Sets the current alarm time, accepting either a JavaScript `Date`, or integer milliseconds since epoch.\n\n  If `setAlarm()` is called with a time equal to or before `Date.now()`, the alarm will be scheduled for asynchronous execution in the immediate future. If the alarm handler is currently executing in this case, it will not be canceled. Alarms can be set to millisecond granularity and will usually execute within a few milliseconds after the set time, but can be delayed by up to a minute due to maintenance or failures while failover takes place.\n\n### `deleteAlarm`\n\n* `deleteAlarm(options Object optional)`: Promise\n  * Deletes the alarm if one exists. Does not cancel the alarm handler if it is currently executing.\n\n#### Supported options\n\n* `setAlarm()` and `deleteAlarm()` support the same options as [`put()`](#put), but without `noCache`.\n\n## Other\n\n### `deleteAll`\n\n* `deleteAll(options Object optional)`: Promise\n\n  * Deletes all stored data, effectively deallocating all storage used by the Durable Object. For Durable Objects with a key-value storage backend, `deleteAll()` removes all keys and associated values for an individual Durable Object. For Durable Objects with a [SQLite storage backend](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#create-sqlite-backed-durable-object-class), `deleteAll()` removes the entire contents of a Durable Object's private SQLite database, including both SQL data and key-value data.\n  * For Durable Objects with a key-value storage backend, an in-progress `deleteAll()` operation can fail, which may leave a subset of data undeleted. Durable Objects with a SQLite storage backend do not have a partial `deleteAll()` issue because `deleteAll()` operations are atomic (all or nothing).\n  * `deleteAll()` does not proactively delete [alarms](https://developers.cloudflare.com/durable-objects/api/alarms/). Use [`deleteAlarm()`](https://developers.cloudflare.com/durable-objects/api/alarms/#deletealarm) to delete an alarm.\n\n### `transactionSync`\n\n* `transactionSync(callback)`: any\n\n  * Only available when using SQLite-backed Durable Objects.\n\n  * Invokes `callback()` wrapped in a transaction, and returns its result.\n\n  * If `callback()` throws an exception, the transaction will be rolled back.\n\n  * The callback must complete synchronously, that is, it should not be declared `async` nor otherwise return a Promise. Only synchronous storage operations can be part of the transaction. This is intended for use with SQL queries using [`ctx.storage.sql.exec()`](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#exec), which complete sychronously.\n\n### `transaction`\n\n* `transaction(closureFunction(txn))`: Promise\n\n  * Runs the sequence of storage operations called on `txn` in a single transaction that either commits successfully or aborts.\n\n  * Explicit transactions are no longer necessary. Any series of write operations with no intervening `await` will automatically be submitted atomically, and the system will prevent concurrent events from executing while `await` a read operation (unless you use `allowConcurrency: true`). Therefore, a series of reads followed by a series of writes (with no other intervening I/O) are automatically atomic and behave like a transaction.\n\n* `txn`\n\n  * Provides access to the `put()`, `get()`, `delete()`, and `list()` methods documented above to run in the current transaction context. In order to get transactional behavior within a transaction closure, you must call the methods on the `txn` Object instead of on the top-level `ctx.storage` Object.\\\n    \\\n    Also supports a `rollback()` function that ensures any changes made during the transaction will be rolled back rather than committed. After `rollback()` is called, any subsequent operations on the `txn` Object will fail with an exception. `rollback()` takes no parameters and returns nothing to the caller.\n\n  * When using [the SQLite-backed storage engine](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#sqlite-storage-backend), the `txn` object is obsolete. Any storage operations performed directly on the `ctx.storage` object, including SQL queries using [`ctx.storage.sql.exec()`](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#exec), will be considered part of the transaction.\n\n### `sync`\n\n* `sync()`: Promise\n\n  * Synchronizes any pending writes to disk.\n\n  * This is similar to normal behavior from automatic write coalescing. If there are any pending writes in the write buffer (including those submitted with [the `allowUnconfirmed` option](#supported-options-1)), the returned promise will resolve when they complete. If there are no pending writes, the returned promise will be already resolved.\n\n## Storage properties\n\n### `sql`\n\n`sql` is a readonly property of type `DurableObjectStorage` encapsulating the [SQL API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#synchronous-sql-api).\n\n## Related resources\n\n* [Durable Objects: Easy, Fast, Correct Choose Three](https://blog.cloudflare.com/durable-objects-easy-fast-correct-choose-three/)\n* [Zero-latency SQLite storage in every Durable Object blog](https://blog.cloudflare.com/sqlite-in-durable-objects/)\n* [WebSockets API](https://developers.cloudflare.com/durable-objects/best-practices/websockets/)\n\n</page>\n\n<page>\n---\ntitle: Durable Object State · Cloudflare Durable Objects docs\ndescription: The DurableObjectState interface is accessible as an instance\n  property on the Durable Object class. This interface encapsulates methods that\n  modify the state of a Durable Object, for example which WebSockets are\n  attached to a Durable Object or how the runtime should handle concurrent\n  Durable Object requests.\nlastUpdated: 2025-12-18T18:32:26.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/api/state/\n  md: https://developers.cloudflare.com/durable-objects/api/state/index.md\n---\n\n## Description\n\nThe `DurableObjectState` interface is accessible as an instance property on the Durable Object class. This interface encapsulates methods that modify the state of a Durable Object, for example which WebSockets are attached to a Durable Object or how the runtime should handle concurrent Durable Object requests.\n\nThe `DurableObjectState` interface is different from the Storage API in that it does not have top-level methods which manipulate persistent application data. These methods are instead encapsulated in the [`DurableObjectStorage`](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/) interface and accessed by [`DurableObjectState::storage`](https://developers.cloudflare.com/durable-objects/api/state/#storage).\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "## Methods and Properties\n\n### `exports`\n\nContains loopback bindings to the Worker's own top-level exports. This has exactly the same meaning as [`ExecutionContext`'s `ctx.exports`](https://developers.cloudflare.com/workers/runtime-apis/context/#exports).\n\n### `waitUntil`\n\n`waitUntil` waits until the promise which is passed as a parameter resolves, and can extend a request context even after the last client disconnects. Refer to [Lifecycle of a Durable Object](https://developers.cloudflare.com/durable-objects/concepts/durable-object-lifecycle/) for more information.\n\n`waitUntil` has no effect in Durable Objects\n\nUnlike in Workers, `waitUntil` has no effect in Durable Objects. It exists only for API compatibility with the [Workers Runtime APIs](https://developers.cloudflare.com/workers/runtime-apis/context/#waituntil).\n\nDurable Objects automatically remain active as long as there is ongoing work or pending I/O, so `waitUntil` is not needed. Refer to [Lifecycle of a Durable Object](https://developers.cloudflare.com/durable-objects/concepts/durable-object-lifecycle/) for more information.\n\n#### Parameters\n\n* A required promise of any type.\n\n#### Return values\n\n* None.\n\n### `blockConcurrencyWhile`\n\n`blockConcurrencyWhile` executes an async callback while blocking any other events from being delivered to the Durable Object until the callback completes. This method guarantees ordering and prevents concurrent requests. All events that were not explicitly initiated as part of the callback itself will be blocked. Once the callback completes, all other events will be delivered.\n\n* `blockConcurrencyWhile` is commonly used within the constructor of the Durable Object class to enforce initialization to occur before any requests are delivered.\n* Another use case is executing `async` operations based on the current state of the Durable Object and using `blockConcurrencyWhile` to prevent that state from changing while yielding the event loop.\n* If the callback throws an exception, the object will be terminated and reset. This ensures that the object cannot be left stuck in an uninitialized state if something fails unexpectedly.\n* To avoid this behavior, enclose the body of your callback in a `try...catch` block to ensure it cannot throw an exception.\n\nTo help mitigate deadlocks there is a 30 second timeout applied when executing the callback. If this timeout is exceeded, the Durable Object will be reset. It is best practice to have the callback do as little work as possible to improve overall request throughput to the Durable Object.\n\nNote\n\nYou should only need `blockConcurrencyWhile` if you are making additional, asynchronous calls (such as to another API or service), and cannot tolerate other requests processed by the Durable Object changing its internal while the event loop is yielded from the original request.\n\nIn practice, this is quite rare, and most use cases do not need `blockConcurrencyWhile`.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* A required callback which returns a `Promise<T>`.\n\n#### Return values\n\n* A `Promise<T>` returned by the callback.\n\n### `acceptWebSocket`\n\n`acceptWebSocket` is part of the [WebSocket Hibernation API](https://developers.cloudflare.com/durable-objects/best-practices/websockets/#websocket-hibernation-api), which allows a Durable Object to be removed from memory to save costs while keeping its WebSockets connected.\n\n`acceptWebSocket` adds a WebSocket to the set of WebSockets attached to the Durable Object. Once called, any incoming messages will be delivered by calling the Durable Object's `webSocketMessage` handler, and `webSocketClose` will be invoked upon disconnect. After calling `acceptWebSocket`, the WebSocket is accepted and its `send` and `close` methods can be used.\n\nThe [WebSocket Hibernation API](https://developers.cloudflare.com/durable-objects/best-practices/websockets/#websocket-hibernation-api) takes the place of the standard [WebSockets API](https://developers.cloudflare.com/workers/runtime-apis/websockets/). Therefore, `ws.accept` must not have been called separately and `ws.addEventListener` method will not receive events as they will instead be delivered to the Durable Object.\n\nThe WebSocket Hibernation API permits a maximum of 32,768 WebSocket connections per Durable Object, but the CPU and memory usage of a given workload may further limit the practical number of simultaneous connections.\n\n#### Parameters\n\n* A required `WebSocket` with name `ws`.\n* An optional `Array<string>` of associated tags. Tags can be used to retrieve WebSockets via [`DurableObjectState::getWebSockets`](https://developers.cloudflare.com/durable-objects/api/state/#getwebsockets). Each tag is a maximum of 256 characters and there can be at most 10 tags associated with a WebSocket.\n\n#### Return values\n\n* None.\n\n### `getWebSockets`\n\n`getWebSockets` is part of the [WebSocket Hibernation API](https://developers.cloudflare.com/durable-objects/best-practices/websockets/#websocket-hibernation-api), which allows a Durable Object to be removed from memory to save costs while keeping its WebSockets connected.\n\n`getWebSockets` returns an `Array<WebSocket>` which is the set of WebSockets attached to the Durable Object. An optional tag argument can be used to filter the list according to tags supplied when calling [`DurableObjectState::acceptWebSocket`](https://developers.cloudflare.com/durable-objects/api/state/#acceptwebsocket).\n\n`waitUntil` is not necessary\n\nDisconnected WebSockets are not returned by this method, but `getWebSockets` may still return WebSockets even after `ws.close` has been called. For example, if the server-side WebSocket sends a close, but does not receive one back (and has not detected a disconnect from the client), then the connection is in the CLOSING 'readyState'. The client might send more messages, so the WebSocket is technically not disconnected.\n\n#### Parameters\n\n* An optional tag of type `string`.\n\n#### Return values\n\n* An `Array<WebSocket>`.\n\n### `setWebSocketAutoResponse`\n\n`setWebSocketAutoResponse` is part of the [WebSocket Hibernation API](https://developers.cloudflare.com/durable-objects/best-practices/websockets/#websocket-hibernation-api), which allows a Durable Object to be removed from memory to save costs while keeping its WebSockets connected.\n\n`setWebSocketAutoResponse` sets an automatic response, auto-response, for the request provided for all WebSockets attached to the Durable Object. If a request is received matching the provided request then the auto-response will be returned without waking WebSockets in hibernation and incurring billable duration charges.\n\n`setWebSocketAutoResponse` is a common alternative to setting up a server for static ping/pong messages because this can be handled without waking hibernating WebSockets.\n\n#### Parameters\n\n* An optional `WebSocketRequestResponsePair(request string, response string)` enabling any WebSocket accepted via [`DurableObjectState::acceptWebSocket`](https://developers.cloudflare.com/durable-objects/api/state/#acceptwebsocket) to automatically reply to the provided response when it receives the provided request. Both request and response are limited to 2,048 characters each. If the parameter is omitted, any previously set auto-response configuration will be removed. [`DurableObjectState::getWebSocketAutoResponseTimestamp`](https://developers.cloudflare.com/durable-objects/api/state/#getwebsocketautoresponsetimestamp) will still reflect the last timestamp that an auto-response was sent.\n\n#### Return values\n\n* None.\n\n### `getWebSocketAutoResponse`\n\n`getWebSocketAutoResponse` returns the `WebSocketRequestResponsePair` object last set by [`DurableObjectState::setWebSocketAutoResponse`](https://developers.cloudflare.com/durable-objects/api/state/#setwebsocketautoresponse), or null if not auto-response has been set.\n\ninspect `WebSocketRequestResponsePair`\n\n`WebSocketRequestResponsePair` can be inspected further by calling `getRequest` and `getResponse` methods.\n\n#### Parameters\n\n* None.\n\n#### Return values\n\n* A `WebSocketRequestResponsePair` or null.\n\n### `getWebSocketAutoResponseTimestamp`\n\n`getWebSocketAutoResponseTimestamp` is part of the [WebSocket Hibernation API](https://developers.cloudflare.com/durable-objects/best-practices/websockets/#websocket-hibernation-api), which allows a Durable Object to be removed from memory to save costs while keeping its WebSockets connected.\n\n`getWebSocketAutoResponseTimestamp` gets the most recent `Date` on which the given WebSocket sent an auto-response, or null if the given WebSocket never sent an auto-response.\n\n#### Parameters\n\n* A required `WebSocket`.\n\n#### Return values\n\n* A `Date` or null.\n\n### `setHibernatableWebSocketEventTimeout`\n\n`setHibernatableWebSocketEventTimeout` is part of the [WebSocket Hibernation API](https://developers.cloudflare.com/durable-objects/best-practices/websockets/#websocket-hibernation-api), which allows a Durable Object to be removed from memory to save costs while keeping its WebSockets connected.\n\n`setHibernatableWebSocketEventTimeout` sets the maximum amount of time in milliseconds that a WebSocket event can run for.\n\nIf no parameter or a parameter of `0` is provided and a timeout has been previously set, then the timeout will be unset. The maximum value of timeout is 604,800,000 ms (7 days).\n\n#### Parameters\n\n* An optional `number`.\n\n#### Return values\n\n* None.\n\n### `getHibernatableWebSocketEventTimeout`\n\n`getHibernatableWebSocketEventTimeout` is part of the [WebSocket Hibernation API](https://developers.cloudflare.com/durable-objects/best-practices/websockets/#websocket-hibernation-api), which allows a Durable Object to be removed from memory to save costs while keeping its WebSockets connected.\n\n`getHibernatableWebSocketEventTimeout` gets the currently set hibernatable WebSocket event timeout if one has been set via [`DurableObjectState::setHibernatableWebSocketEventTimeout`](https://developers.cloudflare.com/durable-objects/api/state/#sethibernatablewebsocketeventtimeout).\n\n#### Parameters\n\n* None.\n\n#### Return values\n\n* A number, or null if the timeout has not been set.\n\n### `getTags`\n\n`getTags` is part of the [WebSocket Hibernation API](https://developers.cloudflare.com/durable-objects/best-practices/websockets/#websocket-hibernation-api), which allows a Durable Object to be removed from memory to save costs while keeping its WebSockets connected.\n\n`getTags` returns tags associated with a given WebSocket. This method throws an exception if the WebSocket has not been associated with the Durable Object via [`DurableObjectState::acceptWebSocket`](https://developers.cloudflare.com/durable-objects/api/state/#acceptwebsocket).\n\n#### Parameters\n\n* A required `WebSocket`.\n\n#### Return values\n\n* An `Array<string>` of tags.\n\n### `abort`\n\n`abort` is used to forcibly reset a Durable Object. A JavaScript `Error` with the message passed as a parameter will be logged. This error is not able to be caught within the application code.\n\n* TypeScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "Not available in local development\n\n`abort` is not available in local development with the `wrangler dev` CLI command.\n\n#### Parameters\n\n* An optional `string` .\n\n#### Return values\n\n* None.\n\n## Properties\n\n### `id`\n\n`id` is a readonly property of type `DurableObjectId` corresponding to the [`DurableObjectId`](https://developers.cloudflare.com/durable-objects/api/id) of the Durable Object.\n\n### `storage`\n\n`storage` is a readonly property of type `DurableObjectStorage` encapsulating the [Storage API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/).\n\n## Related resources\n\n* [Durable Objects: Easy, Fast, Correct - Choose Three](https://blog.cloudflare.com/durable-objects-easy-fast-correct-choose-three/).\n\n</page>\n\n<page>\n---\ntitle: Durable Object Stub · Cloudflare Durable Objects docs\ndescription: The DurableObjectStub interface is a client used to invoke methods\n  on a remote Durable Object. The type of DurableObjectStub is generic to allow\n  for RPC methods to be invoked on the stub.\nlastUpdated: 2025-12-08T15:50:53.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/api/stub/\n  md: https://developers.cloudflare.com/durable-objects/api/stub/index.md\n---\n\n## Description\n\nThe `DurableObjectStub` interface is a client used to invoke methods on a remote Durable Object. The type of `DurableObjectStub` is generic to allow for RPC methods to be invoked on the stub.\n\nDurable Objects implement E-order semantics, a concept deriving from the [E distributed programming language](https://en.wikipedia.org/wiki/E_\\(programming_language\\)). When you make multiple calls to the same Durable Object, it is guaranteed that the calls will be delivered to the remote Durable Object in the order in which you made them. E-order semantics makes many distributed programming problems easier. E-order is implemented by the [Cap'n Proto](https://capnproto.org) distributed object-capability RPC protocol, which Cloudflare Workers uses for internal communications.\n\nIf an exception is thrown by a Durable Object stub all in-flight calls and future calls will fail with [exceptions](https://developers.cloudflare.com/durable-objects/observability/troubleshooting/). To continue invoking methods on a remote Durable Object a Worker must recreate the stub. There are no ordering guarantees between different stubs.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "## Properties\n\n### `id`\n\n`id` is a property of the `DurableObjectStub` corresponding to the [`DurableObjectId`](https://developers.cloudflare.com/durable-objects/api/id) used to create the stub.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "### `name`\n\n`name` is an optional property of a `DurableObjectStub`, which returns a name if it was provided upon stub creation either directly via [`DurableObjectNamespace::getByName`](https://developers.cloudflare.com/durable-objects/api/namespace/#getbyname) or indirectly via a [`DurableObjectId`](https://developers.cloudflare.com/durable-objects/api/id) created by [`DurableObjectNamespace::idFromName`](https://developers.cloudflare.com/durable-objects/api/namespace/#idfromname). This value is undefined if the [`DurableObjectId`](https://developers.cloudflare.com/durable-objects/api/id) used to create the `DurableObjectStub` was constructed using [`DurableObjectNamespace::newUniqueId`](https://developers.cloudflare.com/durable-objects/api/namespace/#newuniqueid).\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "## Related resources\n\n* [Durable Objects: Easy, Fast, Correct – Choose Three](https://blog.cloudflare.com/durable-objects-easy-fast-correct-choose-three/).\n\n</page>\n\n<page>\n---\ntitle: WebGPU · Cloudflare Durable Objects docs\ndescription: The WebGPU API allows you to use the GPU directly from JavaScript.\nlastUpdated: 2025-02-12T13:41:31.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/api/webgpu/\n  md: https://developers.cloudflare.com/durable-objects/api/webgpu/index.md\n---\n\nWarning\n\nThe WebGPU API is only available in local development. You cannot deploy Durable Objects to Cloudflare that rely on the WebGPU API. See [Workers AI](https://developers.cloudflare.com/workers-ai/) for information on running machine learning models on the GPUs in Cloudflare's global network.\n\nThe [WebGPU API](https://developer.mozilla.org/en-US/docs/Web/API/WebGPU_API) allows you to use the GPU directly from JavaScript.\n\nThe WebGPU API is only accessible from within [Durable Objects](https://developers.cloudflare.com/durable-objects/). You cannot use the WebGPU API from within Workers.\n\nTo use the WebGPU API in local development, enable the `experimental` and `webgpu` [compatibility flags](https://developers.cloudflare.com/workers/configuration/compatibility-flags/) in the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/) of your Durable Object.",
      "language": "unknown"
    },
    {
      "code": "The following subset of the WebGPU API is available from within Durable Objects:\n\n| API | Supported? | Notes |\n| - | - | - |\n| [`navigator.gpu`](https://developer.mozilla.org/en-US/docs/Web/API/Navigator/gpu) | ✅ | |\n| [`GPU.requestAdapter`](https://developer.mozilla.org/en-US/docs/Web/API/GPU/requestAdapter) | ✅ | |\n| [`GPUAdapterInfo`](https://developer.mozilla.org/en-US/docs/Web/API/GPUAdapterInfo) | ✅ | |\n| [`GPUAdapter`](https://developer.mozilla.org/en-US/docs/Web/API/GPUAdapter) | ✅ | |\n| [`GPUBindGroupLayout`](https://developer.mozilla.org/en-US/docs/Web/API/GPUBindGroupLayout) | ✅ | |\n| [`GPUBindGroup`](https://developer.mozilla.org/en-US/docs/Web/API/GPUBindGroup) | ✅ | |\n| [`GPUBuffer`](https://developer.mozilla.org/en-US/docs/Web/API/GPUBuffer) | ✅ | |\n| [`GPUCommandBuffer`](https://developer.mozilla.org/en-US/docs/Web/API/GPUCommandBuffer) | ✅ | |\n| [`GPUCommandEncoder`](https://developer.mozilla.org/en-US/docs/Web/API/GPUCommandEncoder) | ✅ | |\n| [`GPUComputePassEncoder`](https://developer.mozilla.org/en-US/docs/Web/API/GPUComputePassEncoder) | ✅ | |\n| [`GPUComputePipeline`](https://developer.mozilla.org/en-US/docs/Web/API/GPUComputePipeline) | ✅ | |\n| [`GPUComputePipelineError`](https://developer.mozilla.org/en-US/docs/Web/API/GPUPipelineError) | ✅ | |\n| [`GPUDevice`](https://developer.mozilla.org/en-US/docs/Web/API/GPUDevice) | ✅ | |\n| [`GPUOutOfMemoryError`](https://developer.mozilla.org/en-US/docs/Web/API/GPUOutOfMemoryError) | ✅ | |\n| [`GPUValidationError`](https://developer.mozilla.org/en-US/docs/Web/API/GPUValidationError) | ✅ | |\n| [`GPUInternalError`](https://developer.mozilla.org/en-US/docs/Web/API/GPUInternalError) | ✅ | |\n| [`GPUDeviceLostInfo`](https://developer.mozilla.org/en-US/docs/Web/API/GPUDeviceLostInfo) | ✅ | |\n| [`GPUPipelineLayout`](https://developer.mozilla.org/en-US/docs/Web/API/GPUPipelineLayout) | ✅ | |\n| [`GPUQuerySet`](https://developer.mozilla.org/en-US/docs/Web/API/GPUQuerySet) | ✅ | |\n| [`GPUQueue`](https://developer.mozilla.org/en-US/docs/Web/API/GPUQueue) | ✅ | |\n| [`GPUSampler`](https://developer.mozilla.org/en-US/docs/Web/API/GPUSampler) | ✅ | |\n| [`GPUCompilationMessage`](https://developer.mozilla.org/en-US/docs/Web/API/GPUCompilationMessage) | ✅ | |\n| [`GPUShaderModule`](https://developer.mozilla.org/en-US/docs/Web/API/GPUShaderModule) | ✅ | |\n| [`GPUSupportedFeatures`](https://developer.mozilla.org/en-US/docs/Web/API/GPUSupportedFeatures) | ✅ | |\n| [`GPUSupportedLimits`](https://developer.mozilla.org/en-US/docs/Web/API/GPUSupportedLimits) | ✅ | |\n| [`GPUMapMode`](https://developer.mozilla.org/en-US/docs/Web/API/WebGPU_API#reading_the_results_back_to_javascript) | ✅ | |\n| [`GPUShaderStage`](https://developer.mozilla.org/en-US/docs/Web/API/WebGPU_API#create_a_bind_group_layout) | ✅ | |\n| [`GPUUncapturedErrorEvent`](https://developer.mozilla.org/en-US/docs/Web/API/GPUUncapturedErrorEvent) | ✅ | |\n\nThe following subset of the WebGPU API is not yet supported:\n\n| API | Supported? | Notes |\n| - | - | - |\n| [`GPU.getPreferredCanvasFormat`](https://developer.mozilla.org/en-US/docs/Web/API/GPU/getPreferredCanvasFormat) | | |\n| [`GPURenderBundle`](https://developer.mozilla.org/en-US/docs/Web/API/GPURenderBundle) | | |\n| [`GPURenderBundleEncoder`](https://developer.mozilla.org/en-US/docs/Web/API/GPURenderBundleEncoder) | | |\n| [`GPURenderPassEncoder`](https://developer.mozilla.org/en-US/docs/Web/API/GPURenderPassEncoder) | | |\n| [`GPURenderPipeline`](https://developer.mozilla.org/en-US/docs/Web/API/GPURenderPipeline) | | |\n| [`GPUShaderModule`](https://developer.mozilla.org/en-US/docs/Web/API/GPUShaderModule) | | |\n| [`GPUTexture`](https://developer.mozilla.org/en-US/docs/Web/API/GPUTexture) | | |\n| [`GPUTextureView`](https://developer.mozilla.org/en-US/docs/Web/API/GPUTextureView) | | |\n| [`GPUExternalTexture`](https://developer.mozilla.org/en-US/docs/Web/API/GPUExternalTexture) | | |\n\n## Examples\n\n* [workers-wonnx](https://github.com/cloudflare/workers-wonnx/) — Image classification, running on a GPU via the WebGPU API, using the [wonnx](https://github.com/webonnx/wonnx) model inference runtime.\n\n</page>\n\n<page>\n---\ntitle: Rust API · Cloudflare Durable Objects docs\nlastUpdated: 2024-12-04T15:21:02.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/api/workers-rs/\n  md: https://developers.cloudflare.com/durable-objects/api/workers-rs/index.md\n---\n\n\n</page>\n\n<page>\n---\ntitle: Access Durable Objects Storage · Cloudflare Durable Objects docs\ndescription: |-\n  Durable Objects are a\n  powerful compute API that provides a compute with storage building block. Each\n  Durable Object has its own private, transactional, and strongly consistent\n  storage. Durable Objects\n  Storage API provides\n  access to a Durable Object's attached storage.\nlastUpdated: 2025-09-24T13:21:38.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/\n  md: https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/index.md\n---\n\nDurable Objects are a powerful compute API that provides a compute with storage building block. Each Durable Object has its own private, transactional, and strongly consistent storage. Durable Objects Storage API provides access to a Durable Object's attached storage.\n\nA Durable Object's [in-memory state](https://developers.cloudflare.com/durable-objects/reference/in-memory-state/) is preserved as long as the Durable Object is not evicted from memory. Inactive Durable Objects with no incoming request traffic can be evicted. There are normal operations like [code deployments](https://developers.cloudflare.com/workers/configuration/versions-and-deployments/) that trigger Durable Objects to restart and lose their in-memory state. For these reasons, you should use Storage API to persist state durably on disk that needs to survive eviction or restart of Durable Objects.\n\n## Access storage\n\nRecommended SQLite-backed Durable Objects\n\nCloudflare recommends all new Durable Object namespaces use the [SQLite storage backend](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#create-sqlite-backed-durable-object-class). These Durable Objects can continue to use storage [key-value API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#synchronous-kv-api).\n\nAdditionally, SQLite-backed Durable Objects allow you to store more types of data (such as tables), and offer Point In Time Recovery API which can restore a Durable Object's embedded SQLite database contents (both SQL data and key-value data) to any point in the past 30 days.\n\nThe [key-value storage backend](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/#create-durable-object-class-with-key-value-storage) remains for backwards compatibility, and a migration path from KV storage backend to SQLite storage backend for existing Durable Object namespaces will be available in the future.\n\nStorage billing on SQLite-backed Durable Objects\n\nStorage billing for SQLite-backed Durable Objects will be enabled in January 2026, with a target date of January 7, 2026 (no earlier). Only SQLite storage usage on and after the billing target date will incur charges. For more information, refer to [Billing for SQLite Storage](https://developers.cloudflare.com/changelog/2025-12-12-durable-objects-sqlite-storage-billing/).\n\n[Storage API methods](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/) are available on `ctx.storage` parameter passed to the Durable Object constructor. Storage API has several methods, including SQL, point-in-time recovery (PITR), key-value (KV), and alarm APIs.\n\nOnly Durable Object classes with a SQLite storage backend can access SQL API.\n\n### Create SQLite-backed Durable Object class\n\nUse `new_sqlite_classes` on the migration in your Worker's Wrangler file:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "[SQL API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#exec) is available on `ctx.storage.sql` parameter passed to the Durable Object constructor.\n\nSQLite-backed Durable Objects also offer [point-in-time recovery API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#pitr-point-in-time-recovery-api), which uses bookmarks to allow you to restore a Durable Object's embedded SQLite database to any point in time in the past 30 days.\n\n### Initialize instance variables from storage\n\nA common pattern is to initialize a Durable Object from [persistent storage](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/) and set instance variables the first time it is accessed. Since future accesses are routed to the same Durable Object, it is then possible to return any initialized values without making further calls to persistent storage.",
      "language": "unknown"
    },
    {
      "code": "### Remove a Durable Object's storage\n\nA Durable Object fully ceases to exist if, when it shuts down, its storage is empty. If you never write to a Durable Object's storage at all (including setting alarms), then storage remains empty, and so the Durable Object will no longer exist once it shuts down.\n\nHowever if you ever write using [Storage API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/), including setting alarms, then you must explicitly call [`storage.deleteAll()`](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#deleteall) to empty storage and [`storage.deleteAlarm()`](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#deletealarm) if you've configured an alarm. It is not sufficient to simply delete the specific data that you wrote, such as deleting a key or dropping a table, as some metadata may remain. The only way to remove all storage is to call `deleteAll()`. Calling `deleteAll()` ensures that a Durable Object will not be billed for storage.",
      "language": "unknown"
    },
    {
      "code": "## SQL API Examples\n\n[SQL API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#exec) examples below use the following SQL schema:",
      "language": "unknown"
    },
    {
      "code": "Iterate over query results as row objects:",
      "language": "unknown"
    },
    {
      "code": "Convert query results to an array of row objects:",
      "language": "unknown"
    },
    {
      "code": "Convert query results to an array of row values arrays:",
      "language": "unknown"
    },
    {
      "code": "Get first row object of query results:",
      "language": "unknown"
    },
    {
      "code": "Check if query results have exactly one row:",
      "language": "unknown"
    },
    {
      "code": "Returned cursor behavior:",
      "language": "unknown"
    },
    {
      "code": "Returned cursor and `raw()` iterator iterate over the same query results:",
      "language": "unknown"
    },
    {
      "code": "`sql.exec().rowsRead()`:",
      "language": "unknown"
    },
    {
      "code": "## TypeScript and query results\n\nYou can use TypeScript [type parameters](https://www.typescriptlang.org/docs/handbook/2/generics.html#working-with-generic-type-variables) to provide a type for your results, allowing you to benefit from type hints and checks when iterating over the results of a query.\n\nWarning\n\nProviding a type parameter does *not* validate that the query result matches your type definition. In TypeScript, properties (fields) that do not exist in your result type will be silently dropped.\n\nYour type must conform to the shape of a TypeScript [Record](https://www.typescriptlang.org/docs/handbook/utility-types.html#recordkeys-type) type representing the name (`string`) of the column and the type of the column. The column type must be a valid `SqlStorageValue`: one of `ArrayBuffer | string | number | null`.\n\nFor example,",
      "language": "unknown"
    },
    {
      "code": "This type can then be passed as the type parameter to a `sql.exec()` call:",
      "language": "unknown"
    },
    {
      "code": "You can represent the shape of any result type you wish, including more complex types. If you are performing a `JOIN` across multiple tables, you can compose a type that reflects the results of your queries.\n\n## Indexes in SQLite\n\nCreating indexes for your most queried tables and filtered columns reduces how much data is scanned and improves query performance at the same time. If you have a read-heavy workload (most common), this can be particularly advantageous. Writing to columns referenced in an index will add at least one (1) additional row written to account for updating the index, but this is typically offset by the reduction in rows read due to the benefits of an index.\n\n## SQL in Durable Objects vs D1\n\nCloudflare Workers offers a SQLite-backed serverless database product - [D1](https://developers.cloudflare.com/d1/). How should you compare [SQLite in Durable Objects](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/) and D1?\n\n**D1 is a managed database product.**\n\nD1 fits into a familiar architecture for developers, where application servers communicate with a database over the network. Application servers are typically Workers; however, D1 also supports external, non-Worker access via an [HTTP API](https://developers.cloudflare.com/api/resources/d1/subresources/database/methods/query/), which helps unlock [third-party tooling](https://developers.cloudflare.com/d1/reference/community-projects/#_top) support for D1.\n\nD1 aims for a \"batteries included\" feature set, including the above HTTP API, [database schema management](https://developers.cloudflare.com/d1/reference/migrations/#_top), [data import/export](https://developers.cloudflare.com/d1/best-practices/import-export-data/), and [database query insights](https://developers.cloudflare.com/d1/observability/metrics-analytics/#query-insights).\n\nWith D1, your application code and SQL database queries are not colocated which can impact application performance. If performance is a concern with D1, Workers has [Smart Placement](https://developers.cloudflare.com/workers/configuration/smart-placement/#_top) to dynamically run your Worker in the best location to reduce total Worker request latency, considering everything your Worker talks to, including D1.\n\n**SQLite in Durable Objects is a lower-level compute with storage building block for distributed systems.**\n\nBy design, Durable Objects are accessed with Workers-only.\n\nDurable Objects require a bit more effort, but in return, give you more flexibility and control. With Durable Objects, you must implement two pieces of code that run in different places: a front-end Worker which routes incoming requests from the Internet to a unique Durable Object, and the Durable Object itself, which runs on the same machine as the SQLite database. You get to choose what runs where, and it may be that your application benefits from running some application business logic right next to the database.\n\nWith SQLite in Durable Objects, you may also need to build some of your own database tooling that comes out-of-the-box with D1.\n\nSQL query pricing and limits are intended to be identical between D1 ([pricing](https://developers.cloudflare.com/d1/platform/pricing/), [limits](https://developers.cloudflare.com/d1/platform/limits/)) and SQLite in Durable Objects ([pricing](https://developers.cloudflare.com/durable-objects/platform/pricing/#sql-storage-billing), [limits](https://developers.cloudflare.com/durable-objects/platform/limits/)).\n\n## Related resources\n\n* [Zero-latency SQLite storage in every Durable Object blog post](https://blog.cloudflare.com/sqlite-in-durable-objects)\n\n</page>\n\n<page>\n---\ntitle: Invoke methods · Cloudflare Durable Objects docs\ndescription: All new projects and existing projects with a compatibility date\n  greater than or equal to 2024-04-03 should prefer to invoke Remote Procedure\n  Call (RPC) methods defined on a Durable Object class.\nlastUpdated: 2025-09-23T20:48:09.000Z\nchatbotDeprioritize: false\ntags: RPC\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/best-practices/create-durable-object-stubs-and-send-requests/\n  md: https://developers.cloudflare.com/durable-objects/best-practices/create-durable-object-stubs-and-send-requests/index.md\n---\n\n## Invoking methods on a Durable Object\n\nAll new projects and existing projects with a compatibility date greater than or equal to [`2024-04-03`](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#durable-object-stubs-and-service-bindings-support-rpc) should prefer to invoke [Remote Procedure Call (RPC)](https://developers.cloudflare.com/workers/runtime-apis/rpc/) methods defined on a Durable Object class.\n\nProjects requiring HTTP request/response flows or legacy projects can continue to invoke the `fetch()` handler on the Durable Object class.\n\n### Invoke RPC methods\n\nBy writing a Durable Object class which inherits from the built-in type `DurableObject`, public methods on the Durable Objects class are exposed as [RPC methods](https://developers.cloudflare.com/workers/runtime-apis/rpc/), which you can call using a [DurableObjectStub](https://developers.cloudflare.com/durable-objects/api/stub) from a Worker.\n\nAll RPC calls are [asynchronous](https://developers.cloudflare.com/workers/runtime-apis/rpc/lifecycle/), accept and return [serializable types](https://developers.cloudflare.com/workers/runtime-apis/rpc/), and [propagate exceptions](https://developers.cloudflare.com/workers/runtime-apis/rpc/error-handling/) to the caller without a stack trace. Refer to [Workers RPC](https://developers.cloudflare.com/workers/runtime-apis/rpc/) for complete details.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Note\n\nWith RPC, the `DurableObject` superclass defines `ctx` and `env` as class properties. What was previously called `state` is now called `ctx` when you extend the `DurableObject` class. The name `ctx` is adopted rather than `state` for the `DurableObjectState` interface to be consistent between `DurableObject` and `WorkerEntrypoint` objects.\n\nRefer to [Build a Counter](https://developers.cloudflare.com/durable-objects/examples/build-a-counter/) for a complete example.\n\n### Invoking the `fetch` handler\n\nIf your project is stuck on a compatibility date before [`2024-04-03`](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#durable-object-stubs-and-service-bindings-support-rpc), or has the need to send a [`Request`](https://developers.cloudflare.com/workers/runtime-apis/request/) object and return a `Response` object, then you should send requests to a Durable Object via the fetch handler.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "The `URL` associated with the [`Request`](https://developers.cloudflare.com/workers/runtime-apis/request/) object passed to the `fetch()` handler of your Durable Object must be a well-formed URL, but does not have to be a publicly-resolvable hostname.\n\nWithout RPC, customers frequently construct requests which corresponded to private methods on the Durable Object and dispatch requests from the `fetch` handler. RPC is obviously more ergonomic in this example.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Rules of Durable Objects · Cloudflare Durable Objects docs\ndescription: Durable Objects provide a powerful primitive for building stateful,\n  coordinated applications. Each Durable Object is a single-threaded,\n  globally-unique instance with its own persistent storage. Understanding how to\n  design around these properties is essential for building effective\n  applications.\nlastUpdated: 2025-12-19T13:42:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/best-practices/rules-of-durable-objects/\n  md: https://developers.cloudflare.com/durable-objects/best-practices/rules-of-durable-objects/index.md\n---\n\nDurable Objects provide a powerful primitive for building stateful, coordinated applications. Each Durable Object is a single-threaded, globally-unique instance with its own persistent storage. Understanding how to design around these properties is essential for building effective applications.\n\nThis is a guidebook on how to build more effective and correct Durable Object applications.\n\n## When to use Durable Objects\n\n### Use Durable Objects for stateful coordination, not stateless request handling\n\nWorkers are stateless functions: each request may run on a different instance, in a different location, with no shared memory between requests. Durable Objects are stateful compute: each instance has a unique identity, runs in a single location, and maintains state across requests.\n\nUse Durable Objects when you need:\n\n* **Coordination** — Multiple clients need to interact with shared state (chat rooms, multiplayer games, collaborative documents)\n* **Strong consistency** — Operations must be serialized to avoid race conditions (inventory management, booking systems, turn-based games)\n* **Per-entity storage** — Each user, tenant, or resource needs its own isolated database (multi-tenant SaaS, per-user data)\n* **Persistent connections** — Long-lived WebSocket connections that survive across requests (real-time notifications, live updates)\n* **Scheduled work per entity** — Each entity needs its own timer or scheduled task (subscription renewals, game timeouts)\n\nUse plain Workers when you need:\n\n* **Stateless request handling** — API endpoints, proxies, or transformations with no shared state\n* **Maximum global distribution** — Requests should be handled at the nearest edge location\n* **High fan-out** — Each request is independent and can be processed in parallel\n\n- JavaScript",
      "language": "unknown"
    },
    {
      "code": "- TypeScript",
      "language": "unknown"
    },
    {
      "code": "A common pattern is to use Workers as the stateless entry point that routes requests to Durable Objects when coordination is needed. The Worker handles authentication, validation, and response formatting, while the Durable Object handles the stateful logic.\n\n## Design and sharding\n\n### Model your Durable Objects around your \"atom\" of coordination\n\nThe most important design decision is choosing what each Durable Object represents. Create one Durable Object per logical unit that needs coordination: a chat room, a game session, a document, a user's data, or a tenant's workspace.\n\nThis is the key insight that makes Durable Objects powerful. Instead of a shared database with locks, each \"atom\" of your application gets its own single-threaded execution environment with private storage.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Note\n\nIf you have global application or user configuration that you need to access frequently (on every request), consider using [Workers KV](https://developers.cloudflare.com/kv/) instead.\n\nDo not create a single \"global\" Durable Object that handles all requests:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "### Use deterministic IDs for predictable routing\n\nUse `getByName()` with meaningful, deterministic strings for consistent routing. The same input always produces the same Durable Object ID, ensuring requests for the same logical entity always reach the same instance.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Creating a stub does not instantiate or wake up the Durable Object. The Durable Object is only activated when you call a method on the stub.\n\nUse `newUniqueId()` only when you need a new, random instance and will store the mapping externally:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "### Use parent-child relationships for related entities\n\nDo not put all your data in a single Durable Object. When you have hierarchical data (workspaces containing projects, game servers managing matches), create separate child Durable Objects for each entity. The parent coordinates and tracks children, while children handle their own state independently.\n\nThis enables parallelism: operations on different children can happen concurrently, while each child maintains its own single-threaded consistency ([read more about this pattern](https://developers.cloudflare.com/reference-architecture/diagrams/storage/durable-object-control-data-plane-pattern/)).\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "With this pattern:\n\n* Listing matches only queries the parent (children stay hibernated)\n* Different matches process player actions in parallel\n* Each match has its own SQLite database for player data\n\n### Consider location hints for latency-sensitive applications\n\nBy default, a Durable Object is created near the location of the first request it receives. For most applications, this works well. However, you can provide a location hint to influence where the Durable Object is created.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Location hints are suggestions, not guarantees. Refer to [Data location](https://developers.cloudflare.com/durable-objects/reference/data-location/) for available regions and details.\n\n## Storage and state\n\n### Use SQLite-backed Durable Objects\n\n[SQLite storage](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/) is the recommended storage backend for new Durable Objects. It provides a familiar SQL API for relational queries, indexes, transactions, and better performance than the legacy key-value storage backed Durable Objects. SQLite Durable Objects also support the KV API in synchronous and asynchronous versions.\n\nConfigure your Durable Object class to use SQLite storage in your Wrangler configuration:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Then use the SQL API in your Durable Object:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Refer to [Access Durable Objects storage](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/) for more details on the SQL API.\n\n### Initialize storage and run migrations in the constructor\n\nUse `blockConcurrencyWhile()` in the constructor to run migrations and initialize state before any requests are processed. This ensures your schema is ready and prevents race conditions during initialization.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "### Understand the difference between in-memory state and persistent storage\n\nDurable Objects provide multiple state management layers, each with different characteristics:\n\n| Type | Speed | Persistence | Use Case |\n| - | - | - | - |\n| In-memory (class properties) | Fastest | Lost on eviction or crash | Caching, active connections |\n| SQLite storage | Fast | Durable across restarts | Primary data storage |\n| External (R2, D1) | Variable | Durable, cross-DO accessible | Large files, shared data |\n\nIn-memory state is **not preserved** if the Durable Object is evicted from memory due to inactivity, or if it crashes from an uncaught exception. Always persist important state to SQLite storage.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Warning\n\nIf an uncaught exception occurs in your Durable Object, the runtime may terminate the instance. Any in-memory state will be lost, but SQLite storage remains intact. Always persist critical state to storage before performing operations that might fail.\n\n### Create indexes for frequently-queried columns\n\nJust like any database, indexes dramatically improve read performance for frequently-filtered columns. The cost is slightly more storage and marginally slower writes.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "### Understand how input and output gates work\n\nWhile Durable Objects are single-threaded, JavaScript's `async`/`await` can allow multiple requests to interleave execution while a request waits for the result of an asynchronous operation. Cloudflare's runtime uses **input gates** and **output gates** to prevent data races and ensure correctness by default.\n\n**Input gates** block new events (incoming requests, fetch responses) while synchronous JavaScript execution is in progress. Awaiting async operations like `fetch()` or KV storage methods opens the input gate, allowing other requests to interleave. However, storage operations provide special protection:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "**Output gates** hold outgoing network messages (responses, fetch requests) until pending storage writes complete. This ensures clients never see confirmation of data that has not been persisted:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "**Write coalescing:** Multiple storage writes without intervening `await` calls are automatically batched into a single atomic implicit transaction:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "For more details, see [Durable Objects: Easy, Fast, Correct — Choose three](https://blog.cloudflare.com/durable-objects-easy-fast-correct-choose-three/) and the [glossary](https://developers.cloudflare.com/durable-objects/reference/glossary/).\n\n### Avoid race conditions with non-storage I/O\n\nInput gates only protect during storage operations. Non-storage I/O like `fetch()` or writing to R2 allows other requests to interleave, which can cause race conditions:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "To handle this, use optimistic locking (check-and-set) patterns: read a version number before the external call, then verify it has not changed before writing.\n\nNote\n\nWith the legacy KV storage backend, use the [`transaction()`](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#transaction) method for atomic read-modify-write operations across async boundaries.\n\n### Use `blockConcurrencyWhile()` sparingly\n\nThe [`blockConcurrencyWhile()`](https://developers.cloudflare.com/durable-objects/api/state/#blockconcurrencywhile) method guarantees that no other events are processed until the provided callback completes, even if the callback performs asynchronous I/O. This is useful for operations that must be atomic, such as state initialization from storage in the constructor:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Because `blockConcurrencyWhile()` blocks *all* concurrency unconditionally, it significantly reduces throughput. If each call takes \\~5ms, that individual Durable Object is limited to approximately 200 requests/second. Reserve it for initialization and migrations, not regular request handling. For normal operations, rely on input/output gates and write coalescing instead.\n\nFor atomic read-modify-write operations during request handling, prefer [`transaction()`](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#transaction) over `blockConcurrencyWhile()`. Transactions provide atomicity for storage operations without blocking unrelated concurrent requests.\n\nWarning\n\nUsing `blockConcurrencyWhile()` across I/O operations (such as `fetch()`, KV, R2, or other external API calls) is an anti-pattern. This is equivalent to holding a lock across I/O in other languages or concurrency frameworks — it blocks all other requests while waiting for slow external operations, severely degrading throughput. Keep `blockConcurrencyWhile()` callbacks fast and limited to local storage operations.\n\n## Communication and API design\n\n### Use RPC methods instead of the `fetch()` handler\n\nProjects with a [compatibility date](https://developers.cloudflare.com/workers/configuration/compatibility-flags/) of `2024-04-03` or later should use RPC methods. RPC is more ergonomic, provides better type safety, and eliminates manual request/response parsing.\n\nDefine public methods on your Durable Object class, and call them directly from stubs with full TypeScript support:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Refer to [Invoke methods](https://developers.cloudflare.com/durable-objects/best-practices/create-durable-object-stubs-and-send-requests/) for more details on RPC and the legacy `fetch()` handler.\n\n### Initialize Durable Objects explicitly with an `init()` method\n\nDurable Objects do not know their own name or ID from within. If your Durable Object needs to know its identity (for example, to store a reference to itself or to communicate with related objects), you must explicitly initialize it.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "### Always `await` RPC calls\n\nWhen calling methods on a Durable Object stub, always use `await`. Unawaited calls create dangling promises, causing errors to be swallowed and return values to be lost.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "## Error handling\n\n### Handle errors and use exception boundaries\n\nUncaught exceptions in a Durable Object can leave it in an unknown state and may cause the runtime to terminate the instance. Wrap risky operations in try/catch blocks, and handle errors appropriately.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "When calling Durable Objects from a Worker, errors may include `.retryable` and `.overloaded` properties indicating whether the operation can be retried. For transient failures, implement exponential backoff to avoid overwhelming the system.\n\nRefer to [Error handling](https://developers.cloudflare.com/durable-objects/best-practices/error-handling/) for details on error properties, retry strategies, and exponential backoff patterns.\n\n## WebSockets and real-time\n\n### Use the Hibernatable WebSockets API for cost efficiency\n\nThe Hibernatable WebSockets API allows Durable Objects to sleep while maintaining WebSocket connections. This significantly reduces costs for applications with many idle connections.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "With the Hibernation API, your Durable Object can go to sleep when there is no active JavaScript execution, but WebSocket connections remain open. When a message arrives, the Durable Object wakes up automatically.\n\nRefer to [WebSockets](https://developers.cloudflare.com/durable-objects/best-practices/websockets/) for more details.\n\n### Use `serializeAttachment()` to persist per-connection state\n\nWebSocket attachments let you store metadata for each connection that survives hibernation. Use this for user IDs, session tokens, or other per-connection data.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "## Scheduling and lifecycle\n\n### Use alarms for per-entity scheduled tasks\n\nEach Durable Object can schedule its own future work using the [Alarms API](https://developers.cloudflare.com/durable-objects/api/alarms/), allowing a Durable Object to execute background tasks on any interval without an incoming request, RPC call, or WebSocket message.\n\nKey points about alarms:\n\n* **`setAlarm(timestamp)`** schedules the `alarm()` handler to run at any time in the future (millisecond precision)\n* **Alarms do not repeat automatically** — you must call `setAlarm()` again to schedule the next execution\n* **Only schedule alarms when there is work to do** — avoid waking up every Durable Object on short intervals (seconds), as each alarm invocation incurs costs\n\n- JavaScript",
      "language": "unknown"
    },
    {
      "code": "- TypeScript",
      "language": "unknown"
    },
    {
      "code": "### Make alarm handlers idempotent\n\nIn rare cases, alarms may fire more than once. Your `alarm()` handler should be safe to run multiple times without causing issues.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "### Clean up storage with `deleteAll()`\n\nTo fully clear a Durable Object's storage, call `deleteAll()`. Simply deleting individual keys or dropping tables is not sufficient, as some internal metadata may remain. If you have alarms set, delete those first.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "## Anti-patterns to avoid\n\n### Do not use a single Durable Object as a global singleton\n\nA single Durable Object handling all traffic becomes a bottleneck. While async operations allow request interleaving, all synchronous JavaScript execution is single-threaded, and storage operations provide serialization guarantees that limit throughput.\n\nA common mistake is using a Durable Object for global rate limiting or global counters. This funnels all traffic through a single instance:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "This pattern does not scale. As traffic increases, the single Durable Object becomes a chokepoint. Instead, identify natural coordination boundaries in your application (per user, per room, per document) and create separate Durable Objects for each.\n\n## Testing and migrations\n\n### Test with Vitest and plan for class migrations\n\nUse `@cloudflare/vitest-pool-workers` for testing Durable Objects. The integration provides isolated storage per test and utilities for direct instance access.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Configure Vitest in your `vitest.config.ts`:",
      "language": "unknown"
    },
    {
      "code": "For schema changes, run migrations in the constructor using `blockConcurrencyWhile()`. For class renames or deletions, use Wrangler migrations:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Refer to [Durable Objects migrations](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/) for more details on class migrations, and [Testing with Durable Objects](https://developers.cloudflare.com/durable-objects/examples/testing-with-durable-objects/) for comprehensive testing patterns including SQLite queries and alarm testing.\n\n</page>\n\n<page>\n---\ntitle: Error handling · Cloudflare Durable Objects docs\ndescription: Any uncaught exceptions thrown by a Durable Object or thrown by\n  Durable Objects' infrastructure (such as overloads or network errors) will be\n  propagated to the callsite of the client. Catching these exceptions allows you\n  to retry creating the DurableObjectStub and sending requests.\nlastUpdated: 2025-09-29T13:29:31.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/best-practices/error-handling/\n  md: https://developers.cloudflare.com/durable-objects/best-practices/error-handling/index.md\n---\n\nAny uncaught exceptions thrown by a Durable Object or thrown by Durable Objects' infrastructure (such as overloads or network errors) will be propagated to the callsite of the client. Catching these exceptions allows you to retry creating the [`DurableObjectStub`](https://developers.cloudflare.com/durable-objects/api/stub) and sending requests.\n\nJavaScript Errors with the property `.retryable` set to True are suggested to be retried if requests to the Durable Object are idempotent, or can be applied multiple times without changing the response. If requests are not idempotent, then you will need to decide what is best for your application. It is strongly recommended to apply exponential backoff when retrying requests.\n\nJavaScript Errors with the property `.overloaded` set to True should not be retried. If a Durable Object is overloaded, then retrying will worsen the overload and increase the overall error rate.\n\nRecreating the DurableObjectStub after exceptions\n\nMany exceptions leave the [`DurableObjectStub`](https://developers.cloudflare.com/durable-objects/api/stub) in a \"broken\" state, such that all attempts to send additional requests will just fail immediately with the original exception. To avoid this, you should avoid reusing a `DurableObjectStub` after it throws an exception. You should instead create a new one for any subsequent requests.\n\n## How exceptions are thrown\n\nDurable Objects can throw exceptions in one of two ways:\n\n* An exception can be thrown within the user code which implements a Durable Object class. The resulting exception will have a `.remote` property set to `True` in this case.\n* An exception can be generated by Durable Object's infrastructure. Some sources of infrastructure exceptions include: transient internal errors, sending too many requests to a single Durable Object, and too many requests being queued due to slow or excessive I/O (external API calls or storage operations) within an individual Durable Object. Some infrastructure exceptions may also have the `.remote` property set to `True` -- for example, when the Durable Object exceeds its memory or CPU limits.\n\nRefer to [Troubleshooting](https://developers.cloudflare.com/durable-objects/observability/troubleshooting/) to review the types of errors returned by a Durable Object and/or Durable Objects infrastructure and how to prevent them.\n\n## Example\n\nThis example demonstrates retrying requests using the recommended exponential backoff algorithm.",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Use WebSockets · Cloudflare Durable Objects docs\ndescription: This guide covers how to use Durable Objects as WebSocket servers\n  that can connect thousands of clients (per instance), as well as a WebSocket\n  client to connect to other servers or even Durable Objects.\nlastUpdated: 2025-12-08T17:05:58.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/best-practices/websockets/\n  md: https://developers.cloudflare.com/durable-objects/best-practices/websockets/index.md\n---\n\nThis guide covers how to use Durable Objects as WebSocket servers that can connect thousands of clients (per instance), as well as a WebSocket client to connect to other servers or even Durable Objects.\n\nThere are two sets of WebSockets API:\n\n1. **Native Durable Object WebSocket API**, which allows your Durable Object to hibernate without disconnecting clients when not actively doing work **(recommended)**.\n2. **Web Standard WebSocket APIs**, using the familiar `addEventListener` event pattern.\n\n## What are WebSockets?\n\nWebSockets are long-lived TCP connections that enable bi-directional, real-time communication between client and server. Both Cloudflare Durable Objects and Workers can act as WebSocket endpoints - either as a client or as a server. Because WebSocket sessions are long-lived, applications commonly use Durable Objects to accept either the client or server connection. While there are other use cases for using Workers exclusively with WebSockets, for example proxying WebSocket messages, WebSockets are most useful when combined with Durable Objects.\n\nBecause Durable Objects provide a single-point-of-coordination between [Cloudflare Workers](https://developers.cloudflare.com/workers/), a single Durable Object instance can be used in parallel with WebSockets to coordinate between multiple clients, such as participants in a chat room or a multiplayer game. Refer to [Cloudflare Edge Chat Demo](https://github.com/cloudflare/workers-chat-demo) for an example of using Durable Objects with WebSockets.\n\nBoth Cloudflare Durable Objects and Workers can use the [Web Standard WebSocket API](https://developers.cloudflare.com/workers/runtime-apis/websockets/) to build applications, but a major differentiator of Cloudflare Durable Objects relative to other platforms is the ability to Hibernate WebSocket connections to save costs. Clients can remain connected when the Durable Object is idle (and not sending messages or running compute tasks), which allows you to push events to clients and minimize the active duration (GB-seconds) associated with long-running Durable Object processes.\n\n## Durable Objects' Hibernation WebSocket API\n\nIn addition to [the Web Standard WebSocket API](https://developers.cloudflare.com/workers/runtime-apis/websockets/), Cloudflare Durable Objects can use the WebSocket Hibernation API which extends the Web Standard WebSocket API to reduce costs. Specifically, [billable Duration (GB-s) charges](https://developers.cloudflare.com/durable-objects/platform/pricing/) are not incurred during periods of inactivity.\n\n### How does Durable Object Hibernation work with WebSockets?\n\nWhen a Durable Object receives no events (like alarms) or messages for a short period of time, the Durable Object is evicted from memory to avoid unnecessary charges (refer to [Lifecycle of a Durable Object](https://developers.cloudflare.com/durable-objects/concepts/durable-object-lifecycle/)). The WebSocket clients remain connected to the Cloudflare network. When your Durable Object receives an event during hibernation, it is re-initialized, its `constructor` function is called, and it can access the WebSocket clients with the `this.ctx.getWebSockets()` function.\n\nWhen the Durable Object is evicted from memory, its in-memory state is reset. It is common to rely on in-memory state to organize your WebSockets (for example, keeping your WebSockets in rooms with a `Map<WebSocket, Object>` data type). With Hibernation, you must restore the in-memory state of your Durable Object within the `constructor` function.\n\nTo do this, you can use the [`serializeAttachment`](#websocketserializeattachment) to persist additional data with the Durable Object WebSocket class, which will persist the data to the Durable Object's storage. Upon re-initialization of the Durable Object, you can access this data with [`deserializeAttachment`](#websocketdeserializeattachment).\n\nThe Durable Object WebSocket class consists of Cloudflare-specific extensions to the Web Standard WebSocket API. These extensions are either present on the [DurableObjectState](https://developers.cloudflare.com/durable-objects/api/state) interface, or as handler methods on the Durable Object class.\n\nNote\n\nHibernation is only supported when a Durable Object acts as a WebSocket server. Currently, outgoing WebSockets cannot hibernate.\n\nEvents, for example [alarms](https://developers.cloudflare.com/durable-objects/api/alarms/), incoming requests, and scheduled callbacks using `setTimeout/setInterval`, can prevent a Durable Object from being inactive and therefore prevent this cost saving. Read more in the section [When does a Durable Object incur duration charges?](https://developers.cloudflare.com/durable-objects/platform/pricing/#when-does-a-durable-object-incur-duration-charges).\n\n### Example\n\nTo use WebSockets with Durable Objects, you first need to proxy the `request` object from the Worker to the Durable Object, as is done in the [WebSocket Standard API example](https://developers.cloudflare.com/durable-objects/examples/websocket-server/). Using the Hibernation WebSockets API in Durable Objects differs slightly from using WebSocket Standard APIs. In summary, [`DurableObjectState::acceptWebSocket`](https://developers.cloudflare.com/durable-objects/api/state/#acceptwebsocket) is called to accept the server side of the WebSocket connection, and handler methods are defined on the Durable Object class for relevant event types rather than adding event listeners.\n\nIf an event occurs for a hibernated Durable Object's corresponding handler method, it will return to memory. This will call the Durable Object's constructor, so it is best to minimize work in the constructor when using WebSocket hibernation.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "Similar to the [WebSocket Standard API example](https://developers.cloudflare.com/durable-objects/examples/websocket-server/), to execute this code, configure your Wrangler file to include a Durable Object [binding](https://developers.cloudflare.com/durable-objects/get-started/#4-configure-durable-object-bindings) and [migration](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/) based on the namespace and class name chosen previously.\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "A full example can be found in [Build a WebSocket server with WebSocket Hibernation](https://developers.cloudflare.com/durable-objects/examples/websocket-hibernation-server/).\n\nSupport for local development\n\nPrior to `wrangler@3.13.2` and Miniflare `v3.20231016.0`, WebSockets did not hibernate when using local development environments such as `wrangler dev` or Miniflare.\n\nIf you are using older versions, note that while hibernatable WebSocket events such as [`webSocketMessage()`](https://developers.cloudflare.com/durable-objects/api/base/#websocketmessage) will still be delivered, the Durable Object will never be evicted from memory.\n\n### Extended methods\n\nThe following are methods available on the **Native Durable Object WebSocket API**, the WebSocket class available in Durable Objects. These methods facilitate persisting state to storage to set and restore state before and after a Durable Object's hibernation.\n\n#### `WebSocket.serializeAttachment()`\n\n* `serializeAttachment(value any)`: void\n\n  * Keeps a copy of `value` associated with the WebSocket to survive hibernation. The value can be any type supported by the [structured clone algorithm](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm), which is true of most types. If the value needs to be durable please use [Durable Object Storage](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/).\n\n  * If you modify `value` after calling this method, those changes will not be retained unless you call this method again. The serialized size of `value` is limited to 2,048 bytes, otherwise this method will throw an error. If you need larger values to survive hibernation, use the [Storage API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/) and pass the corresponding key to this method so it can be retrieved later.\n\n#### `WebSocket.deserializeAttachment()`\n\n* `deserializeAttachment()`: any\n\n  * Retrieves the most recent value passed to `serializeAttachment()`, or `null` if none exists.\n\n## WebSocket Standard API\n\nWebSocket connections are established by making an HTTP GET request with the `Upgrade: websocket` header. A Cloudflare Worker is commonly used to validate the request, proxy the request to the Durable Object to accept the server side connection, and return the client side connection in the response.\n\nValidate requests in a Worker\n\nBoth Workers and Durable Objects are billed, in part, based on the number of requests they receive. To avoid being billed for requests against a Durable Object for invalid requests, be sure to validate requests in your Worker.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "Each WebSocket server in this example is represented by a Durable Object. This WebSocket server creates a single WebSocket connection and responds to all messages over that connection with the total number of accepted WebSocket connections. In the Durable Object's fetch handler we create client and server connections and add event listeners for relevant event types.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "To execute this code, configure your Wrangler file to include a Durable Object [binding](https://developers.cloudflare.com/durable-objects/get-started/#4-configure-durable-object-bindings) and [migration](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/) based on the namespace and class name chosen previously.\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "A full example can be found in [Build a WebSocket server](https://developers.cloudflare.com/durable-objects/examples/websocket-server/).\n\nWebSockets disconnection\n\nCode updates will disconnect all WebSockets. If you deploy a new version of a Worker, every Durable Object is restarted. Any connections to old Durable Objects will be disconnected.\n\n## Related resources\n\n* [Mozilla Developer Network's (MDN) documentation on the WebSocket class](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)\n* [Cloudflare's WebSocket template for building applications on Workers using WebSockets](https://github.com/cloudflare/websocket-template)\n* [Durable Object base class](https://developers.cloudflare.com/durable-objects/api/base/)\n* [Durable Object State interface](https://developers.cloudflare.com/durable-objects/api/state/)\n\n</page>\n\n<page>\n---\ntitle: Lifecycle of a Durable Object · Cloudflare Durable Objects docs\ndescription: This section describes the lifecycle of a Durable Object.\nlastUpdated: 2025-08-27T13:08:43.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/concepts/durable-object-lifecycle/\n  md: https://developers.cloudflare.com/durable-objects/concepts/durable-object-lifecycle/index.md\n---\n\nThis section describes the lifecycle of a [Durable Object](https://developers.cloudflare.com/durable-objects/concepts/what-are-durable-objects/).\n\nTo use a Durable Object you need to create a [Durable Object Stub](https://developers.cloudflare.com/durable-objects/api/stub/). Simply creating the Durable Object Stub does not send a request to the Durable Object, and therefore the Durable Object is not yet instantiated. A request is sent to the Durable Object and its lifecycle begins only once a method is invoked on the Durable Object Stub.",
      "language": "unknown"
    },
    {
      "code": "## Durable Object Lifecycle state transitions\n\nA Durable Object can be in one of the following states at any moment:\n\n| State | Description |\n| - | - |\n| **Active, in-memory** | The Durable Object runs, in memory, and handles incoming requests. |\n| **Idle, in-memory non-hibernateable** | The Durable Object waits for the next incoming request/event, but does not satisfy the criteria for hibernation. |\n| **Idle, in-memory hibernateable** | The Durable Object waits for the next incoming request/event and satisfies the criteria for hibernation. It is up to the runtime to decide when to hibernate the Durable Object. Currently, it is after 10 seconds of inactivity while in this state. |\n| **Hibernated** | The Durable Object is removed from memory. Hibernated WebSocket connections stay connected. |\n| **Inactive** | The Durable Object is completely removed from the host process and might need to cold start. This is the initial state of all Durable Objects. |\n\nThis is how a Durable Object transitions among these states (each state is in a rounded rectangle).\n\n![Lifecycle of a Durable Object](https://developers.cloudflare.com/_astro/lifecycle-of-a-do.C3BLS8lH_Z2nkrrY.webp)\n\nAssuming a Durable Object does not run, the first incoming request or event (like an alarm) will execute the `constructor()` of the Durable Object class, then run the corresponding function invoked.\n\nAt this point the Durable Object is in the **active in-memory state**.\n\nOnce all incoming requests or events have been processed, the Durable Object remains idle in-memory for a few seconds either in a hibernateable state or in a non-hibernateable state.\n\nHibernation can only occur if **all** of the conditions below are true:\n\n* No `setTimeout`/`setInterval` scheduled callbacks are set, since there would be no way to recreate the callback after hibernating.\n* No in-progress awaited `fetch()` exists, since it is considered to be waiting for I/O.\n* No WebSocket standard API is used.\n* No request/event is still being processed, because hibernating would mean losing track of the async function which is eventually supposed to return a response to that request.\n\nAfter 10 seconds of no incoming request or event, and all the above conditions satisfied, the Durable Object will transition into the **hibernated** state.\n\nWarning\n\nWhen hibernated, the in-memory state is discarded, so ensure you persist all important information in the Durable Object's storage.\n\nIf any of the above conditions is false, the Durable Object remains in-memory, in the **idle, in-memory, non-hibernateable** state.\n\nIn case of an incoming request or event while in the **hibernated** state, the `constructor()` will run again, and the Durable Object will transition to the **active, in-memory** state and execute the invoked function.\n\nWhile in the **idle, in-memory, non-hibernateable** state, after 70-140 seconds of inactivity (no incoming requests or events), the Durable Object will be evicted entirely from memory and potentially from the Cloudflare host and transition to the **inactive** state.\n\nObjects in the **hibernated** state keep their Websocket clients connected, and the runtime decides if and when to transition the object to the **inactive** state (for example deciding to move the object to a different host) thus restarting the lifecycle.\n\nThe next incoming request or event starts the cycle again.\n\nLifecycle states incurring duration charges\n\nA Durable Object incurs charges only when it is **actively running in-memory**, or when it is **idle in-memory and non-hibernateable** (indicated as green rectangles in the diagram).\n\n</page>\n\n<page>\n---\ntitle: What are Durable Objects? · Cloudflare Durable Objects docs\ndescription: \"A Durable Object is a special kind of Cloudflare Worker which\n  uniquely combines compute with storage. Like a Worker, a Durable Object is\n  automatically provisioned geographically close to where it is first requested,\n  starts up quickly when needed, and shuts down when idle. You can have millions\n  of them around the world. However, unlike regular Workers:\"\nlastUpdated: 2025-09-24T13:21:38.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/concepts/what-are-durable-objects/\n  md: https://developers.cloudflare.com/durable-objects/concepts/what-are-durable-objects/index.md\n---\n\nA Durable Object is a special kind of [Cloudflare Worker](https://developers.cloudflare.com/workers/) which uniquely combines compute with storage. Like a Worker, a Durable Object is automatically provisioned geographically close to where it is first requested, starts up quickly when needed, and shuts down when idle. You can have millions of them around the world. However, unlike regular Workers:\n\n* Each Durable Object has a **globally-unique name**, which allows you to send requests to a specific object from anywhere in the world. Thus, a Durable Object can be used to coordinate between multiple clients who need to work together.\n* Each Durable Object has some **durable storage** attached. Since this storage lives together with the object, it is strongly consistent yet fast to access.\n\nTherefore, Durable Objects enable **stateful** serverless applications.\n\n## Durable Objects highlights\n\nDurable Objects have properties that make them a great fit for distributed stateful scalable applications.\n\n**Serverless compute, zero infrastructure management**\n\n* Durable Objects are built on-top of the Workers runtime, so they support exactly the same code (JavaScript and WASM), and similar memory and CPU limits.\n* Each Durable Object is [implicitly created on first access](https://developers.cloudflare.com/durable-objects/api/namespace/#get). User applications are not concerned with their lifecycle, creating them or destroying them. Durable Objects migrate among healthy servers, and therefore applications never have to worry about managing them.\n* Each Durable Object stays alive as long as requests are being processed, and remains alive for several seconds after being idle before hibernating, allowing applications to [exploit in-memory caching](https://developers.cloudflare.com/durable-objects/reference/in-memory-state/) while handling many consecutive requests and boosting their performance.\n\n**Storage colocated with compute**\n\n* Each Durable Object has its own [durable, transactional, and strongly consistent storage](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/) (up to 10 GB[1](#user-content-fn-1)), persisted across requests, and accessible only within that object.\n\n**Single-threaded concurrency**\n\n* Each [Durable Object instance has an identifier](https://developers.cloudflare.com/durable-objects/api/id/), either randomly-generated or user-generated, which allows you to globally address which Durable Object should handle a specific action or request.\n* Durable Objects are single-threaded and cooperatively multi-tasked, just like code running in a web browser. For more details on how safety and correctness are achieved, refer to the blog post [\"Durable Objects: Easy, Fast, Correct — Choose three\"](https://blog.cloudflare.com/durable-objects-easy-fast-correct-choose-three/).\n\n**Elastic horizontal scaling across Cloudflare's global network**\n\n* Durable Objects can be spread around the world, and you can [optionally influence where each instance should be located](https://developers.cloudflare.com/durable-objects/reference/data-location/#provide-a-location-hint). Durable Objects are not yet available in every Cloudflare data center; refer to the [where.durableobjects.live](https://where.durableobjects.live/) project for live locations.\n* Each Durable Object type (or [\"Namespace binding\"](https://developers.cloudflare.com/durable-objects/api/namespace/) in Cloudflare terms) corresponds to a JavaScript class implementing the actual logic. There is no hard limit on how many Durable Objects can be created for each namespace.\n* Durable Objects scale elastically as your application creates millions of objects. There is no need for applications to manage infrastructure or plan ahead for capacity.\n\n## Durable Objects features\n\n### In-memory state\n\nEach Durable Object has its own [in-memory state](https://developers.cloudflare.com/durable-objects/reference/in-memory-state/). Applications can use this in-memory state to optimize the performance of their applications by keeping important information in-memory, thereby avoiding the need to access the durable storage at all.\n\nUseful cases for in-memory state include batching and aggregating information before persisting it to storage, or for immediately rejecting/handling incoming requests meeting certain criteria, and more.\n\nIn-memory state is reset when the Durable Object hibernates after being idle for some time. Therefore, it is important to persist any in-memory data to the durable storage if that data will be needed at a later time when the Durable Object receives another request.\n\n### Storage API\n\nThe [Durable Object Storage API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/) allows Durable Objects to access fast, transactional, and strongly consistent storage. A Durable Object's attached storage is private to its unique instance and cannot be accessed by other objects.\n\nThere are two flavors of the storage API, a [key-value (KV) API](https://developers.cloudflare.com/durable-objects/api/legacy-kv-storage-api/) and an [SQL API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/).\n\nWhen using the [new SQLite in Durable Objects storage backend](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/#enable-sqlite-storage-backend-on-new-durable-object-class-migration), you have access to both the APIs. However, if you use the previous storage backend you only have access to the key-value API.\n\n### Alarms API\n\nDurable Objects provide an [Alarms API](https://developers.cloudflare.com/durable-objects/api/alarms/) which allows you to schedule the Durable Object to be woken up at a time in the future. This is useful when you want to do certain work periodically, or at some specific point in time, without having to manually manage infrastructure such as job scheduling runners on your own.\n\nYou can combine Alarms with in-memory state and the durable storage API to build batch and aggregation applications such as queues, workflows, or advanced data pipelines.\n\n### WebSockets\n\nWebSockets are long-lived TCP connections that enable bi-directional, real-time communication between client and server. Because WebSocket sessions are long-lived, applications commonly use Durable Objects to accept either the client or server connection.\n\nBecause Durable Objects provide a single-point-of-coordination between Cloudflare Workers, a single Durable Object instance can be used in parallel with WebSockets to coordinate between multiple clients, such as participants in a chat room or a multiplayer game.\n\nDurable Objects support the [WebSocket Standard API](https://developers.cloudflare.com/durable-objects/best-practices/websockets/#websocket-standard-api), as well as the [WebSockets Hibernation API](https://developers.cloudflare.com/durable-objects/best-practices/websockets/#websocket-hibernation-api) which extends the Web Standard WebSocket API to reduce costs by not incurring billing charges during periods of inactivity.\n\n### RPC\n\nDurable Objects support Workers [Remote-Procedure-Call (RPC)](https://developers.cloudflare.com/workers/runtime-apis/rpc/) which allows applications to use JavaScript-native methods and objects to communicate between Workers and Durable Objects.\n\nUsing RPC for communication makes application development easier and simpler to reason about, and more efficient.\n\n## Actor programming model\n\nAnother way to describe and think about Durable Objects is through the lens of the [Actor programming model](https://en.wikipedia.org/wiki/Actor_model). There are several popular examples of the Actor model supported at the programming language level through runtimes or library frameworks, like [Erlang](https://www.erlang.org/), [Elixir](https://elixir-lang.org/), [Akka](https://akka.io/), or [Microsoft Orleans for .NET](https://learn.microsoft.com/en-us/dotnet/orleans/overview).\n\nThe Actor model simplifies a lot of problems in distributed systems by abstracting away the communication between actors using RPC calls (or message sending) that could be implemented on-top of any transport protocol, and it avoids most of the concurrency pitfalls you get when doing concurrency through shared memory such as race conditions when multiple processes/threads access the same data in-memory.\n\nEach Durable Object instance can be seen as an Actor instance, receiving messages (incoming HTTP/RPC requests), executing some logic in its own single-threaded context using its attached durable storage or in-memory state, and finally sending messages to the outside world (outgoing HTTP/RPC requests or responses), even to another Durable Object instance.\n\nEach Durable Object has certain capabilities in terms of [how much work it can do](https://developers.cloudflare.com/durable-objects/platform/limits/#how-much-work-can-a-single-durable-object-do), which should influence the application's [architecture to fully take advantage of the platform](https://developers.cloudflare.com/reference-architecture/diagrams/storage/durable-object-control-data-plane-pattern/).\n\nDurable Objects are natively integrated into Cloudflare's infrastructure, giving you the ultimate serverless platform to build distributed stateful applications exploiting the entirety of Cloudflare's network.\n\n## Durable Objects in Cloudflare\n\nMany of Cloudflare's products use Durable Objects. Some of our technical blog posts showcase real-world applications and use-cases where Durable Objects make building applications easier and simpler.\n\nThese blog posts may also serve as inspiration on how to architect scalable applications using Durable Objects, and how to integrate them with the rest of Cloudflare Developer Platform.\n\n* [Durable Objects aren't just durable, they're fast: a 10x speedup for Cloudflare Queues](https://blog.cloudflare.com/how-we-built-cloudflare-queues/)\n* [Behind the scenes with Stream Live, Cloudflare's live streaming service](https://blog.cloudflare.com/behind-the-scenes-with-stream-live-cloudflares-live-streaming-service/)\n* [DO it again: how we used Durable Objects to add WebSockets support and authentication to AI Gateway](https://blog.cloudflare.com/do-it-again/)\n* [Workers Builds: integrated CI/CD built on the Workers platform](https://blog.cloudflare.com/workers-builds-integrated-ci-cd-built-on-the-workers-platform/)\n* [Build durable applications on Cloudflare Workers: you write the Workflows, we take care of the rest](https://blog.cloudflare.com/building-workflows-durable-execution-on-workers/)\n* [Building D1: a Global Database](https://blog.cloudflare.com/building-d1-a-global-database/)\n* [Billions and billions (of logs): scaling AI Gateway with the Cloudflare Developer Platform](https://blog.cloudflare.com/billions-and-billions-of-logs-scaling-ai-gateway-with-the-cloudflare/)\n* [Indexing millions of HTTP requests using Durable Objects](https://blog.cloudflare.com/r2-rayid-retrieval/)\n\nFinally, the following blog posts may help you learn some of the technical implementation aspects of Durable Objects, and how they work.\n\n* [Durable Objects: Easy, Fast, Correct — Choose three](https://blog.cloudflare.com/durable-objects-easy-fast-correct-choose-three/)\n* [Zero-latency SQLite storage in every Durable Object](https://blog.cloudflare.com/sqlite-in-durable-objects/)\n* [Workers Durable Objects Beta: A New Approach to Stateful Serverless](https://blog.cloudflare.com/introducing-workers-durable-objects/)\n\n## Get started\n\nGet started now by following the [\"Get started\" guide](https://developers.cloudflare.com/durable-objects/get-started/) to create your first application using Durable Objects.\n\n## Footnotes\n\n1. Storage per Durable Object with SQLite is currently 1 GB. This will be raised to 10 GB for general availability. [↩](#user-content-fnref-1)\n\n</page>\n\n<page>\n---\ntitle: Agents · Cloudflare Durable Objects docs\ndescription: Build AI-powered Agents on Cloudflare\nlastUpdated: 2025-04-06T14:39:24.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/examples/agents/\n  md: https://developers.cloudflare.com/durable-objects/examples/agents/index.md\n---\n\n\n</page>\n\n<page>\n---\ntitle: Use the Alarms API · Cloudflare Durable Objects docs\ndescription: Use the Durable Objects Alarms API to batch requests to a Durable Object.\nlastUpdated: 2025-12-02T18:28:11.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/examples/alarms-api/\n  md: https://developers.cloudflare.com/durable-objects/examples/alarms-api/index.md\n---\n\nThis example implements an `alarm()` handler that allows batching of requests to a single Durable Object.\n\nWhen a request is received and no alarm is set, it sets an alarm for 10 seconds in the future. The `alarm()` handler processes all requests received within that 10-second window.\n\nIf no new requests are received, no further alarms will be set until the next request arrives.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "The `alarm()` handler will be called once every 10 seconds. If an unexpected error terminates the Durable Object, the `alarm()` handler will be re-instantiated on another machine. Following a short delay, the `alarm()` handler will run from the beginning on the other machine.\n\nFinally, configure your Wrangler file to include a Durable Object [binding](https://developers.cloudflare.com/durable-objects/get-started/#4-configure-durable-object-bindings) and [migration](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/) based on the namespace and class name chosen previously.\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Build a counter · Cloudflare Durable Objects docs\ndescription: Build a counter using Durable Objects and Workers with RPC methods.\nlastUpdated: 2025-12-02T18:28:11.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/examples/build-a-counter/\n  md: https://developers.cloudflare.com/durable-objects/examples/build-a-counter/index.md\n---\n\nThis example shows how to build a counter using Durable Objects and Workers with [RPC methods](https://developers.cloudflare.com/workers/runtime-apis/rpc) that can print, increment, and decrement a `name` provided by the URL query string parameter, for example, `?name=A`.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "Finally, configure your Wrangler file to include a Durable Object [binding](https://developers.cloudflare.com/durable-objects/get-started/#4-configure-durable-object-bindings) and [migration](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/) based on the namespace and class name chosen previously.\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "### Related resources\n\n* [Workers RPC](https://developers.cloudflare.com/workers/runtime-apis/rpc/)\n* [Durable Objects: Easy, Fast, Correct — Choose three](https://blog.cloudflare.com/durable-objects-easy-fast-correct-choose-three/).\n\n</page>\n\n<page>\n---\ntitle: Build a rate limiter · Cloudflare Durable Objects docs\ndescription: Build a rate limiter using Durable Objects and Workers.\nlastUpdated: 2025-12-02T18:28:11.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/examples/build-a-rate-limiter/\n  md: https://developers.cloudflare.com/durable-objects/examples/build-a-rate-limiter/index.md\n---\n\nThis example shows how to build a rate limiter using Durable Objects and Workers that can be used to protect upstream resources, including third-party APIs that your application relies on and/or services that may be costly for you to invoke.\n\nThis example also discusses some decisions that need to be made when designing a system, such as a rate limiter, with Durable Objects.\n\nThe Worker creates a `RateLimiter` Durable Object on a per IP basis to protect upstream resources. IP based rate limiting can be effective without negatively impacting latency because any given IP will remain within a small geographic area colocated with the `RateLimiter` Durable Object. Furthermore, throughput is also improved because each IP gets its own Durable Object.\n\nIt might seem simpler to implement a global rate limiter, `const stub = env.RATE_LIMITER.getByName(\"global\");`, which can provide better guarantees on the request rate to the upstream resource. However:\n\n* This would require all requests globally to make a sub-request to a single Durable Object.\n* Implementing a global rate limiter would add additional latency for requests not colocated with the Durable Object, and global throughput would be capped to the throughput of a single Durable Object.\n* A single Durable Object that all requests rely on is typically considered an anti-pattern. Durable Objects work best when they are scoped to a user, room, service and/or the specific subset of your application that requires global co-ordination.\n\nNote\n\nIf you do not need unique or custom rate-limiting capabilities, refer to [Rate limiting rules](https://developers.cloudflare.com/waf/rate-limiting-rules/) that are part of Cloudflare's Web Application Firewall (WAF) product.\n\nThe Durable Object uses a token bucket algorithm to implement rate limiting. The naive idea is that each request requires a token to complete, and the tokens are replenished according to the reciprocal of the desired number of requests per second. As an example, a 1000 requests per second rate limit will have a token replenished every millisecond (as specified by milliseconds\\_per\\_request) up to a given capacity limit.\n\nThis example uses Durable Object's [Alarms API](https://developers.cloudflare.com/durable-objects/api/alarms) to schedule the Durable Object to be woken up at a time in the future.\n\n* When the alarm's scheduled time comes, the `alarm()` handler method is called, and in this case, the alarm will add a token to the \"Bucket\".\n* The implementation is made more efficient by adding tokens in bulk (as specified by milliseconds\\_for\\_updates) and preventing the alarm handler from being invoked every millisecond. More frequent invocations of Durable Objects will lead to higher invocation and duration charges.\n\nThe first implementation of a rate limiter is below:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "While the token bucket algorithm is popular for implementing rate limiting and uses Durable Object features, there is a simpler approach:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "Finally, configure your Wrangler file to include a Durable Object [binding](https://developers.cloudflare.com/durable-objects/get-started/#4-configure-durable-object-bindings) and [migration](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/) based on the namespace and class name chosen previously.\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "### Related resources\n\n* Learn more about Durable Object's [Alarms API](https://developers.cloudflare.com/durable-objects/api/alarms) and how to configure alarms.\n* [Understand how to troubleshoot](https://developers.cloudflare.com/durable-objects/observability/troubleshooting/) common errors related with Durable Objects.\n* Review how [Durable Objects are priced](https://developers.cloudflare.com/durable-objects/platform/pricing/), including pricing examples.\n\n</page>\n\n<page>\n---\ntitle: Durable Object in-memory state · Cloudflare Durable Objects docs\ndescription: Create a Durable Object that stores the last location it was\n  accessed from in-memory.\nlastUpdated: 2025-12-02T18:28:11.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/examples/durable-object-in-memory-state/\n  md: https://developers.cloudflare.com/durable-objects/examples/durable-object-in-memory-state/index.md\n---\n\nThis example shows you how Durable Objects are stateful, meaning in-memory state can be retained between requests. After a brief period of inactivity, the Durable Object will be evicted, and all in-memory state will be lost. The next request will reconstruct the object, but instead of showing the city of the previous request, it will display a message indicating that the object has been reinitialized. If you need your applications state to survive eviction, write the state to storage by using the [Storage API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/), or by storing your data elsewhere.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "Finally, configure your Wrangler file to include a Durable Object [binding](https://developers.cloudflare.com/durable-objects/get-started/#4-configure-durable-object-bindings) and [migration](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/) based on the namespace and class name chosen previously.\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Durable Object Time To Live · Cloudflare Durable Objects docs\ndescription: Use the Durable Objects Alarms API to implement a Time To Live\n  (TTL) for Durable Object instances.\nlastUpdated: 2025-12-02T18:28:11.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/examples/durable-object-ttl/\n  md: https://developers.cloudflare.com/durable-objects/examples/durable-object-ttl/index.md\n---\n\nA common feature request for Durable Objects is a Time To Live (TTL) for Durable Object instances. Durable Objects give developers the tools to implement a custom TTL in only a few lines of code. This example demonstrates how to implement a TTL making use of `alarms`. While this TTL will be extended upon every new request to the Durable Object, this can be customized based on a particular use case.\n\nBe careful when calling `setAlarm` in the Durable Object class constructor\n\nIn this example the TTL is extended upon every new fetch request to the Durable Object. It might be tempting to instead extend the TTL in the constructor of the Durable Object. This is not advised because the Durable Object's constructor will be called before invoking the alarm handler if the alarm wakes the Durable Object up from hibernation. This approach will naively result in the constructor continually extending the TTL without running the alarm handler. If you must call `setAlarm` in the Durable Object class constructor be sure to check that there is no alarm previously set.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "To test and deploy this example, configure your Wrangler file to include a Durable Object [binding](https://developers.cloudflare.com/durable-objects/get-started/#4-configure-durable-object-bindings) and [migration](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/) based on the namespace and class name chosen previously.\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Use ReadableStream with Durable Object and Workers · Cloudflare Durable\n  Objects docs\ndescription: Stream ReadableStream from Durable Objects.\nlastUpdated: 2025-10-24T17:16:32.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/examples/readable-stream/\n  md: https://developers.cloudflare.com/durable-objects/examples/readable-stream/index.md\n---\n\nThis example demonstrates:\n\n* A Worker receives a request, and forwards it to a Durable Object `my-id`.\n* The Durable Object streams an incrementing number every second, until it receives `AbortSignal`.\n* The Worker reads and logs the values from the stream.\n* The Worker then cancels the stream after 5 values.\n\n- JavaScript",
      "language": "unknown"
    },
    {
      "code": "- TypeScript",
      "language": "unknown"
    },
    {
      "code": "Note\n\nIn a setup where a Durable Object returns a readable stream to a Worker, if the Worker cancels the Durable Object's readable stream, the cancellation propagates to the Durable Object.\n\n</page>\n\n<page>\n---\ntitle: Testing Durable Objects · Cloudflare Durable Objects docs\ndescription: Write tests for Durable Objects using the Workers Vitest integration.\nlastUpdated: 2025-12-15T13:52:09.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/examples/testing-with-durable-objects/\n  md: https://developers.cloudflare.com/durable-objects/examples/testing-with-durable-objects/index.md\n---\n\nUse the [`@cloudflare/vitest-pool-workers`](https://www.npmjs.com/package/@cloudflare/vitest-pool-workers) package to write tests for your Durable Objects. This integration runs your tests inside the Workers runtime, giving you direct access to Durable Object bindings and APIs.\n\n## Prerequisites\n\nInstall Vitest and the Workers Vitest integration as dev dependencies:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "## Example Durable Object\n\nThis example tests a simple counter Durable Object with SQLite storage:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "## Configure Vitest\n\nCreate a `vitest.config.ts` file that uses `defineWorkersConfig`:",
      "language": "unknown"
    },
    {
      "code": "Make sure your Wrangler configuration includes the Durable Object binding and SQLite migration:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "## Define types for tests\n\nCreate a `test/tsconfig.json` to configure TypeScript for your tests:",
      "language": "unknown"
    },
    {
      "code": "Create an `env.d.ts` file to type the test environment:",
      "language": "unknown"
    },
    {
      "code": "## Writing tests\n\n### Unit tests with direct Durable Object access\n\nYou can get a stub to a Durable Object directly from the `env` object provided by `cloudflare:test`:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "### Integration tests with SELF\n\nUse the `SELF` fetcher to test your Worker's HTTP handler, which routes requests to Durable Objects:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "### Direct access to Durable Object internals\n\nUse `runInDurableObject()` to access instance properties and storage directly. This is useful for verifying internal state or testing private methods:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "### Test isolation\n\nEach test automatically gets isolated storage. Durable Objects created in one test do not affect other tests:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "### Testing SQLite storage\n\nSQLite-backed Durable Objects work seamlessly in tests. The SQL API is available when your Durable Object class is configured with `new_sqlite_classes` in your Wrangler configuration:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "### Testing alarms\n\nUse `runDurableObjectAlarm()` to immediately trigger a scheduled alarm without waiting for the timer. This allows you to test alarm handlers synchronously:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "To test alarms, add an `alarm()` method to your Durable Object:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "## Running tests\n\nRun your tests with:",
      "language": "unknown"
    },
    {
      "code": "Or add a script to your `package.json`:",
      "language": "unknown"
    },
    {
      "code": "## Related resources\n\n* [Workers Vitest integration](https://developers.cloudflare.com/workers/testing/vitest-integration/) - Full documentation for the Vitest integration\n* [Durable Objects testing recipe](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/durable-objects) - Example from the Workers SDK\n* [RPC testing recipe](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/rpc) - Testing JSRPC with Durable Objects\n\n</page>\n\n<page>\n---\ntitle: Use RpcTarget class to handle Durable Object metadata · Cloudflare\n  Durable Objects docs\ndescription: Access the name from within a Durable Object using RpcTarget.\nlastUpdated: 2025-08-18T14:27:42.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/examples/reference-do-name-using-init/\n  md: https://developers.cloudflare.com/durable-objects/examples/reference-do-name-using-init/index.md\n---\n\nWhen working with Durable Objects, you will need to access the name that was used to create the Durable Object via `idFromName()`. This name is typically a meaningful identifier that represents what the Durable Object is responsible for (like a user ID, room name, or resource identifier).\n\nHowever, there is a limitation in the current implementation: even though you can create a Durable Object with `.idFromName(name)`, you cannot directly access this name inside the Durable Object via `this.ctx.id.name`.\n\nThe `RpcTarget` pattern shown below offers a solution by creating a communication layer that automatically carries the name with each method call. This keeps your API clean while ensuring the Durable Object has access to its own name.\n\nBased on your needs, you can either store the metadata temporarily in the `RpcTarget` class, or use Durable Object storage to persist the metadata for the lifetime of the object.\n\nThis example does not persist the Durable Object metadata. It demonstrates how to:\n\n1. Create an `RpcTarget` class\n2. Set the Durable Object metadata (identifier in this example) in the `RpcTarget` class\n3. Pass the metadata to a Durable Object method\n4. Clean up the `RpcTarget` class after use",
      "language": "unknown"
    },
    {
      "code": "This example persists the Durable Object metadata. It demonstrates similar steps as the previous example, but uses Durable Object storage to store the identifier, eliminating the need to pass it through the RpcTarget.",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Durable Objects - Use KV within Durable Objects · Cloudflare Durable\n  Objects docs\ndescription: Read and write to/from KV within a Durable Object\nlastUpdated: 2025-12-02T18:28:11.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/examples/use-kv-from-durable-objects/\n  md: https://developers.cloudflare.com/durable-objects/examples/use-kv-from-durable-objects/index.md\n---\n\nThe following Worker script shows you how to configure a Durable Object to read from and/or write to a [Workers KV namespace](https://developers.cloudflare.com/kv/concepts/how-kv-works/). This is useful when using a Durable Object to coordinate between multiple clients, and allows you to serialize writes to KV and/or broadcast a single read from KV to hundreds or thousands of clients connected to a single Durable Object [using WebSockets](https://developers.cloudflare.com/durable-objects/best-practices/websockets/).\n\nPrerequisites:\n\n* A [KV namespace](https://developers.cloudflare.com/kv/api/) created via the Cloudflare dashboard or the [wrangler CLI](https://developers.cloudflare.com/workers/wrangler/install-and-update/).\n* A [configured binding](https://developers.cloudflare.com/kv/concepts/kv-bindings/) for the `kv_namespace` in the Cloudflare dashboard or Wrangler file.\n* A [Durable Object namespace binding](https://developers.cloudflare.com/workers/wrangler/configuration/#durable-objects).\n\nConfigure your Wrangler file as follows:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "- TypeScript",
      "language": "unknown"
    },
    {
      "code": "- Python",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Build a WebSocket server with WebSocket Hibernation · Cloudflare Durable\n  Objects docs\ndescription: Build a WebSocket server using WebSocket Hibernation on Durable\n  Objects and Workers.\nlastUpdated: 2025-12-02T18:28:11.000Z\nchatbotDeprioritize: false\ntags: WebSockets\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/examples/websocket-hibernation-server/\n  md: https://developers.cloudflare.com/durable-objects/examples/websocket-hibernation-server/index.md\n---\n\nThis example is similar to the [Build a WebSocket server](https://developers.cloudflare.com/durable-objects/examples/websocket-server/) example, but uses the WebSocket Hibernation API. The WebSocket Hibernation API should be preferred for WebSocket server applications built on Durable Objects, since it significantly decreases duration charge, and provides additional features that pair well with WebSocket applications. For more information, refer to [Use Durable Objects with WebSockets](https://developers.cloudflare.com/durable-objects/best-practices/websockets/).\n\nNote\n\nWebSocket Hibernation is unavailable for outgoing WebSocket use cases. Hibernation is only supported when the Durable Object acts as a server. For use cases where outgoing WebSockets are required, refer to [Write a WebSocket client](https://developers.cloudflare.com/workers/examples/websockets/#write-a-websocket-client).\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "Finally, configure your Wrangler file to include a Durable Object [binding](https://developers.cloudflare.com/durable-objects/get-started/#4-configure-durable-object-bindings) and [migration](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/) based on the namespace and class name chosen previously.\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "### Related resources\n\n* [Durable Objects: Edge Chat Demo with Hibernation](https://github.com/cloudflare/workers-chat-demo/).\n\n</page>\n\n<page>\n---\ntitle: Build a WebSocket server · Cloudflare Durable Objects docs\ndescription: Build a WebSocket server using Durable Objects and Workers.\nlastUpdated: 2025-12-02T18:28:11.000Z\nchatbotDeprioritize: false\ntags: WebSockets\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/examples/websocket-server/\n  md: https://developers.cloudflare.com/durable-objects/examples/websocket-server/index.md\n---\n\nThis example shows how to build a WebSocket server using Durable Objects and Workers. The example exposes an endpoint to create a new WebSocket connection. This WebSocket connection echos any message while including the total number of WebSocket connections currently established. For more information, refer to [Use Durable Objects with WebSockets](https://developers.cloudflare.com/durable-objects/best-practices/websockets/).\n\nWarning\n\nWebSocket connections pin your Durable Object to memory, and so duration charges will be incurred so long as the WebSocket is connected (regardless of activity). To avoid duration charges during periods of inactivity, use the [WebSocket Hibernation API](https://developers.cloudflare.com/durable-objects/examples/websocket-hibernation-server/), which only charges for duration when JavaScript is actively executing.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "* Python",
      "language": "unknown"
    },
    {
      "code": "Finally, configure your Wrangler file to include a Durable Object [binding](https://developers.cloudflare.com/durable-objects/get-started/#4-configure-durable-object-bindings) and [migration](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/) based on the namespace and class name chosen previously.\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "### Related resources\n\n* [Durable Objects: Edge Chat Demo](https://github.com/cloudflare/workers-chat-demo).\n\n</page>\n\n<page>\n---\ntitle: Data Studio · Cloudflare Durable Objects docs\ndescription: Each Durable Object can access private storage using Storage API\n  available on ctx.storage. To view and write to an object's stored data, you\n  can use Durable Objects Data Studio as a UI editor available on the Cloudflare\n  dashboard.\nlastUpdated: 2025-10-16T13:57:27.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/observability/data-studio/\n  md: https://developers.cloudflare.com/durable-objects/observability/data-studio/index.md\n---\n\nEach Durable Object can access private storage using [Storage API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/) available on `ctx.storage`. To view and write to an object's stored data, you can use Durable Objects Data Studio as a UI editor available on the Cloudflare dashboard.\n\nData Studio only supported for SQLite-backed objects\n\nYou can only use Data Studio to access data for [SQLite-backed Durable Objects](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#create-sqlite-backed-durable-object-class).\n\nAt the moment, you can only read/write data persisted using the [SQL API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#sql-api). Key-value data persisted using the KV API will be made read-only in the future.\n\n## View Data Studio\n\nYou need to have at least the `Workers Platform Admin` [role](https://developers.cloudflare.com/fundamentals/manage-members/roles/) to access Data Studio.\n\n1. In the Cloudflare dashboard, go to the **Durable Objects** page.\n\n   [Go to **Durable Objects**](https://dash.cloudflare.com/?to=/:account/workers/durable-objects)\n\n2. Select an existing Durable Object namespace.\n\n3. Select the **Data Studio** button.\n\n4. Provide a Durable Object identifier, either a user-provided [unique name](https://developers.cloudflare.com/durable-objects/api/namespace/#getbyname) or a Cloudflare-generated [Durable Object ID](https://developers.cloudflare.com/durable-objects/api/id/).\n\n* Queries executed by Data Studio send requests to your remote, deployed objects and incur [usage billing](https://developers.cloudflare.com/durable-objects/platform/pricing/) for requests, duration, rows read, and rows written. You should use Data Studio as you would handle your production, running objects.\n* In the **Query** tab when running all statements, each SQL statement is sent as a separate Durable Object request.\n\n## Audit logging\n\nAll queries issued by the Data Studio are logged with [audit logging v1](https://developers.cloudflare.com/fundamentals/account/account-security/review-audit-logs/) for your security and compliance needs.\n\n* Each query emits two audit logs, a `query executed` action and a `query completed` action indicating query success or failure. `query_id` in the log event can be used to correlate the two events per query.\n\n</page>\n\n<page>\n---\ntitle: Metrics and analytics · Cloudflare Durable Objects docs\ndescription: Durable Objects expose analytics for Durable Object namespace-level\n  and request-level metrics.\nlastUpdated: 2025-09-17T14:35:09.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/observability/metrics-and-analytics/\n  md: https://developers.cloudflare.com/durable-objects/observability/metrics-and-analytics/index.md\n---\n\nDurable Objects expose analytics for Durable Object namespace-level and request-level metrics.\n\nThe metrics displayed in the [Cloudflare dashboard](https://dash.cloudflare.com/) charts are queried from Cloudflare's [GraphQL Analytics API](https://developers.cloudflare.com/analytics/graphql-api/). You can access the metrics [programmatically via GraphQL](#query-via-the-graphql-api) or HTTP client.\n\nDurable Object namespace\n\nA Durable Object namespace is a set of Durable Objects that can be addressed by name, backed by the same class. There is only one Durable Object namespace per class. A Durable Object namespace can contain any number of Durable Objects.\n\n## View metrics and analytics\n\nPer-namespace analytics for Durable Objects are available in the Cloudflare dashboard. To view current and historical metrics for a namespace:\n\n1. In the Cloudflare dashboard, go to the **Durable Objects** page.\n\n   [Go to **Durable Objects**](https://dash.cloudflare.com/?to=/:account/workers/durable-objects)\n\n2. View account-level Durable Objects usage.\n\n3. Select an existing Durable Object namespace.\n\n4. Select the **Metrics** tab.\n\nYou can optionally select a time window to query. This defaults to the last 24 hours.\n\n## View logs\n\nYou can view Durable Object logs from the Cloudflare dashboard. Logs are aggregated by the script name and the Durable Object class name.\n\nTo start using Durable Object logging:\n\n1. Enable Durable Object logging in the Wrangler configuration file of the Worker that defines your Durable Object class:\n\n   * wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "2. Deploy the latest version of the Worker with the updated binding.\n\n3. Go to the **Durable Objects** page.\n\n   [Go to **Durable Objects**](https://dash.cloudflare.com/?to=/:account/workers/durable-objects)\n\n4. Select an existing Durable Object namespace.\n\n5. Select the **Logs** tab.\n\nNote\n\nFor information on log limits (such as maximum log retention period), refer to the [Workers Logs documentation](https://developers.cloudflare.com/workers/observability/logs/workers-logs/#limits).\n\n## Query via the GraphQL API\n\nDurable Object metrics are powered by GraphQL.\n\nThe datasets that include Durable Object metrics include:\n\n* `durableObjectsInvocationsAdaptiveGroups`\n* `durableObjectsPeriodicGroups`\n* `durableObjectsStorageGroups`\n* `durableObjectsSubrequestsAdaptiveGroups`\n\nUse [GraphQL Introspection](https://developers.cloudflare.com/analytics/graphql-api/features/discovery/introspection/) to get information on the fields exposed by each datasets.\n\n### WebSocket metrics\n\nDurable Objects using [WebSockets](https://developers.cloudflare.com/durable-objects/best-practices/websockets/) will see request metrics across several GraphQL datasets because WebSockets have different types of requests.\n\n* Metrics for a WebSocket connection itself is represented in `durableObjectsInvocationsAdaptiveGroups` once the connection closes. Since WebSocket connections are long-lived, connections often do not terminate until the Durable Object terminates.\n* Metrics for incoming and outgoing WebSocket messages on a WebSocket connection are available in `durableObjectsPeriodicGroups`. If a WebSocket connection uses [WebSocket Hibernation](https://developers.cloudflare.com/durable-objects/best-practices/websockets/#websocket-hibernation-api), incoming WebSocket messages are instead represented in `durableObjectsInvocationsAdaptiveGroups`.\n\n## Example GraphQL query for Durable Objects",
      "language": "unknown"
    },
    {
      "code": "Refer to the [Querying Workers Metrics with GraphQL](https://developers.cloudflare.com/analytics/graphql-api/tutorials/querying-workers-metrics/) tutorial for authentication and to learn more about querying Workers datasets.\n\n## Additional resources\n\n* For instructions on setting up a Grafana dashboard to query Cloudflare's GraphQL Analytics API, refer to [Grafana Dashboard starter for Durable Object metrics](https://github.com/TimoWilhelm/grafana-do-dashboard).\n\n## FAQs\n\n### How can I identify which Durable Object instance generated a log entry?\n\nYou can use `$workers.durableObjectId` to identify the specific Durable Object instance that generated the log entry.\n\n</page>\n\n<page>\n---\ntitle: Troubleshooting · Cloudflare Durable Objects docs\ndescription: wrangler dev and wrangler tail are both available to help you debug\n  your Durable Objects.\nlastUpdated: 2025-02-12T13:41:31.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/observability/troubleshooting/\n  md: https://developers.cloudflare.com/durable-objects/observability/troubleshooting/index.md\n---\n\n## Debugging\n\n[`wrangler dev`](https://developers.cloudflare.com/workers/wrangler/commands/#dev) and [`wrangler tail`](https://developers.cloudflare.com/workers/wrangler/commands/#tail) are both available to help you debug your Durable Objects.\n\nThe `wrangler dev --remote` command opens a tunnel from your local development environment to Cloudflare's global network, letting you test your Durable Objects code in the Workers environment as you write it.\n\n`wrangler tail` displays a live feed of console and exception logs for each request served by your Worker code, including both normal Worker requests and Durable Object requests. After running `npx wrangler deploy`, you can use `wrangler tail` in the root directory of your Worker project and visit your Worker URL to see console and error logs in your terminal.\n\n## Common errors\n\n### No event handlers were registered. This script does nothing.\n\nIn your Wrangler file, make sure the `dir` and `main` entries point to the correct file containing your Worker code, and that the file extension is `.mjs` instead of `.js` if using ES modules syntax.\n\n### Cannot apply `--delete-class` migration to class.\n\nWhen deleting a migration using `npx wrangler deploy --delete-class <ClassName>`, you may encounter this error: `\"Cannot apply --delete-class migration to class <ClassName> without also removing the binding that references it\"`. You should remove the corresponding binding under `[durable_objects]` in the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/) before attempting to apply `--delete-class` again.\n\n### Durable Object is overloaded.\n\nA single instance of a Durable Object cannot do more work than is possible on a single thread. These errors mean the Durable Object has too much work to keep up with incoming requests:\n\n* `Error: Durable Object is overloaded. Too many requests queued.` The total count of queued requests is too high.\n* `Error: Durable Object is overloaded. Too much data queued.` The total size of data in queued requests is too high.\n* `Error: Durable Object is overloaded. Requests queued for too long.` The oldest request has been in the queue too long.\n* `Error: Durable Object is overloaded. Too many requests for the same object within a 10 second window.` The number of requests for a Durable Object is too high within a short span of time (10 seconds). This error indicates a more extreme level of overload.\n\nTo solve this error, you can either do less work per request, or send fewer requests. For example, you can split the requests among more instances of the Durable Object.\n\nThese errors and others that are due to overload will have an [`.overloaded` property](https://developers.cloudflare.com/durable-objects/best-practices/error-handling) set on their exceptions, which can be used to avoid retrying overloaded operations.\n\n### Your account is generating too much load on Durable Objects. Please back off and try again later.\n\nThere is a limit on how quickly you can create new [stubs](https://developers.cloudflare.com/durable-objects/api/stub) for new or existing Durable Objects. Those lookups are usually cached, meaning attempts for the same set of recently accessed Durable Objects should be successful, so catching this error and retrying after a short wait is safe. If possible, also consider spreading those lookups across multiple requests.\n\n### Durable Object reset because its code was updated.\n\nReset in error messages refers to in-memory state. Any durable state that has already been successfully persisted via `state.storage` is not affected.\n\nRefer to [Global Uniqueness](https://developers.cloudflare.com/durable-objects/platform/known-issues/#global-uniqueness).\n\n### Durable Object storage operation exceeded timeout which caused object to be reset.\n\nTo prevent indefinite blocking, there is a limit on how much time storage operations can take. In Durable Objects containing a sufficiently large number of key-value pairs, `deleteAll()` may hit that time limit and fail. When this happens, note that each `deleteAll()` call does make progress and that it is safe to retry until it succeeds. Otherwise contact [Cloudflare support](https://developers.cloudflare.com/support/contacting-cloudflare-support/).\n\n### Your account is doing too many concurrent storage operations. Please back off and try again later.\n\nBesides the suggested approach of backing off, also consider changing your code to use `state.storage.get(keys Array<string>)` rather than multiple individual `state.storage.get(key)` calls where possible.\n\n</page>\n\n<page>\n---\ntitle: Known issues · Cloudflare Durable Objects docs\ndescription: Durable Objects is generally available. However, there are some known issues.\nlastUpdated: 2025-02-19T09:34:35.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/platform/known-issues/\n  md: https://developers.cloudflare.com/durable-objects/platform/known-issues/index.md\n---\n\nDurable Objects is generally available. However, there are some known issues.\n\n## Global uniqueness\n\nGlobal uniqueness guarantees there is only a single instance of a Durable Object class with a given ID running at once, across the world.\n\nUniqueness is enforced upon starting a new event (such as receiving an HTTP request), and upon accessing storage.\n\nAfter an event is received, if the event takes some time to execute and does not ever access its durable storage, then it is possible that the Durable Object may no longer be current, and some other instance of the same Durable Object ID will have been created elsewhere. If the event accesses storage at this point, it will receive an [exception](https://developers.cloudflare.com/durable-objects/observability/troubleshooting/). If the event completes without ever accessing storage, it may not ever realize that the Durable Object was no longer current.\n\nA Durable Object may be replaced in the event of a network partition or a software update (including either an update of the Durable Object's class code, or of the Workers system itself). Enabling `wrangler tail` or [Cloudflare dashboard](https://dash.cloudflare.com/) logs requires a software update.\n\n## Code updates\n\nCode changes for Workers and Durable Objects are released globally in an eventually consistent manner. Because each Durable Object is globally unique, the situation can arise that a request arrives to the latest version of your Worker (running in one part of the world), which then calls to a unique Durable Object running the previous version of your code for a short period of time (typically seconds to minutes). If you create a [gradual deployment](https://developers.cloudflare.com/workers/configuration/versions-and-deployments/gradual-deployments/), this period of time is determined by how long your live deployment is configured to use more than one version.\n\nFor this reason, it is best practice to ensure that API changes between your Workers and Durable Objects are forward and backward compatible across code updates.\n\n## Development tools\n\n[`wrangler tail`](https://developers.cloudflare.com/workers/wrangler/commands/#tail) logs from requests that are upgraded to WebSockets are delayed until the WebSocket is closed. `wrangler tail` should not be connected to a Worker that you expect will receive heavy volumes of traffic.\n\nThe Workers editor in the [Cloudflare dashboard](https://dash.cloudflare.com/) allows you to interactively edit and preview your Worker and Durable Objects. In the editor, Durable Objects can only be talked to by a preview request if the Worker being previewed both exports the Durable Object class and binds to it. Durable Objects exported by other Workers cannot be talked to in the editor preview.\n\n[`wrangler dev`](https://developers.cloudflare.com/workers/wrangler/commands/#dev) has read access to Durable Object storage, but writes will be kept in memory and will not affect persistent data. However, if you specify the `script_name` explicitly in the [Durable Object binding](https://developers.cloudflare.com/workers/runtime-apis/bindings/), then writes will affect persistent data. Wrangler will emit a warning in that case.\n\n## Alarms in local development\n\nCurrently, when developing locally (using `npx wrangler dev`), Durable Object [alarm methods](https://developers.cloudflare.com/durable-objects/api/alarms) may fail after a hot reload (if you edit the code while the code is running locally).\n\nTo avoid this issue, when using Durable Object alarms, close and restart your `wrangler dev` command after editing your code.\n\n</page>\n\n<page>\n---\ntitle: Limits · Cloudflare Durable Objects docs\ndescription: Durable Objects are a special kind of Worker, so Workers Limits\n  apply according to your Workers plan. In addition, Durable Objects have\n  specific limits as listed in this page.\nlastUpdated: 2025-11-03T13:26:55.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/platform/limits/\n  md: https://developers.cloudflare.com/durable-objects/platform/limits/index.md\n---\n\nDurable Objects are a special kind of Worker, so [Workers Limits](https://developers.cloudflare.com/workers/platform/limits/) apply according to your Workers plan. In addition, Durable Objects have specific limits as listed in this page.\n\n## SQLite-backed Durable Objects general limits\n\n| Feature | Limit |\n| - | - |\n| Number of Objects | Unlimited (within an account or of a given class) |\n| Maximum Durable Object classes | 500 (Workers Paid) / 100 (Free) [1](#user-content-fn-1) |\n| Storage per account | Unlimited (Workers Paid) / 5GB (Free) [2](#user-content-fn-2) |\n| Storage per class | Unlimited [3](#user-content-fn-3) |\n| Storage per Durable Object | 10 GB [3](#user-content-fn-3) |\n| Key size | Key and value combined cannot exceed 2 MB |\n| Value size | Key and value combined cannot exceed 2 MB |\n| WebSocket message size | 32 MiB (only for received messages) |\n| CPU per request | 30 seconds (default) / configurable to 5 minutes of [active CPU time](https://developers.cloudflare.com/workers/platform/limits/#cpu-time) [4](#user-content-fn-4) |\n\nFootnotes\n\n1. Identical to the Workers [script limit](https://developers.cloudflare.com/workers/platform/limits/).\n\n2. Durable Objects both bills and measures storage based on a gigabyte\\\n   (1 GB = 1,000,000,000 bytes) and not a gibibyte (GiB).\n\n3. Accounts on the Workers Free plan are limited to 5GB total Durable Objects storage.\n\n4. Each incoming HTTP request or WebSocket *message* resets the remaining available CPU time to 30 seconds. This allows the Durable Object to consume up to 30 seconds of compute after each incoming network request, with each new network request resetting the timer. If you consume more than 30 seconds of compute between incoming network requests, there is a heightened chance that the individual Durable Object is evicted and reset. CPU time per request invocation [can be increased](https://developers.cloudflare.com/durable-objects/platform/limits/#increasing-durable-object-cpu-limits).\n\n### SQL storage limits\n\nFor Durable Object classes with [SQLite storage](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/) these SQL limits apply:\n\n| SQL | Limit |\n| - | - |\n| Maximum number of columns per table | 100 |\n| Maximum number of rows per table | Unlimited (excluding per-object storage limits) |\n| Maximum string, `BLOB` or table row size | 2 MB |\n| Maximum SQL statement length | 100 KB |\n| Maximum bound parameters per query | 100 |\n| Maximum arguments per SQL function | 32 |\n| Maximum characters (bytes) in a `LIKE` or `GLOB` pattern | 50 bytes |\n\n## Key-value backed Durable Objects general limits\n\nNote\n\nDurable Objects are available both on Workers Free and Workers Paid plans.\n\n* **Workers Free plan**: Only Durable Objects with [SQLite storage backend](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#wrangler-configuration-for-sqlite-backed-durable-objects) are available.\n* **Workers Paid plan**: Durable Objects with either SQLite storage backend or [key-value storage backend](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/#create-durable-object-class-with-key-value-storage) are available.\n\nIf you wish to downgrade from a Workers Paid plan to a Workers Free plan, you must first ensure that you have deleted all Durable Object namespaces with the key-value storage backend.\n\n| Feature | Limit for class with key-value storage backend |\n| - | - |\n| Number of Objects | Unlimited (within an account or of a given class) |\n| Maximum Durable Object classes | 500 (Workers Paid) / 100 (Free) [5](#user-content-fn-5) |\n| Storage per account | 50 GB (can be raised by contacting Cloudflare) [6](#user-content-fn-6) |\n| Storage per class | Unlimited |\n| Storage per Durable Object | Unlimited |\n| Key size | 2 KiB (2048 bytes) |\n| Value size | 128 KiB (131072 bytes) |\n| WebSocket message size | 32 MiB (only for received messages) |\n| CPU per request | 30s (including WebSocket messages) [7](#user-content-fn-7) |\n\nFootnotes\n\n1. Identical to the Workers [script limit](https://developers.cloudflare.com/workers/platform/limits/).\n\n2. Durable Objects both bills and measures storage based on a gigabyte\\\n   (1 GB = 1,000,000,000 bytes) and not a gibibyte (GiB).\n\n3. Each incoming HTTP request or WebSocket *message* resets the remaining available CPU time to 30 seconds. This allows the Durable Object to consume up to 30 seconds of compute after each incoming network request, with each new network request resetting the timer. If you consume more than 30 seconds of compute between incoming network requests, there is a heightened chance that the individual Durable Object is evicted and reset. CPU time per request invocation [can be increased](https://developers.cloudflare.com/durable-objects/platform/limits/#increasing-durable-object-cpu-limits).\n\nNeed a higher limit?\n\nTo request an adjustment to a limit, complete the [Limit Increase Request Form](https://forms.gle/ukpeZVLWLnKeixDu7). If the limit can be increased, Cloudflare will contact you with next steps.\n\n## Frequently Asked Questions\n\n### How much work can a single Durable Object do?\n\nDurable Objects can scale horizontally across many Durable Objects. Each individual Object is inherently single-threaded.\n\n* An individual Object has a soft limit of 1,000 requests per second. You can have an unlimited number of individual objects per namespace.\n* A simple [storage](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/) `get()` on a small value that directly returns the response may realize a higher request throughput compared to a Durable Object that (for example) serializes and/or deserializes large JSON values.\n* Similarly, a Durable Object that performs multiple `list()` operations may be more limited in terms of request throughput.\n\nA Durable Object that receives too many requests will, after attempting to queue them, return an [overloaded](https://developers.cloudflare.com/durable-objects/observability/troubleshooting/#durable-object-is-overloaded) error to the caller.\n\n### How many Durable Objects can I create?\n\nDurable Objects are designed such that the number of individual objects in the system do not need to be limited, and can scale horizontally.\n\n* You can create and run as many separate Durable Objects as you want within a given Durable Object namespace.\n* There are no limits for storage per account when using SQLite-backed Durable Objects on a Workers Paid plan.\n* Each SQLite-backed Durable Object has a storage limit of 10 GB on a Workers Paid plan.\n* Refer to [Durable Object limits](https://developers.cloudflare.com/durable-objects/platform/limits/) for more information.\n\n### Can I increase Durable Objects' CPU limit?\n\nDurable Objects are Worker scripts, and have the same [per invocation CPU limits](https://developers.cloudflare.com/workers/platform/limits/#worker-limits) as any Workers do. Note that CPU time is active processing time: not time spent waiting on network requests, storage calls, or other general I/O, which don't count towards your CPU time or Durable Objects compute consumption.\n\nBy default, the maximum CPU time per Durable Objects invocation (HTTP request, WebSocket message, or Alarm) is set to 30 seconds, but can be increased for all Durable Objects associated with a Durable Object definition by setting `limits.cpu_ms` in your Wrangler configuration:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "## Footnotes\n\n1. Identical to the Workers [script limit](https://developers.cloudflare.com/workers/platform/limits/). [↩](#user-content-fnref-1)\n\n2. Durable Objects both bills and measures storage based on a gigabyte\\\n   (1 GB = 1,000,000,000 bytes) and not a gibibyte (GiB).\\\n   [↩](#user-content-fnref-2)\n\n3. Accounts on the Workers Free plan are limited to 5 GB total Durable Objects storage. [↩](#user-content-fnref-3) [↩2](#user-content-fnref-3-2)\n\n4. Each incoming HTTP request or WebSocket *message* resets the remaining available CPU time to 30 seconds. This allows the Durable Object to consume up to 30 seconds of compute after each incoming network request, with each new network request resetting the timer. If you consume more than 30 seconds of compute between incoming network requests, there is a heightened chance that the individual Durable Object is evicted and reset. CPU time per request invocation [can be increased](https://developers.cloudflare.com/durable-objects/platform/limits/#increasing-durable-object-cpu-limits). [↩](#user-content-fnref-4)\n\n5. Identical to the Workers [script limit](https://developers.cloudflare.com/workers/platform/limits/). [↩](#user-content-fnref-5)\n\n6. Durable Objects both bills and measures storage based on a gigabyte\\\n   (1 GB = 1,000,000,000 bytes) and not a gibibyte (GiB).\\\n   [↩](#user-content-fnref-6)\n\n7. Each incoming HTTP request or WebSocket *message* resets the remaining available CPU time to 30 seconds. This allows the Durable Object to consume up to 30 seconds of compute after each incoming network request, with each new network request resetting the timer. If you consume more than 30 seconds of compute between incoming network requests, there is a heightened chance that the individual Durable Object is evicted and reset. CPU time per request invocation [can be increased](https://developers.cloudflare.com/durable-objects/platform/limits/#increasing-durable-object-cpu-limits). [↩](#user-content-fnref-7)\n\n</page>\n\n<page>\n---\ntitle: Pricing · Cloudflare Durable Objects docs\ndescription: \"Durable Objects can incur two types of billing: compute and storage.\"\nlastUpdated: 2025-08-22T14:24:45.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/platform/pricing/\n  md: https://developers.cloudflare.com/durable-objects/platform/pricing/index.md\n---\n\nDurable Objects can incur two types of billing: compute and storage.\n\nNote\n\nDurable Objects are available both on Workers Free and Workers Paid plans.\n\n* **Workers Free plan**: Only Durable Objects with [SQLite storage backend](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#wrangler-configuration-for-sqlite-backed-durable-objects) are available.\n* **Workers Paid plan**: Durable Objects with either SQLite storage backend or [key-value storage backend](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/#create-durable-object-class-with-key-value-storage) are available.\n\nIf you wish to downgrade from a Workers Paid plan to a Workers Free plan, you must first ensure that you have deleted all Durable Object namespaces with the key-value storage backend.\n\nOn Workers Free plan:\n\n* If you exceed any one of the free tier limits, further operations of that type will fail with an error.\n* Daily free limits reset at 00:00 UTC.\n\n## Compute billing\n\nDurable Objects are billed for duration while the Durable Object is active and running in memory. Requests to a Durable Object keep it active or creates the object if it was inactive, not in memory.\n\n| | Free plan | Paid plan |\n| - | - | - |\n| Requests | 100,000 / day | 1 million, + $0.15/million Includes HTTP requests, RPC sessions1, WebSocket messages2, and alarm invocations |\n| Duration3 | 13,000 GB-s / day | 400,000 GB-s, + $12.50/million GB-s4,5 |\n\nFootnotes\n\n1 Each [RPC session](https://developers.cloudflare.com/workers/runtime-apis/rpc/lifecycle/) is billed as one request to your Durable Object. Every [RPC method call](https://developers.cloudflare.com/durable-objects/best-practices/create-durable-object-stubs-and-send-requests/) on a [Durable Objects stub](https://developers.cloudflare.com/durable-objects/) is its own RPC session and therefore a single billed request.\n\nRPC method calls can return objects (stubs) extending [`RpcTarget`](https://developers.cloudflare.com/workers/runtime-apis/rpc/lifecycle/#lifetimes-memory-and-resource-management) and invoke calls on those stubs. Subsequent calls on the returned stub are part of the same RPC session and are not billed as separate requests. For example:",
      "language": "unknown"
    },
    {
      "code": "2 A request is needed to create a WebSocket connection. There is no charge for outgoing WebSocket messages, nor for incoming [WebSocket protocol pings](https://www.rfc-editor.org/rfc/rfc6455#section-5.5.2). For compute requests billing-only, a 20:1 ratio is applied to incoming WebSocket messages to factor in smaller messages for real-time communication. For example, 100 WebSocket incoming messages would be charged as 5 requests for billing purposes. The 20:1 ratio does not affect Durable Object metrics and analytics, which reflect actual usage.\n\n3 Application level auto-response messages handled by [`state.setWebSocketAutoResponse()`](https://developers.cloudflare.com/durable-objects/best-practices/websockets/) will not incur additional wall-clock time, and so they will not be charged.\n\n4 Duration is billed in wall-clock time as long as the Object is active, but is shared across all requests active on an Object at once. Calling `accept()` on a WebSocket in an Object will incur duration charges for the entire time the WebSocket is connected. It is recommended to use the WebSocket Hibernation API to avoid incurring duration charges once all event handlers finish running. For a complete explanation, refer to [When does a Durable Object incur duration charges?](https://developers.cloudflare.com/durable-objects/platform/pricing/#when-does-a-durable-object-incur-duration-charges).\n\n5 Duration billing charges for the 128 MB of memory your Durable Object is allocated, regardless of actual usage. If your account creates many instances of a single Durable Object class, Durable Objects may run in the same isolate on the same physical machine and share the 128 MB of memory. These Durable Objects are still billed as if they are allocated a full 128 MB of memory.\n\n## Storage billing\n\nThe [Durable Objects Storage API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/) is only accessible from within Durable Objects. Pricing depends on the storage backend of your Durable Objects.\n\n* **SQLite-backed Durable Objects (recommended)**: [SQLite storage backend](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#create-sqlite-backed-durable-object-class) is recommended for all new Durable Object classes. Workers Free plan can only create and access SQLite-backed Durable Objects.\n* **Key-value backed Durable Objects**: [Key-value storage backend](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/#create-durable-object-class-with-key-value-storage) is only available on the Workers Paid plan.\n\n### SQLite storage backend\n\nStorage billing on SQLite-backed Durable Objects\n\nStorage billing for SQLite-backed Durable Objects will be enabled in January 2026, with a target date of January 7, 2026 (no earlier). Only SQLite storage usage on and after the billing target date will incur charges. For more information, refer to [Billing for SQLite Storage](https://developers.cloudflare.com/changelog/2025-12-12-durable-objects-sqlite-storage-billing/).\n\n| | Workers Free plan | Workers Paid plan |\n| - | - | - |\n| Rows reads 1,2 | 5 million / day | First 25 billion / month included + $0.001 / million rows |\n| Rows written 1,2,3,4 | 100,000 / day | First 50 million / month included + $1.00 / million rows |\n| SQL Stored data 5 | 5 GB (total) | 5 GB-month, + $0.20/ GB-month |\n\nFootnotes\n\n1 Rows read and rows written included limits and rates match [D1 pricing](https://developers.cloudflare.com/d1/platform/pricing/), Cloudflare's serverless SQL database.\n\n2 Key-value methods like `get()`, `put()`, `delete()`, or `list()` store and query data in a hidden SQLite table and are billed as rows read and rows written.\n\n3 Each `setAlarm()` is billed as a single row written.\n\n4 Deletes are counted as rows written.\n\n5 Durable Objects will be billed for stored data until the [data is removed](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#remove-a-durable-objects-storage). Once the data is removed, the object will be cleaned up automatically by the system.\n\n### Key-value storage backend\n\n| | Workers Paid plan |\n| - | - |\n| Read request units1,2 | 1 million, + $0.20/million |\n| Write request units3 | 1 million, + $1.00/million |\n| Delete requests4 | 1 million, + $1.00/million |\n| Stored data5 | 1 GB, + $0.20/ GB-month |\n\nFootnotes\n\n1 A request unit is defined as 4 KB of data read or written. A request that writes or reads more than 4 KB will consume multiple units, for example, a 9 KB write will consume 3 write request units.\n\n2 List operations are billed by read request units, based on the amount of data examined. For example, a list request that returns a combined 80 KB of keys and values will be billed 20 read request units. A list request that does not return anything is billed for 1 read request unit.\n\n3 Each `setAlarm` is billed as a single write request unit.\n\n4 Delete requests are unmetered. For example, deleting a 100 KB value will be charged one delete request.\n\n5 Durable Objects will be billed for stored data until the data is removed. Once the data is removed, the object will be cleaned up automatically by the system.\n\nRequests that hit the [Durable Objects in-memory cache](https://developers.cloudflare.com/durable-objects/reference/in-memory-state/) or that use the [multi-key versions of `get()`/`put()`/`delete()` methods](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/) are billed the same as if they were a normal, individual request for each key.\n\n## Compute billing examples\n\nThese examples exclude the costs for the Workers calling the Durable Objects. When modelling the costs of a Durable Object, note that:\n\n* Inactive objects receiving no requests do not incur any duration charges.\n* The [WebSocket Hibernation API](https://developers.cloudflare.com/durable-objects/best-practices/websockets/#websocket-hibernation-api) can dramatically reduce duration-related charges for Durable Objects communicating with clients over the WebSocket protocol, especially if messages are only transmitted occasionally at sparse intervals.\n\n### Example 1\n\nThis example represents a simple Durable Object used as a co-ordination service invoked via HTTP.\n\n* A single Durable Object was called by a Worker 1.5 million times\n* It is active for 1,000,000 seconds in the month\n\nIn this scenario, the estimated monthly cost would be calculated as:\n\n**Requests**:\n\n* (1.5 million requests - included 1 million requests) x $0.15 / 1,000,000 = $0.075\n\n**Compute Duration**:\n\n* 1,000,000 seconds \\* 128 MB / 1 GB = 128,000 GB-s\n* (128,000 GB-s - included 400,000 GB-s) x $12.50 / 1,000,000 = $0.00\n\n**Estimated total**: \\~$0.075 (requests) + $0.00 (compute duration) + minimum $5/mo usage = $5.08 per month\n\n### Example 2\n\nThis example represents a moderately trafficked Durable Objects based application using WebSockets to broadcast game, chat or real-time user state across connected clients:\n\n* 100 Durable Objects have 50 WebSocket connections established to each of them.\n* Clients send approximately one message a minute for eight active hours a day, every day of the month.\n\nIn this scenario, the estimated monthly cost would be calculated as:\n\n**Requests**:\n\n* 50 WebSocket connections \\* 100 Durable Objects to establish the WebSockets = 5,000 connections created each day \\* 30 days = 150,000 WebSocket connection requests.\n* 50 messages per minute \\* 100 Durable Objects \\* 60 minutes \\* 8 hours \\* 30 days = 72,000,000 WebSocket message requests.\n* 150,000 + (72 million requests / 20 for WebSocket message billing ratio) = 3.75 million billing request.\n* (3.75 million requests - included 1 million requests) x $0.15 / 1,000,000 = $0.41.\n\n**Compute Duration**:\n\n* 100 Durable Objects \\* 60 seconds \\* 60 minutes \\* 8 hours \\* 30 days = 86,400,000 seconds.\n* 86,400,000 seconds \\* 128 MB / 1 GB = 11,059,200 GB-s.\n* (11,059,200 GB-s - included 400,000 GB-s) x $12.50 / 1,000,000 = $133.24.\n\n**Estimated total**: $0.41 (requests) + $133.24 (compute duration) + minimum $5/mo usage = $138.65 per month.\n\n### Example 3\n\nThis example represents a horizontally scaled Durable Objects based application using WebSockets to communicate user-specific state to a single client connected to each Durable Object.\n\n* 100 Durable Objects each have a single WebSocket connection established to each of them.\n* Clients sent one message every second of the month so that the Durable Objects were active for the entire month.\n\nIn this scenario, the estimated monthly cost would be calculated as:\n\n**Requests**:\n\n* 100 WebSocket connection requests.\n* 1 message per second \\* 100 connections \\* 60 seconds \\* 60 minutes \\* 24 hours \\* 30 days = 259,200,000 WebSocket message requests.\n* 100 + (259.2 million requests / 20 for WebSocket billing ratio) = 12,960,100 requests.\n* (12.9 million requests - included 1 million requests) x $0.15 / 1,000,000 = $1.79.\n\n**Compute Duration**:\n\n* 100 Durable Objects \\* 60 seconds \\* 60 minutes \\* 24 hours \\* 30 days = 259,200,000 seconds\n* 259,200,000 seconds \\* 128 MB / 1 GB = 33,177,600 GB-s\n* (33,177,600 GB-s - included 400,000 GB-s) x $12.50 / 1,000,000 = $409.72\n\n**Estimated total**: $1.79 (requests) + $409.72 (compute duration) + minimum $5/mo usage = $416.51 per month\n\n### Example 4\n\nThis example represents a moderately trafficked Durable Objects based application using WebSocket Hibernation to broadcast game, chat or real-time user state across connected clients:\n\n* 100 Durable Objects each have 100 Hibernatable WebSocket connections established to each of them.\n* Clients send one message per minute, and it takes 10ms to process a single message in the `webSocketMessage()` handler. Since each Durable Object handles 100 WebSockets, cumulatively each Durable Object will be actively executing JS for 1 second each minute (100 WebSockets \\* 10ms).\n\nIn this scenario, the estimated monthly cost would be calculated as:\n\n**Requests**:\n\n* 100 WebSocket connections \\* 100 Durable Objects to establish the WebSockets = 10,000 initial WebSocket connection requests.\n* 100 messages per minute1 \\* 100 Durable Objects \\* 60 minutes \\* 24 hours \\* 30 days = 432,000,000 requests.\n* 10,000 + (432 million requests / 20 for WebSocket billing ratio) = 21,610,000 million requests.\n* (21.6 million requests - included 1 million requests) x $0.15 / 1,000,000 = $3.09.\n\n**Compute Duration**:\n\n* 100 Durable Objects \\* 1 second2 \\* 60 minutes \\* 24 hours \\* 30 days = 4,320,000 seconds\n* 4,320,000 seconds \\* 128 MB / 1 GB = 552,960 GB-s\n* (552,960 GB-s - included 400,000 GB-s) x $12.50 / 1,000,000 = $1.91\n\n**Estimated total**: $3.09 (requests) + $1.91 (compute duration) + minimum $5/mo usage = $10.00 per month\n\n1 100 messages per minute comes from the fact that 100 clients connect to each DO, and each sends 1 message per minute.\n\n2 The example uses 1 second because each Durable Object is active for 1 second per minute. This can also be thought of as 432 million requests that each take 10 ms to execute (4,320,000 seconds).\n\n## Frequently Asked Questions\n\n### When does a Durable Object incur duration charges?\n\nA Durable Object incurs duration charges as long as the JavaScript object has to be in memory, either because it is actively handling a request, or because it cannot hibernate.\n\nOnce an object has been evicted from memory, the next time it is needed, it will be recreated (calling the constructor again).\n\nThere are several factors that contribute in keeping the Durable Object in memory and keeping it from hibernating or being inactive.\n\nFind more information in [Lifecycle of a Durable Object](https://developers.cloudflare.com/durable-objects/concepts/durable-object-lifecycle/).\n\n### Does an empty table / SQLite database contribute to my storage?\n\nYes, although minimal. Empty tables can consume at least a few kilobytes, based on the number of columns (table width) in the table. An empty SQLite database consumes approximately 12 KB of storage.\n\n### Does metadata stored in Durable Objects count towards my storage?\n\nAll writes to a SQLite-backed Durable Object stores nominal amounts of metadata in internal tables in the Durable Object, which counts towards your billable storage.\n\nThe metadata remains in the Durable Object until you call [`deleteAll()`](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#deleteall).\n\n</page>\n\n<page>\n---\ntitle: Choose a data or storage product · Cloudflare Durable Objects docs\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/platform/storage-options/\n  md: https://developers.cloudflare.com/durable-objects/platform/storage-options/index.md\n---\n\n\n</page>\n\n<page>\n---\ntitle: Data location · Cloudflare Durable Objects docs\ndescription: Jurisdictions are used to create Durable Objects that only run and\n  store data within a region to comply with local regulations such as the GDPR\n  or FedRAMP.\nlastUpdated: 2025-05-30T16:32:37.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/reference/data-location/\n  md: https://developers.cloudflare.com/durable-objects/reference/data-location/index.md\n---\n\n## Restrict Durable Objects to a jurisdiction\n\nJurisdictions are used to create Durable Objects that only run and store data within a region to comply with local regulations such as the [GDPR](https://gdpr-info.eu/) or [FedRAMP](https://blog.cloudflare.com/cloudflare-achieves-fedramp-authorization/).\n\nWorkers may still access Durable Objects constrained to a jurisdiction from anywhere in the world. The jurisdiction constraint only controls where the Durable Object itself runs and persists data. Consider using [Regional Services](https://developers.cloudflare.com/data-localization/regional-services/) to control the regions from which Cloudflare responds to requests.\n\nLogging\n\nA [`DurableObjectId`](https://developers.cloudflare.com/durable-objects/api/id) will be logged outside of the specified jurisdiction for billing and debugging purposes.\n\nDurable Objects can be restricted to a specific jurisdiction by creating a [`DurableObjectNamespace`](https://developers.cloudflare.com/durable-objects/api/namespace/) restricted to a jurisdiction. All [Durable Object ID methods](https://developers.cloudflare.com/durable-objects/api/id/) are valid on IDs within a namespace restricted to a jurisdiction.",
      "language": "unknown"
    },
    {
      "code": "* It is possible to have the same name represent different IDs in different jurisdictions.",
      "language": "unknown"
    },
    {
      "code": "* You will run into an error if the jurisdiction on your [`DurableObjectNamespace`](https://developers.cloudflare.com/durable-objects/api/namespace/) and the jurisdiction on [`DurableObjectId`](https://developers.cloudflare.com/durable-objects/api/id) are different.\n\n* You will not run into an error if the [`DurableObjectNamespace`](https://developers.cloudflare.com/durable-objects/api/namespace/) is not associated with a jurisdiction.\n\n* All [Durable Object ID methods](https://developers.cloudflare.com/durable-objects/api/id/) are valid on IDs within a namespace restricted to a jurisdiction.",
      "language": "unknown"
    },
    {
      "code": "Use `DurableObjectNamespace.jurisdiction`\n\nWhen specifying a jurisdiction, Cloudflare recommends you first create a namespace restricted to a jurisdiction, using `const euSubnamespace = env.MY_DURABLE_OBJECT.jurisdiction(\"eu\")`.\n\nNote that it is also possible to specify a jurisdiction by creating an individual [`DurableObjectId`](https://developers.cloudflare.com/durable-objects/api/id) restricted to a jurisdiction, using `const euId = env.MY_DURABLE_OBJECT.newUniqueId({ jurisdiction: \"eu\" })`.\n\n**However, Cloudflare does not recommend this approach.**\n\n### Supported locations\n\n| Parameter | Location |\n| - | - |\n| eu | The European Union |\n| fedramp | FedRAMP-compliant data centers |\n\n## Provide a location hint\n\nDurable Objects, as with any stateful API, will often add response latency as requests must be forwarded to the data center where the Durable Object, or state, is located.\n\nDurable Objects do not currently change locations after they are created1. By default, a Durable Object is instantiated in a data center close to where the initial `get()` request is made. This may not be in the same data center that the `get()` request is made from, but in most cases, it will be in close proximity.\n\nInitial requests to Durable Objects\n\nIt can negatively impact latency to pre-create Durable Objects prior to the first client request or when the first client request is not representative of where the majority of requests will come from. It is better for latency to create Durable Objects in response to actual production traffic or provide explicit location hints.\n\nLocation hints are the mechanism provided to specify the location that a Durable Object should be located regardless of where the initial `get()` request comes from.\n\nTo manually create Durable Objects in another location, provide an optional `locationHint` parameter to `get()`. Only the first call to `get()` for a particular Object will respect the hint.",
      "language": "unknown"
    },
    {
      "code": "Warning\n\nHints are a best effort and not a guarantee. Unlike with jurisdictions, Durable Objects will not necessarily be instantiated in the hinted location, but instead instantiated in a data center selected to minimize latency from the hinted location.\n\n### Supported locations\n\n| Parameter | Location |\n| - | - |\n| wnam | Western North America |\n| enam | Eastern North America |\n| sam | South America 2 |\n| weur | Western Europe |\n| eeur | Eastern Europe |\n| apac | Asia-Pacific |\n| oc | Oceania |\n| afr | Africa 2 |\n| me | Middle East 2 |\n\n1 Dynamic relocation of existing Durable Objects is planned for the future.\n\n2 Durable Objects currently do not spawn in this location. Instead, the Durable Object will spawn in a nearby location which does support Durable Objects. For example, Durable Objects hinted to South America spawn in Eastern North America instead.\n\n## Additional resources\n\n* You can find our more about where Durable Objects are located using the website: [Where Durable Objects Live](https://where.durableobjects.live/).\n\n</page>\n\n<page>\n---\ntitle: Data security · Cloudflare Durable Objects docs\ndescription: \"This page details the data security properties of Durable Objects, including:\"\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/reference/data-security/\n  md: https://developers.cloudflare.com/durable-objects/reference/data-security/index.md\n---\n\nThis page details the data security properties of Durable Objects, including:\n\n* Encryption-at-rest (EAR).\n* Encryption-in-transit (EIT).\n* Cloudflare's compliance certifications.\n\n## Encryption at Rest\n\nAll Durable Object data, including metadata, is encrypted at rest. Encryption and decryption are automatic, do not require user configuration to enable, and do not impact the effective performance of Durable Objects.\n\nEncryption keys are managed by Cloudflare and securely stored in the same key management systems we use for managing encrypted data across Cloudflare internally.\n\nEncryption at rest is implemented using the Linux Unified Key Setup (LUKS) disk encryption specification and [AES-256](https://www.cloudflare.com/learning/ssl/what-is-encryption/), a widely tested, highly performant and industry-standard encryption algorithm.\n\n## Encryption in Transit\n\nData transfer between a Cloudflare Worker, and/or between nodes within the Cloudflare network and Durable Objects is secured using the same [Transport Layer Security](https://www.cloudflare.com/learning/ssl/transport-layer-security-tls/) (TLS/SSL).\n\nAPI access via the HTTP API or using the [wrangler](https://developers.cloudflare.com/workers/wrangler/install-and-update/) command-line interface is also over TLS/SSL (HTTPS).\n\n## Compliance\n\nTo learn more about Cloudflare's adherence to industry-standard security compliance certifications, visit the Cloudflare [Trust Hub](https://www.cloudflare.com/trust-hub/compliance-resources/).\n\n</page>\n\n<page>\n---\ntitle: Gradual Deployments · Cloudflare Durable Objects docs\ndescription: Gradually deploy changes to Durable Objects.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/reference/durable-object-gradual-deployments/\n  md: https://developers.cloudflare.com/durable-objects/reference/durable-object-gradual-deployments/index.md\n---\n\n\n</page>\n\n<page>\n---\ntitle: Durable Objects migrations · Cloudflare Durable Objects docs\ndescription: A migration is a mapping process from a class name to a runtime\n  state. This process communicates the changes to the Workers runtime and\n  provides the runtime with instructions on how to deal with those changes.\nlastUpdated: 2025-08-20T21:45:15.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/\n  md: https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/index.md\n---\n\nA migration is a mapping process from a class name to a runtime state. This process communicates the changes to the Workers runtime and provides the runtime with instructions on how to deal with those changes.\n\nTo apply a migration, you need to:\n\n1. Edit your `wrangler.toml / wrangler.json` file, as explained below.\n2. Re-deploy your Worker using `npx wrangler deploy`.\n\nYou must initiate a migration process when you:\n\n* Create a new Durable Object class.\n* Rename a Durable Object class.\n* Delete a Durable Object class.\n* Transfer an existing Durable Objects class.\n\nNote\n\nUpdating the code for an existing Durable Object class does not require a migration. To update the code for an existing Durable Object class, run [`npx wrangler deploy`](https://developers.cloudflare.com/workers/wrangler/commands/#deploy). This is true even for changes to how the code interacts with persistent storage. Because of [global uniqueness](https://developers.cloudflare.com/durable-objects/platform/known-issues/#global-uniqueness), you do not have to be concerned about old and new code interacting with the same storage simultaneously. However, it is your responsibility to ensure that the new code is backwards compatible with existing stored data.\n\n## Create migration\n\nThe most common migration performed is a new class migration, which informs the runtime that a new Durable Object class is being uploaded. This is also the migration you need when creating your first Durable Object class.\n\nTo apply a Create migration:\n\n1. Add the following lines to your `wrangler.toml / wrangler.json` file:\n\n   * wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "The Create migration contains:\n\n   * A `tag` to identify the migration.\n   * The array `new_sqlite_classes`, which contains the new Durable Object class.\n\n2. Ensure you reference the correct name of the Durable Object class in your Worker code.\n\n3. Deploy the Worker.\n\nCreate migration example\n\nTo create a new Durable Object binding `DURABLE_OBJECT_A`, your `wrangler.toml / wrangler.json` file should look like the following:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "### Create Durable Object class with key-value storage\n\nRecommended SQLite-backed Durable Objects\n\nCloudflare recommends all new Durable Object namespaces use the [SQLite storage backend](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#create-sqlite-backed-durable-object-class). These Durable Objects can continue to use storage [key-value API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#synchronous-kv-api).\n\nAdditionally, SQLite-backed Durable Objects allow you to store more types of data (such as tables), and offer Point In Time Recovery API which can restore a Durable Object's embedded SQLite database contents (both SQL data and key-value data) to any point in the past 30 days.\n\nThe [key-value storage backend](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/#create-durable-object-class-with-key-value-storage) remains for backwards compatibility, and a migration path from KV storage backend to SQLite storage backend for existing Durable Object namespaces will be available in the future.\n\nUse `new_classes` on the migration in your Worker's Wrangler file to create a Durable Object class with the key-value storage backend:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Note\n\nDurable Objects are available both on Workers Free and Workers Paid plans.\n\n* **Workers Free plan**: Only Durable Objects with [SQLite storage backend](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#wrangler-configuration-for-sqlite-backed-durable-objects) are available.\n* **Workers Paid plan**: Durable Objects with either SQLite storage backend or [key-value storage backend](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/#create-durable-object-class-with-key-value-storage) are available.\n\nIf you wish to downgrade from a Workers Paid plan to a Workers Free plan, you must first ensure that you have deleted all Durable Object namespaces with the key-value storage backend.\n\n## Delete migration\n\nRunning a Delete migration will delete all Durable Objects associated with the deleted class, including all of their stored data.\n\n* Do not run a Delete migration on a class without first ensuring that you are not relying on the Durable Objects within that Worker anymore, that is, first remove the binding from the Worker.\n* Copy any important data to some other location before deleting.\n* You do not have to run a Delete migration on a class that was renamed or transferred.\n\nTo apply a Delete migration:\n\n1. Remove the binding for the class you wish to delete from the `wrangler.toml / wrangler.json` file.\n\n2. Remove references for the class you wish to delete from your Worker code.\n\n3. Add the following lines to your `wrangler.toml / wrangler.json` file.\n\n   * wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "The Delete migration contains:\n\n   * A `tag` to identify the migration.\n   * The array `deleted_classes`, which contains the deleted Durable Object classes.\n\n4. Deploy the Worker.\n\nDelete migration example\n\nTo delete a Durable Object binding `DEPRECATED_OBJECT`, your `wrangler.toml / wrangler.json` file should look like the following:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "## Rename migration\n\nRename migrations are used to transfer stored Durable Objects between two Durable Object classes in the same Worker code file.\n\nTo apply a Rename migration:\n\n1. Update the previous class name to the new class name by editing your `wrangler.toml / wrangler.json` file in the following way:\n\n   * wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "The Rename migration contains:\n\n   * A `tag` to identify the migration.\n\n   * The `renamed_classes` array, which contains objects with `from` and `to` properties.\n\n     * `from` property is the old Durable Object class name.\n     * `to` property is the renamed Durable Object class name.\n\n2. Reference the new Durable Object class name in your Worker code.\n\n3. Deploy the Worker.\n\nRename migration example\n\nTo rename a Durable Object class, from `OldName` to `UpdatedName`, your `wrangler.toml / wrangler.json` file should look like the following:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "## Transfer migration\n\nTransfer migrations are used to transfer stored Durable Objects between two Durable Object classes in different Worker code files.\n\nIf you want to transfer stored Durable Objects between two Durable Object classes in the same Worker code file, use [Rename migrations](#rename-migration) instead.\n\nNote\n\nDo not run a [Create migration](#create-migration) for the destination class before running a Transfer migration. The Transfer migration will create the destination class for you.\n\nTo apply a Transfer migration:\n\n1. Edit your `wrangler.toml / wrangler.json` file in the following way:\n\n   * wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "The Transfer migration contains:\n\n   * A `tag` to identify the migration.\n\n   * The `transferred_class` array, which contains objects with `from`, `from_script`, and `to` properties.\n\n     * `from` property is the name of the source Durable Object class.\n     * `from_script` property is the name of the source Worker script.\n     * `to` property is the name of the destination Durable Object class.\n\n2. Ensure you reference the name of the new, destination Durable Object class in your Worker code.\n\n3. Deploy the Worker.\n\nTransfer migration example\n\nYou can transfer stored Durable Objects from `DurableObjectExample` to `TransferredClass` from a Worker script named `OldWorkerScript`. The configuration of the `wrangler.toml / wrangler.json` file for your new Worker code (destination Worker code) would look like this:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "## Migration Wrangler configuration\n\n* Migrations are performed through the `[[migrations]]` configurations key in your `wrangler.toml` file or `migration` key in your `wrangler.json` file.\n\n* Migrations require a migration tag, which is defined by the `tag` property in each migration entry.\n\n* Migration tags are treated like unique names and are used to determine which migrations have already been applied. Once a given Worker code has a migration tag set on it, all future Worker code deployments must include a migration tag.\n\n* The migration list is an ordered array of tables, specified as a key in your Wrangler configuration file.\n\n* You can define the migration for each environment, as well as at the top level.\n\n  * Top-level migration is specified at the top-level `migrations` key in the Wrangler configuration file.\n\n  * Environment-level migration is specified by a `migrations` key inside the `env` key of the Wrangler configuration file (`[env.<environment_name>.migrations]`).\n\n    * Example Wrangler file:",
      "language": "unknown"
    },
    {
      "code": "* If a migration is only specified at the top-level, but not at the environment-level, the environment will inherit the top-level migration.\n\n  * Migrations at at the environment-level override migrations at the top level.\n\n* All migrations are applied at deployment. Each migration can only be applied once per [environment](https://developers.cloudflare.com/durable-objects/reference/environments/).\n\n* Each migration in the list can have multiple directives, and multiple migrations can be specified as your project grows in complexity.\n\nImportant\n\n* The destination class (the class that stored Durable Objects are being transferred to) for a Rename or Transfer migration must be exported by the deployed Worker.\n\n* You should not create the destination Durable Object class before running a Rename or Transfer migration. The migration will create the destination class for you.\n\n* After a Rename or Transfer migration, requests to the destination Durable Object class will have access to the source Durable Object's stored data.\n\n* After a migration, any existing bindings to the original Durable Object class (for example, from other Workers) will automatically forward to the updated destination class. However, any Workers bound to the updated Durable Object class must update their Durable Object binding configuration in the `wrangler` configuration file for their next deployment.\n\nNote\n\nNote that `.toml` files do not allow line breaks in inline tables (the `{key = \"value\"}` syntax), but line breaks in the surrounding inline array are acceptable.\n\nYou cannot enable a SQLite storage backend on an existing, deployed Durable Object class, so setting `new_sqlite_classes` on later migrations will fail with an error. Automatic migration of deployed classes from their key-value storage backend to SQLite storage backend will be available in the future.\n\nImportant\n\nDurable Object migrations are atomic operations and cannot be gradually deployed. To provide early feedback to developers, new Worker versions with new migrations cannot be uploaded. Refer to [Gradual deployments for Durable Objects](https://developers.cloudflare.com/workers/configuration/versions-and-deployments/gradual-deployments/#gradual-deployments-for-durable-objects) for more information.",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Environments · Cloudflare Durable Objects docs\ndescription: Environments provide isolated spaces where your code runs with\n  specific dependencies and configurations. This can be useful for a number of\n  reasons, such as compatibility testing or version management. Using different\n  environments can help with code consistency, testing, and production\n  segregation, which reduces the risk of errors when deploying code.\nlastUpdated: 2025-09-03T16:40:54.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/reference/environments/\n  md: https://developers.cloudflare.com/durable-objects/reference/environments/index.md\n---\n\nEnvironments provide isolated spaces where your code runs with specific dependencies and configurations. This can be useful for a number of reasons, such as compatibility testing or version management. Using different environments can help with code consistency, testing, and production segregation, which reduces the risk of errors when deploying code.\n\n## Wrangler environments\n\n[Wrangler](https://developers.cloudflare.com/workers/wrangler/install-and-update/) allows you to deploy the same Worker application with different configuration for each [environment](https://developers.cloudflare.com/workers/wrangler/environments/).\n\nIf you are using Wrangler environments, you must specify any [Durable Object bindings](https://developers.cloudflare.com/workers/runtime-apis/bindings/) you wish to use on a per-environment basis.\n\nDurable Object bindings are not inherited. For example, you can define an environment named `staging` as below:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Because Wrangler appends the [environment name](https://developers.cloudflare.com/workers/wrangler/environments/) to the top-level name when publishing, for a Worker named `worker-name` the above example is equivalent to:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "`\"EXAMPLE_CLASS\"` in the staging environment is bound to a different Worker code name compared to the top-level `\"EXAMPLE_CLASS\"` binding, and will therefore access different Durable Objects with different persistent storage.\n\nIf you want an environment-specific binding that accesses the same Objects as the top-level binding, specify the top-level Worker code name explicitly using `script_name`:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "### Migration environments\n\nYou can define a Durable Object migration for each environment, as well as at the top level. Migrations at at the environment-level override migrations at the top level.\n\nFor more information, refer to [Migration Wrangler Configuration](https://developers.cloudflare.com/durable-objects/reference/durable-objects-migrations/#migration-wrangler-configuration).\n\n## Local development\n\nLocal development sessions create a standalone, local-only environment that mirrors the production environment, so that you can test your Worker and Durable Objects before you deploy to production.\n\nAn existing Durable Object binding of `DB` would be available to your Worker when running locally.\n\nRefer to Workers [Local development](https://developers.cloudflare.com/workers/development-testing/bindings-per-env/).\n\n## Remote development\n\nKV-backed Durable Objects support remote development using the dashboard playground. The dashboard playground uses a browser version of Visual Studio Code, allowing you to rapidly iterate on your Worker entirely in your browser.\n\nTo start remote development:\n\n1. In the Cloudflare dashboard, go to the **Workers & Pages** page.\n\n   [Go to **Workers & Pages**](https://dash.cloudflare.com/?to=/:account/workers-and-pages)\n\n2. Select an existing Worker.\n\n3. Select the **Edit code** icon located on the upper-right of the screen.\n\nWarning\n\nRemote development is only available for KV-backed Durable Objects. SQLite-backed Durable Objects do not support remote development.\n\n</page>\n\n<page>\n---\ntitle: FAQs · Cloudflare Durable Objects docs\ndescription: A Durable Object incurs duration charges as long as the JavaScript\n  object has to be in memory, either because it is actively handling a request,\n  or because it cannot hibernate.\nlastUpdated: 2025-09-17T14:35:09.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/reference/faq/\n  md: https://developers.cloudflare.com/durable-objects/reference/faq/index.md\n---\n\n## Pricing\n\n### When does a Durable Object incur duration charges?\n\nA Durable Object incurs duration charges as long as the JavaScript object has to be in memory, either because it is actively handling a request, or because it cannot hibernate.\n\nOnce an object has been evicted from memory, the next time it is needed, it will be recreated (calling the constructor again).\n\nThere are several factors that contribute in keeping the Durable Object in memory and keeping it from hibernating or being inactive.\n\nFind more information in [Lifecycle of a Durable Object](https://developers.cloudflare.com/durable-objects/concepts/durable-object-lifecycle/).\n\n### Does an empty table / SQLite database contribute to my storage?\n\nYes, although minimal. Empty tables can consume at least a few kilobytes, based on the number of columns (table width) in the table. An empty SQLite database consumes approximately 12 KB of storage.\n\n### Does metadata stored in Durable Objects count towards my storage?\n\nAll writes to a SQLite-backed Durable Object stores nominal amounts of metadata in internal tables in the Durable Object, which counts towards your billable storage.\n\nThe metadata remains in the Durable Object until you call [`deleteAll()`](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#deleteall).\n\n## Limits\n\n### How much work can a single Durable Object do?\n\nDurable Objects can scale horizontally across many Durable Objects. Each individual Object is inherently single-threaded.\n\n* An individual Object has a soft limit of 1,000 requests per second. You can have an unlimited number of individual objects per namespace.\n* A simple [storage](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/) `get()` on a small value that directly returns the response may realize a higher request throughput compared to a Durable Object that (for example) serializes and/or deserializes large JSON values.\n* Similarly, a Durable Object that performs multiple `list()` operations may be more limited in terms of request throughput.\n\nA Durable Object that receives too many requests will, after attempting to queue them, return an [overloaded](https://developers.cloudflare.com/durable-objects/observability/troubleshooting/#durable-object-is-overloaded) error to the caller.\n\n### How many Durable Objects can I create?\n\nDurable Objects are designed such that the number of individual objects in the system do not need to be limited, and can scale horizontally.\n\n* You can create and run as many separate Durable Objects as you want within a given Durable Object namespace.\n* There are no limits for storage per account when using SQLite-backed Durable Objects on a Workers Paid plan.\n* Each SQLite-backed Durable Object has a storage limit of 10 GB on a Workers Paid plan.\n* Refer to [Durable Object limits](https://developers.cloudflare.com/durable-objects/platform/limits/) for more information.\n\n### Can I increase Durable Objects' CPU limit?\n\nDurable Objects are Worker scripts, and have the same [per invocation CPU limits](https://developers.cloudflare.com/workers/platform/limits/#worker-limits) as any Workers do. Note that CPU time is active processing time: not time spent waiting on network requests, storage calls, or other general I/O, which don't count towards your CPU time or Durable Objects compute consumption.\n\nBy default, the maximum CPU time per Durable Objects invocation (HTTP request, WebSocket message, or Alarm) is set to 30 seconds, but can be increased for all Durable Objects associated with a Durable Object definition by setting `limits.cpu_ms` in your Wrangler configuration:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "## Metrics and analytics\n\n### How can I identify which Durable Object instance generated a log entry?\n\nYou can use `$workers.durableObjectId` to identify the specific Durable Object instance that generated the log entry.\n\n</page>\n\n<page>\n---\ntitle: Glossary · Cloudflare Durable Objects docs\ndescription: Review the definitions for terms used across Cloudflare's Durable\n  Objects documentation.\nlastUpdated: 2024-10-31T15:59:06.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/reference/glossary/\n  md: https://developers.cloudflare.com/durable-objects/reference/glossary/index.md\n---\n\nReview the definitions for terms used across Cloudflare's Durable Objects documentation.\n\n| Term | Definition |\n| - | - |\n| alarm | A Durable Object alarm is a mechanism that allows you to schedule the Durable Object to be woken up at a time in the future. |\n| bookmark | A bookmark is a mostly alphanumeric string like `0000007b-0000b26e-00001538-0c3e87bb37b3db5cc52eedb93cd3b96b` which represents a specific state of a SQLite database at a certain point in time. Bookmarks are designed to be lexically comparable: a bookmark representing an earlier point in time compares less than one representing a later point, using regular string comparison. |\n| Durable Object | A Durable Object is an individual instance of a Durable Object class. A Durable Object is globally unique (referenced by ID), provides a global point of coordination for all methods/requests sent to it, and has private, persistent storage that is not shared with other Durable Objects within a namespace. |\n| Durable Object class | The JavaScript class that defines the methods (RPC) and handlers (`fetch`, `alarm`) as part of your Durable Object, and/or an optional `constructor`. All Durable Objects within a single namespace share the same class definition. |\n| Durable Objects | The product name, or the collective noun referring to more than one Durable Object. |\n| input gate | While a storage operation is executing, no events shall be delivered to a Durable Object except for storage completion events. Any other events will be deferred until such a time as the object is no longer executing JavaScript code and is no longer waiting for any storage operations. We say that these events are waiting for the \"input gate\" to open. |\n| instance | See \"Durable Object\". |\n| KV API | API methods part of Storage API that support persisting key-value data. |\n| migration | A Durable Object migration is a mapping process from a class name to a runtime state. Initiate a Durable Object migration when you need to:- Create a new Durable Object class.\n- Rename a Durable Object class.\n- Delete a Durable Object class.\n- Transfer an existing Durable Objects class. |\n| namespace | A logical collection of Durable Objects that all share the same Durable Object (class) definition. A single namespace can have (tens of) millions of Durable Objects. Metrics are scoped per namespace.- The binding name of the namespace (as it will be exposed inside Worker code) is defined in the Wrangler file under the `durable_objects.bindings.name` key. Note that the binding name may not uniquely identify a namespace within an account. Instead, each namespace has a unique namespace ID, which you can view from the Cloudflare dashboard.\n- You can instantiate a unique Durable Object within a namespace using [Durable Object namespace methods](https://developers.cloudflare.com/durable-objects/api/namespace/#methods). |\n| output gate | When a storage write operation is in progress, any new outgoing network messages will be held back until the write has completed. We say that these messages are waiting for the \"output gate\" to open. If the write ultimately fails, the outgoing network messages will be discarded and replaced with errors, while the Durable Object will be shut down and restarted from scratch. |\n| SQL API | API methods part of Storage API that support SQL querying. |\n| Storage API | The transactional and strongly consistent (serializable) [Storage API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/) for persisting data within each Durable Object. State stored within a unique Durable Object is \"private\" to that Durable Object, and not accessible from other Durable Objects.Storage API includes key-value (KV) API, SQL API, and point-in-time-recovery (PITR) API.- Durable Object classes with the key-value storage backend can use KV API.\n- Durable Object classes with the SQLite storage backend can use KV API, SQL API, and PITR API. |\n| Storage Backend | By default, a Durable Object class can use Storage API that leverages a key-value storage backend. New Durable Object classes can opt-in to using a [SQLite storage backend](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#sqlite-storage-backend). |\n| stub | An object that refers to a unique Durable Object within a namespace and allows you to call into that Durable Object via RPC methods or the `fetch` API. For example, `let stub = env.MY_DURABLE_OBJECT.get(id)` |\n\n</page>\n\n<page>\n---\ntitle: In-memory state in a Durable Object · Cloudflare Durable Objects docs\ndescription: In-memory state means that each Durable Object has one active\n  instance at any particular time. All requests sent to that Durable Object are\n  handled by that same instance. You can store some state in memory.\nlastUpdated: 2025-09-24T13:21:38.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/reference/in-memory-state/\n  md: https://developers.cloudflare.com/durable-objects/reference/in-memory-state/index.md\n---\n\nIn-memory state means that each Durable Object has one active instance at any particular time. All requests sent to that Durable Object are handled by that same instance. You can store some state in memory.\n\nVariables in a Durable Object will maintain state as long as your Durable Object is not evicted from memory.\n\nA common pattern is to initialize a Durable Object from [persistent storage](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/) and set instance variables the first time it is accessed. Since future accesses are routed to the same Durable Object, it is then possible to return any initialized values without making further calls to persistent storage.",
      "language": "unknown"
    },
    {
      "code": "A given instance of a Durable Object may share global memory with other instances defined in the same Worker code.\n\nIn the example above, using a global variable `value` instead of the instance variable `this.value` would be incorrect. Two different instances of `Counter` will each have their own separate memory for `this.value`, but might share memory for the global variable `value`, leading to unexpected results. Because of this, it is best to avoid global variables.\n\nBuilt-in caching\n\nThe Durable Object's storage has a built-in in-memory cache of its own. If you use `get()` to retrieve a value that was read or written recently, the result will be instantly returned from cache. Instead of writing initialization code like above, you could use `get(\"value\")` whenever you need it, and rely on the built-in cache to make this fast. Refer to the [Build a counter example](https://developers.cloudflare.com/durable-objects/examples/build-a-counter/) to learn more about this approach.\n\nHowever, in applications with more complex state, explicitly storing state in your Object may be easier than making Storage API calls on every access. Depending on the configuration of your project, write your code in the way that is easiest for you.\n\n</page>\n\n<page>\n---\ntitle: Build a seat booking app with SQLite in Durable Objects · Cloudflare\n  Durable Objects docs\ndescription: This tutorial shows you how to build a seat reservation app using\n  Durable Objects.\nlastUpdated: 2025-10-09T15:47:46.000Z\nchatbotDeprioritize: false\ntags: TypeScript,SQL\nsource_url:\n  html: https://developers.cloudflare.com/durable-objects/tutorials/build-a-seat-booking-app/\n  md: https://developers.cloudflare.com/durable-objects/tutorials/build-a-seat-booking-app/index.md\n---\n\nIn this tutorial, you will learn how to build a seat reservation app using Durable Objects. This app will allow users to book a seat for a flight. The app will be written in TypeScript and will use the new [SQLite storage backend in Durable Object](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#sqlite-storage-backend) to store the data.\n\nUsing Durable Objects, you can write reusable code that can handle coordination and state management for multiple clients. Moreover, writing data to SQLite in Durable Objects is synchronous and uses local disks, therefore all queries are executed with great performance. You can learn more about SQLite storage in Durable Objects in the [SQLite in Durable Objects blog post](https://blog.cloudflare.com/sqlite-in-durable-objects).\n\nSQLite in Durable Objects\n\nSQLite in Durable Objects is currently in beta. You can learn more about the limitations of SQLite in Durable Objects in the [SQLite in Durable Objects documentation](https://developers.cloudflare.com/durable-objects/best-practices/access-durable-objects-storage/#sqlite-storage-backend).\n\nThe application will function as follows:\n\n* A user navigates to the application with a flight number passed as a query parameter.\n* The application will create a new Durable Object for the flight number, if it does not already exist.\n* If the Durable Object already exists, the application will retrieve the seats information from the SQLite database.\n* If the Durable Object does not exist, the application will create a new Durable Object and initialize the SQLite database with the seats information. For the purpose of this tutorial, the seats information is hard-coded in the application.\n* When a user selects a seat, the application asks for their name. The application will then reserve the seat and store the name in the SQLite database.\n* The application also broadcasts any changes to the seats to all clients.\n\nLet's get started!\n\n## Prerequisites\n\n1. Sign up for a [Cloudflare account](https://dash.cloudflare.com/sign-up/workers-and-pages).\n2. Install [`Node.js`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm).\n\nNode.js version manager\n\nUse a Node version manager like [Volta](https://volta.sh/) or [nvm](https://github.com/nvm-sh/nvm) to avoid permission issues and change Node.js versions. [Wrangler](https://developers.cloudflare.com/workers/wrangler/install-and-update/), discussed later in this guide, requires a Node version of `16.17.0` or later.\n\n## 1. Create a new project\n\nCreate a new Worker project to create and deploy your app.\n\n1. Create a Worker named `seat-booking` by running:\n\n   * npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "For setup, select the following options:\n\n   * For *What would you like to start with?*, choose `Hello World example`.\n   * For *Which template would you like to use?*, choose `Worker + Durable Objects`.\n   * For *Which language do you want to use?*, choose `TypeScript`.\n   * For *Do you want to use git for version control?*, choose `Yes`.\n   * For *Do you want to deploy your application?*, choose `No` (we will be making some changes before deploying).\n\n2. Change into your new project directory to start developing:",
      "language": "unknown"
    },
    {
      "code": "## 2. Create the frontend\n\nThe frontend of the application is a simple HTML page that allows users to select a seat and enter their name. The application uses [Workers Static Assets](https://developers.cloudflare.com/workers/static-assets/binding/) to serve the frontend.\n\n1. Create a new directory named `public` in the project root.\n\n2. Create a new file named `index.html` in the `public` directory.\n\n3. Add the following HTML code to the `index.html` file:\n\npublic/index.html",
      "language": "unknown"
    },
    {
      "code": "* The frontend makes an HTTP `GET` request to the `/seats` endpoint to retrieve the available seats for the flight.\n* It also uses a WebSocket connection to receive updates about the available seats.\n* When a user clicks on a seat, the `bookSeat()` function is called that prompts the user to enter their name and then makes a `POST` request to the `/book-seat` endpoint.\n\n1. Update the bindings in the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/) to configure `assets` to serve the `public` directory.\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "1. If you start the development server using the following command, the frontend will be served at `http://localhost:8787`. However, it will not work because the backend is not yet implemented.",
      "language": "unknown"
    },
    {
      "code": "Workers Static Assets\n\n[Workers Static Assets](https://developers.cloudflare.com/workers/static-assets/binding/) is currently in beta. You can also use Cloudflare Pages to serve the frontend. However, you will need a separate Worker for the backend.\n\n## 3. Create table for each flight\n\nThe application already has the binding for the Durable Objects class configured in the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). If you update the name of the Durable Objects class in `src/index.ts`, make sure to also update the binding in the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/).\n\n1. Update the binding to use the SQLite storage in Durable Objects. In the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/), replace `new_classes=[\"Flight\"]` with `new_sqlite_classes=[\"Flight\"]`, `name = \"FLIGHT\"` with `name = \"FLIGHT\"`, and `class_name = \"MyDurableObject\"` with `class_name = \"Flight\"`. your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/) should look similar to this:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Your application can now use the SQLite storage in Durable Objects.\n\n1. Add the `initializeSeats()` function to the `Flight` class. This function will be called when the Durable Object is initialized. It will check if the table exists, and if not, it will create it. It will also insert seats information in the table.\n\nFor this tutorial, the function creates an identical seating plan for all the flights. However, in production, you would want to update this function to insert seats based on the flight type.\n\nReplace the `Flight` class with the following code:",
      "language": "unknown"
    },
    {
      "code": "1. Add a `fetch` handler to the `Flight` class. This handler will return a text response. In [Step 5](#5-handle-websocket-connections) You will update the `fetch` handler to handle the WebSocket connection.",
      "language": "unknown"
    },
    {
      "code": "1. Next, update the Worker's fetch handler to create a unique Durable Object for each flight.",
      "language": "unknown"
    },
    {
      "code": "Using the flight ID, from the query parameter, a unique Durable Object is created. This Durable Object is initialized with a table if it does not exist.\n\n## 4. Add methods to the Durable Object\n\n1. Add the `getSeats()` function to the `Flight` class. This function returns all the seats in the table.",
      "language": "unknown"
    },
    {
      "code": "1. Add the `assignSeat()` function to the `Flight` class. This function will assign a seat to a passenger. It takes the seat number and the passenger name as parameters.",
      "language": "unknown"
    },
    {
      "code": "The above function uses the `broadcastSeats()` function to broadcast the updated seats to all the connected clients. In the next section, we will add the `broadcastSeats()` function.\n\n## 5. Handle WebSocket connections\n\nAll the clients will connect to the Durable Object using WebSockets. The Durable Object will broadcast the updated seats to all the connected clients. This allows the clients to update the UI in real time.\n\n1. Add the `handleWebSocket()` function to the `Flight` class. This function handles the WebSocket connections.",
      "language": "unknown"
    },
    {
      "code": "1. Add the `broadcastSeats()` function to the `Flight` class. This function will broadcast the updated seats to all the connected clients.",
      "language": "unknown"
    },
    {
      "code": "1. Next, update the `fetch` handler in the `Flight` class. This handler will handle all the incoming requests from the Worker and handle the WebSocket connections using the `handleWebSocket()` method.",
      "language": "unknown"
    },
    {
      "code": "1. Finally, update the `fetch` handler of the Worker.",
      "language": "unknown"
    },
    {
      "code": "The `fetch` handler in the Worker now calls appropriate Durable Object function to handle the incoming request. If the request is a `GET` request to `/seats`, the Worker returns the seats from the Durable Object. If the request is a `POST` request to `/book-seat`, the Worker calls the `bookSeat` method of the Durable Object to assign the seat to the passenger. If the request is a WebSocket connection, the Durable Object handles the WebSocket connection.\n\n## 6. Test the application\n\nYou can test the application locally by running the following command:",
      "language": "unknown"
    },
    {
      "code": "This starts a local development server that runs the application. The application is served at `http://localhost:8787`.\n\nNavigate to the application at `http://localhost:8787` in your browser. Since the flight ID is not specified, the application displays an error message.\n\nUpdate the URL with the flight ID as `http://localhost:8787?flightId=1234`. The application displays the seats for the flight with the ID `1234`.\n\n## 7. Deploy the application\n\nTo deploy the application, run the following command:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "Navigate to the `[DEPLOYED_APP_LINK]` to see the application. Again, remember to pass the flight ID as a query string parameter.\n\n## Summary\n\nIn this tutorial, you have:\n\n* used the SQLite storage backend in Durable Objects to store the seats for a flight.\n* created a Durable Object class to manage the seat booking.\n* deployed the application to Cloudflare Workers!\n\nThe full code for this tutorial is available on [GitHub](https://github.com/harshil1712/seat-booking-app).\n\n</page>\n\n<page>\n---\ntitle: Demos · Cloudflare Email Routing docs\ndescription: Learn how you can use Email Workers within your existing architecture.\nlastUpdated: 2025-04-08T15:14:04.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-routing/email-workers/demos/\n  md: https://developers.cloudflare.com/email-routing/email-workers/demos/index.md\n---\n\nLearn how you can use Email Workers within your existing architecture.\n\n## Demos\n\nExplore the following demo applications for Email Workers.\n\n* [DMARC Email Worker:](https://github.com/cloudflare/dmarc-email-worker) A Cloudflare worker script to process incoming DMARC reports, store them, and produce analytics.\n\n</page>\n\n<page>\n---\ntitle: Enable Email Workers · Cloudflare Email Routing docs\ndescription: Follow these steps to enable and add your first Email Worker. If\n  you have never used Cloudflare Workers before, Cloudflare will create a\n  subdomain for you, and assign you to the Workers free pricing plan.\nlastUpdated: 2025-12-03T22:57:02.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-routing/email-workers/enable-email-workers/\n  md: https://developers.cloudflare.com/email-routing/email-workers/enable-email-workers/index.md\n---\n\nFollow these steps to enable and add your first Email Worker. If you have never used Cloudflare Workers before, Cloudflare will create a subdomain for you, and assign you to the Workers [free pricing plan](https://developers.cloudflare.com/workers/platform/pricing/).\n\n1. In the Cloudflare dashboard, go to the **Email Routing** page.\n\n   [Go to **Email Routing**](https://dash.cloudflare.com/?to=/:account/:zone/email/routing)\n\n2. Select **Get started**.\n\n3. In **Custom address**, enter the custom email address you want to use (for example, `my-new-email`).\n\n4. In **Destination**, choose the email address or Email Worker you want your emails to be forwarded to — for example, `your-name@gmail.com`. You can only choose a destination address you have already verified. To add a new destination address, refer to [Destination addresses](#destination-addresses).\n\n5. Select **Create and continue**.\n\n6. Verify your destination address and select **Continue**.\n\n7. Configure your DNS records and select **Add records and enable**.\n\nYou have successfully created your Email Worker. In the Email Worker’s card, select the **route** field to expand it and check the routes associated with the Worker.\n\n</page>\n\n<page>\n---\ntitle: Edit Email Workers · Cloudflare Email Routing docs\ndescription: Adding or editing Email Workers is straightforward. You can rename,\n  delete or edit Email Workers, as well as change the routes bound to a specific\n  Email Worker.\nlastUpdated: 2025-12-03T22:57:02.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-routing/email-workers/edit-email-workers/\n  md: https://developers.cloudflare.com/email-routing/email-workers/edit-email-workers/index.md\n---\n\nAdding or editing Email Workers is straightforward. You can rename, delete or edit Email Workers, as well as change the routes bound to a specific Email Worker.\n\n## Add an Email worker\n\n1. In the Cloudflare dashboard, go to the **Email Routing** page.\n\n   [Go to **Email Routing**](https://dash.cloudflare.com/?to=/:account/:zone/email/routing)\n\n2. Select **Email Workers**.\n\n3. Select **Create**.\n\n1) (Optional) Enter a descriptive Email Worker name in **Create a worker name**.\n\n2) In **Select a starter**, select the starter template that best suits your needs. You can also start from scratch and build your own Email Worker with **Create my own**. After choosing your template, select **Create**.\n\n3) Now, configure your code on the left side of the screen. For example, if you are creating an Email Worker from the Allowlist template:\n\n   1. In `const allow = [\"friend@example.com\", \"coworker@example.com\"];` replace the email examples with the addresses you want to allow emails from.\n   2. In `await message.forward(\"inbox@corp\");` replace the email address example with the address where emails should be forwarded to.\n\n4) (Optional) You can test your logic on the right side of the screen. In the **From** field, enter either an email address from your approved senders list or one that is not on the approved list. When you select **Trigger email event** you should see a message telling you if the email address is allowed or rejected.\n\n5) Select **Save and deploy** to save your Email Worker when you are finished.\n\n6) Select the arrow next to the name of your Email Worker to go back to the main screen.\n\n7) Find the Email Worker you have just created, and select **Create route**. This binds the Email Worker to a route (or email address) you can share. All emails received in this route will be forwarded to and processed by the Email Worker.\n\nNote\n\nYou have to create a new route to use with the Email Worker you created. You can have more than one route bound to the same Email Worker.\n\n1. Select **Save** to finish setting up your Email Worker.\n\nYou have successfully created your Email Worker. In the Email Worker’s card, select the **route** field to expand it and check the routes associated with the Worker.\n\n## Edit an Email Worker\n\n1. In the Cloudflare dashboard, go to the **Email Routing** page.\n\n   [Go to **Email Routing**](https://dash.cloudflare.com/?to=/:account/:zone/email/routing)\n\n2. Select **Email Workers**.\n\n3. Find the Email Worker you want to rename, and select the three-dot button next to it.\n\n4. Select **Code editor**.\n\n5. Make the appropriate changes to your code.\n\n6. Select **Save and deploy** when you are finished editing.\n\n## Rename Email Worker\n\nWhen you rename an Email Worker, you will lose the route that was previously bound to it. You will need to configure the route again after renaming the Email Worker.\n\n1. In the Cloudflare dashboard, go to the **Email Routing** page.\n\n   [Go to **Email Routing**](https://dash.cloudflare.com/?to=/:account/:zone/email/routing)\n\n2. Select **Email Workers**.\n\n3. Find the Email Worker you want to rename, and select the three-dot button next to it.\n\n4. From the drop-down menu, select **Manage Worker**.\n\n5. Select **Manage Service** > **Rename service**, and fill in the new Email Worker’s name.\n\n6. Select **Continue** > **Move**.\n\n7. Acknowledge the warning and select **Finish**.\n\n8. Now, go back to **Email** > **Email Routing**.\n\n9. In **Routes** find the custom address you previously had associated with your Email Worker, and select **Edit**.\n\n10. In the **Destination** drop-down menu, select your renamed Email Worker.\n\n11. Select **Save**.\n\n## Edit route\n\nThe following steps show how to change a route associated with an Email Worker.\n\n1. In the Cloudflare dashboard, go to the **Email Routing** page.\n\n   [Go to **Email Routing**](https://dash.cloudflare.com/?to=/:account/:zone/email/routing)\n\n2. Select **Email Workers**.\n\n3. Find the Email Worker you want to change the associated route, and select **route** on its card.\n\n4. Select **Edit** to make the required changes.\n\n5. Select **Save** to finish.\n\n## Delete an Email Worker\n\n1. In the Cloudflare dashboard, go to the **Email Routing** page.\n\n   [Go to **Email Routing**](https://dash.cloudflare.com/?to=/:account/:zone/email/routing)\n\n2. Select **Email Workers**.\n\n3. Find the Email Worker you want to delete, and select the three-dot button next to it.\n\n4. From the drop-down menu, select **Manage Worker**.\n\n5. Select **Manage Service** > **Delete**.\n\n6. Type the name of the Email Worker to confirm you want to delete it, and select **Delete**.\n\n</page>\n\n<page>\n---\ntitle: Local Development · Cloudflare Email Routing docs\ndescription: You can test the behavior of an Email Worker script in local\n  development using Wrangler with wrangler dev, or using the Cloudflare Vite\n  plugin.\nlastUpdated: 2025-08-22T15:29:09.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-routing/email-workers/local-development/\n  md: https://developers.cloudflare.com/email-routing/email-workers/local-development/index.md\n---\n\nYou can test the behavior of an Email Worker script in local development using Wrangler with [wrangler dev](https://developers.cloudflare.com/workers/wrangler/commands/#dev), or using the [Cloudflare Vite plugin](https://developers.cloudflare.com/workers/vite-plugin/).\n\nThis is the minimal wrangler configuration required to run an Email Worker locally:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Note\n\nIf you want to deploy your script you need to [enable Email Routing](https://developers.cloudflare.com/email-routing/get-started/enable-email-routing/) and have at least one verified [destination address](https://developers.cloudflare.com/email-routing/setup/email-routing-addresses/#destination-addresses).\n\nYou can now test receiving, replying, and sending emails in your local environment.\n\n## Receive an email\n\nConsider this example Email Worker script that uses the open source [`postal-mime`](https://www.npmjs.com/package/postal-mime) email parser:",
      "language": "unknown"
    },
    {
      "code": "Now when you run `npx wrangler dev`, wrangler will expose a local `/cdn-cgi/handler/email` endpoint that you can `POST` email messages to and trigger your Worker's `email()` handler:",
      "language": "unknown"
    },
    {
      "code": "This is what you get in the console:",
      "language": "unknown"
    },
    {
      "code": "## Send an email\n\nWrangler can also simulate sending emails locally. Consider this example Email Worker script that uses the [`mimetext`](https://www.npmjs.com/package/mimetext) npm package:",
      "language": "unknown"
    },
    {
      "code": "Now when you run `npx wrangler dev`, go to <http://localhost:8787/> to trigger the `fetch()` handler and send the email. You will see the follow message in your terminal:",
      "language": "unknown"
    },
    {
      "code": "Wrangler simulated `env.EMAIL.send()` by writing the email to a local file in [eml](https://datatracker.ietf.org/doc/html/rfc5322) format. The file contains the raw email message:",
      "language": "unknown"
    },
    {
      "code": "## Reply to and forward messages\n\nLikewise, [`EmailMessage`](https://developers.cloudflare.com/email-routing/email-workers/runtime-api/#emailmessage-definition)'s `forward()` and `reply()` methods are also simulated locally. Consider this Worker that receives an email, parses it, replies to the sender, and forwards the original message to one your verified recipient addresses:",
      "language": "unknown"
    },
    {
      "code": "Run `npx wrangler dev` and use curl to `POST` the same message from the [Receive an email](#receive-an-email) example. Your terminal will show you where to find the replied message in your local disk and to whom the email was forwarded:",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Reply to emails from Workers · Cloudflare Email Routing docs\ndescription: You can reply to incoming emails with another new message and\n  implement smart auto-responders programmatically, adding any content and\n  context in the main body of the message. Think of a customer support email\n  automatically generating a ticket and returning the link to the sender, an\n  out-of-office reply with instructions when you are on vacation, or a detailed\n  explanation of why you rejected an email.\nlastUpdated: 2025-03-12T19:09:43.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-routing/email-workers/reply-email-workers/\n  md: https://developers.cloudflare.com/email-routing/email-workers/reply-email-workers/index.md\n---\n\nYou can reply to incoming emails with another new message and implement smart auto-responders programmatically, adding any content and context in the main body of the message. Think of a customer support email automatically generating a ticket and returning the link to the sender, an out-of-office reply with instructions when you are on vacation, or a detailed explanation of why you rejected an email.\n\nReply to emails is a new method of the [`EmailMessage` object](https://developers.cloudflare.com/email-routing/email-workers/runtime-api/#emailmessage-definition) in the Runtime API. Here is how it works:",
      "language": "unknown"
    },
    {
      "code": "To mitigate security risks and abuse, replying to incoming emails has a few requirements and limits:\n\n* The incoming email has to have valid [DMARC](https://www.cloudflare.com/learning/dns/dns-records/dns-dmarc-record/).\n* The email can only be replied to once in the same `EmailMessage` event.\n* The recipient in the reply must match the incoming sender.\n* The outgoing sender domain must match the same domain that received the email.\n* Every time an email passes through Email Routing or another MTA, an entry is added to the `References` list. We stop accepting replies to emails with more than 100 `References` entries to prevent abuse or accidental loops.\n\nIf these and other internal conditions are not met, `reply()` will fail with an exception. Otherwise, you can freely compose your reply message, send it back to the original sender, and receive subsequent replies multiple times.\n\n</page>\n\n<page>\n---\ntitle: Runtime API · Cloudflare Email Routing docs\ndescription: An EmailEvent is the event type to programmatically process your\n  emails with a Worker. You can reject, forward, or drop emails according to the\n  logic you construct in your Worker.\nlastUpdated: 2025-05-07T07:45:00.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-routing/email-workers/runtime-api/\n  md: https://developers.cloudflare.com/email-routing/email-workers/runtime-api/index.md\n---\n\n## Background\n\nAn `EmailEvent` is the event type to programmatically process your emails with a Worker. You can reject, forward, or drop emails according to the logic you construct in your Worker.\n\n***\n\n## Syntax: ES modules\n\n`EmailEvent` can be handled in Workers functions written using the [ES modules format](https://developers.cloudflare.com/workers/reference/migrate-to-module-workers/) by adding an `email` function to your module's exported handlers:",
      "language": "unknown"
    },
    {
      "code": "### Parameters\n\n* `message` ForwardableEmailMessage\n\n  * A [`ForwardableEmailMessage` object](#forwardableemailmessage-definition).\n\n* `env` object\n\n  * An object containing the bindings associated with your Worker using ES modules format, such as KV namespaces and Durable Objects.\n\n* `ctx` object\n\n  * An object containing the context associated with your Worker using ES modules format. Currently, this object just contains the `waitUntil` function.\n\n***\n\n## Syntax: Service Worker\n\nService Workers are deprecated\n\nService Workers are deprecated but still supported. We recommend using [Module Workers](https://developers.cloudflare.com/workers/reference/migrate-to-module-workers/) instead. New features may not be supported for Service Workers.\n\n`EmailEvent` can be handled in Workers functions written using the Service Worker syntax by attaching to the `email` event with `addEventListener`:",
      "language": "unknown"
    },
    {
      "code": "### Properties\n\n* `event.message` ForwardableEmailMessage\n\n  * An [`ForwardableEmailMessage` object](#forwardableemailmessage-definition).\n\n***\n\n## `ForwardableEmailMessage` definition",
      "language": "unknown"
    },
    {
      "code": "An email message that is sent to a consumer Worker and can be rejected/forwarded.\n\n* `from` string\n\n  * `Envelope From` attribute of the email message.\n\n* `to` string\n\n  * `Envelope To` attribute of the email message.\n\n* `headers` Headers\n\n  * A [`Headers` object](https://developer.mozilla.org/en-US/docs/Web/API/Headers).\n\n* `raw` ReadableStream\n\n  * [Stream](https://developers.cloudflare.com/workers/runtime-apis/streams/readablestream) of the email message content.\n\n* `rawSize` number\n\n  * Size of the email message content.\n\n* `setReject(reasonstring)` : void\n\n  * Reject this email message by returning a permanent SMTP error back to the connecting client, including the given reason.\n\n* `forward(rcptTostring, headersHeadersoptional)` : Promise\n\n  * Forward this email message to a verified destination address of the account. If you want, you can add extra headers to the email message. Only `X-*` headers are allowed.\n  * When the promise resolves, the message is confirmed to be forwarded to a verified destination address.\n\n* `reply(EmailMessage)` : Promise\n\n  * Reply to the sender of this email message with a new EmailMessage object.\n  * When the promise resolves, the message is confirmed to be replied.\n\n## `EmailMessage` definition",
      "language": "unknown"
    },
    {
      "code": "An email message that can be sent from a Worker.\n\n* `from` string\n\n  * `Envelope From` attribute of the email message.\n\n* `to` string\n\n  * `Envelope To` attribute of the email message.\n\n</page>\n\n<page>\n---\ntitle: Send emails from Workers · Cloudflare Email Routing docs\ndescription: You can send an email about your Worker's activity from your Worker\n  to an email address verified on Email Routing. This is useful for when you\n  want to know about certain types of events being triggered, for example.\nlastUpdated: 2025-09-29T14:18:17.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-routing/email-workers/send-email-workers/\n  md: https://developers.cloudflare.com/email-routing/email-workers/send-email-workers/index.md\n---\n\nYou can send an email about your Worker's activity from your Worker to an email address verified on [Email Routing](https://developers.cloudflare.com/email-routing/setup/email-routing-addresses/#destination-addresses). This is useful for when you want to know about certain types of events being triggered, for example.\n\nBefore you can bind an email address to your Worker, you need to [enable Email Routing](https://developers.cloudflare.com/email-routing/get-started/) and have at least one [verified email address](https://developers.cloudflare.com/email-routing/setup/email-routing-addresses/#destination-addresses). Then, create a new binding in the Wrangler configuration file:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "## Types of bindings\n\nThere are several types of restrictions you can configure in the bindings:\n\n* **No attribute defined**: When you do not define an attribute, the binding has no restrictions in place. You can use it to send emails to any verified email address [through Email Routing](https://developers.cloudflare.com/email-routing/setup/email-routing-addresses/#destination-addresses).\n* **`destination_address`**: When you define the `destination_address` attribute, you create a targeted binding. This means you can only send emails to the chosen email address. For example, `{type = \"send_email\", name = \"<NAME_FOR_BINDING>\", destination_address = \"<YOUR_EMAIL>@example.com\"}`.\\\n  For this particular binding, when you call the `send_email` function you can pass `null` or `undefined` to your Worker and it will assume the email address specified in the binding.\n* **`allowed_destination_addresses`**: When you specify this attribute, you create an allowlist, and can send emails to any email address on the list.\n* **`allowed_sender_addresses`**: When you specify this attribute, you create a sender allowlist, and can only send emails from an email address on the list.\n\nYou can add one or more types of bindings to your Wrangler file. However, each attribute must be on its own line:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "## Example Worker\n\nRefer to the example below to learn how to construct a Worker capable of sending emails. This example uses [MIMEText](https://www.npmjs.com/package/mimetext):\n\nNote\n\nThe sender has to be an email from the domain where you have Email Routing active.",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Email Routing audit logs · Cloudflare Email Routing docs\ndescription: \"Audit logs for Email Routing are available in the Cloudflare\n  dashboard. The following changes to Email Routing will be displayed:\"\nlastUpdated: 2025-05-29T18:16:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-routing/get-started/audit-logs/\n  md: https://developers.cloudflare.com/email-routing/get-started/audit-logs/index.md\n---\n\nAudit logs for Email Routing are available in the [Cloudflare dashboard](https://dash.cloudflare.com/?account=audit-log). The following changes to Email Routing will be displayed:\n\n* Add/edit Rule\n* Add address\n* Address change status\n* Enable/disable/unlock zone\n\nRefer to [Review audit logs](https://developers.cloudflare.com/fundamentals/account/account-security/review-audit-logs/) for more information.\n\n</page>\n\n<page>\n---\ntitle: Email Routing analytics · Cloudflare Email Routing docs\ndescription: The Overview page shows you a summary of your account. You can\n  check details such as how many custom and destination addresses you have\n  configured, as well as the status of your routing service.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-routing/get-started/email-routing-analytics/\n  md: https://developers.cloudflare.com/email-routing/get-started/email-routing-analytics/index.md\n---\n\nThe Overview page shows you a summary of your account. You can check details such as how many custom and destination addresses you have configured, as well as the status of your routing service.\n\n## Email Routing summary\n\nIn Email Routing summary you can check metrics related the number of emails received, forwarded, dropped, and rejected. To filter this information by time interval, select the drop-down menu. You can choose preset periods between the previous 30 minutes and 30 days, as well as a custom date range.\n\n## Activity Log\n\nThis section allows you to sort through emails received, and check Email Routing actions - for example, `Forwarded`, `Dropped`, or `Rejected`. Select a specific email to expand its details and check information regarding the [SPF](https://datatracker.ietf.org/doc/html/rfc7208), [DKIM](https://datatracker.ietf.org/doc/html/rfc6376), and [DMARC](https://datatracker.ietf.org/doc/html/rfc7489) statuses. Depending on the information shown, you can opt to mark an email as spam or block the sender.\n\n</page>\n\n<page>\n---\ntitle: Enable Email Routing · Cloudflare Email Routing docs\ndescription: Email Routing is now enabled. You can add other custom addresses to\n  your account.\nlastUpdated: 2025-12-03T22:57:02.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-routing/get-started/enable-email-routing/\n  md: https://developers.cloudflare.com/email-routing/get-started/enable-email-routing/index.md\n---\n\nImportant\n\nEnabling Email Routing adds the appropriate `MX` records to the DNS settings of your zone in order for the service to work. You can [change these `MX` records](https://developers.cloudflare.com/email-routing/setup/email-routing-dns-records/) at any time. However, depending on how you configure them, Email Routing might stop working.\n\n1. In the Cloudflare dashboard, go to the **Email Routing** page.\n\n   [Go to **Email Routing**](https://dash.cloudflare.com/?to=/:account/:zone/email/routing)\n\n2. Review the records that will be added to your zone.\n\n3. Select **Add records and enable**.\n\n4. Go to **Routing rules**.\n\n5. For **Custom addresses**, select **Create address**.\n\n6. Enter the custom email address you want to use (for example, `my-new-email@example.com`).\n\n7. In **Destination addresses**, enter the full email address you want your emails to be forwarded to — for example, `your-name@example.com`.\n\n   Notes\n\n   If you have several destination addresses linked to the same custom email address (rule), Email Routing will only process the most recent rule. To avoid this, do not link several destination addresses to the same custom address.\n\n   The current implementation of email forwarding only supports a single destination address per custom address. To forward a custom address to multiple destinations you must create a Workers script to redirect the email to each destination. All the destinations used in the Workers script must be already validated.\n\n8. Select **Save**.\n\n9. Cloudflare will send a verification email to the address provided in the **Destination address** field. You must verify your email address before being able to proceed.\n\n10. In the verification email Cloudflare sent you, select **Verify email address** > **Go to Email Routing** to activate Email Routing.\n\n11. Your Destination address should now show **Verified**, under **Status**. Select **Continue**.\n\n12. Cloudflare needs to add the relevant `MX` and `TXT` records to DNS records for Email Routing to work. This step is automatic and is only needed the first time you configure Email Routing. It is meant to ensure you have the proper records configured in your zone. Select **Add records and finish**.\n\nEmail Routing is now enabled. You can add other custom addresses to your account.\n\nNote\n\nWhen Email Routing is configured and running, no other email services can be active in the domain you are configuring. If there are other `MX` records already configured in DNS, Cloudflare will ask you if you wish to delete them. If you do not delete existing `MX` records, Email Routing will not be enabled.\n\n</page>\n\n<page>\n---\ntitle: Test Email Routing · Cloudflare Email Routing docs\ndescription: To test that your configuration is working properly, send an email\n  to the custom address you set up in the dashboard. You should send your test\n  email from a different address than the one you specified as the destination\n  address.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-routing/get-started/test-email-routing/\n  md: https://developers.cloudflare.com/email-routing/get-started/test-email-routing/index.md\n---\n\nTo test that your configuration is working properly, send an email to the custom address [you set up in the dashboard](https://developers.cloudflare.com/email-routing/get-started/enable-email-routing/). You should send your test email from a different address than the one you specified as the destination address.\n\nFor example, if you set up `your-name@gmail.com` as the destination address, do not send your test email from that same Gmail account. Send a test email to that destination address from another email account (for example, `your-name@outlook.com`).\n\nThe reason for this is that some email providers will discard what they interpret as an incoming duplicate email and will not show it in your inbox, making it seem like Email Routing is not working properly.\n\n</page>\n\n<page>\n---\ntitle: Disable Email Routing · Cloudflare Email Routing docs\ndescription: \"Email Routing provides two options for disabling the service:\"\nlastUpdated: 2025-12-03T22:57:02.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-routing/setup/disable-email-routing/\n  md: https://developers.cloudflare.com/email-routing/setup/disable-email-routing/index.md\n---\n\nEmail Routing provides two options for disabling the service:\n\n* **Delete and Disable**: This option will immediately disable Email Routing and remove its `MX` records. Your custom email addresses will stop working, and your email will not be routed to its final destination.\n* **Unlock and keep DNS records**: (Advanced) This option is recommended if you plan to migrate to another provider. It allows you to add new `MX` records before disabling the service. Email Routing will stop working when you change your `MX` records.\n\n## Delete and disable Email Routing\n\n1. In the Cloudflare dashboard, go to the **Email Routing** page.\n\n   [Go to **Email Routing**](https://dash.cloudflare.com/?to=/:account/:zone/email/routing)\n\n2. Select **Settings**.\n\n3. Select **Start disabling** > **Delete and Disable**. Email Routing will show you the list of records associated with your account that will be deleted.\n\n4. Select **Delete records**.\n\nEmail Routing is now disabled for your account and will stop forwarding email. To enable the service again, select **Enable Email Routing** and follow the wizard.\n\n## Unlock and keep DNS records\n\n1. In the Cloudflare dashboard, go to the **Email Routing** page.\n\n   [Go to **Email Routing**](https://dash.cloudflare.com/?to=/:account/:zone/email/routing)\n\n2. Select **Settings**.\n\n3. Select **Start disabling** > **Unlock records and continue**.\n\n4. Select **Edit records on DNS**.\n\nYou now have the option to edit your DNS records to migrate your service to another provider.\n\nWarning\n\nChanging your DNS records will make Email Routing stop working. If you changed your mind and want to keep Email Routing working with your account, select **Lock DNS records**.\n\n</page>\n\n<page>\n---\ntitle: Configure rules and addresses · Cloudflare Email Routing docs\ndescription: An email rule is a pair of a custom email address and a destination\n  address, or a custom email address with an Email Worker. This allows you to\n  route emails to your preferred inbox, or apply logic through Email Workers\n  before deciding what should happen to your emails. You can have multiple\n  custom addresses, to route email from specific providers to specific mail\n  inboxes.\nlastUpdated: 2025-12-03T22:57:02.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-routing/setup/email-routing-addresses/\n  md: https://developers.cloudflare.com/email-routing/setup/email-routing-addresses/index.md\n---\n\nAn email rule is a pair of a custom email address and a destination address, or a custom email address with an Email Worker. This allows you to route emails to your preferred inbox, or apply logic through Email Workers before deciding what should happen to your emails. You can have multiple custom addresses, to route email from specific providers to specific mail inboxes.\n\n## Custom addresses\n\n1. In the Cloudflare dashboard, go to the **Email Routing** page.\n\n   [Go to **Email Routing**](https://dash.cloudflare.com/?to=/:account/:zone/email/routing)\n\n2. Select **Routing rules**.\n\n3. Select **Create address**.\n\n4. In **Custom address**, enter the custom email address you want to use (for example, `my-new-email`).\n\n5. In the **Action** drop-down menu, choose what this email rule should do. Refer to [Email rule actions](#email-rule-actions) for more information.\n\n6. In **Destination**, choose the email address or Email Worker you want your emails to be forwarded to — for example, `your-name@gmail.com`. You can only choose a destination address you have already verified. To add a new destination address, refer to [Destination addresses](#destination-addresses).\n\nNote\n\nIf you have more than one destination address linked to the same custom address, Email Routing will only process the most recent rule. This means only the most recent pair of custom address and destination address (rule) will receive your forwarded emails. To avoid this, do not link more than one destination address to the same custom address.\n\n### Email rule actions\n\nWhen creating an email rule, you must specify an **Action**:\n\n* *Send to an email*: Emails will be routed to your destination address. This is the default action.\n* *Send to a Worker*: Emails will be processed by the logic in your [Email Worker](https://developers.cloudflare.com/email-routing/email-workers).\n* *Drop*: Deletes emails sent to the custom address without routing them. This can be useful if you want to make an email address appear valid for privacy reasons.\n\nNote\n\nTo prevent spamming unintended recipients, all email rules are automatically disabled until the destination address is validated by the user.\n\n### Disable an email rule\n\n1. In the Cloudflare dashboard, go to the **Email Routing** page.\n\n   [Go to **Email Routing**](https://dash.cloudflare.com/?to=/:account/:zone/email/routing)\n\n2. Select **Routing rules**.\n\n3. In **Custom addresses**, identify the email rule you want to pause, and toggle the status button to **Disabled**.\n\nYour email rule is now disabled. It will not forward emails to a destination address or Email Worker. To forward emails again, toggle the email rule status button to **Active**.\n\n### Edit custom addresses\n\n1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com/) and select your account and domain.\n2. Go to **Email** > **Email Routing** > **Routes**.\n3. In **Custom addresses**, identify the email rule you want to edit, and select **Edit**.\n4. Make the appropriate changes to this custom address.\n\n## Catch-all address\n\nWhen you enable this feature, Email Routing will catch variations of email addresses to make them valid for the specified domain. For example, if you created an email rule for `info@example.com` and a sender accidentally types `ifno@example.com`, the email will still be correctly handled if you have **Catch-all addresses** enabled.\n\nTo enable Catch-all addresses:\n\n1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com/) and select your account and domain.\n2. Go to **Email** > **Email Routing** > **Routes**.\n3. Enable **Catch-all address**, so it shows as **Active**.\n4. In the **Action** drop-down menu, select what to do with these emails. Refer to [Email rule actions](#email-rule-actions) for more information.\n5. Select **Save**.\n\n## Subaddressing\n\nEmail Routing supports subaddressing, also known as plus addressing, as defined in [RFC 5233](https://www.rfc-editor.org/rfc/rfc5233). This enables using the \"+\" separator to augment your custom addresses with arbitrary detail information.\n\nYou can enable subaddressing at **Email** > **Email Routing** > **Settings**.\n\nOnce enabled, you can use subaddressing with any of your custom addresses. For example, if you send an email to `user+detail@example.com` it will be captured by the `user@example.com` custom address. The `+detail` part is ignored by Email Routing, but it can be captured next in the processing chain in the logs, an [Email Worker](https://developers.cloudflare.com/email-routing/email-workers/) or an [Agent application](https://github.com/cloudflare/agents/tree/main/examples/email-agent).\n\nIf a custom address `user+detail@example.com` already exists, it will take precedence over `user@example.com`. This prevents breaking existing routing rules for users, and allows certain sub-addresses to be captured by a specific rule.\n\n## Destination addresses\n\nThis section lets you manage your destination addresses. It lists all email addresses already verified, as well as email addresses pending verification. You can resend verification emails or delete destination addresses.\n\nDestination addresses are shared at the account level, and can be reused with any other domain in your account. This means the same destination address will be available to different domains in your account.\n\nTo prevent spam, email rules do not become active until after the destination address has been verified. Cloudflare sends a verification email to destination addresses specified in **Custom addresses**. You have to select **Verify email address** in that email to activate a destination address.\n\nNote\n\nDeleting a destination address automatically disables all email rules that use that email address as destination.\n\n</page>\n\n<page>\n---\ntitle: Email DNS records · Cloudflare Email Routing docs\ndescription: You can check the status of your DNS records in the Settings\n  section of Email Routing. This section also allows you to troubleshoot any\n  potential problems you might have with DNS records.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-routing/setup/email-routing-dns-records/\n  md: https://developers.cloudflare.com/email-routing/setup/email-routing-dns-records/index.md\n---\n\nYou can check the status of your DNS records in the **Settings** section of Email Routing. This section also allows you to troubleshoot any potential problems you might have with DNS records.\n\n## Email DNS records\n\nCheck the status of your account's DNS records in the **Email DNS records** card:\n\n* **Email DNS records configured** - DNS records are properly configured.\n* **Email DNS records misconfigured** - There is a problem with your accounts DNS records. Select **Enable Email Routing** to [start troubleshooting problems](https://developers.cloudflare.com/email-routing/troubleshooting/).\n\n### Start disabling\n\nWhen you successfully configure Email Routing, your DNS records will be locked and the dashboard will show a **Start disabling** button in the Email DNS records card. This locked status is the recommended setting by Cloudflare. It means that the DNS records required for Email Routing to work are locked and can only be changed if you disable Email Routing on your domain.\n\nIf you need to delete Email Routing or migrate to another provider, select **Start disabling**. Refer to [Disable Email Routing](https://developers.cloudflare.com/email-routing/setup/disable-email-routing/) for more information.\n\n### Lock DNS records\n\nDepending on your zone configuration, you might have your DNS records unlocked. This will also be true if, for some reason, you have unlocked your DNS records. Select **Lock DNS records** to lock your DNS records and protect them from being accidentally changed or deleted.\n\n## View DNS records\n\nSelect **View DNS records** for a list of the required `MX` and sender policy framework (SPF) records Email Routing is using.\n\nIf you are having trouble with your account's DNS records, refer to the [Troubleshooting](https://developers.cloudflare.com/email-routing/troubleshooting/) section.\n\n</page>\n\n<page>\n---\ntitle: Configure MTA-STS · Cloudflare Email Routing docs\ndescription: MTA Strict Transport Security (MTA-STS) was introduced by email\n  service providers including Microsoft, Google and Yahoo as a solution to\n  protect against downgrade and man-in-the-middle attacks in SMTP sessions, as\n  well as solving the lack of security-first communication standards in email.\nlastUpdated: 2025-12-03T22:57:02.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-routing/setup/mta-sts/\n  md: https://developers.cloudflare.com/email-routing/setup/mta-sts/index.md\n---\n\nMTA Strict Transport Security ([MTA-STS](https://datatracker.ietf.org/doc/html/rfc8461)) was introduced by email service providers including Microsoft, Google and Yahoo as a solution to protect against downgrade and man-in-the-middle attacks in SMTP sessions, as well as solving the lack of security-first communication standards in email.\n\nSuppose that `example.com` is your domain and uses Email Routing. Here is how you can enable MTA-STS for it.\n\n1. In the Cloudflare dashboard, go to the **Records** page.\n\n   [Go to **Records**](https://dash.cloudflare.com/?to=/:account/:zone/dns/records)\n\n2. Create a new CNAME record with the name `_mta-sts` that points to Cloudflare’s record `_mta-sts.mx.cloudflare.net`. Make sure to disable the proxy mode.\n\n![MTA-STS CNAME record](https://developers.cloudflare.com/_astro/mta-sts-record.DbwO-t_X_Z1UxIwF.webp)\n\n1. Confirm that the record was created:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "This tells the other end client that is trying to connect to us that we support MTA-STS.\n\nNext you need an HTTPS endpoint at `mta-sts.example.com` to serve your policy file. This file defines the mail servers in the domain that use MTA-STS. The reason why HTTPS is used here instead of DNS is because not everyone uses DNSSEC yet, so we want to avoid another MITM attack vector.\n\nTo do this you need to deploy a Worker that allows email clients to pull Cloudflare’s Email Routing policy file using the “well-known” URI convention.\n\n1. Go to your **Account** > **Workers & Pages** and select **Create**. Pick the default \"Hello World\" option button, and replace the sample worker code with the following:",
      "language": "unknown"
    },
    {
      "code": "This Worker proxies `https://mta-sts.mx.cloudflare.net/.well-known/mta-sts.txt` to your own domain.\n\n1. After deploying it, go to the Worker configuration, then **Settings** > **Domains & Routes** > **+Add**. Type the subdomain `mta-sts.example.com`.\n\n![MTA-STS Worker Custom Domain](https://developers.cloudflare.com/_astro/mta-sts-domain.UfZmAoBe_Z1Vf75K.webp)\n\nYou can then confirm that your policy file is working with the following:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "This says that you domain `example.com` enforces MTA-STS. Capable email clients will only deliver email to this domain over a secure connection to the specified MX servers. If no secure connection can be established the email will not be delivered.\n\nEmail Routing also supports MTA-STS upstream, which greatly improves security when forwarding your Emails to service providers like Gmail, Microsoft, and others.\n\nWhile enabling MTA-STS involves a few steps today, we aim to simplify things for you and automatically configure MTA-STS for your domains from the Email Routing dashboard as a future improvement.\n\n</page>\n\n<page>\n---\ntitle: Subdomains · Cloudflare Email Routing docs\ndescription: Email Routing is a zone-level feature. A zone has a top-level\n  domain (the same as the zone name) and it can have subdomains (managed under\n  the DNS feature.) As an example, you can have the example.com zone, and then\n  the mail.example.com and corp.example.com sub-domains under it.\nlastUpdated: 2025-12-03T22:57:02.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-routing/setup/subdomains/\n  md: https://developers.cloudflare.com/email-routing/setup/subdomains/index.md\n---\n\nEmail Routing is a [zone-level](https://developers.cloudflare.com/fundamentals/concepts/accounts-and-zones/#zones) feature. A zone has a top-level domain (the same as the zone name) and it can have subdomains (managed under the DNS feature.) As an example, you can have the `example.com` zone, and then the `mail.example.com` and `corp.example.com` sub-domains under it.\n\nYou can use Email Routing with any subdomain of any zone in your account. Follow these steps to add Email Routing features to a new subdomain:\n\n1. In the Cloudflare dashboard, go to the **Email Routing** page.\n\n   [Go to **Email Routing**](https://dash.cloudflare.com/?to=/:account/:zone/email/routing)\n\n2. Go to **Settings**, and select **Add subdomain**.\n\nOnce the subdomain is added and the DNS records are configured, you can see it in the **Settings** list under the **Subdomains** section.\n\nNow you can go to **Email** > **Email Routing** > **Routing rules** and create new custom addresses that will show you the option of using either the top domain of the zone or any other configured subdomain.\n\n</page>\n\n<page>\n---\ntitle: Troubleshooting misconfigured DNS records · Cloudflare Email Routing docs\ndescription: If there is a problem with your SPF records, refer to\n  Troubleshooting SPF records.\nlastUpdated: 2025-12-03T22:57:02.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-routing/troubleshooting/email-routing-dns-records/\n  md: https://developers.cloudflare.com/email-routing/troubleshooting/email-routing-dns-records/index.md\n---\n\n1. In the Cloudflare dashboard, go to the **Email Routing** page.\n\n   [Go to **Email Routing**](https://dash.cloudflare.com/?to=/:account/:zone/email/routing)\n\n2. Go to **Settings**. Email Routing will show you the status of your DNS records, such as `Missing`.\n\n3. Select **Enable Email Routing**.\n\n4. The next page will show you what kind of action is needed. For example, if you are missing DNS records, select **Add records and enable**.\n\nIf there is a problem with your SPF records, refer to [Troubleshooting SPF records](https://developers.cloudflare.com/email-routing/troubleshooting/email-routing-spf-records/).\n\nNote\n\nIf you are not using Email Routing but notice an Email Routing DNS record in your zone that you cannot delete, you can use the [Disable Email Routing API call](https://developers.cloudflare.com/api/resources/email_routing/subresources/dns/methods/delete/). It will remove any unexpected records, such as DKIM TXT records like `cf2024-1._domainkey.<hostname>`.\n\n</page>\n\n<page>\n---\ntitle: Troubleshooting SPF records · Cloudflare Email Routing docs\ndescription: \"Having multiple sender policy framework (SPF) records on your\n  account is not allowed, and will prevent Email Routing from working properly.\n  If your account has multiple SPF records, follow these steps to solve the\n  issue:\"\nlastUpdated: 2025-12-03T22:57:02.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-routing/troubleshooting/email-routing-spf-records/\n  md: https://developers.cloudflare.com/email-routing/troubleshooting/email-routing-spf-records/index.md\n---\n\nHaving multiple [sender policy framework (SPF) records](https://www.cloudflare.com/learning/dns/dns-records/dns-spf-record/) on your account is not allowed, and will prevent Email Routing from working properly. If your account has multiple SPF records, follow these steps to solve the issue:\n\n1. In the Cloudflare dashboard, go to the **Email Routing** page. Email Routing will warn you that you have multiple SPF records.\n\n   [Go to **Email Routing**](https://dash.cloudflare.com/?to=/:account/:zone/email/routing)\n\n2. Under **View DNS records**, select **Fix records**.\n\n3. Delete the incorrect SPF record.\n\nYou should now have your SPF records correctly configured. If you are unsure of which SPF record to delete:\n\n1. In the Cloudflare dashboard, go to the **Email Routing** page. Email Routing will warn you that you have multiple SPF records.\n\n   [Go to **Email Routing**](https://dash.cloudflare.com/?to=/:account/:zone/email/routing)\n\n2. Under **View DNS records**, select **Fix records**.\n\n3. Delete all SPF records.\n\n4. Select **Add records and enable**.\n\n</page>\n\n<page>\n---\ntitle: Escalation contacts · Cloudflare Email security (formerly Area 1) docs\ndescription: Configure escalation contacts in Cloudflare Email security to\n  prioritize alerts for phishing threats and email irregularities. Set up SOC,\n  Triage, Analyst, and Executive contacts.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/account-setup/escalation-contacts/\n  md: https://developers.cloudflare.com/email-security/account-setup/escalation-contacts/index.md\n---\n\nArea 1 has been renamed\n\nArea 1 is now **Email Security (formerly Area 1)**.\n\nAccess to Area 1\n\nBeginning October 1, 2025, access and support for Email Security (formerly Area 1) will only be available through the Cloudflare dashboard. Your Email Security protection will not change, but you will no longer be able to access the Area 1 dashboard or send support requests to `@area1security.com` email addresses. For help accessing the Cloudflare dashboard, reach out to <successteam@cloudflare.com>.\n\nWhenever Email security (formerly Area 1) finds an exceptional phishing threat or Email Service irregularity behavior (compromised email servers at a partner or vendor, wire fraud tactics, and more), we try to reach out to our customers.\n\nThere are four types of contacts available to configure, each with a priority type:\n\n* **SOC Contact**: P1 priority.\n* **Triage Analyst**: P2 priority.\n* **In-Depth Analyst**: P3 priority.\n* **Executive Contact**: P4 priority.\n\nEmail security will start by reaching out to P1-level contacts. If they do not respond, we will then try reaching out to the other contacts down the list until we receive a reply from one of these groups.\n\nYou can enable these special notifications through an opt-in process:\n\n1. Log in to the [Email security (formerly Area 1) dashboard](https://horizon.area1security.com/).\n2. Go to **Settings** (the gear icon).\n3. Go to **Subscriptions** > **Escalation Contacts**.\n4. Select **Add Contact**.\n5. Fill out the form.\n6. Select **Save**.\n\nNote\n\nIf you select **Critical Service Events**, the contact will be sent a text and/or an email message. They will need to select the link to confirm the subscriptions.\n\n</page>\n\n<page>\n---\ntitle: Manage account members · Cloudflare Email security (formerly Area 1) docs\ndescription: If your account is a Super Admin, you have the ability to add,\n  edit, and delete users and - if those users lose their two-factor\n  authentication (2FA) device - reset their 2FA.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/account-setup/manage-account-members/\n  md: https://developers.cloudflare.com/email-security/account-setup/manage-account-members/index.md\n---\n\nArea 1 has been renamed\n\nArea 1 is now **Email Security (formerly Area 1)**.\n\nAccess to Area 1\n\nBeginning October 1, 2025, access and support for Email Security (formerly Area 1) will only be available through the Cloudflare dashboard. Your Email Security protection will not change, but you will no longer be able to access the Area 1 dashboard or send support requests to `@area1security.com` email addresses. For help accessing the Cloudflare dashboard, reach out to <successteam@cloudflare.com>.\n\nIf your account is a **Super Admin**, you have the ability to add, edit, and delete users and - if those users lose their two-factor authentication (2FA) device - reset their 2FA.\n\n## Add user\n\nTo add a user:\n\n1. Log in to the [Email Security (formerly Area 1) dashboard](https://horizon.area1security.com/) .\n2. Go to **Settings** (the gear icon).\n3. Go to **Users and Actions**.\n4. Select **Add User**.\n5. Enter their information, as well as their [**Permission** level](https://developers.cloudflare.com/email-security/account-setup/permissions/).\n6. Select **Send Invitation**.\n\n## Edit user\n\nTo edit a user's settings:\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/).\n2. Go to **Settings** (the gear icon).\n3. Go to **Users and Actions**.\n4. On a specific user, select **...** > **Edit**.\n5. Update any needed information.\n6. Select **Update User**.\n\n## Delete user\n\nTo delete a user:\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/).\n2. Go to **Settings** (the gear icon).\n3. Go to **Users and Actions**.\n4. On a specific user, select **...** > **Delete**.\n\n## Reset two-factor authentication\n\nTo reset a user's two-factor authentication (2FA):\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/).\n2. Go to **Settings** (the gear icon).\n3. Go to **Users and Actions**.\n4. On a specific user, select **...** > **Reset 2FA**.\n\n</page>\n\n<page>\n---\ntitle: Manage parent permissions · Cloudflare Email security (formerly Area 1) docs\ndescription: When you set up Email security through a partner, that partner's\n  account is the parent account to your child account.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/account-setup/manage-parent-permissions/\n  md: https://developers.cloudflare.com/email-security/account-setup/manage-parent-permissions/index.md\n---\n\nArea 1 has been renamed\n\nArea 1 is now **Email Security (formerly Area 1)**.\n\nAccess to Area 1\n\nBeginning October 1, 2025, access and support for Email Security (formerly Area 1) will only be available through the Cloudflare dashboard. Your Email Security protection will not change, but you will no longer be able to access the Area 1 dashboard or send support requests to `@area1security.com` email addresses. For help accessing the Cloudflare dashboard, reach out to <successteam@cloudflare.com>.\n\nWhen you set up Email security through a [partner](https://developers.cloudflare.com/email-security/partners/), that partner's account is the **parent** account to your **child** account.\n\nEach child account can set the level of access allowed to their account from the parent. You may want to update this setting if you are receiving troubleshooting support from your parent account.\n\nTo update parent permissions:\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/).\n\n2. Go to **Settings** (the gear icon).\n\n3. Go to **Delegated Accounts**.\n\n4. Select a permission level:\n\n   * **No external account access**: Shuts off all access from the parent account (including Email security).\n   * **Allow external account view-only access** (default): Allows a parent user to view the customer's portal, including settings.\n   * **Allow external account Super Admin access**: Allows a parent user to administer the customer account on their behalf. By selecting this option the customer is acknowledging consent for outside administration of their account.\n\n5. Select **Save**.\n\n</page>\n\n<page>\n---\ntitle: Permissions · Cloudflare Email security (formerly Area 1) docs\ndescription: When you create a user, the available options for permissions\n  depend on whether your account is a parent account or a child account.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/account-setup/permissions/\n  md: https://developers.cloudflare.com/email-security/account-setup/permissions/index.md\n---\n\nArea 1 has been renamed\n\nArea 1 is now **Email Security (formerly Area 1)**.\n\nAccess to Area 1\n\nBeginning October 1, 2025, access and support for Email Security (formerly Area 1) will only be available through the Cloudflare dashboard. Your Email Security protection will not change, but you will no longer be able to access the Area 1 dashboard or send support requests to `@area1security.com` email addresses. For help accessing the Cloudflare dashboard, reach out to <successteam@cloudflare.com>.\n\nWhen you [create a user](https://developers.cloudflare.com/email-security/account-setup/manage-account-members/#add-user), the available options for permissions depend on whether your account is a **parent** account or a **child** account.\n\n## Parent accounts\n\nParent accounts are treated as containers with no services provisioned. User accounts created at the parent level will allow them to access any child account.\n\nThese accounts are only required for administrators who manage multiple accounts, most commonly associated with our [partners](https://developers.cloudflare.com/email-security/partners/).\n\nParent users can have one of the following roles:\n\n* **Viewer**: Can enter child accounts but is prevented from making any settings changes, regardless of the customer account settings.\n* **SOC Analyst**: Can enter child accounts and make changes on behalf of the customer.\n\nIf your account has [parent permissions](https://developers.cloudflare.com/email-security/account-setup/manage-parent-permissions/) that conflict with a parent user's permissions, the parent permissions set on your account take precedence.\n\n## Child accounts\n\nChild accounts control settings and services associated with an Email security instance.\n\n### Child users\n\nUsers created at child level will only have access to the assigned child account. These users can have one of the following roles:\n\n* **Super Admin**: Has full access to the account and can make any configuration changes. Can access **Settings** (the gear icon).\n* **Configuration Admin**: Can make configuration changes and manage users, except for Super Admin. Has no ability to review messages.\n* **SOC Analyst**: Can search, review and retract messages. Has no admin capabilities or access to **Settings** (the gear icon).\n* **Viewer**: Only has access to metrics within the system. No access to **Settings** (the gear icon).\n\n### Parent users\n\nDepending on the [parent permissions](https://developers.cloudflare.com/email-security/account-setup/manage-parent-permissions/) of your child account, you can delegate access to parent users of your account. This configuration will allow a parent user to view and change settings associated with your account.\n\n</page>\n\n<page>\n---\ntitle: SSO integration · Cloudflare Email security (formerly Area 1) docs\ndescription: For added security and convenience, Email security (formerly Area\n  1) offers support for Security Assertion Markup Language based (SAML-based)\n  single sign-on (SSO) logins. Organizations are able to choose between having\n  users access Email security (formerly Area 1) with a username and password\n  plus a two-factor authentication (2FA) code, or using an SSO provider, such as\n  OneLogin or Okta.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/account-setup/sso/\n  md: https://developers.cloudflare.com/email-security/account-setup/sso/index.md\n---\n\nArea 1 has been renamed\n\nArea 1 is now **Email Security (formerly Area 1)**.\n\nAccess to Area 1\n\nBeginning October 1, 2025, access and support for Email Security (formerly Area 1) will only be available through the Cloudflare dashboard. Your Email Security protection will not change, but you will no longer be able to access the Area 1 dashboard or send support requests to `@area1security.com` email addresses. For help accessing the Cloudflare dashboard, reach out to <successteam@cloudflare.com>.\n\nFor added security and convenience, Email security (formerly Area 1) offers support for Security Assertion Markup Language based (SAML-based) single sign-on (SSO) logins. Organizations are able to choose between having users access Email security (formerly Area 1) with a username and password plus a two-factor authentication (2FA) code, or using an SSO provider, such as OneLogin or Okta.\n\n## SAML configuration options\n\n* **Identity Provider initiated (IDP-initiated) SAML**: IDP-initiated configurations (like Okta or OneLogin) require the IDP to be accessible to the Email security infrastructure in order to successfully authenticate users. At the most basic level, the user selects an application from their IDP. Then, the IDP communicates with Email security using a SAML assertion to provide identity information for the user requesting to login to the Email security dashboard.\n* **Service Provider Initiated (SP-initiated) SAML**: SP-initiated configurations are the most common SAML authentication mechanisms. The main difference compared to IDP is that the service provider (like Email security) does not require any direct connection to the IDP in order to authenticate a user. The user's browser provides the ability for the SAML exchange to occur but the service provider and the IDP do not directly communicate with each other.\n\nEmail security (formerly Area 1) only supports IDP-initiated SAML setup at this point.\n\n## Setup\n\nFor more details on setup, refer to the following resources:\n\n* [Generic SSO guide](https://developers.cloudflare.com/email-security/account-setup/sso/generic-sso/)\n* [Okta guide](https://developers.cloudflare.com/email-security/account-setup/sso/okta/)\n* [Azure guide](https://developers.cloudflare.com/email-security/account-setup/sso/azure/)\n* [Cloudflare Access for SaaS](https://developers.cloudflare.com/cloudflare-one/access-controls/applications/http-apps/saas-apps/area-1/)\n\n</page>\n\n<page>\n---\ntitle: Service accounts · Cloudflare Email security (formerly Area 1) docs\ndescription: A service account allows admins to create and maintain API\n  credentials separate from a single username and password combination. It also\n  allows you to create and control additional API access for different use\n  cases.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/api/service-accounts/\n  md: https://developers.cloudflare.com/email-security/api/service-accounts/index.md\n---\n\nA **service account** allows admins to create and maintain API credentials separate from a single username and password combination. It also allows you to create and control additional API access for different use cases.\n\nWhen you connect to the [Email security (formerly Area 1) API](https://developers.cloudflare.com/email-security/api/), the **Public Key** is used for the *username* and the **Private Key** for the *password*.\n\n## Create service account\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/).\n2. Go to **Settings** (the gear icon).\n3. Go to **Service Accounts**.\n4. Select **Add Service Account**.\n5. Add a **Name**.\n6. Select **Create Service Account**.\n7. You will see your account's **Private Key** in a pop-up message (which will never be displayed again) and **Public Key** in the list of service accounts. Make sure to copy both values and store in a secure location.\n\n***\n\n## Rotate private key\n\nIf you lose your private key or need to rotate it for security reasons, you can generate a new private key:\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/).\n2. Go to **Settings** (the gear icon).\n3. Go to **Service Accounts**.\n4. On a specific account, select **...** > **Refresh key**.\n\n</page>\n\n<page>\n---\ntitle: API deployment · Cloudflare Email security (formerly Area 1) docs\ndescription: When you choose an API deployment for your Email Security (formerly\n  Area 1) setup, email messages only reach Email Security after they have\n  already reached a user's inbox.\nlastUpdated: 2025-08-29T19:00:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/deployment/api/\n  md: https://developers.cloudflare.com/email-security/deployment/api/index.md\n---\n\nArea 1 has been renamed\n\nArea 1 is now **Email Security (formerly Area 1)**.\n\nAccess to Area 1\n\nBeginning October 1, 2025, access and support for Email Security (formerly Area 1) will only be available through the Cloudflare dashboard. Your Email Security protection will not change, but you will no longer be able to access the Area 1 dashboard or send support requests to `@area1security.com` email addresses. For help accessing the Cloudflare dashboard, reach out to <successteam@cloudflare.com>.\n\nWhen you choose an **API deployment** for your [Email Security (formerly Area 1) setup](https://developers.cloudflare.com/email-security/deployment/), email messages only reach Email Security after they have already reached a user's inbox.\n\nThen, through on integrations with your email provider, Email Security can [retract messages](https://developers.cloudflare.com/email-security/email-configuration/retract-settings/) based on your organization's policies.\n\n![With API deployment, messages travel through Email Security's email filter after reaching your users.](https://developers.cloudflare.com/_astro/api-deployment-diagram.sJM5FAp1_1anzpf.webp)\n\n## Benefits\n\nWhen you choose API deployment, you get the following benefits:\n\n* Easy protection for complex email architectures, without requiring any change to mailflow operations.\n* Agentless deployment for Microsoft 365 and Gmail.\n* The initial email protection measures offered by your current email provider.\n\n## Limitations\n\nHowever, API deployment also has the following disadvantages:\n\n* Email Security is dependent on your email provider's API infrastructure and outages will increase the message dwell time in the inbox.\n* Email Security requires read and write access to mailboxes.\n* Requires API support from your email provider (does not typically support on-premise providers).\n* Your email provider may throttle API requests from Email Security.\n* Detection rates may be lower if multiple solutions exist.\n* Messages cannot be modified or quarantined.\n* Certain URL rewrite schemes cannot be decoded (for example, Mimecast).\n\n## Get started\n\nFor help getting started, refer to our [setup guides](https://developers.cloudflare.com/email-security/deployment/api/setup/).\n\n</page>\n\n<page>\n---\ntitle: Inline deployment · Cloudflare Email security (formerly Area 1) docs\ndescription: With an Inline deployment for your Email Security (formerly Area 1)\n  setup, Email Security evaluates email messages before they reach a user's\n  inbox.\nlastUpdated: 2025-08-29T19:00:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/deployment/inline/\n  md: https://developers.cloudflare.com/email-security/deployment/inline/index.md\n---\n\nArea 1 has been renamed\n\nArea 1 is now **Email Security (formerly Area 1)**.\n\nAccess to Area 1\n\nBeginning October 1, 2025, access and support for Email Security (formerly Area 1) will only be available through the Cloudflare dashboard. Your Email Security protection will not change, but you will no longer be able to access the Area 1 dashboard or send support requests to `@area1security.com` email addresses. For help accessing the Cloudflare dashboard, reach out to <successteam@cloudflare.com>.\n\nWith an **Inline deployment** for your [Email Security (formerly Area 1) setup](https://developers.cloudflare.com/email-security/deployment/), Email Security evaluates email messages before they reach a user's inbox.\n\nMore technically, Email Security becomes a hop in the SMTP processing chain and physically interacts with incoming email messages. Based on your policies, various messages are blocked before reaching the inbox.\n\n![With inline deployment, messages travel through Email Security's email filter before reaching your users.](https://developers.cloudflare.com/_astro/inline-deployment-diagram.BP5ZohFt_Z1ar6Rq.webp)\n\n## Benefits\n\nWhen you choose an inline deployment, you get the following benefits:\n\n* Messages are processed and physically blocked before delivery to a user's mailbox.\n* Your deployment is simpler, because any complex processing can happen downstream and without modification.\n* Email Security can [modify delivered messages](https://developers.cloudflare.com/email-security/email-configuration/email-policies/text-addons/), adding subject or body mark-ups.\n* Email Security can offer high availability and adaptive message pooling.\n* You can set up advanced handling downstream for non-quarantined messages with [added `X-headers`](https://developers.cloudflare.com/email-security/reference/dispositions-and-attributes/).\n\n## Limitations\n\nInline deployments are not without their disadvantages. If you deploy Email Security as your MX record, you will have to make changes to your DNS. If not — and you deploy Email Security after your MX record — you will have a more complex SMTP architecture.\n\nAdditionally, this setup may require policy duplication on multiple solutions and the Mail Transfer Agent (MTA).\n\n## Get started\n\nFor help getting started, refer to our [setup guides](https://developers.cloudflare.com/email-security/deployment/inline/setup/).\n\n</page>\n\n<page>\n---\ntitle: Admin Quarantine · Cloudflare Email security (formerly Area 1) docs\ndescription: Admin Quarantine allows you to automatically prevent incoming\n  messages from reaching a recipient's inbox based on the disposition assigned\n  by Email security.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/email-configuration/admin-quarantine/\n  md: https://developers.cloudflare.com/email-security/email-configuration/admin-quarantine/index.md\n---\n\nAdmin Quarantine allows you to automatically prevent incoming messages from reaching a recipient's inbox based on the [disposition](https://developers.cloudflare.com/email-security/reference/dispositions-and-attributes/) assigned by Email security.\n\nThe messages sent to Admin Quarantine are determined by your [domain settings](https://developers.cloudflare.com/email-security/email-configuration/domains-and-routing/domains/).\n\n## Quarantine emails by disposition\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/).\n\n2. Go to **Settings** (the gear icon).\n\n3. Select **Email Configuration** > **Domains**.\n\n4. Select the three dots on the domain that you want to configure admin quarantine for, and choose **Edit**.\n\n5. In **Quarantine Policy** choose the dispositions you want to enable quarantine for that domain.\n\n6. Select **Update Domain**.\n\nNote\n\nQuarantine by disposition needs to be configured manually per domain.\n\n## Access Admin Quarantine\n\nYou can view and potentially release emails that were sent to **Admin Quarantine**:\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/).\n\n2. Go to **Email** > **Admin Quarantine**.\n\n   ![Access Admin Quarantine to review emails](https://developers.cloudflare.com/_astro/access-quarantine.BZq99YOT_ZRDKuQ.webp)\n\n3. Review emails as needed.\n\n## Release quarantined emails\n\nFrom **Admin Quarantine**, you can also release quarantined emails by selecting one or more messages:\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/).\n\n2. Go to **Email** > **Admin Quarantine**.\n\n3. Find the email you want to release.\n\n4. Select **...** > **Release**.\n\n   ![Select release to remove emails from quarantine](https://developers.cloudflare.com/_astro/release-emails.DcaUOQSx_XilYX.webp)\n\n5. Select **Release** to confirm that you want to release the selected email.\n\n6. (Optional) You can also release multiple messages, by selecting the box next to each message you want to release.\n\nNote\n\nAfter being released from quarantine, Email security forwards the original email messages to their destination. These emails will arrive at email inboxes from the original sender, not Email security.\n\n</page>\n\n<page>\n---\ntitle: Domains and routing · Cloudflare Email security (formerly Area 1) docs\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/email-configuration/domains-and-routing/\n  md: https://developers.cloudflare.com/email-security/email-configuration/domains-and-routing/index.md\n---\n\n* [Domains](https://developers.cloudflare.com/email-security/email-configuration/domains-and-routing/domains/)\n* [Alert Webhooks](https://developers.cloudflare.com/email-security/email-configuration/domains-and-routing/alert-webhooks/)\n* [Partner Domains TLS](https://developers.cloudflare.com/email-security/email-configuration/domains-and-routing/partner-domains-tls/)\n\n</page>\n\n<page>\n---\ntitle: Email policies · Cloudflare Email security (formerly Area 1) docs\ndescription: \"When you use an inline setup, you can modify incoming, non-blocked\n  messages with a few added layers of protection:\"\nlastUpdated: 2025-08-29T19:00:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/email-configuration/email-policies/\n  md: https://developers.cloudflare.com/email-security/email-configuration/email-policies/index.md\n---\n\nAccess to Area 1\n\nBeginning October 1, 2025, access and support for Email Security (formerly Area 1) will only be available through the Cloudflare dashboard. Your Email Security protection will not change, but you will no longer be able to access the Area 1 dashboard or send support requests to `@area1security.com` email addresses. For help accessing the Cloudflare dashboard, reach out to <successteam@cloudflare.com>.\n\nWhen you use an [inline setup](https://developers.cloudflare.com/email-security/deployment/inline/), you can modify incoming, non-blocked messages with a few added layers of protection:\n\n* [Text add-ons](https://developers.cloudflare.com/email-security/email-configuration/email-policies/text-addons/)\n* [Link actions](https://developers.cloudflare.com/email-security/email-configuration/email-policies/link-actions/)\n\n</page>\n\n<page>\n---\ntitle: Enhanced detections · Cloudflare Email security (formerly Area 1) docs\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/email-configuration/enhanced-detections/\n  md: https://developers.cloudflare.com/email-security/email-configuration/enhanced-detections/index.md\n---\n\n* [Business email compromise (BEC)](https://developers.cloudflare.com/email-security/email-configuration/enhanced-detections/business-email-compromise/)\n* [Added Detections](https://developers.cloudflare.com/email-security/email-configuration/enhanced-detections/added-detections/)\n\n</page>\n\n<page>\n---\ntitle: Allow and block lists · Cloudflare Email security (formerly Area 1) docs\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/email-configuration/lists/\n  md: https://developers.cloudflare.com/email-security/email-configuration/lists/index.md\n---\n\n* [Allowed patterns](https://developers.cloudflare.com/email-security/email-configuration/lists/allowed-patterns/)\n* [Trusted domains](https://developers.cloudflare.com/email-security/email-configuration/lists/trusted-domains/)\n* [Block lists](https://developers.cloudflare.com/email-security/email-configuration/lists/block-list/)\n\n</page>\n\n<page>\n---\ntitle: Phish submissions · Cloudflare Email security (formerly Area 1) docs\ndescription: As part of your continuous email security posture, administrators\n  and security analysts need to submit missed phish samples to Email security\n  (formerly Area 1) Service Addresses so Cloudflare can process them and take\n  necessary action.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/email-configuration/phish-submissions/\n  md: https://developers.cloudflare.com/email-security/email-configuration/phish-submissions/index.md\n---\n\nAccess to Area 1\n\nBeginning October 1, 2025, access and support for Email Security (formerly Area 1) will only be available through the Cloudflare dashboard. Your Email Security protection will not change, but you will no longer be able to access the Area 1 dashboard or send support requests to `@area1security.com` email addresses. For help accessing the Cloudflare dashboard, reach out to <successteam@cloudflare.com>.\n\nAs part of your continuous email security posture, administrators and security analysts need to submit missed phish samples to [Email security (formerly Area 1) Service Addresses](https://horizon.area1security.com/support/service-addresses/) so Cloudflare can process them and take necessary action.\n\nSometimes phish is missed as Email security uses several techniques to make a detection. These include preemptively crawling the web to identify campaigns, machine learning, custom signatures, among others. In order for Email security to identify why phish was missed, we need to run the original samples through our module and identify why some of our modules did not score the sample high enough to elevate it to malicious.\n\nSubmitting missed phish samples to Cloudflare is of paramount importance and necessary for continuous protection. Submitting missed phish samples helps Cloudflare improve our machine learning (ML) models, and alerts us of new attack vectors before they become prevalent.\n\n## How to submit phish\n\nThere are two different ways to submit a phish sample:\n\n* **User submission**: Submitted directly by the end users, and used with phish submission buttons.\\\n  To learn more about user-submitted phish, refer to the following documentation:\n\n  * [KnowBe4](https://developers.cloudflare.com/email-security/email-configuration/phish-submissions/knowbe4/)\n  * [Microsoft Report Message (not compatible)](https://developers.cloudflare.com/email-security/email-configuration/phish-submissions/microsoft-report-message/)\n  * [PhishNet for Google Workspace](https://developers.cloudflare.com/email-security/email-configuration/phish-submissions/phishnet-gworkspace/)\n  * [PhishNet for Office 365](https://developers.cloudflare.com/email-security/email-configuration/phish-submissions/phishnet-o365/)\n\n* **Team submission**: To be used when IT administrators or security teams submit to Email security. Submit original phish samples as an attachment in EML format to the appropriate [Team Submissions address](https://horizon.area1security.com/support/service-addresses/). For example, if you think an email should be marked as spoof, send it to the `SPOOF` address listed in Team Submissions.\\\n  Phish samples submitted to this address will be considered as submissions from the customer's email security team. This increases the chances of similar samples being detected as malicious in the future.\n\nAfter submitting a phish sample to the team address, you will receive an update from `status@submission.area1reports.com` regarding the investigation and the verdict. The feedback is directly provided to customers by our threat research team, bypassing the support channel, to expedite the process.\n\n## What happens after a phish submission\n\nAfter you or your users submit a phish sample, Email security adds that sample directly into our machine learning (ML) queue for learning. Some samples will be directly converted to `MALICIOUS` upon going through machine learning and the rest will be further processed by our ML module.\n\n### Phish submission feedback\n\nUse the following keywords to search for submitted phish samples on the Email security dashboard:\n\n* `phish_submission`\n* `user_malicious_submission`\n* `team_malicious_submission`\n\nOn the **Reasons** column you will see the feedback regarding the messages found. If the ML module learns and detects it as phish, the **Reasons** column shows the details regarding it. If not, the information on this column shows up as `phish submission`.\n\nIf there is a phishing email that is repeatedly sent to users despite being submitted to Email security for processing, [contact support](https://developers.cloudflare.com/support/contacting-cloudflare-support/) with the details of the problematic phish submission sample (alert ID or message ID of the sample).\n\n### Phish Submission Response (beta)\n\nPhish Submission Response (PSR) is an additional layer of protection. When you enable PSR, Email security will automatically retract messages reported by users which are also deemed malicious by Email security after analysis. This feature uses machine learning margin scores by adding the user as an additional neuron into Email security's neural network.\n\nTo enable PSR:\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/).\n2. Go to **Settings** (the gear icon).\n3. In **Email Configuration**, go to **Retract Settings** > **Auto-Retract**.\n4. Enable **Phish Submission Response (Beta)**.\n\nNote\n\nPSR works only for the phish samples submitted to [user submission addresses](https://horizon.area1security.com/support/service-addresses/). Refer to [Retract settings](https://developers.cloudflare.com/email-security/email-configuration/retract-settings/) to learn more about manual and automatic retraction.\n\n## False positives\n\nIf you find emails in your Email security account that are actually false positives, you can report them from the Email security dashboard:\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/).\n2. Select the **Search** bar.\n3. Search for one or more messages that you want to report as a false positive, and select **Report as false positive**.\n4. In the next screen, choose a disposition from the list to clarify the nature of the false positive. The options are *Bulk*, *Malicious*, *None*, *Spam*, *Spoof* and *Suspicious*.\n5. Select **Report False Positive**.\n\n## False negatives\n\n[Email security administrators](https://developers.cloudflare.com/email-security/account-setup/permissions/) can also submit false negatives directly from the dashboard:\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/).\n2. Select the **Search** bar.\n3. Search for one or more messages that you want to report as a false negative, and select **Report as False Negative**. ![The link to submit false negatives, in the search results](https://developers.cloudflare.com/_astro/false-negative.BSkZB1Ro_ZYGCWL.webp)\n4. In the next screen, choose a disposition from the list to clarify the nature of the false negative. The options are *Bulk*, *Malicious*, *Spam*, *Suspicious* and *Spoof*.\n5. Select **Report False Negative**.\n\n</page>\n\n<page>\n---\ntitle: Retract settings · Cloudflare Email security (formerly Area 1) docs\ndescription: When you are using an API setup for Email security, you cannot\n  prevent mail from reaching a recipient's mailbox.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/email-configuration/retract-settings/\n  md: https://developers.cloudflare.com/email-security/email-configuration/retract-settings/index.md\n---\n\nWhen you are using an [API setup](https://developers.cloudflare.com/email-security/deployment/api/) for Email security, you cannot prevent mail from reaching a recipient's mailbox.\n\nHowever — so long as you also have [journaling](https://developers.cloudflare.com/email-security/deployment/api/setup/#journaling-setup), [BCC](https://developers.cloudflare.com/email-security/deployment/api/setup/#bcc-setup) or [MS Graph](https://developers.cloudflare.com/email-security/deployment/api/setup/office365-graph-api/) configured — you can set up message retraction to take post-delivery actions against suspicious messages. These retractions happen through API integrations with Microsoft 365 and Google Workspaces (Gmail).\n\n## Retraction options\n\nOnce you set up retraction, you can retract messages manually or set up automatic retractions to move messages matching certain dispositions to specific folders within a user’s mailbox. You can also enable Post Delivery Response and Phish Submission Response to re-evaluate messages previously delivered against new information gathered by Email security. Scanned emails that were previously delivered and now match this new phishing information will be retracted.\n\nRefer to [Gmail](https://developers.cloudflare.com/email-security/deployment/api/setup/gsuite-bcc-setup/add-retraction/) and [Office 365](https://developers.cloudflare.com/email-security/email-configuration/retract-settings/office365-retraction/) guides for detailed information regarding these options.\n\n## Retraction metrics\n\nSetting up retraction also gives you access to metrics for this feature. After logging in to your [Email security dashboard](https://horizon.area1security.com), search for the **Retractions** card. Metrics for retractions include information such as:\n\n* **Total retractions**: Displays the total amount of retractions performed.\n\n* **Success**: Shows the percentage of messages Email security was able to find and retract successfully.\n\n* **Fail**: Displays the percentage of messages Email security was not successfully able to retract. Reasons for failure include:\n\n  * The user has already deleted or marked the message as junk, either manually or via a mailbox filter.\n  * The specific copy of the message being retracted was sent to a distribution list address that may not exist as a mailbox, and so the retraction will fail. Separate copies of the message that are sent to each member of that distribution list will be retracted.\n  * The retraction is not, or is no longer, authorized.\n\n* **Unread/Read**: Refers to the state of the message at the time it was retracted. For automated retractions, Email security tries to perform retraction as quickly as possible so the user has no time to see or open the message. Manual retraction might happen at a later time, and so the messages are more likely to have already been read.\n\n* **Auto/Manual**: Refers to the percentage of messages retracted through the automatic/manual modes.\n\nSelecting **View details** will perform a search for retracted emails for the selected time interval.\n\n</page>\n\n<page>\n---\ntitle: Cloudflare SSO · Cloudflare Email security (formerly Area 1) docs\ndescription: You can use your Cloudflare account as the single sign-on (SSO)\n  authentication scheme to log in to the Email security dashboard.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/reference/cloudflare-sso/\n  md: https://developers.cloudflare.com/email-security/reference/cloudflare-sso/index.md\n---\n\nArea 1 has been renamed\n\nArea 1 is now **Email Security (formerly Area 1)**.\n\nAccess to Area 1\n\nBeginning October 1, 2025, access and support for Email Security (formerly Area 1) will only be available through the Cloudflare dashboard. Your Email Security protection will not change, but you will no longer be able to access the Area 1 dashboard or send support requests to `@area1security.com` email addresses. For help accessing the Cloudflare dashboard, reach out to <successteam@cloudflare.com>.\n\nYou can use your Cloudflare account as the single sign-on (SSO) authentication scheme to log in to the Email security dashboard:\n\n1. Log in to the [Email security (formerly Area 1) dashboard](https://horizon.area1security.com/).\n2. Select **Sign in with Cloudflare**. You will be redirected to your Cloudflare account to log in.\n3. Select **Allow** to allow Email security to make changes to your Cloudflare account. You will be redirected to the Email security dashboard.\n4. Enter your Email security's email address to log in.\n\nYou can now use your Cloudflare account as a single sign-on authentication scheme to log in to Email security. The next time you access the Email security dashboard, just select **Sign in with Cloudflare** to log in.\n\n</page>\n\n<page>\n---\ntitle: Dispositions and attributes · Cloudflare Email security (formerly Area 1) docs\ndescription: Email security uses a variety of factors to determine whether a\n  given email message, domain, URL, or packet is part of a phishing campaign.\n  These small pattern assessments are dynamic in nature and — in many cases — no\n  single pattern will determine the final verdict.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/reference/dispositions-and-attributes/\n  md: https://developers.cloudflare.com/email-security/reference/dispositions-and-attributes/index.md\n---\n\nArea 1 has been renamed\n\nArea 1 is now **Email Security (formerly Area 1)**.\n\nAccess to Area 1\n\nBeginning October 1, 2025, access and support for Email Security (formerly Area 1) will only be available through the Cloudflare dashboard. Your Email Security protection will not change, but you will no longer be able to access the Area 1 dashboard or send support requests to `@area1security.com` email addresses. For help accessing the Cloudflare dashboard, reach out to <successteam@cloudflare.com>.\n\nEmail security uses a variety of factors to determine whether a given email message, domain, URL, or packet is part of a phishing campaign. These small pattern assessments are dynamic in nature and — in many cases — no single pattern will determine the final verdict.\n\nBased on these patterns, Email security may add `X-Headers` to each email message that passes through our system.\n\n## Dispositions\n\nAny traffic that flows through Email security is given a final disposition, which represents our evaluation of that specific message. Each message will only receive one disposition header so your organization can take clear and specific actions on different message types.\n\nYou can use disposition values when [creating your quarantine policy](https://developers.cloudflare.com/email-security/email-configuration/domains-and-routing/domains/) or [setting up auto-retract](https://developers.cloudflare.com/email-security/email-configuration/retract-settings/).\n\n### Available values\n\n| Disposition | Description | Recommendation |\n| - | - | - |\n| `MALICIOUS` | Traffic invoked multiple phishing verdict triggers, met thresholds for bad behavior, and is associated with active campaigns. | Block |\n| `SUSPICIOUS` | Traffic associated with phishing campaigns (and is under further analysis by our automated systems). | Research these messages internally to evaluate legitimacy. |\n| `SPOOF` | Traffic associated with phishing campaigns that is either non-compliant with your email authentication policies (SPF, DKIM, DMARC) or has mismatching `Envelope From` and `Header From` values. | Block after investigating (can be triggered by third-party mail services). |\n| `UCE` (Unsolicited Commercial Emails) | Traffic associated with non-malicious, commercial campaigns. | Route to existing Spam quarantine folder. |\n| `BULK` (dashboard only) | Traffic often associated with newsletters or marketing campaigns. Refer to [Graymail](https://en.wikipedia.org/wiki/Graymail_%28email%29) for more details. | Monitor or tag |\n\n### Header structure\n\nWhen Email security adds a disposition header to an email message, that header matches the following format:",
      "language": "unknown"
    },
    {
      "code": "Note that emails with a disposition of `SPAM` will be tagged with `UCE` (unsolicited commercial emails) in their headers:",
      "language": "unknown"
    },
    {
      "code": "## Attributes\n\nTraffic that flows through Email security can also receive one or more **Attributes**, which indicate that a specific condition has been met.\n\n### Available values\n\n| Attribute | Notes |\n| - | - |\n| `CUSTOM_BLOCK_LIST` | This message matches a value you have defined in your custom block list. |\n| `NEW_DOMAIN_SENDER=<REGISTRATION_DATE>` | Alerts to mail from a newly registered domain. Formatted as yyyy-MM-dd HH:mm:ss ZZZ. |\n| `NEW_DOMAIN_LINK=<REGISTRATION_DATE>` | Alerts to mail with links pointing out to a newly registered domain. Formatted as yyyy-MM-dd HH:mm:ss ZZZ. |\n| `ENCRYPTED` | Email message is encrypted. |\n| `EXECUTABLE` | Email message contains an executable file. |\n| `BEC` | Indicates that email address was contained in your [business email compromise (BEC)](https://developers.cloudflare.com/email-security/email-configuration/enhanced-detections/business-email-compromise/) list. Associated with `MALICIOUS` or `SPOOF` dispositions. |\n\n### Header structure\n\nWhen Email security adds a disposition header to an email message, that header matches the following format.",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: How we detect phish · Cloudflare Email security (formerly Area 1) docs\ndescription: Email Security (formerly Area 1) uses a variety of factors to\n  determine whether a given email message, a web domain or URL, or specific\n  network traffic is part of a phishing campaign (marked with a Malicious\n  disposition) or other common campaigns (for example, Spam).\nlastUpdated: 2025-08-29T19:00:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/reference/how-we-detect-phish/\n  md: https://developers.cloudflare.com/email-security/reference/how-we-detect-phish/index.md\n---\n\nArea 1 has been renamed\n\nArea 1 is now **Email Security (formerly Area 1)**.\n\nAccess to Area 1\n\nBeginning October 1, 2025, access and support for Email Security (formerly Area 1) will only be available through the Cloudflare dashboard. Your Email Security protection will not change, but you will no longer be able to access the Area 1 dashboard or send support requests to `@area1security.com` email addresses. For help accessing the Cloudflare dashboard, reach out to <successteam@cloudflare.com>.\n\nEmail Security (formerly Area 1) uses a variety of factors to determine whether a given email message, a web domain or URL, or specific network traffic is part of a phishing campaign (marked with a `Malicious` [disposition](https://developers.cloudflare.com/email-security/reference/dispositions-and-attributes/)) or other common campaigns (for example, `Spam`).\n\nThese small pattern assessments are dynamic in nature and — in many cases — no single one in and of itself will determine the final verdict. Instead, our automated systems use a combination of factors and non-factors to clearly distinguish between a valid phishing campaign and benign traffic.\n\n## ActiveSensors\n\nActiveSensors is a proprietary sensor network that discovers emergent campaign infrastructure, and aggregates attack data from relay points that actors use to launch their threat campaign. Cloudflare's [Network](https://developers.cloudflare.com/directory/?product-group=Network+security) and [Application Security](https://developers.cloudflare.com/directory/?product-group=Application+security) provide early detection on phishing attacks, malware, URLs, domains, IPs, and ASNs from across the Internet.\n\nActiveSensors does the following:\n\n* Infrastructure monitoring, clustering and correlation.\n* User and target impersonation-based crawls.\n* Machine learning based link analysis and content detection.\n* Payload analysis, in-the-wild sandboxing, content denotation, and reconstruction.\n\n## SPARSE (Small Pattern Analytics Engine)\n\nSPARSE is a proprietary analytics engine which determines targeted attacks. SPARSE uses the ActiveSensors network, our 8+ petabyte data warehouse, and AI and ML models to make effective detections with a limited data set.\n\n## IP reputation\n\nIP reputation is just one of many factors to consider but is not consistently accurate due to the dynamic nature of phishing campaigns.\n\nFor example, a particular sender IP in a Comcast range might have a mix of good and bad reputation. Flagging it purely on IP would subject a larger chunk of Comcast's IP address range to detections which could lead to false positives.\n\n## Sample attack types and detections\n\n| Attack type | Example | Detections applied |\n| - | - | - |\n| Malicious payload attached to the message | Classic campaign technique which utilizes a variety of active attachment types (EXE, DOC, XLS, PPT, OLE, PDF, and more) as the malicious payload for ransomware attacks, Trojans, viruses, and malware. | Machine learning (ML) models on binary bitmaps of the payload as well as higher-level attributes of the payload, with specific focus on signatureless detections for maximum coverage. Additionally, for relevant active payloads, the engine invokes a real-time sandbox to assess behavior and determine maliciousness. |\n| Encrypted malicious payload attached to the message, with password in message body as text | Campaigns that induce the user to apply a password within the message body to the attachment. | Real-time lexical parsing of message body for password extraction and ML models on binary bitmaps of the payload, signatureless detections for maximum coverage. |\n| Encrypted malicious payload attached to the message, with password in message body as an image | Campaigns that induce the user to apply a password within the message body to the attachment, with the entire body or part of the body being an image. | Real-time OCR parsing of message body for password extraction and ML models on binary bitmaps of the payload, signatureless detections for maximum coverage. |\n| Malicious payload within an archive attached to the message | Campaigns with payloads within typical archives, such as `.zip` files. | ML detection tree on the payload, as well as decomposition of each individual archive into component parts and fragments for compound documents. |\n| Malicious URLs within message body | Typical phish campaigns with a socially engineered call to action URL that will implant malware (for example, Watering Hole attacks, Malvertizing, or scripting attacks). | Continuous web crawling, followed by real-time link crawling for a select group of suspicious urls, followed by machine learning applied to URL patterns in combination with other pattern rules and topic-based machine learning models for exhaustive coverage of link-based attacks. |\n| Malicious payload linked through a URL in a message | Campaigns where the URL links through to a remote malicious attachment (for example, in a `.doc` or `.pdf` file) | Remote document and/or attachment extraction followed by ML detection tree on the payload, instant crawl of links. |\n| Blind URL campaigns | Entirely new domain with intentional obfuscation, seen for the first time in a campaign. | Link structure analysis, link length analysis, domain age analysis, neural net models on entire URL as well as domain and IP reputation of URL host, including autonomous system name reputation and geolocation based reputation. |\n| Malicious URLs within a benign attachment in the message | Campaigns obfuscating the payload within attachments. | URL extraction within attachments, followed by above mentioned URL detection mechanisms. |\n| Malicious URLs within an archive attached to the message | Campaigns obfuscating the payload within attachments. | Attachments decomposed recursively (both in archive formats and compound document formats) to extract URLs, followed by above mentioned URL detection mechanisms. |\n| Malicious URLs behind URL shortening services | Campaigns leveraging Bitly, Owly, and similar services at multiple levels of redirection to hide the target URL. | URL shorteners crawled in real time at the moment of message delivery to get to the eventual target URL, followed by URL detection methods. Real-time shorterners are intentionally not crawled ahead of time due to the dynamic nature of these services and the variation of target URLs based on time and source. |\n| Malicious URLs associated with QR codes (QR Code Phishing Attacks, Quishing) | Campaigns leveraging QR code image attachment to deliver malicious payload links for malware distribution and/or credential harvesting. | Resolving for images resembling QR codes into URL, followed by above mentioned URL detection mechanisms. |\n| Instant crawl of URLs within message body | Typical phish campaigns with a socially engineered call to action URL that will implant a malware (for example, Watering Hole attacks, Malvertizing, or scripting attacks). | Heuristics applied to URLs in message bodies that are not already detected from ahead of time crawling and those deemed suspicious according to strict criteria are crawled in real time. |\n| Credential Harvesters | Form-based credential submission attacks, leveraging known brands (Office 365, PayPal, Dropbox, Google, and more). | Continuous web crawling, computer vision on top brand lures, ML models, and infrastructure association. |\n| Domain Spoof Attacks | Campaigns spoofing sender domains to refer to the recipient domain or some known partner domain. | Header mismatches, email authentication assessments, sender reputation analysis, homographic analysis, and punycode manipulation assessments. |\n| Domain proximity attacks | Campaigns taking advantage of domain similarity to confuse the end user (for example, `sampledoma1n.com` or `sampledomaln.com` compared to `sampledomain.com`). | Header mismatches, email authentication assessments, and sender reputation analysis. |\n| Email Auth violations | Campaigns taking advantage of incorrect or invalid sender Auth records (SPF/DKIM/DMARC) and bypassing incoming Auth-based controls. | Assessment of sender authentication records against published SPF/DKIM/DMARC records which is applied in combination with overall message attributes. |\n| Name Spoof Attacks / Executive Attacks [(BEC)](https://developers.cloudflare.com/email-security/email-configuration/enhanced-detections/business-email-compromise/) | Campaigns targeting executives and high-value targets within the organization or using the high-value targets as sources to attack other employees within the organization. | Display names compared with known executive names for similarity using several matching models including the Levenshtein Algorithm, and if matched, flagged when sender is originating from an unknown domain. |\n| Fileless / Linkless campaigns [(BEC)](https://developers.cloudflare.com/email-security/email-configuration/enhanced-detections/business-email-compromise/) | Typically BEC campaigns with an offline call to action (call me, wire money, invoice, or others). | Message lexical analysis, subject analysis, word count assessments, and sender analysis. |\n| Deferred campaign attacks | Campaigns that have no malicious payload and the URL is clean when delivered, but is activated in a deferred manner (3-4 hours later), so the end user is compromised at click time. | URL rewrites and/or DNS blocks. |\n| IP-based Spam | Volume-based, large scale spam campaigns primarily originating from compromised IP address spaces or botnets. | Sender and IP reputation, history, and volume analysis. |\n| Content-based Spam | Commodity spam largely focused on selling wares. | Sender reputation, history, volume analysis, and message content analysis for commercial intent. |\n| Web Phishing | Directly originated or targeted through web (for example, LinkedIn, Malvertizing, and more). | Web and DNS service and Network device integrations, like web proxies and Firewalls. |\n| Mobile Phishing | Remote employee getting phished while outside the corporate network. | Employee email protection and web and DNS services enforcement in remote users (typically through an MDM integration or an Always-On VPN solution). |\n| Network Phishing | C2 communications for lateral spread within the network or malicious phish downloaded from an external host. Typically seen when an end user gets infected outside the organization, comes back into the network and the C2 hosts uses the infected endpoint to download the implant based on the IP address space it is now resident in. | Network device integrations (Firewalls) and API-based integrations within existing orchestration services. |\n\n</page>\n\n<page>\n---\ntitle: Language support · Cloudflare Email security (formerly Area 1) docs\ndescription: The scanning service and verdict engines used by Email security are\n  language agnostic. We provide support for Double Byte Character sets (DBCS)\n  and UTF-8, UTF-16, and UTF-32 encoding.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/reference/language-support/\n  md: https://developers.cloudflare.com/email-security/reference/language-support/index.md\n---\n\nArea 1 has been renamed\n\nArea 1 is now **Email Security (formerly Area 1)**.\n\n## Email evaluation\n\nThe scanning service and verdict engines used by Email security are language agnostic. We provide support for Double Byte Character sets (DBCS) and UTF-8, UTF-16, and UTF-32 encoding.\n\n## Dashboard\n\nThe Email security email dashboard is localized to several languages. To update your language settings:\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/).\n\n2. At the bottom of the page, select the language icon.\n\n   ![Select the language icon to toggle your dashboard between English and Japanese.](https://developers.cloudflare.com/_astro/language-switcher.CuJw8iIB_6E2V.webp)\n\n3. Select your preferred language.\n\n</page>\n\n<page>\n---\ntitle: Microsoft 365 Government Community Cloud · Cloudflare Email security\n  (formerly Area 1) docs\ndescription: Microsoft 365 Government Community Cloud (GCC) is designed to meet\n  the requirements of the US government. GCC Low and GCC High are two tiers of\n  GCC, each with different security and compliance requirements.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/reference/office365-gcc/\n  md: https://developers.cloudflare.com/email-security/reference/office365-gcc/index.md\n---\n\nArea 1 has been renamed\n\nArea 1 is now **Email Security (formerly Area 1)**.\n\nMicrosoft 365 Government Community Cloud (GCC) is designed to meet the requirements of the US government. GCC Low and GCC High are two tiers of GCC, each with different security and compliance requirements.\n\nGCC Low is intended for use by US government organizations that handle sensitive but unclassified data, and have less stringent compliance requirements.\n\nEmail security supports GCC Low environments.\n\n</page>\n\n<page>\n---\ntitle: Timestamps · Cloudflare Email security (formerly Area 1) docs\ndescription: Timestamps in the dashboard of Email security (formerly Area 1) are\n  localized to your timezone. Email security reads this information from the\n  clock of your computer when you log in.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/reference/timestamps/\n  md: https://developers.cloudflare.com/email-security/reference/timestamps/index.md\n---\n\nArea 1 has been renamed\n\nArea 1 is now **Email Security (formerly Area 1)**.\n\n\n\nTimestamps in the dashboard of Email security (formerly Area 1) are localized to your timezone. Email security reads this information from the clock of your computer when you log in.\n\nThe example below shows timestamps for [Audit logs](https://developers.cloudflare.com/email-security/reporting/audit-logs/). However, note that the same applies to all sections in the Email security dashboard that show timestamps.\n\n![How timestamps are localized to the user's current time zone.](https://developers.cloudflare.com/_astro/timestamps.Rc87K5bG_2wfXKQ.webp)\n\n</page>\n\n<page>\n---\ntitle: Audit Logs · Cloudflare Email security (formerly Area 1) docs\ndescription: Use Email security (formerly Area 1) logs to review actions\n  performed on your account.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/reporting/audit-logs/\n  md: https://developers.cloudflare.com/email-security/reporting/audit-logs/index.md\n---\n\nYou can use Email security logs to review actions performed on your account:\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/).\n2. Go to **Settings** (the gear icon).\n3. Go to **Users and Actions** > **Audit Log**.\n4. Review the logs. You can also filter by type of log from the dropdown menu.\n\n## Logs preview\n\nYou can use one of the Preview logs to preview how Email security handles post delivery retractions. With Audit logs Preview, Email security shows you the emails that would have been retracted with Post Delivery Response (PDR) or Phish Submissions Response (PSR) enabled.\n\nRefer to **Post delivery retractions for new threats** for [Gmail](https://developers.cloudflare.com/email-security/deployment/api/setup/gsuite-bcc-setup/add-retraction/#post-delivery-retractions-for-new-threats) or [Office 365](https://developers.cloudflare.com/email-security/email-configuration/retract-settings/office365-retraction/#post-delivery-retractions-for-new-threats) to learn more about this feature.\n\nTo review preview logs:\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/).\n2. Go to **Settings** (the gear icon).\n3. Go to **Users and Actions** > **Audit Log**.\n4. From the dropdown, select one of the **Preview** logs. This will show you what would have been retracted with Post Delivery Response or Phish Submission Response enabled.\n\nNote\n\nTimestamps in the dashboard of Email security (formerly Area 1) are localized to your timezone. Email security reads this information from the clock of your computer when you log in.\n\n</page>\n\n<page>\n---\ntitle: Phish reports · Cloudflare Email security (formerly Area 1) docs\ndescription: Access Phish reports through the dashboard or an email digest.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/reporting/phish-reports/\n  md: https://developers.cloudflare.com/email-security/reporting/phish-reports/index.md\n---\n\nAccess to Area 1\n\nBeginning October 1, 2025, access and support for Email Security (formerly Area 1) will only be available through the Cloudflare dashboard. Your Email Security protection will not change, but you will no longer be able to access the Area 1 dashboard or send support requests to `@area1security.com` email addresses. For help accessing the Cloudflare dashboard, reach out to <successteam@cloudflare.com>.\n\nEmail security automatically generates phish reports to provide an overview of your email traffic. The report only includes malicious emails. Spam and bulk emails are not included.\n\n## In the dashboard\n\nTo view phishing reports in the Email security dashboard, [log in](https://horizon.area1security.com/) and explore the non-Settings areas of the Email security dashboard (**Home**, **Email**, **Web**, and **Detection Details**).\n\n## Through an email subscription\n\nThe same reports that are visible through the dashboard can also be delivered through an email.\n\nTo subscribe an email address to daily or weekly reports:\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/).\n2. Go to **Settings** (the gear icon).\n3. Go to **Subscriptions** > **Email Subscriptions**.\n4. Select **Add Subscriber**.\n5. Enter an **Email** and choose the desired reports.\n6. Select **Add Subscriber**.\n\n</page>\n\n<page>\n---\ntitle: Search · Cloudflare Email security (formerly Area 1) docs\ndescription: Search for messages with a detection disposition or that have been\n  processeded by Email security (formerly Area 1).\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/reporting/search/\n  md: https://developers.cloudflare.com/email-security/reporting/search/index.md\n---\n\nArea 1 has been renamed\n\nArea 1 is now **Email Security (formerly Area 1)**.\n\nYou can search for emails that have been processed by Email security (formerly Area 1), whether they are marked with a [detection disposition](https://developers.cloudflare.com/email-security/reference/dispositions-and-attributes/) or not.\n\nThere are two ways for searching emails:\n\n* **Fielded Search**: Presents you with fields where you can enter search terms.\n* **Freeform Search**: Has one search field where you can construct your own search query, like `My great products`.\n\nNote\n\nTimestamps in the dashboard of Email security (formerly Area 1) are localized to your timezone. Email security reads this information from the clock of your computer when you log in.\n\n## Search terms\n\nIn Freeform Search, you can search for any value or combination of values separated by a space. Using spaces with multiple search terms is the equivalent of using the operator `AND`.\n\nTerms less than three characters long and common English words that do not offer significance for search value like `and`, `the`, `then`, `their` are ignored.\n\nFor more exact matches, use the named fields in **Fielded Search** to denote which field should contain the value. For example, to find only messages sent by `demo@example.com`, enter `demo@example.com` in **FROM (EXACT)**. `EXACT` in a field descriptor means the term will match how the value appears in the message.\n\n## Fielded Search\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/).\n\n2. Select the **Search** bar.\n\n3. Fill out one or more of the following fields. Filling multiple fields is the equivalent of adding the `AND` operator between the following terms:\n\n   * **Terms**: Searches for terms in any of the available fields. If you want to search for a message that matches multiple recipients, use this field. Only one value can be specified in the **From** and **To** fields.\n   * **From (Exact)**: Searches for the sender’s exact email address.\n   * **To (Exact)**: Searches for the recipient’s exact email address.\n   * **Subject**: Searches for the terms in the subject field.\n   * **Domain**: Searches for messages from a specific domain.\n   * **Message ID**: Searches for messages with the stated message ID.\n   * **Alert ID**: Searches for messages with the stated alert ID.\n\n1) **Detections only** is enabled by default. This means that the system will only search through and display emails that Email Security (formerly Area 1) has marked with a detection [disposition](https://developers.cloudflare.com/email-security/reference/dispositions-and-attributes/). If you prefer to search through and view all emails that have been processed by Email Security, whether they are marked with a detection disposition or not, disable this option.\n\n2) The **All detections** drop-down menu allows you to refine your search by detection disposition. This menu will be disabled if **Detections only** is not selected.\n\n3) By default, the search results are limited to the previous 30 days. Select **Last 30 days** to change this setting.\n\n4) (Optional) You can download the results from your search in CSV format. The CSV file is capped at 1,000 rows.\n\n5) The system returns a list of emails that fit your search criteria, and will inform you if there are emails similar to the ones found. If Email Security finds emails similar to the ones returned by your query, select **Show** to display them. Otherwise, select **View** on the email you are interested in. This will show you more information about that particular email, such as:\n\n   * Disposition (if any)\n   * Email status (for example `Quarantined`)\n   * Sender details (for example, IP address)\n\n## Freeform Search\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/).\n2. Select the **Search bar** > **Freeform Search**.\n3. Build your search query — for example, `My great products`. The system will return all the emails that fit the query.\n\n1) **Detections only** is enabled by default. This means that the system will only search through and display emails that Email Security (formerly Area 1) has marked with a detection [disposition](https://developers.cloudflare.com/email-security/reference/dispositions-and-attributes/). If you prefer to search through and view all emails that have been processed by Email Security, whether they are marked with a detection disposition or not, disable this option.\n\n2) The **All detections** drop-down menu allows you to refine your search by detection disposition. This menu will be disabled if **Detections only** is not selected.\n\n3) By default, the search results are limited to the previous 30 days. Select **Last 30 days** to change this setting.\n\n4) (Optional) You can download the results from your search in CSV format. The CSV file is capped at 1,000 rows.\n\n5) The system returns a list of emails that fit your search criteria, and will inform you if there are emails similar to the ones found. If Email Security finds emails similar to the ones returned by your query, select **Show** to display them. Otherwise, select **View** on the email you are interested in. This will show you more information about that particular email, such as:\n\n   * Disposition (if any)\n   * Email status (for example `Quarantined`)\n   * Sender details (for example, IP address)\n\n## Search tips\n\n### Parameter filtering\n\nTo search for specific values in one of the [available parameters](https://developers.cloudflare.com/email-security/reporting/search/available-parameters/), format your search to be:",
      "language": "unknown"
    },
    {
      "code": "For example, you might search for `final_disposition:MALICIOUS`. Refer to our reference material for a full list of [dispositions](https://developers.cloudflare.com/email-security/reference/dispositions-and-attributes/).\n\n### `message_id`\n\nFor normal queries, spaces split search terms into different values. For example, `billing statement` would look for all messages that contain both `billing` and `statement`.\n\nHowever, spaces, quotations, and other characters are sometimes part of the `message_id` parameter. To ensure these values are included as part of filtering on the message ID, you should prefix the `message_id` value with `message_id`.\n\nFor example, the following query would find all messages that contain the terms `billing` and `statement` and have a `message_id` equal to `<Amazon aws Support@email.amazonses.com>`.",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: SIEM integration · Cloudflare Email security (formerly Area 1) docs\ndescription: SIEM integrations allow you to view message-level information\n  outside of the dashboard and create your own custom reports.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/reporting/siem-integration/\n  md: https://developers.cloudflare.com/email-security/reporting/siem-integration/index.md\n---\n\nArea 1 has been renamed\n\nArea 1 is now **Email Security (formerly Area 1)**.\n\nWith a bit of configuration, you can also bring Email security (formerly Area 1) data into your Security Information and Event Management (SIEM) tools to view message-level information outside of the dashboard and create your own custom reports.\n\n## Connect a SIEM tool\n\nThe following steps are required to connect your SIEM tool.\n\n### 1. Set up your SIEM tool\n\nFor help setting up the proper configuration in your SIEM tool, refer to the following guides:\n\n* [KnowBe4](https://developers.cloudflare.com/email-security/reporting/siem-integration/knowbe4-integration-guide/)\n* [LogScale](https://developers.cloudflare.com/email-security/reporting/siem-integration/logscale-integration-guide/)\n* [Splunk](https://developers.cloudflare.com/email-security/reporting/siem-integration/splunk-integration-guide/)\n* [Sumo Logic](https://developers.cloudflare.com/email-security/reporting/siem-integration/sumo-logic-integration-guide/)\n\n### 2. Create a webhook\n\nRefer to [Alert webhooks](https://developers.cloudflare.com/email-security/email-configuration/domains-and-routing/alert-webhooks/) to learn how to create a webhook and send data into your SIEM tool.\n\n</page>\n\n<page>\n---\ntitle: Statistics overview · Cloudflare Email security (formerly Area 1) docs\ndescription: Statistics overview allows you to have an at-a-glance overview of\n  emails processed and number of threats detected.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/reporting/statistics-overview/\n  md: https://developers.cloudflare.com/email-security/reporting/statistics-overview/index.md\n---\n\nTo access an overview of your account, total number of emails processed, a breakdown of types of threads detected, among other types of information:\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/users/login).\n2. Make sure you are in the Home section to review information regarding your account:\n\n| Field | Description |\n| - | - |\n| **System stats** | * Status of Area 1’s services\n* Uptime of Area 1’s services as well as any downtime\n* Number of processed emails and attacks prevented |\n| **Detection stats** | Statistics regarding the total number of detections made, and emails processed. |\n| **Retractions** | Shows the distribution of messages removed from your user's mailboxes. |\n| **Phish Submissions Stats** | Statistics regarding the number of phish emails submitted by your users and security operations center (SOC) |\n| **Threat Origins** | Top geographical threat origins to your organization. |\n| **Org Spoofs** | Shows attacks where names in envelopes differ from the header, as well as spoofed domains. |\n| **Domain Proximity** | List of domains similar to your own. |\n| **Malicious Threat Type** | Breakdown of malicious threat types. |\n| **Email Link Isolation** | How many email were processed by [Email Link Isolation](https://developers.cloudflare.com/email-security/email-configuration/email-policies/link-actions/#email-link-isolation). |\n| **Top BEC Targets** | What email addresses are the top targets on the [Business Email Compromise feature](https://developers.cloudflare.com/email-security/email-configuration/enhanced-detections/business-email-compromise/). |\n\n</page>\n\n<page>\n---\ntitle: Types of malicious detections · Cloudflare Email security (formerly Area\n  1) docs\ndescription: Types of malicious detections shows you information related to the\n  number and types of malicious detections made on your account.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/email-security/reporting/types-malicious-detections/\n  md: https://developers.cloudflare.com/email-security/reporting/types-malicious-detections/index.md\n---\n\nTo review the number and type of malicious detections made on your account:\n\n1. Log in to the [Email security dashboard](https://horizon.area1security.com/users/login).\n2. Select the **Email** tab.\n3. The **Overview** section will show you graphs with the total number of emails processed, as well as how many of those pertain to different threat categories - such as Malicious or Spam, among others. Refer to [Dispositions and attributes](https://developers.cloudflare.com/email-security/reference/dispositions-and-attributes/) for more information. Select **View Details**.\n4. You will open the **Detections** page. This page breaks down the information regarding the various types of threats detected. You have access to:\n\n| Field | Description |\n| - | - |\n| **Attachments** | * How many of the malicious emails received have an attachment.\n* Of these, what are the top types of malicious files received (for example, PDF files). |\n| **Senders** | - Total number of malicious senders, as well as a graph showing how they are distributed throughout the month.\n- Top malicious domains. |\n| **Targets** | Top email targets on the [BEC feature](https://developers.cloudflare.com/email-security/email-configuration/enhanced-detections/business-email-compromise/). |\n| **New domains** | * Total number of malicious domains registered in the past month.\n* Most common top level malicious domains. |\n| **Links** | - Total number of malicious links and their distribution throughout the month.\n- Top threat types (for example, credential harvester). |\n| **Threat types** | Top malicious threat types, and their percentage relatively to the total amount of threats received. |\n| **Threat origins** | A graph representing where in the world are your top threat origins. |\n\n</page>\n\n<page>\n---\ntitle: Call sequence · Cloudflare Firewall Rules (deprecated) docs\ndescription: The API call examples in this site illustrate the recommended\n  sequence of calling the two APIs (the Cloudflare Filters API and the Firewall\n  Rules API).\nlastUpdated: 2025-08-20T21:45:15.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/firewall/api/call-sequence/\n  md: https://developers.cloudflare.com/firewall/api/call-sequence/index.md\n---\n\nThe API call examples in this site illustrate the **recommended sequence** of calling the two APIs (the [Cloudflare Filters API](https://developers.cloudflare.com/firewall/api/cf-filters/) and the [Firewall Rules API](https://developers.cloudflare.com/firewall/api/cf-firewall-rules/)).\n\nDeprecation notice\n\nCloudflare Firewall Rules has been deprecated. Cloudflare has moved existing firewall rules to [WAF custom rules](https://developers.cloudflare.com/waf/custom-rules/). For more information on this change, refer to the [upgrade guide](https://developers.cloudflare.com/waf/reference/legacy/firewall-rules-upgrade/).\n\nThe image below depicts this sequence, which can be applied for creating and editing rules. The reverse would apply for delete operations.\n\n![Recommended flow for calling the Cloudflare Filters API and Firewall Rules API when creating or editing rules](https://developers.cloudflare.com/_astro/recommended-flow.DBuGef-x_Zq1LlP.webp)\n\nCloudflare recommends this sequence because it facilitates filter reusability and allows working with either API independently. Thanks to the standalone nature of Cloudflare Filters, the same filter can be shared in multiple firewall rules and in other future Cloudflare products and features.\n\nFor example, a filter that matches all traffic for your API (that is, `http.request.uri.path matches \"^/api/.*$\"`) may disable caching, disable human CAPTCHAs, configure JSON custom errors, and appear in a firewall rule. With the recommended sequence above, you would repeat steps 3-6 for every Cloudflare feature to configure against the same filter created in steps 1-2.\n\nHowever, for a `POST` operation, the **simplified sequence** — shown below — allows you to create both a filter and rule in the same call. In this case, the filter and rule only refer to each other.\n\n![Basic flow for invoking the Firewall Rules API to create both a filter and a rule in a single call](https://developers.cloudflare.com/_astro/simple-flow.DifdHPUG_Z1rqtoN.webp)\n\nIn this sequence, a single `POST` request to the `/firewall/rules` endpoint takes the filter object in the JSON to create the filter in the Filters API (also via a `POST` request). If successful, the firewall rule is created.\n\nBelow is an example call and response using this method:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "However, this approach has some disadvantages:\n\n* The firewall rules client has to implement error and exception handling for every potential failure occurring in both the firewall rules and the filters APIs.\n* To protect against accidentally modifying or deleting filters used by other Cloudflare features, the `PUT` or `DELETE` operations are not allowed.\n\nBy default, if either the filter or rule is invalid, neither will be created.\n\nHowever, one exception applies. If you are about to exceed your rule quota, Cloudflare may create the filter but not the firewall rule. This happens because the rule is only created after the filter in the sequence diagram.\n\nAfter you resolve the issue of exceeding your quota or requesting a feature that is unavailable to your zone, return to the recommended flow to create a rule that references the filter.\n\nIn summary, Cloudflare strongly recommends the sequence with the two API calls. Limit your rule and filter creation using the simplified sequence for emergency situations, and only via `curl` requests.\n\n</page>\n\n<page>\n---\ntitle: Cloudflare Filters API · Cloudflare Firewall Rules (deprecated) docs\ndescription: Cloudflare Filters is an API-only component of firewall rules for\n  designing complex criteria that rely on boolean operators and other logic to\n  examine incoming HTTP traffic and look for a match.\nlastUpdated: 2025-08-20T21:45:15.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/firewall/api/cf-filters/\n  md: https://developers.cloudflare.com/firewall/api/cf-filters/index.md\n---\n\n**Cloudflare Filters** is an API-only component of firewall rules for designing complex criteria that rely on boolean operators and other logic to examine incoming HTTP traffic and look for a match.\n\nDeprecation notice\n\nCloudflare Firewall Rules has been deprecated. Cloudflare has moved existing firewall rules to [WAF custom rules](https://developers.cloudflare.com/waf/custom-rules/). For more information on this change, refer to the [upgrade guide](https://developers.cloudflare.com/waf/reference/legacy/firewall-rules-upgrade/).\n\nFor example, a filter matching:\n\n* An HTTP user agent, and\n* The HTTP path, and\n* The source IP address\n\nAssociate a filter with a firewall rule to define the scope of that rule.\n\nUse IP lists within a filter to refer collectively to a group of IP addresses. Refer to the [Lists API](https://developers.cloudflare.com/waf/tools/lists/lists-api/) for more information.\n\nBefore getting started with the Cloudflare Filters API, familiarize yourself with rule [expressions](https://developers.cloudflare.com/ruleset-engine/rules-language/expressions/). For a complete reference, refer to [Rules language](https://developers.cloudflare.com/ruleset-engine/rules-language/).\n\n## Differences from other Cloudflare APIs\n\nThe Firewall Rules API behaves differently from most Cloudflare APIs in two ways:\n\n* API calls accept and return multiple items, and allow applying data changes to multiple items.\n* Although API calls return the [standard response](https://developers.cloudflare.com/fundamentals/api/), the error object follows the [JSON API standard](http://jsonapi.org/format/#errors), such that in an error condition, it is clear which item produced the error and why.\n\nTo get started, review [What is a filter?](https://developers.cloudflare.com/firewall/api/cf-filters/what-is-a-filter/), followed by the Cloudflare Filters [JSON object](https://developers.cloudflare.com/firewall/api/cf-firewall-rules/json-object/) and [Endpoints](https://developers.cloudflare.com/firewall/api/cf-firewall-rules/endpoints/).\n\n</page>\n\n<page>\n---\ntitle: Firewall Rules API · Cloudflare Firewall Rules (deprecated) docs\ndescription: Use the Firewall Rules API to programmatically manage your rules.\nlastUpdated: 2025-08-20T21:45:15.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/firewall/api/cf-firewall-rules/\n  md: https://developers.cloudflare.com/firewall/api/cf-firewall-rules/index.md\n---\n\nUse the Firewall Rules API to programmatically manage your rules.\n\nDeprecation notice\n\nCloudflare Firewall Rules has been deprecated. Cloudflare has moved existing firewall rules to [WAF custom rules](https://developers.cloudflare.com/waf/custom-rules/). For more information on this change, refer to the [upgrade guide](https://developers.cloudflare.com/waf/reference/legacy/firewall-rules-upgrade/).\n\nWhen working with the Firewall Rules API, refer to these topics for additional context:\n\n* [Firewall rules actions](https://developers.cloudflare.com/firewall/cf-firewall-rules/actions/)\n* [Cloudflare Filters API](https://developers.cloudflare.com/firewall/api/cf-filters/)\n\nTo get started with the API, review the Firewall Rules API [JSON object](https://developers.cloudflare.com/firewall/api/cf-firewall-rules/json-object/) and [Endpoints](https://developers.cloudflare.com/firewall/api/cf-firewall-rules/endpoints/).\n\nFor more information on the Rules language used to write rule expressions, refer to [Rules language](https://developers.cloudflare.com/ruleset-engine/rules-language/) in the Ruleset Engine documentation.\n\n## Differences from other Cloudflare APIs\n\nThe Firewall Rules API behaves differently from most Cloudflare APIs in two ways:\n\n* API calls accept and return multiple items, and allow applying data changes to multiple items.\n* Although API calls return the [standard response](https://developers.cloudflare.com/fundamentals/api/), the error object follows the [JSON API standard](http://jsonapi.org/format/#errors), such that in an error condition, it is clear which item produced the error and why.\n\n</page>\n\n<page>\n---\ntitle: Create, edit, and delete rules · Cloudflare Firewall Rules (deprecated) docs\ndescription: \"A firewall rule has two main attributes: an expression and an action.\"\nlastUpdated: 2025-08-20T21:45:15.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/firewall/cf-dashboard/create-edit-delete-rules/\n  md: https://developers.cloudflare.com/firewall/cf-dashboard/create-edit-delete-rules/index.md\n---\n\nA firewall rule has two main attributes: an [expression](https://developers.cloudflare.com/ruleset-engine/rules-language/expressions/) and an [action](https://developers.cloudflare.com/firewall/cf-firewall-rules/actions/).\n\nDeprecation notice\n\nCloudflare Firewall Rules has been deprecated. Cloudflare has moved existing firewall rules to [WAF custom rules](https://developers.cloudflare.com/waf/custom-rules/). For more information on this change, refer to the [upgrade guide](https://developers.cloudflare.com/waf/reference/legacy/firewall-rules-upgrade/).\n\nWhen an incoming HTTP request matches a firewall rule expression, Cloudflare performs the specified action. For more information, refer to [Expressions](https://developers.cloudflare.com/ruleset-engine/rules-language/expressions/) and [Actions](https://developers.cloudflare.com/firewall/cf-firewall-rules/actions/).\n\nNote\n\nThe maximum length of a rule expression is 4,096 characters.\n\n## Create a firewall rule\n\n1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com/), and select your account and website.\n\n2. Go to **Security** > **WAF** > **Firewall rules**.\n\n3. Select **Create a firewall rule**.\n\n4. In the **Create firewall rule** page that displays, use the **Rule name** input to supply a descriptive name.\n\n5. Under **When incoming requests match**, use the **Field** drop-down list to choose an HTTP property (refer to the [Fields reference](https://developers.cloudflare.com/ruleset-engine/rules-language/fields/reference/) for details). For each request, the value of the property you choose for **Field** is compared to the value you specify for **Value**.\n\n   Alternatively, use the [Expression Editor](https://developers.cloudflare.com/ruleset-engine/rules-language/expressions/edit-expressions/#expression-editor) to define the rule expression.\n\n   ![Example firewall rule expression with a selected field, operator, and value](https://developers.cloudflare.com/_astro/firewall-rules-expression-builder-value.Cm4ecLGt_Z1h4xcT.webp)\n\n6. Use the **Operator** drop-down list to choose a comparison operator. For an expression to match, the value of the request **Field** and the value specified in the **Value** input must satisfy the comparison operator.\n\n7. Next, specify the value to match. If the value is an enumeration, then the **Value** control will be a drop-down list. Otherwise, it will be a text input.\n\n8. To add a new sub-expression to the rule expression, select **And** or **Or** next to **Value**.\n\n9. Select an action for your rule in the **Action** drop-down list.\n\n10. To save and deploy your rule, select **Deploy**. If you are not ready to deploy your rule, select **Save as draft**.\n\nAfter you choose an option, you return to the rules list, which displays your new rule.\n\n## Manage rules\n\nUse the available options in the rules list to manage firewall rules.\n\n![The rules list interface in the dashboard where you can manage firewall rules](https://developers.cloudflare.com/_astro/cf-firewall-rules-list.Co9nTUAW_4HIGK.webp)\n\n### Edit rule\n\nSelect **Edit** (wrench icon) located on the right of your rule in the rules list to open the **Edit firewall rule** panel and make the changes you want.\n\n### Enable or disable rule\n\nUse the toggle switch associated with a firewall rule to enable or disable it.\n\n### Delete rule\n\n1. Next to the rule you want to delete, select **Delete** (**X** icon).\n2. In the confirmation dialog, select **Delete** to complete the operation.\n\n### Order rules\n\nBy default, Cloudflare evaluates firewall rules in **list order**, where rules are evaluated in the order they appear in the rules list. When list ordering is enabled, the rules list allows you to drag and drop firewall rules into position, as shown below.\n\n![Animation of a user dragging and dropping a rule in the rules list to reorder it](https://developers.cloudflare.com/images/firewall/firewall-rules-expression-builder-10.gif)\n\nOnce there are more than 200 total rules (including inactive rules), you must manage evaluation using **priority ordering**, in which Cloudflare evaluates firewall rules in order of their **priority number**, starting with the lowest. When you cross this threshold, the firewall rules interface automatically switches to priority ordering. For more on working with priority ordering, refer to [Order and priority](https://developers.cloudflare.com/firewall/cf-firewall-rules/order-priority/).\n\n## Test firewall rules with Rule Preview\n\nRule Preview allows customers on an Enterprise plan to understand the potential impact of a new firewall rule, by testing it against a sample of requests drawn from the last 72 hours of traffic.\n\nRule Preview is built into the **Create firewall rule** and **Edit firewall rule** panels so that you can test a rule as you edit it. For more information, refer to [Preview rules](https://developers.cloudflare.com/firewall/cf-dashboard/rule-preview/).\n\n</page>\n\n<page>\n---\ntitle: Create a mTLS rule · Cloudflare Firewall Rules (deprecated) docs\ndescription: Use the Mutual TLS Rule interface in the Cloudflare dashboard to\n  create an mTLS rule that requires requests to your API or web application to\n  present a valid client certificate.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/firewall/cf-dashboard/create-mtls-rule/\n  md: https://developers.cloudflare.com/firewall/cf-dashboard/create-mtls-rule/index.md\n---\n\nUse the [Mutual TLS](https://developers.cloudflare.com/api-shield/security/mtls/configure/) Rule interface in the Cloudflare dashboard to create an mTLS rule that requires requests to your API or web application to present a valid client certificate.\n\n</page>\n\n<page>\n---\ntitle: Preview firewall rules · Cloudflare Firewall Rules (deprecated) docs\ndescription: The expression of a firewall rule can become quite complex. In this\n  situation, you should test your firewall rule before deploying it to ensure\n  that the rule will behave as expected.\nlastUpdated: 2025-08-18T14:27:42.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/firewall/cf-dashboard/rule-preview/\n  md: https://developers.cloudflare.com/firewall/cf-dashboard/rule-preview/index.md\n---\n\nThe expression of a firewall rule can become quite complex. In this situation, you should test your firewall rule before deploying it to ensure that the rule will behave as expected.\n\nRule Preview helps you understand the potential impact of a firewall rule, by testing the rule against a sample drawn from the last 72 hours of traffic. Rule Preview is built into the firewall rules Expression Editor so that you can test a rule as you edit it.\n\nWarning\n\nRule Preview is only available to customers on an Enterprise plan.\n\n## Test a firewall rule with Rule Preview\n\n1. Locate the desired rule in the rules list and select **Edit** (wrench icon).\n2. Select **Test rule** to trigger the test.\n\n![The Test Rule button next to the Action drop-down list allows you to check the traffic that would be affected by the current firewall rule](https://developers.cloudflare.com/_astro/firewall-rules-preview-1.D1bW7NGh_qxVt8.webp)\n\nThe results of the test are displayed in a plot that simulates how many of the total requests in the last 72 hours would have matched the tested expression.\n\nIn this screenshot, a rule that matches all User-Agents that contain the string `Mozilla` would block about 8% of requests to the zone:\n\n![Example chart of a rule preview operation, stating that about 8% of the zone requests would be blocked by the current rule](https://developers.cloudflare.com/_astro/cf-firewall-rules-preview-rule-plot-chart.BW_d_L46_Z1AbcPr.webp)\n\n## Important notes\n\n**Consider the results of Firewall Preview an *indication* of traffic levels**, not an exact calculation. The sample rate can be as little as 1% of your total traffic.\n\n**Rule Preview does not take into account other firewall rules** that you have already configured. In effect, Rule Preview tests a single firewall rule in isolation. Security events or any other rules with a higher priority that may have blocked or challenged a request are ignored.\n\n**You cannot test firewall rules that reference [IP lists](https://developers.cloudflare.com/waf/tools/lists/custom-lists/#ip-lists)**.\n\n**Cloudflare does not store the entirety of requests, so only a limited number of fields are available to Rule Preview**. The table below lists the fields that Rule Preview supports (green cells), broken down by operator. Fields and operators that are not supported are not included in this table.\n\n</page>\n\n<page>\n---\ntitle: Firewall rules actions · Cloudflare Firewall Rules (deprecated) docs\ndescription: The action of a firewall rule tells Cloudflare how to handle HTTP\n  requests that have matched the rule expression.\nlastUpdated: 2025-08-20T21:45:15.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/firewall/cf-firewall-rules/actions/\n  md: https://developers.cloudflare.com/firewall/cf-firewall-rules/actions/index.md\n---\n\nThe action of a firewall rule tells Cloudflare how to handle HTTP requests that have matched the rule expression.\n\nDeprecation notice\n\nCloudflare Firewall Rules has been deprecated. Cloudflare has moved existing firewall rules to [WAF custom rules](https://developers.cloudflare.com/waf/custom-rules/). For more information on this change, refer to the [upgrade guide](https://developers.cloudflare.com/waf/reference/legacy/firewall-rules-upgrade/).\n\n## Supported actions\n\nThe table below lists the actions available in firewall rules. These actions are listed in order of precedence. If the same request matches two different rules which have the same priority, precedence determines the action to take.\n\nFor example, the *Allow* action takes precedence over the *Block* action. In a case where a request matches a rule with the *Allow* action and another with the *Block* action, precedence resolves the tie, and Cloudflare allows the request.\n\nThere are two exceptions to this behavior: the *Log* and *Bypass* actions. Unlike other actions, *Log* and *Bypass* do not terminate further evaluation within firewall rules. This means that if a request matches two different rules and one of those rules specifies the *Log* or *Bypass* action, the second action will be triggered instead, even though *Log*/*Bypass* has precedence.\n\nNote\n\nFor reference information on rule actions available for Cloudflare products powered by the Ruleset Engine, refer to [Rules language: Actions](https://developers.cloudflare.com/ruleset-engine/rules-language/actions/).\n\n| Action | Description | Order of precedence |\n| - | - | - |\n| **Log** API value: `log` | * Records matching requests in the Cloudflare Logs.\n\n* Only available for Enterprise plans.\n\n* Recommended for validating rules before committing to a more severe action. | 1 |\n| **Bypass** API value: `bypass` | - Allows user to dynamically disable Cloudflare security features for a request.\n\n- Available to all plans.\n\n- Matching requests exempt from evaluation by a user-defined list containing one or more of the following Cloudflare security features:\n\n  * [User Agent Blocking](https://developers.cloudflare.com/waf/tools/user-agent-blocking/)\n\n  * [Browser Integrity Check](https://developers.cloudflare.com/waf/tools/browser-integrity-check/)\n\n  * [Hotlink Protection](https://developers.cloudflare.com/waf/tools/scrape-shield/hotlink-protection/)\n\n  * [Security Level (IP Reputation)](https://developers.cloudflare.com/waf/tools/security-level/)\n\n  * [Rate Limiting](https://developers.cloudflare.com/waf/reference/legacy/old-rate-limiting/) (previous version, deprecated)\n\n  * [Zone Lockdown](https://developers.cloudflare.com/waf/tools/zone-lockdown/)\n\n  * [WAF managed rules](https://developers.cloudflare.com/waf/reference/legacy/old-waf-managed-rules/) (previous version, deprecated)\n\n  **Notes:**\n\n  * Currently, you cannot bypass Bot Fight Mode. For more information on this product, refer to [Cloudflare bot solutions](https://developers.cloudflare.com/bots/).\n\n  * You cannot bypass the new [WAF managed rules](https://developers.cloudflare.com/waf/managed-rules/) using this action, only the previous version of WAF managed rules. To skip one or more managed rules in the new WAF for specific requests, [create an exception](https://developers.cloudflare.com/waf/managed-rules/waf-exceptions/).\n\n- Requests which match the *Bypass* action are still subject to evaluation (and thus a challenge or block) within Firewall Rules, based on the order of execution. | 2 |\n| **Allow** API value: `allow` | * Matching requests are exempt from *Bypass*, *Block*, and challenge actions triggered by other firewall rules.\n\n* The scope of the *Allow* action is limited to firewall rules; matching requests are **not** exempt from action by other Cloudflare security products such as Bot Fight Mode, IP Access Rules, and WAF Managed Rules.\n\n* Matched requests will be mitigated if they are part of a DDoS attack. | 3 |\n| **Interactive Challenge** API value: `challenge` | - This option is not recommended. Instead, choose **Managed Challenge (Recommended)**, which issues interactive challenges to visitors only when necessary.\n\n- The client that made the request must pass an interactive challenge.\n\n- If successful, Cloudflare accepts the matched request; otherwise, it is blocked.\n\n- For additional information, refer to [Notes about challenge actions](#notes-about-challenge-actions). | 4 |\n| **Managed Challenge (Recommended)** API value: `managed_challenge` | * Helps reduce the lifetimes of human time spent solving interactive challenges across the Internet.\n\n* Depending on the characteristics of a request, Cloudflare will dynamically choose the appropriate type of challenge from the following actions based on specific criteria:\n\n  * Show a non-interactive challenge page (similar to the current JS Challenge).\n\n  * Show an interactive challenge (such as requiring the visitor to click a button or to perform a task).\n\n* For additional information, refer to [Notes about challenge actions](#notes-about-challenge-actions). | 5 |\n| **JS Challenge** API value: `js_challenge` | - Useful for ensuring that bots and spam cannot access the requested resource; browsers, however, are free to satisfy the challenge automatically.\n\n- The client that made the request must pass a Cloudflare JavaScript Challenge before proceeding.\n\n- If successful, Cloudflare accepts the matched request; otherwise, it is blocked.\n\n- For additional information, refer to [Notes about challenge actions](#notes-about-challenge-actions). | 6 |\n| **Block** API value: `block` | Matching requests are denied access to the site. | 7 |\n\n## Notes about challenge actions\n\nWhen you configure a firewall rule with one of the challenge actions — *Managed Challenge*, *JS Challenge*, or *Interactive Challenge* — and a request matches the rule, one of two things can happen:\n\n* The request is blocked if the visitor fails the challenge\n* The request is allowed if the visitor passes the challenge\n\nIn this last case, no further firewall rules will be processed. This means that the action of any later rules with a challenge or *Block* action also matching the request will not be applied, and the request will be allowed.\n\n</page>\n\n<page>\n---\ntitle: Order and priority · Cloudflare Firewall Rules (deprecated) docs\ndescription: Cloudflare Firewall Rules, now deprecated, is part of a larger\n  evaluation chain for HTTP requests, as illustrated in the diagram below. For\n  example, Firewall Rules only evaluates requests that first clear IP Access\n  rules. If a request is blocked by a rule at any stage in the chain, Cloudflare\n  does not evaluate the request further.\nlastUpdated: 2024-12-16T22:33:26.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/firewall/cf-firewall-rules/order-priority/\n  md: https://developers.cloudflare.com/firewall/cf-firewall-rules/order-priority/index.md\n---\n\nCloudflare Firewall Rules, now deprecated, is part of a larger evaluation chain for HTTP requests, as illustrated in the diagram below. For example, Firewall Rules only evaluates requests that first clear IP Access rules. If a request is blocked by a rule at any stage in the chain, Cloudflare does not evaluate the request further.\n\n![Flow chart of request evaluation at Cloudflare for security products that are not powered by the Ruleset Engine](https://developers.cloudflare.com/_astro/firewall-rules-order-and-priority-1.DvL3658y_Z1iKFmj.webp)\n\nWarning\n\n* You can use [IP Access rules](https://developers.cloudflare.com/waf/tools/ip-access-rules/) to allowlist requests under certain conditions, effectively excluding these requests from all security checks. However, allowing a given country code will not bypass [WAF Managed Rules](https://developers.cloudflare.com/waf/managed-rules/) or [WAF managed rules (previous version)](https://developers.cloudflare.com/waf/reference/legacy/old-waf-managed-rules/).\n\n* The execution order diagram does not include products powered by the [Ruleset Engine](https://developers.cloudflare.com/ruleset-engine/) like the [WAF](https://developers.cloudflare.com/waf/) or [Transform Rules](https://developers.cloudflare.com/rules/transform/).\n\nBy default, Cloudflare evaluates firewall rules in **list order**, where rules are evaluated in the order they appear in the firewall rules list. List ordering is convenient when working with small numbers of rules because you can manage their order by dragging and dropping them into position. However, as the number of rules grows, managing rules in list order becomes difficult. This is where priority order comes into play.\n\nWhen **priority ordering** is enabled, Cloudflare evaluates firewall rules in order of their **priority number**, starting with the lowest. If a request matches two rules with the same priority, action precedence is used to resolve the tie. In this case, only the action of the rule with the highest precedence is executed, unless that action is *Log* or *Bypass* (refer to [Firewall rules actions](https://developers.cloudflare.com/firewall/cf-firewall-rules/actions/#supported-actions) for details). Priority ordering makes it a lot easier to manage large numbers of firewall rules, and once the number of rules passes 200, Cloudflare requires it.\n\n## Managing rule evaluation by list order\n\nUsers with relatively small numbers of firewall rules (no more than 200) will find that list ordering is enabled by default. When list ordering is enabled, the rules list allows you to drag and drop firewall rules into position, as shown below:\n\n![Animation of a firewall rule being moved into a new position in the rules list to reorder it](https://developers.cloudflare.com/_astro/firewall-rules-order-and-priority-2.od1TBIqG_204OIe.webp)\n\nOnce there are more than 200 total rules, including inactive rules, you must manage evaluation using priority ordering. When you cross this threshold, the firewall rules interface automatically switches to priority ordering.\n\n## Managing rule evaluation by priority order\n\nAlthough priority ordering is enabled automatically when the number of active and inactive firewall rules exceeds 200, you can manually enable priority ordering at any time from the rules list.\n\nCloudflare Firewall Rules does not impose default priorities, and you are not required to set a priority for every rule.\n\n### Enable priority ordering\n\nTo manually enable priority ordering:\n\n1. Above the rules list, select **Ordering**.\n2. Select *Priority Numbers*.\n\nOnce priority ordering is enabled, you can set a priority number for each firewall rule.\n\n### Set rule priority\n\nTo set the priority number for a firewall rule:\n\n1. Locate the desired rule in the rules list and select **Edit** (wrench icon).\n\n2. In the **Edit firewall rule** panel, enter a positive integer value in **Priority**.\n\n   ![Editing a firewall rule in the dashboard to define its Priority value](https://developers.cloudflare.com/_astro/firewall-rules-order-and-priority-4.BOS_CRyn_1yTbI5.webp)\n\n3. Select **Save**.\n\nThe **Priority** column in the rules list displays the priority value for each rule.\n\n![When using priority order, the Firewall rules tab displays the priority of each rule (if any) in the first column of the rules list](https://developers.cloudflare.com/_astro/firewall-rules-order-and-priority-5.DaI_uWtJ_Z1ijrDp.webp)\n\n## Working with priority ordering\n\nCloudflare has designed priority ordering to be extremely flexible. This flexibility is particularly useful for managing large rulesets programmatically via the Cloudflare API. Use the Update firewall rules command to set the `priority` property. Refer to [Cloudflare API: Firewall rules](https://developers.cloudflare.com/api/resources/firewall/subresources/rules/methods/list/) for details.\n\nWhile your priority numbering scheme can be arbitrary, keep the following in mind:\n\n* **The evaluation sequence starts from the lowest priority number** and goes to the highest.\n\n* **Rules without a priority number are evaluated last**, in order of their action precedence. For example, a rule with the *Log* action is evaluated before a rule that has the *Block* action. For more on action precedence, refer to [Firewall rules actions](https://developers.cloudflare.com/firewall/cf-firewall-rules/actions/).\n\n* **Avoid using the number `1` as a priority** to make rule order modification easier in the future.\n\n* **Consider grouping ranges of priority numbers into categories** that have some meaning for your deployment. Here are some examples:\n\n  * 5000-9999: Trusted IP addresses\n  * 10000-19999: Blocking rules for bad crawlers\n  * 20000-29999: Blocking rules for abusive users/spam\n\n</page>\n\n<page>\n---\ntitle: Required firewall rule changes to enable URL normalization · Cloudflare\n  Firewall Rules (deprecated) docs\ndescription: On 2021-04-08, Cloudflare announced URL normalization, a feature\n  that protects zones by normalizing HTTP request URI paths.\nlastUpdated: 2025-08-20T21:45:15.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/firewall/troubleshooting/required-changes-to-enable-url-normalization/\n  md: https://developers.cloudflare.com/firewall/troubleshooting/required-changes-to-enable-url-normalization/index.md\n---\n\nDeprecation notice\n\nCloudflare Firewall Rules has been deprecated. Cloudflare has moved existing firewall rules to [WAF custom rules](https://developers.cloudflare.com/waf/custom-rules/). For more information on this change, refer to the [upgrade guide](https://developers.cloudflare.com/waf/reference/legacy/firewall-rules-upgrade/).\n\nOn 2021-04-08, Cloudflare announced [URL normalization](https://developers.cloudflare.com/rules/normalization/), a feature that protects zones by normalizing HTTP request URI paths.\n\nMalicious users can craft specific URIs that could be interpreted differently by firewall systems and origin systems. When you enable **Normalize incoming URLs**, all rules filtering on the URI path will receive the URL in a canonical form, which provides an extra layer of protection against these malicious users.\n\nCloudflare gradually enabled URL normalization for all Cloudflare zones except for those that could be impacted by this change. We determined the impacted zones by analyzing all firewall rules, looking for patterns in HTTP fields that would no longer match when using URL normalization techniques.\n\nThese fields are the following:\n\n* `http.request.uri.path`\n* `http.request.full_uri`\n* `http.request.uri`\n\nCloudflare did not enable URL normalization automatically for zones that would be impacted by these changes to prevent any change in behavior of your existing firewall rules.\n\n## Why URL normalization is important\n\nCloudflare strongly recommends that you enable **Normalize incoming URLs** in **Rules** > **Overview** > **URL Normalization** to strengthen your zone's security posture. Not doing so leaves your zone at greater risk of a successful attack. Malicious parties could craft the URL in a way that the rules are not accounting for.\n\nFor example, a firewall rule with an expression such as `http.request.uri.path contains \"/login\"` could be bypassed if the malicious actor has encoded the `l` character as `%6C`. In this scenario, and with URL normalization disabled, traffic would not be matched by the firewall rule.\n\nRefer to [How URL normalization works](https://developers.cloudflare.com/rules/normalization/how-it-works/) for more information and additional examples.\n\n***\n\n## Recommended procedure\n\nIt is recommended that you:\n\n1. Update any firewall rules impacted by the URL normalization changes.\n2. Enable URL normalization.\n\nThese steps will ensure a stronger security posture on your zone(s).\n\n### 1. Review and update firewall rules\n\nBefore enabling URL normalization, you should review the affected firewall rules on your zone(s) and take one of the following approaches:\n\n* Edit these firewall rules to remove the parts which will no longer trigger once normalized — for example, any rules that look for `//` or `../` in URL paths. Administrators previously created these rules to perform a limited URL normalization, and these rules can now be safely disabled and then deleted.\n\n* If you wish to identify visitors with non-normalized URI paths with these firewall rules, you should update them to use the original (or raw) non-normalized fields. These fields are the following:\n\n  * `raw.http.request.uri.path`\n  * `raw.http.request.full_uri`\n  * `raw.http.request.uri`\n\n### 2. Enable URL normalization\n\nOnce you have updated the affected firewall rules, enable URL normalization in **Rules** > **Overview** > **URL Normalization**.\n\nA Cloudflare user must have the [Firewall role](https://developers.cloudflare.com/fundamentals/manage-members/roles/) or one of the Administrator roles to access URL normalization settings in the dashboard.\n\n***\n\n## Related resources\n\n* [URL normalization](https://developers.cloudflare.com/rules/normalization/)\n* [Transform Rules](https://developers.cloudflare.com/rules/transform/)\n\n</page>\n\n<page>\n---\ntitle: Change Super Administrator · Cloudflare Fundamentals docs\ndescription: If you or someone in your organization leaves or loses access to\n  email, you can add another Super Administrator using any other Super\n  Administrator on your Account with a verified email address.\nlastUpdated: 2025-06-18T18:14:42.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/fundamentals/account/change-super-admin/\n  md: https://developers.cloudflare.com/fundamentals/account/change-super-admin/index.md\n---\n\nIf you or someone in your organization leaves or loses access to email, you can add another Super Administrator using any other Super Administrator on your Account with a [verified email](https://developers.cloudflare.com/fundamentals/account/verify-email-address/) address.\n\nFirst, [add a member](https://developers.cloudflare.com/fundamentals/manage-members/manage/) to your account and assign the **Super Administrator** role.\n\nThen, if needed, remove the previous Super Administrator.\n\n</page>\n\n<page>\n---\ntitle: Account security · Cloudflare Fundamentals docs\nlastUpdated: 2025-05-29T18:16:56.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/fundamentals/account/account-security/\n  md: https://developers.cloudflare.com/fundamentals/account/account-security/index.md\n---\n\n* [Add abuse contact](https://developers.cloudflare.com/fundamentals/account/account-security/abuse-contact/)\n* [Allow Cloudflare access](https://developers.cloudflare.com/fundamentals/account/account-security/cloudflare-access/)\n* [Leaked Password Notifications](https://developers.cloudflare.com/fundamentals/account/account-security/leaked-password-notifications/)\n* [Review audit logs - v1](https://developers.cloudflare.com/fundamentals/account/account-security/review-audit-logs/)\n* [Audit Logs - version 2 (beta)](https://developers.cloudflare.com/fundamentals/account/account-security/audit-logs/)\n* [Secure compromised account](https://developers.cloudflare.com/fundamentals/account/account-security/secure-a-compromised-account/)\n* [Set up SSO](https://developers.cloudflare.com/fundamentals/manage-members/dashboard-sso/)\n* [Manage active sessions](https://developers.cloudflare.com/fundamentals/account/account-security/manage-active-sessions/)\n* [SCIM provisioning](https://developers.cloudflare.com/fundamentals/account/account-security/scim-setup/)\n* [Zone holds](https://developers.cloudflare.com/fundamentals/account/account-security/zone-holds/)\n\n</page>\n\n<page>\n---\ntitle: Create account · Cloudflare Fundamentals docs\ndescription: Learn how to create a new Cloudflare account.\nlastUpdated: 2025-09-15T14:53:30.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/fundamentals/account/create-account/\n  md: https://developers.cloudflare.com/fundamentals/account/create-account/index.md\n---\n\nTo create a Cloudflare account:\n\n1. Go to the [Sign up page](https://dash.cloudflare.com/sign-up).\n2. Enter your **Email** and **Password**.\n3. Select **Create Account**.\n\nOnce you create your account, Cloudflare will automatically send an email to your address to [verify that email address](https://developers.cloudflare.com/fundamentals/user-profiles/verify-email-address/).\n\n## Account name\n\nYour account name defaults to `<<YOUR_EMAIL_ADDRESS>>'s Account`.\n\nYou may want to customize the name of this account, either to help specify its purpose or to help associate it with multiple accounts.\n\nTo change your account name:\n\n1. In the Cloudflare dashboard, go to the **Configurations** page.\n\n   [Go to **Settings**](https://dash.cloudflare.com/?to=/:account/configurations)\n\n2. For **Account Name**, select **Change Name**.\n\n3. Enter a new account name.\n\n4. Select **Save**.\n\n## Best practices\n\nIf you are creating an account for your team or a business, we recommend choosing an email alias or distribution list for your **Email**, such as `cloudflare@example.com`.\n\nThis email address is the main point of contact for your Cloudflare billing, usage notifications, and account recovery.\n\nRefer to [Account and domain management best practices](https://developers.cloudflare.com/fundamentals/reference/best-practices/) for a detailed list of ways to protect your account and domain.\n\nOnce you [set up an account](https://developers.cloudflare.com/fundamentals/account/), you have several ways to interact with Cloudflare.\n\n## Interact with Cloudflare\n\nIf you prefer working without code, you can manage your account and domain settings through the [Cloudflare dashboard](https://dash.cloudflare.com/login).\n\nNote\n\nIf your domain was added to Cloudflare by a hosting partner, manage your DNS records via the hosting partner.\n\nFor those who prefer to interact with Cloudflare programmatically, you can use several methods:\n\n| Resource | Docs | Description |\n| - | - | - |\n| [Cloudflare API](https://developers.cloudflare.com/fundamentals/api/) | [API docs](https://developers.cloudflare.com/api/) | RESTful API based on HTTPS requests and JSON responses. |\n| [Terraform](https://registry.terraform.io/providers/cloudflare/cloudflare/latest/docs) | [Terraform docs](https://developers.cloudflare.com/terraform/) | Configure Cloudflare using HashiCorp's Infrastructure as Code tool, Terraform. |\n| [cloudflare-go](https://github.com/cloudflare/cloudflare-go) | [README](https://github.com/cloudflare/cloudflare-go#readme) | The official Go library for the Cloudflare API. |\n| [cloudflare-typescript](https://github.com/cloudflare/cloudflare-typescript) | [README](https://github.com/cloudflare/cloudflare-typescript#readme) | The official TypeScript library for the Cloudflare API. |\n| [cloudflare-python](https://github.com/cloudflare/cloudflare-python) | [README](https://github.com/cloudflare/cloudflare-python#readme) | The official Python library for the Cloudflare API. |\n\n</page>\n\n<page>\n---\ntitle: Find account and zone IDs · Cloudflare Fundamentals docs\ndescription: Once you set up a new account and add your domain to Cloudflare,\n  you may need access to your zone and account IDs for API operations.\nlastUpdated: 2025-09-15T14:53:30.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/fundamentals/account/find-account-and-zone-ids/\n  md: https://developers.cloudflare.com/fundamentals/account/find-account-and-zone-ids/index.md\n---\n\nOnce you [set up a new account](https://developers.cloudflare.com/fundamentals/account/) and [add your domain](https://developers.cloudflare.com/fundamentals/manage-domains/add-site/) to Cloudflare, you may need access to your zone and account IDs for API operations.\n\n## Copy your Account ID\n\n1. In the Cloudflare dashboard, go to the **Account home** page.\n\n   [Go to **Account home**](https://dash.cloudflare.com/?to=/:account/home)\n\n2. Select the menu button at the end of the account row. ![Screenshot of the Overview page with the API section highlighted](https://developers.cloudflare.com/_astro/overview-account-id.0vaDbwHf_ZgiWlG.webp)\n\n3. Select **Copy account ID**.\n\n### Users with a single account\n\nTo copy the account ID when you only have one account:\n\n1. In the Cloudflare dashboard, go to the **Account home** page and locate your account.\n\n   [Go to **Account home**](https://dash.cloudflare.com/?to=/:account/home)\n\n2. Select the menu button next to your account name.\n\n3. From the list that appears, select **Copy account ID**. ![Screenshot of the Overview page with the API section highlighted](https://developers.cloudflare.com/_astro/single-account-id.D7jBJK09_ZqgF3b.webp)\n\n## Copy your Zone ID\n\n1. In the Cloudflare dashboard, go to the **Account** home and locate your account.\n\n   [Go to **Account home**](https://dash.cloudflare.com/?to=/:account/home)\n\n2. From the **Overview** page for your account, locate the **API** section towards the bottom of the page.\n\n![Screenshot of the Overview page with the API section highlighted](https://developers.cloudflare.com/_astro/dash-overview-api-highlighted.BUg6qi1p_Z2j2dMU.webp)\n\n1. Under **Zone ID** select **Click to copy**. You can also find your **Account ID** under the **API** section.\n\n## Find account ID (Workers and Pages)\n\nYou can also find your account ID from the **Workers & Pages** section of your account.\n\n1. In the Cloudflare dashboard, go to the **Workers & Pages** page.\n\n   [Go to **Workers & Pages**](https://dash.cloudflare.com/?to=/:account/workers-and-pages)\n\n2. The **Account details** section contains your **Account ID**.\n\n3. To copy the Account ID, select **Click to copy**.\n\n![Screenshot of the Workers & Pages Overview page with the account ID section highlighted](https://developers.cloudflare.com/_astro/workers-account-id.BrhDn1KP_Zo2Uiz.webp)\n\n</page>\n\n<page>\n---\ntitle: Get started · Cloudflare Fundamentals docs\ndescription: Using the Cloudflare API requires authentication so that Cloudflare\n  knows who is making requests and what permissions you have. Create an API\n  token to grant access to the API to perform actions.\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/fundamentals/api/get-started/\n  md: https://developers.cloudflare.com/fundamentals/api/get-started/index.md\n---\n\nUsing the Cloudflare API requires authentication so that Cloudflare knows who is making requests and what permissions you have. [Create an API token](https://developers.cloudflare.com/fundamentals/api/get-started/create-token/) to grant access to the API to perform actions.\n\nNote\n\nYou can also authenticate with [API keys](https://developers.cloudflare.com/fundamentals/api/get-started/keys/), but these keys have [several limitations](https://developers.cloudflare.com/fundamentals/api/get-started/keys/#limitations) that make them less secure than API tokens. Whenever possible, use API tokens to interact with the Cloudflare API.\n\n* [Create API token](https://developers.cloudflare.com/fundamentals/api/get-started/create-token/)\n* [Get Global API key (legacy)](https://developers.cloudflare.com/fundamentals/api/get-started/keys/)\n* [Get Origin CA keys](https://developers.cloudflare.com/fundamentals/api/get-started/ca-keys/)\n* [Account API tokens](https://developers.cloudflare.com/fundamentals/api/get-started/account-owned-tokens/)\n\n</page>\n\n<page>\n---\ntitle: How to · Cloudflare Fundamentals docs\ndescription: Using the Cloudflare API requires authentication so that Cloudflare\n  knows who is making requests and what permissions you have. Create an API\n  token to grant access to the API to perform actions.\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/fundamentals/api/how-to/\n  md: https://developers.cloudflare.com/fundamentals/api/how-to/index.md\n---\n\nUsing the Cloudflare API requires authentication so that Cloudflare knows who is making requests and what permissions you have. [Create an API token](https://developers.cloudflare.com/fundamentals/api/get-started/create-token/) to grant access to the API to perform actions.\n\nNote\n\nYou can also authenticate with [API keys](https://developers.cloudflare.com/fundamentals/api/get-started/keys/), but these keys have [several limitations](https://developers.cloudflare.com/fundamentals/api/get-started/keys/#limitations) that make them less secure than API tokens. Whenever possible, use API tokens to interact with the Cloudflare API.\n\n* [Make API calls](https://developers.cloudflare.com/fundamentals/api/how-to/make-api-calls/)\n* [Create tokens via API](https://developers.cloudflare.com/fundamentals/api/how-to/create-via-api/)\n* [Control API Access](https://developers.cloudflare.com/fundamentals/api/how-to/control-api-access/)\n* [Restrict tokens](https://developers.cloudflare.com/fundamentals/api/how-to/restrict-tokens/)\n* [Roll tokens](https://developers.cloudflare.com/fundamentals/api/how-to/roll-token/)\n\n</page>\n\n<page>\n---\ntitle: Reference · Cloudflare Fundamentals docs\nlastUpdated: 2024-10-31T11:42:05.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/fundamentals/api/reference/\n  md: https://developers.cloudflare.com/fundamentals/api/reference/index.md\n---\n\n* [REST API](https://developers.cloudflare.com/api/)\n* [GraphQL API](https://developers.cloudflare.com/analytics/graphql-api/)\n* [Wrangler API](https://developers.cloudflare.com/workers/wrangler/api/)\n* [API token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/)\n* [API deprecations](https://developers.cloudflare.com/fundamentals/api/reference/deprecations/)\n* [API token templates](https://developers.cloudflare.com/fundamentals/api/reference/template/)\n* [Rate limits](https://developers.cloudflare.com/fundamentals/api/reference/limits/)\n* [SDKs](https://developers.cloudflare.com/fundamentals/api/reference/sdks/)\n\n</page>\n\n<page>\n---\ntitle: Troubleshooting · Cloudflare Fundamentals docs\ndescription: 'Ensure the token has been verified by running the following curl\n  command and confirming that the response returns \"status\": \"active\".'\nlastUpdated: 2025-03-06T13:01:10.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/fundamentals/api/troubleshooting/\n  md: https://developers.cloudflare.com/fundamentals/api/troubleshooting/index.md\n---\n\n## The token is not verified\n\nEnsure the token has been verified by running the following `curl` command and confirming that the response returns `\"status\": \"active\"`.",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "## The token has incorrect permissions\n\nReview the permissions groups for your token in the [Cloudflare dashboard](https://dash.cloudflare.com/profile/api-tokens). Refer to [API token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) for more information.\n\n## The incorrect syntax is used\n\nOccasionally customers will attempt to use an API token with an API key syntax. Ensure you are using the Bearer option rather than the email and API key pair.\n\n## You have the incorrect user permissions\n\nYou cannot create a token that exceeds the permission granted to you on your account. For example, if you have been granted an **Admin (Read only)** role, you would need your Super Administrator to update your role so that you could create a token for yourself.\n\n</page>\n\n<page>\n---\ntitle: Accounts, zones, and profiles · Cloudflare Fundamentals docs\ndescription: \"Within the Cloudflare ecosystem, there are three organizing\n  concepts that control where specific settings live: user profiles, accounts,\n  and zones.\"\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/fundamentals/concepts/accounts-and-zones/\n  md: https://developers.cloudflare.com/fundamentals/concepts/accounts-and-zones/index.md\n---\n\nWithin the Cloudflare ecosystem, there are three organizing concepts that control where specific settings live: user profiles, accounts, and zones.",
      "language": "unknown"
    },
    {
      "code": "***\n\n## User profiles\n\nEach user has a profile that contains several settings, such as [Communication preferences](https://developers.cloudflare.com/fundamentals/user-profiles/customize-account/#notifications) and [Language preferences](https://developers.cloudflare.com/fundamentals/user-profiles/customize-account/#language).\n\nTo access your profile, select the user icon and then **My Profile** from any page within the [Cloudflare dashboard](https://dash.cloudflare.com).\n\n## Accounts\n\nAn account refers to an organization account, which contains one or more users and zones. Users can belong to multiple accounts, and each account maintains its own settings, including [billing profiles](https://developers.cloudflare.com/billing/create-billing-profile/), [account members](https://developers.cloudflare.com/fundamentals/manage-members/), [lists](https://developers.cloudflare.com/waf/tools/lists/), and other configurations.\n\nSeveral account-level products - such as [Workers](https://developers.cloudflare.com/workers/), [Pages](https://developers.cloudflare.com/pages/), [Security Center](https://developers.cloudflare.com/security-center/), and [Bulk redirects](https://developers.cloudflare.com/rules/url-forwarding/bulk-redirects/) - can affect some or all zones contained within that account.\n\nAfter you [log in](https://dash.cloudflare.com) and select an account - but before you select a zone - the sidebar will list account-level products.\n\nWhen you log into the [Cloudflare dashboard](https://dash.cloudflare.com), you can access all accounts where your user is a member. To access account settings and account-level products from within a zone, use the **Accounts** option from the navigation sidebar.\n\n## Zones\n\nDomains (or [subdomains](https://developers.cloudflare.com/dns/zone-setups/subdomain-setup/)) that are added to Cloudflare become zones[1](#user-content-fn-1), which have a direct impact on the security and performance of your website, application, or API. Use your zone to monitor security and performance, update configurations, and apply zone-level products and services.\n\nZone-level services - such as [Load Balancers](https://developers.cloudflare.com/load-balancing/) and [Cache rules](https://developers.cloudflare.com/cache/how-to/cache-rules/) - only affect your website, application, or API for that zone and not other zones, even if they are contained within the same account.\n\nWhen you log into the [Cloudflare dashboard](https://dash.cloudflare.com) and choose an account, you can view a list of all zones within that account.\n\nOnce you are within a zone, items within the sidebar will be zone-related products. If you need to change to another zone, use the forward arrow next to the zone name or by go back to the homepage of your account.\n\n## Footnotes\n\n1. Similar to [DNS zones](https://www.cloudflare.com/learning/dns/glossary/dns-zone/), but with additional capabilities. [↩](#user-content-fnref-1)\n\n</page>\n\n<page>\n---\ntitle: Cloudflare IP addresses · Cloudflare Fundamentals docs\ndescription: Cloudflare has several IP address ranges which are shared by all\n  proxied hostnames.\nlastUpdated: 2025-07-18T14:20:57.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/fundamentals/concepts/cloudflare-ip-addresses/\n  md: https://developers.cloudflare.com/fundamentals/concepts/cloudflare-ip-addresses/index.md\n---\n\nCloudflare has several [IP address ranges](https://www.cloudflare.com/ips/) which are shared by all proxied hostnames.\n\nTogether, these IP addresses form the backbone of our [anycast network](https://www.cloudflare.com/learning/cdn/glossary/anycast-network/), helping distribute traffic amongst various edge network servers.\n\nNote\n\nCloudflare uses other IP ranges for various products and services, but these addresses will not make connections to your origin.\n\n## Allow Cloudflare IP addresses\n\nAll traffic to [proxied DNS records](https://developers.cloudflare.com/dns/proxy-status/) passes through Cloudflare before reaching your origin server. This means that your origin server will stop receiving traffic from individual visitor IP addresses and instead receive traffic from [Cloudflare IP addresses](https://www.cloudflare.com/ips), which are shared by all proxied hostnames.\n\nThis setup can cause issues if your origin server blocks or rate limits connections from Cloudflare IP addresses. Because all visitor traffic will appear to come from Cloudflare IP addresses, blocking these IPs — even accidentally — will prevent visitor traffic from reaching your application.\n\nIn addition, allowing Cloudflare IPs might be needed to avoid rate limiting or blocking these requests at your origin server.\n\nFor [Magic Transit](https://developers.cloudflare.com/magic-transit/) customers, Cloudflare routes the traffic instead of proxying it. Once Cloudflare starts advertising your IP prefixes, it will accept IP packets destined for your network, process them, and then output these packets to your origin infrastructure.\n\n## Configure origin server\n\n### Allowlist Cloudflare IP addresses\n\nTo avoid blocking Cloudflare IP addresses unintentionally, you also want to allow Cloudflare IP addresses at your origin web server.\n\nYou can explicitly allow these IP addresses with a [.htaccess file](https://httpd.apache.org/docs/trunk/mod/mod_authz_core.html#require) or by using [iptables](https://www.linode.com/docs/security/firewalls/control-network-traffic-with-iptables/#block-or-allow-traffic-by-port-number-to-create-an-iptables-firewall).\n\nThe following example demonstrates how you could use an iptables rule to allow a Cloudflare IP address range. Replace `$ip` below with one of the [Cloudflare IP address ranges](https://www.cloudflare.com/ips).",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "5. Query your database from the Worker",
      "id": "5.-query-your-database-from-the-worker"
    },
    {
      "level": "h2",
      "text": "6. Run the Worker locally",
      "id": "6.-run-the-worker-locally"
    },
    {
      "level": "h2",
      "text": "7. Deploy the Worker",
      "id": "7.-deploy-the-worker"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "1. Create a D1 API token",
      "id": "1.-create-a-d1-api-token"
    },
    {
      "level": "h2",
      "text": "2. Create the target table",
      "id": "2.-create-the-target-table"
    },
    {
      "level": "h2",
      "text": "3. Create an `index.js` file",
      "id": "3.-create-an-`index.js`-file"
    },
    {
      "level": "h2",
      "text": "4. Generate example data (optional)",
      "id": "4.-generate-example-data-(optional)"
    },
    {
      "level": "h2",
      "text": "5. Generate the SQL command",
      "id": "5.-generate-the-sql-command"
    },
    {
      "level": "h2",
      "text": "6. Import the data to D1",
      "id": "6.-import-the-data-to-d1"
    },
    {
      "level": "h2",
      "text": "7. Write the final code",
      "id": "7.-write-the-final-code"
    },
    {
      "level": "h2",
      "text": "8. Run the code",
      "id": "8.-run-the-code"
    },
    {
      "level": "h2",
      "text": "Summary",
      "id": "summary"
    },
    {
      "level": "h2",
      "text": "Quick start",
      "id": "quick-start"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "Step 1: Create a Workers project",
      "id": "step-1:-create-a-workers-project"
    },
    {
      "level": "h2",
      "text": "Step 2: Update the frontend",
      "id": "step-2:-update-the-frontend"
    },
    {
      "level": "h2",
      "text": "Step 3: Create a D1 database and enable read replication",
      "id": "step-3:-create-a-d1-database-and-enable-read-replication"
    },
    {
      "level": "h2",
      "text": "Step 4: Create the API routes",
      "id": "step-4:-create-the-api-routes"
    },
    {
      "level": "h2",
      "text": "Step 5: Create local D1 database schema",
      "id": "step-5:-create-local-d1-database-schema"
    },
    {
      "level": "h2",
      "text": "Step 6: Add retry logic",
      "id": "step-6:-add-retry-logic"
    },
    {
      "level": "h2",
      "text": "Step 7: Update the API routes",
      "id": "step-7:-update-the-api-routes"
    },
    {
      "level": "h3",
      "text": "1. POST /api/product",
      "id": "1.-post-/api/product"
    },
    {
      "level": "h3",
      "text": "2. GET /api/products",
      "id": "2.-get-/api/products"
    },
    {
      "level": "h3",
      "text": "3. GET /api/products/:id",
      "id": "3.-get-/api/products/:id"
    },
    {
      "level": "h2",
      "text": "Step 8: Test the application",
      "id": "step-8:-test-the-application"
    },
    {
      "level": "h2",
      "text": "Step 9: Deploy the application",
      "id": "step-9:-deploy-the-application"
    },
    {
      "level": "h2",
      "text": "Conclusion",
      "id": "conclusion"
    },
    {
      "level": "h2",
      "text": "Methods",
      "id": "methods"
    },
    {
      "level": "h3",
      "text": "`prepare()`",
      "id": "`prepare()`"
    },
    {
      "level": "h3",
      "text": "`batch()`",
      "id": "`batch()`"
    },
    {
      "level": "h3",
      "text": "`exec()`",
      "id": "`exec()`"
    },
    {
      "level": "h3",
      "text": "`dump`",
      "id": "`dump`"
    },
    {
      "level": "h3",
      "text": "`withSession()`",
      "id": "`withsession()`"
    },
    {
      "level": "h2",
      "text": "`D1DatabaseSession` methods",
      "id": "`d1databasesession`-methods"
    },
    {
      "level": "h3",
      "text": "`getBookmark`",
      "id": "`getbookmark`"
    },
    {
      "level": "h3",
      "text": "`prepare()`",
      "id": "`prepare()`"
    },
    {
      "level": "h3",
      "text": "`batch()`",
      "id": "`batch()`"
    },
    {
      "level": "h2",
      "text": "Methods",
      "id": "methods"
    },
    {
      "level": "h3",
      "text": "`bind()`",
      "id": "`bind()`"
    },
    {
      "level": "h3",
      "text": "`run()`",
      "id": "`run()`"
    },
    {
      "level": "h3",
      "text": "`raw()`",
      "id": "`raw()`"
    },
    {
      "level": "h3",
      "text": "`first()`",
      "id": "`first()`"
    },
    {
      "level": "h2",
      "text": "`D1Result`",
      "id": "`d1result`"
    },
    {
      "level": "h3",
      "text": "Example",
      "id": "example"
    },
    {
      "level": "h2",
      "text": "`D1ExecResult`",
      "id": "`d1execresult`"
    },
    {
      "level": "h3",
      "text": "Example",
      "id": "example"
    },
    {
      "level": "h2",
      "text": "Regional Services",
      "id": "regional-services"
    },
    {
      "level": "h2",
      "text": "Customer Metadata Boundary",
      "id": "customer-metadata-boundary"
    },
    {
      "level": "h2",
      "text": "Regional Services",
      "id": "regional-services"
    },
    {
      "level": "h2",
      "text": "Customer Metadata Boundary",
      "id": "customer-metadata-boundary"
    },
    {
      "level": "h2",
      "text": "Regional Services",
      "id": "regional-services"
    },
    {
      "level": "h2",
      "text": "Customer Metadata Boundary",
      "id": "customer-metadata-boundary"
    },
    {
      "level": "h2",
      "text": "Regional Services",
      "id": "regional-services"
    },
    {
      "level": "h2",
      "text": "Customer Metadata Boundary",
      "id": "customer-metadata-boundary"
    },
    {
      "level": "h2",
      "text": "Regional Services",
      "id": "regional-services"
    },
    {
      "level": "h2",
      "text": "Customer Metadata Boundary",
      "id": "customer-metadata-boundary"
    },
    {
      "level": "h2",
      "text": "Regional Services",
      "id": "regional-services"
    },
    {
      "level": "h3",
      "text": "Send logs to R2 via S3-Compatible endpoint",
      "id": "send-logs-to-r2-via-s3-compatible-endpoint"
    },
    {
      "level": "h2",
      "text": "Customer Metadata Boundary",
      "id": "customer-metadata-boundary"
    },
    {
      "level": "h2",
      "text": "Regional Services",
      "id": "regional-services"
    },
    {
      "level": "h3",
      "text": "Caveats",
      "id": "caveats"
    },
    {
      "level": "h2",
      "text": "Customer Metadata Boundary",
      "id": "customer-metadata-boundary"
    },
    {
      "level": "h2",
      "text": "Gateway",
      "id": "gateway"
    },
    {
      "level": "h3",
      "text": "Egress policies",
      "id": "egress-policies"
    },
    {
      "level": "h3",
      "text": "HTTP policies",
      "id": "http-policies"
    },
    {
      "level": "h3",
      "text": "Network policies",
      "id": "network-policies"
    },
    {
      "level": "h3",
      "text": "DNS policies",
      "id": "dns-policies"
    },
    {
      "level": "h3",
      "text": "Custom certificates",
      "id": "custom-certificates"
    },
    {
      "level": "h3",
      "text": "Logs and Analytics",
      "id": "logs-and-analytics"
    },
    {
      "level": "h2",
      "text": "Access",
      "id": "access"
    },
    {
      "level": "h2",
      "text": "Cloudflare Tunnel",
      "id": "cloudflare-tunnel"
    },
    {
      "level": "h2",
      "text": "WARP settings",
      "id": "warp-settings"
    },
    {
      "level": "h3",
      "text": "Local Domain Fallback",
      "id": "local-domain-fallback"
    },
    {
      "level": "h3",
      "text": "Split Tunnels",
      "id": "split-tunnels"
    },
    {
      "level": "h2",
      "text": "What data is covered by the Customer Metadata Boundary?",
      "id": "what-data-is-covered-by-the-customer-metadata-boundary?"
    },
    {
      "level": "h2",
      "text": "What data is not covered by the Customer Metadata Boundary?",
      "id": "what-data-is-not-covered-by-the-customer-metadata-boundary?"
    },
    {
      "level": "h2",
      "text": "Who can use the Customer Metadata Boundary?",
      "id": "who-can-use-the-customer-metadata-boundary?"
    },
    {
      "level": "h2",
      "text": "What are the analytics products available for Metadata Boundary?",
      "id": "what-are-the-analytics-products-available-for-metadata-boundary?"
    },
    {
      "level": "h2",
      "text": "Configure Customer Metadata Boundary in the dashboard",
      "id": "configure-customer-metadata-boundary-in-the-dashboard"
    },
    {
      "level": "h2",
      "text": "Configure Customer Metadata Boundary via API",
      "id": "configure-customer-metadata-boundary-via-api"
    },
    {
      "level": "h2",
      "text": "View or change settings",
      "id": "view-or-change-settings"
    },
    {
      "level": "h2",
      "text": "Footnotes",
      "id": "footnotes"
    },
    {
      "level": "h2",
      "text": "Configure Regional Services in the dashboard",
      "id": "configure-regional-services-in-the-dashboard"
    },
    {
      "level": "h2",
      "text": "Configure Regional Services via API",
      "id": "configure-regional-services-via-api"
    },
    {
      "level": "h2",
      "text": "Verify regional map for Zero Trust",
      "id": "verify-regional-map-for-zero-trust"
    },
    {
      "level": "h2",
      "text": "Terraform support",
      "id": "terraform-support"
    },
    {
      "level": "h2",
      "text": "Footnotes",
      "id": "footnotes"
    },
    {
      "level": "h2",
      "text": "Getting additional DNS protection",
      "id": "getting-additional-dns-protection"
    },
    {
      "level": "h2",
      "text": "Autonomous Edge",
      "id": "autonomous-edge"
    },
    {
      "level": "h2",
      "text": "Centralized DDoS protection system",
      "id": "centralized-ddos-protection-system"
    },
    {
      "level": "h2",
      "text": "Thresholds",
      "id": "thresholds"
    },
    {
      "level": "h2",
      "text": "Time to mitigate",
      "id": "time-to-mitigate"
    },
    {
      "level": "h2",
      "text": "Data localization",
      "id": "data-localization"
    },
    {
      "level": "h2",
      "text": "Prefixes",
      "id": "prefixes"
    },
    {
      "level": "h2",
      "text": "Allowlist",
      "id": "allowlist"
    },
    {
      "level": "h2",
      "text": "Rule",
      "id": "rule"
    },
    {
      "level": "h3",
      "text": "Rule settings",
      "id": "rule-settings"
    },
    {
      "level": "h2",
      "text": "Filter",
      "id": "filter"
    },
    {
      "level": "h3",
      "text": "Example use case",
      "id": "example-use-case"
    },
    {
      "level": "h2",
      "text": "Determining the execution mode",
      "id": "determining-the-execution-mode"
    },
    {
      "level": "h2",
      "text": "Mitigation reasons",
      "id": "mitigation-reasons"
    },
    {
      "level": "h2",
      "text": "Thresholds",
      "id": "thresholds"
    },
    {
      "level": "h3",
      "text": "Automatic thresholds",
      "id": "automatic-thresholds"
    },
    {
      "level": "h2",
      "text": "Prefixes",
      "id": "prefixes"
    },
    {
      "level": "h2",
      "text": "Rules",
      "id": "rules"
    },
    {
      "level": "h2",
      "text": "Enablement",
      "id": "enablement"
    },
    {
      "level": "h2",
      "text": "All customers",
      "id": "all-customers"
    },
    {
      "level": "h2",
      "text": "Enterprise customers",
      "id": "enterprise-customers"
    },
    {
      "level": "h2",
      "text": "Magic Transit customers",
      "id": "magic-transit-customers"
    },
    {
      "level": "h2",
      "text": "Using a third-party CDN in front of Cloudflare",
      "id": "using-a-third-party-cdn-in-front-of-cloudflare"
    },
    {
      "level": "h3",
      "text": "Recommended DDoS configuration adjustments",
      "id": "recommended-ddos-configuration-adjustments"
    },
    {
      "level": "h2",
      "text": "Using VPNs, NATs, and other third-party services",
      "id": "using-vpns,-nats,-and-other-third-party-services"
    },
    {
      "level": "h3",
      "text": "Recommended DDoS configuration adjustments",
      "id": "recommended-ddos-configuration-adjustments"
    },
    {
      "level": "h2",
      "text": "2024-06-03",
      "id": "2024-06-03"
    },
    {
      "level": "h2",
      "text": "2024-04-17",
      "id": "2024-04-17"
    },
    {
      "level": "h2",
      "text": "Availability",
      "id": "availability"
    },
    {
      "level": "h2",
      "text": "How it works",
      "id": "how-it-works"
    },
    {
      "level": "h2",
      "text": "View flagged traffic",
      "id": "view-flagged-traffic"
    },
    {
      "level": "h2",
      "text": "Configure the rules",
      "id": "configure-the-rules"
    },
    {
      "level": "h2",
      "text": "Ruleset configuration",
      "id": "ruleset-configuration"
    },
    {
      "level": "h2",
      "text": "Origin Protect rules",
      "id": "origin-protect-rules"
    },
    {
      "level": "h2",
      "text": "Availability",
      "id": "availability"
    },
    {
      "level": "h2",
      "text": "Related Cloudflare products",
      "id": "related-cloudflare-products"
    },
    {
      "level": "h2",
      "text": "Ruleset configuration",
      "id": "ruleset-configuration"
    },
    {
      "level": "h3",
      "text": "Network Analytics rule display",
      "id": "network-analytics-rule-display"
    },
    {
      "level": "h2",
      "text": "Availability",
      "id": "availability"
    },
    {
      "level": "h2",
      "text": "Related Cloudflare products",
      "id": "related-cloudflare-products"
    },
    {
      "level": "h2",
      "text": "Set up a notification for DDoS alerts",
      "id": "set-up-a-notification-for-ddos-alerts"
    },
    {
      "level": "h2",
      "text": "Edit an existing notification",
      "id": "edit-an-existing-notification"
    },
    {
      "level": "h2",
      "text": "Alert types",
      "id": "alert-types"
    },
    {
      "level": "h3",
      "text": "Standard alerts",
      "id": "standard-alerts"
    },
    {
      "level": "h3",
      "text": "Advanced alerts",
      "id": "advanced-alerts"
    },
    {
      "level": "h2",
      "text": "Availability",
      "id": "availability"
    },
    {
      "level": "h2",
      "text": "Example notification",
      "id": "example-notification"
    },
    {
      "level": "h2",
      "text": "Final remarks",
      "id": "final-remarks"
    },
    {
      "level": "h2",
      "text": "Availability",
      "id": "availability"
    },
    {
      "level": "h2",
      "text": "Remarks",
      "id": "remarks"
    },
    {
      "level": "h2",
      "text": "Weekly DDoS reports",
      "id": "weekly-ddos-reports"
    },
    {
      "level": "h3",
      "text": "Example report",
      "id": "example-report"
    },
    {
      "level": "h3",
      "text": "Manage reporting subscriptions",
      "id": "manage-reporting-subscriptions"
    },
    {
      "level": "h2",
      "text": "Before you start",
      "id": "before-you-start"
    },
    {
      "level": "h2",
      "text": "Analytics",
      "id": "analytics"
    },
    {
      "level": "h3",
      "text": "Availability and limits",
      "id": "availability-and-limits"
    },
    {
      "level": "h3",
      "text": "View on the dashboard",
      "id": "view-on-the-dashboard"
    },
    {
      "level": "h3",
      "text": "Explore with the API",
      "id": "explore-with-the-api"
    },
    {
      "level": "h2",
      "text": "Logs",
      "id": "logs"
    },
    {
      "level": "h2",
      "text": "Steps",
      "id": "steps"
    },
    {
      "level": "h2",
      "text": "Available settings",
      "id": "available-settings"
    },
    {
      "level": "h2",
      "text": "PTR records",
      "id": "ptr-records"
    },
    {
      "level": "h2",
      "text": "Availability",
      "id": "availability"
    },
    {
      "level": "h2",
      "text": "Set up a reverse zone",
      "id": "set-up-a-reverse-zone"
    },
    {
      "level": "h3",
      "text": "1. Create a reverse DNS zone",
      "id": "1.-create-a-reverse-dns-zone"
    },
    {
      "level": "h3",
      "text": "2. Add PTR records",
      "id": "2.-add-ptr-records"
    },
    {
      "level": "h3",
      "text": "3. Set Cloudflare nameservers",
      "id": "3.-set-cloudflare-nameservers"
    },
    {
      "level": "h2",
      "text": "Other resources",
      "id": "other-resources"
    },
    {
      "level": "h2",
      "text": "Example use case",
      "id": "example-use-case"
    },
    {
      "level": "h2",
      "text": "Aspects to consider",
      "id": "aspects-to-consider"
    },
    {
      "level": "h2",
      "text": "For your zone apex",
      "id": "for-your-zone-apex"
    },
    {
      "level": "h2",
      "text": "For all CNAME records",
      "id": "for-all-cname-records"
    },
    {
      "level": "h2",
      "text": "Per record",
      "id": "per-record"
    },
    {
      "level": "h2",
      "text": "Analytics",
      "id": "analytics"
    },
    {
      "level": "h3",
      "text": "Availability and limits",
      "id": "availability-and-limits"
    },
    {
      "level": "h3",
      "text": "Dashboard",
      "id": "dashboard"
    },
    {
      "level": "h3",
      "text": "GraphQL",
      "id": "graphql"
    },
    {
      "level": "h3",
      "text": "API Legacy",
      "id": "api-legacy"
    },
    {
      "level": "h2",
      "text": "Logs",
      "id": "logs"
    },
    {
      "level": "h2",
      "text": "Response reasons",
      "id": "response-reasons"
    },
    {
      "level": "h2",
      "text": "Resources",
      "id": "resources"
    },
    {
      "level": "h2",
      "text": "Limitations",
      "id": "limitations"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "Configure DNS Firewall",
      "id": "configure-dns-firewall"
    },
    {
      "level": "h3",
      "text": "Create a DNS Firewall cluster",
      "id": "create-a-dns-firewall-cluster"
    },
    {
      "level": "h3",
      "text": "Update registrar settings",
      "id": "update-registrar-settings"
    },
    {
      "level": "h3",
      "text": "Update DNS servers",
      "id": "update-dns-servers"
    },
    {
      "level": "h3",
      "text": "Test DNS resolution",
      "id": "test-dns-resolution"
    },
    {
      "level": "h3",
      "text": "Update security policies",
      "id": "update-security-policies"
    },
    {
      "level": "h2",
      "text": "Additional options",
      "id": "additional-options"
    },
    {
      "level": "h2",
      "text": "Requirement",
      "id": "requirement"
    },
    {
      "level": "h2",
      "text": "1. Set up Cloudflare",
      "id": "1.-set-up-cloudflare"
    },
    {
      "level": "h2",
      "text": "2. Cross-import ZSKs",
      "id": "2.-cross-import-zsks"
    },
    {
      "level": "h2",
      "text": "3. Set up registrar",
      "id": "3.-set-up-registrar"
    },
    {
      "level": "h2",
      "text": "4. Remove previous provider",
      "id": "4.-remove-previous-provider"
    },
    {
      "level": "h2",
      "text": "Enable NSEC3",
      "id": "enable-nsec3"
    },
    {
      "level": "h3",
      "text": "Pre-signed DNSSEC",
      "id": "pre-signed-dnssec"
    },
    {
      "level": "h2",
      "text": "Verify NSEC3 is in use",
      "id": "verify-nsec3-is-in-use"
    },
    {
      "level": "h3",
      "text": "Non-existent zone name",
      "id": "non-existent-zone-name"
    },
    {
      "level": "h3",
      "text": "Non-existent record type at an existing name",
      "id": "non-existent-record-type-at-an-existing-name"
    },
    {
      "level": "h2",
      "text": "Availability",
      "id": "availability"
    },
    {
      "level": "h2",
      "text": "Footnotes",
      "id": "footnotes"
    },
    {
      "level": "h2",
      "text": "Test DNSSEC with Dig",
      "id": "test-dnssec-with-dig"
    },
    {
      "level": "h2",
      "text": "Troubleshoot DNSSEC validation using DNSViz",
      "id": "troubleshoot-dnssec-validation-using-dnsviz"
    },
    {
      "level": "h3",
      "text": "Example with missing or incorrect RRSIG record on authoritative nameserver",
      "id": "example-with-missing-or-incorrect-rrsig-record-on-authoritative-nameserver"
    },
    {
      "level": "h2",
      "text": "View the DNSSEC chain of trust with Dig",
      "id": "view-the-dnssec-chain-of-trust-with-dig"
    },
    {
      "level": "h2",
      "text": "Troubleshoot DNSSEC validation with Dig",
      "id": "troubleshoot-dnssec-validation-with-dig"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "Anycast network groups",
      "id": "anycast-network-groups"
    },
    {
      "level": "h2",
      "text": "Dedicated release process",
      "id": "dedicated-release-process"
    },
    {
      "level": "h2",
      "text": "Nameservers hosting and assignment",
      "id": "nameservers-hosting-and-assignment"
    },
    {
      "level": "h2",
      "text": "Further reading",
      "id": "further-reading"
    },
    {
      "level": "h2",
      "text": "Before you begin",
      "id": "before-you-begin"
    },
    {
      "level": "h3",
      "text": "Differences from standard nameservers",
      "id": "differences-from-standard-nameservers"
    },
    {
      "level": "h2",
      "text": "Enable on a zone",
      "id": "enable-on-a-zone"
    },
    {
      "level": "h2",
      "text": "GraphQL",
      "id": "graphql"
    },
    {
      "level": "h2",
      "text": "Logs",
      "id": "logs"
    },
    {
      "level": "h2",
      "text": "Configuration conditions",
      "id": "configuration-conditions"
    },
    {
      "level": "h2",
      "text": "Footnotes",
      "id": "footnotes"
    },
    {
      "level": "h2",
      "text": "Create a view",
      "id": "create-a-view"
    },
    {
      "level": "h2",
      "text": "Delete a view",
      "id": "delete-a-view"
    },
    {
      "level": "h2",
      "text": "Other API actions",
      "id": "other-api-actions"
    },
    {
      "level": "h2",
      "text": "Before you begin",
      "id": "before-you-begin"
    },
    {
      "level": "h2",
      "text": "1. Set up your internal DNS zone",
      "id": "1.-set-up-your-internal-dns-zone"
    },
    {
      "level": "h3",
      "text": "(Optional) Reference a zone from another zone",
      "id": "(optional)-reference-a-zone-from-another-zone"
    },
    {
      "level": "h2",
      "text": "2. Link your internal zone to a view",
      "id": "2.-link-your-internal-zone-to-a-view"
    },
    {
      "level": "h2",
      "text": "3. Configure Gateway policies",
      "id": "3.-configure-gateway-policies"
    },
    {
      "level": "h2",
      "text": "Resources",
      "id": "resources"
    },
    {
      "level": "h2",
      "text": "Configuration scope",
      "id": "configuration-scope"
    },
    {
      "level": "h2",
      "text": "Availability",
      "id": "availability"
    },
    {
      "level": "h2",
      "text": "Restrictions",
      "id": "restrictions"
    },
    {
      "level": "h2",
      "text": "Assignment method",
      "id": "assignment-method"
    },
    {
      "level": "h3",
      "text": "Nameserver consistency",
      "id": "nameserver-consistency"
    },
    {
      "level": "h3",
      "text": "DNS zone defaults",
      "id": "dns-zone-defaults"
    },
    {
      "level": "h2",
      "text": "Multi-provider DNS",
      "id": "multi-provider-dns"
    },
    {
      "level": "h2",
      "text": "Nameserver TTL",
      "id": "nameserver-ttl"
    },
    {
      "level": "h2",
      "text": "Specific processes",
      "id": "specific-processes"
    },
    {
      "level": "h3",
      "text": "Your domain uses a different registrar",
      "id": "your-domain-uses-a-different-registrar"
    },
    {
      "level": "h3",
      "text": "You have acquired your domain from a reseller",
      "id": "you-have-acquired-your-domain-from-a-reseller"
    },
    {
      "level": "h3",
      "text": "Your domain is delegated to another zone",
      "id": "your-domain-is-delegated-to-another-zone"
    },
    {
      "level": "h2",
      "text": "Proxy eligibility",
      "id": "proxy-eligibility"
    },
    {
      "level": "h3",
      "text": "Pre-signed DNSSEC",
      "id": "pre-signed-dnssec"
    },
    {
      "level": "h2",
      "text": "Ports and protocols",
      "id": "ports-and-protocols"
    },
    {
      "level": "h2",
      "text": "Pending domains",
      "id": "pending-domains"
    },
    {
      "level": "h2",
      "text": "Windows authentication",
      "id": "windows-authentication"
    },
    {
      "level": "h2",
      "text": "Features",
      "id": "features"
    },
    {
      "level": "h3",
      "text": "Advanced nameservers",
      "id": "advanced-nameservers"
    },
    {
      "level": "h3",
      "text": "CNAME flattening",
      "id": "cname-flattening"
    },
    {
      "level": "h3",
      "text": "Custom nameservers",
      "id": "custom-nameservers"
    },
    {
      "level": "h3",
      "text": "DNS analytics",
      "id": "dns-analytics"
    },
    {
      "level": "h3",
      "text": "DNSSEC",
      "id": "dnssec"
    },
    {
      "level": "h3",
      "text": "DNS Firewall",
      "id": "dns-firewall"
    },
    {
      "level": "h3",
      "text": "Full zone setup",
      "id": "full-zone-setup"
    },
    {
      "level": "h3",
      "text": "Partial zone setup",
      "id": "partial-zone-setup"
    },
    {
      "level": "h3",
      "text": "DNS records management",
      "id": "dns-records-management"
    },
    {
      "level": "h3",
      "text": "DNS record comments",
      "id": "dns-record-comments"
    },
    {
      "level": "h3",
      "text": "DNS record tags",
      "id": "dns-record-tags"
    },
    {
      "level": "h3",
      "text": "DNS zone transfers",
      "id": "dns-zone-transfers"
    },
    {
      "level": "h3",
      "text": "Subdomain zone setup",
      "id": "subdomain-zone-setup"
    },
    {
      "level": "h3",
      "text": "Subdomain delegation",
      "id": "subdomain-delegation"
    },
    {
      "level": "h3",
      "text": "Reverse zones",
      "id": "reverse-zones"
    },
    {
      "level": "h2",
      "text": "Metrics",
      "id": "metrics"
    },
    {
      "level": "h2",
      "text": "Dimensions",
      "id": "dimensions"
    },
    {
      "level": "h2",
      "text": "Filters",
      "id": "filters"
    },
    {
      "level": "h3",
      "text": "Filter operators",
      "id": "filter-operators"
    },
    {
      "level": "h3",
      "text": "Combining filters",
      "id": "combining-filters"
    },
    {
      "level": "h2",
      "text": "What is Domain Connect",
      "id": "what-is-domain-connect"
    },
    {
      "level": "h2",
      "text": "Setup",
      "id": "setup"
    },
    {
      "level": "h3",
      "text": "Before you begin",
      "id": "before-you-begin"
    },
    {
      "level": "h3",
      "text": "1. Add templates to the repository",
      "id": "1.-add-templates-to-the-repository"
    },
    {
      "level": "h3",
      "text": "2. Contact Cloudflare to onboard your template",
      "id": "2.-contact-cloudflare-to-onboard-your-template"
    },
    {
      "level": "h2",
      "text": "Properties support",
      "id": "properties-support"
    },
    {
      "level": "h3",
      "text": "Apply template URL",
      "id": "apply-template-url"
    },
    {
      "level": "h3",
      "text": "Template definition",
      "id": "template-definition"
    },
    {
      "level": "h3",
      "text": "DNS records",
      "id": "dns-records"
    },
    {
      "level": "h2",
      "text": "Template updates",
      "id": "template-updates"
    },
    {
      "level": "h3",
      "text": "Troubleshooting",
      "id": "troubleshooting"
    },
    {
      "level": "h2",
      "text": "Footnotes",
      "id": "footnotes"
    },
    {
      "level": "h2",
      "text": "Common causes and resolutions",
      "id": "common-causes-and-resolutions"
    },
    {
      "level": "h3",
      "text": "Mistyped domain or subdomain",
      "id": "mistyped-domain-or-subdomain"
    },
    {
      "level": "h3",
      "text": "Missing DNS records",
      "id": "missing-dns-records"
    },
    {
      "level": "h3",
      "text": "DNSSEC was not disabled before the domain was added to Cloudflare",
      "id": "dnssec-was-not-disabled-before-the-domain-was-added-to-cloudflare"
    },
    {
      "level": "h3",
      "text": "Nameservers no longer point to Cloudflare",
      "id": "nameservers-no-longer-point-to-cloudflare"
    },
    {
      "level": "h3",
      "text": "Unresolved IP address",
      "id": "unresolved-ip-address"
    },
    {
      "level": "h2",
      "text": "Background",
      "id": "background"
    },
    {
      "level": "h2",
      "text": "Potential solutions",
      "id": "potential-solutions"
    },
    {
      "level": "h2",
      "text": "Background",
      "id": "background"
    },
    {
      "level": "h2",
      "text": "Potential solutions",
      "id": "potential-solutions"
    },
    {
      "level": "h2",
      "text": "Are your records correct?",
      "id": "are-your-records-correct?"
    },
    {
      "level": "h2",
      "text": "Are DNS records missing?",
      "id": "are-dns records-missing?"
    },
    {
      "level": "h2",
      "text": "Do you have NS records configured?",
      "id": "do-you-have-ns-records-configured?"
    },
    {
      "level": "h2",
      "text": "Do you have CNAME Flattening enabled?",
      "id": "do-you-have-cname-flattening-enabled?"
    },
    {
      "level": "h2",
      "text": "Is Cloudflare Spectrum enabled on your account?",
      "id": "is-cloudflare-spectrum-enabled-on-your-account?"
    },
    {
      "level": "h2",
      "text": "Contact your mail provider for assistance",
      "id": "contact-your-mail-provider-for-assistance"
    },
    {
      "level": "h2",
      "text": "dc-######### subdomain",
      "id": "dc-#########-subdomain"
    },
    {
      "level": "h2",
      "text": "Best practices for MX records on Cloudflare",
      "id": "best-practices-for-mx-records-on-cloudflare"
    },
    {
      "level": "h2",
      "text": "Is Cloudflare a free DNS (domain nameserver) provider?",
      "id": "is-cloudflare-a-free-dns-(domain-nameserver)-provider?"
    },
    {
      "level": "h2",
      "text": "Does Cloudflare charge for or limit DNS queries?",
      "id": "does-cloudflare-charge-for-or-limit-dns-queries?"
    },
    {
      "level": "h2",
      "text": "Where do I change my nameservers to point to Cloudflare?",
      "id": "where-do-i-change-my-nameservers-to-point-to-cloudflare?"
    },
    {
      "level": "h2",
      "text": "Does Cloudflare limit the number of DNS records a domain can have?",
      "id": "does-cloudflare-limit-the-number-of-dns-records-a-domain-can-have?"
    },
    {
      "level": "h2",
      "text": "Which record types can Cloudflare proxy?",
      "id": "which-record-types-can-cloudflare-proxy?"
    },
    {
      "level": "h2",
      "text": "How do I add ANAME records on Cloudflare?",
      "id": "how-do-i-add-aname-records-on-cloudflare?"
    },
    {
      "level": "h2",
      "text": "Footnotes",
      "id": "footnotes"
    },
    {
      "level": "h2",
      "text": "Can I CNAME a domain not on Cloudflare to a domain that is on Cloudflare?",
      "id": "can-i-cname-a-domain-not-on-cloudflare-to-a-domain-that-is-on-cloudflare?"
    },
    {
      "level": "h2",
      "text": "Does Cloudflare support wildcard DNS entries?",
      "id": "does-cloudflare-support-wildcard-dns-entries?"
    },
    {
      "level": "h2",
      "text": "How long does it take for a DNS change I made to push out?",
      "id": "how-long-does-it-take-for-a-dns-change-i-made-to-push-out?"
    },
    {
      "level": "h2",
      "text": "Does Cloudflare offer domain masking?",
      "id": "does-cloudflare-offer-domain-masking?"
    },
    {
      "level": "h2",
      "text": "Why can't I make ANY queries to Cloudflare DNS servers?",
      "id": "why-can't-i-make-any-queries-to-cloudflare-dns-servers?"
    },
    {
      "level": "h2",
      "text": "Why do I have to remove my `DS` record when signing up for Cloudflare?",
      "id": "why-do-i-have-to-remove-my-`ds`-record-when-signing-up-for-cloudflare?"
    },
    {
      "level": "h2",
      "text": "What happens when I remove the `DS` record?",
      "id": "what-happens-when-i-remove-the-`ds`-record?"
    },
    {
      "level": "h2",
      "text": "Does Cloudflare support EDNS0 (extension mechanisms for DNS)?",
      "id": "does-cloudflare-support-edns0-(extension-mechanisms-for-dns)?"
    },
    {
      "level": "h2",
      "text": "What should I do if I change my server IP address or hosting provider?",
      "id": "what-should-i-do-if-i-change-my-server-ip-address-or-hosting-provider?"
    },
    {
      "level": "h2",
      "text": "Where can I find my Cloudflare nameservers?",
      "id": "where-can-i-find-my-cloudflare-nameservers?"
    },
    {
      "level": "h2",
      "text": "Why are Cloudflare's A or AAAA records / IP addresses for my domain's DNS responses appearing?",
      "id": "why-are-cloudflare's-a-or-aaaa-records-/-ip-addresses-for-my-domain's-dns-responses-appearing?"
    },
    {
      "level": "h2",
      "text": "Can subdomains be added directly to Cloudflare?",
      "id": "can-subdomains-be-added-directly-to-cloudflare?"
    },
    {
      "level": "h2",
      "text": "403 Authentication error when creating DNS records using Terraform",
      "id": "403-authentication-error-when-creating-dns-records-using-terraform"
    },
    {
      "level": "h2",
      "text": "Why am I getting hundreds of random DNS records after adding my domain?",
      "id": "why-am-i-getting-hundreds-of-random-dns-records-after-adding-my-domain?"
    },
    {
      "level": "h2",
      "text": "What IP should I use for parked domain / redirect-only / originless setup?",
      "id": "what-ip-should-i-use-for-parked-domain-/-redirect-only-/-originless-setup?"
    },
    {
      "level": "h2",
      "text": "Why are DNS queries returning incorrect results?",
      "id": "why-are-dns-queries-returning-incorrect-results?"
    },
    {
      "level": "h2",
      "text": "Why have I received an email: Your Name Servers have Changed?",
      "id": "why-have-i-received-an-email:-your-name-servers-have-changed?"
    },
    {
      "level": "h2",
      "text": "Why am I getting a warning for hostname not covered even if I have a custom certificate?",
      "id": "why-am-i-getting-a-warning-for-hostname-not-covered-even-if-i-have-a-custom-certificate?"
    },
    {
      "level": "h2",
      "text": "I've updated my CNAME to a new SaaS provider, but I still see content from the old provider",
      "id": "i've-updated-my-cname-to-a-new-saas-provider,-but-i-still-see-content-from-the-old-provider"
    },
    {
      "level": "h2",
      "text": "How to",
      "id": "how-to"
    },
    {
      "level": "h2",
      "text": "Availability",
      "id": "availability"
    },
    {
      "level": "h2",
      "text": "Reference",
      "id": "reference"
    },
    {
      "level": "h3",
      "text": "DNS resolution",
      "id": "dns-resolution"
    },
    {
      "level": "h3",
      "text": "CNAME flattening",
      "id": "cname-flattening"
    },
    {
      "level": "h3",
      "text": "DDoS protection",
      "id": "ddos-protection"
    },
    {
      "level": "h3",
      "text": "Domain ownership",
      "id": "domain-ownership"
    },
    {
      "level": "h2",
      "text": "How to",
      "id": "how-to"
    },
    {
      "level": "h2",
      "text": "Availability",
      "id": "availability"
    },
    {
      "level": "h2",
      "text": "Availability",
      "id": "availability"
    },
    {
      "level": "h3",
      "text": "Access applications",
      "id": "access-applications"
    },
    {
      "level": "h2",
      "text": "Resources",
      "id": "resources"
    },
    {
      "level": "h2",
      "text": "Peer DNS server",
      "id": "peer-dns-server"
    },
    {
      "level": "h2",
      "text": "Availability",
      "id": "availability"
    },
    {
      "level": "h2",
      "text": "Background",
      "id": "background"
    },
    {
      "level": "h2",
      "text": "Scheduling multiple events with a single alarm",
      "id": "scheduling-multiple-events-with-a-single-alarm"
    },
    {
      "level": "h2",
      "text": "Storage methods",
      "id": "storage-methods"
    },
    {
      "level": "h3",
      "text": "`getAlarm`",
      "id": "`getalarm`"
    },
    {
      "level": "h3",
      "text": "`setAlarm`",
      "id": "`setalarm`"
    },
    {
      "level": "h3",
      "text": "`deleteAlarm`",
      "id": "`deletealarm`"
    },
    {
      "level": "h2",
      "text": "Handler methods",
      "id": "handler-methods"
    },
    {
      "level": "h3",
      "text": "`alarm`",
      "id": "`alarm`"
    },
    {
      "level": "h2",
      "text": "Example",
      "id": "example"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Methods",
      "id": "methods"
    },
    {
      "level": "h3",
      "text": "`fetch`",
      "id": "`fetch`"
    },
    {
      "level": "h3",
      "text": "`alarm`",
      "id": "`alarm`"
    },
    {
      "level": "h3",
      "text": "`webSocketMessage`",
      "id": "`websocketmessage`"
    },
    {
      "level": "h3",
      "text": "`webSocketClose`",
      "id": "`websocketclose`"
    },
    {
      "level": "h3",
      "text": "`webSocketError`",
      "id": "`websocketerror`"
    },
    {
      "level": "h2",
      "text": "Properties",
      "id": "properties"
    },
    {
      "level": "h3",
      "text": "`DurableObjectState`",
      "id": "`durableobjectstate`"
    },
    {
      "level": "h3",
      "text": "`Env`",
      "id": "`env`"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Description",
      "id": "description"
    },
    {
      "level": "h2",
      "text": "Attributes",
      "id": "attributes"
    },
    {
      "level": "h3",
      "text": "`running`",
      "id": "`running`"
    },
    {
      "level": "h2",
      "text": "Methods",
      "id": "methods"
    },
    {
      "level": "h3",
      "text": "`start`",
      "id": "`start`"
    },
    {
      "level": "h3",
      "text": "`destroy`",
      "id": "`destroy`"
    },
    {
      "level": "h3",
      "text": "`signal`",
      "id": "`signal`"
    },
    {
      "level": "h3",
      "text": "`getTcpPort`",
      "id": "`gettcpport`"
    },
    {
      "level": "h3",
      "text": "`monitor`",
      "id": "`monitor`"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Description",
      "id": "description"
    },
    {
      "level": "h2",
      "text": "Methods",
      "id": "methods"
    },
    {
      "level": "h3",
      "text": "`toString`",
      "id": "`tostring`"
    },
    {
      "level": "h3",
      "text": "`equals`",
      "id": "`equals`"
    },
    {
      "level": "h2",
      "text": "Properties",
      "id": "properties"
    },
    {
      "level": "h3",
      "text": "`name`",
      "id": "`name`"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Access storage",
      "id": "access-storage"
    },
    {
      "level": "h2",
      "text": "Asynchronous KV API",
      "id": "asynchronous-kv-api"
    },
    {
      "level": "h3",
      "text": "get",
      "id": "get"
    },
    {
      "level": "h3",
      "text": "put",
      "id": "put"
    },
    {
      "level": "h3",
      "text": "delete",
      "id": "delete"
    },
    {
      "level": "h3",
      "text": "list",
      "id": "list"
    },
    {
      "level": "h2",
      "text": "Alarms",
      "id": "alarms"
    },
    {
      "level": "h3",
      "text": "`getAlarm`",
      "id": "`getalarm`"
    },
    {
      "level": "h3",
      "text": "`setAlarm`",
      "id": "`setalarm`"
    },
    {
      "level": "h3",
      "text": "`deleteAlarm`",
      "id": "`deletealarm`"
    },
    {
      "level": "h2",
      "text": "Other",
      "id": "other"
    },
    {
      "level": "h3",
      "text": "`deleteAll`",
      "id": "`deleteall`"
    },
    {
      "level": "h3",
      "text": "`transactionSync`",
      "id": "`transactionsync`"
    },
    {
      "level": "h3",
      "text": "`transaction`",
      "id": "`transaction`"
    },
    {
      "level": "h3",
      "text": "`sync`",
      "id": "`sync`"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Description",
      "id": "description"
    },
    {
      "level": "h2",
      "text": "Methods",
      "id": "methods"
    },
    {
      "level": "h3",
      "text": "`idFromName`",
      "id": "`idfromname`"
    },
    {
      "level": "h3",
      "text": "`newUniqueId`",
      "id": "`newuniqueid`"
    },
    {
      "level": "h3",
      "text": "`idFromString`",
      "id": "`idfromstring`"
    },
    {
      "level": "h3",
      "text": "`get`",
      "id": "`get`"
    },
    {
      "level": "h3",
      "text": "`getByName`",
      "id": "`getbyname`"
    },
    {
      "level": "h3",
      "text": "`jurisdiction`",
      "id": "`jurisdiction`"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Access storage",
      "id": "access-storage"
    },
    {
      "level": "h2",
      "text": "SQL API",
      "id": "sql-api"
    },
    {
      "level": "h3",
      "text": "`exec`",
      "id": "`exec`"
    },
    {
      "level": "h3",
      "text": "`databaseSize`",
      "id": "`databasesize`"
    },
    {
      "level": "h2",
      "text": "PITR (Point In Time Recovery) API",
      "id": "pitr-(point-in-time-recovery)-api"
    },
    {
      "level": "h3",
      "text": "`getCurrentBookmark`",
      "id": "`getcurrentbookmark`"
    },
    {
      "level": "h3",
      "text": "`getBookmarkForTime`",
      "id": "`getbookmarkfortime`"
    },
    {
      "level": "h3",
      "text": "`onNextSessionRestoreBookmark`",
      "id": "`onnextsessionrestorebookmark`"
    },
    {
      "level": "h2",
      "text": "Synchronous KV API",
      "id": "synchronous-kv-api"
    },
    {
      "level": "h3",
      "text": "`get`",
      "id": "`get`"
    },
    {
      "level": "h3",
      "text": "`put`",
      "id": "`put`"
    },
    {
      "level": "h3",
      "text": "`delete`",
      "id": "`delete`"
    },
    {
      "level": "h3",
      "text": "`list`",
      "id": "`list`"
    },
    {
      "level": "h2",
      "text": "Asynchronous KV API",
      "id": "asynchronous-kv-api"
    },
    {
      "level": "h3",
      "text": "get",
      "id": "get"
    },
    {
      "level": "h3",
      "text": "put",
      "id": "put"
    },
    {
      "level": "h3",
      "text": "delete",
      "id": "delete"
    },
    {
      "level": "h3",
      "text": "list",
      "id": "list"
    },
    {
      "level": "h2",
      "text": "Alarms",
      "id": "alarms"
    },
    {
      "level": "h3",
      "text": "`getAlarm`",
      "id": "`getalarm`"
    },
    {
      "level": "h3",
      "text": "`setAlarm`",
      "id": "`setalarm`"
    },
    {
      "level": "h3",
      "text": "`deleteAlarm`",
      "id": "`deletealarm`"
    },
    {
      "level": "h2",
      "text": "Other",
      "id": "other"
    },
    {
      "level": "h3",
      "text": "`deleteAll`",
      "id": "`deleteall`"
    },
    {
      "level": "h3",
      "text": "`transactionSync`",
      "id": "`transactionsync`"
    },
    {
      "level": "h3",
      "text": "`transaction`",
      "id": "`transaction`"
    },
    {
      "level": "h3",
      "text": "`sync`",
      "id": "`sync`"
    },
    {
      "level": "h2",
      "text": "Storage properties",
      "id": "storage-properties"
    },
    {
      "level": "h3",
      "text": "`sql`",
      "id": "`sql`"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Description",
      "id": "description"
    },
    {
      "level": "h2",
      "text": "Methods and Properties",
      "id": "methods-and-properties"
    },
    {
      "level": "h3",
      "text": "`exports`",
      "id": "`exports`"
    },
    {
      "level": "h3",
      "text": "`waitUntil`",
      "id": "`waituntil`"
    },
    {
      "level": "h3",
      "text": "`blockConcurrencyWhile`",
      "id": "`blockconcurrencywhile`"
    },
    {
      "level": "h3",
      "text": "`acceptWebSocket`",
      "id": "`acceptwebsocket`"
    },
    {
      "level": "h3",
      "text": "`getWebSockets`",
      "id": "`getwebsockets`"
    },
    {
      "level": "h3",
      "text": "`setWebSocketAutoResponse`",
      "id": "`setwebsocketautoresponse`"
    },
    {
      "level": "h3",
      "text": "`getWebSocketAutoResponse`",
      "id": "`getwebsocketautoresponse`"
    },
    {
      "level": "h3",
      "text": "`getWebSocketAutoResponseTimestamp`",
      "id": "`getwebsocketautoresponsetimestamp`"
    },
    {
      "level": "h3",
      "text": "`setHibernatableWebSocketEventTimeout`",
      "id": "`sethibernatablewebsocketeventtimeout`"
    },
    {
      "level": "h3",
      "text": "`getHibernatableWebSocketEventTimeout`",
      "id": "`gethibernatablewebsocketeventtimeout`"
    },
    {
      "level": "h3",
      "text": "`getTags`",
      "id": "`gettags`"
    },
    {
      "level": "h3",
      "text": "`abort`",
      "id": "`abort`"
    },
    {
      "level": "h2",
      "text": "Properties",
      "id": "properties"
    },
    {
      "level": "h3",
      "text": "`id`",
      "id": "`id`"
    },
    {
      "level": "h3",
      "text": "`storage`",
      "id": "`storage`"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Description",
      "id": "description"
    },
    {
      "level": "h2",
      "text": "Properties",
      "id": "properties"
    },
    {
      "level": "h3",
      "text": "`id`",
      "id": "`id`"
    },
    {
      "level": "h3",
      "text": "`name`",
      "id": "`name`"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Examples",
      "id": "examples"
    },
    {
      "level": "h2",
      "text": "Access storage",
      "id": "access-storage"
    },
    {
      "level": "h3",
      "text": "Create SQLite-backed Durable Object class",
      "id": "create-sqlite-backed-durable-object-class"
    },
    {
      "level": "h3",
      "text": "Initialize instance variables from storage",
      "id": "initialize-instance-variables-from-storage"
    },
    {
      "level": "h3",
      "text": "Remove a Durable Object's storage",
      "id": "remove-a-durable-object's-storage"
    },
    {
      "level": "h2",
      "text": "SQL API Examples",
      "id": "sql-api-examples"
    },
    {
      "level": "h2",
      "text": "TypeScript and query results",
      "id": "typescript-and-query-results"
    },
    {
      "level": "h2",
      "text": "Indexes in SQLite",
      "id": "indexes-in-sqlite"
    },
    {
      "level": "h2",
      "text": "SQL in Durable Objects vs D1",
      "id": "sql-in-durable-objects-vs-d1"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Invoking methods on a Durable Object",
      "id": "invoking-methods-on-a-durable-object"
    },
    {
      "level": "h3",
      "text": "Invoke RPC methods",
      "id": "invoke-rpc-methods"
    },
    {
      "level": "h3",
      "text": "Invoking the `fetch` handler",
      "id": "invoking-the-`fetch`-handler"
    },
    {
      "level": "h2",
      "text": "When to use Durable Objects",
      "id": "when-to-use-durable-objects"
    },
    {
      "level": "h3",
      "text": "Use Durable Objects for stateful coordination, not stateless request handling",
      "id": "use-durable-objects-for-stateful-coordination,-not-stateless-request-handling"
    },
    {
      "level": "h2",
      "text": "Design and sharding",
      "id": "design-and-sharding"
    },
    {
      "level": "h3",
      "text": "Model your Durable Objects around your \"atom\" of coordination",
      "id": "model-your-durable-objects-around-your-\"atom\"-of-coordination"
    },
    {
      "level": "h3",
      "text": "Use deterministic IDs for predictable routing",
      "id": "use-deterministic-ids-for-predictable-routing"
    },
    {
      "level": "h3",
      "text": "Use parent-child relationships for related entities",
      "id": "use-parent-child-relationships-for-related-entities"
    },
    {
      "level": "h3",
      "text": "Consider location hints for latency-sensitive applications",
      "id": "consider-location-hints-for-latency-sensitive-applications"
    },
    {
      "level": "h2",
      "text": "Storage and state",
      "id": "storage-and-state"
    },
    {
      "level": "h3",
      "text": "Use SQLite-backed Durable Objects",
      "id": "use-sqlite-backed-durable-objects"
    },
    {
      "level": "h3",
      "text": "Initialize storage and run migrations in the constructor",
      "id": "initialize-storage-and-run-migrations-in-the-constructor"
    },
    {
      "level": "h3",
      "text": "Understand the difference between in-memory state and persistent storage",
      "id": "understand-the-difference-between-in-memory-state-and-persistent-storage"
    },
    {
      "level": "h3",
      "text": "Create indexes for frequently-queried columns",
      "id": "create-indexes-for-frequently-queried-columns"
    },
    {
      "level": "h3",
      "text": "Understand how input and output gates work",
      "id": "understand-how-input-and-output-gates-work"
    },
    {
      "level": "h3",
      "text": "Avoid race conditions with non-storage I/O",
      "id": "avoid-race-conditions-with-non-storage-i/o"
    },
    {
      "level": "h3",
      "text": "Use `blockConcurrencyWhile()` sparingly",
      "id": "use-`blockconcurrencywhile()`-sparingly"
    },
    {
      "level": "h2",
      "text": "Communication and API design",
      "id": "communication-and-api-design"
    },
    {
      "level": "h3",
      "text": "Use RPC methods instead of the `fetch()` handler",
      "id": "use-rpc-methods-instead-of-the-`fetch()`-handler"
    },
    {
      "level": "h3",
      "text": "Initialize Durable Objects explicitly with an `init()` method",
      "id": "initialize-durable-objects-explicitly-with-an-`init()`-method"
    },
    {
      "level": "h3",
      "text": "Always `await` RPC calls",
      "id": "always-`await`-rpc-calls"
    },
    {
      "level": "h2",
      "text": "Error handling",
      "id": "error-handling"
    },
    {
      "level": "h3",
      "text": "Handle errors and use exception boundaries",
      "id": "handle-errors-and-use-exception-boundaries"
    },
    {
      "level": "h2",
      "text": "WebSockets and real-time",
      "id": "websockets-and-real-time"
    },
    {
      "level": "h3",
      "text": "Use the Hibernatable WebSockets API for cost efficiency",
      "id": "use-the-hibernatable-websockets-api-for-cost-efficiency"
    },
    {
      "level": "h3",
      "text": "Use `serializeAttachment()` to persist per-connection state",
      "id": "use-`serializeattachment()`-to-persist-per-connection-state"
    },
    {
      "level": "h2",
      "text": "Scheduling and lifecycle",
      "id": "scheduling-and-lifecycle"
    },
    {
      "level": "h3",
      "text": "Use alarms for per-entity scheduled tasks",
      "id": "use-alarms-for-per-entity-scheduled-tasks"
    },
    {
      "level": "h3",
      "text": "Make alarm handlers idempotent",
      "id": "make-alarm-handlers-idempotent"
    },
    {
      "level": "h3",
      "text": "Clean up storage with `deleteAll()`",
      "id": "clean-up-storage-with-`deleteall()`"
    },
    {
      "level": "h2",
      "text": "Anti-patterns to avoid",
      "id": "anti-patterns-to-avoid"
    },
    {
      "level": "h3",
      "text": "Do not use a single Durable Object as a global singleton",
      "id": "do-not-use-a-single-durable-object-as-a-global-singleton"
    },
    {
      "level": "h2",
      "text": "Testing and migrations",
      "id": "testing-and-migrations"
    },
    {
      "level": "h3",
      "text": "Test with Vitest and plan for class migrations",
      "id": "test-with-vitest-and-plan-for-class-migrations"
    },
    {
      "level": "h2",
      "text": "How exceptions are thrown",
      "id": "how-exceptions-are-thrown"
    },
    {
      "level": "h2",
      "text": "Example",
      "id": "example"
    },
    {
      "level": "h2",
      "text": "What are WebSockets?",
      "id": "what-are-websockets?"
    },
    {
      "level": "h2",
      "text": "Durable Objects' Hibernation WebSocket API",
      "id": "durable-objects'-hibernation-websocket-api"
    },
    {
      "level": "h3",
      "text": "How does Durable Object Hibernation work with WebSockets?",
      "id": "how-does-durable-object-hibernation-work-with-websockets?"
    },
    {
      "level": "h3",
      "text": "Example",
      "id": "example"
    },
    {
      "level": "h3",
      "text": "Extended methods",
      "id": "extended-methods"
    },
    {
      "level": "h2",
      "text": "WebSocket Standard API",
      "id": "websocket-standard-api"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Durable Object Lifecycle state transitions",
      "id": "durable-object-lifecycle-state-transitions"
    },
    {
      "level": "h2",
      "text": "Durable Objects highlights",
      "id": "durable-objects-highlights"
    },
    {
      "level": "h2",
      "text": "Durable Objects features",
      "id": "durable-objects-features"
    },
    {
      "level": "h3",
      "text": "In-memory state",
      "id": "in-memory-state"
    },
    {
      "level": "h3",
      "text": "Storage API",
      "id": "storage-api"
    },
    {
      "level": "h3",
      "text": "Alarms API",
      "id": "alarms-api"
    },
    {
      "level": "h3",
      "text": "WebSockets",
      "id": "websockets"
    },
    {
      "level": "h3",
      "text": "RPC",
      "id": "rpc"
    },
    {
      "level": "h2",
      "text": "Actor programming model",
      "id": "actor-programming-model"
    },
    {
      "level": "h2",
      "text": "Durable Objects in Cloudflare",
      "id": "durable-objects-in-cloudflare"
    },
    {
      "level": "h2",
      "text": "Get started",
      "id": "get-started"
    },
    {
      "level": "h2",
      "text": "Footnotes",
      "id": "footnotes"
    },
    {
      "level": "h3",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h3",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "Example Durable Object",
      "id": "example-durable-object"
    },
    {
      "level": "h2",
      "text": "Configure Vitest",
      "id": "configure-vitest"
    },
    {
      "level": "h2",
      "text": "Define types for tests",
      "id": "define-types-for-tests"
    },
    {
      "level": "h2",
      "text": "Writing tests",
      "id": "writing-tests"
    },
    {
      "level": "h3",
      "text": "Unit tests with direct Durable Object access",
      "id": "unit-tests-with-direct-durable-object-access"
    },
    {
      "level": "h3",
      "text": "Integration tests with SELF",
      "id": "integration-tests-with-self"
    },
    {
      "level": "h3",
      "text": "Direct access to Durable Object internals",
      "id": "direct-access-to-durable-object-internals"
    },
    {
      "level": "h3",
      "text": "Test isolation",
      "id": "test-isolation"
    },
    {
      "level": "h3",
      "text": "Testing SQLite storage",
      "id": "testing-sqlite-storage"
    },
    {
      "level": "h3",
      "text": "Testing alarms",
      "id": "testing-alarms"
    },
    {
      "level": "h2",
      "text": "Running tests",
      "id": "running-tests"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h3",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h3",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "View Data Studio",
      "id": "view-data-studio"
    },
    {
      "level": "h2",
      "text": "Audit logging",
      "id": "audit-logging"
    },
    {
      "level": "h2",
      "text": "View metrics and analytics",
      "id": "view-metrics-and-analytics"
    },
    {
      "level": "h2",
      "text": "View logs",
      "id": "view-logs"
    },
    {
      "level": "h2",
      "text": "Query via the GraphQL API",
      "id": "query-via-the-graphql-api"
    },
    {
      "level": "h3",
      "text": "WebSocket metrics",
      "id": "websocket-metrics"
    },
    {
      "level": "h2",
      "text": "Example GraphQL query for Durable Objects",
      "id": "example-graphql-query-for-durable-objects"
    },
    {
      "level": "h2",
      "text": "Additional resources",
      "id": "additional-resources"
    },
    {
      "level": "h2",
      "text": "FAQs",
      "id": "faqs"
    },
    {
      "level": "h3",
      "text": "How can I identify which Durable Object instance generated a log entry?",
      "id": "how-can-i-identify-which-durable-object-instance-generated-a-log-entry?"
    },
    {
      "level": "h2",
      "text": "Debugging",
      "id": "debugging"
    },
    {
      "level": "h2",
      "text": "Common errors",
      "id": "common-errors"
    },
    {
      "level": "h3",
      "text": "No event handlers were registered. This script does nothing.",
      "id": "no-event-handlers-were-registered.-this-script-does-nothing."
    },
    {
      "level": "h3",
      "text": "Cannot apply `--delete-class` migration to class.",
      "id": "cannot-apply-`--delete-class`-migration-to-class."
    },
    {
      "level": "h3",
      "text": "Durable Object is overloaded.",
      "id": "durable-object-is-overloaded."
    },
    {
      "level": "h3",
      "text": "Your account is generating too much load on Durable Objects. Please back off and try again later.",
      "id": "your-account-is-generating-too-much-load-on-durable-objects.-please-back-off-and-try-again-later."
    },
    {
      "level": "h3",
      "text": "Durable Object reset because its code was updated.",
      "id": "durable-object-reset-because-its-code-was-updated."
    },
    {
      "level": "h3",
      "text": "Durable Object storage operation exceeded timeout which caused object to be reset.",
      "id": "durable-object-storage-operation-exceeded-timeout-which-caused-object-to-be-reset."
    },
    {
      "level": "h3",
      "text": "Your account is doing too many concurrent storage operations. Please back off and try again later.",
      "id": "your-account-is-doing-too-many-concurrent-storage-operations.-please-back-off-and-try-again-later."
    },
    {
      "level": "h2",
      "text": "Global uniqueness",
      "id": "global-uniqueness"
    },
    {
      "level": "h2",
      "text": "Code updates",
      "id": "code-updates"
    },
    {
      "level": "h2",
      "text": "Development tools",
      "id": "development-tools"
    },
    {
      "level": "h2",
      "text": "Alarms in local development",
      "id": "alarms-in-local-development"
    },
    {
      "level": "h2",
      "text": "SQLite-backed Durable Objects general limits",
      "id": "sqlite-backed-durable-objects-general-limits"
    },
    {
      "level": "h3",
      "text": "SQL storage limits",
      "id": "sql-storage-limits"
    },
    {
      "level": "h2",
      "text": "Key-value backed Durable Objects general limits",
      "id": "key-value-backed-durable-objects-general-limits"
    },
    {
      "level": "h2",
      "text": "Frequently Asked Questions",
      "id": "frequently-asked-questions"
    },
    {
      "level": "h3",
      "text": "How much work can a single Durable Object do?",
      "id": "how-much-work-can-a-single-durable-object-do?"
    },
    {
      "level": "h3",
      "text": "How many Durable Objects can I create?",
      "id": "how-many-durable-objects-can-i-create?"
    },
    {
      "level": "h3",
      "text": "Can I increase Durable Objects' CPU limit?",
      "id": "can-i-increase-durable-objects'-cpu-limit?"
    },
    {
      "level": "h2",
      "text": "Footnotes",
      "id": "footnotes"
    },
    {
      "level": "h2",
      "text": "Compute billing",
      "id": "compute-billing"
    },
    {
      "level": "h2",
      "text": "Storage billing",
      "id": "storage-billing"
    },
    {
      "level": "h3",
      "text": "SQLite storage backend",
      "id": "sqlite-storage-backend"
    },
    {
      "level": "h3",
      "text": "Key-value storage backend",
      "id": "key-value-storage-backend"
    },
    {
      "level": "h2",
      "text": "Compute billing examples",
      "id": "compute-billing-examples"
    },
    {
      "level": "h3",
      "text": "Example 1",
      "id": "example-1"
    },
    {
      "level": "h3",
      "text": "Example 2",
      "id": "example-2"
    },
    {
      "level": "h3",
      "text": "Example 3",
      "id": "example-3"
    },
    {
      "level": "h3",
      "text": "Example 4",
      "id": "example-4"
    },
    {
      "level": "h2",
      "text": "Frequently Asked Questions",
      "id": "frequently-asked-questions"
    },
    {
      "level": "h3",
      "text": "When does a Durable Object incur duration charges?",
      "id": "when-does-a-durable-object-incur-duration-charges?"
    },
    {
      "level": "h3",
      "text": "Does an empty table / SQLite database contribute to my storage?",
      "id": "does-an-empty-table-/-sqlite-database-contribute-to-my-storage?"
    },
    {
      "level": "h3",
      "text": "Does metadata stored in Durable Objects count towards my storage?",
      "id": "does-metadata-stored-in-durable-objects-count-towards-my-storage?"
    },
    {
      "level": "h2",
      "text": "Restrict Durable Objects to a jurisdiction",
      "id": "restrict-durable-objects-to-a-jurisdiction"
    },
    {
      "level": "h3",
      "text": "Supported locations",
      "id": "supported-locations"
    },
    {
      "level": "h2",
      "text": "Provide a location hint",
      "id": "provide-a-location-hint"
    },
    {
      "level": "h3",
      "text": "Supported locations",
      "id": "supported-locations"
    },
    {
      "level": "h2",
      "text": "Additional resources",
      "id": "additional-resources"
    },
    {
      "level": "h2",
      "text": "Encryption at Rest",
      "id": "encryption-at-rest"
    },
    {
      "level": "h2",
      "text": "Encryption in Transit",
      "id": "encryption-in-transit"
    },
    {
      "level": "h2",
      "text": "Compliance",
      "id": "compliance"
    },
    {
      "level": "h2",
      "text": "Create migration",
      "id": "create-migration"
    },
    {
      "level": "h3",
      "text": "Create Durable Object class with key-value storage",
      "id": "create-durable-object-class-with-key-value-storage"
    },
    {
      "level": "h2",
      "text": "Delete migration",
      "id": "delete-migration"
    },
    {
      "level": "h2",
      "text": "Rename migration",
      "id": "rename-migration"
    },
    {
      "level": "h2",
      "text": "Transfer migration",
      "id": "transfer-migration"
    },
    {
      "level": "h2",
      "text": "Migration Wrangler configuration",
      "id": "migration-wrangler-configuration"
    },
    {
      "level": "h2",
      "text": "Wrangler environments",
      "id": "wrangler-environments"
    },
    {
      "level": "h3",
      "text": "Migration environments",
      "id": "migration-environments"
    },
    {
      "level": "h2",
      "text": "Local development",
      "id": "local-development"
    },
    {
      "level": "h2",
      "text": "Remote development",
      "id": "remote-development"
    },
    {
      "level": "h2",
      "text": "Pricing",
      "id": "pricing"
    },
    {
      "level": "h3",
      "text": "When does a Durable Object incur duration charges?",
      "id": "when-does-a-durable-object-incur-duration-charges?"
    },
    {
      "level": "h3",
      "text": "Does an empty table / SQLite database contribute to my storage?",
      "id": "does-an-empty-table-/-sqlite-database-contribute-to-my-storage?"
    },
    {
      "level": "h3",
      "text": "Does metadata stored in Durable Objects count towards my storage?",
      "id": "does-metadata-stored-in-durable-objects-count-towards-my-storage?"
    },
    {
      "level": "h2",
      "text": "Limits",
      "id": "limits"
    },
    {
      "level": "h3",
      "text": "How much work can a single Durable Object do?",
      "id": "how-much-work-can-a-single-durable-object-do?"
    },
    {
      "level": "h3",
      "text": "How many Durable Objects can I create?",
      "id": "how-many-durable-objects-can-i-create?"
    },
    {
      "level": "h3",
      "text": "Can I increase Durable Objects' CPU limit?",
      "id": "can-i-increase-durable-objects'-cpu-limit?"
    },
    {
      "level": "h2",
      "text": "Metrics and analytics",
      "id": "metrics-and-analytics"
    },
    {
      "level": "h3",
      "text": "How can I identify which Durable Object instance generated a log entry?",
      "id": "how-can-i-identify-which-durable-object-instance-generated-a-log-entry?"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "1. Create a new project",
      "id": "1.-create-a-new-project"
    },
    {
      "level": "h2",
      "text": "2. Create the frontend",
      "id": "2.-create-the-frontend"
    },
    {
      "level": "h2",
      "text": "3. Create table for each flight",
      "id": "3.-create-table-for-each-flight"
    },
    {
      "level": "h2",
      "text": "4. Add methods to the Durable Object",
      "id": "4.-add-methods-to-the-durable-object"
    },
    {
      "level": "h2",
      "text": "5. Handle WebSocket connections",
      "id": "5.-handle-websocket-connections"
    },
    {
      "level": "h2",
      "text": "6. Test the application",
      "id": "6.-test-the-application"
    },
    {
      "level": "h2",
      "text": "7. Deploy the application",
      "id": "7.-deploy-the-application"
    },
    {
      "level": "h2",
      "text": "Summary",
      "id": "summary"
    },
    {
      "level": "h2",
      "text": "Demos",
      "id": "demos"
    },
    {
      "level": "h2",
      "text": "Add an Email worker",
      "id": "add-an-email-worker"
    },
    {
      "level": "h2",
      "text": "Edit an Email Worker",
      "id": "edit-an-email-worker"
    },
    {
      "level": "h2",
      "text": "Rename Email Worker",
      "id": "rename-email-worker"
    },
    {
      "level": "h2",
      "text": "Edit route",
      "id": "edit-route"
    },
    {
      "level": "h2",
      "text": "Delete an Email Worker",
      "id": "delete-an-email-worker"
    },
    {
      "level": "h2",
      "text": "Receive an email",
      "id": "receive-an-email"
    },
    {
      "level": "h2",
      "text": "Send an email",
      "id": "send-an-email"
    },
    {
      "level": "h2",
      "text": "Reply to and forward messages",
      "id": "reply-to-and-forward-messages"
    },
    {
      "level": "h2",
      "text": "Background",
      "id": "background"
    },
    {
      "level": "h2",
      "text": "Syntax: ES modules",
      "id": "syntax:-es-modules"
    },
    {
      "level": "h3",
      "text": "Parameters",
      "id": "parameters"
    },
    {
      "level": "h2",
      "text": "Syntax: Service Worker",
      "id": "syntax:-service-worker"
    },
    {
      "level": "h3",
      "text": "Properties",
      "id": "properties"
    },
    {
      "level": "h2",
      "text": "`ForwardableEmailMessage` definition",
      "id": "`forwardableemailmessage`-definition"
    },
    {
      "level": "h2",
      "text": "`EmailMessage` definition",
      "id": "`emailmessage`-definition"
    },
    {
      "level": "h2",
      "text": "Types of bindings",
      "id": "types-of-bindings"
    },
    {
      "level": "h2",
      "text": "Example Worker",
      "id": "example-worker"
    },
    {
      "level": "h2",
      "text": "Email Routing summary",
      "id": "email-routing-summary"
    },
    {
      "level": "h2",
      "text": "Activity Log",
      "id": "activity-log"
    },
    {
      "level": "h2",
      "text": "Delete and disable Email Routing",
      "id": "delete-and-disable-email-routing"
    },
    {
      "level": "h2",
      "text": "Unlock and keep DNS records",
      "id": "unlock-and-keep-dns-records"
    },
    {
      "level": "h2",
      "text": "Custom addresses",
      "id": "custom-addresses"
    },
    {
      "level": "h3",
      "text": "Email rule actions",
      "id": "email-rule-actions"
    },
    {
      "level": "h3",
      "text": "Disable an email rule",
      "id": "disable-an-email-rule"
    },
    {
      "level": "h3",
      "text": "Edit custom addresses",
      "id": "edit-custom-addresses"
    },
    {
      "level": "h2",
      "text": "Catch-all address",
      "id": "catch-all-address"
    },
    {
      "level": "h2",
      "text": "Subaddressing",
      "id": "subaddressing"
    },
    {
      "level": "h2",
      "text": "Destination addresses",
      "id": "destination-addresses"
    },
    {
      "level": "h2",
      "text": "Email DNS records",
      "id": "email-dns-records"
    },
    {
      "level": "h3",
      "text": "Start disabling",
      "id": "start-disabling"
    },
    {
      "level": "h3",
      "text": "Lock DNS records",
      "id": "lock-dns-records"
    },
    {
      "level": "h2",
      "text": "View DNS records",
      "id": "view-dns-records"
    },
    {
      "level": "h2",
      "text": "Add user",
      "id": "add-user"
    },
    {
      "level": "h2",
      "text": "Edit user",
      "id": "edit-user"
    },
    {
      "level": "h2",
      "text": "Delete user",
      "id": "delete-user"
    },
    {
      "level": "h2",
      "text": "Reset two-factor authentication",
      "id": "reset-two-factor-authentication"
    },
    {
      "level": "h2",
      "text": "Parent accounts",
      "id": "parent-accounts"
    },
    {
      "level": "h2",
      "text": "Child accounts",
      "id": "child-accounts"
    },
    {
      "level": "h3",
      "text": "Child users",
      "id": "child-users"
    },
    {
      "level": "h3",
      "text": "Parent users",
      "id": "parent-users"
    },
    {
      "level": "h2",
      "text": "SAML configuration options",
      "id": "saml-configuration-options"
    },
    {
      "level": "h2",
      "text": "Setup",
      "id": "setup"
    },
    {
      "level": "h2",
      "text": "Create service account",
      "id": "create-service-account"
    },
    {
      "level": "h2",
      "text": "Rotate private key",
      "id": "rotate-private-key"
    },
    {
      "level": "h2",
      "text": "Benefits",
      "id": "benefits"
    },
    {
      "level": "h2",
      "text": "Limitations",
      "id": "limitations"
    },
    {
      "level": "h2",
      "text": "Get started",
      "id": "get-started"
    },
    {
      "level": "h2",
      "text": "Benefits",
      "id": "benefits"
    },
    {
      "level": "h2",
      "text": "Limitations",
      "id": "limitations"
    },
    {
      "level": "h2",
      "text": "Get started",
      "id": "get-started"
    },
    {
      "level": "h2",
      "text": "Quarantine emails by disposition",
      "id": "quarantine-emails-by-disposition"
    },
    {
      "level": "h2",
      "text": "Access Admin Quarantine",
      "id": "access-admin-quarantine"
    },
    {
      "level": "h2",
      "text": "Release quarantined emails",
      "id": "release-quarantined-emails"
    },
    {
      "level": "h2",
      "text": "How to submit phish",
      "id": "how-to-submit-phish"
    },
    {
      "level": "h2",
      "text": "What happens after a phish submission",
      "id": "what-happens-after-a-phish-submission"
    },
    {
      "level": "h3",
      "text": "Phish submission feedback",
      "id": "phish-submission-feedback"
    },
    {
      "level": "h3",
      "text": "Phish Submission Response (beta)",
      "id": "phish-submission-response-(beta)"
    },
    {
      "level": "h2",
      "text": "False positives",
      "id": "false-positives"
    },
    {
      "level": "h2",
      "text": "False negatives",
      "id": "false-negatives"
    },
    {
      "level": "h2",
      "text": "Retraction options",
      "id": "retraction-options"
    },
    {
      "level": "h2",
      "text": "Retraction metrics",
      "id": "retraction-metrics"
    },
    {
      "level": "h2",
      "text": "Dispositions",
      "id": "dispositions"
    },
    {
      "level": "h3",
      "text": "Available values",
      "id": "available-values"
    },
    {
      "level": "h3",
      "text": "Header structure",
      "id": "header-structure"
    },
    {
      "level": "h2",
      "text": "Attributes",
      "id": "attributes"
    },
    {
      "level": "h3",
      "text": "Available values",
      "id": "available-values"
    },
    {
      "level": "h3",
      "text": "Header structure",
      "id": "header-structure"
    },
    {
      "level": "h2",
      "text": "ActiveSensors",
      "id": "activesensors"
    },
    {
      "level": "h2",
      "text": "SPARSE (Small Pattern Analytics Engine)",
      "id": "sparse-(small-pattern-analytics-engine)"
    },
    {
      "level": "h2",
      "text": "IP reputation",
      "id": "ip-reputation"
    },
    {
      "level": "h2",
      "text": "Sample attack types and detections",
      "id": "sample-attack-types-and-detections"
    },
    {
      "level": "h2",
      "text": "Email evaluation",
      "id": "email-evaluation"
    },
    {
      "level": "h2",
      "text": "Dashboard",
      "id": "dashboard"
    },
    {
      "level": "h2",
      "text": "Logs preview",
      "id": "logs-preview"
    },
    {
      "level": "h2",
      "text": "In the dashboard",
      "id": "in-the-dashboard"
    },
    {
      "level": "h2",
      "text": "Through an email subscription",
      "id": "through-an-email-subscription"
    },
    {
      "level": "h2",
      "text": "Search terms",
      "id": "search-terms"
    },
    {
      "level": "h2",
      "text": "Fielded Search",
      "id": "fielded-search"
    },
    {
      "level": "h2",
      "text": "Freeform Search",
      "id": "freeform-search"
    },
    {
      "level": "h2",
      "text": "Search tips",
      "id": "search-tips"
    },
    {
      "level": "h3",
      "text": "Parameter filtering",
      "id": "parameter-filtering"
    },
    {
      "level": "h3",
      "text": "`message_id`",
      "id": "`message_id`"
    },
    {
      "level": "h2",
      "text": "Connect a SIEM tool",
      "id": "connect-a-siem-tool"
    },
    {
      "level": "h3",
      "text": "1. Set up your SIEM tool",
      "id": "1.-set-up-your-siem-tool"
    },
    {
      "level": "h3",
      "text": "2. Create a webhook",
      "id": "2.-create-a-webhook"
    },
    {
      "level": "h2",
      "text": "Differences from other Cloudflare APIs",
      "id": "differences-from-other-cloudflare-apis"
    },
    {
      "level": "h2",
      "text": "Differences from other Cloudflare APIs",
      "id": "differences-from-other-cloudflare-apis"
    },
    {
      "level": "h2",
      "text": "Create a firewall rule",
      "id": "create-a-firewall-rule"
    },
    {
      "level": "h2",
      "text": "Manage rules",
      "id": "manage-rules"
    },
    {
      "level": "h3",
      "text": "Edit rule",
      "id": "edit-rule"
    },
    {
      "level": "h3",
      "text": "Enable or disable rule",
      "id": "enable-or-disable-rule"
    },
    {
      "level": "h3",
      "text": "Delete rule",
      "id": "delete-rule"
    },
    {
      "level": "h3",
      "text": "Order rules",
      "id": "order-rules"
    },
    {
      "level": "h2",
      "text": "Test firewall rules with Rule Preview",
      "id": "test-firewall-rules-with-rule-preview"
    },
    {
      "level": "h2",
      "text": "Test a firewall rule with Rule Preview",
      "id": "test-a-firewall-rule-with-rule-preview"
    },
    {
      "level": "h2",
      "text": "Important notes",
      "id": "important-notes"
    },
    {
      "level": "h2",
      "text": "Supported actions",
      "id": "supported-actions"
    },
    {
      "level": "h2",
      "text": "Notes about challenge actions",
      "id": "notes-about-challenge-actions"
    },
    {
      "level": "h2",
      "text": "Managing rule evaluation by list order",
      "id": "managing-rule-evaluation-by-list-order"
    },
    {
      "level": "h2",
      "text": "Managing rule evaluation by priority order",
      "id": "managing-rule-evaluation-by-priority-order"
    },
    {
      "level": "h3",
      "text": "Enable priority ordering",
      "id": "enable-priority-ordering"
    },
    {
      "level": "h3",
      "text": "Set rule priority",
      "id": "set-rule-priority"
    },
    {
      "level": "h2",
      "text": "Working with priority ordering",
      "id": "working-with-priority-ordering"
    },
    {
      "level": "h2",
      "text": "Why URL normalization is important",
      "id": "why-url-normalization-is-important"
    },
    {
      "level": "h2",
      "text": "Recommended procedure",
      "id": "recommended-procedure"
    },
    {
      "level": "h3",
      "text": "1. Review and update firewall rules",
      "id": "1.-review-and-update-firewall-rules"
    },
    {
      "level": "h3",
      "text": "2. Enable URL normalization",
      "id": "2.-enable-url-normalization"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Account name",
      "id": "account-name"
    },
    {
      "level": "h2",
      "text": "Best practices",
      "id": "best-practices"
    },
    {
      "level": "h2",
      "text": "Interact with Cloudflare",
      "id": "interact-with-cloudflare"
    },
    {
      "level": "h2",
      "text": "Copy your Account ID",
      "id": "copy-your-account-id"
    },
    {
      "level": "h3",
      "text": "Users with a single account",
      "id": "users-with-a-single-account"
    },
    {
      "level": "h2",
      "text": "Copy your Zone ID",
      "id": "copy-your-zone-id"
    },
    {
      "level": "h2",
      "text": "Find account ID (Workers and Pages)",
      "id": "find-account-id-(workers-and-pages)"
    },
    {
      "level": "h2",
      "text": "The token is not verified",
      "id": "the-token-is-not-verified"
    },
    {
      "level": "h2",
      "text": "The token has incorrect permissions",
      "id": "the-token-has-incorrect-permissions"
    },
    {
      "level": "h2",
      "text": "The incorrect syntax is used",
      "id": "the-incorrect-syntax-is-used"
    },
    {
      "level": "h2",
      "text": "You have the incorrect user permissions",
      "id": "you-have-the-incorrect-user-permissions"
    },
    {
      "level": "h2",
      "text": "User profiles",
      "id": "user-profiles"
    },
    {
      "level": "h2",
      "text": "Accounts",
      "id": "accounts"
    },
    {
      "level": "h2",
      "text": "Zones",
      "id": "zones"
    },
    {
      "level": "h2",
      "text": "Footnotes",
      "id": "footnotes"
    },
    {
      "level": "h2",
      "text": "Allow Cloudflare IP addresses",
      "id": "allow-cloudflare-ip-addresses"
    },
    {
      "level": "h2",
      "text": "Configure origin server",
      "id": "configure-origin-server"
    },
    {
      "level": "h3",
      "text": "Allowlist Cloudflare IP addresses",
      "id": "allowlist-cloudflare-ip-addresses"
    }
  ],
  "url": "llms-txt#escape-with-`-instead-of-\\",
  "links": []
}