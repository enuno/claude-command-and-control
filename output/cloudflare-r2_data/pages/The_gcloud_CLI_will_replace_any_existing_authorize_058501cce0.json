{
  "title": "The gcloud CLI will replace any existing authorized networks with the list you provide here.",
  "content": "gcloud sql instances patch YOUR_INSTANCE_NAME --authorized-networks=\"0.0.0.0/0\"\ntxt\npostgres://USERNAME:PASSWORD@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\nsh\n     npx wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=\"postgres://user:password@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\"\n     jsonc\n       {\n         \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n         \"name\": \"hyperdrive-example\",\n         \"main\": \"src/index.ts\",\n         \"compatibility_date\": \"2024-08-21\",\n         \"compatibility_flags\": [\n           \"nodejs_compat\"\n         ],\n         \"hyperdrive\": [\n           {\n             \"binding\": \"HYPERDRIVE\",\n             \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n           }\n         ]\n       }\n       toml\n       name = \"hyperdrive-example\"\n       main = \"src/index.ts\"\n       compatibility_date = \"2024-08-21\"\n       compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n       [[hyperdrive]]\n       binding = \"HYPERDRIVE\"\n       id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n       jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"hyperdrive-example\",\n    \"main\": \"src/index.ts\",\n    \"compatibility_date\": \"2024-08-21\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n      }\n    ]\n  }\n  toml\n  name = \"hyperdrive-example\"\n  main = \"src/index.ts\"\n  compatibility_date = \"2024-08-21\"\n  compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n  [[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n  sh\n  npm i pg@>8.16.3\n  sh\n  yarn add pg@>8.16.3\n  sh\n  pnpm add pg@>8.16.3\n  sh\n  npm i -D @types/pg\n  sh\n  yarn add -D @types/pg\n  sh\n  pnpm add -D @types/pg\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"compatibility_date\": \"2024-09-23\",\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<your-hyperdrive-id-here>\"\n      }\n    ]\n  }\n  toml\n  # required for database drivers to function\n  compatibility_flags = [\"nodejs_compat\"]\n  compatibility_date = \"2024-09-23\"\n\n[[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<your-hyperdrive-id-here>\"\n  ts\n// filepath: src/index.ts\nimport { Client } from \"pg\";\n\nexport default {\n  async fetch(\n    request: Request,\n    env: Env,\n    ctx: ExecutionContext,\n  ): Promise<Response> {\n    // Create a new client instance for each request.\n    const client = new Client({\n      connectionString: env.HYPERDRIVE.connectionString,\n    });\n\ntry {\n      // Connect to the database\n      await client.connect();\n      console.log(\"Connected to PostgreSQL database\");\n\n// Perform a simple query\n      const result = await client.query(\"SELECT * FROM pg_tables\");\n\nreturn Response.json({\n        success: true,\n        result: result.rows,\n      });\n    } catch (error: any) {\n      console.error(\"Database error:\", error.message);\n\nnew Response(\"Internal error occurred\", { status: 500 });\n    }\n  },\n};\ntxt\npostgres://USERNAME:PASSWORD@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\nsh\n     npx wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=\"postgres://user:password@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\"\n     jsonc\n       {\n         \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n         \"name\": \"hyperdrive-example\",\n         \"main\": \"src/index.ts\",\n         \"compatibility_date\": \"2024-08-21\",\n         \"compatibility_flags\": [\n           \"nodejs_compat\"\n         ],\n         \"hyperdrive\": [\n           {\n             \"binding\": \"HYPERDRIVE\",\n             \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n           }\n         ]\n       }\n       toml\n       name = \"hyperdrive-example\"\n       main = \"src/index.ts\"\n       compatibility_date = \"2024-08-21\"\n       compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n       [[hyperdrive]]\n       binding = \"HYPERDRIVE\"\n       id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n       jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"hyperdrive-example\",\n    \"main\": \"src/index.ts\",\n    \"compatibility_date\": \"2024-08-21\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n      }\n    ]\n  }\n  toml\n  name = \"hyperdrive-example\"\n  main = \"src/index.ts\"\n  compatibility_date = \"2024-08-21\"\n  compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n  [[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n  sh\n  npm i pg@>8.16.3\n  sh\n  yarn add pg@>8.16.3\n  sh\n  pnpm add pg@>8.16.3\n  sh\n  npm i -D @types/pg\n  sh\n  yarn add -D @types/pg\n  sh\n  pnpm add -D @types/pg\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"compatibility_date\": \"2024-09-23\",\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<your-hyperdrive-id-here>\"\n      }\n    ]\n  }\n  toml\n  # required for database drivers to function\n  compatibility_flags = [\"nodejs_compat\"]\n  compatibility_date = \"2024-09-23\"\n\n[[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<your-hyperdrive-id-here>\"\n  ts\n// filepath: src/index.ts\nimport { Client } from \"pg\";\n\nexport default {\n  async fetch(\n    request: Request,\n    env: Env,\n    ctx: ExecutionContext,\n  ): Promise<Response> {\n    // Create a new client instance for each request.\n    const client = new Client({\n      connectionString: env.HYPERDRIVE.connectionString,\n    });\n\ntry {\n      // Connect to the database\n      await client.connect();\n      console.log(\"Connected to PostgreSQL database\");\n\n// Perform a simple query\n      const result = await client.query(\"SELECT * FROM pg_tables\");\n\nreturn Response.json({\n        success: true,\n        result: result.rows,\n      });\n    } catch (error: any) {\n      console.error(\"Database error:\", error.message);\n\nnew Response(\"Internal error occurred\", { status: 500 });\n    }\n  },\n};\ntxt\npostgres://USERNAME:PASSWORD@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\nsh\n     npx wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=\"postgres://user:password@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\"\n     jsonc\n       {\n         \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n         \"name\": \"hyperdrive-example\",\n         \"main\": \"src/index.ts\",\n         \"compatibility_date\": \"2024-08-21\",\n         \"compatibility_flags\": [\n           \"nodejs_compat\"\n         ],\n         \"hyperdrive\": [\n           {\n             \"binding\": \"HYPERDRIVE\",\n             \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n           }\n         ]\n       }\n       toml\n       name = \"hyperdrive-example\"\n       main = \"src/index.ts\"\n       compatibility_date = \"2024-08-21\"\n       compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n       [[hyperdrive]]\n       binding = \"HYPERDRIVE\"\n       id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n       jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"hyperdrive-example\",\n    \"main\": \"src/index.ts\",\n    \"compatibility_date\": \"2024-08-21\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n      }\n    ]\n  }\n  toml\n  name = \"hyperdrive-example\"\n  main = \"src/index.ts\"\n  compatibility_date = \"2024-08-21\"\n  compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n  [[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n  sh\n  npm i pg@>8.16.3\n  sh\n  yarn add pg@>8.16.3\n  sh\n  pnpm add pg@>8.16.3\n  sh\n  npm i -D @types/pg\n  sh\n  yarn add -D @types/pg\n  sh\n  pnpm add -D @types/pg\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"compatibility_date\": \"2024-09-23\",\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<your-hyperdrive-id-here>\"\n      }\n    ]\n  }\n  toml\n  # required for database drivers to function\n  compatibility_flags = [\"nodejs_compat\"]\n  compatibility_date = \"2024-09-23\"\n\n[[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<your-hyperdrive-id-here>\"\n  ts\n// filepath: src/index.ts\nimport { Client } from \"pg\";\n\nexport default {\n  async fetch(\n    request: Request,\n    env: Env,\n    ctx: ExecutionContext,\n  ): Promise<Response> {\n    // Create a new client instance for each request.\n    const client = new Client({\n      connectionString: env.HYPERDRIVE.connectionString,\n    });\n\ntry {\n      // Connect to the database\n      await client.connect();\n      console.log(\"Connected to PostgreSQL database\");\n\n// Perform a simple query\n      const result = await client.query(\"SELECT * FROM pg_tables\");\n\nreturn Response.json({\n        success: true,\n        result: result.rows,\n      });\n    } catch (error: any) {\n      console.error(\"Database error:\", error.message);\n\nnew Response(\"Internal error occurred\", { status: 500 });\n    }\n  },\n};\ntxt\n    postgres://0191c898-...:4d7d8b45-...@eu-central-1.db.thenile.dev:5432/my_database\ntxt\npostgres://USERNAME:PASSWORD@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\nsh\n     npx wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=\"postgres://user:password@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\"\n     jsonc\n       {\n         \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n         \"name\": \"hyperdrive-example\",\n         \"main\": \"src/index.ts\",\n         \"compatibility_date\": \"2024-08-21\",\n         \"compatibility_flags\": [\n           \"nodejs_compat\"\n         ],\n         \"hyperdrive\": [\n           {\n             \"binding\": \"HYPERDRIVE\",\n             \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n           }\n         ]\n       }\n       toml\n       name = \"hyperdrive-example\"\n       main = \"src/index.ts\"\n       compatibility_date = \"2024-08-21\"\n       compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n       [[hyperdrive]]\n       binding = \"HYPERDRIVE\"\n       id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n       jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"hyperdrive-example\",\n    \"main\": \"src/index.ts\",\n    \"compatibility_date\": \"2024-08-21\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n      }\n    ]\n  }\n  toml\n  name = \"hyperdrive-example\"\n  main = \"src/index.ts\"\n  compatibility_date = \"2024-08-21\"\n  compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n  [[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n  sh\n  npm i pg@>8.16.3\n  sh\n  yarn add pg@>8.16.3\n  sh\n  pnpm add pg@>8.16.3\n  sh\n  npm i -D @types/pg\n  sh\n  yarn add -D @types/pg\n  sh\n  pnpm add -D @types/pg\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"compatibility_date\": \"2024-09-23\",\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<your-hyperdrive-id-here>\"\n      }\n    ]\n  }\n  toml\n  # required for database drivers to function\n  compatibility_flags = [\"nodejs_compat\"]\n  compatibility_date = \"2024-09-23\"\n\n[[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<your-hyperdrive-id-here>\"\n  ts\n// filepath: src/index.ts\nimport { Client } from \"pg\";\n\nexport default {\n  async fetch(\n    request: Request,\n    env: Env,\n    ctx: ExecutionContext,\n  ): Promise<Response> {\n    // Create a new client instance for each request.\n    const client = new Client({\n      connectionString: env.HYPERDRIVE.connectionString,\n    });\n\ntry {\n      // Connect to the database\n      await client.connect();\n      console.log(\"Connected to PostgreSQL database\");\n\n// Perform a simple query\n      const result = await client.query(\"SELECT * FROM pg_tables\");\n\nreturn Response.json({\n        success: true,\n        result: result.rows,\n      });\n    } catch (error: any) {\n      console.error(\"Database error:\", error.message);\n\nnew Response(\"Internal error occurred\", { status: 500 });\n    }\n  },\n};\ntxt\npostgres://USERNAME:PASSWORD@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\nsh\n     npx wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=\"postgres://user:password@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\"\n     jsonc\n       {\n         \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n         \"name\": \"hyperdrive-example\",\n         \"main\": \"src/index.ts\",\n         \"compatibility_date\": \"2024-08-21\",\n         \"compatibility_flags\": [\n           \"nodejs_compat\"\n         ],\n         \"hyperdrive\": [\n           {\n             \"binding\": \"HYPERDRIVE\",\n             \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n           }\n         ]\n       }\n       toml\n       name = \"hyperdrive-example\"\n       main = \"src/index.ts\"\n       compatibility_date = \"2024-08-21\"\n       compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n       [[hyperdrive]]\n       binding = \"HYPERDRIVE\"\n       id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n       jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"hyperdrive-example\",\n    \"main\": \"src/index.ts\",\n    \"compatibility_date\": \"2024-08-21\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n      }\n    ]\n  }\n  toml\n  name = \"hyperdrive-example\"\n  main = \"src/index.ts\"\n  compatibility_date = \"2024-08-21\"\n  compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n  [[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n  sh\n  npm i pg@>8.16.3\n  sh\n  yarn add pg@>8.16.3\n  sh\n  pnpm add pg@>8.16.3\n  sh\n  npm i -D @types/pg\n  sh\n  yarn add -D @types/pg\n  sh\n  pnpm add -D @types/pg\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"compatibility_date\": \"2024-09-23\",\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<your-hyperdrive-id-here>\"\n      }\n    ]\n  }\n  toml\n  # required for database drivers to function\n  compatibility_flags = [\"nodejs_compat\"]\n  compatibility_date = \"2024-09-23\"\n\n[[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<your-hyperdrive-id-here>\"\n  ts\n// filepath: src/index.ts\nimport { Client } from \"pg\";\n\nexport default {\n  async fetch(\n    request: Request,\n    env: Env,\n    ctx: ExecutionContext,\n  ): Promise<Response> {\n    // Create a new client instance for each request.\n    const client = new Client({\n      connectionString: env.HYPERDRIVE.connectionString,\n    });\n\ntry {\n      // Connect to the database\n      await client.connect();\n      console.log(\"Connected to PostgreSQL database\");\n\n// Perform a simple query\n      const result = await client.query(\"SELECT * FROM pg_tables\");\n\nreturn Response.json({\n        success: true,\n        result: result.rows,\n      });\n    } catch (error: any) {\n      console.error(\"Database error:\", error.message);\n\nnew Response(\"Internal error occurred\", { status: 500 });\n    }\n  },\n};\ntxt\npostgres://USERNAME:PASSWORD@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\nsh\n     npx wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=\"postgres://user:password@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\"\n     jsonc\n       {\n         \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n         \"name\": \"hyperdrive-example\",\n         \"main\": \"src/index.ts\",\n         \"compatibility_date\": \"2024-08-21\",\n         \"compatibility_flags\": [\n           \"nodejs_compat\"\n         ],\n         \"hyperdrive\": [\n           {\n             \"binding\": \"HYPERDRIVE\",\n             \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n           }\n         ]\n       }\n       toml\n       name = \"hyperdrive-example\"\n       main = \"src/index.ts\"\n       compatibility_date = \"2024-08-21\"\n       compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n       [[hyperdrive]]\n       binding = \"HYPERDRIVE\"\n       id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n       jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"hyperdrive-example\",\n    \"main\": \"src/index.ts\",\n    \"compatibility_date\": \"2024-08-21\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n      }\n    ]\n  }\n  toml\n  name = \"hyperdrive-example\"\n  main = \"src/index.ts\"\n  compatibility_date = \"2024-08-21\"\n  compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n  [[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n  sh\n  npm i pg@>8.16.3\n  sh\n  yarn add pg@>8.16.3\n  sh\n  pnpm add pg@>8.16.3\n  sh\n  npm i -D @types/pg\n  sh\n  yarn add -D @types/pg\n  sh\n  pnpm add -D @types/pg\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"compatibility_date\": \"2024-09-23\",\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<your-hyperdrive-id-here>\"\n      }\n    ]\n  }\n  toml\n  # required for database drivers to function\n  compatibility_flags = [\"nodejs_compat\"]\n  compatibility_date = \"2024-09-23\"\n\n[[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<your-hyperdrive-id-here>\"\n  ts\n// filepath: src/index.ts\nimport { Client } from \"pg\";\n\nexport default {\n  async fetch(\n    request: Request,\n    env: Env,\n    ctx: ExecutionContext,\n  ): Promise<Response> {\n    // Create a new client instance for each request.\n    const client = new Client({\n      connectionString: env.HYPERDRIVE.connectionString,\n    });\n\ntry {\n      // Connect to the database\n      await client.connect();\n      console.log(\"Connected to PostgreSQL database\");\n\n// Perform a simple query\n      const result = await client.query(\"SELECT * FROM pg_tables\");\n\nreturn Response.json({\n        success: true,\n        result: result.rows,\n      });\n    } catch (error: any) {\n      console.error(\"Database error:\", error.message);\n\nnew Response(\"Internal error occurred\", { status: 500 });\n    }\n  },\n};\ntxt\npostgres://USERNAME:PASSWORD@HOSTNAME_OR_IP_ADDRESS:PORT/\nbash\nnpx create-db@latest\ntxt\npostgres://USERNAME:PASSWORD@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\nsh\n     npx wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=\"postgres://user:password@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\"\n     jsonc\n       {\n         \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n         \"name\": \"hyperdrive-example\",\n         \"main\": \"src/index.ts\",\n         \"compatibility_date\": \"2024-08-21\",\n         \"compatibility_flags\": [\n           \"nodejs_compat\"\n         ],\n         \"hyperdrive\": [\n           {\n             \"binding\": \"HYPERDRIVE\",\n             \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n           }\n         ]\n       }\n       toml\n       name = \"hyperdrive-example\"\n       main = \"src/index.ts\"\n       compatibility_date = \"2024-08-21\"\n       compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n       [[hyperdrive]]\n       binding = \"HYPERDRIVE\"\n       id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n       jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"hyperdrive-example\",\n    \"main\": \"src/index.ts\",\n    \"compatibility_date\": \"2024-08-21\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n      }\n    ]\n  }\n  toml\n  name = \"hyperdrive-example\"\n  main = \"src/index.ts\"\n  compatibility_date = \"2024-08-21\"\n  compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n  [[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n  sh\n  npm i pg@>8.16.3\n  sh\n  yarn add pg@>8.16.3\n  sh\n  pnpm add pg@>8.16.3\n  sh\n  npm i -D @types/pg\n  sh\n  yarn add -D @types/pg\n  sh\n  pnpm add -D @types/pg\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"compatibility_date\": \"2024-09-23\",\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<your-hyperdrive-id-here>\"\n      }\n    ]\n  }\n  toml\n  # required for database drivers to function\n  compatibility_flags = [\"nodejs_compat\"]\n  compatibility_date = \"2024-09-23\"\n\n[[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<your-hyperdrive-id-here>\"\n  ts\n// filepath: src/index.ts\nimport { Client } from \"pg\";\n\nexport default {\n  async fetch(\n    request: Request,\n    env: Env,\n    ctx: ExecutionContext,\n  ): Promise<Response> {\n    // Create a new client instance for each request.\n    const client = new Client({\n      connectionString: env.HYPERDRIVE.connectionString,\n    });\n\ntry {\n      // Connect to the database\n      await client.connect();\n      console.log(\"Connected to PostgreSQL database\");\n\n// Perform a simple query\n      const result = await client.query(\"SELECT * FROM pg_tables\");\n\nreturn Response.json({\n        success: true,\n        result: result.rows,\n      });\n    } catch (error: any) {\n      console.error(\"Database error:\", error.message);\n\nnew Response(\"Internal error occurred\", { status: 500 });\n    }\n  },\n};\nbash\n     npx wrangler hyperdrive update <HYPERDRIVE_ID> --origin-connection-limit=10\n     bash\n     npx wrangler hyperdrive get <HYPERDRIVE_ID>\n     sql\nCREATE ROLE hyperdrive_user LOGIN PASSWORD 'sufficientlyRandomPassword';\n\n-- Here, you are granting it the postgres role. In practice, you want to create a role with lesser privileges.\nGRANT postgres to hyperdrive_user;\ntxt\npostgres://USERNAME:PASSWORD@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\nsh\n     npx wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=\"postgres://user:password@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\"\n     jsonc\n       {\n         \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n         \"name\": \"hyperdrive-example\",\n         \"main\": \"src/index.ts\",\n         \"compatibility_date\": \"2024-08-21\",\n         \"compatibility_flags\": [\n           \"nodejs_compat\"\n         ],\n         \"hyperdrive\": [\n           {\n             \"binding\": \"HYPERDRIVE\",\n             \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n           }\n         ]\n       }\n       toml\n       name = \"hyperdrive-example\"\n       main = \"src/index.ts\"\n       compatibility_date = \"2024-08-21\"\n       compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n       [[hyperdrive]]\n       binding = \"HYPERDRIVE\"\n       id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n       jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"hyperdrive-example\",\n    \"main\": \"src/index.ts\",\n    \"compatibility_date\": \"2024-08-21\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n      }\n    ]\n  }\n  toml\n  name = \"hyperdrive-example\"\n  main = \"src/index.ts\"\n  compatibility_date = \"2024-08-21\"\n  compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n  [[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n  sh\n  npm i pg@>8.16.3\n  sh\n  yarn add pg@>8.16.3\n  sh\n  pnpm add pg@>8.16.3\n  sh\n  npm i -D @types/pg\n  sh\n  yarn add -D @types/pg\n  sh\n  pnpm add -D @types/pg\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"compatibility_date\": \"2024-09-23\",\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<your-hyperdrive-id-here>\"\n      }\n    ]\n  }\n  toml\n  # required for database drivers to function\n  compatibility_flags = [\"nodejs_compat\"]\n  compatibility_date = \"2024-09-23\"\n\n[[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<your-hyperdrive-id-here>\"\n  ts\n// filepath: src/index.ts\nimport { Client } from \"pg\";\n\nexport default {\n  async fetch(\n    request: Request,\n    env: Env,\n    ctx: ExecutionContext,\n  ): Promise<Response> {\n    // Create a new client instance for each request.\n    const client = new Client({\n      connectionString: env.HYPERDRIVE.connectionString,\n    });\n\ntry {\n      // Connect to the database\n      await client.connect();\n      console.log(\"Connected to PostgreSQL database\");\n\n// Perform a simple query\n      const result = await client.query(\"SELECT * FROM pg_tables\");\n\nreturn Response.json({\n        success: true,\n        result: result.rows,\n      });\n    } catch (error: any) {\n      console.error(\"Database error:\", error.message);\n\nnew Response(\"Internal error occurred\", { status: 500 });\n    }\n  },\n};\ntxt\npostgres://tsdbadmin:YOUR_PASSWORD_HERE@pn79dztyy0.xzhhbfensb.tsdb.cloud.timescale.com:31358/tsdb\ntxt\npostgres://USERNAME:PASSWORD@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\nsh\n     npx wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=\"postgres://user:password@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\"\n     jsonc\n       {\n         \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n         \"name\": \"hyperdrive-example\",\n         \"main\": \"src/index.ts\",\n         \"compatibility_date\": \"2024-08-21\",\n         \"compatibility_flags\": [\n           \"nodejs_compat\"\n         ],\n         \"hyperdrive\": [\n           {\n             \"binding\": \"HYPERDRIVE\",\n             \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n           }\n         ]\n       }\n       toml\n       name = \"hyperdrive-example\"\n       main = \"src/index.ts\"\n       compatibility_date = \"2024-08-21\"\n       compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n       [[hyperdrive]]\n       binding = \"HYPERDRIVE\"\n       id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n       jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"hyperdrive-example\",\n    \"main\": \"src/index.ts\",\n    \"compatibility_date\": \"2024-08-21\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n      }\n    ]\n  }\n  toml\n  name = \"hyperdrive-example\"\n  main = \"src/index.ts\"\n  compatibility_date = \"2024-08-21\"\n  compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n  [[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n  sh\n  npm i pg@>8.16.3\n  sh\n  yarn add pg@>8.16.3\n  sh\n  pnpm add pg@>8.16.3\n  sh\n  npm i -D @types/pg\n  sh\n  yarn add -D @types/pg\n  sh\n  pnpm add -D @types/pg\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"compatibility_date\": \"2024-09-23\",\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<your-hyperdrive-id-here>\"\n      }\n    ]\n  }\n  toml\n  # required for database drivers to function\n  compatibility_flags = [\"nodejs_compat\"]\n  compatibility_date = \"2024-09-23\"\n\n[[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<your-hyperdrive-id-here>\"\n  ts\n// filepath: src/index.ts\nimport { Client } from \"pg\";\n\nexport default {\n  async fetch(\n    request: Request,\n    env: Env,\n    ctx: ExecutionContext,\n  ): Promise<Response> {\n    // Create a new client instance for each request.\n    const client = new Client({\n      connectionString: env.HYPERDRIVE.connectionString,\n    });\n\ntry {\n      // Connect to the database\n      await client.connect();\n      console.log(\"Connected to PostgreSQL database\");\n\n// Perform a simple query\n      const result = await client.query(\"SELECT * FROM pg_tables\");\n\nreturn Response.json({\n        success: true,\n        result: result.rows,\n      });\n    } catch (error: any) {\n      console.error(\"Database error:\", error.message);\n\nnew Response(\"Internal error occurred\", { status: 500 });\n    }\n  },\n};\ntxt\npostgres://USERNAME:PASSWORD@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\nsh\n     npx wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=\"postgres://user:password@HOSTNAME_OR_IP_ADDRESS:PORT/database_name\"\n     jsonc\n       {\n         \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n         \"name\": \"hyperdrive-example\",\n         \"main\": \"src/index.ts\",\n         \"compatibility_date\": \"2024-08-21\",\n         \"compatibility_flags\": [\n           \"nodejs_compat\"\n         ],\n         \"hyperdrive\": [\n           {\n             \"binding\": \"HYPERDRIVE\",\n             \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n           }\n         ]\n       }\n       toml\n       name = \"hyperdrive-example\"\n       main = \"src/index.ts\"\n       compatibility_date = \"2024-08-21\"\n       compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n       [[hyperdrive]]\n       binding = \"HYPERDRIVE\"\n       id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n       jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"hyperdrive-example\",\n    \"main\": \"src/index.ts\",\n    \"compatibility_date\": \"2024-08-21\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n      }\n    ]\n  }\n  toml\n  name = \"hyperdrive-example\"\n  main = \"src/index.ts\"\n  compatibility_date = \"2024-08-21\"\n  compatibility_flags = [\"nodejs_compat\"]\n\n# Pasted from the output of `wrangler hyperdrive create <NAME_OF_HYPERDRIVE_CONFIG> --connection-string=[...]` above.\n  [[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<ID OF THE CREATED HYPERDRIVE CONFIGURATION>\"\n  sh\n  npm i pg@>8.16.3\n  sh\n  yarn add pg@>8.16.3\n  sh\n  pnpm add pg@>8.16.3\n  sh\n  npm i -D @types/pg\n  sh\n  yarn add -D @types/pg\n  sh\n  pnpm add -D @types/pg\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"compatibility_date\": \"2024-09-23\",\n    \"hyperdrive\": [\n      {\n        \"binding\": \"HYPERDRIVE\",\n        \"id\": \"<your-hyperdrive-id-here>\"\n      }\n    ]\n  }\n  toml\n  # required for database drivers to function\n  compatibility_flags = [\"nodejs_compat\"]\n  compatibility_date = \"2024-09-23\"\n\n[[hyperdrive]]\n  binding = \"HYPERDRIVE\"\n  id = \"<your-hyperdrive-id-here>\"\n  ts\n// filepath: src/index.ts\nimport { Client } from \"pg\";\n\nexport default {\n  async fetch(\n    request: Request,\n    env: Env,\n    ctx: ExecutionContext,\n  ): Promise<Response> {\n    // Create a new client instance for each request.\n    const client = new Client({\n      connectionString: env.HYPERDRIVE.connectionString,\n    });\n\ntry {\n      // Connect to the database\n      await client.connect();\n      console.log(\"Connected to PostgreSQL database\");\n\n// Perform a simple query\n      const result = await client.query(\"SELECT * FROM pg_tables\");\n\nreturn Response.json({\n        success: true,\n        result: result.rows,\n      });\n    } catch (error: any) {\n      console.error(\"Database error:\", error.message);\n\nnew Response(\"Internal error occurred\", { status: 500 });\n    }\n  },\n};\njson\n{\n  \"Id\": \"<POLICY_ID>\",\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"Stmt1506627150918\",\n      \"Action\": [\"s3:PutObject\"],\n      \"Effect\": \"Allow\",\n      \"Resource\": \"arn:aws:s3:::burritobot/logs/*\",\n      \"Principal\": {\n        \"AWS\": [\"arn:aws:iam::391854517948:user/cloudflare-logpush\"]\n      }\n    }\n  ]\n}\nbash\ncurl \"https://api.cloudflare.com/client/v4/zones/$ZONE_ID/settings/aegis\" \\\n  --request PATCH \\\n  --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\" \\\n  --json '{\n    \"id\": \"aegis\",\n    \"value\": {\n        \"enabled\": true,\n        \"pool_id\": \"<YOUR_EGRESS_POOL_ID>\"\n    }\n  }'\ntxt\nhttps://logpush.yourdestinationendpoint.com?header_X-Logpush-Secret=YOUR_RANDOM_SECRET_TOKEN\ntxt\n  (http.host eq \"logpush.yourdestinationendpoint.com\" and all(http.request.headers[\"x-logpush-secret\"][*] ne \"YOUR_RANDOM_SECRET_TOKEN\"))\n  txt\n  (http.host eq \"logpush.yourdestinationendpoint.com\" and not ip.geoip.asnum in {13335 132892})\n  txt\nhttps://logpush.yourdestinationendpoint.com?header_CF-Access-Client-Id=YOUR_CLIENT_ID&header_CF-Access-Client-Secret=YOUR_CLIENT_SECRET\nbash\n$ curl https://logpush.yourdestinationendpoint.com",
  "code_samples": [
    {
      "code": "Refer to [Google Cloud's documentation](https://cloud.google.com/sql/docs/postgres/create-manage-users) for additional configuration options.\n\n## 2. Create a database configuration\n\nTo configure Hyperdrive, you will need:\n\n* The IP address (or hostname) and port of your database.\n* The database username (for example, `hyperdrive-demo`) you configured in a previous step.\n* The password associated with that username.\n* The name of the database you want Hyperdrive to connect to. For example, `postgres`.\n\nHyperdrive accepts the combination of these parameters in the common connection string format used by database drivers:",
      "language": "unknown"
    },
    {
      "code": "Most database providers will provide a connection string you can directly copy-and-paste directly into Hyperdrive.\n\n* Dashboard\n\n  To create a Hyperdrive configuration with the Cloudflare dashboard:\n\n  1. In the Cloudflare dashboard, go to the **Hyperdrive** page.\n\n     [Go to **Hyperdrive**](https://dash.cloudflare.com/?to=/:account/workers/hyperdrive)\n\n  2. Select **Create Configuration**.\n\n  3. Fill out the form, including the connection string.\n\n  4. Select **Create**.\n\n* Wrangler CLI\n\n  To create a Hyperdrive configuration with the [Wrangler CLI](https://developers.cloudflare.com/workers/wrangler/install-and-update/):\n\n  1. Open your terminal and run the following command. Replace `<NAME_OF_HYPERDRIVE_CONFIG>` with a name for your Hyperdrive configuration and paste the connection string provided from your database host, or replace `user`, `password`, `HOSTNAME_OR_IP_ADDRESS`, `port`, and `database_name` placeholders with those specific to your database:",
      "language": "unknown"
    },
    {
      "code": "2. This command outputs a binding for the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/):\n\n     * wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Note\n\nHyperdrive will attempt to connect to your database with the provided credentials to verify they are correct before creating a configuration. If you encounter an error when attempting to connect, refer to Hyperdrive's [troubleshooting documentation](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug possible causes.\n\n## 3. Use Hyperdrive from your Worker\n\nInstall the `node-postgres` driver:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Note\n\nThe minimum version of `node-postgres` required for Hyperdrive is `8.16.3`.\n\nIf using TypeScript, install the types package:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Add the required Node.js compatibility flags and Hyperdrive binding to your `wrangler.jsonc` file:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Create a new `Client` instance and pass the Hyperdrive `connectionString`:",
      "language": "unknown"
    },
    {
      "code": "## Next steps\n\n* Learn more about [How Hyperdrive Works](https://developers.cloudflare.com/hyperdrive/concepts/how-hyperdrive-works/).\n* Refer to the [troubleshooting guide](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug common issues.\n* Understand more about other [storage options](https://developers.cloudflare.com/workers/platform/storage-options/) available to Cloudflare Workers.\n\n</page>\n\n<page>\n---\ntitle: Materialize · Cloudflare Hyperdrive docs\ndescription: Connect Hyperdrive to a Materialize streaming database.\nlastUpdated: 2025-08-20T20:59:04.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/materialize/\n  md: https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/materialize/index.md\n---\n\nThis example shows you how to connect Hyperdrive to a [Materialize](https://materialize.com/) database. Materialize is a Postgres-compatible streaming database that can automatically compute real-time results against your streaming data sources.\n\n## 1. Allow Hyperdrive access\n\nTo allow Hyperdrive to connect to your database, you will need to ensure that Hyperdrive has valid user credentials and network access to your database.\n\n### Materialize Console\n\nNote\n\nRead the Materialize [Quickstart guide](https://materialize.com/docs/get-started/quickstart/) to set up your first database. The steps below assume you have an existing Materialize database ready to go.\n\nYou will need to create a new application user and password for Hyperdrive to connect with:\n\n1. Log in to the [Materialize Console](https://console.materialize.com/).\n2. Under the **App Passwords** section, select **Manage app passwords**.\n3. Select **New app password** and enter a name, for example, `hyperdrive-user`.\n4. Select **Create Password**.\n5. Copy the provided password: it will only be shown once.\n\nTo retrieve the hostname and database name of your Materialize configuration:\n\n1. Select **Connect** in the sidebar of the Materialize Console.\n2. Select **External tools**.\n3. Copy the **Host**, **Port** and **Database** settings.\n\nWith the username, app password, hostname, port and database name, you can now connect Hyperdrive to your Materialize database.\n\n## 2. Create a database configuration\n\nTo configure Hyperdrive, you will need:\n\n* The IP address (or hostname) and port of your database.\n* The database username (for example, `hyperdrive-demo`) you configured in a previous step.\n* The password associated with that username.\n* The name of the database you want Hyperdrive to connect to. For example, `postgres`.\n\nHyperdrive accepts the combination of these parameters in the common connection string format used by database drivers:",
      "language": "unknown"
    },
    {
      "code": "Most database providers will provide a connection string you can directly copy-and-paste directly into Hyperdrive.\n\n* Dashboard\n\n  To create a Hyperdrive configuration with the Cloudflare dashboard:\n\n  1. In the Cloudflare dashboard, go to the **Hyperdrive** page.\n\n     [Go to **Hyperdrive**](https://dash.cloudflare.com/?to=/:account/workers/hyperdrive)\n\n  2. Select **Create Configuration**.\n\n  3. Fill out the form, including the connection string.\n\n  4. Select **Create**.\n\n* Wrangler CLI\n\n  To create a Hyperdrive configuration with the [Wrangler CLI](https://developers.cloudflare.com/workers/wrangler/install-and-update/):\n\n  1. Open your terminal and run the following command. Replace `<NAME_OF_HYPERDRIVE_CONFIG>` with a name for your Hyperdrive configuration and paste the connection string provided from your database host, or replace `user`, `password`, `HOSTNAME_OR_IP_ADDRESS`, `port`, and `database_name` placeholders with those specific to your database:",
      "language": "unknown"
    },
    {
      "code": "2. This command outputs a binding for the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/):\n\n     * wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Note\n\nHyperdrive will attempt to connect to your database with the provided credentials to verify they are correct before creating a configuration. If you encounter an error when attempting to connect, refer to Hyperdrive's [troubleshooting documentation](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug possible causes.\n\n## 3. Use Hyperdrive from your Worker\n\nInstall the `node-postgres` driver:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Note\n\nThe minimum version of `node-postgres` required for Hyperdrive is `8.16.3`.\n\nIf using TypeScript, install the types package:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Add the required Node.js compatibility flags and Hyperdrive binding to your `wrangler.jsonc` file:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Create a new `Client` instance and pass the Hyperdrive `connectionString`:",
      "language": "unknown"
    },
    {
      "code": "## Next steps\n\n* Learn more about [How Hyperdrive Works](https://developers.cloudflare.com/hyperdrive/concepts/how-hyperdrive-works/).\n* Refer to the [troubleshooting guide](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug common issues.\n* Understand more about other [storage options](https://developers.cloudflare.com/workers/platform/storage-options/) available to Cloudflare Workers.\n\n</page>\n\n<page>\n---\ntitle: Neon · Cloudflare Hyperdrive docs\ndescription: Connect Hyperdrive to a Neon Postgres database.\nlastUpdated: 2025-08-20T20:59:04.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/neon/\n  md: https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/neon/index.md\n---\n\nThis example shows you how to connect Hyperdrive to a [Neon](https://neon.tech/) Postgres database.\n\n## 1. Allow Hyperdrive access\n\nYou can connect Hyperdrive to any existing Neon database by creating a new user and fetching your database connection string.\n\n### Neon Dashboard\n\n1. Go to the [**Neon dashboard**](https://console.neon.tech/app/projects) and select the project (database) you wish to connect to.\n2. Select **Roles** from the sidebar and select **New Role**. Enter `hyperdrive-user` as the name (or your preferred name) and **copy the password**. Note that the password will not be displayed again: you will have to reset it if you do not save it somewhere.\n3. Select **Dashboard** from the sidebar > go to the **Connection Details** pane > ensure you have selected the **branch**, **database** and **role** (for example,`hyperdrive-user`) that Hyperdrive will connect through.\n4. Select the `psql` and **uncheck the connection pooling** checkbox. Note down the connection string (starting with `postgres://hyperdrive-user@...`) from the text box.\n\nWith both the connection string and the password, you can now create a Hyperdrive database configuration.\n\n## 2. Create a database configuration\n\nTo configure Hyperdrive, you will need:\n\n* The IP address (or hostname) and port of your database.\n* The database username (for example, `hyperdrive-demo`) you configured in a previous step.\n* The password associated with that username.\n* The name of the database you want Hyperdrive to connect to. For example, `postgres`.\n\nHyperdrive accepts the combination of these parameters in the common connection string format used by database drivers:",
      "language": "unknown"
    },
    {
      "code": "Most database providers will provide a connection string you can directly copy-and-paste directly into Hyperdrive.\n\n* Dashboard\n\n  To create a Hyperdrive configuration with the Cloudflare dashboard:\n\n  1. In the Cloudflare dashboard, go to the **Hyperdrive** page.\n\n     [Go to **Hyperdrive**](https://dash.cloudflare.com/?to=/:account/workers/hyperdrive)\n\n  2. Select **Create Configuration**.\n\n  3. Fill out the form, including the connection string.\n\n  4. Select **Create**.\n\n* Wrangler CLI\n\n  To create a Hyperdrive configuration with the [Wrangler CLI](https://developers.cloudflare.com/workers/wrangler/install-and-update/):\n\n  1. Open your terminal and run the following command. Replace `<NAME_OF_HYPERDRIVE_CONFIG>` with a name for your Hyperdrive configuration and paste the connection string provided from your database host, or replace `user`, `password`, `HOSTNAME_OR_IP_ADDRESS`, `port`, and `database_name` placeholders with those specific to your database:",
      "language": "unknown"
    },
    {
      "code": "2. This command outputs a binding for the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/):\n\n     * wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Note\n\nHyperdrive will attempt to connect to your database with the provided credentials to verify they are correct before creating a configuration. If you encounter an error when attempting to connect, refer to Hyperdrive's [troubleshooting documentation](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug possible causes.\n\n## 3. Use Hyperdrive from your Worker\n\nInstall the `node-postgres` driver:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Note\n\nThe minimum version of `node-postgres` required for Hyperdrive is `8.16.3`.\n\nIf using TypeScript, install the types package:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Add the required Node.js compatibility flags and Hyperdrive binding to your `wrangler.jsonc` file:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Create a new `Client` instance and pass the Hyperdrive `connectionString`:",
      "language": "unknown"
    },
    {
      "code": "Note\n\nWhen connecting to a Neon database with Hyperdrive, you should use a driver like [node-postgres (pg)](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-drivers-and-libraries/node-postgres/) or [Postgres.js](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-drivers-and-libraries/postgres-js/) to connect directly to the underlying database instead of the [Neon serverless driver](https://neon.tech/docs/serverless/serverless-driver). Hyperdrive is optimized for database access for Workers and will perform global connection pooling and fast query routing by connecting directly to your database.\n\n## Next steps\n\n* Learn more about [How Hyperdrive Works](https://developers.cloudflare.com/hyperdrive/concepts/how-hyperdrive-works/).\n* Refer to the [troubleshooting guide](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug common issues.\n* Understand more about other [storage options](https://developers.cloudflare.com/workers/platform/storage-options/) available to Cloudflare Workers.\n\n</page>\n\n<page>\n---\ntitle: Nile · Cloudflare Hyperdrive docs\ndescription: Connect Hyperdrive to a Nile Postgres database instance.\nlastUpdated: 2025-08-20T20:59:04.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/nile/\n  md: https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/nile/index.md\n---\n\nThis example shows you how to connect Hyperdrive to a [Nile](https://thenile.dev) PostgreSQL database instance.\n\nNile is PostgreSQL re-engineered for multi-tenant applications. Nile's virtual tenant databases provide you with isolation, placement, insight, and other features for your tenant's data and embedding. Refer to [Nile documentation](https://www.thenile.dev/docs/getting-started/whatisnile) to learn more.\n\n## 1. Allow Hyperdrive access\n\nYou can connect Cloudflare Hyperdrive to any Nile database in your workspace using its connection string - either with a new set of credentials, or using an existing set.\n\n### Nile console\n\nTo get a connection string from Nile console:\n\n1. Log in to [Nile console](https://console.thenile.dev), then select a database.\n2. On the left hand menu, click **Settings** (the bottom-most icon) and then select **Connection**.\n3. Select the PostgreSQL logo to show the connection string.\n4. Select \"Generate credentials\" to generate new credentials.\n5. Copy the connection string (without the \"psql\" part).\n\nYou will have obtained a connection string similar to the following:",
      "language": "unknown"
    },
    {
      "code": "With the connection string, you can now create a Hyperdrive database configuration.\n\n## 2. Create a database configuration\n\nTo configure Hyperdrive, you will need:\n\n* The IP address (or hostname) and port of your database.\n* The database username (for example, `hyperdrive-demo`) you configured in a previous step.\n* The password associated with that username.\n* The name of the database you want Hyperdrive to connect to. For example, `postgres`.\n\nHyperdrive accepts the combination of these parameters in the common connection string format used by database drivers:",
      "language": "unknown"
    },
    {
      "code": "Most database providers will provide a connection string you can directly copy-and-paste directly into Hyperdrive.\n\n* Dashboard\n\n  To create a Hyperdrive configuration with the Cloudflare dashboard:\n\n  1. In the Cloudflare dashboard, go to the **Hyperdrive** page.\n\n     [Go to **Hyperdrive**](https://dash.cloudflare.com/?to=/:account/workers/hyperdrive)\n\n  2. Select **Create Configuration**.\n\n  3. Fill out the form, including the connection string.\n\n  4. Select **Create**.\n\n* Wrangler CLI\n\n  To create a Hyperdrive configuration with the [Wrangler CLI](https://developers.cloudflare.com/workers/wrangler/install-and-update/):\n\n  1. Open your terminal and run the following command. Replace `<NAME_OF_HYPERDRIVE_CONFIG>` with a name for your Hyperdrive configuration and paste the connection string provided from your database host, or replace `user`, `password`, `HOSTNAME_OR_IP_ADDRESS`, `port`, and `database_name` placeholders with those specific to your database:",
      "language": "unknown"
    },
    {
      "code": "2. This command outputs a binding for the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/):\n\n     * wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Note\n\nHyperdrive will attempt to connect to your database with the provided credentials to verify they are correct before creating a configuration. If you encounter an error when attempting to connect, refer to Hyperdrive's [troubleshooting documentation](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug possible causes.\n\n## 3. Use Hyperdrive from your Worker\n\nInstall the `node-postgres` driver:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Note\n\nThe minimum version of `node-postgres` required for Hyperdrive is `8.16.3`.\n\nIf using TypeScript, install the types package:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Add the required Node.js compatibility flags and Hyperdrive binding to your `wrangler.jsonc` file:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Create a new `Client` instance and pass the Hyperdrive `connectionString`:",
      "language": "unknown"
    },
    {
      "code": "## Next steps\n\n* Learn more about [How Hyperdrive Works](https://developers.cloudflare.com/hyperdrive/concepts/how-hyperdrive-works/).\n* Refer to the [troubleshooting guide](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug common issues.\n* Understand more about other [storage options](https://developers.cloudflare.com/workers/platform/storage-options/) available to Cloudflare Workers.\n\n</page>\n\n<page>\n---\ntitle: pgEdge Cloud · Cloudflare Hyperdrive docs\ndescription: Connect Hyperdrive to a pgEdge Postgres database.\nlastUpdated: 2025-08-20T20:59:04.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/pgedge/\n  md: https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/pgedge/index.md\n---\n\nThis example shows you how to connect Hyperdrive to a [pgEdge](https://pgedge.com/) Postgres database. pgEdge Cloud provides easy deployment of fully-managed, fully-distributed, and secure Postgres.\n\n## 1. Allow Hyperdrive access\n\nYou can connect Hyperdrive to any existing pgEdge database with the default user and password provided by pgEdge.\n\n### pgEdge dashboard\n\nTo retrieve your connection string from the pgEdge dashboard:\n\n1. Go to the [**pgEdge dashboard**](https://app.pgedge.com) and select the database you wish to connect to.\n2. From the **Connect to your database** section, note down the connection string (starting with `postgres://app@...`) from the **Connection String** text box.\n\n## 2. Create a database configuration\n\nTo configure Hyperdrive, you will need:\n\n* The IP address (or hostname) and port of your database.\n* The database username (for example, `hyperdrive-demo`) you configured in a previous step.\n* The password associated with that username.\n* The name of the database you want Hyperdrive to connect to. For example, `postgres`.\n\nHyperdrive accepts the combination of these parameters in the common connection string format used by database drivers:",
      "language": "unknown"
    },
    {
      "code": "Most database providers will provide a connection string you can directly copy-and-paste directly into Hyperdrive.\n\n* Dashboard\n\n  To create a Hyperdrive configuration with the Cloudflare dashboard:\n\n  1. In the Cloudflare dashboard, go to the **Hyperdrive** page.\n\n     [Go to **Hyperdrive**](https://dash.cloudflare.com/?to=/:account/workers/hyperdrive)\n\n  2. Select **Create Configuration**.\n\n  3. Fill out the form, including the connection string.\n\n  4. Select **Create**.\n\n* Wrangler CLI\n\n  To create a Hyperdrive configuration with the [Wrangler CLI](https://developers.cloudflare.com/workers/wrangler/install-and-update/):\n\n  1. Open your terminal and run the following command. Replace `<NAME_OF_HYPERDRIVE_CONFIG>` with a name for your Hyperdrive configuration and paste the connection string provided from your database host, or replace `user`, `password`, `HOSTNAME_OR_IP_ADDRESS`, `port`, and `database_name` placeholders with those specific to your database:",
      "language": "unknown"
    },
    {
      "code": "2. This command outputs a binding for the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/):\n\n     * wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Note\n\nHyperdrive will attempt to connect to your database with the provided credentials to verify they are correct before creating a configuration. If you encounter an error when attempting to connect, refer to Hyperdrive's [troubleshooting documentation](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug possible causes.\n\n## 3. Use Hyperdrive from your Worker\n\nInstall the `node-postgres` driver:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Note\n\nThe minimum version of `node-postgres` required for Hyperdrive is `8.16.3`.\n\nIf using TypeScript, install the types package:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Add the required Node.js compatibility flags and Hyperdrive binding to your `wrangler.jsonc` file:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Create a new `Client` instance and pass the Hyperdrive `connectionString`:",
      "language": "unknown"
    },
    {
      "code": "## Next steps\n\n* Learn more about [How Hyperdrive Works](https://developers.cloudflare.com/hyperdrive/concepts/how-hyperdrive-works/).\n* Refer to the [troubleshooting guide](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug common issues.\n* Understand more about other [storage options](https://developers.cloudflare.com/workers/platform/storage-options/) available to Cloudflare Workers.\n\n</page>\n\n<page>\n---\ntitle: PlanetScale · Cloudflare Hyperdrive docs\ndescription: Connect Hyperdrive to a PlanetScale PostgreSQL database.\nlastUpdated: 2025-09-05T14:33:32.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/planetscale-postgres/\n  md: https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/planetscale-postgres/index.md\n---\n\nThis example shows you how to connect Hyperdrive to a [PlanetScale](https://planetscale.com/) PostgreSQL database.\n\n## 1. Allow Hyperdrive access\n\nYou can connect Hyperdrive to any existing PlanetScale PostgreSQL database by creating a new role (optional) and retrieving a connection string to your database.\n\n### PlanetScale Dashboard\n\n1. Go to the [**PlanetScale dashboard**](https://app.planetscale.com/) and select the database you wish to connect to.\n\n2. Click **Connect**.\n\n3. Create a new role for your Hyperdrive configuration (recommended):\n\n   1. Ensure the minimum required permissions for Hyperdrive to read and write data to your tables:\n\n      * **pg\\_read\\_all\\_data**: Read data from all tables, views, and sequences\n      * **pg\\_write\\_all\\_data**: Write data to all tables, views, and sequences\n\n   2. Click **Create role**.\n\n4. Note the user, the password, the database host, and the database name (or `postgres` as the default database). You will need these to create a database configuration in Hyperdrive.\n\nWith the host, database name, username and password, you can now create a Hyperdrive database configuration.\n\n## 2. Create a database configuration\n\nTo configure Hyperdrive, you will need:\n\n* The IP address (or hostname) and port of your database.\n* The database username (for example, `hyperdrive-demo`) you configured in a previous step.\n* The password associated with that username.\n* The name of the database you want Hyperdrive to connect to. For example, `postgres`.\n\nHyperdrive accepts the combination of these parameters in the common connection string format used by database drivers:",
      "language": "unknown"
    },
    {
      "code": "Most database providers will provide a connection string you can directly copy-and-paste directly into Hyperdrive.\n\n* Dashboard\n\n  To create a Hyperdrive configuration with the Cloudflare dashboard:\n\n  1. In the Cloudflare dashboard, go to the **Hyperdrive** page.\n\n     [Go to **Hyperdrive**](https://dash.cloudflare.com/?to=/:account/workers/hyperdrive)\n\n  2. Select **Create Configuration**.\n\n  3. Fill out the form, including the connection string.\n\n  4. Select **Create**.\n\n* Wrangler CLI\n\n  To create a Hyperdrive configuration with the [Wrangler CLI](https://developers.cloudflare.com/workers/wrangler/install-and-update/):\n\n  1. Open your terminal and run the following command. Replace `<NAME_OF_HYPERDRIVE_CONFIG>` with a name for your Hyperdrive configuration and paste the connection string provided from your database host, or replace `user`, `password`, `HOSTNAME_OR_IP_ADDRESS`, `port`, and `database_name` placeholders with those specific to your database:",
      "language": "unknown"
    },
    {
      "code": "2. This command outputs a binding for the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/):\n\n     * wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Note\n\nHyperdrive will attempt to connect to your database with the provided credentials to verify they are correct before creating a configuration. If you encounter an error when attempting to connect, refer to Hyperdrive's [troubleshooting documentation](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug possible causes.\n\n## 3. Use Hyperdrive from your Worker\n\nInstall the `node-postgres` driver:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Note\n\nThe minimum version of `node-postgres` required for Hyperdrive is `8.16.3`.\n\nIf using TypeScript, install the types package:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Add the required Node.js compatibility flags and Hyperdrive binding to your `wrangler.jsonc` file:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Create a new `Client` instance and pass the Hyperdrive `connectionString`:",
      "language": "unknown"
    },
    {
      "code": "Note\n\nWhen connecting to a PlanetScale PostgreSQL database with Hyperdrive, you should use a driver like [node-postgres (pg)](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-drivers-and-libraries/node-postgres/) or [Postgres.js](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-drivers-and-libraries/postgres-js/) to connect directly to the underlying database instead of the [PlanetScale serverless driver](https://planetscale.com/docs/tutorials/planetscale-serverless-driver). Hyperdrive is optimized for database access for Workers and will perform global connection pooling and fast query routing by connecting directly to your database.\n\n## Next steps\n\n* Learn more about [How Hyperdrive Works](https://developers.cloudflare.com/hyperdrive/concepts/how-hyperdrive-works/).\n* Refer to the [troubleshooting guide](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug common issues.\n* Understand more about other [storage options](https://developers.cloudflare.com/workers/platform/storage-options/) available to Cloudflare Workers.\n\n</page>\n\n<page>\n---\ntitle: Prisma Postgres · Cloudflare Hyperdrive docs\ndescription: Connect Hyperdrive to a Prisma Postgres database.\nlastUpdated: 2025-08-21T08:39:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/prisma-postgres/\n  md: https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/prisma-postgres/index.md\n---\n\nThis example shows you how to connect Hyperdrive to a [Prisma Postgres](https://www.prisma.io/postgres) database.\n\n## 1. Allow Hyperdrive access\n\nYou can connect Hyperdrive to any existing Prisma Postgres database by using your existing database connection string.\n\n### Prisma Data Platform\n\n1. Go to the [**Prisma Data Platform Console**](https://console.prisma.io/) and select the project (database) you wish to connect to.\n2. Select **Connect to your database** > **Any client**.\n3. Select **Generate database credentials**. Copy the connection string for your Prisma Postgres database.\n4. Edit the connection string to make it compatible with Hyperdrive.\n\n* Add the database name after the port. You may remove any query parameters, such as `?sslmode=require`.\n* The final string will look like:",
      "language": "unknown"
    },
    {
      "code": "Note\n\nAn alternative to the Prisma Data Platform is to use the [`create-db`](https://www.npmjs.com/package/create-db) package. This package will generate a quick temporary Prisma Postgres database for you to use.",
      "language": "unknown"
    },
    {
      "code": "With this connection string, you can now create a Hyperdrive database configuration.\n\n## 2. Create a database configuration\n\nTo configure Hyperdrive, you will need:\n\n* The IP address (or hostname) and port of your database.\n* The database username (for example, `hyperdrive-demo`) you configured in a previous step.\n* The password associated with that username.\n* The name of the database you want Hyperdrive to connect to. For example, `postgres`.\n\nHyperdrive accepts the combination of these parameters in the common connection string format used by database drivers:",
      "language": "unknown"
    },
    {
      "code": "Most database providers will provide a connection string you can directly copy-and-paste directly into Hyperdrive.\n\n* Dashboard\n\n  To create a Hyperdrive configuration with the Cloudflare dashboard:\n\n  1. In the Cloudflare dashboard, go to the **Hyperdrive** page.\n\n     [Go to **Hyperdrive**](https://dash.cloudflare.com/?to=/:account/workers/hyperdrive)\n\n  2. Select **Create Configuration**.\n\n  3. Fill out the form, including the connection string.\n\n  4. Select **Create**.\n\n* Wrangler CLI\n\n  To create a Hyperdrive configuration with the [Wrangler CLI](https://developers.cloudflare.com/workers/wrangler/install-and-update/):\n\n  1. Open your terminal and run the following command. Replace `<NAME_OF_HYPERDRIVE_CONFIG>` with a name for your Hyperdrive configuration and paste the connection string provided from your database host, or replace `user`, `password`, `HOSTNAME_OR_IP_ADDRESS`, `port`, and `database_name` placeholders with those specific to your database:",
      "language": "unknown"
    },
    {
      "code": "2. This command outputs a binding for the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/):\n\n     * wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Note\n\nHyperdrive will attempt to connect to your database with the provided credentials to verify they are correct before creating a configuration. If you encounter an error when attempting to connect, refer to Hyperdrive's [troubleshooting documentation](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug possible causes.\n\n## 3. Use Hyperdrive from your Worker\n\nInstall the `node-postgres` driver:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Note\n\nThe minimum version of `node-postgres` required for Hyperdrive is `8.16.3`.\n\nIf using TypeScript, install the types package:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Add the required Node.js compatibility flags and Hyperdrive binding to your `wrangler.jsonc` file:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Create a new `Client` instance and pass the Hyperdrive `connectionString`:",
      "language": "unknown"
    },
    {
      "code": "## 4. Configure Hyperdrive maximum connections\n\nPrisma Postgres has limits on the number of direct connections that can be made to the database using Hyperdrive. Refer to [Prisma Postgres limits](https://www.prisma.io/docs/postgres/database/direct-connections?utm_source=website\\&utm_medium=postgres-page#connection-limit).\n\nNote\n\nThere are two limits to consider here.\n\n* Origin database's connection limit, set by the origin database provider. This is the maximum number of direct database connections that can be made to the origin database.\n* Hyperdrive's origin connection limit, set by Hyperdrive. This is the maximum number of database connections that Hyperdrive can make to your origin database (in this case, Prisma Postgres).\n\nHyperdrive's origin connection limit should be lower than the Prisma Postgres connection limit, since Hyperdrive's origin connection limit is a soft limit, and Hyperdrive may create more connections if there are network disruptions that prevent existing connections from being used.\n\n* Dashboard\n\n  1. From the [Cloudflare Hyperdrive dashboard](https://dash.cloudflare.com/?to=/:account/workers/hyperdrive), select your newly created Hyperdrive configuration.\n  2. Go to **Settings**.\n  3. In **Origin connection limit**, select **Edit Settings**, and set your maximum connections to a number that is lower than your Prisma connection limit.\n\n* Wrangler CLI\n\n  1. Edit your existing Hyperdrive configuration with the `--origin-connection-limit` parameter:",
      "language": "unknown"
    },
    {
      "code": "Replace `<HYPERDRIVE_ID>` with your Hyperdrive configuration ID and set the connection limit to a number that is less than your Prisma connection limit.\n\n  2. Verify the configuration change:",
      "language": "unknown"
    },
    {
      "code": "Note\n\nWhen connecting to a Prisma Postgres database with Hyperdrive, you should use a driver like [node-postgres (pg)](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-drivers-and-libraries/node-postgres/) or [Postgres.js](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-drivers-and-libraries/postgres-js/) to connect directly to the underlying PostgreSQL database, instead of the Prisma Accelerate extension. Hyperdrive is optimized for database access for Workers, and connects directly to your database to perform global connection pooling and fast query routing.\n\n## Next steps\n\n* Learn more about [How Hyperdrive Works](https://developers.cloudflare.com/hyperdrive/concepts/how-hyperdrive-works/).\n* Refer to the [troubleshooting guide](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug common issues.\n* Understand more about other [storage options](https://developers.cloudflare.com/workers/platform/storage-options/) available to Cloudflare Workers.\n\n</page>\n\n<page>\n---\ntitle: Supabase · Cloudflare Hyperdrive docs\ndescription: Connect Hyperdrive to a Supabase Postgres database.\nlastUpdated: 2025-12-03T16:30:02.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/supabase/\n  md: https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/supabase/index.md\n---\n\nThis example shows you how to connect Hyperdrive to a [Supabase](https://supabase.com/) Postgres database.\n\n## 1. Allow Hyperdrive access\n\nYou can connect Hyperdrive to any existing Supabase database as the Postgres user which is set up during project creation. Alternatively, to create a new user for Hyperdrive, run these commands in the [SQL Editor](https://supabase.com/dashboard/project/_/sql/new).",
      "language": "unknown"
    },
    {
      "code": "The database endpoint can be found in the [database settings page](https://supabase.com/dashboard/project/_/settings/database).\n\nWith a database user, password, database endpoint (hostname and port) and database name (default: postgres), you can now set up Hyperdrive.\n\nNote\n\nWhen connecting to Supabase from Hyperdrive, you should use the **Direct connection** connection string rather than the pooled connection strings. Hyperdrive will perform pooling of connections to ensure optimal access from Workers.\n\n## 2. Create a database configuration\n\nTo configure Hyperdrive, you will need:\n\n* The IP address (or hostname) and port of your database.\n* The database username (for example, `hyperdrive-demo`) you configured in a previous step.\n* The password associated with that username.\n* The name of the database you want Hyperdrive to connect to. For example, `postgres`.\n\nHyperdrive accepts the combination of these parameters in the common connection string format used by database drivers:",
      "language": "unknown"
    },
    {
      "code": "Most database providers will provide a connection string you can directly copy-and-paste directly into Hyperdrive.\n\n* Dashboard\n\n  To create a Hyperdrive configuration with the Cloudflare dashboard:\n\n  1. In the Cloudflare dashboard, go to the **Hyperdrive** page.\n\n     [Go to **Hyperdrive**](https://dash.cloudflare.com/?to=/:account/workers/hyperdrive)\n\n  2. Select **Create Configuration**.\n\n  3. Fill out the form, including the connection string.\n\n  4. Select **Create**.\n\n* Wrangler CLI\n\n  To create a Hyperdrive configuration with the [Wrangler CLI](https://developers.cloudflare.com/workers/wrangler/install-and-update/):\n\n  1. Open your terminal and run the following command. Replace `<NAME_OF_HYPERDRIVE_CONFIG>` with a name for your Hyperdrive configuration and paste the connection string provided from your database host, or replace `user`, `password`, `HOSTNAME_OR_IP_ADDRESS`, `port`, and `database_name` placeholders with those specific to your database:",
      "language": "unknown"
    },
    {
      "code": "2. This command outputs a binding for the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/):\n\n     * wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Note\n\nHyperdrive will attempt to connect to your database with the provided credentials to verify they are correct before creating a configuration. If you encounter an error when attempting to connect, refer to Hyperdrive's [troubleshooting documentation](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug possible causes.\n\n## 3. Use Hyperdrive from your Worker\n\nInstall the `node-postgres` driver:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Note\n\nThe minimum version of `node-postgres` required for Hyperdrive is `8.16.3`.\n\nIf using TypeScript, install the types package:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Add the required Node.js compatibility flags and Hyperdrive binding to your `wrangler.jsonc` file:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Create a new `Client` instance and pass the Hyperdrive `connectionString`:",
      "language": "unknown"
    },
    {
      "code": "Note\n\nWhen connecting to a Supabase database with Hyperdrive, you should use a driver like [node-postgres (pg)](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-drivers-and-libraries/node-postgres/) or [Postgres.js](https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-drivers-and-libraries/postgres-js/) to connect directly to the underlying database instead of the [Supabase JavaScript client](https://github.com/supabase/supabase-js). Hyperdrive is optimized for database access for Workers and will perform global connection pooling and fast query routing by connecting directly to your database.\n\n## Next steps\n\n* Learn more about [How Hyperdrive Works](https://developers.cloudflare.com/hyperdrive/concepts/how-hyperdrive-works/).\n* Refer to the [troubleshooting guide](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug common issues.\n* Understand more about other [storage options](https://developers.cloudflare.com/workers/platform/storage-options/) available to Cloudflare Workers.\n\n</page>\n\n<page>\n---\ntitle: Timescale · Cloudflare Hyperdrive docs\ndescription: Connect Hyperdrive to a Timescale time-series database.\nlastUpdated: 2025-08-20T20:59:04.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/timescale/\n  md: https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/timescale/index.md\n---\n\nThis example shows you how to connect Hyperdrive to a [Timescale](https://www.timescale.com/) time-series database. Timescale is built on PostgreSQL, and includes powerful time-series, event and analytics features.\n\nYou can learn more about Timescale by referring to their [Timescale services documentation](https://docs.timescale.com/getting-started/latest/services/).\n\n## 1. Allow Hyperdrive access\n\nYou can connect Hyperdrive to any existing Timescale database by creating a new user and fetching your database connection string.\n\n### Timescale Dashboard\n\nNote\n\nSimilar to most services, Timescale requires you to reset the password associated with your database user if you do not have it stored securely. You should ensure that you do not break any existing clients if when you reset the password.\n\nTo retrieve your credentials and database endpoint in the [Timescale Console](https://console.cloud.timescale.com/):\n\n1. Select the service (database) you want Hyperdrive to connect to.\n2. Expand **Connection info**.\n3. Copy the **Service URL**. The Service URL is the connection string that Hyperdrive will use to connect. This string includes the database hostname, port number and database name.\n\nIf you do not have your password stored, you will need to select **Forgot your password?** and set a new **SCRAM** password. Save this password, as Timescale will only display it once.\n\nYou will end up with a connection string resembling the below:",
      "language": "unknown"
    },
    {
      "code": "With the connection string, you can now create a Hyperdrive database configuration.\n\n## 2. Create a database configuration\n\nTo configure Hyperdrive, you will need:\n\n* The IP address (or hostname) and port of your database.\n* The database username (for example, `hyperdrive-demo`) you configured in a previous step.\n* The password associated with that username.\n* The name of the database you want Hyperdrive to connect to. For example, `postgres`.\n\nHyperdrive accepts the combination of these parameters in the common connection string format used by database drivers:",
      "language": "unknown"
    },
    {
      "code": "Most database providers will provide a connection string you can directly copy-and-paste directly into Hyperdrive.\n\n* Dashboard\n\n  To create a Hyperdrive configuration with the Cloudflare dashboard:\n\n  1. In the Cloudflare dashboard, go to the **Hyperdrive** page.\n\n     [Go to **Hyperdrive**](https://dash.cloudflare.com/?to=/:account/workers/hyperdrive)\n\n  2. Select **Create Configuration**.\n\n  3. Fill out the form, including the connection string.\n\n  4. Select **Create**.\n\n* Wrangler CLI\n\n  To create a Hyperdrive configuration with the [Wrangler CLI](https://developers.cloudflare.com/workers/wrangler/install-and-update/):\n\n  1. Open your terminal and run the following command. Replace `<NAME_OF_HYPERDRIVE_CONFIG>` with a name for your Hyperdrive configuration and paste the connection string provided from your database host, or replace `user`, `password`, `HOSTNAME_OR_IP_ADDRESS`, `port`, and `database_name` placeholders with those specific to your database:",
      "language": "unknown"
    },
    {
      "code": "2. This command outputs a binding for the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/):\n\n     * wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Note\n\nHyperdrive will attempt to connect to your database with the provided credentials to verify they are correct before creating a configuration. If you encounter an error when attempting to connect, refer to Hyperdrive's [troubleshooting documentation](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug possible causes.\n\n## 3. Use Hyperdrive from your Worker\n\nInstall the `node-postgres` driver:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Note\n\nThe minimum version of `node-postgres` required for Hyperdrive is `8.16.3`.\n\nIf using TypeScript, install the types package:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Add the required Node.js compatibility flags and Hyperdrive binding to your `wrangler.jsonc` file:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Create a new `Client` instance and pass the Hyperdrive `connectionString`:",
      "language": "unknown"
    },
    {
      "code": "## Next steps\n\n* Learn more about [How Hyperdrive Works](https://developers.cloudflare.com/hyperdrive/concepts/how-hyperdrive-works/).\n* Refer to the [troubleshooting guide](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug common issues.\n* Understand more about other [storage options](https://developers.cloudflare.com/workers/platform/storage-options/) available to Cloudflare Workers.\n\n</page>\n\n<page>\n---\ntitle: Xata · Cloudflare Hyperdrive docs\ndescription: Connect Hyperdrive to a Xata database instance.\nlastUpdated: 2025-08-20T20:59:04.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/xata/\n  md: https://developers.cloudflare.com/hyperdrive/examples/connect-to-postgres/postgres-database-providers/xata/index.md\n---\n\nThis example shows you how to connect Hyperdrive to a Xata PostgreSQL database instance.\n\n## 1. Allow Hyperdrive access\n\nYou can connect Hyperdrive to any existing Xata PostgreSQL database with the connection string provided by Xata.\n\n### Xata dashboard\n\nTo retrieve your connection string from the Xata dashboard:\n\n1. Go to the [**Xata dashboard**](https://xata.io/).\n2. Select the database you want to connect to.\n3. Copy the `PostgreSQL` connection string.\n\nRefer to the full [Xata documentation](https://xata.io/documentation).\n\n## 2. Create a database configuration\n\nTo configure Hyperdrive, you will need:\n\n* The IP address (or hostname) and port of your database.\n* The database username (for example, `hyperdrive-demo`) you configured in a previous step.\n* The password associated with that username.\n* The name of the database you want Hyperdrive to connect to. For example, `postgres`.\n\nHyperdrive accepts the combination of these parameters in the common connection string format used by database drivers:",
      "language": "unknown"
    },
    {
      "code": "Most database providers will provide a connection string you can directly copy-and-paste directly into Hyperdrive.\n\n* Dashboard\n\n  To create a Hyperdrive configuration with the Cloudflare dashboard:\n\n  1. In the Cloudflare dashboard, go to the **Hyperdrive** page.\n\n     [Go to **Hyperdrive**](https://dash.cloudflare.com/?to=/:account/workers/hyperdrive)\n\n  2. Select **Create Configuration**.\n\n  3. Fill out the form, including the connection string.\n\n  4. Select **Create**.\n\n* Wrangler CLI\n\n  To create a Hyperdrive configuration with the [Wrangler CLI](https://developers.cloudflare.com/workers/wrangler/install-and-update/):\n\n  1. Open your terminal and run the following command. Replace `<NAME_OF_HYPERDRIVE_CONFIG>` with a name for your Hyperdrive configuration and paste the connection string provided from your database host, or replace `user`, `password`, `HOSTNAME_OR_IP_ADDRESS`, `port`, and `database_name` placeholders with those specific to your database:",
      "language": "unknown"
    },
    {
      "code": "2. This command outputs a binding for the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/):\n\n     * wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Note\n\nHyperdrive will attempt to connect to your database with the provided credentials to verify they are correct before creating a configuration. If you encounter an error when attempting to connect, refer to Hyperdrive's [troubleshooting documentation](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug possible causes.\n\n## 3. Use Hyperdrive from your Worker\n\nInstall the `node-postgres` driver:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Note\n\nThe minimum version of `node-postgres` required for Hyperdrive is `8.16.3`.\n\nIf using TypeScript, install the types package:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Add the required Node.js compatibility flags and Hyperdrive binding to your `wrangler.jsonc` file:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Create a new `Client` instance and pass the Hyperdrive `connectionString`:",
      "language": "unknown"
    },
    {
      "code": "## Next steps\n\n* Learn more about [How Hyperdrive Works](https://developers.cloudflare.com/hyperdrive/concepts/how-hyperdrive-works/).\n* Refer to the [troubleshooting guide](https://developers.cloudflare.com/hyperdrive/observability/troubleshooting/) to debug common issues.\n* Understand more about other [storage options](https://developers.cloudflare.com/workers/platform/storage-options/) available to Cloudflare Workers.\n\n</page>\n\n<page>\n---\ntitle: CMB support by dataset · Cloudflare Logs docs\nlastUpdated: 2025-07-28T14:13:32.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/cmb/\n  md: https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/cmb/index.md\n---\n\n\n</page>\n\n<page>\n---\ntitle: Account-scoped datasets · Cloudflare Logs docs\nlastUpdated: 2025-07-25T16:42:51.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/\n  md: https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/index.md\n---\n\n* [Access requests](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/access_requests/)\n* [Audit Logs](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/audit_logs/)\n* [Audit Logs V2](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/audit_logs_v2/)\n* [Browser Isolation User Actions](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/biso_user_actions/)\n* [CASB Findings](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/casb_findings/)\n* [Device posture results](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/device_posture_results/)\n* [DEX Application Tests](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/dex_application_tests/)\n* [DEX Device State Events](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/dex_device_state_events/)\n* [DLP Forensic Copies](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/dlp_forensic_copies/)\n* [DNS Firewall Logs](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/dns_firewall_logs/)\n* [Email security Alerts](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/email_security_alerts/)\n* [Gateway DNS](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/gateway_dns/)\n* [Gateway HTTP](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/gateway_http/)\n* [Gateway Network](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/gateway_network/)\n* [IPSec Logs](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/ipsec_logs/)\n* [Magic IDS Detections](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/magic_ids_detections/)\n* [Network Analytics Logs](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/network_analytics_logs/)\n* [Sinkhole HTTP Logs](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/sinkhole_http_logs/)\n* [SSH Logs](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/ssh_logs/)\n* [WARP Config Changes](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/warp_config_changes/)\n* [WARP Toggle Changes](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/warp_toggle_changes/)\n* [Workers Trace Events](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/workers_trace_events/)\n* [Zero Trust Network Session Logs](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/zero_trust_network_sessions/)\n\n</page>\n\n<page>\n---\ntitle: Zone-scoped datasets · Cloudflare Logs docs\nlastUpdated: 2025-07-25T16:42:51.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/zone/\n  md: https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/zone/index.md\n---\n\n* [DNS logs](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/zone/dns_logs/)\n* [Firewall events](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/zone/firewall_events/)\n* [HTTP requests](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/zone/http_requests/)\n* [NEL reports](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/zone/nel_reports/)\n* [Page Shield events](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/zone/page_shield_events/)\n* [Spectrum events](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/zone/spectrum_events/)\n* [Zaraz Events](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/zone/zaraz_events/)\n\n</page>\n\n<page>\n---\ntitle: Enable Logpush to Amazon S3 · Cloudflare Logs docs\ndescription: Cloudflare Logpush supports pushing logs directly to Amazon S3 via\n  the Cloudflare dashboard or via API. Customers that use AWS GovCloud locations\n  should use our S3-compatible endpoint and not the Amazon S3 endpoint.\nlastUpdated: 2025-10-10T13:43:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/logs/logpush/logpush-job/enable-destinations/aws-s3/\n  md: https://developers.cloudflare.com/logs/logpush/logpush-job/enable-destinations/aws-s3/index.md\n---\n\nCloudflare Logpush supports pushing logs directly to Amazon S3 via the Cloudflare dashboard or via API. Customers that use AWS GovCloud locations should use our **S3-compatible endpoint** and not the **Amazon S3 endpoint**.\n\n## Manage via the Cloudflare dashboard\n\n1. In the Cloudflare dashboard, go to the **Logpush** page at the account or or domain (also known as zone) level.\n\n   For account: [Go to **Logpush**](https://dash.cloudflare.com/?to=/:account/logs)\n\n   For domain (also known as zone): [Go to **Logpush**](https://dash.cloudflare.com/?to=/:account/:zone/analytics/logs)\n\n2. Depending on your choice, you have access to [account-scoped datasets](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/) and [zone-scoped datasets](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/zone/), respectively.\n\n3. Select **Create a Logpush job**.\n\n1) In **Select a destination**, choose **Amazon S3**.\n\n2) Enter or select the following destination information:\n\n   * **Bucket** - S3 bucket name\n   * **Path** - bucket location within the storage container\n   * **Organize logs into daily subfolders** (recommended)\n   * **Bucket region**\n   * If your policy requires [AWS SSE-S3 AES256 Server Side Encryption](https://docs.aws.amazon.com/AmazonS3/latest/userguide/serv-side-encryption.html).\n   * For **Grant Cloudflare access to upload files to your bucket**, make sure your bucket has a [policy](https://docs.aws.amazon.com/AmazonS3/latest/userguide/example-policies-s3.html#iam-policy-ex0) (if you did not add it already):\n     * Copy the JSON policy, then go to your bucket in the Amazon S3 console and paste the policy in **Permissions** > **Bucket Policy** and select **Save**.\n\nWhen you are done entering the destination details, select **Continue**.\n\n1. To prove ownership, Cloudflare will send a file to your designated destination. To find the token, select the **Open** button in the **Overview** tab of the ownership challenge file, then paste it into the Cloudflare dashboard to verify your access to the bucket. Enter the **Ownership Token** and select **Continue**.\n\n2. Select the dataset to push to the storage service.\n\n3. In the next step, you need to configure your logpush job:\n\n   * Enter the **Job name**.\n   * Under **If logs match**, you can select the events to include and/or remove from your logs. Refer to [Filters](https://developers.cloudflare.com/logs/logpush/logpush-job/filters/) for more information. Not all datasets have this option available.\n   * In **Send the following fields**, you can choose to either push all logs to your storage destination or selectively choose which logs you want to push.\n\n4. In **Advanced Options**, you can:\n\n   * Choose the format of timestamp fields in your logs (`RFC3339`(default),`Unix`, or `UnixNano`).\n   * Select a [sampling rate](https://developers.cloudflare.com/logs/logpush/logpush-job/api-configuration/#sampling-rate) for your logs or push a randomly-sampled percentage of logs.\n   * Enable redaction for `CVE-2021-44228`. This option will replace every occurrence of `${` with `x{`.\n\n5. Select **Submit** once you are done configuring your logpush job.\n\n## Create and get access to an S3 bucket\n\nCloudflare uses Amazon Identity and Access Management (IAM) to gain access to your S3 bucket. The Cloudflare IAM user needs `PutObject` permission for the bucket.\n\nLogs are written into that bucket as gzipped objects using the S3 Access Control List (ACL) `Bucket-owner-full-control` permission.\n\nFor illustrative purposes, imagine that you want to store logs in the bucket `burritobot`, in the `logs` directory. The S3 URL would then be `s3://burritobot/logs`.\n\nEnsure **Log Share** permissions are enabled, before attempting to read or configure a Logpush job. For more information refer to the [Roles section](https://developers.cloudflare.com/logs/logpush/permissions/#roles).\n\n\n\nTo enable Logpush to Amazon S3:\n\n1. Create an S3 bucket. Refer to [instructions from Amazon](https://docs.aws.amazon.com/AmazonS3/latest/gsg/CreatingABucket.html).\n\n   Note\n\n   Buckets in China regions (`cn-north-1`, `cn-northwest-1`) are currently not supported.\n\n2. Edit and paste the policy below into **S3** > **Bucket** > **Permissions** > **Bucket Policy**, replacing the `Resource` value with your own bucket path. The `AWS` `Principal` is owned by Cloudflare and should not be changed.",
      "language": "unknown"
    },
    {
      "code": "Note\n\nLogpush uses multipart upload for S3. Aborted uploads will result in incomplete files remaining in your bucket. To minimize your storage costs, Amazon recommends configuring a lifecycle rule using the `AbortIncompleteMultipartUpload` action. Refer to [Uploading and copying objects using multipart upload](https://docs.aws.amazon.com/AmazonS3/latest/dev/mpuoverview.html#mpu-abort-incomplete-mpu-lifecycle-config).\n\n</page>\n\n<page>\n---\ntitle: Enable Logpush to Microsoft Azure · Cloudflare Logs docs\ndescription: Cloudflare Logpush supports pushing logs directly to Microsoft\n  Azure via the Cloudflare dashboard or via API.\nlastUpdated: 2025-11-19T11:40:36.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/logs/logpush/logpush-job/enable-destinations/azure/\n  md: https://developers.cloudflare.com/logs/logpush/logpush-job/enable-destinations/azure/index.md\n---\n\nCloudflare Logpush supports pushing logs directly to Microsoft Azure via the Cloudflare dashboard or via API.\n\nNote\n\nThe [Microsoft Sentinel](https://developers.cloudflare.com/analytics/analytics-integrations/sentinel/) integration for Cloudflare is available in two connector versions.\n\n## Manage via the Cloudflare dashboard\n\n1. In the Cloudflare dashboard, go to the **Logpush** page at the account or or domain (also known as zone) level.\n\n   For account: [Go to **Logpush**](https://dash.cloudflare.com/?to=/:account/logs)\n\n   For domain (also known as zone): [Go to **Logpush**](https://dash.cloudflare.com/?to=/:account/:zone/analytics/logs)\n\n2. Depending on your choice, you have access to [account-scoped datasets](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/) and [zone-scoped datasets](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/zone/), respectively.\n\n3. Select **Create a Logpush job**.\n\n1) In **Select a destination**, choose **Microsoft Azure**.\n\n2) Enter or select the following destination details:\n\n   * **SAS URL** - a pre-signed URL that grants access to Azure Storage resources. Refer to [Azure storage documentation](https://learn.microsoft.com/en-us/azure/storage/storage-explorer/vs-azure-tools-storage-manage-with-storage-explorer?tabs=macos#shared-access-signature-sas-url) for more information on generating a SAS URL using Azure Storage Explorer. The service must be set to Blob-only (`ss=b`), and the resource type must be set to Object-only (`srt=o`).\n   * **Path** - bucket location within the storage container\n   * **Organize logs into daily subfolders** (recommended)\n\nWhen you are done entering the destination details, select **Continue**.\n\n1. Select the dataset to push to the storage service.\n\n2. In the next step, you need to configure your logpush job:\n\n   * Enter the **Job name**.\n   * Under **If logs match**, you can select the events to include and/or remove from your logs. Refer to [Filters](https://developers.cloudflare.com/logs/logpush/logpush-job/filters/) for more information. Not all datasets have this option available.\n   * In **Send the following fields**, you can choose to either push all logs to your storage destination or selectively choose which logs you want to push.\n\n3. In **Advanced Options**, you can:\n\n   * Choose the format of timestamp fields in your logs (`RFC3339`(default),`Unix`, or `UnixNano`).\n   * Select a [sampling rate](https://developers.cloudflare.com/logs/logpush/logpush-job/api-configuration/#sampling-rate) for your logs or push a randomly-sampled percentage of logs.\n   * Enable redaction for `CVE-2021-44228`. This option will replace every occurrence of `${` with `x{`.\n\n4. Select **Submit** once you are done configuring your logpush job.\n\n## Create and get access to a Blob Storage container\n\nCloudflare uses a shared access signature (SAS) token to gain access to your Blob Storage container. You will need to provide `Write` permission and an expiration period of at least five years, which will allow you to not worry about the SAS token expiring.\n\nEnsure **Log Share** permissions are enabled, before attempting to read or configure a Logpush job. For more information refer to the [Roles section](https://developers.cloudflare.com/logs/logpush/permissions/#roles).\n\n\n\nTo enable Logpush to Azure:\n\n1. Create a Blob Storage container. Refer to [instructions from Azure](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-portal).\n\n2. Create a [shared access signature (SAS)](https://learn.microsoft.com/en-us/azure/storage/common/storage-sas-overview) to secure and restrict access to your blob storage container. Use [Storage Explorer](https://learn.microsoft.com/en-us/azure/storage/storage-explorer/vs-azure-tools-storage-manage-with-storage-explorer) to navigate to your container and right click to create a signature. Set the signature to expire at least five years from now and only provide write permission.\n\n3. Provide the SAS URL when prompted by the Logpush API or UI.\n\nNote\n\nLogpush will stop pushing logs if your SAS token expires, which is why an expiration period of at least five years is required. The renewal for your SAS token needs to be done via API, updating the `destination_conf` parameter in your Logpush job.\n\n</page>\n\n<page>\n---\ntitle: Enable Logpush to BigQuery · Cloudflare Logs docs\ndescription: Configure Logpush to send batches of Cloudflare logs to BigQuery.\nlastUpdated: 2025-07-21T15:07:21.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/logs/logpush/logpush-job/enable-destinations/bigquery/\n  md: https://developers.cloudflare.com/logs/logpush/logpush-job/enable-destinations/bigquery/index.md\n---\n\nConfigure Logpush to send batches of Cloudflare logs to BigQuery.\n\nBigQuery supports loading up to 1,500 jobs per table per day (including failures) with up to 10 million files in each load. That means you can load into BigQuery once per minute and include up to 10 million files in a load. For more information, refer to BigQuery's quotas for load jobs.\n\nLogpush delivers batches of logs as soon as possible, which means you could receive more than one batch of files per minute. Ensure your BigQuery job is configured to ingest files on a given time interval, like every minute, as opposed to when files are received. Ingesting files into BigQuery as each Logpush file is received could exhaust your BigQuery quota quickly.\n\nFor a community-supported example of how to set up a schedule job load with BigQuery, refer to [Cloudflare + Google Cloud | Integrations repository](https://github.com/cloudflare/cloudflare-gcp/tree/master/logpush-to-bigquery). Note that this repository is provided on a best-effort basis and is not maintained routinely.\n\n</page>\n\n<page>\n---\ntitle: Dedicated Egress IP for Logpush · Cloudflare Logs docs\ndescription: This guide covers Dedicated CDN Egress IPs and Logpush\n  configuration and testing instructions to enable log delivery with a fixed,\n  dedicated egress IP.\nlastUpdated: 2025-12-19T01:58:33.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/logs/logpush/logpush-job/enable-destinations/egress-ip/\n  md: https://developers.cloudflare.com/logs/logpush/logpush-job/enable-destinations/egress-ip/index.md\n---\n\nThis guide covers [Dedicated CDN Egress IPs](https://developers.cloudflare.com/smart-shield/configuration/dedicated-egress-ips/) and Logpush configuration and testing instructions to enable log delivery with a fixed, dedicated egress IP.\n\n## Prerequisites\n\nTo use Logpush with a dedicated egress IP, you will need to have [Smart Shield Advanced](https://developers.cloudflare.com/smart-shield/get-started/#smart-shield-advanced) with Dedicated CDN Egress IPs (formerly known as Aegis). Note that the Dedicated CDN Egress IPs pool is associated with a zone, not with an account. To use Logpush with dedicated IPs, traffic must be routed to a single zone.\n\nThe general approach is to have your Logpush job proxying Logpush data through a Cloudflare zone with Dedicated CDN Egress IPs enabled to send data to your desired destination. This way your destination will only need to allowlist the provisioned dedicated egress IPs of your proxy zone.\n\nAs a prerequisite, you need to create a dedicated zone or use an existing zone. If using an existing zone, be aware that the zone's egress will be restricted to Dedicated CDN Egress IPs. Make sure all services using that zone will not be impacted.\n\nIt is recommended to use a separate, dedicated zone as a proxy to avoid impacting production systems. If you choose to create a new zone, follow the [steps](https://developers.cloudflare.com/registrar/get-started/register-domain/) to register a new domain with Cloudflare.\n\nThe following example shows how to set up logpush and Dedicated CDN Egress IPs to proxy an HTTPS destination, but the proxying should work for any supported Logpush destination as all destinations use the HTTP protocol underneath.\n\n## 1. Provision dedicated egress IP Pool\n\n1. Work with your Cloudflare account team to purchase [Dedicated CDN Egress IPs](https://developers.cloudflare.com/smart-shield/configuration/dedicated-egress-ips/) for your zone.\n\n2. (Optional but recommended) Request two IPs — one in PDX-B and one in SJC-A — to ensure coverage across regions.\n\n3. Confirm Pool ID once provisioned.\n\n## 2. Configure a zone\n\n1. Register or use an existing zone for the dedicated egress IPs pool.\n2. Contact your account team to get the ID for your dedicated egress IPs pool.\n3. Make a `PATCH` request to the [Edit Zone Setting](https://developers.cloudflare.com/api/resources/zones/subresources/settings/methods/edit/) endpoint:\n\n* Specify `aegis` as the setting ID in the URL.\n* In the request body, set `enabled` to `true` and use the ID from the previous step as `pool_id`.\n\nRequired API token permissions\n\nAt least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n* `Zone Settings Write`",
      "language": "unknown"
    },
    {
      "code": "## 3. Proxy zone setup\n\n1. In your zone, add a DNS record (CNAME or A/AAAA) with **Target** as HTTP destination endpoint.\n\n![Create a DNS record in the Cloudflare dashboard to define the HTTP destination endpoint](https://developers.cloudflare.com/_astro/endpoint.DmFFJC-j_14N2lf.webp)\n\n1. If needed, configure [origin rules](https://developers.cloudflare.com/rules/origin-rules/) to specify a custom port. This is useful if your destination only accepts traffic on a non standard port, for example `12345`. You can configure `logpush.yourdestinationendpoint.com` (without specifying a port, as Cloudflare by default only proxies traffic on HTTP/HTTPS ports) to proxy to `yourdestinationendpoint.com:12345`.\n\n## 4. Configure Logpush\n\n1. Create a Logpush job with the following details:\n\n* Destination: HTTP\n* Endpoint: Use the domain/path set up (the Cloudflare dashboard will auto-validate the destination). Use the server name specified in the **Name** section in the DNS record. In this case, `logpush.yourdestionationendpoint.com`.\n\n![Enter destination details when creating a Logpush job in the Cloudflare dashboard](https://developers.cloudflare.com/_astro/destination-details.imLwZlEZ_1Y0Gk.webp)\n\n* Configuration: Select dataset, job name, filters, and fields. Refer to the [Logpush documentation](https://developers.cloudflare.com/logs/logpush/) for more details.\n\n1. Check destination to confirm if the logs are received.\n\n## 5. Secure your proxy zone endpoint\n\nThe proxy zone hostname is publicly resolvable, but traffic passes through Cloudflare's edge where you can apply security controls. Use the following best practices to protect your endpoint.\n\n### Add a secret header with WAF validation\n\nAdd a secret token as an HTTP header in your Logpush job, then create a WAF rule to block requests without it. This is the recommended approach for most deployments.\n\n**Configure Logpush with a secret header**\n\nAny URL parameter starting with `header_` becomes an HTTP header in the request. When creating or updating your Logpush job, add the secret header to your destination URL:",
      "language": "unknown"
    },
    {
      "code": "Generate a strong random token using `openssl rand -hex 32`.\n\n**Create a WAF custom rule**\n\nIn the proxy zone, go to **Security** > **WAF** > **Custom rules** and create a rule to block requests without the correct secret header.\n\n* **Expression:**",
      "language": "unknown"
    },
    {
      "code": "* **Action:** Block\n\n### Add ASN-based filtering\n\nFor defense in depth, add a rule to only allow traffic from Cloudflare's ASN. Logpush traffic originates from Cloudflare's network (ASN 13335 or 132892).\n\n* **Expression:**",
      "language": "unknown"
    },
    {
      "code": "* **Action:** Block\n\nNote\n\nASN filtering alone is insufficient because other Cloudflare customers' traffic also originates from these ASNs. Always combine with secret header validation.\n\n### Use Access Service Tokens for high-security environments\n\nFor stronger authentication, use [Cloudflare Access Service Tokens](https://developers.cloudflare.com/cloudflare-one/access-controls/service-credentials/service-tokens/) for machine-to-machine authentication. Create a Service Token in the Zero Trust dashboard, then configure Logpush with the Access headers:",
      "language": "unknown"
    },
    {
      "code": "### Verify your security configuration\n\nTest that your WAF rules are blocking unauthorized requests:",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "2. Create a database configuration",
      "id": "2.-create-a-database-configuration"
    },
    {
      "level": "h2",
      "text": "3. Use Hyperdrive from your Worker",
      "id": "3.-use-hyperdrive-from-your-worker"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "1. Allow Hyperdrive access",
      "id": "1.-allow-hyperdrive-access"
    },
    {
      "level": "h3",
      "text": "Materialize Console",
      "id": "materialize-console"
    },
    {
      "level": "h2",
      "text": "2. Create a database configuration",
      "id": "2.-create-a-database-configuration"
    },
    {
      "level": "h2",
      "text": "3. Use Hyperdrive from your Worker",
      "id": "3.-use-hyperdrive-from-your-worker"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "1. Allow Hyperdrive access",
      "id": "1.-allow-hyperdrive-access"
    },
    {
      "level": "h3",
      "text": "Neon Dashboard",
      "id": "neon-dashboard"
    },
    {
      "level": "h2",
      "text": "2. Create a database configuration",
      "id": "2.-create-a-database-configuration"
    },
    {
      "level": "h2",
      "text": "3. Use Hyperdrive from your Worker",
      "id": "3.-use-hyperdrive-from-your-worker"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "1. Allow Hyperdrive access",
      "id": "1.-allow-hyperdrive-access"
    },
    {
      "level": "h3",
      "text": "Nile console",
      "id": "nile-console"
    },
    {
      "level": "h2",
      "text": "2. Create a database configuration",
      "id": "2.-create-a-database-configuration"
    },
    {
      "level": "h2",
      "text": "3. Use Hyperdrive from your Worker",
      "id": "3.-use-hyperdrive-from-your-worker"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "1. Allow Hyperdrive access",
      "id": "1.-allow-hyperdrive-access"
    },
    {
      "level": "h3",
      "text": "pgEdge dashboard",
      "id": "pgedge-dashboard"
    },
    {
      "level": "h2",
      "text": "2. Create a database configuration",
      "id": "2.-create-a-database-configuration"
    },
    {
      "level": "h2",
      "text": "3. Use Hyperdrive from your Worker",
      "id": "3.-use-hyperdrive-from-your-worker"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "1. Allow Hyperdrive access",
      "id": "1.-allow-hyperdrive-access"
    },
    {
      "level": "h3",
      "text": "PlanetScale Dashboard",
      "id": "planetscale-dashboard"
    },
    {
      "level": "h2",
      "text": "2. Create a database configuration",
      "id": "2.-create-a-database-configuration"
    },
    {
      "level": "h2",
      "text": "3. Use Hyperdrive from your Worker",
      "id": "3.-use-hyperdrive-from-your-worker"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "1. Allow Hyperdrive access",
      "id": "1.-allow-hyperdrive-access"
    },
    {
      "level": "h3",
      "text": "Prisma Data Platform",
      "id": "prisma-data-platform"
    },
    {
      "level": "h2",
      "text": "2. Create a database configuration",
      "id": "2.-create-a-database-configuration"
    },
    {
      "level": "h2",
      "text": "3. Use Hyperdrive from your Worker",
      "id": "3.-use-hyperdrive-from-your-worker"
    },
    {
      "level": "h2",
      "text": "4. Configure Hyperdrive maximum connections",
      "id": "4.-configure-hyperdrive-maximum-connections"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "1. Allow Hyperdrive access",
      "id": "1.-allow-hyperdrive-access"
    },
    {
      "level": "h2",
      "text": "2. Create a database configuration",
      "id": "2.-create-a-database-configuration"
    },
    {
      "level": "h2",
      "text": "3. Use Hyperdrive from your Worker",
      "id": "3.-use-hyperdrive-from-your-worker"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "1. Allow Hyperdrive access",
      "id": "1.-allow-hyperdrive-access"
    },
    {
      "level": "h3",
      "text": "Timescale Dashboard",
      "id": "timescale-dashboard"
    },
    {
      "level": "h2",
      "text": "2. Create a database configuration",
      "id": "2.-create-a-database-configuration"
    },
    {
      "level": "h2",
      "text": "3. Use Hyperdrive from your Worker",
      "id": "3.-use-hyperdrive-from-your-worker"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "1. Allow Hyperdrive access",
      "id": "1.-allow-hyperdrive-access"
    },
    {
      "level": "h3",
      "text": "Xata dashboard",
      "id": "xata-dashboard"
    },
    {
      "level": "h2",
      "text": "2. Create a database configuration",
      "id": "2.-create-a-database-configuration"
    },
    {
      "level": "h2",
      "text": "3. Use Hyperdrive from your Worker",
      "id": "3.-use-hyperdrive-from-your-worker"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "Manage via the Cloudflare dashboard",
      "id": "manage-via-the-cloudflare-dashboard"
    },
    {
      "level": "h2",
      "text": "Create and get access to an S3 bucket",
      "id": "create-and-get-access-to-an-s3-bucket"
    },
    {
      "level": "h2",
      "text": "Manage via the Cloudflare dashboard",
      "id": "manage-via-the-cloudflare-dashboard"
    },
    {
      "level": "h2",
      "text": "Create and get access to a Blob Storage container",
      "id": "create-and-get-access-to-a-blob-storage-container"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "1. Provision dedicated egress IP Pool",
      "id": "1.-provision-dedicated-egress-ip-pool"
    },
    {
      "level": "h2",
      "text": "2. Configure a zone",
      "id": "2.-configure-a-zone"
    },
    {
      "level": "h2",
      "text": "3. Proxy zone setup",
      "id": "3.-proxy-zone-setup"
    },
    {
      "level": "h2",
      "text": "4. Configure Logpush",
      "id": "4.-configure-logpush"
    },
    {
      "level": "h2",
      "text": "5. Secure your proxy zone endpoint",
      "id": "5.-secure-your-proxy-zone-endpoint"
    },
    {
      "level": "h3",
      "text": "Add a secret header with WAF validation",
      "id": "add-a-secret-header-with-waf-validation"
    },
    {
      "level": "h3",
      "text": "Add ASN-based filtering",
      "id": "add-asn-based-filtering"
    },
    {
      "level": "h3",
      "text": "Use Access Service Tokens for high-security environments",
      "id": "use-access-service-tokens-for-high-security-environments"
    },
    {
      "level": "h3",
      "text": "Verify your security configuration",
      "id": "verify-your-security-configuration"
    }
  ],
  "url": "llms-txt#the-gcloud-cli-will-replace-any-existing-authorized-networks-with-the-list-you-provide-here.",
  "links": []
}