{
  "title": "llama-2-7b-chat-fp16",
  "content": "Text Generation • Meta\n\n@cf/meta/llama-2-7b-chat-fp16\n\nFull precision (fp16) generative text model with 7 billion parameters from Meta\n\n| Model Info | |\n| - | - |\n| Context Window[](https://developers.cloudflare.com/workers-ai/glossary/) | 4,096 tokens |\n| Terms and License | [link](https://ai.meta.com/resources/models-and-libraries/llama-downloads/) |\n| More information | [link](https://ai.meta.com/llama/) |\n| Unit Pricing | $0.56 per M input tokens, $6.67 per M output tokens |\n\nTry out this model with Workers AI LLM Playground. It does not require any setup or authentication and an instant way to preview and test a model directly in the browser.\n\n[Launch the LLM Playground](https://playground.ai.cloudflare.com/?model=@cf/meta/llama-2-7b-chat-fp16)\n\nOpenAI compatible endpoints\n\nWorkers AI also supports OpenAI compatible API endpoints for `/v1/chat/completions` and `/v1/embeddings`. For more details, refer to [Configurations ](https://developers.cloudflare.com/workers-ai/configuration/open-ai-compatibility/).\n\n\\* indicates a required field\n\n* `prompt` string required min 1\n\nThe input text prompt for the model to generate a response.\n\nName of the LoRA (Low-Rank Adaptation) model to fine-tune the base model.\n\n* `response_format` object\n\nIf true, a chat template is not applied and you must adhere to the specific model's expected formatting.\n\nIf true, the response will be streamed back incrementally using SSE, Server Sent Events.\n\n* `max_tokens` integer default 256\n\nThe maximum number of tokens to generate in the response.\n\n* `temperature` number default 0.6 min 0 max 5\n\nControls the randomness of the output; higher values produce more random results.\n\n* `top_p` number min 0.001 max 1\n\nAdjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses.\n\n* `top_k` integer min 1 max 50\n\nLimits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises.\n\n* `seed` integer min 1 max 9999999999\n\nRandom seed for reproducibility of the generation.\n\n* `repetition_penalty` number min 0 max 2\n\nPenalty for repeated tokens; higher values discourage repetition.\n\n* `frequency_penalty` number min -2 max 2\n\nDecreases the likelihood of the model repeating the same lines verbatim.\n\n* `presence_penalty` number min -2 max 2\n\nIncreases the likelihood of the model introducing new topics.\n\n* `messages` array required\n\nAn array of message objects representing the conversation history.\n\n* `role` string required\n\nThe role of the message sender (e.g., 'user', 'assistant', 'system', 'tool').\n\n* `content` string required\n\nThe content of the message as a string.\n\n* `name` string required\n\n* `code` string required\n\nA list of tools available for the assistant to use.\n\n* `name` string required\n\nThe name of the tool. More descriptive the better.\n\n* `description` string required\n\nA brief description of what the tool does.\n\n* `parameters` object required\n\nSchema defining the parameters accepted by the tool.\n\n* `type` string required\n\nThe type of the parameters object (usually 'object').\n\nList of required parameter names.\n\n* `properties` object required\n\nDefinitions of each parameter.\n\n* `additionalProperties` object\n\n* `type` string required\n\nThe data type of the parameter.\n\n* `description` string required\n\nA description of the expected parameter.\n\n* `type` string required\n\nSpecifies the type of tool (e.g., 'function').\n\n* `function` object required\n\nDetails of the function tool.\n\n* `name` string required\n\nThe name of the function.\n\n* `description` string required\n\nA brief description of what the function does.\n\n* `parameters` object required\n\nSchema defining the parameters accepted by the function.\n\n* `type` string required\n\nThe type of the parameters object (usually 'object').\n\nList of required parameter names.\n\n* `properties` object required\n\nDefinitions of each parameter.\n\n* `additionalProperties` object\n\n* `type` string required\n\nThe data type of the parameter.\n\n* `description` string required\n\nA description of the expected parameter.\n\n* `response_format` object\n\nIf true, a chat template is not applied and you must adhere to the specific model's expected formatting.\n\nIf true, the response will be streamed back incrementally using SSE, Server Sent Events.\n\n* `max_tokens` integer default 256\n\nThe maximum number of tokens to generate in the response.\n\n* `temperature` number default 0.6 min 0 max 5\n\nControls the randomness of the output; higher values produce more random results.\n\n* `top_p` number min 0.001 max 1\n\nAdjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses.\n\n* `top_k` integer min 1 max 50\n\nLimits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises.\n\n* `seed` integer min 1 max 9999999999\n\nRandom seed for reproducibility of the generation.\n\n* `repetition_penalty` number min 0 max 2\n\nPenalty for repeated tokens; higher values discourage repetition.\n\n* `frequency_penalty` number min -2 max 2\n\nDecreases the likelihood of the model repeating the same lines verbatim.\n\n* `presence_penalty` number min -2 max 2\n\nIncreases the likelihood of the model introducing new topics.\n\n* `response` string required\n\nThe generated text response from the model\n\nUsage statistics for the inference request\n\n* `prompt_tokens` number 0\n\nTotal number of tokens in input\n\n* `completion_tokens` number 0\n\nTotal number of tokens in output\n\n* `total_tokens` number 0\n\nTotal number of input and output tokens\n\nAn array of tool calls requests made during the response generation\n\nThe arguments passed to be passed to the tool call request\n\nThe name of the tool to be called\n\nThe following schemas are based on JSON Schema\n\n<page>\n---\ntitle: llama-2-13b-chat-awq · Cloudflare Workers AI docs\ndescription: Llama 2 13B Chat AWQ is an efficient, accurate and blazing-fast\n  low-bit weight quantized Llama 2 variant.\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers-ai/models/llama-2-13b-chat-awq/\n  md: https://developers.cloudflare.com/workers-ai/models/llama-2-13b-chat-awq/index.md\n---",
  "code_samples": [
    {
      "code": "export interface Env {\n  AI: Ai;\n}\n\n\nexport default {\n  async fetch(request, env): Promise<Response> {\n\n\n    const messages = [\n      { role: \"system\", content: \"You are a friendly assistant\" },\n      {\n        role: \"user\",\n        content: \"What is the origin of the phrase Hello, World\",\n      },\n    ];\n\n\n    const stream = await env.AI.run(\"@cf/meta/llama-2-7b-chat-fp16\", {\n      messages,\n      stream: true,\n    });\n\n\n    return new Response(stream, {\n      headers: { \"content-type\": \"text/event-stream\" },\n    });\n  },\n} satisfies ExportedHandler<Env>;",
      "language": "ts"
    },
    {
      "code": "export interface Env {\n  AI: Ai;\n}\n\n\nexport default {\n  async fetch(request, env): Promise<Response> {\n\n\n    const messages = [\n      { role: \"system\", content: \"You are a friendly assistant\" },\n      {\n        role: \"user\",\n        content: \"What is the origin of the phrase Hello, World\",\n      },\n    ];\n    const response = await env.AI.run(\"@cf/meta/llama-2-7b-chat-fp16\", { messages });\n\n\n    return Response.json(response);\n  },\n} satisfies ExportedHandler<Env>;",
      "language": "ts"
    },
    {
      "code": "import os\nimport requests\n\n\nACCOUNT_ID = \"your-account-id\"\nAUTH_TOKEN = os.environ.get(\"CLOUDFLARE_AUTH_TOKEN\")\n\n\nprompt = \"Tell me all about PEP-8\"\nresponse = requests.post(\n  f\"https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/run/@cf/meta/llama-2-7b-chat-fp16\",\n    headers={\"Authorization\": f\"Bearer {AUTH_TOKEN}\"},\n    json={\n      \"messages\": [\n        {\"role\": \"system\", \"content\": \"You are a friendly assistant\"},\n        {\"role\": \"user\", \"content\": prompt}\n      ]\n    }\n)\nresult = response.json()\nprint(result)",
      "language": "py"
    },
    {
      "code": "curl https://api.cloudflare.com/client/v4/accounts/$CLOUDFLARE_ACCOUNT_ID/ai/run/@cf/meta/llama-2-7b-chat-fp16 \\\n  -X POST \\\n  -H \"Authorization: Bearer $CLOUDFLARE_AUTH_TOKEN\" \\\n  -d '{ \"messages\": [{ \"role\": \"system\", \"content\": \"You are a friendly assistant\" }, { \"role\": \"user\", \"content\": \"Why is pizza so good\" }]}'",
      "language": "sh"
    },
    {
      "code": "{\n      \"type\": \"object\",\n      \"oneOf\": [\n          {\n              \"title\": \"Prompt\",\n              \"properties\": {\n                  \"prompt\": {\n                      \"type\": \"string\",\n                      \"minLength\": 1,\n                      \"description\": \"The input text prompt for the model to generate a response.\"\n                  },\n                  \"lora\": {\n                      \"type\": \"string\",\n                      \"description\": \"Name of the LoRA (Low-Rank Adaptation) model to fine-tune the base model.\"\n                  },\n                  \"response_format\": {\n                      \"title\": \"JSON Mode\",\n                      \"type\": \"object\",\n                      \"properties\": {\n                          \"type\": {\n                              \"type\": \"string\",\n                              \"enum\": [\n                                  \"json_object\",\n                                  \"json_schema\"\n                              ]\n                          },\n                          \"json_schema\": {}\n                      }\n                  },\n                  \"raw\": {\n                      \"type\": \"boolean\",\n                      \"default\": false,\n                      \"description\": \"If true, a chat template is not applied and you must adhere to the specific model's expected formatting.\"\n                  },\n                  \"stream\": {\n                      \"type\": \"boolean\",\n                      \"default\": false,\n                      \"description\": \"If true, the response will be streamed back incrementally using SSE, Server Sent Events.\"\n                  },\n                  \"max_tokens\": {\n                      \"type\": \"integer\",\n                      \"default\": 256,\n                      \"description\": \"The maximum number of tokens to generate in the response.\"\n                  },\n                  \"temperature\": {\n                      \"type\": \"number\",\n                      \"default\": 0.6,\n                      \"minimum\": 0,\n                      \"maximum\": 5,\n                      \"description\": \"Controls the randomness of the output; higher values produce more random results.\"\n                  },\n                  \"top_p\": {\n                      \"type\": \"number\",\n                      \"minimum\": 0.001,\n                      \"maximum\": 1,\n                      \"description\": \"Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses.\"\n                  },\n                  \"top_k\": {\n                      \"type\": \"integer\",\n                      \"minimum\": 1,\n                      \"maximum\": 50,\n                      \"description\": \"Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises.\"\n                  },\n                  \"seed\": {\n                      \"type\": \"integer\",\n                      \"minimum\": 1,\n                      \"maximum\": 9999999999,\n                      \"description\": \"Random seed for reproducibility of the generation.\"\n                  },\n                  \"repetition_penalty\": {\n                      \"type\": \"number\",\n                      \"minimum\": 0,\n                      \"maximum\": 2,\n                      \"description\": \"Penalty for repeated tokens; higher values discourage repetition.\"\n                  },\n                  \"frequency_penalty\": {\n                      \"type\": \"number\",\n                      \"minimum\": -2,\n                      \"maximum\": 2,\n                      \"description\": \"Decreases the likelihood of the model repeating the same lines verbatim.\"\n                  },\n                  \"presence_penalty\": {\n                      \"type\": \"number\",\n                      \"minimum\": -2,\n                      \"maximum\": 2,\n                      \"description\": \"Increases the likelihood of the model introducing new topics.\"\n                  }\n              },\n              \"required\": [\n                  \"prompt\"\n              ]\n          },\n          {\n              \"title\": \"Messages\",\n              \"properties\": {\n                  \"messages\": {\n                      \"type\": \"array\",\n                      \"description\": \"An array of message objects representing the conversation history.\",\n                      \"items\": {\n                          \"type\": \"object\",\n                          \"properties\": {\n                              \"role\": {\n                                  \"type\": \"string\",\n                                  \"description\": \"The role of the message sender (e.g., 'user', 'assistant', 'system', 'tool').\"\n                              },\n                              \"content\": {\n                                  \"type\": \"string\",\n                                  \"description\": \"The content of the message as a string.\"\n                              }\n                          },\n                          \"required\": [\n                              \"role\",\n                              \"content\"\n                          ]\n                      }\n                  },\n                  \"functions\": {\n                      \"type\": \"array\",\n                      \"items\": {\n                          \"type\": \"object\",\n                          \"properties\": {\n                              \"name\": {\n                                  \"type\": \"string\"\n                              },\n                              \"code\": {\n                                  \"type\": \"string\"\n                              }\n                          },\n                          \"required\": [\n                              \"name\",\n                              \"code\"\n                          ]\n                      }\n                  },\n                  \"tools\": {\n                      \"type\": \"array\",\n                      \"description\": \"A list of tools available for the assistant to use.\",\n                      \"items\": {\n                          \"type\": \"object\",\n                          \"oneOf\": [\n                              {\n                                  \"properties\": {\n                                      \"name\": {\n                                          \"type\": \"string\",\n                                          \"description\": \"The name of the tool. More descriptive the better.\"\n                                      },\n                                      \"description\": {\n                                          \"type\": \"string\",\n                                          \"description\": \"A brief description of what the tool does.\"\n                                      },\n                                      \"parameters\": {\n                                          \"type\": \"object\",\n                                          \"description\": \"Schema defining the parameters accepted by the tool.\",\n                                          \"properties\": {\n                                              \"type\": {\n                                                  \"type\": \"string\",\n                                                  \"description\": \"The type of the parameters object (usually 'object').\"\n                                              },\n                                              \"required\": {\n                                                  \"type\": \"array\",\n                                                  \"description\": \"List of required parameter names.\",\n                                                  \"items\": {\n                                                      \"type\": \"string\"\n                                                  }\n                                              },\n                                              \"properties\": {\n                                                  \"type\": \"object\",\n                                                  \"description\": \"Definitions of each parameter.\",\n                                                  \"additionalProperties\": {\n                                                      \"type\": \"object\",\n                                                      \"properties\": {\n                                                          \"type\": {\n                                                              \"type\": \"string\",\n                                                              \"description\": \"The data type of the parameter.\"\n                                                          },\n                                                          \"description\": {\n                                                              \"type\": \"string\",\n                                                              \"description\": \"A description of the expected parameter.\"\n                                                          }\n                                                      },\n                                                      \"required\": [\n                                                          \"type\",\n                                                          \"description\"\n                                                      ]\n                                                  }\n                                              }\n                                          },\n                                          \"required\": [\n                                              \"type\",\n                                              \"properties\"\n                                          ]\n                                      }\n                                  },\n                                  \"required\": [\n                                      \"name\",\n                                      \"description\",\n                                      \"parameters\"\n                                  ]\n                              },\n                              {\n                                  \"properties\": {\n                                      \"type\": {\n                                          \"type\": \"string\",\n                                          \"description\": \"Specifies the type of tool (e.g., 'function').\"\n                                      },\n                                      \"function\": {\n                                          \"type\": \"object\",\n                                          \"description\": \"Details of the function tool.\",\n                                          \"properties\": {\n                                              \"name\": {\n                                                  \"type\": \"string\",\n                                                  \"description\": \"The name of the function.\"\n                                              },\n                                              \"description\": {\n                                                  \"type\": \"string\",\n                                                  \"description\": \"A brief description of what the function does.\"\n                                              },\n                                              \"parameters\": {\n                                                  \"type\": \"object\",\n                                                  \"description\": \"Schema defining the parameters accepted by the function.\",\n                                                  \"properties\": {\n                                                      \"type\": {\n                                                          \"type\": \"string\",\n                                                          \"description\": \"The type of the parameters object (usually 'object').\"\n                                                      },\n                                                      \"required\": {\n                                                          \"type\": \"array\",\n                                                          \"description\": \"List of required parameter names.\",\n                                                          \"items\": {\n                                                              \"type\": \"string\"\n                                                          }\n                                                      },\n                                                      \"properties\": {\n                                                          \"type\": \"object\",\n                                                          \"description\": \"Definitions of each parameter.\",\n                                                          \"additionalProperties\": {\n                                                              \"type\": \"object\",\n                                                              \"properties\": {\n                                                                  \"type\": {\n                                                                      \"type\": \"string\",\n                                                                      \"description\": \"The data type of the parameter.\"\n                                                                  },\n                                                                  \"description\": {\n                                                                      \"type\": \"string\",\n                                                                      \"description\": \"A description of the expected parameter.\"\n                                                                  }\n                                                              },\n                                                              \"required\": [\n                                                                  \"type\",\n                                                                  \"description\"\n                                                              ]\n                                                          }\n                                                      }\n                                                  },\n                                                  \"required\": [\n                                                      \"type\",\n                                                      \"properties\"\n                                                  ]\n                                              }\n                                          },\n                                          \"required\": [\n                                              \"name\",\n                                              \"description\",\n                                              \"parameters\"\n                                          ]\n                                      }\n                                  },\n                                  \"required\": [\n                                      \"type\",\n                                      \"function\"\n                                  ]\n                              }\n                          ]\n                      }\n                  },\n                  \"response_format\": {\n                      \"title\": \"JSON Mode\",\n                      \"type\": \"object\",\n                      \"properties\": {\n                          \"type\": {\n                              \"type\": \"string\",\n                              \"enum\": [\n                                  \"json_object\",\n                                  \"json_schema\"\n                              ]\n                          },\n                          \"json_schema\": {}\n                      }\n                  },\n                  \"raw\": {\n                      \"type\": \"boolean\",\n                      \"default\": false,\n                      \"description\": \"If true, a chat template is not applied and you must adhere to the specific model's expected formatting.\"\n                  },\n                  \"stream\": {\n                      \"type\": \"boolean\",\n                      \"default\": false,\n                      \"description\": \"If true, the response will be streamed back incrementally using SSE, Server Sent Events.\"\n                  },\n                  \"max_tokens\": {\n                      \"type\": \"integer\",\n                      \"default\": 256,\n                      \"description\": \"The maximum number of tokens to generate in the response.\"\n                  },\n                  \"temperature\": {\n                      \"type\": \"number\",\n                      \"default\": 0.6,\n                      \"minimum\": 0,\n                      \"maximum\": 5,\n                      \"description\": \"Controls the randomness of the output; higher values produce more random results.\"\n                  },\n                  \"top_p\": {\n                      \"type\": \"number\",\n                      \"minimum\": 0.001,\n                      \"maximum\": 1,\n                      \"description\": \"Adjusts the creativity of the AI's responses by controlling how many possible words it considers. Lower values make outputs more predictable; higher values allow for more varied and creative responses.\"\n                  },\n                  \"top_k\": {\n                      \"type\": \"integer\",\n                      \"minimum\": 1,\n                      \"maximum\": 50,\n                      \"description\": \"Limits the AI to choose from the top 'k' most probable words. Lower values make responses more focused; higher values introduce more variety and potential surprises.\"\n                  },\n                  \"seed\": {\n                      \"type\": \"integer\",\n                      \"minimum\": 1,\n                      \"maximum\": 9999999999,\n                      \"description\": \"Random seed for reproducibility of the generation.\"\n                  },\n                  \"repetition_penalty\": {\n                      \"type\": \"number\",\n                      \"minimum\": 0,\n                      \"maximum\": 2,\n                      \"description\": \"Penalty for repeated tokens; higher values discourage repetition.\"\n                  },\n                  \"frequency_penalty\": {\n                      \"type\": \"number\",\n                      \"minimum\": -2,\n                      \"maximum\": 2,\n                      \"description\": \"Decreases the likelihood of the model repeating the same lines verbatim.\"\n                  },\n                  \"presence_penalty\": {\n                      \"type\": \"number\",\n                      \"minimum\": -2,\n                      \"maximum\": 2,\n                      \"description\": \"Increases the likelihood of the model introducing new topics.\"\n                  }\n              },\n              \"required\": [\n                  \"messages\"\n              ]\n          }\n      ]\n  }",
      "language": "json"
    },
    {
      "code": "{\n      \"oneOf\": [\n          {\n              \"type\": \"object\",\n              \"properties\": {\n                  \"response\": {\n                      \"type\": \"string\",\n                      \"description\": \"The generated text response from the model\"\n                  },\n                  \"usage\": {\n                      \"type\": \"object\",\n                      \"description\": \"Usage statistics for the inference request\",\n                      \"properties\": {\n                          \"prompt_tokens\": {\n                              \"type\": \"number\",\n                              \"description\": \"Total number of tokens in input\",\n                              \"default\": 0\n                          },\n                          \"completion_tokens\": {\n                              \"type\": \"number\",\n                              \"description\": \"Total number of tokens in output\",\n                              \"default\": 0\n                          },\n                          \"total_tokens\": {\n                              \"type\": \"number\",\n                              \"description\": \"Total number of input and output tokens\",\n                              \"default\": 0\n                          }\n                      }\n                  },\n                  \"tool_calls\": {\n                      \"type\": \"array\",\n                      \"description\": \"An array of tool calls requests made during the response generation\",\n                      \"items\": {\n                          \"type\": \"object\",\n                          \"properties\": {\n                              \"arguments\": {\n                                  \"type\": \"object\",\n                                  \"description\": \"The arguments passed to be passed to the tool call request\"\n                              },\n                              \"name\": {\n                                  \"type\": \"string\",\n                                  \"description\": \"The name of the tool to be called\"\n                              }\n                          }\n                      }\n                  }\n              },\n              \"required\": [\n                  \"response\"\n              ]\n          },\n          {\n              \"type\": \"string\",\n              \"format\": \"binary\"\n          }\n      ]\n  }",
      "language": "json"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Playground",
      "id": "playground"
    },
    {
      "level": "h2",
      "text": "Usage",
      "id": "usage"
    },
    {
      "level": "h2",
      "text": "Parameters",
      "id": "parameters"
    },
    {
      "level": "h3",
      "text": "Input",
      "id": "input"
    },
    {
      "level": "h3",
      "text": "Output",
      "id": "output"
    },
    {
      "level": "h2",
      "text": "API Schemas",
      "id": "api-schemas"
    }
  ],
  "url": "llms-txt#llama-2-7b-chat-fp16",
  "links": []
}