{
  "title": "gpt-oss-120b",
  "content": "Text Generation • OpenAI\n\n@cf/openai/gpt-oss-120b\n\nOpenAI’s open-weight models designed for powerful reasoning, agentic tasks, and versatile developer use cases – gpt-oss-120b is for production, general purpose, high reasoning use-cases.\n\n| Model Info | |\n| - | - |\n| Context Window[](https://developers.cloudflare.com/workers-ai/glossary/) | 128,000 tokens |\n| Unit Pricing | $0.35 per M input tokens, $0.75 per M output tokens |\n\n\\* indicates a required field\n\nResponses API Input messages. Refer to OpenAI Responses API docs to learn more about supported content types\n\nResponses API Input messages. Refer to OpenAI Responses API docs to learn more about supported content types\n\nConstrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.\n\nA summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.\n\n* `requests` array required\n\nResponses API Input messages. Refer to OpenAI Responses API docs to learn more about supported content types\n\nResponses API Input messages. Refer to OpenAI Responses API docs to learn more about supported content types\n\nConstrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.\n\nA summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.\n\nThe following schemas are based on JSON Schema\n\n<page>\n---\ntitle: gpt-oss-20b · Cloudflare Workers AI docs\ndescription: OpenAI’s open-weight models designed for powerful reasoning,\n  agentic tasks, and versatile developer use cases – gpt-oss-20b is for lower\n  latency, and local or specialized use-cases.\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers-ai/models/gpt-oss-20b/\n  md: https://developers.cloudflare.com/workers-ai/models/gpt-oss-20b/index.md\n---\n\n![OpenAI logo](https://developers.cloudflare.com/_astro/openai.ChTKThcR.svg)",
  "code_samples": [
    {
      "code": "export default {\n  async fetch(request, env): Promise<Response> {\n    const response = await env.AI.run('@cf/openai/gpt-oss-120b', {\n      instructions: 'You are a concise assistant.',\n      input: 'What is the origin of the phrase Hello, World?',\n    });\n\n\n    return Response.json(response);\n  },\n} satisfies ExportedHandler<Env>;",
      "language": "ts"
    },
    {
      "code": "import os\nimport requests\n\n\nACCOUNT_ID = os.environ.get(\"CLOUDFLARE_ACCOUNT_ID\")\nAUTH_TOKEN = os.environ.get(\"CLOUDFLARE_AUTH_TOKEN\")\n\n\nprompt = \"Tell me all about PEP-8\"\nresponse = requests.post(\n  f\"https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/v1/responses\",\n    headers={\"Authorization\": f\"Bearer {AUTH_TOKEN}\"},\n    json={\n      \"model\": \"@cf/openai/gpt-oss-120b\",\n      \"input\": \"Tell me all about PEP-8\"\n    }\n)\nresult = response.json()\nprint(result)",
      "language": "py"
    },
    {
      "code": "curl https://api.cloudflare.com/client/v4/accounts/$CLOUDFLARE_ACCOUNT_ID/ai/v1/responses   -H \"Content-Type: application/json\"   -H \"Authorization: Bearer $CLOUDFLARE_AUTH_TOKEN\"   -d '{\n    \"model\": \"@cf/openai/gpt-oss-120b\",\n    \"input\": \"What are the benefits of open-source models?\"\n  }'",
      "language": "sh"
    },
    {
      "code": "{\n      \"oneOf\": [\n          {\n              \"type\": \"object\",\n              \"title\": \"Responses\",\n              \"properties\": {\n                  \"input\": {\n                      \"anyOf\": [\n                          {\n                              \"type\": \"string\"\n                          },\n                          {\n                              \"items\": {},\n                              \"type\": \"array\"\n                          }\n                      ],\n                      \"description\": \"Responses API Input messages. Refer to OpenAI Responses API docs to learn more about supported content types\"\n                  },\n                  \"reasoning\": {\n                      \"type\": \"object\",\n                      \"properties\": {\n                          \"effort\": {\n                              \"type\": \"string\",\n                              \"description\": \"Constrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.\",\n                              \"enum\": [\n                                  \"low\",\n                                  \"medium\",\n                                  \"high\"\n                              ]\n                          },\n                          \"summary\": {\n                              \"type\": \"string\",\n                              \"description\": \"A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.\",\n                              \"enum\": [\n                                  \"auto\",\n                                  \"concise\",\n                                  \"detailed\"\n                              ]\n                          }\n                      }\n                  }\n              },\n              \"required\": [\n                  \"input\"\n              ]\n          },\n          {\n              \"type\": \"object\",\n              \"title\": \"Async Request\",\n              \"properties\": {\n                  \"requests\": {\n                      \"type\": \"array\",\n                      \"items\": {\n                          \"type\": \"object\",\n                          \"properties\": {\n                              \"input\": {\n                                  \"anyOf\": [\n                                      {\n                                          \"type\": \"string\"\n                                      },\n                                      {\n                                          \"items\": {},\n                                          \"type\": \"array\"\n                                      }\n                                  ],\n                                  \"description\": \"Responses API Input messages. Refer to OpenAI Responses API docs to learn more about supported content types\"\n                              },\n                              \"reasoning\": {\n                                  \"type\": \"object\",\n                                  \"properties\": {\n                                      \"effort\": {\n                                          \"type\": \"string\",\n                                          \"description\": \"Constrains effort on reasoning for reasoning models. Currently supported values are low, medium, and high. Reducing reasoning effort can result in faster responses and fewer tokens used on reasoning in a response.\",\n                                          \"enum\": [\n                                              \"low\",\n                                              \"medium\",\n                                              \"high\"\n                                          ]\n                                      },\n                                      \"summary\": {\n                                          \"type\": \"string\",\n                                          \"description\": \"A summary of the reasoning performed by the model. This can be useful for debugging and understanding the model's reasoning process. One of auto, concise, or detailed.\",\n                                          \"enum\": [\n                                              \"auto\",\n                                              \"concise\",\n                                              \"detailed\"\n                                          ]\n                                      }\n                                  }\n                              }\n                          },\n                          \"required\": [\n                              \"input\"\n                          ]\n                      }\n                  }\n              },\n              \"required\": [\n                  \"requests\"\n              ]\n          }\n      ]\n  }",
      "language": "json"
    },
    {
      "code": "{\n      \"oneOf\": [\n          {\n              \"type\": \"object\",\n              \"contentType\": \"application/json\"\n          },\n          {\n              \"type\": \"string\",\n              \"contentType\": \"text/event-stream\",\n              \"format\": \"binary\"\n          }\n      ]\n  }",
      "language": "json"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Usage",
      "id": "usage"
    },
    {
      "level": "h2",
      "text": "Parameters",
      "id": "parameters"
    },
    {
      "level": "h3",
      "text": "Input",
      "id": "input"
    },
    {
      "level": "h3",
      "text": "Output",
      "id": "output"
    },
    {
      "level": "h2",
      "text": "API Schemas",
      "id": "api-schemas"
    }
  ],
  "url": "llms-txt#gpt-oss-120b",
  "links": []
}