{
  "title": "no nodejs_compat flags here",
  "content": "typescript\nexport default {\n  async fetch(request, env, ctx): Promise<Response> {\n    process.env.TEST = 'test';\n    return new Response(process.env.TEST);\n  },\n} satisfies ExportedHandler<Env>;\ntypescript\nit('responds with \"test\"', async () => {\n  const response = await SELF.fetch('https://example.com/');\n  expect(await response.text()).toMatchInlineSnapshot(`\"test\"`);\n});\nplaintext\n âœ“ test/index.spec.ts (1)\n   âœ“ responds with \"test\"\n\nTest Files  1 passed (1)\n      Tests  1 passed (1)\nts\n// Example: Seed data\nbeforeAll(async () => {\n  await env.KV.put('message', 'test message');\n  await env.R2.put('file', 'hello-world');\n});\nts\nusing result = await stub.getCounter();\nts\ntest('check if file exists', async () => {\n  await env.R2.put('file', 'hello-world');\n  const response = await env.R2.get('file');\n\nexpect(response).not.toBe(null);\n  // Consume the response body even if you are not asserting it\n  await response.text()\n});\nts\n// index.ts\nexport * from \"@virtual-module\";\nts\nimport { defineWorkersConfig } from \"@cloudflare/vitest-pool-workers/config\";\n\nexport default defineWorkersConfig({\n  test: {\n    poolOptions: {\n      workers: {\n        wrangler: { configPath: \"./wrangler.toml\" },\n        additionalExports: {\n          MyEntrypoint: \"WorkerEntrypoint\",\n        },\n      },\n    },\n  },\n});\ntsx\nimport { defineWorkersConfig } from \"@cloudflare/vitest-pool-workers/config\";\n\nexport default defineWorkersConfig({\n  test: {\n    deps: {\n      optimizer: {\n        ssr: {\n          enabled: true,\n          include: [\"your-package-name\"],\n        },\n      },\n    },\n    poolOptions: {\n      workers: {\n        // ...\n      },\n    },\n  },\n});\nts\n// File: global-setup-wrapper.ts\nimport { createServer } from \"vite\"\n\n// Import the actual global setup file with the correct setup\nconst mod = await viteImport(\"./global-setup.ts\")\n\nexport default mod.default;\n\n// Helper to import the file with default node setup\nasync function viteImport(file: string) {\n  const server = await createServer({\n    root: import.meta.dirname,\n    configFile: false,\n    server: { middlewareMode: true, hmr: false, watch: null, ws: false },\n    optimizeDeps: { noDiscovery: true },\n    clearScreen: false,\n  });\n  const mod = await server.ssrLoadModule(file);\n  await server.close();\n  return mod;\n}\nts\n// File: vitest.config.ts\nimport { defineWorkersConfig } from \"@cloudflare/vitest-pool-workers/config\";\n\nexport default defineWorkersConfig({\n  test: {\n    // Replace the globalSetup with the wrapper file\n    globalSetup: [\"./global-setup-wrapper.ts\"],\n    poolOptions: {\n      workers: {\n        // ...\n      },\n    },\n  },\n});\njs\n    import { env } from \"cloudflare:test\";\n\nit(\"uses binding\", async () => {\n      await env.KV_NAMESPACE.put(\"key\", \"value\");\n      expect(await env.KV_NAMESPACE.get(\"key\")).toBe(\"value\");\n    });\n    ts\n    declare module \"cloudflare:test\" {\n      interface ProvidedEnv {\n        KV_NAMESPACE: KVNamespace;\n      }\n      // ...or if you have an existing `Env` type...\n      interface ProvidedEnv extends Env {}\n    }\n    js\n    import { SELF } from \"cloudflare:test\";\n\nit(\"dispatches fetch event\", async () => {\n      const response = await SELF.fetch(\"https://example.com\");\n      expect(await response.text()).toMatchInlineSnapshot(...);\n    });\n    js\n    import { fetchMock } from \"cloudflare:test\";\n    import { beforeAll, afterEach, it, expect } from \"vitest\";\n\nbeforeAll(() => {\n      // Enable outbound request mocking...\n      fetchMock.activate();\n      // ...and throw errors if an outbound request isn't mocked\n      fetchMock.disableNetConnect();\n    });\n    // Ensure we matched every mock we defined\n    afterEach(() => fetchMock.assertNoPendingInterceptors());\n\nit(\"mocks requests\", async () => {\n      // Mock the first request to `https://example.com`\n      fetchMock\n        .get(\"https://example.com\")\n        .intercept({ path: \"/\" })\n        .reply(200, \"body\");\n\nconst response = await fetch(\"https://example.com/\");\n      expect(await response.text()).toBe(\"body\");\n    });\n    ts\n    import { env, createExecutionContext, waitOnExecutionContext } from \"cloudflare:test\";\n    import { it, expect } from \"vitest\";\n    import worker from \"./index.mjs\";\n\nit(\"calls fetch handler\", async () => {\n      const request = new Request(\"https://example.com\");\n      const ctx = createExecutionContext();\n      const response = await worker.fetch(request, env, ctx);\n      await waitOnExecutionContext(ctx);\n      expect(await response.text()).toMatchInlineSnapshot(...);\n    });\n    ts\n    import { env, createScheduledController, createExecutionContext, waitOnExecutionContext } from \"cloudflare:test\";\n    import { it, expect } from \"vitest\";\n    import worker from \"./index.mjs\";\n\nit(\"calls scheduled handler\", async () => {\n      const ctrl = createScheduledController({\n        scheduledTime: new Date(1000),\n        cron: \"30 * * * *\"\n      });\n      const ctx = createExecutionContext();\n      await worker.scheduled(ctrl, env, ctx);\n      await waitOnExecutionContext(ctx);\n    });\n    ts\n    import { env, createMessageBatch, createExecutionContext, getQueueResult } from \"cloudflare:test\";\n    import { it, expect } from \"vitest\";\n    import worker from \"./index.mjs\";\n\nit(\"calls queue handler\", async () => {\n      const batch = createMessageBatch(\"my-queue\", [\n        {\n          id: \"message-1\",\n          timestamp: new Date(1000),\n          body: \"body-1\"\n        }\n      ]);\n      const ctx = createExecutionContext();\n      await worker.queue(batch, env, ctx);\n      const result = await getQueueResult(batch, ctx);\n      expect(result.ackAll).toBe(false);\n      expect(result.retryBatch).toMatchObject({ retry: false });\n      expect(result.explicitAcks).toStrictEqual([\"message-1\"]);\n      expect(result.retryMessages).toStrictEqual([]);\n    });\n    ts\n    export class Counter {\n      constructor(readonly state: DurableObjectState) {}\n\nasync fetch(request: Request): Promise<Response> {\n        let count = (await this.state.storage.get<number>(\"count\")) ?? 0;\n        void this.state.storage.put(\"count\", ++count);\n        return new Response(count.toString());\n      }\n    }\n    ts\n    import { env, runInDurableObject } from \"cloudflare:test\";\n    import { it, expect } from \"vitest\";\n    import { Counter } from \"./index.ts\";\n\nit(\"increments count\", async () => {\n      const id = env.COUNTER.newUniqueId();\n      const stub = env.COUNTER.get(id);\n      let response = await stub.fetch(\"https://example.com\");\n      expect(await response.text()).toBe(\"1\");\n\nresponse = await runInDurableObject(stub, async (instance: Counter, state) => {\n        expect(instance).toBeInstanceOf(Counter);\n        expect(await state.storage.get<number>(\"count\")).toBe(1);\n\nconst request = new Request(\"https://example.com\");\n        return instance.fetch(request);\n      });\n      expect(await response.text()).toBe(\"2\");\n    });\n    ts\n    import { env, listDurableObjectIds } from \"cloudflare:test\";\n    import { it, expect } from \"vitest\";\n\nit(\"increments count\", async () => {\n      const id = env.COUNTER.newUniqueId();\n      const stub = env.COUNTER.get(id);\n      const response = await stub.fetch(\"https://example.com\");\n      expect(await response.text()).toBe(\"1\");\n\nconst ids = await listDurableObjectIds(env.COUNTER);\n      expect(ids.length).toBe(1);\n      expect(ids[0].equals(id)).toBe(true);\n    });\n    ts\n    import { env, introspectWorkflowInstance } from \"cloudflare:test\";\n\nit(\"should disable all sleeps, mock an event and complete\", async () => {\n      // 1. CONFIGURATION\n      await using instance = await introspectWorkflowInstance(env.MY_WORKFLOW, \"123456\");\n      await instance.modify(async (m) => {\n        await m.disableSleeps();\n        await m.mockEvent({\n          type: \"user-approval\",\n          payload: { approved: true, approverId: \"user-123\" },\n        });\n      });\n\n// 2. EXECUTION\n      await env.MY_WORKFLOW.create({ id: \"123456\" });\n\n// 3. ASSERTION\n      await expect(instance.waitForStatus(\"complete\")).resolves.not.toThrow();\n\n// 4. DISPOSE: is implicit and automatic here.\n    });\n    ts\n    import { env, introspectWorkflow, SELF } from \"cloudflare:test\";\n\nit(\"should disable all sleeps, mock an event and complete\", async () => {\n      // 1. CONFIGURATION\n      await using introspector = await introspectWorkflow(env.MY_WORKFLOW);\n      await introspector.modifyAll(async (m) => {\n        await m.disableSleeps();\n        await m.mockEvent({\n          type: \"user-approval\",\n          payload: { approved: true, approverId: \"user-123\" },\n        });\n      });\n\n// 2. EXECUTION\n      await env.MY_WORKFLOW.create();\n\n// 3. ASSERTION\n      const instances = introspector.get();\n      for(const instance of instances) {\n        await expect(instance.waitForStatus(\"complete\")).resolves.not.toThrow();\n      }\n\n// 4. DISPOSE: is implicit and automatic here.\n    });\n    js\n    // This also works for the EXECUTION phase:\n    await SELF.fetch(\"https://example.com/trigger-workflows\");\n    ts\n    import { env, introspectWorkflowInstance } from \"cloudflare:test\";\n\n// This example showcases explicit disposal\n    it(\"should apply all modifier functions\", async () => {\n      // 1. CONFIGURATION\n      const instance = await introspectWorkflowInstance(env.COMPLEX_WORKFLOW, \"123456\");\n\ntry {\n        // Modify instance behavior\n        await instance.modify(async (m) => {\n          // Disables all sleeps to make the test run instantly\n          await m.disableSleeps();\n\n// Mocks the successful result of a data-fetching step\n          await m.mockStepResult(\n            { name: \"get-order-details\" },\n            { orderId: \"abc-123\", amount: 99.99 }\n          );\n\n// Mocks an incoming event to satisfy a `step.waitForEvent()`\n          await m.mockEvent({\n            type: \"user-approval\",\n            payload: { approved: true, approverId: \"user-123\" },\n          });\n\n// Forces a step to fail once with a specific error to test retry logic\n          await m.mockStepError(\n            { name: \"process-payment\" },\n            new Error(\"Payment gateway timeout\"),\n            1 // Fail only the first time\n          );\n\n// Forces a `step.do()` to time out immediately\n          await m.forceStepTimeout({ name: \"notify-shipping-partner\" });\n\n// Forces a `step.waitForEvent()` to time out\n          await m.forceEventTimeout({ name: \"wait-for-fraud-check\" });\n        });\n\n// 2. EXECUTION\n        await env.COMPLEX_WORKFLOW.create({ id: \"123456\" });\n\n// 3. ASSERTION\n        expect(await instance.waitForStepResult({ name: \"get-order-details\" })).toEqual({\n          orderId: \"abc-123\",\n          amount: 99.99,\n        });\n        // Given the forced timeouts, the workflow will end in an errored state\n        await expect(instance.waitForStatus(\"errored\")).resolves.not.toThrow();\n\n} catch {\n        // 4. DISPOSE\n        await instance.dispose();\n      }\n    });\n    sh\n    npm i -D vitest@~3.2.0 @cloudflare/vitest-pool-workers\n    sh\n    yarn add -D vitest@~3.2.0 @cloudflare/vitest-pool-workers\n    sh\n    pnpm add -D vitest@~3.2.0 @cloudflare/vitest-pool-workers\n    ts\nimport { defineWorkersConfig } from \"@cloudflare/vitest-pool-workers/config\";\n\nexport default defineWorkersConfig({\n  test: {\n    poolOptions: {\n      workers: {\n        wrangler: { configPath: \"./wrangler.jsonc\" },\n      },\n    },\n  },\n});\njs\nexport default defineWorkersConfig({\n  test: {\n    poolOptions: {\n      workers: {\n        wrangler: { configPath: \"./wrangler.jsonc\" },\n        miniflare: {\n          kvNamespaces: [\"TEST_NAMESPACE\"],\n        },\n      },\n    },\n  },\n});\njsonc\n{\n  \"extends\": \"../tsconfig.json\",\n  \"compilerOptions\": {\n    \"moduleResolution\": \"bundler\",\n    \"types\": [\n      \"@cloudflare/vitest-pool-workers\", // provides `cloudflare:test` types\n    ],\n  },\n  \"include\": [\n    \"./**/*.ts\",\n    \"../src/worker-configuration.d.ts\", // output of `wrangler types`\n  ],\n}\nts\ndeclare module \"cloudflare:test\" {\n  // ProvidedEnv controls the type of `import(\"cloudflare:test\").env`\n  interface ProvidedEnv extends Env {}\n}\njs\n  export default {\n    async fetch(request, env, ctx) {\n      if (pathname === \"/404\") {\n        return new Response(\"Not found\", { status: 404 });\n      }\n      return new Response(\"Hello World!\");\n    },\n  };\n  ts\n  export default {\n    async fetch(request, env, ctx): Promise<Response> {\n      if (pathname === \"/404\") {\n        return new Response(\"Not found\", { status: 404 });\n      }\n      return new Response(\"Hello World!\");\n    },\n  } satisfies ExportedHandler<Env>;\n  js\n  import {\n    env,\n    createExecutionContext,\n    waitOnExecutionContext,\n  } from \"cloudflare:test\";\n  import { describe, it, expect } from \"vitest\";\n  // Import your worker so you can unit test it\n  import worker from \"../src\";\n\n// For now, you'll need to do something like this to get a correctly-typed\n  // `Request` to pass to `worker.fetch()`.\n  const IncomingRequest = Request;\n\ndescribe(\"Hello World worker\", () => {\n    it(\"responds with Hello World!\", async () => {\n      const request = new IncomingRequest(\"http://example.com/404\");\n      // Create an empty context to pass to `worker.fetch()`\n      const ctx = createExecutionContext();\n      const response = await worker.fetch(request, env, ctx);\n      // Wait for all `Promise`s passed to `ctx.waitUntil()` to settle before running test assertions\n      await waitOnExecutionContext(ctx);\n      expect(response.status).toBe(404);\n      expect(await response.text()).toBe(\"Not found\");\n    });\n  });\n  ts\n  import {\n    env,\n    createExecutionContext,\n    waitOnExecutionContext,\n  } from \"cloudflare:test\";\n  import { describe, it, expect } from \"vitest\";\n  // Import your worker so you can unit test it\n  import worker from \"../src\";\n\n// For now, you'll need to do something like this to get a correctly-typed\n  // `Request` to pass to `worker.fetch()`.\n  const IncomingRequest = Request<unknown, IncomingRequestCfProperties>;\n\ndescribe(\"Hello World worker\", () => {\n    it(\"responds with Hello World!\", async () => {\n      const request = new IncomingRequest(\"http://example.com/404\");\n      // Create an empty context to pass to `worker.fetch()`\n      const ctx = createExecutionContext();\n      const response = await worker.fetch(request, env, ctx);\n      // Wait for all `Promise`s passed to `ctx.waitUntil()` to settle before running test assertions\n      await waitOnExecutionContext(ctx);\n      expect(response.status).toBe(404);\n      expect(await response.text()).toBe(\"Not found\");\n    });\n  });\n  js\n  import { SELF } from \"cloudflare:test\";\n  import { describe, it, expect } from \"vitest\";\n\ndescribe(\"Hello World worker\", () => {\n    it(\"responds with not found and proper status for /404\", async () => {\n      const response = await SELF.fetch(\"http://example.com/404\");\n      expect(response.status).toBe(404);\n      expect(await response.text()).toBe(\"Not found\");\n    });\n  });\n  ts\n  import { SELF } from \"cloudflare:test\";\n  import { describe, it, expect } from \"vitest\";\n\ndescribe(\"Hello World worker\", () => {\n    it(\"responds with not found and proper status for /404\", async () => {\n      const response = await SELF.fetch(\"http://example.com/404\");\n      expect(response.status).toBe(404);\n      expect(await response.text()).toBe(\"Not found\");\n    });\n  });\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"my-worker\",\n    \"compatibility_date\": \"2025-04-03\",\n    \"main\": \"./src/index.ts\",\n    \"vars\": {\n      \"MY_VAR\": \"Top-level var\"\n    },\n    \"env\": {\n      \"staging\": {\n        \"vars\": {\n          \"MY_VAR\": \"Staging var\"\n        }\n      },\n      \"production\": {\n        \"vars\": {\n          \"MY_VAR\": \"Production var\"\n        }\n      }\n    }\n  }\n  toml\n  name = \"my-worker\"\n  compatibility_date = \"2025-04-03\"\n  main = \"./src/index.ts\"\n\nvars = { MY_VAR = \"Top-level var\" }\n\n[env.staging]\n  vars = { MY_VAR = \"Staging var\" }\n\n[env.production]\n  vars = { MY_VAR = \"Production var\" }\n  json\n{\n  \"name\": \"my-worker\",\n  \"compatibility_date\": \"2025-04-03\",\n  \"main\": \"index.js\",\n  \"vars\": { \"MY_VAR\": \"Production var\" }\n}\nbash\nSECRET_KEY=\"value\"\nAPI_TOKEN=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9\"\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"my-worker\",\n    \"compatibility_date\": \"2025-04-03\",\n    \"main\": \"./src/index.ts\",\n    \"vars\": {\n      \"MY_VAR\": \"Top-level var\"\n    },\n    \"env\": {\n      \"staging\": {\n        \"vars\": {\n          \"MY_VAR\": \"Staging var\"\n        }\n      },\n      \"production\": {\n        \"vars\": {\n          \"MY_VAR\": \"Production var\"\n        }\n      }\n    }\n  }\n  toml\n  # wrangler.toml\n\nname = \"my-worker\"\n  compatibility_date = \"2025-04-03\"\n  main = \"./src/index.ts\"\n\nvars = { MY_VAR = \"Top-level var\" }\n\n[env.staging]\n  vars = { MY_VAR = \"Staging var\" }\n\n[env.production]\n  vars = { MY_VAR = \"Production var\" }\n  sh\nCLOUDFLARE_ENV=staging\nsh\nCLOUDFLARE_ENV=production\nts\nimport { defineConfig } from \"vite\";\nimport { cloudflare } from \"@cloudflare/vite-plugin\";\n\nexport default defineConfig({\n  plugins: [cloudflare()],\n});\njson\n{\n  \"configurations\": [\n    {\n      \"name\": \"<NAME_OF_WORKER>\",\n      \"type\": \"node\",\n      \"request\": \"attach\",\n      \"websocketAddress\": \"ws://localhost:9229/<NAME_OF_WORKER>\",\n      \"resolveSourceMapLocations\": null,\n      \"attachExistingChildren\": false,\n      \"autoAttachChildProcesses\": false,\n      \"sourceMaps\": true\n    }\n  ],\n  \"compounds\": [\n    {\n      \"name\": \"Debug Workers\",\n      \"configurations\": [\"<NAME_OF_WORKER>\"],\n      \"stopAll\": true\n    }\n  ]\n}\nts\nimport { defineConfig } from \"vite\";\nimport { cloudflare } from \"@cloudflare/vite-plugin\";\n\nexport default defineConfig({\n  plugins: [\n    cloudflare({\n      config: {\n        compatibility_date: \"2025-01-01\",\n        vars: {\n          API_URL: \"https://api.example.com\",\n        },\n      },\n    }),\n  ],\n});\nts\nimport { defineConfig } from \"vite\";\nimport { cloudflare } from \"@cloudflare/vite-plugin\";\n\nexport default defineConfig({\n  plugins: [\n    cloudflare({\n      config: (userConfig) => ({\n        vars: {\n          WORKER_NAME: userConfig.name,\n          BUILD_TIME: new Date().toISOString(),\n        },\n      }),\n    }),\n  ],\n});\nts\nimport { defineConfig } from \"vite\";\nimport { cloudflare } from \"@cloudflare/vite-plugin\";\n\nexport default defineConfig({\n  plugins: [\n    cloudflare({\n      config: (userConfig) => {\n        // Replace all existing compatibility flags\n        userConfig.compatibility_flags = [\"nodejs_compat\"];\n      },\n    }),\n  ],\n});\nts\nimport { defineConfig } from \"vite\";\nimport { cloudflare } from \"@cloudflare/vite-plugin\";\n\nexport default defineConfig({\n  plugins: [\n    cloudflare({\n      config: {\n        name: \"entry-worker\",\n        main: \"./src/entry.ts\",\n        compatibility_date: \"2025-01-01\",\n        services: [{ binding: \"API\", service: \"api-worker\" }],\n      },\n      auxiliaryWorkers: [\n        {\n          config: {\n            name: \"api-worker\",\n            main: \"./src/api.ts\",\n            compatibility_date: \"2025-01-01\",\n          },\n        },\n      ],\n    }),\n  ],\n});\nts\nimport { defineConfig } from \"vite\";\nimport { cloudflare } from \"@cloudflare/vite-plugin\";\n\nexport default defineConfig({\n  plugins: [\n    cloudflare({\n      configPath: \"./wrangler.jsonc\",\n      auxiliaryWorkers: [\n        {\n          configPath: \"./workers/api/wrangler.jsonc\",\n          config: {\n            vars: {\n              ENDPOINT: \"https://api.example.com/v2\",\n            },\n          },\n        },\n      ],\n    }),\n  ],\n});\nts\nimport { defineConfig } from \"vite\";\nimport { cloudflare } from \"@cloudflare/vite-plugin\";\n\nexport default defineConfig({\n  plugins: [\n    cloudflare({\n      auxiliaryWorkers: [\n        {\n          config: (_, { entryWorkerConfig }) => ({\n            name: \"auxiliary-worker\",\n            main: \"./src/auxiliary-worker.ts\",\n            // Inherit compatibility settings from entry Worker\n            compatibility_date: entryWorkerConfig.compatibility_date,\n            compatibility_flags: entryWorkerConfig.compatibility_flags,\n          }),\n        },\n      ],\n    }),\n  ],\n});\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"assets\": {\n      \"not_found_handling\": \"single-page-application\"\n    }\n  }\n  toml\n  assets = { not_found_handling = \"single-page-application\" }\n  ts\nimport myImage from \"./my-image.png\";\n\nexport default {\n  fetch(request, env) {\n    return env.ASSETS.fetch(new URL(myImage, request.url));\n  },\n};\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"my-worker\",\n    \"compatibility_date\": \"2025-04-03\",\n    \"main\": \"./src/index.ts\"\n  }\n  toml\n  name = \"my-worker\"\n  compatibility_date = \"2025-04-03\"\n  main = \"./src/index.ts\"\n  ts\nimport { defineConfig } from \"vite\";\nimport { cloudflare } from \"@cloudflare/vite-plugin\";\n\nexport default defineConfig({\n  environments: {\n    my_worker: {\n      define: {\n        __APP_VERSION__: JSON.stringify(\"v1.0.0\"),\n      },\n    },\n  },\n  plugins: [cloudflare()],\n});\nts\nimport { defineConfig } from \"vite\";\nimport { cloudflare } from \"@cloudflare/vite-plugin\";\nimport { reactRouter } from \"@react-router/dev/vite\";\n\nexport default defineConfig({\n  plugins: [cloudflare({ viteEnvironment: { name: \"ssr\" } }), reactRouter()],\n});\nbash\ncurl \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/ai/run/@cf/baai/bge-m3?queueRequest=true\" \\\n --header \"Authorization: Bearer $API_TOKEN\" \\\n --header 'Content-Type: application/json' \\\n --json '{\n    \"requests\": [\n        {\n            \"query\": \"This is a story about Cloudflare\",\n            \"contexts\": [\n                {\n                    \"text\": \"This is a story about an orange cloud\",\n                    \"external_reference\": \"story1\"\n                },\n                {\n                    \"text\": \"This is a story about a llama\",\n                    \"external_reference\": \"story2\"\n                },\n                {\n                    \"text\": \"This is a story about a hugging emoji\",\n                    \"external_reference\": \"story3\"\n                }\n            ]\n        }\n    ]\n  }'\njson\n{\n  \"result\": {\n    \"status\": \"queued\",\n    \"request_id\": \"768f15b7-4fd6-4498-906e-ad94ffc7f8d2\",\n    \"model\": \"@cf/baai/bge-m3\"\n  },\n  \"success\": true,\n  \"errors\": [],\n  \"messages\": []\n}\nbash\ncurl \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/ai/run/@cf/baai/bge-m3?queueRequest=true\" \\\n --header \"Authorization: Bearer $API_TOKEN\" \\\n --header 'Content-Type: application/json' \\\n --json '{\n    \"request_id\": \"<uuid>\"\n  }'\njson\n{\n  \"result\": {\n    \"responses\": [\n      {\n        \"id\": 0,\n        \"result\": {\n          \"response\": [\n            { \"id\": 0, \"score\": 0.73974609375 },\n            { \"id\": 1, \"score\": 0.642578125 },\n            { \"id\": 2, \"score\": 0.6220703125 }\n          ]\n        },\n        \"success\": true,\n        \"external_reference\": null\n      }\n    ],\n    \"usage\": { \"prompt_tokens\": 12, \"completion_tokens\": 0, \"total_tokens\": 12 }\n  },\n  \"success\": true,\n  \"errors\": [],\n  \"messages\": []\n}\nts\nexport interface Env {\n  AI: Ai;\n}\nexport default {\n  async fetch(request, env): Promise<Response> {\n    const embeddings = await env.AI.run(\n      \"@cf/baai/bge-m3\",\n      {\n        requests: [\n          {\n            query: \"This is a story about Cloudflare\",\n            contexts: [\n              {\n                text: \"This is a story about an orange cloud\",\n              },\n              {\n                text: \"This is a story about a llama\",\n              },\n              {\n                text: \"This is a story about a hugging emoji\",\n              },\n            ],\n          },\n        ],\n      },\n      { queueRequest: true },\n    );\n\nreturn Response.json(embeddings);\n  },\n} satisfies ExportedHandler<Env>;\njson\n{\n  \"status\": \"queued\",\n  \"model\": \"@cf/baai/bge-m3\",\n  \"request_id\": \"000-000-000\"\n}\ntypescript\nexport interface Env {\n  AI: Ai;\n}\n\nexport default {\n  async fetch(request, env): Promise<Response> {\n    const status = await env.AI.run(\"@cf/baai/bge-m3\", {\n      request_id: \"000-000-000\",\n    });\n\nreturn Response.json(status);\n  },\n} satisfies ExportedHandler<Env>;\njson\n{\n  \"responses\": [\n    {\n      \"id\": 0,\n      \"result\": {\n        \"response\": [\n          { \"id\": 0, \"score\": 0.73974609375 },\n          { \"id\": 1, \"score\": 0.642578125 },\n          { \"id\": 2, \"score\": 0.6220703125 }\n        ]\n      },\n      \"success\": true,\n      \"external_reference\": null\n    }\n  ],\n  \"usage\": { \"prompt_tokens\": 12, \"completion_tokens\": 0, \"total_tokens\": 12 }\n}\njs\nconst response = await env.AI.run(\"@hf/nousresearch/hermes-2-pro-mistral-7b\", {\n  messages: [\n    {\n      role: \"user\",\n      content: \"what is the weather in london?\",\n    },\n  ],\n  tools: [\n    {\n      name: \"getWeather\",\n      description: \"Return the weather for a latitude and longitude\",\n      parameters: {\n        type: \"object\",\n        properties: {\n          latitude: {\n            type: \"string\",\n            description: \"The latitude for the given location\",\n          },\n          longitude: {\n            type: \"string\",\n            description: \"The longitude for the given location\",\n          },\n        },\n        required: [\"latitude\", \"longitude\"],\n      },\n    },\n  ],\n});\n\nreturn new Response(JSON.stringify(response.tool_calls));\njson\n[\n  {\n    \"arguments\": { \"latitude\": \"51.5074\", \"longitude\": \"-0.1278\" },\n    \"name\": \"getWeather\"\n  }\n]\njson\n{\n  \"alpha_pattern\": {},\n  \"auto_mapping\": null,\n  ...\n  \"target_modules\": [\n    \"q_proj\",\n    \"v_proj\"\n  ],\n  \"task_type\": \"CAUSAL_LM\",\n  \"model_type\": \"mistral\",\n}\nbash\nnpx wrangler ai finetune create <model_name> <finetune_name> <folder_path>\n#ðŸŒ€ Creating new finetune \"test-lora\" for model \"@cf/mistral/mistral-7b-instruct-v0.2-lora\"...\n#ðŸŒ€ Uploading file \"/Users/abcd/Downloads/adapter_config.json\" to \"test-lora\"...\n#ðŸŒ€ Uploading file \"/Users/abcd/Downloads/adapter_model.safetensors\" to \"test-lora\"...\n#âœ… Assets uploaded, finetune \"test-lora\" is ready to use.\n\nnpx wrangler ai finetune list\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ finetune_id                          â”‚ name            â”‚ description â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ 00000000-0000-0000-0000-000000000000 â”‚ test-lora       â”‚             â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\nbash\ncurl \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/ai/finetunes\" \\\n  --request POST \\\n  --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\" \\\n  --json '{\n    \"model\": \"SUPPORTED_MODEL_NAME\",\n    \"name\": \"FINETUNE_NAME\",\n    \"description\": \"OPTIONAL_DESCRIPTION\"\n  }'\nbash\n## Input: finetune_id, adapter_model.safetensors, then adapter_config.json\n## Output: success true/false\n\ncurl -X POST https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/finetunes/{FINETUNE_ID}/finetune-assets/ \\\n    -H 'Authorization: Bearer {API_TOKEN}' \\\n    -H 'Content-Type: multipart/form-data' \\\n    -F 'file_name=adapter_model.safetensors' \\\n    -F 'file=@{PATH/TO/adapter_model.safetensors}'\nbash\ncurl \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/ai/finetunes\" \\\n  --request GET \\\n  --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\"\njson\n{\n  \"success\": true,\n  \"result\": [\n    [\n      {\n        \"id\": \"00000000-0000-0000-0000-000000000\",\n        \"model\": \"@cf/meta-llama/llama-2-7b-chat-hf-lora\",\n        \"name\": \"llama2-finetune\",\n        \"description\": \"test\"\n      },\n      {\n        \"id\": \"00000000-0000-0000-0000-000000000\",\n        \"model\": \"@cf/mistralai/mistral-7b-instruct-v0.2-lora\",\n        \"name\": \"mistral-finetune\",\n        \"description\": \"test\"\n      }\n    ]\n  ]\n}\njavascript\n  const response = await env.AI.run(\n    \"@cf/mistralai/mistral-7b-instruct-v0.2-lora\", //the model supporting LoRAs\n    {\n      messages: [{ role: \"user\", content: \"Hello world\" }],\n      raw: true, //skip applying the default chat template\n      lora: \"00000000-0000-0000-0000-000000000\", //the finetune id OR name\n    },\n  );\n  bash\n  curl https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/run/@cf/mistral/mistral-7b-instruct-v0.2-lora \\\n    -H 'Authorization: Bearer {API_TOKEN}' \\\n    -d '{\n      \"messages\": [{\"role\": \"user\", \"content\": \"Hello world\"}],\n      \"raw\": \"true\",\n      \"lora\": \"00000000-0000-0000-0000-000000000\"\n    }'\n  bash\ncurl \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/ai/finetunes/public\" \\\n  --request GET \\\n  --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\"\nbash\ncurl https://api.cloudflare.com/client/v4/accounts/{account_id}/ai/run/@cf/mistral/mistral-7b-instruct-v0.1 \\\n  --header 'Authorization: Bearer {cf_token}' \\\n  --data '{\n    \"messages\": [\n      {\n        \"role\": \"user\",\n        \"content\": \"Write a python program to check if a number is even or odd.\"\n      }\n    ],\n    \"lora\": \"cf-public-magicoder\"\n  }'\njs\nconst answer = await env.AI.run(\"@cf/mistral/mistral-7b-instruct-v0.1\", {\n  stream: true,\n  raw: true,\n  messages: [\n    {\n      role: \"user\",\n      content:\n        \"Summarize the following: Some newspapers, TV channels and well-known companies publish false news stories to fool people on 1 April. One of the earliest examples of this was in 1957 when a programme on the BBC, the UKs national TV channel, broadcast a report on how spaghetti grew on trees. The film showed a family in Switzerland collecting spaghetti from trees and many people were fooled into believing it, as in the 1950s British people didnt eat much pasta and many didnt know how it was made! Most British people wouldnt fall for the spaghetti trick today, but in 2008 the BBC managed to fool their audience again with their Miracles of Evolution trailer, which appeared to show some special penguins that had regained the ability to fly. Two major UK newspapers, The Daily Telegraph and the Daily Mirror, published the important story on their front pages.\",\n    },\n  ],\n  lora: \"cf-public-cnn-summarization\",\n});\nsh\n  npm create cloudflare@latest -- rag-ai-tutorial\n  sh\n  yarn create cloudflare rag-ai-tutorial\n  sh\n  pnpm create cloudflare@latest rag-ai-tutorial\n  sh\ncd rag-ai-tutorial\nsh\nnpx wrangler dev\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"ai\": {\n      \"binding\": \"AI\",\n      \"remote\": true\n    }\n  }\n  toml\n  [ai]\n  binding = \"AI\"\n  remote = true\n  js\nexport default {\n  async fetch(request, env, ctx) {\n    const answer = await env.AI.run(\"@cf/meta/llama-3-8b-instruct\", {\n      messages: [{ role: \"user\", content: `What is the square root of 9?` }],\n    });\n\nreturn new Response(JSON.stringify(answer));\n  },\n};\nsh\nnpx wrangler deploy\nsh\ncurl https://example.username.workers.dev\nsh\n{\"response\":\"Answer: The square root of 9 is 3.\"}\nsh\nnpx wrangler vectorize create vector-index --dimensions=768 --metric=cosine\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"vectorize\": [\n      {\n        \"binding\": \"VECTOR_INDEX\",\n        \"index_name\": \"vector-index\"\n      }\n    ]\n  }\n  toml\n  # ... existing wrangler configuration\n\n[[vectorize]]\n  binding = \"VECTOR_INDEX\"\n  index_name = \"vector-index\"\n  sh\nnpx wrangler d1 create database\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"d1_databases\": [\n      {\n        \"binding\": \"DB\",\n        \"database_name\": \"database\",\n        \"database_id\": \"abc-def-geh\"\n      }\n    ]\n  }\n  toml\n  # ... existing wrangler configuration\n\n[[d1_databases]]\n  binding = \"DB\" # available in your Worker on env.DB\n  database_name = \"database\"\n  database_id = \"abc-def-geh\" # replace this with a real database_id (UUID)\n  sh\nnpx wrangler d1 execute database --remote --command \"CREATE TABLE IF NOT EXISTS notes (id INTEGER PRIMARY KEY, text TEXT NOT NULL)\"\nsh\nnpx wrangler d1 execute database --remote --command \"INSERT INTO notes (text) VALUES ('The best pizza topping is pepperoni')\"\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"workflows\": [\n      {\n        \"name\": \"rag\",\n        \"binding\": \"RAG_WORKFLOW\",\n        \"class_name\": \"RAGWorkflow\"\n      }\n    ]\n  }\n  toml\n  # ... existing wrangler configuration\n\n[[workflows]]\n  name = \"rag\"\n  binding = \"RAG_WORKFLOW\"\n  class_name = \"RAGWorkflow\"\n  js\nimport { WorkflowEntrypoint } from \"cloudflare:workers\";\n\nexport class RAGWorkflow extends WorkflowEntrypoint {\n  async run(event, step) {\n    await step.do(\"example step\", async () => {\n      console.log(\"Hello World!\");\n    });\n  }\n}\njs\nenv.RAG_WORKFLOW.create({ params: { text } });\nsh\n  npm i hono\n  sh\n  yarn add hono\n  sh\n  pnpm add hono\n  js\nimport { Hono } from \"hono\";\nconst app = new Hono();\n\napp.get(\"/\", async (c) => {\n  const answer = await c.env.AI.run(\"@cf/meta/llama-3-8b-instruct\", {\n    messages: [{ role: \"user\", content: `What is the square root of 9?` }],\n  });\n\nreturn c.json(answer);\n});\n\nexport default app;\njs\nimport { WorkflowEntrypoint } from \"cloudflare:workers\";\n\nexport class RAGWorkflow extends WorkflowEntrypoint {\n  async run(event, step) {\n    const env = this.env;\n    const { text } = event.payload;\n\nconst record = await step.do(`create database record`, async () => {\n      const query = \"INSERT INTO notes (text) VALUES (?) RETURNING *\";\n\nconst { results } = await env.DB.prepare(query).bind(text).run();\n\nconst record = results[0];\n      if (!record) throw new Error(\"Failed to create note\");\n      return record;\n    });\n\nconst embedding = await step.do(`generate embedding`, async () => {\n      const embeddings = await env.AI.run(\"@cf/baai/bge-base-en-v1.5\", {\n        text: text,\n      });\n      const values = embeddings.data[0];\n      if (!values) throw new Error(\"Failed to generate vector embedding\");\n      return values;\n    });\n\nawait step.do(`insert vector`, async () => {\n      return env.VECTOR_INDEX.upsert([\n        {\n          id: record.id.toString(),\n          values: embedding,\n        },\n      ]);\n    });\n  }\n}\njs\napp.post(\"/notes\", async (c) => {\n  const { text } = await c.req.json();\n  if (!text) return c.text(\"Missing text\", 400);\n  await c.env.RAG_WORKFLOW.create({ params: { text } });\n  return c.text(\"Created note\", 201);\n});\njs\nimport { Hono } from \"hono\";\nconst app = new Hono();\n\n// Existing post route...\n// app.post('/notes', async (c) => { ... })\n\napp.get(\"/\", async (c) => {\n  const question = c.req.query(\"text\") || \"What is the square root of 9?\";\n\nconst embeddings = await c.env.AI.run(\"@cf/baai/bge-base-en-v1.5\", {\n    text: question,\n  });\n  const vectors = embeddings.data[0];\n\nconst vectorQuery = await c.env.VECTOR_INDEX.query(vectors, { topK: 1 });\n  let vecId;\n  if (\n    vectorQuery.matches &&\n    vectorQuery.matches.length > 0 &&\n    vectorQuery.matches[0]\n  ) {\n    vecId = vectorQuery.matches[0].id;\n  } else {\n    console.log(\"No matching vector found or vectorQuery.matches is empty\");\n  }\n\nlet notes = [];\n  if (vecId) {\n    const query = `SELECT * FROM notes WHERE id = ?`;\n    const { results } = await c.env.DB.prepare(query).bind(vecId).run();\n    if (results) notes = results.map((vec) => vec.text);\n  }\n\nconst contextMessage = notes.length\n    ? `Context:\\n${notes.map((note) => `- ${note}`).join(\"\\n\")}`\n    : \"\";\n\nconst systemPrompt = `When answering the question or responding, use the context provided, if it is provided and relevant.`;\n\nconst { response: answer } = await c.env.AI.run(\n    \"@cf/meta/llama-3-8b-instruct\",\n    {\n      messages: [\n        ...(notes.length ? [{ role: \"system\", content: contextMessage }] : []),\n        { role: \"system\", content: systemPrompt },\n        { role: \"user\", content: question },\n      ],\n    },\n  );\n\nreturn c.text(answer);\n});\n\napp.onError((err, c) => {\n  return c.text(err);\n});\n\nexport default app;\nsh\n  npm i @anthropic-ai/sdk\n  sh\n  yarn add @anthropic-ai/sdk\n  sh\n  pnpm add @anthropic-ai/sdk\n  js\nimport Anthropic from '@anthropic-ai/sdk';\n\napp.get('/', async (c) => {\n  // ... Existing code\n  const systemPrompt = `When answering the question or responding, use the context provided, if it is provided and relevant.`\n\nlet modelUsed: string = \"\"\n  let response = null\n\nif (c.env.ANTHROPIC_API_KEY) {\n    const anthropic = new Anthropic({\n      apiKey: c.env.ANTHROPIC_API_KEY\n    })\n\nconst model = \"claude-3-5-sonnet-latest\"\n    modelUsed = model\n\nconst message = await anthropic.messages.create({\n      max_tokens: 1024,\n      model,\n      messages: [\n        { role: 'user', content: question }\n      ],\n      system: [systemPrompt, notes ? contextMessage : ''].join(\" \")\n    })\n\nresponse = {\n      response: message.content.map(content => content.text).join(\"\\n\")\n    }\n  } else {\n    const model = \"@cf/meta/llama-3.1-8b-instruct\"\n    modelUsed = model\n\nresponse = await c.env.AI.run(\n      model,\n      {\n        messages: [\n          ...(notes.length ? [{ role: 'system', content: contextMessage }] : []),\n          { role: 'system', content: systemPrompt },\n          { role: 'user', content: question }\n        ]\n      }\n    )\n  }\n\nif (response) {\n    c.header('x-model-used', modelUsed)\n    return c.text(response.response)\n  } else {\n    return c.text(\"We were unable to generate output\", 500)\n  }\n})\nsh\n$ npx wrangler secret put ANTHROPIC_API_KEY\njs\napp.delete(\"/notes/:id\", async (c) => {\n  const { id } = c.req.param();\n\nconst query = `DELETE FROM notes WHERE id = ?`;\n  await c.env.DB.prepare(query).bind(id).run();\n\nawait c.env.VECTOR_INDEX.deleteByIds([id]);\n\nreturn c.status(204);\n});\nsh\n  npm i @langchain/textsplitters\n  sh\n  yarn add @langchain/textsplitters\n  sh\n  pnpm add @langchain/textsplitters\n  js\nimport { RecursiveCharacterTextSplitter } from \"@langchain/textsplitters\";\n\nconst text = \"Some long piece of text...\";\n\nconst splitter = new RecursiveCharacterTextSplitter({\n  // These can be customized to change the chunking size\n  // chunkSize: 1000,\n  // chunkOverlap: 200,\n});\n\nconst output = await splitter.createDocuments([text]);\nconsole.log(output); // [{ pageContent: 'Some long piece of text...' }]\njs\nexport class RAGWorkflow extends WorkflowEntrypoint {\n  async run(event, step) {\n    const env = this.env;\n    const { text } = event.payload;\n    let texts = await step.do(\"split text\", async () => {\n      const splitter = new RecursiveCharacterTextSplitter();\n      const output = await splitter.createDocuments([text]);\n      return output.map((doc) => doc.pageContent);\n    });\n\nconsole.log(\n      \"RecursiveCharacterTextSplitter generated ${texts.length} chunks\",\n    );\n\nfor (const index in texts) {\n      const text = texts[index];\n      const record = await step.do(\n        `create database record: ${index}/${texts.length}`,\n        async () => {\n          const query = \"INSERT INTO notes (text) VALUES (?) RETURNING *\";\n\nconst { results } = await env.DB.prepare(query).bind(text).run();\n\nconst record = results[0];\n          if (!record) throw new Error(\"Failed to create note\");\n          return record;\n        },\n      );\n\nconst embedding = await step.do(\n        `generate embedding: ${index}/${texts.length}`,\n        async () => {\n          const embeddings = await env.AI.run(\"@cf/baai/bge-base-en-v1.5\", {\n            text: text,\n          });\n          const values = embeddings.data[0];\n          if (!values) throw new Error(\"Failed to generate vector embedding\");\n          return values;\n        },\n      );\n\nawait step.do(`insert vector: ${index}/${texts.length}`, async () => {\n        return env.VECTOR_INDEX.upsert([\n          {\n            id: record.id.toString(),\n            values: embedding,\n          },\n        ]);\n      });\n    }\n  }\n}\nsh\nnpx wrangler deploy\nsh\n  npm create cloudflare@latest -- whisper-tutorial\n  sh\n  yarn create cloudflare whisper-tutorial\n  sh\n  pnpm create cloudflare@latest whisper-tutorial\n  sh\ncd whisper-tutorial\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"ai\": {\n      \"binding\": \"AI\"\n    }\n  }\n  toml\n  [ai]\n  binding = \"AI\"\n  jsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\"\n    ],\n    \"compatibility_date\": \"2024-09-23\"\n  }\n  toml\n  compatibility_flags = [ \"nodejs_compat\" ]\n  compatibility_date = \"2024-09-23\"\n  ts\nimport { Buffer } from \"node:buffer\";\nimport type { Ai } from \"workers-ai\";\n\nexport interface Env {\n  AI: Ai;\n  // If needed, add your KV namespace for storing transcripts.\n  // MY_KV_NAMESPACE: KVNamespace;\n}\n\n/**\n * Fetches the audio file from the provided URL and splits it into chunks.\n * This function explicitly follows redirects.\n *\n * @param audioUrl - The URL of the audio file.\n * @returns An array of ArrayBuffers, each representing a chunk of the audio.\n */\nasync function getAudioChunks(audioUrl: string): Promise<ArrayBuffer[]> {\n  const response = await fetch(audioUrl, { redirect: \"follow\" });\n  if (!response.ok) {\n    throw new Error(`Failed to fetch audio: ${response.status}`);\n  }\n  const arrayBuffer = await response.arrayBuffer();\n\n// Example: Split the audio into 1MB chunks.\n  const chunkSize = 1024 * 1024; // 1MB\n  const chunks: ArrayBuffer[] = [];\n  for (let i = 0; i < arrayBuffer.byteLength; i += chunkSize) {\n    const chunk = arrayBuffer.slice(i, i + chunkSize);\n    chunks.push(chunk);\n  }\n  return chunks;\n}\n\n/**\n * Transcribes a single audio chunk using the Whisperâ€‘largeâ€‘v3â€‘turbo model.\n * The function converts the audio chunk to a Base64-encoded string and\n * sends it to the model via the AI binding.\n *\n * @param chunkBuffer - The audio chunk as an ArrayBuffer.\n * @param env - The Cloudflare Worker environment, including the AI binding.\n * @returns The transcription text from the model.\n */\nasync function transcribeChunk(\n  chunkBuffer: ArrayBuffer,\n  env: Env,\n): Promise<string> {\n  const base64 = Buffer.from(chunkBuffer, \"binary\").toString(\"base64\");\n  const res = await env.AI.run(\"@cf/openai/whisper-large-v3-turbo\", {\n    audio: base64,\n    // Optional parameters (uncomment and set if needed):\n    // task: \"transcribe\",   // or \"translate\"\n    // language: \"en\",\n    // vad_filter: \"false\",\n    // initial_prompt: \"Provide context if needed.\",\n    // prefix: \"Transcription:\",\n  });\n  return res.text; // Assumes the transcription result includes a \"text\" property.\n}\n\n/**\n * The main fetch handler. It extracts the 'url' query parameter, fetches the audio,\n * processes it in chunks, and returns the full transcription.\n */\nexport default {\n  async fetch(\n    request: Request,\n    env: Env,\n    ctx: ExecutionContext,\n  ): Promise<Response> {\n    // Extract the audio URL from the query parameters.\n    const { searchParams } = new URL(request.url);\n    const audioUrl = searchParams.get(\"url\");\n\nif (!audioUrl) {\n      return new Response(\"Missing 'url' query parameter\", { status: 400 });\n    }\n\n// Get the audio chunks.\n    const audioChunks: ArrayBuffer[] = await getAudioChunks(audioUrl);\n    let fullTranscript = \"\";\n\n// Process each chunk and build the full transcript.\n    for (const chunk of audioChunks) {\n      try {\n        const transcript = await transcribeChunk(chunk, env);\n        fullTranscript += transcript + \"\\n\";\n      } catch (error) {\n        fullTranscript += \"[Error transcribing chunk]\\n\";\n      }\n    }\n\nreturn new Response(fullTranscript, {\n      headers: { \"Content-Type\": \"text/plain\" },\n    });\n  },\n} satisfies ExportedHandler<Env>;\nsh\nnpx wrangler dev\nsh\ncurl \"http://localhost:8787?url=https://raw.githubusercontent.com/your-username/your-repo/main/your-audio-file.mp3\"\nsh\nnpx wrangler deploy\nsh\ncurl \"https://<your-worker-subdomain>.workers.dev?url=https://raw.githubusercontent.com/your-username/your-repo/main/your-audio-file.mp3\"\nsh\nThis is the transcript of the audio...\npython\nimport sys\n!{sys.executable} -m pip install requests python-dotenv\nplaintext\nRequirement already satisfied: requests in ./venv/lib/python3.12/site-packages (2.31.0)\nRequirement already satisfied: python-dotenv in ./venv/lib/python3.12/site-packages (1.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests) (2023.11.17)\npython\nimport os\nfrom getpass import getpass\n\nfrom IPython.display import display, Image, Markdown, Audio\n\nimport requests\npython\n%load_ext dotenv\n%dotenv\nbash\nCLOUDFLARE_API_TOKEN=\"YOUR-TOKEN\"\nCLOUDFLARE_ACCOUNT_ID=\"YOUR-ACCOUNT-ID\"\npython\nif \"CLOUDFLARE_API_TOKEN\" in os.environ:\n    api_token = os.environ[\"CLOUDFLARE_API_TOKEN\"]\nelse:\n    api_token = getpass(\"Enter you Cloudflare API Token\")\npython\nif \"CLOUDFLARE_ACCOUNT_ID\" in os.environ:\n    account_id = os.environ[\"CLOUDFLARE_ACCOUNT_ID\"]\nelse:\n    account_id = getpass(\"Enter your account id\")\n`python\nmodel = \"@hf/thebloke/deepseek-coder-6.7b-base-awq\"\n\nprompt = \"# A function that checks if a given word is a palindrome\"\n\nresponse = requests.post(\n    f\"https://api.cloudflare.com/client/v4/accounts/{account_id}/ai/run/{model}\",\n    headers={\"Authorization\": f\"Bearer {api_token}\"},\n    json={\"messages\": [\n        {\"role\": \"user\", \"content\": prompt}\n    ]}\n)\ninference = response.json()\ncode = inference[\"result\"][\"response\"]\n\ndisplay(Markdown(f\"\"\"\n    `",
  "code_samples": [
    {
      "code": "In our `src/index.ts` file, we use the `process` object, which is a Node.js global, unavailable in the Workerd runtime:",
      "language": "unknown"
    },
    {
      "code": "The test is a simple assertion that the Worker managed to use `process`.",
      "language": "unknown"
    },
    {
      "code": "Now, if we run `npm run test`, we see that the tests will *pass*:",
      "language": "unknown"
    },
    {
      "code": "And we can run `wrangler dev` and `wrangler deploy` without issues. It *looks like* our code is fine. However, this code will fail in production as `process` is not available in the Workerd runtime.\n\nTo fix the issue, we either need to avoid using Node.js APIs, or add the `nodejs_compat` flag to our Wrangler configuration.\n\n</page>\n\n<page>\n---\ntitle: Known issues Â· Cloudflare Workers docs\ndescription: Explore the known issues associated with the Workers Vitest integration.\nlastUpdated: 2025-12-19T13:52:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/testing/vitest-integration/known-issues/\n  md: https://developers.cloudflare.com/workers/testing/vitest-integration/known-issues/index.md\n---\n\nThe Workers Vitest pool is currently in open beta. The following are issues Cloudflare is aware of and fixing:\n\n### Coverage\n\nNative code coverage via [V8](https://v8.dev/blog/javascript-code-coverage) is not supported. You must use instrumented code coverage via [Istanbul](https://istanbul.js.org/) instead. Refer to the [Vitest Coverage documentation](https://vitest.dev/guide/coverage) for setup instructions.\n\n### Fake timers\n\nVitest's [fake timers](https://vitest.dev/guide/mocking.html#timers) do not apply to KV, R2 and cache simulators. For example, you cannot expire a KV key by advancing fake time.\n\n### Dynamic `import()` statements with `SELF` and Durable Objects\n\nDynamic `import()` statements do not work inside `export default { ... }` handlers when writing integration tests with `SELF`, or inside Durable Object event handlers. You must import and call your handlers directly, or use static `import` statements in the global scope.\n\n### Durable Object alarms\n\nDurable Object alarms are not reset between test runs and do not respect isolated storage. Ensure you delete or run all alarms with [`runDurableObjectAlarm()`](https://developers.cloudflare.com/workers/testing/vitest-integration/test-apis/#durable-objects) scheduled in each test before finishing the test.\n\n### WebSockets\n\nUsing WebSockets with Durable Objects with the [`isolatedStorage`](https://developers.cloudflare.com/workers/testing/vitest-integration/isolation-and-concurrency) flag turned on is not supported. You must set `isolatedStorage: false` in your `vitest.config.ts` file.\n\n### Isolated storage\n\nWhen the `isolatedStorage` flag is enabled (the default), the test runner will undo any writes to the storage at the end of the test as detailed in the [isolation and concurrency documentation](https://developers.cloudflare.com/workers/testing/vitest-integration/isolation-and-concurrency/). However, Cloudflare recommends that you consider the following actions to avoid any common issues:\n\n#### Await all storage operations\n\nAlways `await` all `Promise`s that read or write to storage services.",
      "language": "unknown"
    },
    {
      "code": "#### Explicitly signal resource disposal\n\nWhen calling RPC methods of a Service Worker or Durable Object that return non-primitive values (such as objects or classes extending `RpcTarget`), use the `using` keyword to explicitly signal when resources can be disposed of. See [this example test](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/rpc/test/unit.test.ts#L155) and refer to [explicit-resource-management](https://developers.cloudflare.com/workers/runtime-apis/rpc/lifecycle#explicit-resource-management) for more details.",
      "language": "unknown"
    },
    {
      "code": "#### Consume response bodies\n\nWhen making requests via `fetch` or `R2.get()`, consume the entire response body, even if you are not asserting its content. For example:",
      "language": "unknown"
    },
    {
      "code": "### Missing properties on `ctx.exports`\n\nThe `ctx.exports` property provides access to the exports of the main (`SELF`) Worker. The Workers Vitest integration attempts to automatically infer these exports by statically analyzing the Worker source code using esbuild. However, complex build setups, such as those using virtual modules or wildcard re-exports that esbuild cannot follow, may result in missing properties on the `ctx.exports` object.\n\nFor example, consider a Worker that re-exports an entrypoint from a virtual module using a wildcard export:",
      "language": "unknown"
    },
    {
      "code": "In this case, any exports from `@virtual-module` (such as `MyEntrypoint`) cannot be automatically inferred and will be missing from `ctx.exports`.\n\nTo work around this, add the `additionalExports` option to your Vitest configuration:",
      "language": "unknown"
    },
    {
      "code": "The `additionalExports` option is a map where keys are the export names and values are the type of export (`\"WorkerEntrypoint\"`, `\"DurableObject\"`, or `\"WorkflowEntrypoint\"`).\n\n### Module resolution\n\nIf you encounter module resolution issues such as: `Error: Cannot use require() to import an ES Module` or `Error: No such module`, you can bundle these dependencies using the [deps.optimizer](https://vitest.dev/config/#deps-optimizer) option:",
      "language": "unknown"
    },
    {
      "code": "You can find an example in the [Recipes](https://developers.cloudflare.com/workers/testing/vitest-integration/recipes) page.\n\n### Importing modules from global setup file\n\nAlthough Vitest is set up to resolve packages for the `workerd` runtime, it runs your global setup file in the Node.js environment. This can cause issues when importing packages like [Postgres.js](https://github.com/cloudflare/workers-sdk/issues/6465), which exports a non-Node version for `workerd`. To work around this, you can create a wrapper that uses Vite's SSR module loader to import the global setup file under the correct conditions. Then, adjust your Vitest configuration to point to this wrapper. For example:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Migration guides Â· Cloudflare Workers docs\ndescription: Migrate to using the Workers Vitest integration.\nlastUpdated: 2025-04-10T14:17:11.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/workers/testing/vitest-integration/migration-guides/\n  md: https://developers.cloudflare.com/workers/testing/vitest-integration/migration-guides/index.md\n---\n\n* [Migrate from Miniflare 2's test environments](https://developers.cloudflare.com/workers/testing/vitest-integration/migration-guides/migrate-from-miniflare-2/)\n* [Migrate from unstable\\_dev](https://developers.cloudflare.com/workers/testing/vitest-integration/migration-guides/migrate-from-unstable-dev/)\n\n</page>\n\n<page>\n---\ntitle: Recipes and examples Â· Cloudflare Workers docs\ndescription: Examples that demonstrate how to write unit and integration tests\n  with the Workers Vitest integration.\nlastUpdated: 2025-12-19T13:52:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/testing/vitest-integration/recipes/\n  md: https://developers.cloudflare.com/workers/testing/vitest-integration/recipes/index.md\n---\n\nRecipes are examples that help demonstrate how to write unit tests and integration tests for Workers projects using the [`@cloudflare/vitest-pool-workers`](https://www.npmjs.com/package/@cloudflare/vitest-pool-workers) package.\n\n* [Basic unit and integration tests for Workers using `SELF`](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/basics-unit-integration-self)\n* [Basic unit and integration tests for Pages Functions using `SELF`](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/pages-functions-unit-integration-self)\n* [Basic integration tests using an auxiliary Worker](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/basics-integration-auxiliary)\n* [Basic integration test for Workers with static assets](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/workers-assets)\n* [Isolated tests using KV, R2 and the Cache API](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/kv-r2-caches)\n* [Isolated tests using D1 with migrations](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/d1)\n* [Isolated tests using Durable Objects with direct access](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/durable-objects)\n* [Isolated tests using Workflows](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/workflows)\n* [Tests using Queue producers and consumers](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/queues)\n* [Tests using Hyperdrive with a Vitest managed TCP server](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/hyperdrive)\n* [Tests using declarative/imperative outbound request mocks](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/request-mocking)\n* [Tests using multiple auxiliary Workers and request mocks](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/multiple-workers)\n* [Tests importing WebAssembly modules](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/web-assembly)\n* [Tests using JSRPC with entrypoints and Durable Objects](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/rpc)\n* [Tests using `ctx.exports` to access Worker exports](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/context-exports)\n* [Integration test with static assets and Puppeteer](https://github.com/GregBrimble/puppeteer-vitest-workers-assets)\n* [Resolving modules with Vite Dependency Pre-Bundling](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/module-resolution)\n* [Mocking Workers AI and Vectorize bindings in unit tests](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/ai-vectorize)\n\n</page>\n\n<page>\n---\ntitle: Test APIs Â· Cloudflare Workers docs\ndescription: Runtime helpers for writing tests, exported from the `cloudflare:test` module.\nlastUpdated: 2025-09-12T15:23:11.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/testing/vitest-integration/test-apis/\n  md: https://developers.cloudflare.com/workers/testing/vitest-integration/test-apis/index.md\n---\n\nThe Workers Vitest integration provides runtime helpers for writing tests in the `cloudflare:test` module. The `cloudflare:test` module is provided by the `@cloudflare/vitest-pool-workers` package, but can only be imported from test files that execute in the Workers runtime.\n\n## `cloudflare:test` module definition\n\n* `env`: import(\"cloudflare:test\").ProvidedEnv\n\n  * Exposes the [`env` object](https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch/#parameters) for use as the second argument passed to ES modules format exported handlers. This provides access to [bindings](https://developers.cloudflare.com/workers/runtime-apis/bindings/) that you have defined in your [Vitest configuration file](https://developers.cloudflare.com/workers/testing/vitest-integration/configuration/).",
      "language": "unknown"
    },
    {
      "code": "To configure the type of this value, use an ambient module type:",
      "language": "unknown"
    },
    {
      "code": "* `SELF`: Fetcher\n\n  * [Service binding](https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings/) to the default export defined in the `main` Worker. Use this to write integration tests against your Worker. The `main` Worker runs in the same isolate/context as tests so any global mocks will apply to it too.",
      "language": "unknown"
    },
    {
      "code": "* `fetchMock`: import(\"undici\").MockAgent\n\n  * Declarative interface for mocking outbound `fetch()` requests. Deactivated by default and reset before running each test file. Refer to [`undici`'s `MockAgent` documentation](https://undici.nodejs.org/#/docs/api/MockAgent) for more information. Note this only mocks `fetch()` requests for the current test runner Worker. Auxiliary Workers should mock `fetch()`es using the Miniflare `fetchMock`/`outboundService` options. Refer to [Configuration](https://developers.cloudflare.com/workers/testing/vitest-integration/configuration/#workerspooloptions) for more information.",
      "language": "unknown"
    },
    {
      "code": "### Events\n\n* `createExecutionContext()`: ExecutionContext\n\n  * Creates an instance of the [`context` object](https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch/#parameters) for use as the third argument to ES modules format exported handlers.\n\n* `waitOnExecutionContext(ctx:ExecutionContext)`: Promise\\<void>\n\n  * Use this to wait for all Promises passed to `ctx.waitUntil()` to settle, before running test assertions on any side effects. Only accepts instances of `ExecutionContext` returned by `createExecutionContext()`.",
      "language": "unknown"
    },
    {
      "code": "* `createScheduledController(options?:FetcherScheduledOptions)`: ScheduledController\n\n  * Creates an instance of `ScheduledController` for use as the first argument to modules-format [`scheduled()`](https://developers.cloudflare.com/workers/runtime-apis/handlers/scheduled/) exported handlers.",
      "language": "unknown"
    },
    {
      "code": "* `createMessageBatch(queueName:string, messages:ServiceBindingQueueMessage[])`: MessageBatch\n\n  * Creates an instance of `MessageBatch` for use as the first argument to modules-format [`queue()`](https://developers.cloudflare.com/queues/configuration/javascript-apis/#consumer) exported handlers.\n\n* `getQueueResult(batch:MessageBatch, ctx:ExecutionContext)`: Promise\\<FetcherQueueResult>\n\n  * Gets the acknowledged/retry state of messages in the `MessageBatch`, and waits for all `ExecutionContext#waitUntil()`ed `Promise`s to settle. Only accepts instances of `MessageBatch` returned by `createMessageBatch()`, and instances of `ExecutionContext` returned by `createExecutionContext()`.",
      "language": "unknown"
    },
    {
      "code": "### Durable Objects\n\n* `runInDurableObject<O extends DurableObject, R>(stub:DurableObjectStub, callback:(instance: O, state: DurableObjectState) => R | Promise<R>)`: Promise\\<R>\n\n  * Runs the provided `callback` inside the Durable Object that corresponds to the provided `stub`.\n\n\n\n    This temporarily replaces your Durable Object's `fetch()` handler with `callback`, then sends a request to it, returning the result. This can be used to call/spy-on Durable Object methods or seed/get persisted data. Note this can only be used with `stub`s pointing to Durable Objects defined in the `main` Worker.",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "* `runDurableObjectAlarm(stub:DurableObjectStub)`: Promise\\<boolean>\n\n  * Immediately runs and removes the Durable Object pointed to by `stub`'s alarm if one is scheduled. Returns `true` if an alarm ran, and `false` otherwise. Note this can only be used with `stub`s pointing to Durable Objects defined in the `main` Worker.\n\n* `listDurableObjectIds(namespace:DurableObjectNamespace)`: Promise\\<DurableObjectId\\[]>\n\n  * Gets the IDs of all objects that have been created in the `namespace`. Respects `isolatedStorage` if enabled, meaning objects created in a different test will not be returned.",
      "language": "unknown"
    },
    {
      "code": "### D1\n\n* `applyD1Migrations(db:D1Database, migrations:D1Migration[], migrationTableName?:string)`: Promise\\<void>\n\n  * Applies all un-applied [D1 migrations](https://developers.cloudflare.com/d1/reference/migrations/) stored in the `migrations` array to database `db`, recording migrations state in the `migrationsTableName` table. `migrationsTableName` defaults to `d1_migrations`. Call the [`readD1Migrations()`](https://developers.cloudflare.com/workers/testing/vitest-integration/configuration/#readd1migrationsmigrationspath) function from the `@cloudflare/vitest-pool-workers/config` package inside Node.js to get the `migrations` array. Refer to the [D1Â recipe](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/d1) for an example project using migrations.\n\n### Workflows\n\nWorkflows with `isolatedStorage`\n\nTo ensure proper test isolation in Workflows with isolated storage, introspectors should be disposed at the end of each test. This is accomplished by either:\n\n* Using an `await using` statement on the introspector.\n* Explicitly calling the introspector `dispose()` method.\n\nVersion\n\nAvailable in `@cloudflare/vitest-pool-workers` version **0.9.0**!\n\n* `introspectWorkflowInstance(workflow: Workflow, instanceId: string)`: Promise\\<WorkflowInstanceIntrospector>\n\n  * Creates an **introspector** for a specific Workflow instance, used to **modify** its behavior, **await** outcomes, and **clear** its state during tests. This is the primary entry point for testing individual Workflow instances with a known ID.",
      "language": "unknown"
    },
    {
      "code": "* The returned `WorkflowInstanceIntrospector` object has the following methods:\n\n    * `modify(fn: (m: WorkflowInstanceModifier) => Promise<void>): Promise<void>`: Applies modifications to the Workflow instance's behavior.\n    * `waitForStepResult(step: { name: string; index?: number }): Promise<unknown>`: Waits for a specific step to complete and returns a result. If multiple steps share the same name, use the optional `index` property (1-based, defaults to `1`) to target a specific occurrence.\n    * `waitForStatus(status: InstanceStatus[\"status\"]): Promise<void>`: Waits for the Workflow instance to reach a specific [status](https://developers.cloudflare.com/workflows/build/workers-api/#instancestatus) (e.g., 'running', 'complete').\n    * `dispose(): Promise<void>`: Disposes the Workflow instance, which is crucial for test isolation. If this function isn't called and `await using` is not used, isolated storage will fail and the instance's state will persist across subsequent tests. For example, an instance that becomes completed in one test will already be completed at the start of the next.\n    * `[Symbol.asyncDispose](): Provides automatic dispose. It's invoked by the `await using`statement, which calls`dispose()\\`.\n\n* `introspectWorkflow(workflow: Workflow)`: Promise\\<WorkflowIntrospector>\n\n  * Creates an **introspector** for a Workflow where instance IDs are unknown beforehand. This allows for defining modifications that will apply to **all subsequently created instances**.",
      "language": "unknown"
    },
    {
      "code": "The workflow instance doesn't have to be created directly inside the test. The introspector will capture **all** instances created after it is initialized. For example, you could trigger the creation of **one or multiple** instances via a single `fetch` event to your Worker:",
      "language": "unknown"
    },
    {
      "code": "* The returned `WorkflowIntrospector` object has the following methods:\n\n    * `modifyAll(fn: (m: WorkflowInstanceModifier) => Promise<void>): Promise<void>`: Applies modifications to all Workflow instances created after calling `introspectWorkflow`.\n    * `get(): Promise<WorkflowInstanceIntrospector[]>`: Returns all `WorkflowInstanceIntrospector` objects from instances created after `introspectWorkflow` was called.\n    * `dispose(): Promise<void>`: Disposes the Workflow introspector. All `WorkflowInstanceIntrospector` from created instances will also be disposed. This is crucial to prevent modifications and captured instances from leaking between tests. After calling this method, the `WorkflowIntrospector` should not be reused.\n    * `[Symbol.asyncDispose](): Promise<void>`: Provides automatic dispose. It's invoked by the `await using` statement, which calls `dispose()`.\n\n* `WorkflowInstanceModifier`\n\n  * This object is provided to the `modify` and `modifyAll` callbacks to mock or alter the behavior of a Workflow instance's steps, events, and sleeps.\n\n    * `disableSleeps(steps?: { name: string; index?: number }[])`: Disables sleeps, causing `step.sleep()` and `step.sleepUntil()` to resolve immediately. If `steps` is omitted, all sleeps are disabled.\n    * `mockStepResult(step: { name: string; index?: number }, stepResult: unknown)`: Mocks the result of a `step.do()`, causing it to return the specified value instantly without executing the step's implementation.\n    * `mockStepError(step: { name: string; index?: number }, error: Error, times?: number)`: Forces a `step.do()` to throw an error, simulating a failure. `times` is an optional number that sets how many times the step should error. If `times` is omitted, the step will error on every attempt, making the Workflow instance fail.\n    * `forceStepTimeout(step: { name: string; index?: number }, times?: number)`: Forces a `step.do()` to fail by timing out immediately. `times` is an optional number that sets how many times the step should timeout. If `times` is omitted, the step will timeout on every attempt, making the Workflow instance fail.\n    * `mockEvent(event: { type: string; payload: unknown })`: Sends a mock event to the Workflow instance, causing a `step.waitForEvent()` to resolve with the provided payload. `type` must match the `waitForEvent` type.\n    * `forceEventTimeout(step: { name: string; index?: number })`: Forces a `step.waitForEvent()` to time out instantly, causing the step to fail.",
      "language": "unknown"
    },
    {
      "code": "When targeting a step, use its `name`. If multiple steps share the same name, use the optional `index` property (1-based, defaults to `1`) to specify the occurrence.\n\n</page>\n\n<page>\n---\ntitle: Write your first test Â· Cloudflare Workers docs\ndescription: Write tests against Workers using Vitest\nlastUpdated: 2025-08-18T13:46:45.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/testing/vitest-integration/write-your-first-test/\n  md: https://developers.cloudflare.com/workers/testing/vitest-integration/write-your-first-test/index.md\n---\n\nThis guide will instruct you through getting started with the `@cloudflare/vitest-pool-workers` package. For more complex examples of testing using `@cloudflare/vitest-pool-workers`, refer to [Recipes](https://developers.cloudflare.com/workers/testing/vitest-integration/recipes/).\n\n## Prerequisites\n\nFirst, make sure that:\n\n* Your [compatibility date](https://developers.cloudflare.com/workers/configuration/compatibility-dates/) is set to `2022-10-31` or later.\n\n* Your Worker using the ES modules format (if not, refer to the [migrate to the ES modules format](https://developers.cloudflare.com/workers/reference/migrate-to-module-workers/) guide).\n\n* Vitest and `@cloudflare/vitest-pool-workers` are installed in your project as dev dependencies\n\n  * npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Note\n\n  Currently, the `@cloudflare/vitest-pool-workers` package *only* works with Vitest 2.0.x - 3.2.x.\n\n## Define Vitest configuration\n\nIn your `vitest.config.ts` file, use `defineWorkersConfig` to configure the Workers Vitest integration.\n\nYou can use your Worker configuration from your [Wrangler config file](https://developers.cloudflare.com/workers/wrangler/configuration/) by specifying it with `wrangler.configPath`.",
      "language": "unknown"
    },
    {
      "code": "You can also override or define additional configuration using the `miniflare` key. This takes precedence over values set in via your Wrangler config.\n\nFor example, this configuration would add a KV namespace `TEST_NAMESPACE` that was only accessed and modified in tests.",
      "language": "unknown"
    },
    {
      "code": "For a full list of available Miniflare options, refer to the [Miniflare `WorkersOptions` API documentation](https://github.com/cloudflare/workers-sdk/tree/main/packages/miniflare#interface-workeroptions).\n\nFor a full list of available configuration options, refer to [Configuration](https://developers.cloudflare.com/workers/testing/vitest-integration/configuration/).\n\n## Define types\n\nIf you are not using Typescript, you can skip this section.\n\nFirst make sure you have run [`wrangler types`](https://developers.cloudflare.com/workers/wrangler/commands/), which generates [types for the Cloudflare Workers runtime](https://developers.cloudflare.com/workers/languages/typescript/) and an `Env` type based on your Worker's bindings.\n\nThen add a `tsconfig.json` in your tests folder and add `\"@cloudflare/vitest-pool-workers\"` to your types array to define types for `cloudflare:test`. You should also add the output of `wrangler types` to the `include` array so that the types for the Cloudflare Workers runtime are available.\n\nExample test/tsconfig.json",
      "language": "unknown"
    },
    {
      "code": "You also need to define the type of the `env` object that is provided to your tests. Create an `env.d.ts` file in your tests folder, and declare the `ProvidedEnv` interface by extending the `Env` interface that is generated by `wrangler types`.",
      "language": "unknown"
    },
    {
      "code": "If your test bindings differ from the bindings in your Wrangler config, you should type them here in `ProvidedEnv`.\n\n## Writing tests\n\nWe will use this simple Worker as an example. It returns a 404 response for the `/404` path and `\"Hello World!\"` for all other paths.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "### Unit tests\n\nBy importing the Worker we can write a unit test for its `fetch` handler.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "### Integration tests\n\nYou can use the SELF fetcher provided by the `cloudflare:test` to write an integration test. This is a service binding to the default export defined in the main Worker.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "When using `SELF` for integration tests, your Worker code runs in the same context as the test runner. This means you can use global mocks to control your Worker, but also means your Worker uses the subtly different module resolution behavior provided by Vite. Usually this is not a problem, but to run your Worker in a fresh environment that is as close to production as possible, you can use an auxiliary Worker. Refer to [this example](https://github.com/cloudflare/workers-sdk/blob/main/fixtures/vitest-pool-workers-examples/basics-integration-auxiliary/vitest.config.ts) for how to set up integration tests using auxiliary Workers. However, using auxiliary Workers comes with [limitations](https://developers.cloudflare.com/workers/testing/vitest-integration/configuration/#workerspooloptions) that you should be aware of.\n\n## Related resources\n\n* For more complex examples of testing using `@cloudflare/vitest-pool-workers`, refer to [Recipes](https://developers.cloudflare.com/workers/testing/vitest-integration/recipes/).\n* [Configuration API reference](https://developers.cloudflare.com/workers/testing/vitest-integration/configuration/)\n* [Test APIs reference](https://developers.cloudflare.com/workers/testing/vitest-integration/test-apis/)\n\n</page>\n\n<page>\n---\ntitle: Cloudflare Environments Â· Cloudflare Workers docs\ndescription: Using Cloudflare environments with the Vite plugin\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/vite-plugin/reference/cloudflare-environments/\n  md: https://developers.cloudflare.com/workers/vite-plugin/reference/cloudflare-environments/index.md\n---\n\nA Worker config file may contain configuration for multiple [Cloudflare environments](https://developers.cloudflare.com/workers/wrangler/environments/). With the Cloudflare Vite plugin, you select a Cloudflare environment at dev or build time by providing the `CLOUDFLARE_ENV` environment variable. Consider the following example Worker config file:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "If you run `CLOUDFLARE_ENV=production vite build` then the output `wrangler.json` file generated by the build will be a flattened configuration for the 'production' Cloudflare environment, as shown in the following example:",
      "language": "unknown"
    },
    {
      "code": "Notice that the value of `MY_VAR` is `Production var`. This flattened configuration combines [top-level only](https://developers.cloudflare.com/workers/wrangler/configuration/#top-level-only-keys), [inheritable](https://developers.cloudflare.com/workers/wrangler/configuration/#inheritable-keys), and [non-inheritable](https://developers.cloudflare.com/workers/wrangler/configuration/#non-inheritable-keys) keys.\n\nNote\n\nThe default Vite environment name for a Worker is always the top-level Worker name. This enables you to reference the Worker consistently in your Vite config when using multiple Cloudflare environments. See [Vite Environments](https://developers.cloudflare.com/workers/vite-plugin/reference/vite-environments/) for more information.\n\nCloudflare environments can also be used in development. For example, you could run `CLOUDFLARE_ENV=development vite dev`. It is common to use the default top-level environment as the development environment and then add additional environments as necessary.\n\nNote\n\nRunning `vite dev` or `vite build` without providing `CLOUDFLARE_ENV` will use the default top-level Cloudflare environment. As Cloudflare environments are applied at dev and build time, specifying `CLOUDFLARE_ENV` when running `vite preview` or `wrangler deploy` will have no effect.\n\n## Secrets in local development\n\nWarning\n\nDo not use `vars` to store sensitive information in your Worker's Wrangler configuration file. Use secrets instead.\n\nPut secrets for use in local development in either a `.dev.vars` file or a `.env` file, in the same directory as the Wrangler configuration file.\n\nChoose to use either `.dev.vars` or `.env` but not both. If you define a `.dev.vars` file, then values in `.env` files will not be included in the `env` object during local development.\n\nThese files should be formatted using the [dotenv](https://hexdocs.pm/dotenvy/dotenv-file-format.html) syntax. For example:",
      "language": "unknown"
    },
    {
      "code": "Do not commit secrets to git\n\nThe `.dev.vars` and `.env` files should not committed to git. Add `.dev.vars*` and `.env*` to your project's `.gitignore` file.\n\nTo set different secrets for each Cloudflare environment, create files named `.dev.vars.<environment-name>` or `.env.<environment-name>`.\n\nWhen you select a Cloudflare environment in your local development, the corresponding environment-specific file will be loaded ahead of the generic `.dev.vars` (or `.env`) file.\n\n* When using `.dev.vars.<environment-name>` files, all secrets must be defined per environment. If `.dev.vars.<environment-name>` exists then only this will be loaded; the `.dev.vars` file will not be loaded.\n\n* In contrast, all matching `.env` files are loaded and the values are merged. For each variable, the value from the most specific file is used, with the following precedence:\n\n  * `.env.<environment-name>.local` (most specific)\n  * `.env.local`\n  * `.env.<environment-name>`\n  * `.env` (least specific)\n\nControlling `.env` handling\n\nIt is possible to control how `.env` files are loaded in local development by setting environment variables on the process running the tools.\n\n* To disable loading local dev vars from `.env` files without providing a `.dev.vars` file, set the `CLOUDFLARE_LOAD_DEV_VARS_FROM_DOT_ENV` environment variable to `\"false\"`.\n* To include every environment variable defined in your system's process environment as a local development variable, ensure there is no `.dev.vars` and then set the `CLOUDFLARE_INCLUDE_PROCESS_ENV` environment variable to `\"true\"`.\n\n## Combining Cloudflare environments and Vite modes\n\nYou may wish to combine the concepts of [Cloudflare environments](https://developers.cloudflare.com/workers/wrangler/environments/) and [Vite modes](https://vite.dev/guide/env-and-mode.html#modes). With this approach, the Vite mode can be used to select the Cloudflare environment and a single method can be used to determine environment specific configuration and code. Consider again the previous example:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Next, provide `.env.staging` and `.env.production` files:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "By default, `vite build` uses the 'production' Vite mode. Vite will therefore load the `.env.production` file to get the environment variables that are used in the build. Since the `.env.production` file contains `CLOUDFLARE_ENV=production`, the Cloudflare Vite plugin will select the 'production' Cloudflare environment. The value of `MY_VAR` will therefore be `'Production var'`. If you run `vite build --mode staging` then the 'staging' Vite mode will be used and the 'staging' Cloudflare environment will be selected. The value of `MY_VAR` will therefore be `'Staging var'`.\n\nFor more information about using `.env` files with Vite, see the [relevant documentation](https://vite.dev/guide/env-and-mode#env-files).\n\n</page>\n\n<page>\n---\ntitle: API Â· Cloudflare Workers docs\ndescription: Vite plugin API\nlastUpdated: 2025-12-18T13:44:09.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/vite-plugin/reference/api/\n  md: https://developers.cloudflare.com/workers/vite-plugin/reference/api/index.md\n---\n\n## `cloudflare()`\n\nThe `cloudflare` plugin should be included in the Vite `plugins` array:",
      "language": "unknown"
    },
    {
      "code": "It accepts an optional `PluginConfig` parameter.\n\n## `interface PluginConfig`\n\n* `configPath` string optional\n\n  An optional path to your Worker config file. By default, a `wrangler.jsonc`, `wrangler.json`, or `wrangler.toml` file in the root of your application will be used as the Worker config.\n\n  For more information about the Worker configuration, see [Configuration](https://developers.cloudflare.com/workers/wrangler/configuration/).\n\n* `config` WorkerConfigCustomizer\\<true> optional\n\n  Customize or override Worker configuration programmatically. Accepts a partial configuration object or a function that receives the current config.\n\n  Applied after any config file loads. Use it to override values, modify the existing config, or define Workers entirely in code.\n\n  See [Programmatic configuration](https://developers.cloudflare.com/workers/vite-plugin/reference/programmatic-configuration/) for details.\n\n* `viteEnvironment` { name?: string } optional\n\n  Optional Vite environment options. By default, the environment name is the Worker name with `-` characters replaced with `_`. Setting the name here will override this. A typical use case is setting `viteEnvironment: { name: \"ssr\" }` to apply the Worker to the SSR environment.\n\n  See [Vite Environments](https://developers.cloudflare.com/workers/vite-plugin/reference/vite-environments/) for more information.\n\n* `persistState` boolean | { path: string } optional\n\n  An optional override for state persistence. By default, state is persisted to `.wrangler/state`. A custom `path` can be provided or, alternatively, persistence can be disabled by setting the value to `false`.\n\n* `inspectorPort` number | false optional\n\n  An optional override for debugging your Workers. By default, the debugging inspector is enabled and listens on port `9229`. A custom port can be provided or, alternatively, setting this to `false` will disable the debugging inspector.\n\n  See [Debugging](https://developers.cloudflare.com/workers/vite-plugin/reference/debugging/) for more information.\n\n* `auxiliaryWorkers` Array\\<AuxiliaryWorkerConfig> optional\n\n  An optional array of auxiliary Workers. Auxiliary Workers are additional Workers that are used as part of your application. You can use [service bindings](https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings/) to call auxiliary Workers from your main (entry) Worker. All requests are routed through your entry Worker. During the build, each Worker is output to a separate subdirectory of `dist`.\n\n  Note\n\n  Auxiliary Workers are not currently supported when using [React Router](https://reactrouter.com/) as a framework.\n\n  Note\n\n  When running `wrangler deploy`, only your main (entry) Worker will be deployed. If using multiple Workers, each auxiliary Worker must be deployed individually. You can inspect the `dist` directory and then run `wrangler deploy -c dist/<auxiliary-worker>/wrangler.json` for each.\n\n## `interface AuxiliaryWorkerConfig`\n\nAuxiliary Workers require a `configPath`, a `config` option, or both.\n\n* `configPath` string optional\n\n  The path to your Worker config file. This field is required unless `config` is provided.\n\n  For more information about the Worker configuration, see [Configuration](https://developers.cloudflare.com/workers/wrangler/configuration/).\n\n* `config` WorkerConfigCustomizer\\<false> optional\n\n  Customize or override Worker configuration programmatically. When used without `configPath`, this allows defining auxiliary Workers entirely in code.\n\n  See [Programmatic configuration](https://developers.cloudflare.com/workers/vite-plugin/reference/programmatic-configuration/) for usage examples.\n\n* `viteEnvironment` { name?: string } optional\n\n  Optional Vite environment options. By default, the environment name is the Worker name with `-` characters replaced with `_`. Setting the name here will override this.\n\n  See [Vite Environments](https://developers.cloudflare.com/workers/vite-plugin/reference/vite-environments/) for more information.\n\n</page>\n\n<page>\n---\ntitle: Debugging Â· Cloudflare Workers docs\ndescription: Debugging with the Vite plugin\nlastUpdated: 2025-04-04T07:52:43.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/vite-plugin/reference/debugging/\n  md: https://developers.cloudflare.com/workers/vite-plugin/reference/debugging/index.md\n---\n\nThe Cloudflare Vite plugin has debugging enabled by default and listens on port `9229`. You may choose a custom port or disable debugging by setting the `inspectorPort` option in the [plugin config](https://developers.cloudflare.com/workers/vite-plugin/reference/api#interface-pluginconfig). There are two recommended methods for debugging your Workers during local development:\n\n## DevTools\n\nWhen running `vite dev` or `vite preview`, a `/__debug` route is added that provides access to [Cloudflare's implementation](https://github.com/cloudflare/workers-sdk/tree/main/packages/chrome-devtools-patches) of [Chrome's DevTools](https://developer.chrome.com/docs/devtools/overview). Navigating to this route will open a DevTools tab for each of the Workers in your application.\n\nOnce the tab(s) are open, you can make a request to your application and start debugging your Worker code.\n\nNote\n\nWhen debugging multiple Workers, you may need to allow your browser to open pop-ups.\n\n## VS Code\n\nTo set up [VS Code](https://code.visualstudio.com/) to support breakpoint debugging in your application, you should create a `.vscode/launch.json` file that contains the following configuration:",
      "language": "unknown"
    },
    {
      "code": "Here, `<NAME_OF_WORKER>` indicates the name of the Worker as specified in your Worker config file. If you have used the `inspectorPort` option to set a custom port then this should be the value provided in the `websocketaddress` field.\n\nNote\n\nIf you have more than one Worker in your application, you should add a configuration in the `configurations` field for each and include the configuration name in the `compounds` `configurations` array.\n\nWith this set up, you can run `vite dev` or `vite preview` and then select **Debug Workers** at the top of the **Run & Debug** panel to start debugging.\n\n</page>\n\n<page>\n---\ntitle: Migrating from wrangler dev Â· Cloudflare Workers docs\ndescription: Migrating from wrangler dev to the Vite plugin\nlastUpdated: 2025-12-08T10:06:57.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/vite-plugin/reference/migrating-from-wrangler-dev/\n  md: https://developers.cloudflare.com/workers/vite-plugin/reference/migrating-from-wrangler-dev/index.md\n---\n\nIn most cases, migrating from [`wrangler dev`](https://developers.cloudflare.com/workers/wrangler/commands/#dev) is straightforward and you can follow the instructions in [Get started](https://developers.cloudflare.com/workers/vite-plugin/get-started/). There are a few key differences to highlight:\n\n## Input and output Worker config files\n\nWith the Cloudflare Vite plugin, your [Worker config file](https://developers.cloudflare.com/workers/wrangler/configuration/) (for example, `wrangler.jsonc`) is the input configuration and a separate output configuration is created as part of the build. This output file is a snapshot of your configuration at the time of the build and is modified to reference your build artifacts. It is the configuration that is used for preview and deployment. Once you have run `vite build`, running `wrangler deploy` or `vite preview` will automatically locate this output configuration file.\n\n## Cloudflare Environments\n\nWith the Cloudflare Vite plugin, [Cloudflare Environments](https://developers.cloudflare.com/workers/vite-plugin/reference/cloudflare-environments/) are applied at dev and build time. Running `wrangler deploy --env some-env` is therefore not applicable and the environment to deploy should instead be set by running `CLOUDFLARE_ENV=some-env vite build`.\n\n## Redundant fields in the Wrangler config file\n\nThere are various options in the [Worker config file](https://developers.cloudflare.com/workers/wrangler/configuration/) that are ignored when using Vite, as they are either no longer applicable or are replaced by Vite equivalents. If these options are provided, then warnings will be printed to the console with suggestions for how to proceed.\n\n### Not applicable\n\nThe following build-related options are handled by Vite and are not applicable when using the Cloudflare Vite plugin:\n\n* `tsconfig`\n* `rules`\n* `build`\n* `no_bundle`\n* `find_additional_modules`\n* `base_dir`\n* `preserve_file_names`\n\n### Not supported\n\n* `site` â€” Use [Workers Assets](https://developers.cloudflare.com/workers/static-assets/) instead.\n\n### Replaced by Vite equivalents\n\nThe following options have Vite equivalents that should be used instead:\n\n| Wrangler option | Vite equivalent |\n| - | - |\n| `define` | [`define`](https://vite.dev/config/shared-options.html#define) |\n| `alias` | [`resolve.alias`](https://vite.dev/config/shared-options.html#resolve-alias) |\n| `minify` | [`build.minify`](https://vite.dev/config/build-options.html#build-minify) |\n| Local dev settings (`ip`, `port`, `local_protocol`, etc.) | [Server options](https://vite.dev/config/server-options.html) |\n\nSee [Vite Environments](https://developers.cloudflare.com/workers/vite-plugin/reference/vite-environments/) for more information about configuring your Worker environments in Vite.\n\n</page>\n\n<page>\n---\ntitle: Secrets Â· Cloudflare Workers docs\ndescription: Using secrets with the Vite plugin\nlastUpdated: 2025-04-04T07:52:43.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/vite-plugin/reference/secrets/\n  md: https://developers.cloudflare.com/workers/vite-plugin/reference/secrets/index.md\n---\n\n[Secrets](https://developers.cloudflare.com/workers/configuration/secrets/) are typically used for storing sensitive information such as API keys and auth tokens. For deployed Workers, they are set via the dashboard or Wrangler CLI.\n\nIn local development, secrets can be provided to your Worker by using a [`.dev.vars`](https://developers.cloudflare.com/workers/configuration/secrets/#local-development-with-secrets) file. If you are using [Cloudflare Environments](https://developers.cloudflare.com/workers/vite-plugin/reference/cloudflare-environments/) then the relevant `.dev.vars` file will be selected. For example, `CLOUDFLARE_ENV=staging vite dev` will load `.dev.vars.staging` if it exists and fall back to `.dev.vars`.\n\nNote\n\nThe `vite build` command copies the relevant `.dev.vars` file to the output directory. This is only used when running `vite preview` and is not deployed with your Worker.\n\n</page>\n\n<page>\n---\ntitle: Programmatic configuration Â· Cloudflare Workers docs\ndescription: Configure Workers programmatically using the Vite plugin\nlastUpdated: 2025-12-18T13:44:09.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/vite-plugin/reference/programmatic-configuration/\n  md: https://developers.cloudflare.com/workers/vite-plugin/reference/programmatic-configuration/index.md\n---\n\nThe Wrangler configuration file is optional when using the Cloudflare Vite plugin. Without one, the plugin uses default values. You can customize Worker configuration programmatically with the `config` option. This is useful when the Cloudflare plugin runs inside another plugin or framework.\n\nNote\n\nProgrammatic configuration is primarily designed for use by frameworks and plugin developers. Users should normally use Wrangler config files instead. Configuration set via the `config` option will not be included when running `wrangler types` or resource based Wrangler CLI commands such as `wrangler kv` or `wrangler d1`.\n\n## Default configuration\n\nWithout a configuration file, the plugin generates sensible defaults for an assets-only Worker. The `name` comes from `package.json` or the project directory name. The `compatibility_date` uses the latest date supported by your installed Miniflare version.\n\n## The `config` option\n\nThe `config` option offers three ways to programmatically configure your Worker. You can set any property from the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/), though some options are [ignored or replaced by Vite equivalents](https://developers.cloudflare.com/workers/vite-plugin/reference/migrating-from-wrangler-dev/#redundant-fields-in-the-wrangler-config-file).\n\nNote\n\nYou cannot define [Cloudflare environments](https://developers.cloudflare.com/workers/vite-plugin/reference/cloudflare-environments/) via `config`, as they are resolved before this option is applied.\n\n### Configuration object\n\nSet `config` to an object to provide values that merge with defaults and Wrangler config file settings:",
      "language": "unknown"
    },
    {
      "code": "These values merge with Wrangler config file values, with the `config` values taking precedence.\n\n### Dynamic configuration function\n\nUse a function when configuration depends on existing config values or external data, or if you need to compute or conditionally set values:",
      "language": "unknown"
    },
    {
      "code": "The function receives the current configuration (defaults or loaded config file). Return an object with values to merge.\n\n### In-place editing\n\nA `config` function can mutate the config object directly instead of returning overrides. This is useful for deleting properties or removing array items:",
      "language": "unknown"
    },
    {
      "code": "Note\n\nWhen editing in place, do not return a value from the function.\n\n## Auxiliary Workers\n\nAuxiliary Workers also support the `config` option, enabling multi-Worker architectures without config files.\n\nDefine auxiliary Workers without config files using `config` inside the `auxiliaryWorkers` array:",
      "language": "unknown"
    },
    {
      "code": "### Configuration overrides\n\nCombine a config file with `config` to override specific values:",
      "language": "unknown"
    },
    {
      "code": "### Configuration inheritance\n\nAuxiliary Workers receive the resolved entry Worker config in the second parameter to the `config` function. This makes it straightforward to inherit configuration from the entry Worker in auxiliary Workers.",
      "language": "unknown"
    },
    {
      "code": "## Configuration merging behavior\n\nThe `config` option uses [defu](https://github.com/unjs/defu) for merging configuration objects.\n\n* Object properties are recursively merged\n* Arrays are concatenated (`config` values first, then existing values)\n* Primitive values from `config` override existing values\n* `undefined` values in `config` do not override existing values\n\n</page>\n\n<page>\n---\ntitle: Static Assets Â· Cloudflare Workers docs\ndescription: Static assets and the Vite plugin\nlastUpdated: 2025-07-01T10:19:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/vite-plugin/reference/static-assets/\n  md: https://developers.cloudflare.com/workers/vite-plugin/reference/static-assets/index.md\n---\n\nThis guide focuses on the areas of working with static assets that are unique to the Vite plugin. For more general documentation, see [Static Assets](https://developers.cloudflare.com/workers/static-assets/).\n\n## Configuration\n\nThe Vite plugin does not require that you provide the `assets` field in order to enable assets and instead determines whether assets should be included based on whether the `client` environment has been built. By default, the `client` environment is built if any of the following conditions are met:\n\n* There is an `index.html` file in the root of your project\n* `build.rollupOptions.input` or `environments.client.build.rollupOptions.input` is specified in your Vite config\n* You have a non-empty [`public` directory](https://vite.dev/guide/assets#the-public-directory)\n* Your Worker [imports assets as URLs](https://vite.dev/guide/assets#importing-asset-as-url)\n\nOn running `vite build`, an output `wrangler.json` configuration file is generated as part of the build output. The `assets.directory` field in this file is automatically populated with the path to your `client` build output. It is therefore not necessary to provide the `assets.directory` field in your input Worker configuration.\n\nThe `assets` configuration should be used, however, if you wish to set [routing configuration](https://developers.cloudflare.com/workers/static-assets/routing/) or enable the [assets binding](https://developers.cloudflare.com/workers/static-assets/binding/#binding). The following example configures the `not_found_handling` for a single-page application so that the fallback will always be the root `index.html` file.\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "## Features\n\nThe Vite plugin ensures that all of Vite's [static asset handling](https://vite.dev/guide/assets) features are supported in your Worker as well as in your frontend. These include importing assets as URLs, importing as strings and importing from the `public` directory as well as inlining assets.\n\nAssets [imported as URLs](https://vite.dev/guide/assets#importing-asset-as-url) can be fetched via the [assets binding](https://developers.cloudflare.com/workers/static-assets/binding/#binding). As the binding's `fetch` method requires a full URL, we recommend using the request URL as the `base`. This is demonstrated in the following example:",
      "language": "unknown"
    },
    {
      "code": "Assets imported as URLs in your Worker will automatically be moved to the client build output. When running `vite build` the paths of any moved assets will be displayed in the console.\n\nNote\n\nIf you are developing a multi-Worker application, assets can only be accessed on the client and in your entry Worker.\n\n## Headers and redirects\n\nCustom [headers](https://developers.cloudflare.com/workers/static-assets/headers/) and [redirects](https://developers.cloudflare.com/workers/static-assets/redirects/) are supported at build, preview and deploy time by adding `_headers` and `_redirects` files to your [`public` directory](https://vite.dev/guide/assets#the-public-directory). The paths in these files should reflect the structure of your client build output. For example, generated assets are typically located in an [assets subdirectory](https://vite.dev/config/build-options#build-assetsdir).\n\n</page>\n\n<page>\n---\ntitle: Vite Environments Â· Cloudflare Workers docs\ndescription: Vite environments and the Vite plugin\nlastUpdated: 2025-10-29T21:32:51.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/vite-plugin/reference/vite-environments/\n  md: https://developers.cloudflare.com/workers/vite-plugin/reference/vite-environments/index.md\n---\n\nThe [Vite Environment API](https://vite.dev/guide/api-environment), released in Vite 6, is the key feature that enables the Cloudflare Vite plugin to integrate Vite directly with the Workers runtime. It is not necessary to understand all the intricacies of the Environment API as an end user, but it is useful to have a high-level understanding.\n\n## Default behavior\n\nVite creates two environments by default: `client` and `ssr`. A front-end only application uses the `client` environment, whereas a full-stack application created with a framework typically uses the `client` environment for front-end code and the `ssr` environment for server-side rendering.\n\nBy default, when you add a Worker using the Cloudflare Vite plugin, an additional environment is created. Its name is derived from the Worker name, with any dashes replaced with underscores. This name can be used to reference the environment in your Vite config in order to apply environment specific configuration.\n\nNote\n\nThe default Vite environment name for a Worker is always the top-level Worker name. This enables you to reference the Worker consistently in your Vite config when using multiple [Cloudflare Environments](https://developers.cloudflare.com/workers/vite-plugin/reference/cloudflare-environments/).\n\n## Environment configuration\n\nIn the following example we have a Worker named `my-worker` that is associated with a Vite environment named `my_worker`. We use the Vite config to set global constant replacements for this environment:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "For more information about Vite's configuration options, see [Configuring Vite](https://vite.dev/config/).\n\nThe default behavior of using the Worker name as the environment name is appropriate when you have a standalone Worker, such as an API that is accessed from your front-end application, or an [auxiliary Worker](https://developers.cloudflare.com/workers/vite-plugin/reference/api/#interface-pluginconfig) that is accessed via service bindings.\n\n## Full-stack frameworks\n\nIf you are using the Cloudflare Vite plugin with [TanStack Start](https://tanstack.com/start/) or [React Router v7](https://reactrouter.com/), then your Worker is used for server-side rendering and tightly integrated with the framework. To support this, you should assign it to the `ssr` environment by setting `viteEnvironment.name` in the plugin config.",
      "language": "unknown"
    },
    {
      "code": "This merges the Worker's environment configuration with the framework's SSR configuration and ensures that the Worker is included as part of the framework's build output.\n\n</page>\n\n<page>\n---\ntitle: Migrate from Wrangler v2 to v3 Â· Cloudflare Workers docs\ndescription: There are no special instructions for migrating from Wrangler v2 to\n  v3. You should be able to update Wrangler by following the instructions in\n  Install/Update Wrangler. You should experience no disruption to your workflow.\nlastUpdated: 2025-03-13T11:08:22.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/wrangler/migration/update-v2-to-v3/\n  md: https://developers.cloudflare.com/workers/wrangler/migration/update-v2-to-v3/index.md\n---\n\nThere are no special instructions for migrating from Wrangler v2 to v3. You should be able to update Wrangler by following the instructions in [Install/Update Wrangler](https://developers.cloudflare.com/workers/wrangler/install-and-update/#update-wrangler). You should experience no disruption to your workflow.\n\nWarning\n\nIf you tried to update to Wrangler v3 prior to v3.3, you may have experienced some compatibility issues with older operating systems. Please try again with the latest v3 where those have been resolved.\n\n## Deprecations\n\nRefer to [Deprecations](https://developers.cloudflare.com/workers/wrangler/deprecations/#wrangler-v3) for more details on what is no longer supported in v3.\n\n## Additional assistance\n\nIf you do have an issue or need further assistance, [file an issue](https://github.com/cloudflare/workers-sdk/issues/new/choose) in the `workers-sdk` repo on GitHub.\n\n</page>\n\n<page>\n---\ntitle: Migrate from Wrangler v3 to v4 Â· Cloudflare Workers docs\ndescription: Wrangler v4 is a major release focused on updates to underlying\n  systems and dependencies, along with improvements to keep Wrangler commands\n  consistent and clear. Unlike previous major versions of Wrangler, which were\n  foundational rewrites and rearchitectures â€”Â Version 4 of Wrangler includes a\n  much smaller set of changes. If you use Wrangler today, your workflow is very\n  unlikely to change.\nlastUpdated: 2025-03-13T19:20:11.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/wrangler/migration/update-v3-to-v4/\n  md: https://developers.cloudflare.com/workers/wrangler/migration/update-v3-to-v4/index.md\n---\n\nWrangler v4 is a major release focused on updates to underlying systems and dependencies, along with improvements to keep Wrangler commands consistent and clear. Unlike previous major versions of Wrangler, which were [foundational rewrites](https://blog.cloudflare.com/wrangler-v2-beta/) and [rearchitectures](https://blog.cloudflare.com/wrangler3/) â€”Â Version 4 of Wrangler includes a much smaller set of changes. If you use Wrangler today, your workflow is very unlikely to change.\n\nWhile many users should expect a no-op upgrade, the following sections outline the more significant changes and steps for migrating where necessary.\n\n### Summary of changes\n\n* **Updated Node.js support policy:** Node.js v16, which reached End-of-Life in 2022, is no longer supported in Wrangler v4. Wrangler now follows Node.js's [official support lifecycle](https://nodejs.org/en/about/previous-releases).\n\n* **Upgraded esbuild version**: Wrangler uses [esbuild](https://esbuild.github.io/) to bundle Worker code before deploying it, and was previously pinned to esbuild v0.17.19. Wrangler v4 uses esbuild v0.24, which could impact dynamic wildcard imports. Going forward, Wrangler will be periodically updating the `esbuild` version included with Wrangler, and since `esbuild` is a pre-1.0.0 tool, this may sometimes include breaking changes to how bundling works. In particular, we may bump the `esbuild` version in a Wrangler minor version.\n\n* **Commands default to local mode**: All commands that can run in either local or remote mode now default to local, requiring a `--remote` flag for API queries.\n\n* **Deprecated commands and configurations removed:** Legacy commands, flags, and configurations are removed.\n\n## Detailed Changes\n\n### Updated Node.js support policy\n\nWrangler now supports only Node.js versions that align with [Node.js's official lifecycle](https://nodejs.org/en/about/previous-releases):\n\n* **Supported**: Current, Active LTS, Maintenance LTS\n* **No longer supported:** Node.js v16 (EOL in 2022)\n\nWrangler tests no longer run on v16, and users still on this version may encounter unsupported behavior. Users still using Node.js v16 must upgrade to a supported version to continue receiving support and compatibility with Wrangler.\n\n### Upgraded esbuild version\n\nWrangler v4 upgrades esbuild from **v0.17.19** to **v0.24**, bringing improvements (such as the ability to use the `using` keyword with RPC) and changes to bundling behavior:\n\n* **Dynamic imports:** Wildcard imports (for example, `import('./data/' + kind + '.json')`) now automatically include all matching files in the bundle.\n\nUsers relying on wildcard dynamic imports may see unwanted files bundled. Prior to esbuild v0.19, `import` statements with dynamic paths ( like `import('./data/' + kind + '.json')`) did not bundle all files matches the glob pattern (`*.json`) . Only files explicitly referenced or included using `find_additional_modules` were bundled. With esbuild v0.19, wildcard imports now automatically bundle all files matching the glob pattern. This could result in unwanted files being bundled, so users might want to avoid wildcard dynamic imports and use explicit imports instead.\n\n### Commands default to local mode\n\nAll commands now run in **local mode by default.** Wrangler has many commands for accessing resources like KV and R2, but the commands were previously inconsistent in whether they ran in a local or remote environment. For example, D1 defaulted to querying a local datastore, and required the `--remote` flag to query via the API. KV, on the other hand, previously defaulted to querying via the API (implicitly using the `--remote` flag) and required a `--local` flag to query a local datastore. In order to make the behavior consistent across Wrangler, each command now uses the `--local` flag by default, and requires an explicit `--remote` flag to query via the API.\n\nFor example:\n\n* **Previous Behavior (Wrangler v3):** `wrangler kv get` queried remotely by default.\n* **New Behavior (Wrangler v4):** `wrangler kv get` queries locally unless `--remote` is specified.\n\nThose using `wrangler kv key` and/or `wrangler r2 object` commands to query or write to their data store will need to add the `--remote` flag in order to replicate previous behavior.\n\n### Deprecated commands and configurations removed\n\nAll previously deprecated features in [Wrangler v2](https://developers.cloudflare.com/workers/wrangler/deprecations/#wrangler-v2) and in [Wrangler v3](https://developers.cloudflare.com/workers/wrangler/deprecations/#wrangler-v3) are now removed. Additionally, the following features that were deprecated during the Wrangler v3 release are also now removed:\n\n* Legacy Assets (using `wrangler dev/deploy --legacy-assets` or the `legacy_assets` config file property). Instead, we recommend you [migrate to Workers assets](https://developers.cloudflare.com/workers/static-assets/).\n* Legacy Node.js compatibility (using `wrangler dev/deploy --node-compat` or the `node_compat` config file property). Instead, use the [`nodejs_compat` compatibility flag](https://developers.cloudflare.com/workers/runtime-apis/nodejs). This includes the functionality from legacy `node_compat` polyfills and natively implemented Node.js APIs.\n* `wrangler version`. Instead, use `wrangler --version` to check the current version of Wrangler.\n* `getBindingsProxy()` (via `import { getBindingsProxy } from \"wrangler\"`). Instead, use the [`getPlatformProxy()` API](https://developers.cloudflare.com/workers/wrangler/api/#getplatformproxy), which takes exactly the same arguments.\n* `usage_model`. This no longer has any effect, after the [rollout of Workers Standard Pricing](https://blog.cloudflare.com/workers-pricing-scale-to-zero/).\n\n</page>\n\n<page>\n---\ntitle: Migrate from Wrangler v1 to v2 Â· Cloudflare Workers docs\ndescription: This guide details how to migrate from Wrangler v1 to v2.\nlastUpdated: 2025-03-13T11:08:22.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/\n  md: https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/index.md\n---\n\nThis guide details how to migrate from Wrangler v1 to v2.\n\n* [1. Migrate webpack projects](https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/eject-webpack/)\n* [2. Update to Wrangler v2](https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/update-v1-to-v2/)\n* [Wrangler v1 (legacy)](https://developers.cloudflare.com/workers/wrangler/migration/v1-to-v2/wrangler-legacy/)\n\n</page>\n\n<page>\n---\ntitle: REST API Â· Cloudflare Workers AI docs\ndescription: \"If you prefer to work directly with the REST API instead of a\n  Cloudflare Worker, below are the steps on how to do it:\"\nlastUpdated: 2025-04-10T22:24:36.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers-ai/features/batch-api/rest-api/\n  md: https://developers.cloudflare.com/workers-ai/features/batch-api/rest-api/index.md\n---\n\nIf you prefer to work directly with the REST API instead of a [Cloudflare Worker](https://developers.cloudflare.com/workers-ai/features/batch-api/workers-binding/), below are the steps on how to do it:\n\n## 1. Sending a Batch Request\n\nMake a POST request using the following pattern. You can pass `external_reference` as a unique ID per-prompt that will be returned in the response.",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "## 2. Retrieving the Batch Response\n\nAfter receiving a `request_id` from your initial POST, you can poll for or retrieve the results with another POST request:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Workers Binding Â· Cloudflare Workers AI docs\ndescription: You can use Workers Bindings to interact with the Batch API.\nlastUpdated: 2025-04-10T22:24:36.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers-ai/features/batch-api/workers-binding/\n  md: https://developers.cloudflare.com/workers-ai/features/batch-api/workers-binding/index.md\n---\n\nYou can use Workers Bindings to interact with the Batch API.\n\n## Send a Batch request\n\nSend your initial batch inference request by composing a JSON payload containing an array of individual inference requests and the `queueRequest: true` property (which is what controlls queueing behavior).\n\nNote\n\nEnsure that the total payload is under 10 MB.",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "You will get a response with the following values:\n\n* **`status`**: Indicates that your request is queued.\n* **`request_id`**: A unique identifier for the batch request.\n* **`model`**: The model used for the batch inference.\n\nOf these, the `request_id` is important for when you need to [poll the batch status](#poll-batch-status).\n\n### Poll batch status\n\nOnce your batch request is queued, use the `request_id` to poll for its status. During processing, the API returns a status `queued` or `running` indicating that the request is still in the queue or being processed.",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "When the inference is complete, the API returns a final HTTP status code of `200` along with an array of responses. Each response object corresponds to an individual input prompt, identified by an `id` that maps to the index of the prompt in your original request.\n\n</page>\n\n<page>\n---\ntitle: Embedded function calling Â· Cloudflare Workers AI docs\ndescription: Cloudflare has a unique embedded function calling feature that\n  allows you to execute function code alongside your tool call inference. Our\n  npm package @cloudflare/ai-utils is the developer toolkit to get started.\nlastUpdated: 2025-04-03T16:21:18.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers-ai/features/function-calling/embedded/\n  md: https://developers.cloudflare.com/workers-ai/features/function-calling/embedded/index.md\n---\n\nCloudflare has a unique [embedded function calling](https://blog.cloudflare.com/embedded-function-calling) feature that allows you to execute function code alongside your tool call inference. Our npm package [`@cloudflare/ai-utils`](https://www.npmjs.com/package/@cloudflare/ai-utils) is the developer toolkit to get started.\n\nEmbedded function calling can be used to easily make complex agents that interact with websites and APIs, like using natural language to create meetings on Google Calendar, saving data to Notion, automatically routing requests to other APIs, saving data to an R2 bucket - or all of this at the same time. All you need is a prompt and an OpenAPI spec to get started.\n\nREST API support\n\nEmbedded function calling depends on features native to the Workers platform. This means that embedded function calling is only supported via [Cloudflare Workers](https://developers.cloudflare.com/workers-ai/get-started/workers-wrangler/), not via the [REST API](https://developers.cloudflare.com/workers-ai/get-started/rest-api/).\n\n## Resources\n\n* [Get Started](https://developers.cloudflare.com/workers-ai/features/function-calling/embedded/get-started/)\n* [Examples](https://developers.cloudflare.com/workers-ai/features/function-calling/embedded/examples/)\n* [API Reference](https://developers.cloudflare.com/workers-ai/features/function-calling/embedded/api-reference/)\n* [Troubleshooting](https://developers.cloudflare.com/workers-ai/features/function-calling/embedded/troubleshooting/)\n\n</page>\n\n<page>\n---\ntitle: Traditional function calling Â· Cloudflare Workers AI docs\ndescription: This page shows how you can do traditional function calling, as\n  defined by industry standards. Workers AI also offers embedded function\n  calling, which is drastically easier than traditional function calling.\nlastUpdated: 2025-04-03T16:21:18.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers-ai/features/function-calling/traditional/\n  md: https://developers.cloudflare.com/workers-ai/features/function-calling/traditional/index.md\n---\n\nThis page shows how you can do traditional function calling, as defined by industry standards. Workers AI also offers [embedded function calling](https://developers.cloudflare.com/workers-ai/features/function-calling/embedded/), which is drastically easier than traditional function calling.\n\nWith traditional function calling, you define an array of tools with the name, description, and tool arguments. The example below shows how you would pass a tool called `getWeather` in an inference request to a model.",
      "language": "unknown"
    },
    {
      "code": "The LLM will then return a JSON object with the required arguments and the name of the tool that was called. You can then pass this JSON object to make an API call.",
      "language": "unknown"
    },
    {
      "code": "For a working example on how to do function calling, take a look at our [demo app](https://github.com/craigsdennis/lightbulb-moment-tool-calling/blob/main/src/index.ts).\n\n</page>\n\n<page>\n---\ntitle: Fine-tuned inference with LoRA adapters Â· Cloudflare Workers AI docs\ndescription: Upload and use LoRA adapters to get fine-tuned inference on Workers AI.\nlastUpdated: 2025-10-27T15:50:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers-ai/features/fine-tunes/loras/\n  md: https://developers.cloudflare.com/workers-ai/features/fine-tunes/loras/index.md\n---\n\nWorkers AI supports fine-tuned inference with adapters trained with [Low-Rank Adaptation](https://blog.cloudflare.com/fine-tuned-inference-with-loras). This feature is in open beta and free during this period.\n\n## Limitations\n\n* We only support LoRAs for a [variety of models](https://developers.cloudflare.com/workers-ai/models/?capabilities=LoRA) (must not be quantized)\n* Adapter must be trained with rank `r <=8` as well as larger ranks if up to 32. You can check the rank of a pre-trained LoRA adapter through the adapter's `config.json` file\n* LoRA adapter file must be < 300MB\n* LoRA adapter files must be named `adapter_config.json` and `adapter_model.safetensors` exactly\n* You can test up to 100 LoRA adapters per account\n\n***\n\n## Choosing compatible LoRA adapters\n\n### Finding open-source LoRA adapters\n\nWe have started a [Hugging Face Collection](https://huggingface.co/collections/Cloudflare/workers-ai-compatible-loras-6608dd9f8d305a46e355746e) that lists a few LoRA adapters that are compatible with Workers AI. Generally, any LoRA adapter that fits our limitations above should work.\n\n### Training your own LoRA adapters\n\nTo train your own LoRA adapter, follow the [tutorial](https://developers.cloudflare.com/workers-ai/guides/tutorials/fine-tune-models-with-autotrain/).\n\n***\n\n## Uploading LoRA adapters\n\nIn order to run inference with LoRAs on Workers AI, you'll need to create a new fine tune on your account and upload your adapter files. You should have a `adapter_model.safetensors` file with model weights and `adapter_config.json` with your config information. *Note that we only accept adapter files in these types.*\n\nRight now, you can't edit a fine tune's asset files after you upload it. We will support this soon, but for now you will need to create a new fine tune and upload files again if you would like to use a new LoRA.\n\nBefore you upload your LoRA adapter, you'll need to edit your `adapter_config.json` file to include `model_type` as one of `mistral`, `gemma` or `llama` like below.",
      "language": "unknown"
    },
    {
      "code": "### Wrangler\n\nYou can create a finetune and upload your LoRA adapter via wrangler with the following commands:",
      "language": "unknown"
    },
    {
      "code": "### REST API\n\nAlternatively, you can use our REST API to create a finetune and upload your adapter files. You will need a Cloudflare API Token with `Workers AI: Edit` permissions to make calls to our REST API, which you can generate via the Cloudflare Dashboard.\n\n#### Creating a fine-tune on your account\n\nRequired API token permissions\n\nAt least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n* `Workers AI Write`",
      "language": "unknown"
    },
    {
      "code": "#### Uploading your adapter weights and config\n\nYou have to call the upload endpoint each time you want to upload a new file, so you usually run this once for `adapter_model.safetensors` and once for `adapter_config.json`. Make sure you include the `@` before your path to files.\n\nYou can either use the finetune `name` or `id` that you used when you created the fine tune.",
      "language": "unknown"
    },
    {
      "code": "#### List fine-tunes in your account\n\nYou can call this method to confirm what fine-tunes you have created in your account\n\nRequired API token permissions\n\nAt least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n* `Workers AI Write`\n* `Workers AI Read`",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "***\n\n## Running inference with LoRAs\n\nTo make inference requests and apply the LoRA adapter, you will need your model and finetune `name` or `id`. You should use the chat template that your LoRA was trained on, but you can try running it with `raw: true` and the messages template like below.\n\n* workers ai sdk",
      "language": "unknown"
    },
    {
      "code": "* rest api",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Public LoRA adapters Â· Cloudflare Workers AI docs\ndescription: Cloudflare offers a few public LoRA adapters that are immediately\n  ready for use.\nlastUpdated: 2025-06-27T16:14:01.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers-ai/features/fine-tunes/public-loras/\n  md: https://developers.cloudflare.com/workers-ai/features/fine-tunes/public-loras/index.md\n---\n\nCloudflare offers a few public LoRA adapters that can immediately be used for fine-tuned inference. You can try them out immediately via our [playground](https://playground.ai.cloudflare.com).\n\nPublic LoRAs will have the name `cf-public-x`, and the prefix will be reserved for Cloudflare.\n\nNote\n\nHave more LoRAs you would like to see? Let us know on [Discord](https://discord.cloudflare.com).\n\n| Name | Description | Compatible with |\n| - | - | - |\n| [cf-public-magicoder](https://huggingface.co/predibase/magicoder) | Coding tasks in multiple languages | `@cf/mistral/mistral-7b-instruct-v0.1` `@hf/mistral/mistral-7b-instruct-v0.2` |\n| [cf-public-jigsaw-classification](https://huggingface.co/predibase/jigsaw) | Toxic comment classification | `@cf/mistral/mistral-7b-instruct-v0.1` `@hf/mistral/mistral-7b-instruct-v0.2` |\n| [cf-public-cnn-summarization](https://huggingface.co/predibase/cnn) | Article summarization | `@cf/mistral/mistral-7b-instruct-v0.1` `@hf/mistral/mistral-7b-instruct-v0.2` |\n\nYou can also list these public LoRAs with an API call:\n\nRequired API token permissions\n\nAt least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n* `Workers AI Write`\n* `Workers AI Read`",
      "language": "unknown"
    },
    {
      "code": "## Running inference with public LoRAs\n\nTo run inference with public LoRAs, you just need to define the LoRA name in the request.\n\nWe recommend that you use the prompt template that the LoRA was trained on. You can find this in the HuggingFace repos linked above for each adapter.\n\n### cURL",
      "language": "unknown"
    },
    {
      "code": "### JavaScript",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Build a Retrieval Augmented Generation (RAG) AI Â· Cloudflare Workers AI docs\ndescription: Build your first AI app with Cloudflare AI. This guide uses Workers\n  AI, Vectorize, D1, and Cloudflare Workers.\nlastUpdated: 2025-10-13T13:40:40.000Z\nchatbotDeprioritize: false\ntags: AI,Hono,JavaScript\nsource_url:\n  html: https://developers.cloudflare.com/workers-ai/guides/tutorials/build-a-retrieval-augmented-generation-ai/\n  md: https://developers.cloudflare.com/workers-ai/guides/tutorials/build-a-retrieval-augmented-generation-ai/index.md\n---\n\nThis guide will instruct you through setting up and deploying your first application with Cloudflare AI. You will build a fully-featured AI-powered application, using tools like Workers AI, Vectorize, D1, and Cloudflare Workers.\n\nLooking for a managed option?\n\n[AI Search](https://developers.cloudflare.com/ai-search/) offers a fully managed way to build RAG pipelines on Cloudflare, handling ingestion, indexing, and querying out of the box. [Get started](https://developers.cloudflare.com/ai-search/get-started/).\n\nAt the end of this tutorial, you will have built an AI tool that allows you to store information and query it using a Large Language Model. This pattern, known as Retrieval Augmented Generation, or RAG, is a useful project you can build by combining multiple aspects of Cloudflare's AI toolkit. You do not need to have experience working with AI tools to build this application.\n\n1. Sign up for a [Cloudflare account](https://dash.cloudflare.com/sign-up/workers-and-pages).\n2. Install [`Node.js`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm).\n\nNode.js version manager\n\nUse a Node version manager like [Volta](https://volta.sh/) or [nvm](https://github.com/nvm-sh/nvm) to avoid permission issues and change Node.js versions. [Wrangler](https://developers.cloudflare.com/workers/wrangler/install-and-update/), discussed later in this guide, requires a Node version of `16.17.0` or later.\n\nYou will also need access to [Vectorize](https://developers.cloudflare.com/vectorize/platform/pricing/). During this tutorial, we will show how you can optionally integrate with [Anthropic Claude](http://anthropic.com) as well. You will need an [Anthropic API key](https://docs.anthropic.com/en/api/getting-started) to do so.\n\n## 1. Create a new Worker project\n\nC3 (`create-cloudflare-cli`) is a command-line tool designed to help you setup and deploy Workers to Cloudflare as fast as possible.\n\nOpen a terminal window and run C3 to create your Worker project:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "For setup, select the following options:\n\n* For *What would you like to start with?*, choose `Hello World example`.\n* For *Which template would you like to use?*, choose `Worker only`.\n* For *Which language do you want to use?*, choose `JavaScript`.\n* For *Do you want to use git for version control?*, choose `Yes`.\n* For *Do you want to deploy your application?*, choose `No` (we will be making some changes before deploying).\n\nIn your project directory, C3 has generated several files.\n\nWhat files did C3 create?\n\n1. `wrangler.jsonc`: Your [Wrangler](https://developers.cloudflare.com/workers/wrangler/configuration/#sample-wrangler-configuration) configuration file.\n2. `worker.js` (in `/src`): A minimal `'Hello World!'` Worker written in [ES module](https://developers.cloudflare.com/workers/reference/migrate-to-module-workers/) syntax.\n3. `package.json`: A minimal Node dependencies configuration file.\n4. `package-lock.json`: Refer to [`npm` documentation on `package-lock.json`](https://docs.npmjs.com/cli/v9/configuring-npm/package-lock-json).\n5. `node_modules`: Refer to [`npm` documentation `node_modules`](https://docs.npmjs.com/cli/v7/configuring-npm/folders#node-modules).\n\nNow, move into your newly created directory:",
      "language": "unknown"
    },
    {
      "code": "## 2. Develop with Wrangler CLI\n\nThe Workers command-line interface, [Wrangler](https://developers.cloudflare.com/workers/wrangler/install-and-update/), allows you to [create](https://developers.cloudflare.com/workers/wrangler/commands/#init), [test](https://developers.cloudflare.com/workers/wrangler/commands/#dev), and [deploy](https://developers.cloudflare.com/workers/wrangler/commands/#deploy) your Workers projects. C3 will install Wrangler in projects by default.\n\nAfter you have created your first Worker, run the [`wrangler dev`](https://developers.cloudflare.com/workers/wrangler/commands/#dev) command in the project directory to start a local server for developing your Worker. This will allow you to test your Worker locally during development.",
      "language": "unknown"
    },
    {
      "code": "You will now be able to go to <http://localhost:8787> to see your Worker running. Any changes you make to your code will trigger a rebuild, and reloading the page will show you the up-to-date output of your Worker.\n\n## 3. Adding the AI binding\n\nTo begin using Cloudflare's AI products, you can add the `ai` block to the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/) as a [remote binding](https://developers.cloudflare.com/workers/development-testing/#remote-bindings). This will set up a binding to Cloudflare's AI models in your code that you can use to interact with the available AI models on the platform.\n\nNote\n\nIf you have not used Wrangler before, it will try to open your web browser to login with your Cloudflare account.\n\nIf you have issues with this step or you do not have access to a browser interface, refer to the [`wrangler login`](https://developers.cloudflare.com/workers/wrangler/commands/#login) documentation for more information.\n\nThis example features the [`@cf/meta/llama-3-8b-instruct` model](https://developers.cloudflare.com/workers-ai/models/llama-3-8b-instruct/), which generates text.\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Now, find the `src/index.js` file. Inside the `fetch` handler, you can query the `AI` binding:",
      "language": "unknown"
    },
    {
      "code": "By querying the LLM through the `AI` binding, we can interact directly with Cloudflare AI's large language models directly in our code. In this example, we are using the [`@cf/meta/llama-3-8b-instruct` model](https://developers.cloudflare.com/workers-ai/models/llama-3-8b-instruct/), which generates text.\n\nYou can deploy your Worker using `wrangler`:",
      "language": "unknown"
    },
    {
      "code": "Making a request to your Worker will now generate a text response from the LLM, and return it as a JSON object.",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "## 4. Adding embeddings using Cloudflare D1 and Vectorize\n\nEmbeddings allow you to add additional capabilities to the language models you can use in your Cloudflare AI projects. This is done via **Vectorize**, Cloudflare's vector database.\n\nTo begin using Vectorize, create a new embeddings index using `wrangler`. This index will store vectors with 768 dimensions, and will use cosine similarity to determine which vectors are most similar to each other:",
      "language": "unknown"
    },
    {
      "code": "Then, add the configuration details for your new Vectorize index to the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/):\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "A vector index allows you to store a collection of dimensions, which are floating point numbers used to represent your data. When you want to query the vector database, you can also convert your query into dimensions. **Vectorize** is designed to efficiently determine which stored vectors are most similar to your query.\n\nTo implement the searching feature, you must set up a D1 database from Cloudflare. In D1, you can store your app's data. Then, you change this data into a vector format. When someone searches and it matches the vector, you can show them the matching data.\n\nCreate a new D1 database using `wrangler`:",
      "language": "unknown"
    },
    {
      "code": "Then, paste the configuration details output from the previous command into the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/):\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "In this application, we'll create a `notes` table in D1, which will allow us to store notes and later retrieve them in Vectorize. To create this table, run a SQL command using `wrangler d1 execute`:",
      "language": "unknown"
    },
    {
      "code": "Now, we can add a new note to our database using `wrangler d1 execute`:",
      "language": "unknown"
    },
    {
      "code": "## 5. Creating a workflow\n\nBefore we begin creating notes, we will introduce a [Cloudflare Workflow](https://developers.cloudflare.com/workflows). This will allow us to define a durable workflow that can safely and robustly execute all the steps of the RAG process.\n\nTo begin, add a new `[[workflows]]` block to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/):\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "In `src/index.js`, add a new class called `RAGWorkflow` that extends `WorkflowEntrypoint`:",
      "language": "unknown"
    },
    {
      "code": "This class will define a single workflow step that will log \"Hello World!\" to the console. You can add as many steps as you need to your workflow.\n\nOn its own, this workflow will not do anything. To execute the workflow, we will call the `RAG_WORKFLOW` binding, passing in any parameters that the workflow needs to properly complete. Here is an example of how we can call the workflow:",
      "language": "unknown"
    },
    {
      "code": "## 6. Creating notes and adding them to Vectorize\n\nTo expand on your Workers function in order to handle multiple routes, we will add `hono`, a routing library for Workers. This will allow us to create a new route for adding notes to our database. Install `hono` using `npm`:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Then, import `hono` into your `src/index.js` file. You should also update the `fetch` handler to use `hono`:",
      "language": "unknown"
    },
    {
      "code": "This will establish a route at the root path `/` that is functionally equivalent to the previous version of your application.\n\nNow, we can update our workflow to begin adding notes to our database, and generating the related embeddings for them.\n\nThis example features the [`@cf/baai/bge-base-en-v1.5` model](https://developers.cloudflare.com/workers-ai/models/bge-base-en-v1.5/), which can be used to create an embedding. Embeddings are stored and retrieved inside [Vectorize](https://developers.cloudflare.com/vectorize/), Cloudflare's vector database. The user query is also turned into an embedding so that it can be used for searching within Vectorize.",
      "language": "unknown"
    },
    {
      "code": "The workflow does the following things:\n\n1. Accepts a `text` parameter.\n2. Insert a new row into the `notes` table in D1, and retrieve the `id` of the new row.\n3. Convert the `text` into a vector using the `embeddings` model of the LLM binding.\n4. Upsert the `id` and `vectors` into the `vector-index` index in Vectorize.\n\nBy doing this, you will create a new vector representation of the note, which can be used to retrieve the note later.\n\nTo complete the code, we will add a route that allows users to submit notes to the database. This route will parse the JSON request body, get the `note` parameter, and create a new instance of the workflow, passing the parameter:",
      "language": "unknown"
    },
    {
      "code": "## 7. Querying Vectorize to retrieve notes\n\nTo complete your code, you can update the root path (`/`) to query Vectorize. You will convert the query into a vector, and then use the `vector-index` index to find the most similar vectors.\n\nThe `topK` parameter limits the number of vectors returned by the function. For instance, providing a `topK` of 1 will only return the *most similar* vector based on the query. Setting `topK` to 5 will return the 5 most similar vectors.\n\nGiven a list of similar vectors, you can retrieve the notes that match the record IDs stored alongside those vectors. In this case, we are only retrieving a single note - but you may customize this as needed.\n\nYou can insert the text of those notes as context into the prompt for the LLM binding. This is the basis of Retrieval-Augmented Generation, or RAG: providing additional context from data outside of the LLM to enhance the text generated by the LLM.\n\nWe'll update the prompt to include the context, and to ask the LLM to use the context when responding:",
      "language": "unknown"
    },
    {
      "code": "## 8. Adding Anthropic Claude model (optional)\n\nIf you are working with larger documents, you have the option to use Anthropic's [Claude models](https://claude.ai/), which have large context windows and are well-suited to RAG workflows.\n\nTo begin, install the `@anthropic-ai/sdk` package:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "In `src/index.js`, you can update the `GET /` route to check for the `ANTHROPIC_API_KEY` environment variable. If it's set, we can generate text using the Anthropic SDK. If it isn't set, we'll fall back to the existing Workers AI code:",
      "language": "unknown"
    },
    {
      "code": "Finally, you'll need to set the `ANTHROPIC_API_KEY` environment variable in your Workers application. You can do this by using `wrangler secret put`:",
      "language": "unknown"
    },
    {
      "code": "## 9. Deleting notes and vectors\n\nIf you no longer need a note, you can delete it from the database. Any time that you delete a note, you will also need to delete the corresponding vector from Vectorize. You can implement this by building a `DELETE /notes/:id` route in your `src/index.js` file:",
      "language": "unknown"
    },
    {
      "code": "## 10. Text splitting (optional)\n\nFor large pieces of text, it is recommended to split the text into smaller chunks. This allows LLMs to more effectively gather relevant context, without needing to retrieve large pieces of text.\n\nTo implement this, we'll add a new NPM package to our project, \\`@langchain/textsplitters':\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "The `RecursiveCharacterTextSplitter` class provided by this package will split the text into smaller chunks. It can be customized to your liking, but the default config works in most cases:",
      "language": "unknown"
    },
    {
      "code": "To use this splitter, we'll update the workflow to split the text into smaller chunks. We'll then iterate over the chunks and run the rest of the workflow for each chunk of text:",
      "language": "unknown"
    },
    {
      "code": "Now, when large pieces of text are submitted to the `/notes` endpoint, they will be split into smaller chunks, and each chunk will be processed by the workflow.\n\n## 11. Deploy your project\n\nIf you did not deploy your Worker during [step 1](https://developers.cloudflare.com/workers/get-started/guide/#1-create-a-new-worker-project), deploy your Worker via Wrangler, to a `*.workers.dev` subdomain, or a [Custom Domain](https://developers.cloudflare.com/workers/configuration/routing/custom-domains/), if you have one configured. If you have not configured any subdomain or domain, Wrangler will prompt you during the publish process to set one up.",
      "language": "unknown"
    },
    {
      "code": "Preview your Worker at `<YOUR_WORKER>.<YOUR_SUBDOMAIN>.workers.dev`.\n\nNote\n\nWhen pushing to your `*.workers.dev` subdomain for the first time, you may see [`523` errors](https://developers.cloudflare.com/support/troubleshooting/http-status-codes/cloudflare-5xx-errors/error-523/) while DNS is propagating. These errors should resolve themselves after a minute or so.\n\n## Related resources\n\nA full version of this codebase is available on GitHub. It includes a frontend UI for querying, adding, and deleting notes, as well as a backend API for interacting with the database and vector index. You can find it here: [github.com/kristianfreeman/cloudflare-retrieval-augmented-generation-example](https://github.com/kristianfreeman/cloudflare-retrieval-augmented-generation-example/).\n\nTo do more:\n\n* Explore the reference diagram for a [Retrieval Augmented Generation (RAG) Architecture](https://developers.cloudflare.com/reference-architecture/diagrams/ai/ai-rag/).\n* Review Cloudflare's [AI documentation](https://developers.cloudflare.com/workers-ai).\n* Review [Tutorials](https://developers.cloudflare.com/workers/tutorials/) to build projects on Workers.\n* Explore [Examples](https://developers.cloudflare.com/workers/examples/) to experiment with copy and paste Worker code.\n* Understand how Workers works in [Reference](https://developers.cloudflare.com/workers/reference/).\n* Learn about Workers features and functionality in [Platform](https://developers.cloudflare.com/workers/platform/).\n* Set up [Wrangler](https://developers.cloudflare.com/workers/wrangler/install-and-update/) to programmatically create, test, and deploy your Worker projects.\n\n</page>\n\n<page>\n---\ntitle: Whisper-large-v3-turbo with Cloudflare Workers AI Â· Cloudflare Workers AI docs\ndescription: Learn how to transcribe large audio files using Workers AI.\nlastUpdated: 2025-08-19T18:37:36.000Z\nchatbotDeprioritize: false\ntags: AI\nsource_url:\n  html: https://developers.cloudflare.com/workers-ai/guides/tutorials/build-a-workers-ai-whisper-with-chunking/\n  md: https://developers.cloudflare.com/workers-ai/guides/tutorials/build-a-workers-ai-whisper-with-chunking/index.md\n---\n\nIn this tutorial you will learn how to:\n\n* **Transcribe large audio files:** Use the [Whisper-large-v3-turbo](https://developers.cloudflare.com/workers-ai/models/whisper-large-v3-turbo/) model from Cloudflare Workers AI to perform automatic speech recognition (ASR) or translation.\n* **Handle large files:** Split large audio files into smaller chunks for processing, which helps overcome memory and execution time limitations.\n* **Deploy using Cloudflare Workers:** Create a scalable, lowâ€‘latency transcription pipeline in a serverless environment.\n\n## 1: Create a new Cloudflare Worker project\n\n1. Sign up for a [Cloudflare account](https://dash.cloudflare.com/sign-up/workers-and-pages).\n2. Install [`Node.js`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm).\n\nNode.js version manager\n\nUse a Node version manager like [Volta](https://volta.sh/) or [nvm](https://github.com/nvm-sh/nvm) to avoid permission issues and change Node.js versions. [Wrangler](https://developers.cloudflare.com/workers/wrangler/install-and-update/), discussed later in this guide, requires a Node version of `16.17.0` or later.\n\nYou will create a new Worker project using the `create-cloudflare` CLI (C3). [C3](https://github.com/cloudflare/workers-sdk/tree/main/packages/create-cloudflare) is a command-line tool designed to help you set up and deploy new applications to Cloudflare.\n\nCreate a new project named `whisper-tutorial` by running:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Running `npm create cloudflare@latest` will prompt you to install the [`create-cloudflare` package](https://www.npmjs.com/package/create-cloudflare), and lead you through setup. C3 will also install [Wrangler](https://developers.cloudflare.com/workers/wrangler/), the Cloudflare Developer Platform CLI.\n\nFor setup, select the following options:\n\n* For *What would you like to start with?*, choose `Hello World example`.\n* For *Which template would you like to use?*, choose `Worker only`.\n* For *Which language do you want to use?*, choose `TypeScript`.\n* For *Do you want to use git for version control?*, choose `Yes`.\n* For *Do you want to deploy your application?*, choose `No` (we will be making some changes before deploying).\n\nThis will create a new `whisper-tutorial` directory. Your new `whisper-tutorial` directory will include:\n\n* A `\"Hello World\"` [Worker](https://developers.cloudflare.com/workers/get-started/guide/#3-write-code) at `src/index.ts`.\n* A [`wrangler.jsonc`](https://developers.cloudflare.com/workers/wrangler/configuration/) configuration file.\n\nGo to your application directory:",
      "language": "unknown"
    },
    {
      "code": "## 2. Connect your Worker to Workers AI\n\nYou must create an AI binding for your Worker to connect to Workers AI. [Bindings](https://developers.cloudflare.com/workers/runtime-apis/bindings/) allow your Workers to interact with resources, like Workers AI, on the Cloudflare Developer Platform.\n\nTo bind Workers AI to your Worker, add the following to the end of your `wrangler.toml` file:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Your binding is [available in your Worker code](https://developers.cloudflare.com/workers/reference/migrate-to-module-workers/#bindings-in-es-modules-format) on [`env.AI`](https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch/).\n\n## 3. Configure Wrangler\n\nIn your wrangler file, add or update the following settings to enable Node.js APIs and polyfills (with a compatibility date of 2024â€‘09â€‘23 or later):\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "## 4. Handle large audio files with chunking\n\nReplace the contents of your `src/index.ts` file with the following integrated code. This sample demonstrates how to:\n\n(1) Extract an audio file URL from the query parameters.\n\n(2) Fetch the audio file while explicitly following redirects.\n\n(3) Split the audio file into smaller chunks (such as, 1 MB chunks).\n\n(4) Transcribe each chunk using the Whisper-large-v3-turbo model via the Cloudflare AI binding.\n\n(5) Return the aggregated transcription as plain text.",
      "language": "unknown"
    },
    {
      "code": "## 5. Deploy your Worker\n\n1. **Run the Worker locally:**\n\n   Use wrangler's development mode to test your Worker locally:",
      "language": "unknown"
    },
    {
      "code": "Open your browser and go to <http://localhost:8787>, or use curl:",
      "language": "unknown"
    },
    {
      "code": "Replace the URL query parameter with the direct link to your audio file. (For GitHub-hosted files, ensure you use the raw file URL.)\n\n1. **Deploy the Worker:**\n\n   Once testing is complete, deploy your Worker with:",
      "language": "unknown"
    },
    {
      "code": "1. **Test the deployed Worker:**\n\n   After deployment, test your Worker by passing the audio URL as a query parameter:",
      "language": "unknown"
    },
    {
      "code": "Make sure to replace `<your-worker-subdomain>`, `your-username`, `your-repo`, and `your-audio-file.mp3` with your actual details.\n\nIf successful, the Worker will return a transcript of the audio file:",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Explore Code Generation Using DeepSeek Coder Models Â· Cloudflare Workers\n  AI docs\ndescription: Explore how you can use AI models to generate code and work more efficiently.\nlastUpdated: 2025-08-19T18:37:36.000Z\nchatbotDeprioritize: false\ntags: AI,Python\nsource_url:\n  html: https://developers.cloudflare.com/workers-ai/guides/tutorials/explore-code-generation-using-deepseek-coder-models/\n  md: https://developers.cloudflare.com/workers-ai/guides/tutorials/explore-code-generation-using-deepseek-coder-models/index.md\n---\n\nA handy way to explore all of the models available on [Workers AI](https://developers.cloudflare.com/workers-ai) is to use a [Jupyter Notebook](https://jupyter.org/).\n\nYou can [download the DeepSeek Coder notebook](https://developers.cloudflare.com/workers-ai/static/documentation/notebooks/deepseek-coder-exploration.ipynb) or view the embedded notebook below.\n\n***\n\n## Exploring Code Generation Using DeepSeek Coder\n\nAI Models being able to generate code unlocks all sorts of use cases. The [DeepSeek Coder](https://github.com/deepseek-ai/DeepSeek-Coder) models `@hf/thebloke/deepseek-coder-6.7b-base-awq` and `@hf/thebloke/deepseek-coder-6.7b-instruct-awq` are now available on [Workers AI](https://developers.cloudflare.com/workers-ai).\n\nLet's explore them using the API!",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "### Configuring your environment\n\nTo use the API you'll need your [Cloudflare Account ID](https://dash.cloudflare.com) (head to Workers & Pages > Overview > Account details > Account ID) and a [Workers AI enabled API Token](https://dash.cloudflare.com/profile/api-tokens).\n\nIf you want to add these files to your environment, you can create a new file named `.env`",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "### Generate code from a comment\n\nA common use case is to complete the code for the user after they provide a descriptive comment.",
      "language": "unknown"
    },
    {
      "code": "{prompt}\n    {code.strip()}",
      "language": "python"
    },
    {
      "code": "",
      "language": "plaintext"
    }
  ],
  "headings": [
    {
      "level": "h3",
      "text": "Coverage",
      "id": "coverage"
    },
    {
      "level": "h3",
      "text": "Fake timers",
      "id": "fake-timers"
    },
    {
      "level": "h3",
      "text": "Dynamic `import()` statements with `SELF` and Durable Objects",
      "id": "dynamic-`import()`-statements-with-`self`-and-durable-objects"
    },
    {
      "level": "h3",
      "text": "Durable Object alarms",
      "id": "durable-object-alarms"
    },
    {
      "level": "h3",
      "text": "WebSockets",
      "id": "websockets"
    },
    {
      "level": "h3",
      "text": "Isolated storage",
      "id": "isolated-storage"
    },
    {
      "level": "h3",
      "text": "Missing properties on `ctx.exports`",
      "id": "missing-properties-on-`ctx.exports`"
    },
    {
      "level": "h3",
      "text": "Module resolution",
      "id": "module-resolution"
    },
    {
      "level": "h3",
      "text": "Importing modules from global setup file",
      "id": "importing-modules-from-global-setup-file"
    },
    {
      "level": "h2",
      "text": "`cloudflare:test` module definition",
      "id": "`cloudflare:test`-module-definition"
    },
    {
      "level": "h3",
      "text": "Events",
      "id": "events"
    },
    {
      "level": "h3",
      "text": "Durable Objects",
      "id": "durable-objects"
    },
    {
      "level": "h3",
      "text": "D1",
      "id": "d1"
    },
    {
      "level": "h3",
      "text": "Workflows",
      "id": "workflows"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "Define Vitest configuration",
      "id": "define-vitest-configuration"
    },
    {
      "level": "h2",
      "text": "Define types",
      "id": "define-types"
    },
    {
      "level": "h2",
      "text": "Writing tests",
      "id": "writing-tests"
    },
    {
      "level": "h3",
      "text": "Unit tests",
      "id": "unit-tests"
    },
    {
      "level": "h3",
      "text": "Integration tests",
      "id": "integration-tests"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Secrets in local development",
      "id": "secrets-in-local-development"
    },
    {
      "level": "h2",
      "text": "Combining Cloudflare environments and Vite modes",
      "id": "combining-cloudflare-environments-and-vite-modes"
    },
    {
      "level": "h2",
      "text": "`cloudflare()`",
      "id": "`cloudflare()`"
    },
    {
      "level": "h2",
      "text": "`interface PluginConfig`",
      "id": "`interface-pluginconfig`"
    },
    {
      "level": "h2",
      "text": "`interface AuxiliaryWorkerConfig`",
      "id": "`interface-auxiliaryworkerconfig`"
    },
    {
      "level": "h2",
      "text": "DevTools",
      "id": "devtools"
    },
    {
      "level": "h2",
      "text": "VS Code",
      "id": "vs-code"
    },
    {
      "level": "h2",
      "text": "Input and output Worker config files",
      "id": "input-and-output-worker-config-files"
    },
    {
      "level": "h2",
      "text": "Cloudflare Environments",
      "id": "cloudflare-environments"
    },
    {
      "level": "h2",
      "text": "Redundant fields in the Wrangler config file",
      "id": "redundant-fields-in-the-wrangler-config-file"
    },
    {
      "level": "h3",
      "text": "Not applicable",
      "id": "not-applicable"
    },
    {
      "level": "h3",
      "text": "Not supported",
      "id": "not-supported"
    },
    {
      "level": "h3",
      "text": "Replaced by Vite equivalents",
      "id": "replaced-by-vite-equivalents"
    },
    {
      "level": "h2",
      "text": "Default configuration",
      "id": "default-configuration"
    },
    {
      "level": "h2",
      "text": "The `config` option",
      "id": "the-`config`-option"
    },
    {
      "level": "h3",
      "text": "Configuration object",
      "id": "configuration-object"
    },
    {
      "level": "h3",
      "text": "Dynamic configuration function",
      "id": "dynamic-configuration-function"
    },
    {
      "level": "h3",
      "text": "In-place editing",
      "id": "in-place-editing"
    },
    {
      "level": "h2",
      "text": "Auxiliary Workers",
      "id": "auxiliary-workers"
    },
    {
      "level": "h3",
      "text": "Configuration overrides",
      "id": "configuration-overrides"
    },
    {
      "level": "h3",
      "text": "Configuration inheritance",
      "id": "configuration-inheritance"
    },
    {
      "level": "h2",
      "text": "Configuration merging behavior",
      "id": "configuration-merging-behavior"
    },
    {
      "level": "h2",
      "text": "Configuration",
      "id": "configuration"
    },
    {
      "level": "h2",
      "text": "Features",
      "id": "features"
    },
    {
      "level": "h2",
      "text": "Headers and redirects",
      "id": "headers-and-redirects"
    },
    {
      "level": "h2",
      "text": "Default behavior",
      "id": "default-behavior"
    },
    {
      "level": "h2",
      "text": "Environment configuration",
      "id": "environment-configuration"
    },
    {
      "level": "h2",
      "text": "Full-stack frameworks",
      "id": "full-stack-frameworks"
    },
    {
      "level": "h2",
      "text": "Deprecations",
      "id": "deprecations"
    },
    {
      "level": "h2",
      "text": "Additional assistance",
      "id": "additional-assistance"
    },
    {
      "level": "h3",
      "text": "Summary of changes",
      "id": "summary-of-changes"
    },
    {
      "level": "h2",
      "text": "Detailed Changes",
      "id": "detailed-changes"
    },
    {
      "level": "h3",
      "text": "Updated Node.js support policy",
      "id": "updated-node.js-support-policy"
    },
    {
      "level": "h3",
      "text": "Upgraded esbuild version",
      "id": "upgraded-esbuild-version"
    },
    {
      "level": "h3",
      "text": "Commands default to local mode",
      "id": "commands-default-to-local-mode"
    },
    {
      "level": "h3",
      "text": "Deprecated commands and configurations removed",
      "id": "deprecated-commands-and-configurations-removed"
    },
    {
      "level": "h2",
      "text": "1. Sending a Batch Request",
      "id": "1.-sending-a-batch-request"
    },
    {
      "level": "h2",
      "text": "2. Retrieving the Batch Response",
      "id": "2.-retrieving-the-batch-response"
    },
    {
      "level": "h2",
      "text": "Send a Batch request",
      "id": "send-a-batch-request"
    },
    {
      "level": "h3",
      "text": "Poll batch status",
      "id": "poll-batch-status"
    },
    {
      "level": "h2",
      "text": "Resources",
      "id": "resources"
    },
    {
      "level": "h2",
      "text": "Limitations",
      "id": "limitations"
    },
    {
      "level": "h2",
      "text": "Choosing compatible LoRA adapters",
      "id": "choosing-compatible-lora-adapters"
    },
    {
      "level": "h3",
      "text": "Finding open-source LoRA adapters",
      "id": "finding-open-source-lora-adapters"
    },
    {
      "level": "h3",
      "text": "Training your own LoRA adapters",
      "id": "training-your-own-lora-adapters"
    },
    {
      "level": "h2",
      "text": "Uploading LoRA adapters",
      "id": "uploading-lora-adapters"
    },
    {
      "level": "h3",
      "text": "Wrangler",
      "id": "wrangler"
    },
    {
      "level": "h3",
      "text": "REST API",
      "id": "rest-api"
    },
    {
      "level": "h2",
      "text": "Input: finetune_id, adapter_model.safetensors, then adapter_config.json",
      "id": "input:-finetune_id,-adapter_model.safetensors,-then-adapter_config.json"
    },
    {
      "level": "h2",
      "text": "Output: success true/false",
      "id": "output:-success-true/false"
    },
    {
      "level": "h2",
      "text": "Running inference with LoRAs",
      "id": "running-inference-with-loras"
    },
    {
      "level": "h2",
      "text": "Running inference with public LoRAs",
      "id": "running-inference-with-public-loras"
    },
    {
      "level": "h3",
      "text": "cURL",
      "id": "curl"
    },
    {
      "level": "h3",
      "text": "JavaScript",
      "id": "javascript"
    },
    {
      "level": "h2",
      "text": "1. Create a new Worker project",
      "id": "1.-create-a-new-worker-project"
    },
    {
      "level": "h2",
      "text": "2. Develop with Wrangler CLI",
      "id": "2.-develop-with-wrangler-cli"
    },
    {
      "level": "h2",
      "text": "3. Adding the AI binding",
      "id": "3.-adding-the-ai-binding"
    },
    {
      "level": "h2",
      "text": "4. Adding embeddings using Cloudflare D1 and Vectorize",
      "id": "4.-adding-embeddings-using-cloudflare-d1-and-vectorize"
    },
    {
      "level": "h2",
      "text": "5. Creating a workflow",
      "id": "5.-creating-a-workflow"
    },
    {
      "level": "h2",
      "text": "6. Creating notes and adding them to Vectorize",
      "id": "6.-creating-notes-and-adding-them-to-vectorize"
    },
    {
      "level": "h2",
      "text": "7. Querying Vectorize to retrieve notes",
      "id": "7.-querying-vectorize-to-retrieve-notes"
    },
    {
      "level": "h2",
      "text": "8. Adding Anthropic Claude model (optional)",
      "id": "8.-adding-anthropic-claude-model-(optional)"
    },
    {
      "level": "h2",
      "text": "9. Deleting notes and vectors",
      "id": "9.-deleting-notes-and-vectors"
    },
    {
      "level": "h2",
      "text": "10. Text splitting (optional)",
      "id": "10.-text-splitting-(optional)"
    },
    {
      "level": "h2",
      "text": "11. Deploy your project",
      "id": "11.-deploy-your-project"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "1: Create a new Cloudflare Worker project",
      "id": "1:-create-a-new-cloudflare-worker-project"
    },
    {
      "level": "h2",
      "text": "2. Connect your Worker to Workers AI",
      "id": "2.-connect-your-worker-to-workers-ai"
    },
    {
      "level": "h2",
      "text": "3. Configure Wrangler",
      "id": "3.-configure-wrangler"
    },
    {
      "level": "h2",
      "text": "4. Handle large audio files with chunking",
      "id": "4.-handle-large-audio-files-with-chunking"
    },
    {
      "level": "h2",
      "text": "5. Deploy your Worker",
      "id": "5.-deploy-your-worker"
    },
    {
      "level": "h2",
      "text": "Exploring Code Generation Using DeepSeek Coder",
      "id": "exploring-code-generation-using-deepseek-coder"
    },
    {
      "level": "h3",
      "text": "Configuring your environment",
      "id": "configuring-your-environment"
    },
    {
      "level": "h3",
      "text": "Generate code from a comment",
      "id": "generate-code-from-a-comment"
    }
  ],
  "url": "llms-txt#no-nodejs_compat-flags-here",
  "links": []
}