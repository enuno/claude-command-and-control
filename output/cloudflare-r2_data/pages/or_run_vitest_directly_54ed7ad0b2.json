{
  "title": "or run vitest directly",
  "content": "$ npx vitest\nsh\n  MyAgent\n    ✓ should return a greeting (1 ms)\n\nTest Files  1 passed (1)\nsh\n$ npx wrangler dev\nsh\nYour Worker and resources are simulated locally via Miniflare. For more information, see: https://developers.cloudflare.com/workers/testing/local-development.\n\nYour worker has access to the following bindings:\n- Durable Objects:\n  - MyAgent: MyAgent\n  Starting local server...\n[wrangler:inf] Ready on http://localhost:53645\nsh\n  npm create cloudflare@latest -- my-chess-app\n  sh\n  yarn create cloudflare my-chess-app\n  sh\n  pnpm create cloudflare@latest my-chess-app\n  sh\ncd my-chess-app\nsh\nnpm install agents @modelcontextprotocol/sdk chess.js react react-dom react-chessboard\nsh\nnpm install -D @cloudflare/vite-plugin @vitejs/plugin-react vite vite-plugin-singlefile @types/react @types/react-dom\njsonc\n  {\n    \"name\": \"my-chess-app\",\n    \"main\": \"src/index.ts\",\n    \"compatibility_date\": \"2025-01-01\",\n    \"compatibility_flags\": [\"nodejs_compat\"],\n    \"durable_objects\": {\n      \"bindings\": [\n        {\n          \"name\": \"CHESS\",\n          \"class_name\": \"ChessGame\"\n        }\n      ]\n    },\n    \"migrations\": [\n      {\n        \"tag\": \"v1\",\n        \"new_sqlite_classes\": [\"ChessGame\"]\n      }\n    ],\n    \"assets\": {\n      \"directory\": \"dist\",\n      \"binding\": \"ASSETS\"\n    }\n  }\n  toml\n  name = \"my-chess-app\"\n  main = \"src/index.ts\"\n  compatibility_date = \"2025-01-01\"\n  compatibility_flags = [ \"nodejs_compat\" ]\n\n[[durable_objects.bindings]]\n  name = \"CHESS\"\n  class_name = \"ChessGame\"\n\n[[migrations]]\n  tag = \"v1\"\n  new_sqlite_classes = [ \"ChessGame\" ]\n\n[assets]\n  directory = \"dist\"\n  binding = \"ASSETS\"\n  ts\nimport { cloudflare } from \"@cloudflare/vite-plugin\";\nimport react from \"@vitejs/plugin-react\";\nimport { defineConfig } from \"vite\";\nimport { viteSingleFile } from \"vite-plugin-singlefile\";\n\nexport default defineConfig({\n  plugins: [react(), cloudflare(), viteSingleFile()],\n  build: {\n    minify: false\n  }\n});\njson\n{\n  \"scripts\": {\n    \"dev\": \"vite\",\n    \"build\": \"vite build\",\n    \"deploy\": \"vite build && wrangler deploy\"\n  }\n}\ntsx\nimport { Agent, callable, getCurrentAgent } from \"agents\";\nimport { Chess } from \"chess.js\";\n\ntype Color = \"w\" | \"b\";\n\ntype ConnectionState = {\n  playerId: string;\n};\n\nexport type State = {\n  board: string;\n  players: { w?: string; b?: string };\n  status: \"waiting\" | \"active\" | \"mate\" | \"draw\" | \"resigned\";\n  winner?: Color;\n  lastSan?: string;\n};\n\nexport class ChessGame extends Agent<Env, State> {\n  initialState: State = {\n    board: new Chess().fen(),\n    players: {},\n    status: \"waiting\"\n  };\n\nconstructor(ctx: DurableObjectState, public env: Env) {\n    super(ctx, env);\n    this.game.load(this.state.board);\n  }\n\nprivate colorOf(playerId: string): Color | undefined {\n    const { players } = this.state;\n    if (players.w === playerId) return \"w\";\n    if (players.b === playerId) return \"b\";\n    return undefined;\n  }\n\n@callable()\n  join(params: { playerId: string; preferred?: Color | \"any\" }) {\n    const { playerId, preferred = \"any\" } = params;\n    const { connection } = getCurrentAgent();\n    if (!connection) throw new Error(\"Not connected\");\n\nconnection.setState({ playerId });\n    const s = this.state;\n\n// Already seated? Return seat\n    const already = this.colorOf(playerId);\n    if (already) {\n      return { ok: true, role: already as Color, state: s };\n    }\n\n// Choose a seat\n    const free: Color[] = ([\"w\", \"b\"] as const).filter((c) => !s.players[c]);\n    if (free.length === 0) {\n      return { ok: true, role: \"spectator\" as const, state: s };\n    }\n\nlet seat: Color = free[0];\n    if (preferred === \"w\" && free.includes(\"w\")) seat = \"w\";\n    if (preferred === \"b\" && free.includes(\"b\")) seat = \"b\";\n\ns.players[seat] = playerId;\n    s.status = s.players.w && s.players.b ? \"active\" : \"waiting\";\n    this.setState(s);\n    return { ok: true, role: seat, state: s };\n  }\n\n@callable()\n  move(\n    move: { from: string; to: string; promotion?: string },\n    expectedFen?: string\n  ) {\n    if (this.state.status === \"waiting\") {\n      return {\n        ok: false,\n        reason: \"not-in-game\",\n        fen: this.game.fen(),\n        status: this.state.status\n      };\n    }\n\nconst { connection } = getCurrentAgent();\n    if (!connection) throw new Error(\"Not connected\");\n    const { playerId } = connection.state as ConnectionState;\n\nconst seat = this.colorOf(playerId);\n    if (!seat) {\n      return {\n        ok: false,\n        reason: \"not-in-game\",\n        fen: this.game.fen(),\n        status: this.state.status\n      };\n    }\n\nif (seat !== this.game.turn()) {\n      return {\n        ok: false,\n        reason: \"not-your-turn\",\n        fen: this.game.fen(),\n        status: this.state.status\n      };\n    }\n\n// Optimistic sync guard\n    if (expectedFen && expectedFen !== this.game.fen()) {\n      return {\n        ok: false,\n        reason: \"stale\",\n        fen: this.game.fen(),\n        status: this.state.status\n      };\n    }\n\nconst res = this.game.move(move);\n    if (!res) {\n      return {\n        ok: false,\n        reason: \"illegal\",\n        fen: this.game.fen(),\n        status: this.state.status\n      };\n    }\n\nconst fen = this.game.fen();\n    let status: State[\"status\"] = \"active\";\n    if (this.game.isCheckmate()) status = \"mate\";\n    else if (this.game.isDraw()) status = \"draw\";\n\nthis.setState({\n      ...this.state,\n      board: fen,\n      lastSan: res.san,\n      status,\n      winner: status === \"mate\" ? (this.game.turn() === \"w\" ? \"b\" : \"w\") : undefined\n    });\n\nreturn { ok: true, fen, san: res.san, status };\n  }\n\n@callable()\n  resign() {\n    const { connection } = getCurrentAgent();\n    if (!connection) throw new Error(\"Not connected\");\n    const { playerId } = connection.state as ConnectionState;\n\nconst seat = this.colorOf(playerId);\n    if (!seat) return { ok: false, reason: \"not-in-game\", state: this.state };\n\nconst winner = seat === \"w\" ? \"b\" : \"w\";\n    this.setState({ ...this.state, status: \"resigned\", winner });\n    return { ok: true, state: this.state };\n  }\n}\nts\nimport { createMcpHandler } from \"agents/mcp\";\nimport { routeAgentRequest } from \"agents\";\nimport { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\";\nimport { env } from \"cloudflare:workers\";\n\nconst getWidgetHtml = async (host: string) => {\n  let html = await (await env.ASSETS.fetch(\"http://localhost/\")).text();\n  html = html.replace(\n    \"<!--RUNTIME_CONFIG-->\",\n    `<script>window.HOST = \\`${host}\\`;</script>`\n  );\n  return html;\n};\n\nconst server = new McpServer({ name: \"Chess\", version: \"v1.0.0\" });\n\n// Register a UI resource that ChatGPT can render\nserver.registerResource(\n  \"chess\",\n  \"ui://widget/index.html\",\n  {},\n  async (_uri, extra) => {\n    return {\n      contents: [\n        {\n          uri: \"ui://widget/index.html\",\n          mimeType: \"text/html+skybridge\",\n          text: await getWidgetHtml(extra.requestInfo?.headers.host as string)\n        }\n      ]\n    };\n  }\n);\n\n// Register a tool that ChatGPT can call to render the UI\nserver.registerTool(\n  \"playChess\",\n  {\n    title: \"Renders a chess game menu, ready to start or join a game.\",\n    annotations: { readOnlyHint: true },\n    _meta: {\n      \"openai/outputTemplate\": \"ui://widget/index.html\",\n      \"openai/toolInvocation/invoking\": \"Opening chess widget\",\n      \"openai/toolInvocation/invoked\": \"Chess widget opened\"\n    }\n  },\n  async (_, _extra) => {\n    return {\n      content: [{ type: \"text\", text: \"Successfully rendered chess game menu\" }]\n    };\n  }\n);\n\nconst mcpHandler = createMcpHandler(server);\n\nexport default {\n  async fetch(req: Request, env: Env, ctx: ExecutionContext) {\n    const url = new URL(req.url);\n    if (url.pathname.startsWith(\"/mcp\")) return mcpHandler(req, env, ctx);\n\nreturn (\n      (await routeAgentRequest(req, env)) ??\n      new Response(\"Not found\", { status: 404 })\n    );\n  }\n};\n\nexport { ChessGame } from \"./chess\";\nhtml\n<!doctype html>\n<html>\n  <head>\n    <!--RUNTIME_CONFIG-->\n  </head>\n  <body>\n    <div id=\"root\" style=\"font-family: verdana\"></div>\n    <script type=\"module\" src=\"/src/app.tsx\"></script>\n  </body>\n</html>\ntsx\nimport { useEffect, useRef, useState } from \"react\";\nimport { useAgent } from \"agents/react\";\nimport { createRoot } from \"react-dom/client\";\nimport { Chess, type Square } from \"chess.js\";\nimport { Chessboard, type PieceDropHandlerArgs } from \"react-chessboard\";\nimport type { State as ServerState } from \"./chess\";\n\nfunction usePlayerId() {\n  const [pid] = useState(() => {\n    const existing = localStorage.getItem(\"playerId\");\n    if (existing) return existing;\n    const id = crypto.randomUUID();\n    localStorage.setItem(\"playerId\", id);\n    return id;\n  });\n  return pid;\n}\n\nfunction App() {\n  const playerId = usePlayerId();\n  const [gameId, setGameId] = useState<string | null>(null);\n  const [gameIdInput, setGameIdInput] = useState(\"\");\n  const [menuError, setMenuError] = useState<string | null>(null);\n\nconst gameRef = useRef(new Chess());\n  const [fen, setFen] = useState(gameRef.current.fen());\n  const [myColor, setMyColor] = useState<\"w\" | \"b\" | \"spectator\">(\"spectator\");\n  const [pending, setPending] = useState(false);\n  const [serverState, setServerState] = useState<ServerState | null>(null);\n  const [joined, setJoined] = useState(false);\n\nconst host = window.HOST ?? \"http://localhost:5173/\";\n\nconst { stub } = useAgent<ServerState>({\n    host,\n    name: gameId ?? \"__lobby__\",\n    agent: \"chess\",\n    onStateUpdate: (s) => {\n      if (!gameId) return;\n      gameRef.current.load(s.board);\n      setFen(s.board);\n      setServerState(s);\n    }\n  });\n\nuseEffect(() => {\n    if (!gameId || joined) return;\n\n(async () => {\n      try {\n        const res = await stub.join({ playerId, preferred: \"any\" });\n        if (!res?.ok) return;\n\nsetMyColor(res.role);\n        gameRef.current.load(res.state.board);\n        setFen(res.state.board);\n        setServerState(res.state);\n        setJoined(true);\n      } catch (error) {\n        console.error(\"Failed to join game\", error);\n      }\n    })();\n  }, [playerId, gameId, stub, joined]);\n\nasync function handleStartNewGame() {\n    const newId = crypto.randomUUID();\n    setGameId(newId);\n    setGameIdInput(newId);\n    setMenuError(null);\n    setJoined(false);\n  }\n\nasync function handleJoinGame() {\n    const trimmed = gameIdInput.trim();\n    if (!trimmed) {\n      setMenuError(\"Enter a game ID to join.\");\n      return;\n    }\n    setGameId(trimmed);\n    setMenuError(null);\n    setJoined(false);\n  }\n\nconst handleHelpClick = () => {\n    window.openai?.sendFollowUpMessage?.({\n      prompt: `Help me with my chess game. I am playing as ${myColor} and the board is: ${fen}. Please only offer written advice.`\n    });\n  };\n\nfunction onPieceDrop({ sourceSquare, targetSquare }: PieceDropHandlerArgs) {\n    if (!gameId || !sourceSquare || !targetSquare || pending) return false;\n\nconst game = gameRef.current;\n    if (myColor === \"spectator\" || game.turn() !== myColor) return false;\n\nconst piece = game.get(sourceSquare as Square);\n    if (!piece || piece.color !== myColor) return false;\n\nconst prevFen = game.fen();\n\ntry {\n      const local = game.move({ from: sourceSquare, to: targetSquare, promotion: \"q\" });\n      if (!local) return false;\n    } catch {\n      return false;\n    }\n\nconst nextFen = game.fen();\n    setFen(nextFen);\n    setPending(true);\n\nstub\n      .move({ from: sourceSquare, to: targetSquare, promotion: \"q\" }, prevFen)\n      .then((r) => {\n        if (!r.ok) {\n          game.load(r.fen);\n          setFen(r.fen);\n        }\n      })\n      .finally(() => setPending(false));\n\nreturn (\n    <div style={{ padding: \"20px\", background: \"#f8fafc\", minHeight: \"100vh\" }}>\n      {!gameId ? (\n        <div style={{ maxWidth: \"420px\", margin: \"0 auto\", background: \"#fff\", borderRadius: \"16px\", padding: \"24px\" }}>\n          <h1>Ready to play?</h1>\n          <p>Start a new match or join an existing game.</p>\n          <button onClick={handleStartNewGame} style={{ padding: \"12px\", background: \"#2563eb\", color: \"#fff\", border: \"none\", borderRadius: \"8px\", cursor: \"pointer\", width: \"100%\" }}>\n            Start a new game\n          </button>\n          <div style={{ marginTop: \"16px\" }}>\n            <input\n              placeholder=\"Paste a game ID\"\n              value={gameIdInput}\n              onChange={(e) => setGameIdInput(e.target.value)}\n              style={{ width: \"100%\", padding: \"10px\", borderRadius: \"8px\", border: \"1px solid #ccc\" }}\n            />\n            <button onClick={handleJoinGame} style={{ marginTop: \"8px\", padding: \"10px\", background: \"#0f172a\", color: \"#fff\", border: \"none\", borderRadius: \"8px\", cursor: \"pointer\", width: \"100%\" }}>\n              Join\n            </button>\n            {menuError && <p style={{ color: \"red\", fontSize: \"0.85rem\" }}>{menuError}</p>}\n          </div>\n        </div>\n      ) : (\n        <div style={{ maxWidth: \"600px\", margin: \"0 auto\" }}>\n          <div style={{ background: \"#fff\", padding: \"16px\", borderRadius: \"16px\", marginBottom: \"16px\" }}>\n            <h2>Game {gameId}</h2>\n            <p>Status: {serverState?.status}</p>\n            <button onClick={handleHelpClick} style={{ padding: \"10px\", background: \"#2563eb\", color: \"#fff\", border: \"none\", borderRadius: \"8px\", cursor: \"pointer\" }}>\n              Ask for help\n            </button>\n          </div>\n          <div style={{ background: \"#fff\", padding: \"16px\", borderRadius: \"16px\" }}>\n            <Chessboard\n              position={fen}\n              onPieceDrop={onPieceDrop}\n              boardOrientation={myColor === \"b\" ? \"black\" : \"white\"}\n            />\n          </div>\n        </div>\n      )}\n    </div>\n  );\n}\n\nconst root = createRoot(document.getElementById(\"root\")!);\nroot.render(<App />);\nsh\nnpm run build\nsh\nnpx wrangler deploy\nplaintext\nhttps://my-chess-app.YOUR_SUBDOMAIN.workers.dev\nts\nconst server = new McpServer({ name: \"Chess\", version: \"v1.0.0\" });\n\n// Register a UI resource that ChatGPT can render\nserver.registerResource(\n  \"chess\",\n  \"ui://widget/index.html\",\n  {},\n  async (_uri, extra) => {\n    return {\n      contents: [\n        {\n          uri: \"ui://widget/index.html\",\n          mimeType: \"text/html+skybridge\",\n          text: await getWidgetHtml(extra.requestInfo?.headers.host as string)\n        }\n      ]\n    };\n  }\n);\n\n// Register a tool that ChatGPT can call to render the UI\nserver.registerTool(\n  \"playChess\",\n  {\n    title: \"Renders a chess game menu, ready to start or join a game.\",\n    annotations: { readOnlyHint: true },\n    _meta: {\n      \"openai/outputTemplate\": \"ui://widget/index.html\",\n      \"openai/toolInvocation/invoking\": \"Opening chess widget\",\n      \"openai/toolInvocation/invoked\": \"Chess widget opened\"\n    }\n  },\n  async (_, _extra) => {\n    return {\n      content: [{ type: \"text\", text: \"Successfully rendered chess game menu\" }]\n    };\n  }\n);\ntsx\nexport class ChessGame extends Agent<Env, State> {\n  initialState: State = {\n    board: new Chess().fen(),\n    players: {},\n    status: \"waiting\"\n  };\n\nconstructor(\n    ctx: DurableObjectState,\n    public env: Env\n  ) {\n    super(ctx, env);\n    this.game.load(this.state.board);\n  }\nts\n@callable()\njoin(params: { playerId: string; preferred?: Color | \"any\" }) {\n  const { playerId, preferred = \"any\" } = params;\n  const { connection } = getCurrentAgent();\n  if (!connection) throw new Error(\"Not connected\");\n\nconnection.setState({ playerId });\n  const s = this.state;\n\n// Already seated? Return seat\n  const already = this.colorOf(playerId);\n  if (already) {\n    return { ok: true, role: already as Color, state: s };\n  }\n\n// Choose a seat\n  const free: Color[] = ([\"w\", \"b\"] as const).filter((c) => !s.players[c]);\n  if (free.length === 0) {\n    return { ok: true, role: \"spectator\" as const, state: s };\n  }\n\nlet seat: Color = free[0];\n  if (preferred === \"w\" && free.includes(\"w\")) seat = \"w\";\n  if (preferred === \"b\" && free.includes(\"b\")) seat = \"b\";\n\ns.players[seat] = playerId;\n  s.status = s.players.w && s.players.b ? \"active\" : \"waiting\";\n  this.setState(s);\n  return { ok: true, role: seat, state: s };\n}\ntsx\nconst { stub } = useAgent<ServerState>({\n  host,\n  name: gameId ?? \"__lobby__\",\n  agent: \"chess\",\n  onStateUpdate: (s) => {\n    gameRef.current.load(s.board);\n    setFen(s.board);\n    setServerState(s);\n  }\n});\ntsx\nconst res = await stub.join({ playerId, preferred: \"any\" });\nawait stub.move({ from: \"e2\", to: \"e4\" });\nts\nconst handleHelpClick = () => {\n  window.openai?.sendFollowUpMessage?.({\n    prompt: `Help me with my chess game. I am playing as ${myColor} and the board is: ${fen}. Please only offer written advice as there are no tools for you to use.`\n  });\n};\nsh\n     npm create cloudflare@latest -- my-mcp-client --template=cloudflare/ai/demos/hello-world\n     sh\n     yarn create cloudflare my-mcp-client --template=cloudflare/ai/demos/hello-world\n     sh\n     pnpm create cloudflare@latest my-mcp-client --template=cloudflare/ai/demos/hello-world\n     sh\n   cd my-mcp-client\n   js\n     import { Agent, routeAgentRequest } from \"agents\";\n\nexport class HelloAgent extends Agent {\n       async onRequest(request) {\n         return new Response(\"Hello, Agent!\", { status: 200 });\n       }\n     }\n\nexport default {\n       async fetch(request, env) {\n         return (\n           (await routeAgentRequest(request, env, { cors: true })) ||\n           new Response(\"Not found\", { status: 404 })\n         );\n       },\n     };\n     ts\n     import { Agent, type AgentNamespace, routeAgentRequest } from \"agents\";\n\ntype Env = {\n       HelloAgent: AgentNamespace<HelloAgent>;\n     };\n\nexport class HelloAgent extends Agent<Env, never> {\n       async onRequest(request: Request): Promise<Response> {\n         return new Response(\"Hello, Agent!\", { status: 200 });\n       }\n     }\n\nexport default {\n       async fetch(request: Request, env: Env) {\n         return (\n           (await routeAgentRequest(request, env, { cors: true })) ||\n           new Response(\"Not found\", { status: 404 })\n         );\n       },\n     } satisfies ExportedHandler<Env>;\n     js\n     export class HelloAgent extends Agent {\n       async onRequest(request) {\n         const url = new URL(request.url);\n\n// Connect to an MCP server\n         if (url.pathname.endsWith(\"add-mcp\") && request.method === \"POST\") {\n           const { serverUrl, name } = await request.json();\n\nconst { id, authUrl } = await this.addMcpServer(name, serverUrl);\n\nif (authUrl) {\n             // OAuth required - return auth URL\n             return new Response(JSON.stringify({ serverId: id, authUrl }), {\n               headers: { \"Content-Type\": \"application/json\" },\n             });\n           }\n\nreturn new Response(\n             JSON.stringify({ serverId: id, status: \"connected\" }),\n             { headers: { \"Content-Type\": \"application/json\" } },\n           );\n         }\n\nreturn new Response(\"Not found\", { status: 404 });\n       }\n     }\n     ts\n     export class HelloAgent extends Agent<Env, never> {\n       async onRequest(request: Request): Promise<Response> {\n         const url = new URL(request.url);\n\n// Connect to an MCP server\n         if (url.pathname.endsWith(\"add-mcp\") && request.method === \"POST\") {\n           const { serverUrl, name } = (await request.json()) as {\n             serverUrl: string;\n             name: string;\n           };\n\nconst { id, authUrl } = await this.addMcpServer(name, serverUrl);\n\nif (authUrl) {\n             // OAuth required - return auth URL\n             return new Response(\n               JSON.stringify({ serverId: id, authUrl }),\n               { headers: { \"Content-Type\": \"application/json\" } },\n             );\n           }\n\nreturn new Response(\n             JSON.stringify({ serverId: id, status: \"connected\" }),\n             { headers: { \"Content-Type\": \"application/json\" } },\n           );\n         }\n\nreturn new Response(\"Not found\", { status: 404 });\n       }\n     }\n     sh\n   npm start\n   sh\n   curl -X POST http://localhost:8788/agents/hello-agent/default/add-mcp \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\n       \"serverUrl\": \"https://docs.mcp.cloudflare.com/mcp\",\n       \"name\": \"Example Server\"\n     }'\n   json\n   {\n     \"serverId\": \"example-server-id\",\n     \"status\": \"connected\"\n   }\n   js\n     export class HelloAgent extends Agent {\n       async onRequest(request) {\n         const url = new URL(request.url);\n\n// ... previous add-mcp endpoint ...\n\n// List MCP state (servers, tools, etc)\n         if (url.pathname.endsWith(\"mcp-state\") && request.method === \"GET\") {\n           const mcpState = this.getMcpServers();\n\nreturn new Response(JSON.stringify(mcpState, null, 2), {\n             headers: { \"Content-Type\": \"application/json\" },\n           });\n         }\n\nreturn new Response(\"Not found\", { status: 404 });\n       }\n     }\n     ts\n     export class HelloAgent extends Agent<Env, never> {\n       async onRequest(request: Request): Promise<Response> {\n         const url = new URL(request.url);\n\n// ... previous add-mcp endpoint ...\n\n// List MCP state (servers, tools, etc)\n         if (url.pathname.endsWith(\"mcp-state\") && request.method === \"GET\") {\n           const mcpState = this.getMcpServers();\n\nreturn new Response(JSON.stringify(mcpState, null, 2), {\n             headers: { \"Content-Type\": \"application/json\" },\n           });\n         }\n\nreturn new Response(\"Not found\", { status: 404 });\n       }\n     }\n     sh\n   curl http://localhost:8788/agents/hello-agent/default/mcp-state\n   json\n   {\n     \"servers\": {\n       \"example-server-id\": {\n         \"name\": \"Example Server\",\n         \"state\": \"ready\",\n         \"server_url\": \"https://docs.mcp.cloudflare.com/mcp\",\n         ...\n       }\n     },\n     \"tools\": [\n       {\n         \"name\": \"add\",\n         \"description\": \"Add two numbers\",\n         \"serverId\": \"example-server-id\",\n         ...\n       }\n     ]\n   }\n   sh\n  npm create cloudflare@latest -- human-in-the-loop\n  sh\n  yarn create cloudflare human-in-the-loop\n  sh\n  pnpm create cloudflare@latest human-in-the-loop\n  sh\ncd human-in-the-loop\nsh\nnpm install agents @ai-sdk/openai ai zod react react-dom\nsh\ntouch .dev.vars\nsh\nOPENAI_API_KEY=\"your-openai-api-key\"\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"human-in-the-loop\",\n    \"main\": \"./src/server.ts\",\n    \"compatibility_date\": \"2025-02-21\",\n    \"compatibility_flags\": [\n      \"nodejs_compat\",\n      \"nodejs_compat_populate_process_env\"\n    ],\n    \"assets\": {\n      \"directory\": \"public\"\n    },\n    \"durable_objects\": {\n      \"bindings\": [\n        {\n          \"name\": \"HumanInTheLoop\",\n          \"class_name\": \"HumanInTheLoop\"\n        }\n      ]\n    },\n    \"migrations\": [\n      {\n        \"tag\": \"v1\",\n        \"new_sqlite_classes\": [\n          \"HumanInTheLoop\"\n        ]\n      }\n    ]\n  }\n  toml\n  name = \"human-in-the-loop\"\n  main = \"./src/server.ts\"\n  compatibility_date = \"2025-02-21\"\n  compatibility_flags = [\"nodejs_compat\", \"nodejs_compat_populate_process_env\"]\n\nassets = { directory = \"public\" }\n\n[[durable_objects.bindings]]\n  name = \"HumanInTheLoop\"\n  class_name = \"HumanInTheLoop\"\n\n[[migrations]]\n  tag = \"v1\"\n  new_sqlite_classes = [\"HumanInTheLoop\"]\n  ts\nimport { tool } from \"ai\";\nimport { z } from \"zod\";\nimport type { AITool } from \"agents/ai-react\";\n\n// Server-side tool that requires confirmation (no execute function)\nconst getWeatherInformationTool = tool({\n  description:\n    \"Get the current weather information for a specific city. Always use this tool when the user asks about weather.\",\n  inputSchema: z.object({\n    city: z.string().describe(\"The name of the city to get weather for\")\n  })\n  // no execute function - requires human approval\n});\n\n// Client-side tool that requires confirmation\nconst getLocalTimeTool = tool({\n  description: \"Get the local time for a specified location\",\n  inputSchema: z.object({ location: z.string() }),\n  execute: async ({ location }) => {\n    console.log(`Getting local time for ${location}`);\n    await new Promise((res) => setTimeout(res, 2000));\n    return \"10am\";\n  }\n});\n\n// Server-side tool that does NOT require confirmation\nconst getLocalNewsTool = tool({\n  description: \"Get local news for a specified location\",\n  inputSchema: z.object({ location: z.string() }),\n  execute: async ({ location }) => {\n    console.log(`Getting local news for ${location}`);\n    await new Promise((res) => setTimeout(res, 2000));\n    return `${location} kittens found drinking tea this last weekend`;\n  }\n});\n\n// Export AI SDK tools for server-side use\nexport const tools = {\n  getLocalTime: {\n    description: getLocalTimeTool.description,\n    inputSchema: getLocalTimeTool.inputSchema\n  },\n  getWeatherInformation: getWeatherInformationTool,\n  getLocalNews: getLocalNewsTool\n};\n\n// Export AITool format for client-side use\nexport const clientTools: Record<string, AITool> = {\n  getLocalTime: getLocalTimeTool as AITool,\n  getWeatherInformation: {\n    description: getWeatherInformationTool.description,\n    inputSchema: getWeatherInformationTool.inputSchema\n  },\n  getLocalNews: {\n    description: getLocalNewsTool.description,\n    inputSchema: getLocalNewsTool.inputSchema\n  }\n};\nts\nimport type { UIMessage } from \"@ai-sdk/react\";\nimport type { UIMessageStreamWriter, ToolSet } from \"ai\";\nimport type { z } from \"zod\";\n\n// Approval constants\nexport const APPROVAL = {\n  NO: \"No, denied.\",\n  YES: \"Yes, confirmed.\"\n} as const;\n\n// Tools that require Human-In-The-Loop confirmation\nexport const toolsRequiringConfirmation = [\n  \"getLocalTime\",\n  \"getWeatherInformation\"\n];\n\n// Type guard to check if part has required properties\nfunction isToolConfirmationPart(part: unknown): part is {\n  type: string;\n  output: string;\n  input?: Record<string, unknown>;\n} {\n  return (\n    typeof part === \"object\" &&\n    part !== null &&\n    \"type\" in part &&\n    \"output\" in part &&\n    typeof (part as { type: unknown }).type === \"string\" &&\n    typeof (part as { output: unknown }).output === \"string\"\n  );\n}\n\n// Check if a message contains tool confirmations\nexport function hasToolConfirmation(message: UIMessage): boolean {\n  return (\n    message?.parts?.some(\n      (part) =>\n        part.type?.startsWith(\"tool-\") &&\n        toolsRequiringConfirmation.includes(part.type?.slice(\"tool-\".length)) &&\n        \"output\" in part\n    ) || false\n  );\n}\n\n// Weather tool implementation\nexport async function getWeatherInformation(args: unknown): Promise<string> {\n  const { city } = args as { city: string };\n  const conditions = [\"sunny\", \"cloudy\", \"rainy\", \"snowy\"];\n  return `The weather in ${city} is ${\n    conditions[Math.floor(Math.random() * conditions.length)]\n  }.`;\n}\nts\nimport { openai } from \"@ai-sdk/openai\";\nimport { routeAgentRequest } from \"agents\";\nimport { AIChatAgent } from \"agents/ai-chat-agent\";\nimport {\n  convertToModelMessages,\n  createUIMessageStream,\n  createUIMessageStreamResponse,\n  type StreamTextOnFinishCallback,\n  streamText,\n  stepCountIs\n} from \"ai\";\nimport { tools } from \"./tools\";\nimport {\n  processToolCalls,\n  hasToolConfirmation,\n  getWeatherInformation\n} from \"./utils\";\n\ntype Env = {\n  OPENAI_API_KEY: string;\n};\n\nexport class HumanInTheLoop extends AIChatAgent<Env> {\n  async onChatMessage(onFinish: StreamTextOnFinishCallback<{}>) {\n    const startTime = Date.now();\n    const lastMessage = this.messages[this.messages.length - 1];\n\n// Check if the last message contains tool confirmations\n    if (hasToolConfirmation(lastMessage)) {\n      // Process tool confirmations using UI stream\n      const stream = createUIMessageStream({\n        execute: async ({ writer }) => {\n          await processToolCalls(\n            { writer, messages: this.messages, tools },\n            { getWeatherInformation }\n          );\n        }\n      });\n      return createUIMessageStreamResponse({ stream });\n    }\n\n// Normal message flow - stream AI response\n    const result = streamText({\n      messages: convertToModelMessages(this.messages),\n      model: openai(\"gpt-4o\"),\n      onFinish,\n      tools,\n      stopWhen: stepCountIs(5)\n    });\n\nreturn result.toUIMessageStreamResponse({\n      messageMetadata: ({ part }) => {\n        if (part.type === \"start\") {\n          return {\n            model: \"gpt-4o\",\n            createdAt: Date.now(),\n            messageCount: this.messages.length\n          };\n        }\n        if (part.type === \"finish\") {\n          return {\n            responseTime: Date.now() - startTime,\n            totalTokens: part.totalUsage?.totalTokens\n          };\n        }\n      }\n    });\n  }\n}\n\nexport default {\n  async fetch(request: Request, env: Env, _ctx: ExecutionContext) {\n    return (\n      (await routeAgentRequest(request, env)) ||\n      new Response(\"Not found\", { status: 404 })\n    );\n  }\n} satisfies ExportedHandler<Env>;\ntsx\nimport type { UIMessage as Message } from \"ai\";\nimport { getToolName, isToolUIPart } from \"ai\";\nimport { clientTools } from \"./tools\";\nimport { APPROVAL, toolsRequiringConfirmation } from \"./utils\";\nimport { useAgentChat, type AITool } from \"agents/ai-react\";\nimport { useAgent } from \"agents/react\";\nimport { useCallback, useEffect, useRef, useState } from \"react\";\n\nexport default function Chat() {\n  const messagesEndRef = useRef<HTMLDivElement>(null);\n\nconst scrollToBottom = useCallback(() => {\n    messagesEndRef.current?.scrollIntoView({ behavior: \"smooth\" });\n  }, []);\n\nconst agent = useAgent({\n    agent: \"human-in-the-loop\"\n  });\n\nconst { messages, sendMessage, addToolResult, clearHistory } = useAgentChat({\n    agent,\n    experimental_automaticToolResolution: true,\n    toolsRequiringConfirmation,\n    tools: clientTools satisfies Record<string, AITool>\n  });\n\nconst [input, setInput] = useState(\"\");\n\nconst handleSubmit = useCallback(\n    (e: React.FormEvent<HTMLFormElement>) => {\n      e.preventDefault();\n      if (input.trim()) {\n        sendMessage({ role: \"user\", parts: [{ type: \"text\", text: input }] });\n        setInput(\"\");\n      }\n    },\n    [input, sendMessage]\n  );\n\n// Scroll to bottom when messages change\n  useEffect(() => {\n    messages.length > 0 && scrollToBottom();\n  }, [messages, scrollToBottom]);\n\n// Check if there's a pending tool confirmation\n  const pendingToolCallConfirmation = messages.some((m: Message) =>\n    m.parts?.some(\n      (part) => isToolUIPart(part) && part.state === \"input-available\"\n    )\n  );\n\nreturn (\n    <div className=\"chat-container\">\n      <div className=\"messages-wrapper\">\n        {messages?.map((m: Message) => (\n          <div key={m.id} className=\"message\">\n            <strong>{`${m.role}: `}</strong>\n            {m.parts?.map((part, i) => {\n              switch (part.type) {\n                case \"text\":\n                  return (\n                    <div key={i} className=\"message-content\">\n                      {part.text}\n                    </div>\n                  );\n                default:\n                  if (isToolUIPart(part)) {\n                    const toolCallId = part.toolCallId;\n                    const toolName = getToolName(part);\n\n// Show tool results for automatic tools\n                    if (part.state === \"output-available\") {\n                      return (\n                        <div key={toolCallId} className=\"tool-invocation\">\n                          <span className=\"tool-name\">{toolName}</span>{\" \"}\n                          returned:{\" \"}\n                          <span className=\"tool-result\">\n                            {JSON.stringify(part.output, null, 2)}\n                          </span>\n                        </div>\n                      );\n                    }\n\n// Render confirmation UI for tools requiring approval\n                    if (part.state === \"input-available\") {\n                      const tool = clientTools[toolName];\n\nif (!toolsRequiringConfirmation.includes(toolName)) {\n                        return (\n                          <div key={toolCallId} className=\"tool-invocation\">\n                            <span className=\"tool-name\">{toolName}</span>{\" \"}\n                            executing...\n                          </div>\n                        );\n                      }\n\nreturn (\n                        <div key={toolCallId} className=\"tool-invocation\">\n                          Run <span className=\"tool-name\">{toolName}</span> with\n                          args:{\" \"}\n                          <span className=\"tool-args\">\n                            {JSON.stringify(part.input)}\n                          </span>\n                          <div className=\"button-container\">\n                            <button\n                              type=\"button\"\n                              className=\"button-approve\"\n                              onClick={async () => {\n                                const output = tool.execute\n                                  ? await tool.execute(part.input)\n                                  : APPROVAL.YES;\n                                addToolResult({\n                                  tool: toolName,\n                                  output,\n                                  toolCallId\n                                });\n                              }}\n                            >\n                              Approve\n                            </button>\n                            <button\n                              type=\"button\"\n                              className=\"button-reject\"\n                              onClick={() => {\n                                const output = tool.execute\n                                  ? \"User declined to run tool\"\n                                  : APPROVAL.NO;\n                                addToolResult({\n                                  tool: toolName,\n                                  output,\n                                  toolCallId\n                                });\n                              }}\n                            >\n                              Reject\n                            </button>\n                          </div>\n                        </div>\n                      );\n                    }\n                  }\n                  return null;\n              }\n            })}\n          </div>\n        ))}\n        <div ref={messagesEndRef} />\n      </div>\n\n<form onSubmit={handleSubmit}>\n        <input\n          disabled={pendingToolCallConfirmation}\n          className=\"chat-input\"\n          value={input}\n          placeholder=\"Say something...\"\n          onChange={(e) => setInput(e.target.value)}\n        />\n      </form>\n    </div>\n  );\n}\nsh\nnpm run dev\nsh\nnpx wrangler secret put OPENAI_API_KEY\nsh\nnpm run deploy\nplaintext\nhttps://human-in-the-loop.your-account.workers.dev\nts\nexport const toolsRequiringConfirmation = [\n  \"getLocalTime\",\n  \"getWeatherInformation\",\n  \"sendEmail\", // Add your new tools here\n  \"makePurchase\"\n];\nts\nif (hasToolConfirmation(lastMessage)) {\n  const stream = createUIMessageStream({\n    execute: async ({ writer }) => {\n      await processToolCalls(\n        { writer, messages: this.messages, tools },\n        {\n          getWeatherInformation,\n          sendEmail: async ({ to, subject, body }) => {\n            // Your email sending logic\n            return `Email sent to ${to}`;\n          }\n        }\n      );\n    }\n  });\n  return createUIMessageStreamResponse({ stream });\n}\ntsx\nif (part.state === \"input-available\") {\n  return (\n    <div className=\"tool-approval-card\">\n      <h3>Action Required</h3>\n      <p>\n        The AI wants to execute: <strong>{toolName}</strong>\n      </p>\n      <pre>{JSON.stringify(part.input, null, 2)}</pre>\n      <div className=\"approval-buttons\">\n        <button className=\"approve\" onClick={() => handleApprove(part)}>\n          ✓ Approve\n        </button>\n        <button className=\"reject\" onClick={() => handleReject(part)}>\n          ✗ Reject\n        </button>\n      </div>\n    </div>\n  );\n}\nts\nimport { createWorkersAI } from \"workers-ai-provider\";\n\nexport class HumanInTheLoop extends AIChatAgent<Env> {\n  async onChatMessage(onFinish: StreamTextOnFinishCallback<{}>) {\n    const workersai = createWorkersAI({ binding: this.env.AI });\n\nconst result = streamText({\n      messages: convertToModelMessages(this.messages),\n      model: workersai(\"@cf/meta/llama-3-8b-instruct\"),\n      onFinish,\n      tools\n    });\n\nreturn result.toUIMessageStreamResponse();\n  }\n}\njs\n  export class MyAgent extends Agent {\n    async onRequest(request) {\n      const url = new URL(request.url);\n\nif (url.pathname.endsWith(\"/connect\") && request.method === \"POST\") {\n        const { id, authUrl } = await this.addMcpServer(\n          \"Cloudflare Observability\",\n          \"https://observability.mcp.cloudflare.com/mcp\",\n        );\n\nif (authUrl) {\n          // OAuth required - redirect user to authorize\n          return Response.redirect(authUrl, 302);\n        }\n\n// Already authenticated - connection complete\n        return Response.json({ serverId: id, status: \"connected\" });\n      }\n\nreturn new Response(\"Not found\", { status: 404 });\n    }\n  }\n  ts\n  export class MyAgent extends Agent<Env, never> {\n    async onRequest(request: Request): Promise<Response> {\n      const url = new URL(request.url);\n\nif (url.pathname.endsWith(\"/connect\") && request.method === \"POST\") {\n        const { id, authUrl } = await this.addMcpServer(\n          \"Cloudflare Observability\",\n          \"https://observability.mcp.cloudflare.com/mcp\",\n        );\n\nif (authUrl) {\n          // OAuth required - redirect user to authorize\n          return Response.redirect(authUrl, 302);\n        }\n\n// Already authenticated - connection complete\n        return Response.json({ serverId: id, status: \"connected\" });\n      }\n\nreturn new Response(\"Not found\", { status: 404 });\n    }\n  }\n  js\n  export class MyAgent extends Agent {\n    onStart() {\n      this.mcp.configureOAuthCallback({\n        successRedirect: \"/dashboard\",\n        errorRedirect: \"/auth-error\",\n      });\n    }\n  }\n  ts\n  export class MyAgent extends Agent<Env, never> {\n    onStart() {\n      this.mcp.configureOAuthCallback({\n        successRedirect: \"/dashboard\",\n        errorRedirect: \"/auth-error\",\n      });\n    }\n  }\n  js\n  import { Agent } from \"agents\";\n  export class MyAgent extends Agent {\n    onStart() {\n      this.mcp.configureOAuthCallback({\n        customHandler: (result) => {\n          if (result.authSuccess) {\n            // Success - close the popup\n            return new Response(\"<script>window.close();</script>\", {\n              headers: { \"content-type\": \"text/html\" },\n            });\n          } else {\n            // Error - show message, then close\n            return new Response(\n              `<script>alert('Authorization failed: ${result.authError}'); window.close();</script>`,\n              { headers: { \"content-type\": \"text/html\" } },\n            );\n          }\n        },\n      });\n    }\n  }\n  ts\n  import { Agent } from \"agents\";\n  import type { MCPClientOAuthResult } from \"agents/mcp\";\n\nexport class MyAgent extends Agent<Env, never> {\n    onStart() {\n      this.mcp.configureOAuthCallback({\n        customHandler: (result: MCPClientOAuthResult) => {\n          if (result.authSuccess) {\n            // Success - close the popup\n            return new Response(\"<script>window.close();</script>\", {\n              headers: { \"content-type\": \"text/html\" },\n            });\n          } else {\n            // Error - show message, then close\n            return new Response(\n              `<script>alert('Authorization failed: ${result.authError}'); window.close();</script>`,\n              { headers: { \"content-type\": \"text/html\" } },\n            );\n          }\n        },\n      });\n    }\n  }\n  js\n  import { useAgent } from \"agents/react\";\n  function App() {\n    const [mcpState, setMcpState] = useState({\n      prompts: [],\n      resources: [],\n      servers: {},\n      tools: [],\n    });\n\nconst agent = useAgent({\n      agent: \"my-agent\",\n      name: \"session-id\",\n      onMcpUpdate: (mcpServers) => {\n        // Automatically called when MCP state changes!\n        setMcpState(mcpServers);\n      },\n    });\n\nreturn (\n      <div>\n        {Object.entries(mcpState.servers).map(([id, server]) => (\n          <div key={id}>\n            <strong>{server.name}</strong>: {server.state}\n            {server.state === \"authenticating\" && server.auth_url && (\n              <button onClick={() => window.open(server.auth_url, \"_blank\")}>\n                Authorize\n              </button>\n            )}\n          </div>\n        ))}\n      </div>\n    );\n  }\n  ts\n  import { useAgent } from \"agents/react\";\n  import type { MCPServersState } from \"agents\";\n\nfunction App() {\n    const [mcpState, setMcpState] = useState<MCPServersState>({\n      prompts: [],\n      resources: [],\n      servers: {},\n      tools: [],\n    });\n\nconst agent = useAgent({\n      agent: \"my-agent\",\n      name: \"session-id\",\n      onMcpUpdate: (mcpServers: MCPServersState) => {\n        // Automatically called when MCP state changes!\n        setMcpState(mcpServers);\n      },\n    });\n\nreturn (\n      <div>\n        {Object.entries(mcpState.servers).map(([id, server]) => (\n          <div key={id}>\n            <strong>{server.name}</strong>: {server.state}\n            {server.state === \"authenticating\" && server.auth_url && (\n              <button onClick={() => window.open(server.auth_url, \"_blank\")}>\n                Authorize\n              </button>\n            )}\n          </div>\n        ))}\n      </div>\n    );\n  }\n  js\n  export class MyAgent extends Agent {\n    async onRequest(request) {\n      const url = new URL(request.url);\n\nif (\n        url.pathname.endsWith(\"connection-status\") &&\n        request.method === \"GET\"\n      ) {\n        const mcpState = this.getMcpServers();\n\nconst connections = Object.entries(mcpState.servers).map(\n          ([id, server]) => ({\n            serverId: id,\n            name: server.name,\n            state: server.state,\n            isReady: server.state === \"ready\",\n            needsAuth: server.state === \"authenticating\",\n            authUrl: server.auth_url,\n          }),\n        );\n\nreturn Response.json(connections);\n      }\n\nreturn new Response(\"Not found\", { status: 404 });\n    }\n  }\n  ts\n  export class MyAgent extends Agent<Env, never> {\n    async onRequest(request: Request): Promise<Response> {\n      const url = new URL(request.url);\n\nif (\n        url.pathname.endsWith(\"connection-status\") &&\n        request.method === \"GET\"\n      ) {\n        const mcpState = this.getMcpServers();\n\nconst connections = Object.entries(mcpState.servers).map(\n          ([id, server]) => ({\n            serverId: id,\n            name: server.name,\n            state: server.state,\n            isReady: server.state === \"ready\",\n            needsAuth: server.state === \"authenticating\",\n            authUrl: server.auth_url,\n          }),\n        );\n\nreturn Response.json(connections);\n      }\n\nreturn new Response(\"Not found\", { status: 404 });\n    }\n  }\n  js\n  import { useAgent } from \"agents/react\";\n  function App() {\n    const [mcpState, setMcpState] = useState({\n      prompts: [],\n      resources: [],\n      servers: {},\n      tools: [],\n    });\n\nconst agent = useAgent({\n      agent: \"my-agent\",\n      name: \"session-id\",\n      onMcpUpdate: setMcpState,\n    });\n\nconst handleRetry = async (serverId, serverUrl, name) => {\n      // Remove failed connection\n      await fetch(`/agents/my-agent/session-id/disconnect`, {\n        method: \"POST\",\n        body: JSON.stringify({ serverId }),\n      });\n\n// Retry connection\n      const response = await fetch(`/agents/my-agent/session-id/connect`, {\n        method: \"POST\",\n        body: JSON.stringify({ serverUrl, name }),\n      });\n      const { authUrl } = await response.json();\n      if (authUrl) window.open(authUrl, \"_blank\");\n    };\n\nreturn (\n      <div>\n        {Object.entries(mcpState.servers).map(([id, server]) => (\n          <div key={id}>\n            <strong>{server.name}</strong>: {server.state}\n            {server.state === \"failed\" && (\n              <div>\n                <p>Connection failed. Please try again.</p>\n                <button\n                  onClick={() => handleRetry(id, server.server_url, server.name)}\n                >\n                  Retry Connection\n                </button>\n              </div>\n            )}\n          </div>\n        ))}\n      </div>\n    );\n  }\n  ts\n  import { useAgent } from \"agents/react\";\n  import type { MCPServersState } from \"agents\";\n\nfunction App() {\n    const [mcpState, setMcpState] = useState<MCPServersState>({\n      prompts: [],\n      resources: [],\n      servers: {},\n      tools: [],\n    });\n\nconst agent = useAgent({\n      agent: \"my-agent\",\n      name: \"session-id\",\n      onMcpUpdate: setMcpState,\n    });\n\nconst handleRetry = async (serverId: string, serverUrl: string, name: string) => {\n      // Remove failed connection\n      await fetch(`/agents/my-agent/session-id/disconnect`, {\n        method: \"POST\",\n        body: JSON.stringify({ serverId }),\n      });\n\n// Retry connection\n      const response = await fetch(`/agents/my-agent/session-id/connect`, {\n        method: \"POST\",\n        body: JSON.stringify({ serverUrl, name }),\n      });\n      const { authUrl } = await response.json();\n      if (authUrl) window.open(authUrl, \"_blank\");\n    };\n\nreturn (\n      <div>\n        {Object.entries(mcpState.servers).map(([id, server]) => (\n          <div key={id}>\n            <strong>{server.name}</strong>: {server.state}\n\n{server.state === \"failed\" && (\n              <div>\n                <p>Connection failed. Please try again.</p>\n                <button onClick={() => handleRetry(id, server.server_url, server.name)}>\n                  Retry Connection\n                </button>\n              </div>\n            )}\n          </div>\n        ))}\n      </div>\n    );\n  }\n  js\n  import { Agent, routeAgentRequest } from \"agents\";\n  export class MyAgent extends Agent {\n    onStart() {\n      this.mcp.configureOAuthCallback({\n        customHandler: (result) => {\n          if (result.authSuccess) {\n            return new Response(\"<script>window.close();</script>\", {\n              headers: { \"content-type\": \"text/html\" },\n            });\n          } else {\n            return new Response(\n              `<script>alert('Authorization failed: ${result.authError}'); window.close();</script>`,\n              { headers: { \"content-type\": \"text/html\" } },\n            );\n          }\n        },\n      });\n    }\n\nasync onRequest(request) {\n      const url = new URL(request.url);\n\n// Connect to MCP server\n      if (url.pathname.endsWith(\"/connect\") && request.method === \"POST\") {\n        const { id, authUrl } = await this.addMcpServer(\n          \"Cloudflare Observability\",\n          \"https://observability.mcp.cloudflare.com/mcp\",\n        );\n\nif (authUrl) {\n          return Response.json({\n            serverId: id,\n            authUrl: authUrl,\n            message: \"Please authorize access\",\n          });\n        }\n\nreturn Response.json({ serverId: id, status: \"connected\" });\n      }\n\n// Check connection status\n      if (url.pathname.endsWith(\"/status\") && request.method === \"GET\") {\n        const mcpState = this.getMcpServers();\n        const connections = Object.entries(mcpState.servers).map(\n          ([id, server]) => ({\n            serverId: id,\n            name: server.name,\n            state: server.state,\n            authUrl: server.auth_url,\n          }),\n        );\n        return Response.json(connections);\n      }\n\n// Disconnect\n      if (url.pathname.endsWith(\"/disconnect\") && request.method === \"POST\") {\n        const { serverId } = await request.json();\n        await this.removeMcpServer(serverId);\n        return Response.json({ message: \"Disconnected\" });\n      }\n\nreturn new Response(\"Not found\", { status: 404 });\n    }\n  }\n\nexport default {\n    async fetch(request, env) {\n      return (\n        (await routeAgentRequest(request, env, { cors: true })) ||\n        new Response(\"Not found\", { status: 404 })\n      );\n    },\n  };\n  ts\n  import { Agent, type AgentNamespace, routeAgentRequest } from \"agents\";\n  import type { MCPClientOAuthResult } from \"agents/mcp\";\n\ntype Env = {\n    MyAgent: AgentNamespace<MyAgent>;\n  };\n\nexport class MyAgent extends Agent<Env, never> {\n    onStart() {\n      this.mcp.configureOAuthCallback({\n        customHandler: (result: MCPClientOAuthResult) => {\n          if (result.authSuccess) {\n            return new Response(\"<script>window.close();</script>\", {\n              headers: { \"content-type\": \"text/html\" },\n            });\n          } else {\n            return new Response(\n              `<script>alert('Authorization failed: ${result.authError}'); window.close();</script>`,\n              { headers: { \"content-type\": \"text/html\" } },\n            );\n          }\n        },\n      });\n    }\n\nasync onRequest(request: Request): Promise<Response> {\n      const url = new URL(request.url);\n\n// Connect to MCP server\n      if (url.pathname.endsWith(\"/connect\") && request.method === \"POST\") {\n        const { id, authUrl } = await this.addMcpServer(\n          \"Cloudflare Observability\",\n          \"https://observability.mcp.cloudflare.com/mcp\",\n        );\n\nif (authUrl) {\n          return Response.json({\n            serverId: id,\n            authUrl: authUrl,\n            message: \"Please authorize access\",\n          });\n        }\n\nreturn Response.json({ serverId: id, status: \"connected\" });\n      }\n\n// Check connection status\n      if (url.pathname.endsWith(\"/status\") && request.method === \"GET\") {\n        const mcpState = this.getMcpServers();\n        const connections = Object.entries(mcpState.servers).map(\n          ([id, server]) => ({\n            serverId: id,\n            name: server.name,\n            state: server.state,\n            authUrl: server.auth_url,\n          }),\n        );\n        return Response.json(connections);\n      }\n\n// Disconnect\n      if (url.pathname.endsWith(\"/disconnect\") && request.method === \"POST\") {\n        const { serverId } = (await request.json()) as { serverId: string };\n        await this.removeMcpServer(serverId);\n        return Response.json({ message: \"Disconnected\" });\n      }\n\nreturn new Response(\"Not found\", { status: 404 });\n    }\n  }\n\nexport default {\n    async fetch(request: Request, env: Env) {\n      return (\n        (await routeAgentRequest(request, env, { cors: true })) ||\n        new Response(\"Not found\", { status: 404 })\n      );\n    },\n  };\n  sh\n  npm create cloudflare@latest -- my-mcp-server --template=cloudflare/ai/demos/remote-mcp-authless\n  sh\n  yarn create cloudflare my-mcp-server --template=cloudflare/ai/demos/remote-mcp-authless\n  sh\n  pnpm create cloudflare@latest my-mcp-server --template=cloudflare/ai/demos/remote-mcp-authless\n  sh\ncd my-mcp-server\nsh\nnpm start\nsh\nnpx @modelcontextprotocol/inspector@latest\nsh\nopen http://localhost:5173\nsh\nnpx wrangler@latest deploy\njson\n{\n  \"mcpServers\": {\n    \"math\": {\n      \"command\": \"npx\",\n      \"args\": [\n        \"mcp-remote\",\n        \"https://your-worker-name.your-account.workers.dev/sse\"\n      ]\n    }\n  }\n}\nsh\n  npm create cloudflare@latest -- my-mcp-server-github-auth --template=cloudflare/ai/demos/remote-mcp-github-oauth\n  sh\n  yarn create cloudflare my-mcp-server-github-auth --template=cloudflare/ai/demos/remote-mcp-github-oauth\n  sh\n  pnpm create cloudflare@latest my-mcp-server-github-auth --template=cloudflare/ai/demos/remote-mcp-github-oauth\n  sh\ncd my-mcp-server-github-auth\nts\nimport GitHubHandler from \"./github-handler\";\n\nexport default new OAuthProvider({\n  apiRoute: \"/sse\",\n  apiHandler: MyMCP.Router,\n  defaultHandler: GitHubHandler,\n  authorizeEndpoint: \"/authorize\",\n  tokenEndpoint: \"/token\",\n  clientRegistrationEndpoint: \"/register\",\n});\nsh\ntouch .dev.vars\necho 'GITHUB_CLIENT_ID=\"your-client-id\"' >> .dev.vars\necho 'GITHUB_CLIENT_SECRET=\"your-client-secret\"' >> .dev.vars\ncat .dev.vars\nsh\nnpm start\nsh\nnpx @modelcontextprotocol/inspector@latest\nsh\nopen http://localhost:5173\nsh\nwrangler secret put GITHUB_CLIENT_ID\nsh\nwrangler secret put GITHUB_CLIENT_SECRET\nplaintext\nnpx wrangler secret put COOKIE_ENCRYPTION_KEY # add any random string here e.g. openssl rand -hex 32\nbash\nnpx wrangler kv namespace create \"OAUTH_KV\"\njson\n{\n  \"kvNamespaces\": [\n    {\n      \"binding\": \"OAUTH_KV\",\n      \"id\": \"<YOUR_KV_NAMESPACE_ID>\"\n    }\n  ]\n}\nbash\nnpm run deploy\nsh\n  npm create cloudflare@latest -- my-slack-agent\n  sh\n  yarn create cloudflare my-slack-agent\n  sh\n  pnpm create cloudflare@latest my-slack-agent\n  sh\ncd my-slack-agent\nsh\nnpm install agents openai\nsh\ntouch .dev.vars\nsh\nSLACK_CLIENT_ID=\"your-slack-client-id\"\nSLACK_CLIENT_SECRET=\"your-slack-client-secret\"\nSLACK_SIGNING_SECRET=\"your-slack-signing-secret\"\nOPENAI_API_KEY=\"your-openai-api-key\"\nOPENAI_BASE_URL=\"https://gateway.ai.cloudflare.com/v1/YOUR_ACCOUNT_ID/YOUR_GATEWAY/openai\"\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"my-slack-agent\",\n    \"main\": \"src/index.ts\",\n    \"compatibility_date\": \"2024-01-01\",\n    \"durable_objects\": {\n      \"bindings\": [\n        {\n          \"name\": \"MyAgent\",\n          \"class_name\": \"MyAgent\",\n          \"script_name\": \"my-slack-agent\"\n        }\n      ]\n    },\n    \"migrations\": [\n      {\n        \"tag\": \"v1\",\n        \"new_classes\": [\n          \"MyAgent\"\n        ]\n      }\n    ]\n  }\n  toml\n  name = \"my-slack-agent\"\n  main = \"src/index.ts\"\n  compatibility_date = \"2024-01-01\"\n\n[[durable_objects.bindings]]\n  name = \"MyAgent\"\n  class_name = \"MyAgent\"\n  script_name = \"my-slack-agent\"\n\n[[migrations]]\n  tag = \"v1\"\n  new_classes = [\"MyAgent\"]\n  ts\nimport { env } from \"cloudflare:workers\";\nimport { SlackAgent } from \"./slack\";\nimport { OpenAI } from \"openai\";\n\nconst openai = new OpenAI({\n  apiKey: env.OPENAI_API_KEY,\n  baseURL: env.OPENAI_BASE_URL\n});\n\ntype SlackMsg = {\n  user?: string;\n  text?: string;\n  ts: string;\n  thread_ts?: string;\n  subtype?: string;\n  bot_id?: string;\n};\n\nfunction normalizeForLLM(msgs: SlackMsg[], selfUserId: string) {\n  return msgs.map((m) => {\n    const role = m.user && m.user !== selfUserId ? \"user\" : \"assistant\";\n    const text = (m.text ?? \"\").replace(/<@([A-Z0-9]+)>/g, \"@$1\");\n    return { role, content: text };\n  });\n}\n\nexport class MyAgent extends SlackAgent {\n  async generateAIReply(conversation: SlackMsg[]) {\n    const selfId = await this.ensureAppUserId();\n    const messages = normalizeForLLM(conversation, selfId);\n\nconst system = `You are a helpful AI assistant in Slack.\nBe brief, specific, and actionable. If you're unsure, ask a single clarifying question.`;\n\nconst input = [{ role: \"system\", content: system }, ...messages];\n\nconst response = await openai.chat.completions.create({\n      model: \"gpt-4o-mini\",\n      messages: input\n    });\n\nconst msg = response.choices[0].message.content;\n    if (!msg) throw new Error(\"No message from AI\");\n\nasync onSlackEvent(event: { type: string } & Record<string, unknown>) {\n    // Ignore bot messages and subtypes (edits, joins, etc.)\n    if (event.bot_id || event.subtype) return;\n\n// Handle direct messages\n    if (event.type === \"message\") {\n      const e = event as unknown as SlackMsg & { channel: string };\n      const isDM = (e.channel || \"\").startsWith(\"D\");\n      const mentioned = (e.text || \"\").includes(\n        `<@${await this.ensureAppUserId()}>`\n      );\n\nif (!isDM && !mentioned) return;\n\nconst conversation = await this.fetchConversation(e.channel);\n      const content = await this.generateAIReply(conversation);\n      await this.sendMessage(content, { channel: e.channel });\n      return;\n    }\n\n// Handle @mentions in channels\n    if (event.type === \"app_mention\") {\n      const e = event as unknown as SlackMsg & {\n        channel: string;\n        text?: string;\n      };\n      const thread = await this.fetchThread(e.channel, e.thread_ts || e.ts);\n      const content = await this.generateAIReply(thread);\n      await this.sendMessage(content, {\n        channel: e.channel,\n        thread_ts: e.thread_ts || e.ts\n      });\n      return;\n    }\n  }\n}\n\nexport default MyAgent.listen({\n  clientId: env.SLACK_CLIENT_ID,\n  clientSecret: env.SLACK_CLIENT_SECRET,\n  slackSigningSecret: env.SLACK_SIGNING_SECRET,\n  scopes: [\n    \"chat:write\",\n    \"chat:write.public\",\n    \"channels:history\",\n    \"app_mentions:read\",\n    \"im:write\",\n    \"im:history\"\n  ]\n});\nsh\nnpm run dev\nsh\nnpx cloudflared tunnel --url http://localhost:8787\nsh\nnpx wrangler secret put SLACK_CLIENT_ID\nnpx wrangler secret put SLACK_CLIENT_SECRET\nnpx wrangler secret put SLACK_SIGNING_SECRET\nnpx wrangler secret put OPENAI_API_KEY\nnpx wrangler secret put OPENAI_BASE_URL\nsh\nnpx wrangler deploy\nplaintext\nhttps://my-slack-agent.your-account.workers.dev\nts\nconst response = await openai.chat.completions.create({\n  model: \"gpt-4o\", // or any other model\n  messages: input,\n});\nts\nasync storeMessage(channel: string, message: SlackMsg) {\n  const history = await this.ctx.storage.kv.get(`history:${channel}`) || [];\n  history.push(message);\n  await this.ctx.storage.kv.put(`history:${channel}`, history);\n}\nts\nasync onSlackEvent(event: { type: string } & Record<string, unknown>) {\n  if (event.type === \"message\") {\n    const e = event as unknown as SlackMsg & { channel: string };\n\nif (e.text?.includes(\"help\")) {\n      await this.sendMessage(\"Here's how I can help...\", {\n        channel: e.channel\n      });\n      return;\n    }\n  }\n\n// ... rest of your event handling\n}\nts\nimport { Ai } from \"@cloudflare/ai\";\n\nexport class MyAgent extends SlackAgent {\n  async generateAIReply(conversation: SlackMsg[]) {\n    const ai = new Ai(this.ctx.env.AI);\n    const response = await ai.run(\"@cf/meta/llama-3-8b-instruct\", {\n      messages: normalizeForLLM(conversation, await this.ensureAppUserId()),\n    });\n    return response.response;\n  }\n}\nbash\nnpx @modelcontextprotocol/inspector\njson\n{\n  \"mcpServers\": {\n    \"my-server\": {\n      \"command\": \"npx\",\n      \"args\": [\"mcp-remote\", \"http://my-mcp-server.my-account.workers.dev/mcp\"]\n    }\n  }\n}\njson\n{\n  \"mcpServers\": {\n    \"my-server\": {\n      \"url\": \"http://my-mcp-server.my-account.workers.dev/mcp\"\n    }\n  }\n}\njson\n{\n  \"mcpServers\": {\n    \"my-server\": {\n      \"serverUrl\": \"http://my-mcp-server.my-account.workers.dev/mcp\"\n    }\n  }\n}\nts\nexport default new OAuthProvider({\n  apiRoute: \"/mcp\",\n  // Your MCP server:\n  apiHandler: MyMCPServer.Router,\n  // Your handler for authentication and authorization:\n  defaultHandler: MyAuthHandler,\n  authorizeEndpoint: \"/authorize\",\n  tokenEndpoint: \"/token\",\n  clientRegistrationEndpoint: \"/register\",\n});\nmermaid\nsequenceDiagram\n    participant B as User-Agent (Browser)\n    participant C as MCP Client\n    participant M as MCP Server (your Worker)\n\nC->>M: MCP Request\n    M->>C: HTTP 401 Unauthorized\n    Note over C: Generate code_verifier and code_challenge\n    C->>B: Open browser with authorization URL + code_challenge\n    B->>M: GET /authorize\n    Note over M: User logs in and authorizes\n    M->>B: Redirect to callback URL with auth code\n    B->>C: Callback with authorization code\n    C->>M: Token Request with code + code_verifier\n    M->>C: Access Token (+ Refresh Token)\n    C->>M: MCP Request with Access Token\n    Note over C,M: Begin standard MCP message exchange\nts\nimport MyAuthHandler from \"./auth-handler\";\n\nexport default new OAuthProvider({\n  apiRoute: \"/mcp\",\n  // Your MCP server:\n  apiHandler: MyMCPServer.Router,\n  // Replace this handler with your own handler for authentication and authorization with the third-party provider:\n  \n  authorizeEndpoint: \"/authorize\",\n  tokenEndpoint: \"/token\",\n  clientRegistrationEndpoint: \"/register\",\n});\nmermaid\nsequenceDiagram\n    participant B as User-Agent (Browser)\n    participant C as MCP Client\n    participant M as MCP Server (your Worker)\n    participant T as Third-Party Auth Server\n\nC->>M: Initial OAuth Request\n    M->>B: Redirect to Third-Party /authorize\n    B->>T: Authorization Request\n    Note over T: User authorizes\n    T->>B: Redirect to MCP Server callback\n    B->>M: Authorization code\n    M->>T: Exchange code for token\n    T->>M: Third-party access token\n    Note over M: Generate bound MCP token\n    M->>B: Redirect to MCP Client callback\n    B->>C: MCP authorization code\n    C->>M: Exchange code for token\n    M->>C: MCP access token\njs\nexport class MyMCP extends McpAgent<Env, unknown, AuthContext> {\n  async init() {\n    this.server.tool(\"userInfo\", \"Get user information\", {}, async () => ({\n      content: [{ type: \"text\", text: `Hello, ${this.props.claims.name || \"user\"}!` }],\n    }));\n  }\n}\njs\n// Create a wrapper function to check permissions\nfunction requirePermission(permission, handler) {\n  return async (request, context) => {\n    // Check if user has the required permission\n    const userPermissions = context.props.permissions || [];\n    if (!userPermissions.includes(permission)) {\n      return {\n        content: [{ type: \"text\", text: `Permission denied: requires ${permission}` }],\n        status: 403\n      };\n    }\n\n// If permission check passes, execute the handler\n    return handler(request, context);\n  };\n}\n\n// Use the wrapper with your MCP tools\nasync init() {\n  // Basic tools available to all authenticated users\n  this.server.tool(\"basicTool\", \"Available to all users\", {}, async () => {\n    // Implementation for all users\n  });\n\n// Protected tool using the permission wrapper\n  this.server.tool(\n    \"adminAction\",\n    \"Administrative action requiring special permission\",\n    { /* parameters */ },\n    requirePermission(\"admin\", async (req) => {\n      // Only executes if user has \"admin\" permission\n      return {\n        content: [{ type: \"text\", text: \"Admin action completed\" }]\n      };\n    })\n  );\n\n// Conditionally register tools based on user permissions\n  if (this.props.permissions?.includes(\"special_feature\")) {\n    this.server.tool(\"specialTool\", \"Special feature\", {}, async () => {\n      // This tool only appears for users with the special_feature permission\n    });\n  }\n}\njs\n  import { McpAgent } from \"agents/mcp\";\n  import { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\";\n  import { z } from \"zod\";\n\nexport class MyMCP extends McpAgent {\n    server = new McpServer({ name: \"Demo\", version: \"1.0.0\" });\n\nasync init() {\n      this.server.tool(\n        \"add\",\n        { a: z.number(), b: z.number() },\n        async ({ a, b }) => ({\n          content: [{ type: \"text\", text: String(a + b) }],\n        }),\n      );\n    }\n  }\n  ts\n  import { McpAgent } from \"agents/mcp\";\n  import { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\";\n  import { z } from \"zod\";\n\nexport class MyMCP extends McpAgent {\n    server = new McpServer({ name: \"Demo\", version: \"1.0.0\" });\n\nasync init() {\n      this.server.tool(\n        \"add\",\n        { a: z.number(), b: z.number() },\n        async ({ a, b }) => ({\n          content: [{ type: \"text\", text: String(a + b) }],\n        }),\n      );\n    }\n  }\n  js\n  import { McpAgent } from \"agents/mcp\";\n  import { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\";\n  import { z } from \"zod\";\n\nexport class MyMCP extends McpAgent {\n    server = new McpServer({\n      name: \"Demo\",\n      version: \"1.0.0\",\n    });\n\ninitialState = {\n      counter: 1,\n    };\n\nasync init() {\n      this.server.resource(`counter`, `mcp://resource/counter`, (uri) => {\n        return {\n          contents: [{ uri: uri.href, text: String(this.state.counter) }],\n        };\n      });\n\nthis.server.tool(\n        \"add\",\n        \"Add to the counter, stored in the MCP\",\n        { a: z.number() },\n        async ({ a }) => {\n          this.setState({ ...this.state, counter: this.state.counter + a });\n\nreturn {\n            content: [\n              {\n                type: \"text\",\n                text: String(`Added ${a}, total is now ${this.state.counter}`),\n              },\n            ],\n          };\n        },\n      );\n    }\n\nonStateUpdate(state) {\n      console.log({ stateUpdate: state });\n    }\n  }\n  ts\n  import { McpAgent } from \"agents/mcp\";\n  import { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\";\n  import { z } from \"zod\";\n\ntype State = { counter: number };\n\nexport class MyMCP extends McpAgent<Env, State, {}> {\n    server = new McpServer({\n      name: \"Demo\",\n      version: \"1.0.0\",\n    });\n\ninitialState: State = {\n      counter: 1,\n    };\n\nasync init() {\n      this.server.resource(`counter`, `mcp://resource/counter`, (uri) => {\n        return {\n          contents: [{ uri: uri.href, text: String(this.state.counter) }],\n        };\n      });\n\nthis.server.tool(\n        \"add\",\n        \"Add to the counter, stored in the MCP\",\n        { a: z.number() },\n        async ({ a }) => {\n          this.setState({ ...this.state, counter: this.state.counter + a });\n\nreturn {\n            content: [\n              {\n                type: \"text\",\n                text: String(`Added ${a}, total is now ${this.state.counter}`),\n              },\n            ],\n          };\n        },\n      );\n    }\n\nonStateUpdate(state: State) {\n      console.log({ stateUpdate: state });\n    }\n  }\n  js\n  import { Agent } from \"agents\";\n\nexport class MyAgent extends Agent {\n    async onRequest(request) {\n      const url = new URL(request.url);\n\nif (url.pathname === \"/connect\" && request.method === \"POST\") {\n        const result = await this.addMcpServer(\n          \"Weather API\",\n          \"https://weather-mcp.example.com/mcp\",\n        );\n\nif (result.state === \"authenticating\") {\n          return new Response(JSON.stringify({ authUrl: result.authUrl }), {\n            headers: { \"Content-Type\": \"application/json\" },\n          });\n        }\n\nreturn new Response(`Connected: ${result.id}`, { status: 200 });\n      }\n    }\n  }\n  ts\n  import { Agent, type AgentNamespace } from \"agents\";\n\ntype Env = {\n    MyAgent: AgentNamespace<MyAgent>;\n  };\n\nexport class MyAgent extends Agent<Env, never> {\n    async onRequest(request: Request): Promise<Response> {\n      const url = new URL(request.url);\n\nif (url.pathname === \"/connect\" && request.method === \"POST\") {\n        const result = await this.addMcpServer(\n          \"Weather API\",\n          \"https://weather-mcp.example.com/mcp\",\n        );\n\nif (result.state === \"authenticating\") {\n          return new Response(JSON.stringify({ authUrl: result.authUrl }), {\n            headers: { \"Content-Type\": \"application/json\" },\n          });\n        }\n\nreturn new Response(`Connected: ${result.id}`, { status: 200 });\n      }\n    }\n  }\n  ts\nasync addMcpServer(\n  serverName: string,\n  url: string,\n  callbackHost?: string,\n  agentsPrefix?: string,\n  options?: {\n    client?: ConstructorParameters<typeof Client>[1];\n    transport?: {\n      headers?: HeadersInit;\n      type?: \"sse\" | \"streamable-http\" | \"auto\";\n    };\n  }\n): Promise<\n  | { id: string; state: \"authenticating\"; authUrl: string }\n  | { id: string; state: \"ready\"; authUrl?: undefined }\n>\njs\n  export class MyAgent extends Agent {\n    async onRequest(request) {\n      const result = await this.addMcpServer(\n        \"Weather API\",\n        \"https://weather-mcp.example.com/mcp\",\n      );\n\nif (result.state === \"authenticating\") {\n        // User needs to complete OAuth flow\n        return new Response(\n          JSON.stringify({ serverId: result.id, authUrl: result.authUrl }),\n          {\n            headers: { \"Content-Type\": \"application/json\" },\n          },\n        );\n      }\n\nreturn new Response(`Connected: ${result.id}`, { status: 200 });\n    }\n  }\n  ts\n  export class MyAgent extends Agent<Env, never> {\n    async onRequest(request: Request): Promise<Response> {\n      const result = await this.addMcpServer(\n        \"Weather API\",\n        \"https://weather-mcp.example.com/mcp\",\n      );\n\nif (result.state === \"authenticating\") {\n        // User needs to complete OAuth flow\n        return new Response(JSON.stringify({ serverId: result.id, authUrl: result.authUrl }), {\n          headers: { \"Content-Type\": \"application/json\" },\n        });\n      }\n\nreturn new Response(`Connected: ${result.id}`, { status: 200 });\n    }\n  }\n  ts\nasync removeMcpServer(id: string): Promise<void>\njs\n  export class MyAgent extends Agent {\n    async onRequest(request) {\n      const url = new URL(request.url);\n\nif (url.pathname === \"/disconnect\" && request.method === \"POST\") {\n        const { serverId } = await request.json();\n        await this.removeMcpServer(serverId);\n\nreturn new Response(\"Disconnected\", { status: 200 });\n      }\n    }\n  }\n  ts\n  export class MyAgent extends Agent<Env, never> {\n    async onRequest(request: Request): Promise<Response> {\n      const url = new URL(request.url);\n\nif (url.pathname === \"/disconnect\" && request.method === \"POST\") {\n        const { serverId } = await request.json();\n        await this.removeMcpServer(serverId);\n\nreturn new Response(\"Disconnected\", { status: 200 });\n      }\n    }\n  }\n  ts\ngetMcpServers(): MCPServersState\nts\n{\n  servers: Record<\n    string,\n    {\n      name: string;\n      server_url: string;\n      auth_url: string | null;\n      state:\n        | \"authenticating\"\n        | \"connecting\"\n        | \"connected\"\n        | \"discovering\"\n        | \"ready\"\n        | \"failed\";\n      capabilities: ServerCapabilities | null;\n      instructions: string | null;\n    }\n  >;\n  tools: Array<Tool & { serverId: string }>;\n  prompts: Array<Prompt & { serverId: string }>;\n  resources: Array<Resource & { serverId: string }>;\n  resourceTemplates: Array<ResourceTemplate & { serverId: string }>;\n}\njs\n  export class MyAgent extends Agent {\n    async onRequest(request) {\n      const url = new URL(request.url);\n\nif (url.pathname === \"/mcp-state\") {\n        const mcpState = this.getMcpServers();\n\nreturn new Response(JSON.stringify(mcpState, null, 2), {\n          headers: { \"Content-Type\": \"application/json\" },\n        });\n      }\n    }\n  }\n  ts\n  export class MyAgent extends Agent<Env, never> {\n    async onRequest(request: Request): Promise<Response> {\n      const url = new URL(request.url);\n\nif (url.pathname === \"/mcp-state\") {\n        const mcpState = this.getMcpServers();\n\nreturn new Response(JSON.stringify(mcpState, null, 2), {\n          headers: { \"Content-Type\": \"application/json\" },\n        });\n      }\n    }\n  }\n  ts\nasync registerServer(\n  id: string,\n  options: {\n    url: string;\n    name: string;\n    callbackUrl: string;\n    clientOptions?: ClientOptions;\n    transportOptions?: TransportOptions;\n  }\n): Promise<string>\nts\nasync connectToServer(id: string): Promise<MCPConnectionResult>\nts\ntype MCPConnectionResult =\n  | { state: \"failed\"; error: string }\n  | { state: \"authenticating\"; authUrl: string }\n  | { state: \"connected\" }\nts\nasync discoverIfConnected(\n  serverId: string,\n  options?: { timeoutMs?: number }\n): Promise<MCPDiscoverResult | undefined>\nts\ntype MCPDiscoverResult = {\n  success: boolean;\n  state: MCPConnectionState;\n  error?: string;\n}\nts\nasync closeConnection(id: string): Promise<void>\nts\nasync closeAllConnections(): Promise<void>\nts\ngetAITools(): ToolSet\njs\n  import { generateText } from \"ai\";\n\nexport class MyAgent extends Agent {\n    async onRequest(request) {\n      // Get all MCP tools as AI SDK compatible tools\n      const tools = this.mcp.getAITools();\n\nconst result = await generateText({\n        model: openai(\"gpt-4\"),\n        prompt: \"What's the weather in San Francisco?\",\n        tools,\n      });\n\nreturn new Response(result.text);\n    }\n  }\n  ts\n  import { generateText } from \"ai\";\n\nexport class MyAgent extends Agent<Env, never> {\n    async onRequest(request: Request): Promise<Response> {\n      // Get all MCP tools as AI SDK compatible tools\n      const tools = this.mcp.getAITools();\n\nconst result = await generateText({\n        model: openai(\"gpt-4\"),\n        prompt: \"What's the weather in San Francisco?\",\n        tools,\n      });\n\nreturn new Response(result.text);\n    }\n  }\n  js\n  export class MyAgent extends Agent {\n    onStart() {\n      this.mcp.configureOAuthCallback({\n        successRedirect: \"/connected\",\n        errorRedirect: \"/auth-failed\",\n      });\n    }\n  }\n  ts\n  export class MyAgent extends Agent<Env, never> {\n    onStart() {\n      this.mcp.configureOAuthCallback({\n        successRedirect: \"/connected\",\n        errorRedirect: \"/auth-failed\",\n      });\n    }\n  }\n  js\n  import { isUnauthorized, isTransportNotImplemented } from \"agents/mcp\";\n\nexport class MyAgent extends Agent {\n    async onRequest(request) {\n      try {\n        await this.addMcpServer(\"Server\", \"https://mcp.example.com/mcp\");\n      } catch (error) {\n        if (isUnauthorized(error)) {\n          return new Response(\"Authentication required\", { status: 401 });\n        } else if (isTransportNotImplemented(error)) {\n          return new Response(\"Transport not supported\", { status: 400 });\n        }\n        throw error;\n      }\n    }\n  }\n  ts\n  import { isUnauthorized, isTransportNotImplemented } from \"agents/mcp\";\n\nexport class MyAgent extends Agent<Env, never> {\n    async onRequest(request: Request): Promise<Response> {\n      try {\n        await this.addMcpServer(\"Server\", \"https://mcp.example.com/mcp\");\n      } catch (error) {\n        if (isUnauthorized(error)) {\n          return new Response(\"Authentication required\", { status: 401 });\n        } else if (isTransportNotImplemented(error)) {\n          return new Response(\"Transport not supported\", { status: 400 });\n        }\n        throw error;\n      }\n    }\n  }\n  ts\nimport { createMcpHandler, type CreateMcpHandlerOptions } from \"agents/mcp\";\nimport { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\";\n\nfunction createMcpHandler(\n  server: McpServer,\n  options?: CreateMcpHandlerOptions,\n): (request: Request, env: Env, ctx: ExecutionContext) => Promise<Response>;\nts\ninterface CreateMcpHandlerOptions extends WorkerTransportOptions {\n  /**\n   * The route path that this MCP handler should respond to.\n   * If specified, the handler will only process requests that match this route.\n   * @default \"/mcp\"\n   */\n  route?: string;\n\n/**\n   * An optional auth context to use for handling MCP requests.\n   * If not provided, the handler will look for props in the execution context.\n   */\n  authContext?: McpAuthContext;\n\n/**\n   * An optional transport to use for handling MCP requests.\n   * If not provided, a WorkerTransport will be created with the provided WorkerTransportOptions.\n   */\n  transport?: WorkerTransport;\n\n// Inherited from WorkerTransportOptions:\n  sessionIdGenerator?: () => string;\n  enableJsonResponse?: boolean;\n  onsessioninitialized?: (sessionId: string) => void;\n  corsOptions?: CORSOptions;\n  storage?: MCPStorageApi;\n}\njs\n  const handler = createMcpHandler(server, {\n    route: \"/api/mcp\", // Only respond to requests at /api/mcp\n  });\n  ts\n  const handler = createMcpHandler(server, {\n    route: \"/api/mcp\", // Only respond to requests at /api/mcp\n  });\n  js\n  import { createMcpHandler, WorkerTransport } from \"agents/mcp\";\n\nconst transport = new WorkerTransport({\n    sessionIdGenerator: () => `session-${crypto.randomUUID()}`,\n    storage: {\n      get: () => myStorage.get(\"transport-state\"),\n      set: (state) => myStorage.put(\"transport-state\", state),\n    },\n  });\n\nconst handler = createMcpHandler(server, { transport });\n  ts\n  import { createMcpHandler, WorkerTransport } from \"agents/mcp\";\n\nconst transport = new WorkerTransport({\n    sessionIdGenerator: () => `session-${crypto.randomUUID()}`,\n    storage: {\n      get: () => myStorage.get(\"transport-state\"),\n      set: (state) => myStorage.put(\"transport-state\", state),\n    },\n  });\n\nconst handler = createMcpHandler(server, { transport });\n  js\n  import { createMcpHandler } from \"agents/mcp\";\n  import { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\";\n  import { z } from \"zod\";\n\nconst server = new McpServer({\n    name: \"Hello MCP Server\",\n    version: \"1.0.0\",\n  });\n\nserver.tool(\n    \"hello\",\n    \"Returns a greeting message\",\n    { name: z.string().optional() },\n    async ({ name }) => {\n      return {\n        content: [\n          {\n            text: `Hello, ${name ?? \"World\"}!`,\n            type: \"text\",\n          },\n        ],\n      };\n    },\n  );\n\nexport default {\n    fetch: async (request, env, ctx) => {\n      const handler = createMcpHandler(server);\n      return handler(request, env, ctx);\n    },\n  };\n  ts\n  import { createMcpHandler } from \"agents/mcp\";\n  import { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\";\n  import { z } from \"zod\";\n\nconst server = new McpServer({\n    name: \"Hello MCP Server\",\n    version: \"1.0.0\",\n  });\n\nserver.tool(\n    \"hello\",\n    \"Returns a greeting message\",\n    { name: z.string().optional() },\n    async ({ name }) => {\n      return {\n        content: [\n          {\n            text: `Hello, ${name ?? \"World\"}!`,\n            type: \"text\",\n          },\n        ],\n      };\n    },\n  );\n\nexport default {\n    fetch: async (request: Request, env: Env, ctx: ExecutionContext) => {\n      const handler = createMcpHandler(server);\n      return handler(request, env, ctx);\n    },\n  };\n  js\n  import { Agent } from \"agents\";\n  import { createMcpHandler, WorkerTransport } from \"agents/mcp\";\n  import { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\";\n\nconst STATE_KEY = \"mcp-transport-state\";\n\nexport class MyStatefulMcpAgent extends Agent {\n    server = new McpServer({\n      name: \"Stateful MCP Server\",\n      version: \"1.0.0\",\n    });\n\ntransport = new WorkerTransport({\n      sessionIdGenerator: () => this.name,\n      storage: {\n        get: () => {\n          return this.ctx.storage.kv.get(STATE_KEY);\n        },\n        set: (state) => {\n          this.ctx.storage.kv.put(STATE_KEY, state);\n        },\n      },\n    });\n\nasync onMcpRequest(request) {\n      return createMcpHandler(this.server, {\n        transport: this.transport,\n      })(request, this.env, {});\n    }\n  }\n  ts\n  import { Agent } from \"agents\";\n  import {\n    createMcpHandler,\n    WorkerTransport,\n    type TransportState,\n  } from \"agents/mcp\";\n  import { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\";\n\nconst STATE_KEY = \"mcp-transport-state\";\n\nexport class MyStatefulMcpAgent extends Agent<Env, State> {\n    server = new McpServer({\n      name: \"Stateful MCP Server\",\n      version: \"1.0.0\",\n    });\n\ntransport = new WorkerTransport({\n      sessionIdGenerator: () => this.name,\n      storage: {\n        get: () => {\n          return this.ctx.storage.kv.get<TransportState>(STATE_KEY);\n        },\n        set: (state: TransportState) => {\n          this.ctx.storage.kv.put<TransportState>(STATE_KEY, state);\n        },\n      },\n    });\n\nasync onMcpRequest(request: Request) {\n      return createMcpHandler(this.server, {\n        transport: this.transport,\n      })(request, this.env, {} as ExecutionContext);\n    }\n  }\n  js\n  import { getAgentByName } from \"agents\";\n\nexport default {\n    async fetch(request, env, ctx) {\n      // Extract session ID from header or generate a new one\n      const sessionId =\n        request.headers.get(\"mcp-session-id\") ?? crypto.randomUUID();\n\n// Get the Agent instance by name/session ID\n      const agent = await getAgentByName(env.MyStatefulMcpAgent, sessionId);\n\n// Route the MCP request to the agent\n      return await agent.onMcpRequest(request);\n    },\n  };\n  ts\n  import { getAgentByName } from \"agents\";\n\nexport default {\n    async fetch(request: Request, env: Env, ctx: ExecutionContext) {\n      // Extract session ID from header or generate a new one\n      const sessionId =\n        request.headers.get(\"mcp-session-id\") ?? crypto.randomUUID();\n\n// Get the Agent instance by name/session ID\n      const agent = await getAgentByName(env.MyStatefulMcpAgent, sessionId);\n\n// Route the MCP request to the agent\n      return await agent.onMcpRequest(request);\n    },\n  };\n  ts\nclass WorkerTransport implements Transport {\n  sessionId?: string;\n  started: boolean;\n  onclose?: () => void;\n  onerror?: (error: Error) => void;\n  onmessage?: (message: JSONRPCMessage, extra?: MessageExtraInfo) => void;\n\nconstructor(options?: WorkerTransportOptions);\n\nasync handleRequest(\n    request: Request,\n    parsedBody?: unknown,\n  ): Promise<Response>;\n  async send(\n    message: JSONRPCMessage,\n    options?: TransportSendOptions,\n  ): Promise<void>;\n  async start(): Promise<void>;\n  async close(): Promise<void>;\n}\nts\ninterface WorkerTransportOptions {\n  /**\n   * Function that generates a unique session ID.\n   * Called when a new session is initialized.\n   */\n  sessionIdGenerator?: () => string;\n\n/**\n   * Enable traditional Request/Response mode, disabling streaming.\n   * When true, responses are returned as JSON instead of SSE streams.\n   * @default false\n   */\n  enableJsonResponse?: boolean;\n\n/**\n   * Callback invoked when a session is initialized.\n   * Receives the generated or restored session ID.\n   */\n  onsessioninitialized?: (sessionId: string) => void;\n\n/**\n   * CORS configuration for cross-origin requests.\n   * Configures Access-Control-* headers.\n   */\n  corsOptions?: CORSOptions;\n\n/**\n   * Optional storage API for persisting transport state.\n   * Use this to store session state in Durable Object/Agent storage\n   * so it survives hibernation/restart.\n   */\n  storage?: MCPStorageApi;\n}\njs\n  const transport = new WorkerTransport({\n    sessionIdGenerator: () => `user-${Date.now()}-${Math.random()}`,\n  });\n  ts\n  const transport = new WorkerTransport({\n    sessionIdGenerator: () => `user-${Date.now()}-${Math.random()}`,\n  });\n  js\n  const transport = new WorkerTransport({\n    enableJsonResponse: true, // Disable streaming, return JSON responses\n  });\n  ts\n  const transport = new WorkerTransport({\n    enableJsonResponse: true, // Disable streaming, return JSON responses\n  });\n  js\n  const transport = new WorkerTransport({\n    onsessioninitialized: (sessionId) => {\n      console.log(`MCP session initialized: ${sessionId}`);\n    },\n  });\n  ts\n  const transport = new WorkerTransport({\n    onsessioninitialized: (sessionId) => {\n      console.log(`MCP session initialized: ${sessionId}`);\n    },\n  });\n  ts\ninterface CORSOptions {\n  origin?: string;\n  methods?: string;\n  headers?: string;\n  maxAge?: number;\n  exposeHeaders?: string;\n}\njs\n  const transport = new WorkerTransport({\n    corsOptions: {\n      origin: \"https://example.com\",\n      methods: \"GET, POST, OPTIONS\",\n      headers: \"Content-Type, Authorization\",\n      maxAge: 86400,\n    },\n  });\n  ts\n  const transport = new WorkerTransport({\n    corsOptions: {\n      origin: \"https://example.com\",\n      methods: \"GET, POST, OPTIONS\",\n      headers: \"Content-Type, Authorization\",\n      maxAge: 86400,\n    },\n  });\n  ts\ninterface MCPStorageApi {\n  get(): Promise<TransportState | undefined> | TransportState | undefined;\n  set(state: TransportState): Promise<void> | void;\n}\n\ninterface TransportState {\n  sessionId?: string;\n  initialized: boolean;\n  protocolVersion?: ProtocolVersion;\n}\njs\n  const transport = new WorkerTransport({\n    storage: {\n      get: async () => {\n        // Retrieve state from Durable Object storage\n        return await this.ctx.storage.get(\"mcp-state\");\n      },\n      set: async (state) => {\n        // Persist state to Durable Object storage\n        await this.ctx.storage.put(\"mcp-state\", state);\n      },\n    },\n  });\n  ts\n  const transport = new WorkerTransport({\n    storage: {\n      get: async () => {\n        // Retrieve state from Durable Object storage\n        return await this.ctx.storage.get<TransportState>(\"mcp-state\");\n      },\n      set: async (state) => {\n        // Persist state to Durable Object storage\n        await this.ctx.storage.put(\"mcp-state\", state);\n      },\n    },\n  });\n  ts\ninterface McpAuthContext {\n  props: Record<string, unknown>;\n}\nts\nimport { getMcpAuthContext } from \"agents/mcp\";\n\nfunction getMcpAuthContext(): McpAuthContext | undefined;\njs\n  import { getMcpAuthContext } from \"agents/mcp\";\n  import { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\";\n\nconst server = new McpServer({ name: \"Auth Server\", version: \"1.0.0\" });\n\nserver.tool(\"getProfile\", \"Get the current user's profile\", {}, async () => {\n    // Access user info automatically populated by OAuth provider\n    const auth = getMcpAuthContext();\n    const username = auth?.props?.username;\n    const email = auth?.props?.email;\n\nreturn {\n      content: [\n        {\n          type: \"text\",\n          text: `User: ${username ?? \"anonymous\"}, Email: ${email ?? \"none\"}`,\n        },\n      ],\n    };\n  });\n  ts\n  import { getMcpAuthContext } from \"agents/mcp\";\n  import { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\";\n\nconst server = new McpServer({ name: \"Auth Server\", version: \"1.0.0\" });\n\nserver.tool(\"getProfile\", \"Get the current user's profile\", {}, async () => {\n    // Access user info automatically populated by OAuth provider\n    const auth = getMcpAuthContext();\n    const username = auth?.props?.username as string | undefined;\n    const email = auth?.props?.email as string | undefined;\n\nreturn {\n      content: [\n        {\n          type: \"text\",\n          text: `User: ${username ?? \"anonymous\"}, Email: ${email ?? \"none\"}`,\n        },\n      ],\n    };\n  });\n  js\n  server.tool(\"riskyOperation\", \"An operation that might fail\", {}, async () => {\n    if (Math.random() > 0.5) {\n      throw new Error(\"Random failure occurred\");\n    }\n    return {\n      content: [{ type: \"text\", text: \"Success!\" }],\n    };\n  });\n\n// Errors are automatically caught and returned as:\n  // {\n  //   \"jsonrpc\": \"2.0\",\n  //   \"error\": {\n  //     \"code\": -32603,\n  //     \"message\": \"Random failure occurred\"\n  //   },\n  //   \"id\": <request_id>\n  // }\n  ts\n  server.tool(\"riskyOperation\", \"An operation that might fail\", {}, async () => {\n    if (Math.random() > 0.5) {\n      throw new Error(\"Random failure occurred\");\n    }\n    return {\n      content: [{ type: \"text\", text: \"Success!\" }],\n    };\n  });\n\n// Errors are automatically caught and returned as:\n  // {\n  //   \"jsonrpc\": \"2.0\",\n  //   \"error\": {\n  //     \"code\": -32603,\n  //     \"message\": \"Random failure occurred\"\n  //   },\n  //   \"id\": <request_id>\n  // }\n  js\n  import { McpServer } from \"@modelcontextprotocol/sdk/server/mcp\";\n  import { McpAgent } from \"agents/mcp\";\n  import { z } from \"zod\";\n\nexport class MyMCP extends McpAgent {\n    server = new McpServer({ name: \"Demo\", version: \"1.0.0\" });\n    async init() {\n      this.server.tool(\n        \"add\",\n        { a: z.number(), b: z.number() },\n        async ({ a, b }) => ({\n          content: [{ type: \"text\", text: String(a + b) }],\n        }),\n      );\n    }\n  }\n  ts\n  import { McpServer } from \"@modelcontextprotocol/sdk/server/mcp\";\n  import { McpAgent } from \"agents/mcp\";\n  import { z } from \"zod\";\n\nexport class MyMCP extends McpAgent {\n    server = new McpServer({ name: \"Demo\", version: \"1.0.0\" });\n    async init() {\n      this.server.tool(\n        \"add\",\n        { a: z.number(), b: z.number() },\n        async ({ a, b }) => ({\n          content: [{ type: \"text\", text: String(a + b) }],\n        }),\n      );\n    }\n  }\n  js\n  import { createMcpHandler } from \"agents/mcp\";\n  import { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\";\n  import { z } from \"zod\";\n\nconst server = new McpServer({\n    name: \"My MCP Server\",\n    version: \"1.0.0\",\n  });\n\nserver.registerTool(\n    \"hello\",\n    {\n      description: \"Returns a greeting message\",\n      inputSchema: { name: z.string().optional() },\n    },\n    async ({ name }) => {\n      return {\n        content: [{ text: `Hello, ${name ?? \"World\"}!`, type: \"text\" }],\n      };\n    },\n  );\n\nexport default {\n    fetch: (request, env, ctx) => {\n      return createMcpHandler(server)(request, env, ctx);\n    },\n  };\n  ts\n  import { createMcpHandler } from \"agents/mcp\";\n  import { McpServer } from \"@modelcontextprotocol/sdk/server/mcp.js\";\n  import { z } from \"zod\";\n\nconst server = new McpServer({\n    name: \"My MCP Server\",\n    version: \"1.0.0\",\n  });\n\nserver.registerTool(\n    \"hello\",\n    {\n      description: \"Returns a greeting message\",\n      inputSchema: { name: z.string().optional() },\n    },\n    async ({ name }) => {\n      return {\n        content: [{ text: `Hello, ${name ?? \"World\"}!`, type: \"text\" }],\n      };\n    },\n  );\n\nexport default {\n    fetch: (request: Request, env: Env, ctx: ExecutionContext) => {\n      return createMcpHandler(server)(request, env, ctx);\n    },\n  };\n  js\n  export default new OAuthProvider({\n    apiRoute: \"/mcp\",\n    apiHandler: {\n      fetch: (request, env, ctx) => {\n        return createMcpHandler(server)(request, env, ctx);\n      },\n    },\n    // ... other OAuth configuration\n  });\n  ts\n  export default new OAuthProvider({\n    apiRoute: \"/mcp\",\n    apiHandler: {\n      fetch: (request: Request, env: Env, ctx: ExecutionContext) => {\n        return createMcpHandler(server)(request, env, ctx);\n      },\n    },\n    // ... other OAuth configuration\n  });\n  bash\ncurl https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/openai/chat/completions \\\n  --header 'cf-aig-authorization: Bearer {CF_AIG_TOKEN}' \\\n  --header 'Authorization: Bearer OPENAI_TOKEN' \\\n  --header 'Content-Type: application/json' \\\n  --data '{\"model\": \"gpt-5-mini\", \"messages\": [{\"role\": \"user\", \"content\": \"What is Cloudflare?\"}]}'\njavascript\nimport OpenAI from \"openai\";\n\nconst openai = new OpenAI({\n  apiKey: process.env.OPENAI_API_KEY,\n  baseURL: \"https://gateway.ai.cloudflare.com/v1/account-id/gateway/openai\",\n  defaultHeaders: {\n    \"cf-aig-authorization\": `Bearer {token}`,\n  },\n});\njavascript\nimport { createOpenAI } from \"@ai-sdk/openai\";\n\nconst openai = createOpenAI({\n  baseURL: \"https://gateway.ai.cloudflare.com/v1/account-id/gateway/openai\",\n  headers: {\n    \"cf-aig-authorization\": `Bearer {token}`,\n  },\n});\nbash\n   curl https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/openai/chat/completions \\\n     -H 'cf-aig-authorization: Bearer {CF_AIG_TOKEN}' \\\n     -H \"Authorization: Bearer YOUR_OPENAI_API_KEY\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"model\": \"gpt-4\", \"messages\": [...]}'\n   bash\n   curl https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/openai/chat/completions \\\n     -H 'cf-aig-authorization: Bearer {CF_AIG_TOKEN}' \\\n     -H \"Content-Type: application/json\" \\\n     -d '{\"model\": \"gpt-4\", \"messages\": [...]}'\n   bash\ncurl https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/openai/chat/completions \\\n  --header \"Authorization: Bearer $TOKEN\" \\\n  --header 'Content-Type: application/json' \\\n  --header 'cf-aig-custom-cost: {\"per_token_in\":0.000001,\"per_token_out\":0.000002}' \\\n  --data ' {\n        \"model\": \"gpt-4o-mini\",\n        \"messages\": [\n          {\n            \"role\": \"user\",\n            \"content\": \"When is Cloudflare’s Birthday Week?\"\n          }\n        ]\n      }'\nbash\n  curl -X POST \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/ai-gateway/custom-providers\" \\\n    -H \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\" \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\n      \"name\": \"My Custom Provider\",\n      \"slug\": \"some-provider\",\n      \"base_url\": \"https://api.myprovider.com\",\n      \"description\": \"Custom AI provider for internal models\",\n      \"enable\": true\n    }'\n  json\n  {\n    \"success\": true,\n    \"result\": {\n      \"id\": \"550e8400-e29b-41d4-a716-446655440000\",\n      \"account_id\": \"abc123def456\",\n      \"account_tag\": \"my-account\",\n      \"name\": \"My Custom Provider\",\n      \"slug\": \"some-provider\",\n      \"base_url\": \"https://api.myprovider.com\",\n      \"description\": \"Custom AI provider for internal models\",\n      \"enable\": true,\n      \"beta\": false,\n      \"logo\": \"Base64 encoded SVG logo\",\n      \"link\": null,\n      \"curl_example\": null,\n      \"js_example\": null,\n      \"created_at\": 1700000000,\n      \"modified_at\": 1700000000\n    }\n  }\n  bash\n  curl \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/ai-gateway/custom-providers\" \\\n    -H \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\"\n  bash\n  curl \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/ai-gateway/custom-providers?enable=true\" \\\n    -H \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\"\n  bash\n  curl \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/ai-gateway/custom-providers?search=custom\" \\\n    -H \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\"\n  json\n  {\n    \"success\": true,\n    \"result\": [\n      {\n        \"id\": \"550e8400-e29b-41d4-a716-446655440000\",\n        \"name\": \"My Custom Provider\",\n        \"slug\": \"some-provider\",\n        \"base_url\": \"https://api.myprovider.com\",\n        \"enable\": true,\n        \"created_at\": 1700000000,\n        \"modified_at\": 1700000000\n      }\n    ],\n    \"result_info\": {\n      \"page\": 1,\n      \"per_page\": 20,\n      \"total_count\": 1,\n      \"total_pages\": 1\n    }\n  }\n  bash\n  curl \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/ai-gateway/custom-providers/{provider_id}\" \\\n    -H \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\"\n  json\n  {\n    \"success\": true,\n    \"result\": {\n      \"id\": \"550e8400-e29b-41d4-a716-446655440000\",\n      \"account_id\": \"abc123def456\",\n      \"account_tag\": \"my-account\",\n      \"name\": \"My Custom Provider\",\n      \"slug\": \"some-provider\",\n      \"base_url\": \"https://api.myprovider.com\",\n      \"description\": \"Custom AI provider for internal models\",\n      \"enable\": true,\n      \"beta\": false,\n      \"logo\": \"Base64 encoded SVG logo\",\n      \"link\": \"https://docs.myprovider.com\",\n      \"curl_example\": \"curl -X POST https://api.myprovider.com/v1/chat ...\",\n      \"js_example\": \"fetch('https://api.myprovider.com/v1/chat', {...})\",\n      \"created_at\": 1700000000,\n      \"modified_at\": 1700000000\n    }\n  }\n  bash\n  curl -X PATCH \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/ai-gateway/custom-providers/{provider_id}\" \\\n    -H \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\" \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\n      \"name\": \"Updated Provider Name\",\n      \"enable\": true,\n      \"description\": \"Updated description\"\n    }'\n  bash\n  curl -X PATCH \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/ai-gateway/custom-providers/{provider_id}\" \\\n    -H \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\" \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"enable\": true}'\n  bash\n  curl -X PATCH \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/ai-gateway/custom-providers/{provider_id}\" \\\n    -H \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\" \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"base_url\": \"https://api.newprovider.com\"}'\n  bash\n  curl -X DELETE \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/ai-gateway/custom-providers/{provider_id}\" \\\n    -H \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\"\n  json\n  {\n    \"success\": true,\n    \"result\": {\n      \"id\": \"550e8400-e29b-41d4-a716-446655440000\",\n      \"name\": \"My Custom Provider\",\n      \"slug\": \"some-provider\"\n    }\n  }\n  bash\ncurl https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/compat/chat/completions \\\n  -H \"Authorization: Bearer $PROVIDER_API_KEY\" \\\n  -H \"cf-aig-authorization: Bearer $CF_AIG_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"custom-some-provider/model-name\",\n    \"messages\": [{\"role\": \"user\", \"content\": \"Hello!\"}]\n  }'\nbash\ncurl https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/custom-some-provider/your-endpoint \\\n  -H \"Authorization: Bearer $PROVIDER_API_KEY\" \\\n  -H \"cf-aig-authorization: Bearer $CF_AIG_TOKEN\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"your\": \"request payload\"\n  }'\njson\n{\n  \"success\": false,\n  \"errors\": [\n    {\n      \"code\": 1003,\n      \"message\": \"A custom provider with this slug already exists\",\n      \"path\": [\"body\", \"slug\"]\n    }\n  ]\n}\njson\n{\n  \"success\": false,\n  \"errors\": [\n    {\n      \"code\": 1004,\n      \"message\": \"Custom Provider not found\"\n    }\n  ]\n}\njson\n{\n  \"success\": false,\n  \"errors\": [\n    {\n      \"code\": 1002,\n      \"message\": \"base_url must be a valid HTTPS URL starting with https://\",\n      \"path\": [\"body\", \"base_url\"]\n    }\n  ]\n}\nmermaid\ngraph TD\n    A[AI Gateway] --> B[Request to Workers AI Inference API]\n    B -->|Success| C[Return Response]\n    B -->|Failure| D[Request to OpenAI API]\n    D --> E[Return Response]\nbash\ncurl https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id} \\\n  --header 'Content-Type: application/json' \\\n  --data '[\n  {\n    \"provider\": \"workers-ai\",\n    \"endpoint\": \"@cf/meta/llama-3.1-8b-instruct\",\n    \"headers\": {\n      \"Authorization\": \"Bearer {cloudflare_token}\",\n      \"Content-Type\": \"application/json\"\n    },\n    \"query\": {\n      \"messages\": [\n        {\n          \"role\": \"system\",\n          \"content\": \"You are a friendly assistant\"\n        },\n        {\n          \"role\": \"user\",\n          \"content\": \"What is Cloudflare?\"\n        }\n      ]\n    }\n  },\n  {\n    \"provider\": \"openai\",\n    \"endpoint\": \"chat/completions\",\n    \"headers\": {\n      \"Authorization\": \"Bearer {open_ai_token}\",\n      \"Content-Type\": \"application/json\"\n    },\n    \"query\": {\n      \"model\": \"gpt-4o-mini\",\n      \"stream\": true,\n      \"messages\": [\n        {\n          \"role\": \"user\",\n          \"content\": \"What is Cloudflare?\"\n        }\n      ]\n    }\n  }\n]'\nbash\ncurl 'https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}' \\\n  --header 'Content-Type: application/json' \\\n  --data '[\n    {\n        \"provider\": \"workers-ai\",\n        \"endpoint\": \"@cf/meta/llama-3.1-8b-instruct\",\n        \"headers\": {\n            \"Authorization\": \"Bearer {cloudflare_token}\",\n            \"Content-Type\": \"application/json\"\n        },\n        \"config\": {\n            \"requestTimeout\": 1000\n        },\n        \"query\": {\n34 collapsed lines\n            \"messages\": [\n                {\n                    \"role\": \"system\",\n                    \"content\": \"You are a friendly assistant\"\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": \"What is Cloudflare?\"\n                }\n            ]\n        }\n    },\n    {\n        \"provider\": \"workers-ai\",\n        \"endpoint\": \"@cf/meta/llama-3.1-8b-instruct-fast\",\n        \"headers\": {\n            \"Authorization\": \"Bearer {cloudflare_token}\",\n            \"Content-Type\": \"application/json\"\n        },\n        \"query\": {\n            \"messages\": [\n                {\n                    \"role\": \"system\",\n                    \"content\": \"You are a friendly assistant\"\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": \"What is Cloudflare?\"\n                }\n            ]\n        },\n        \"config\": {\n            \"requestTimeout\": 3000\n        },\n    }\n]'\nbash\ncurl https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/workers-ai/@cf/meta/llama-3.1-8b-instruct \\\n --header 'Authorization: Bearer {cf_api_token}' \\\n --header 'Content-Type: application/json' \\\n --header 'cf-aig-request-timeout: 5000'\n --data '{\"prompt\": \"What is Cloudflare?\"}'\njson\nconfig:{\n  maxAttempts?: number;\n  retryDelay?: number;\n  backoff?: \"constant\" | \"linear\" | \"exponential\";\n}\nbash\ncurl 'https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}' \\\n  --header 'Content-Type: application/json' \\\n  --data '[\n    {\n        \"provider\": \"workers-ai\",\n        \"endpoint\": \"@cf/meta/llama-3.1-8b-instruct\",\n        \"headers\": {\n            \"Authorization\": \"Bearer {cloudflare_token}\",\n            \"Content-Type\": \"application/json\"\n        },\n        \"config\": {\n            \"maxAttempts\": 2,\n            \"retryDelay\": 1000,\n            \"backoff\": \"constant\"\n        },\n39 collapsed lines\n        \"query\": {\n            \"messages\": [\n                {\n                    \"role\": \"system\",\n                    \"content\": \"You are a friendly assistant\"\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": \"What is Cloudflare?\"\n                }\n            ]\n        }\n    },\n    {\n        \"provider\": \"workers-ai\",\n        \"endpoint\": \"@cf/meta/llama-3.1-8b-instruct-fast\",\n        \"headers\": {\n            \"Authorization\": \"Bearer {cloudflare_token}\",\n            \"Content-Type\": \"application/json\"\n        },\n        \"query\": {\n            \"messages\": [\n                {\n                    \"role\": \"system\",\n                    \"content\": \"You are a friendly assistant\"\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": \"What is Cloudflare?\"\n                }\n            ]\n        },\n        \"config\": {\n            \"maxAttempts\": 4,\n            \"retryDelay\": 1000,\n            \"backoff\": \"exponential\"\n        },\n    }\n]'\njson\n{\n  \"status\": \"success\",\n  \"headers\": {\n    \"cf-aig-log-id\": \"01JADMCQQQBWH3NXZ5GCRN98DP\"\n  },\n  \"data\": {\n    \"response\": \"Sample response data\"\n  }\n}\nbash\ncurl \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/ai-gateway/gateways/$GATEWAY_ID/logs\" \\\n  --request GET \\\n  --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\"\njson\n{\n  \"result\": [\n    {\n      \"id\": \"01JADMCQQQBWH3NXZ5GCRN98DP\",\n      \"cached\": true,\n      \"created_at\": \"2019-08-24T14:15:22Z\",\n      \"custom_cost\": true,\n      \"duration\": 0,\n      \"id\": \"string\",\n      \"metadata\": \"string\",\n      \"model\": \"string\",\n      \"model_type\": \"string\",\n      \"path\": \"string\",\n      \"provider\": \"string\",\n      \"request_content_type\": \"string\",\n      \"request_type\": \"string\",\n      \"response_content_type\": \"string\",\n      \"status_code\": 0,\n      \"step\": 0,\n      \"success\": true,\n      \"tokens_in\": 0,\n      \"tokens_out\": 0\n    }\n  ]\n}\njs\nconst resp = await env.AI.run(\n  \"@cf/meta/llama-3-8b-instruct\",\n  {\n    prompt: \"tell me a joke\",\n  },\n  {\n    gateway: {\n      id: \"my_gateway_id\",\n    },\n  },\n);\n\nconst myLogId = env.AI.aiGatewayLogId;\nbash\ncurl \"https://api.cloudflare.com/client/v4/accounts/$ACCOUNT_ID/ai-gateway/gateways/$GATEWAY_ID/logs/$ID\" \\\n  --request PATCH \\\n  --header \"Authorization: Bearer $CLOUDFLARE_API_TOKEN\" \\\n  --json '{\n    \"feedback\": 1\n  }'\njson\n{\n  \"feedback\": -1\n}\njavascript\nconst resp = await env.AI.run(\n  \"@cf/meta/llama-3.1-8b-instruct\",\n  {\n    prompt: \"tell me a joke\",\n  },\n  {\n    gateway: {\n      id: \"my-gateway\",\n    },\n  },\n);\n\nconst myLogId = env.AI.aiGatewayLogId;\njavascript\nawait env.AI.gateway(\"my-gateway\").patchLog(myLogId, {\n  feedback: 1, // all fields are optional; set values that fit your use case\n  score: 100,\n  metadata: {\n    user: \"123\", // Optional metadata to provide additional context\n  },\n});\njavascript\ngateway.patchLog(\"my-log-id\", {\n  feedback: 1,\n  score: 100,\n  metadata: {\n    user: \"123\",\n  },\n});\nbash\ncurl https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/openai/chat/completions \\\n  --header \"Authorization: Bearer $TOKEN\" \\\n  --header 'Content-Type: application/json' \\\n  --header 'cf-aig-skip-cache: true' \\\n  --data ' {\n        \"model\": \"gpt-4o-mini\",\n        \"messages\": [\n          {\n            \"role\": \"user\",\n            \"content\": \"how to build a wooden spoon in 3 short steps? give as short as answer as possible\"\n          }\n        ]\n      }\n'\nbash\ncurl https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/openai/chat/completions \\\n  --header \"Authorization: Bearer $TOKEN\" \\\n  --header 'Content-Type: application/json' \\\n  --header 'cf-aig-cache-ttl: 3600' \\\n  --data ' {\n        \"model\": \"gpt-4o-mini\",\n        \"messages\": [\n          {\n            \"role\": \"user\",\n            \"content\": \"how to build a wooden spoon in 3 short steps? give as short as answer as possible\"\n          }\n        ]\n      }\n'\nbash\ncurl https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/openai/chat/completions \\\n  --header 'Authorization: Bearer {openai_token}' \\\n  --header 'Content-Type: application/json' \\\n  --header 'cf-aig-cache-key: responseA' \\\n  --data ' {\n        \"model\": \"gpt-4o-mini\",\n        \"messages\": [\n          {\n            \"role\": \"user\",\n            \"content\": \"how to build a wooden spoon in 3 short steps? give as short as answer as possible\"\n          }\n        ]\n      }\n'\nbash\ncurl -X POST https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/compat/chat/completions \\\n  --header 'cf-aig-authorization: Bearer {CLOUDFLARE_TOKEN}' \\\n  --header 'Content-Type: application/json' \\\n  --data '{\n    \"model\": \"google-ai-studio/gemini-2.5-pro\",\n    \"messages\": [\n      {\n        \"role\": \"user\",\n        \"content\": \"What is Cloudflare?\"\n      }\n    ]\n  }'\nsh\n  npm create cloudflare@latest -- hello-ai\n  sh\n  yarn create cloudflare hello-ai\n  sh\n  pnpm create cloudflare@latest hello-ai\n  bash\ncd hello-ai\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"ai\": {\n      \"binding\": \"AI\"\n    }\n  }\n  toml\n  [ai]\n  binding = \"AI\"\n  typescript\nexport interface Env {\n  // If you set another name in the [Wrangler configuration file](/workers/wrangler/configuration/) as the value for 'binding',\n  // replace \"AI\" with the variable name you defined.\n  AI: Ai;\n}\n\nexport default {\n  async fetch(request, env): Promise<Response> {\n    // Specify the gateway label and other options here\n    const response = await env.AI.run(\n      \"@cf/meta/llama-3.1-8b-instruct-fast\",\n      {\n        prompt: \"What is the origin of the phrase Hello, World\",\n      },\n      {\n        gateway: {\n          id: \"GATEWAYID\", // Use your gateway label here\n          skipCache: true, // Optional: Skip cache if needed\n        },\n      },\n    );\n\n// Return the AI response as a JSON object\n    return new Response(JSON.stringify(response), {\n      headers: { \"Content-Type\": \"application/json\" },\n    });\n  },\n} satisfies ExportedHandler<Env>;\nbash\nnpx wrangler dev\n`json\n{\n  \"response\": \"A fascinating question!\\n\\nThe phrase \\\"Hello, World!\\\" originates from a simple computer program written in the early days of programming. It is often attributed to Brian Kernighan, a Canadian computer scientist and a pioneer in the field of computer programming.\\n\\nIn the early 1970s, Kernighan, along with his colleague Dennis Ritchie, were working on the C programming language. They wanted to create a simple program that would output a message to the screen to demonstrate the basic structure of a program. They chose the phrase \\\"Hello, World!\\\" because it was a simple and recognizable message that would illustrate how a program could print text to the screen.\\n\\nThe exact code was written in the 5th edition of Kernighan and Ritchie's book \\\"The C Programming Language,\\\" published in 1988. The code, literally known as \\\"Hello, World!\\\" is as follows:\\n\\n\\n\\nThis code is still often used as a starting point for learning programming languages, as it demonstrates how to output a simple message to the console.\\n\\nThe phrase \\\"Hello, World!\\\" has since become a catch-all phrase to indicate the start of a new program or a small test program, and is widely used in computer science and programming education.\\n\\nSincerely, I'm glad I could help clarify the origin of this iconic phrase for you!\"\n}\nbash\nnpx wrangler login\nbash\nnpx wrangler deploy\nbash\nhttps://hello-ai.<YOUR_SUBDOMAIN>.workers.dev\nbash\nnpm install ai-gateway-provider\njs\n  import { createAiGateway } from 'ai-gateway-provider';\n  import { createOpenAI } from 'ai-gateway-provider/providers/openai';\n  import { generateText } from \"ai\";\n\nconst aigateway = createAiGateway({\n    accountId: \"{CLOUDFLARE_ACCOUNT_ID}\",\n    gateway: '{GATEWAY_NAME}',\n    apiKey: '{CF_AIG_TOKEN}',\n  });\n\nconst openai = createOpenAI({ apiKey: '{OPENAI_API_KEY}' });\n\nconst { text } = await generateText({\n    model: aigateway(openai.chat(\"gpt-5.1\")),\n    prompt: 'Write a vegetarian lasagna recipe for 4 people.',\n  });\n  js\n  import { createAiGateway } from 'ai-gateway-provider';\n  import { createOpenAI } from 'ai-gateway-provider/providers/openai';\n  import { generateText } from \"ai\";\n\nconst aigateway = createAiGateway({\n    accountId: \"{CLOUDFLARE_ACCOUNT_ID}\",\n    gateway: '{GATEWAY_NAME}',\n  });\n\nconst openai = createOpenAI({ apiKey: '{OPENAI_API_KEY}' });\n\nconst { text } = await generateText({\n    model: aigateway(openai.chat(\"gpt-5.1\")),\n    prompt: 'Write a vegetarian lasagna recipe for 4 people.',\n  });\n  js\nimport { createAiGateway } from 'ai-gateway-provider';\nimport { createOpenAI } from 'ai-gateway-provider/providers/openai';\nimport { generateText } from \"ai\";\n\nconst aigateway = createAiGateway({\n  accountId: \"{CLOUDFLARE_ACCOUNT_ID}\",\n  gateway: '{GATEWAY_NAME}',\n  apiKey: '{CF_AIG_TOKEN}',\n});\n\nconst openai = createOpenAI();\n\nconst { text } = await generateText({\n  model: aigateway(openai.chat(\"gpt-5.1\")),\n  prompt: 'Write a vegetarian lasagna recipe for 4 people.',\n});\njs\nconst { text } = await generateText({\n  model: aigateway([\n    openai.chat(\"gpt-5.1\"), anthropic(\"claude-sonnet-4-5\")\n  ]),\n  prompt: 'Write a vegetarian lasagna recipe for 4 people.',\n});\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"ai\": {\n      \"binding\": \"AI\"\n    }\n  }\n  toml\n  [ai]\n  binding = \"AI\"\n  typescript\nconst resp = await env.AI.run(\n  \"@cf/meta/llama-3.1-8b-instruct\",\n  {\n    prompt: \"tell me a joke\",\n  },\n  {\n    gateway: {\n      id: \"my-gateway\",\n    },\n  },\n);\ntypescript\nconst myLogId = env.AI.aiGatewayLogId;\ntypescript\nconst gateway = env.AI.gateway(\"my-gateway\");\ntypescript\ngateway.patchLog(\"my-log-id\", {\n  feedback: 1,\n  score: 100,\n  metadata: {\n    user: \"123\",\n  },\n});\ntypescript\nconst log = await gateway.getLog(\"my-log-id\");\ntypescript\n// Get the base gateway URL\nconst baseUrl = await gateway.getUrl();\n// Output: https://gateway.ai.cloudflare.com/v1/my-account-id/my-gateway/\n\n// Get a provider-specific URL\nconst openaiUrl = await gateway.getUrl(\"openai\");\n// Output: https://gateway.ai.cloudflare.com/v1/my-account-id/my-gateway/openai\ntypescript\nimport OpenAI from \"openai\";\n\nconst openai = new OpenAI({\n  apiKey: \"my api key\", // defaults to process.env[\"OPENAI_API_KEY\"]\n  baseURL: await env.AI.gateway(\"my-gateway\").getUrl(\"openai\"),\n});\ntypescript\nimport { createOpenAI } from \"@ai-sdk/openai\";\n\nconst openai = createOpenAI({\n  baseURL: await env.AI.gateway(\"my-gateway\").getUrl(\"openai\"),\n});\ntypescript\nimport { createAnthropic } from \"@ai-sdk/anthropic\";\n\nconst anthropic = createAnthropic({\n  baseURL: await env.AI.gateway(\"my-gateway\").getUrl(\"anthropic\"),\n});\ntypescript\nconst resp = await gateway.run({\n  provider: \"workers-ai\",\n  endpoint: \"@cf/meta/llama-3.1-8b-instruct\",\n  headers: {\n    authorization: \"Bearer my-api-token\",\n  },\n  query: {\n    prompt: \"tell me a joke\",\n  },\n});\nbash\n  curl https://api.cloudflare.com/client/v4/graphql \\\n    --header 'Authorization: Bearer TOKEN \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n      \"query\": \"query{\\n  viewer {\\n  accounts(filter: { accountTag: \\\"{account_id}\\\" }) {\\n  requests: aiGatewayRequestsAdaptiveGroups(\\n      limit: $limit\\n      filter: { datetimeHour_geq: $start, datetimeHour_leq: $end }\\n      orderBy: [datetimeMinute_ASC]\\n    ) {\\n      count,\\n      dimensions {\\n          model,\\n          provider,\\n          gateway,\\n          ts: datetimeMinute\\n      }\\n      \\n    }\\n      \\n  }\\n  }\\n}\",\n      \"variables\": {\n        \"limit\": 1000,\n        \"start\": \"2023-09-01T10:00:00.000Z\",\n        \"end\": \"2023-09-30T10:00:00.000Z\",\n        \"orderBy\": \"date_ASC\"\n      }\n  }'\n  bash\ncurl https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/openai/chat/completions \\\n  --header 'Authorization: Bearer {api_token}' \\\n  --header 'Content-Type: application/json' \\\n  --header 'cf-aig-metadata: {\"team\": \"AI\", \"user\": 12345, \"test\":true}' \\\n  --data '{\"model\": \"gpt-4o\", \"messages\": [{\"role\": \"user\", \"content\": \"What should I eat for lunch?\"}]}'\njavascript\nimport OpenAI from \"openai\";\n\nexport default {\n async fetch(request, env, ctx) {\n   const openai = new OpenAI({\n     apiKey: env.OPENAI_API_KEY,\n     baseURL: \"https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/openai\",\n   });\n\ntry {\n     const chatCompletion = await openai.chat.completions.create(\n       {\n         model: \"gpt-4o\",\n         messages: [{ role: \"user\", content: \"What should I eat for lunch?\" }],\n         max_tokens: 50,\n       },\n       {\n         headers: {\n           \"cf-aig-metadata\": JSON.stringify({\n             user: \"JaneDoe\",\n             team: 12345,\n             test: true\n           }),\n         },\n       }\n     );\n\nconst response = chatCompletion.choices[0].message;\n     return new Response(JSON.stringify(response));\n   } catch (e) {\n     console.log(e);\n     return new Response(e);\n   }\n },\n};\njavascript\nexport default {\n async fetch(request, env, ctx) {\n   const aiResp = await env.AI.run(\n       '@cf/mistral/mistral-7b-instruct-v0.1',\n       { prompt: 'What should I eat for lunch?' },\n       { gateway: { id: 'gateway_id', metadata: { \"team\": \"AI\", \"user\": 12345, \"test\": true} } }\n   );\n\nreturn new Response(aiResp);\n },\n};\nbash\ncurl https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/openai/chat/completions \\\n  --header \"Authorization: Bearer $TOKEN\" \\\n  --header 'Content-Type: application/json' \\\n  --header 'cf-aig-collect-log: false \\\n  --data ' {\n        \"model\": \"gpt-4o-mini\",\n        \"messages\": [\n          {\n            \"role\": \"user\",\n            \"content\": \"What is the email address and phone number of user123?\"\n          }\n        ]\n      }\n'\njson\n{\n \"action\": {\n     \"info\": \"gateway created\",\n     \"result\": true,\n     \"type\": \"create\"\n },\n \"actor\": {\n     \"email\": \"<ACTOR_EMAIL>\",\n     \"id\": \"3f7b730e625b975bc1231234cfbec091\",\n     \"ip\": \"fe32:43ed:12b5:526::1d2:13\",\n     \"type\": \"user\"\n },\n \"id\": \"5eaeb6be-1234-406a-87ab-1971adc1234c\",\n \"interface\": \"UI\",\n \"metadata\": {},\n \"newValue\": \"\",\n \"newValueJson\": {\n     \"cache_invalidate_on_update\": false,\n     \"cache_ttl\": 0,\n     \"collect_logs\": true,\n     \"id\": \"test\",\n     \"rate_limiting_interval\": 0,\n     \"rate_limiting_limit\": 0,\n     \"rate_limiting_technique\": \"fixed\"\n },\n \"oldValue\": \"\",\n \"oldValueJson\": {},\n \"owner\": {\n     \"id\": \"1234d848c0b9e484dfc37ec392b5fa8a\"\n },\n \"resource\": {\n     \"id\": \"89303df8-1234-4cfa-a0f8-0bd848e831ca\",\n     \"type\": \"ai_gateway.gateway\"\n },\n \"when\": \"2024-07-17T14:06:11.425Z\"\n}\nbash\n   curl https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/workers-ai/@cf/meta/llama-3.1-8b-instruct \\\n   --header 'Authorization: Bearer {cf_api_token}' \\\n   --header 'Content-Type: application/json' \\\n   --data '{\"prompt\": \"What is Cloudflare?\"}'\n   bash\n{\"result\":{\"response\":\"I'd be happy to explain what Cloudflare is.\\n\\nCloudflare is a cloud-based service that provides a range of features to help protect and improve the performance, security, and reliability of websites, applications, and other online services. Think of it as a shield for your online presence!\\n\\nHere are some of the key things Cloudflare does:\\n\\n1. **Content Delivery Network (CDN)**: Cloudflare has a network of servers all over the world. When you visit a website that uses Cloudflare, your request is sent to the nearest server, which caches a copy of the website's content. This reduces the time it takes for the content to load, making your browsing experience faster.\\n2. **DDoS Protection**: Cloudflare protects against Distributed Denial-of-Service (DDoS) attacks. This happens when a website is overwhelmed with traffic from multiple sources to make it unavailable. Cloudflare filters out this traffic, ensuring your site remains accessible.\\n3. **Firewall**: Cloudflare acts as an additional layer of security, filtering out malicious traffic and hacking attempts, such as SQL injection or cross-site scripting (XSS) attacks.\\n4. **SSL Encryption**: Cloudflare offers free SSL encryption, which secure sensitive information (like passwords, credit card numbers, and browsing data) with an HTTPS connection (the \\\"S\\\" stands for Secure).\\n5. **Bot Protection**: Cloudflare has an AI-driven system that identifies and blocks bots trying to exploit vulnerabilities or scrape your content.\\n6. **Analytics**: Cloudflare provides insights into website traffic, helping you understand your audience and make informed decisions.\\n7. **Cybersecurity**: Cloudflare offers advanced security features, such as intrusion protection, DNS filtering, and Web Application Firewall (WAF) protection.\\n\\nOverall, Cloudflare helps protect against cyber threats, improves website performance, and enhances security for online businesses, bloggers, and individuals who need to establish a strong online presence.\\n\\nWould you like to know more about a specific aspect of Cloudflare?\"},\"success\":true,\"errors\":[],\"messages\":[]}%\nsh\n  npm create cloudflare@latest -- openai-aig\n  sh\n  yarn create cloudflare openai-aig\n  sh\n  pnpm create cloudflare@latest openai-aig\n  sh\ncd openai-aig\njs\nexport default {\n  async fetch(request, env, ctx) {\n    return new Response(\"Hello World!\");\n  },\n};\nsh\n  npm i openai\n  sh\n  yarn add openai\n  sh\n  pnpm add openai\n  js\nimport OpenAI from \"openai\";\njs\nimport OpenAI from \"openai\";\n\nexport default {\n  async fetch(request, env, ctx) {\n    const openai = new OpenAI({\n      apiKey: env.OPENAI_API_KEY,\n      baseURL:\n        \"https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/openai\", // paste your AI Gateway endpoint here\n    });\n  },\n};\nsh\n  npx wrangler secret put OPENAI_API_KEY\n  sh\n  yarn wrangler secret put OPENAI_API_KEY\n  sh\n  pnpm wrangler secret put OPENAI_API_KEY\n  txt\nOPENAI_API_KEY = \"<YOUR_OPENAI_API_KEY_HERE>\"\njs\nimport OpenAI from \"openai\";\n\nexport default {\n  async fetch(request, env, ctx) {\n    const openai = new OpenAI({\n      apiKey: env.OPENAI_API_KEY,\n      baseURL:\n        \"https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/openai\",\n    });\n\ntry {\n      const chatCompletion = await openai.chat.completions.create({\n        model: \"gpt-4o-mini\",\n        messages: [{ role: \"user\", content: \"What is a neuron?\" }],\n        max_tokens: 100,\n      });\n\nconst response = chatCompletion.choices[0].message;\n\nreturn new Response(JSON.stringify(response));\n    } catch (e) {\n      return new Response(e);\n    }\n  },\n};\nsh\n  npx wrangler deploy\n  sh\n  yarn wrangler deploy\n  sh\n  pnpm wrangler deploy\n  txt\nhttps://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/compat/chat/completions\njs\n  import OpenAI from \"openai\";\n\nconst client = new OpenAI({\n    apiKey: \"YOUR_PROVIDER_API_KEY\",\n    defaultHeaders: {\n      \"cf-aig-authorization\": `Bearer {cf_api_token}`,\n    },\n    baseURL:\n      \"https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/compat\",\n  });\n\n// Use different providers by changing the model parameter\n  const response = await client.chat.completions.create({\n    model: \"google-ai-studio/gemini-2.5-flash\", // or \"openai/gpt-5-mini\", \"anthropic/claude-sonnet-4-5\"\n    messages: [{ role: \"user\", content: \"Hello, world!\" }],\n  });\n  js\n  import OpenAI from \"openai\";\n\nconst client = new OpenAI({\n    apiKey: \"YOUR_PROVIDER_API_KEY\",\n    baseURL:\n      \"https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/compat\",\n  });\n\n// Use different providers by changing the model parameter\n  const response = await client.chat.completions.create({\n    model: \"google-ai-studio/gemini-2.5-flash\", // or \"openai/gpt-5-mini\", \"anthropic/claude-sonnet-4-5\"\n    messages: [{ role: \"user\", content: \"Hello, world!\" }],\n  });\n  js\nimport OpenAI from \"openai\";\n\nconst client = new OpenAI({\n  apiKey: \"{cf_api_token}\",\n  baseURL:\n    \"https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/compat\",\n});\n\n// Ensure either your LLM Keys are stored with BYOK\n// or Unified Billing has credits\nconst response = await client.chat.completions.create({\n  // Use different providers by changing the model parameter\n  model: \"google-ai-studio/gemini-2.5-flash\", // or \"openai/gpt-5-mini\"\n  messages: [{ role: \"user\", content: \"Hello, world!\" }],\n});\nbash\n  curl -X POST https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/compat/chat/completions \\\n    --header 'Authorization: Bearer {GOOGLE_GENERATIVE_AI_API_KEY}' \\\n    --header 'cf-aig-authorization: Bearer {CF_AIG_TOKEN}' \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n      \"model\": \"google-ai-studio/gemini-2.5-flash\",\n      \"messages\": [\n        {\n          \"role\": \"user\",\n          \"content\": \"What is Cloudflare?\"\n        }\n      ]\n    }'\n  bash\n  curl -X POST https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/compat/chat/completions \\\n    --header 'Authorization: Bearer {GOOGLE_GENERATIVE_AI_API_KEY}' \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n      \"model\": \"google-ai-studio/gemini-2.5-flash\",\n      \"messages\": [\n        {\n          \"role\": \"user\",\n          \"content\": \"What is Cloudflare?\"\n        }\n      ]\n    }'\n  bash\ncurl -X POST https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}/compat/chat/completions \\\n  --header 'cf-aig-authorization: Bearer {CF_AIG_TOKEN}' \\\n  --header 'Content-Type: application/json' \\\n  --data '{\n    \"model\": \"google-ai-studio/gemini-2.5-flash\",\n    \"messages\": [\n      {\n        \"role\": \"user\",\n        \"content\": \"What is Cloudflare?\"\n      }\n    ]\n  }'\ntxt\nhttps://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id}\nbash\ncurl https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id} \\\n  --header 'Content-Type: application/json' \\\n  --data '[\n  {\n    \"provider\": \"workers-ai\",\n    \"endpoint\": \"@cf/meta/llama-3.1-8b-instruct\",\n    \"headers\": {\n      \"Authorization\": \"Bearer {cloudflare_token}\",\n      \"Content-Type\": \"application/json\"\n    },\n    \"query\": {\n      \"messages\": [\n        {\n          \"role\": \"system\",\n          \"content\": \"You are a friendly assistant\"\n        },\n        {\n          \"role\": \"user\",\n          \"content\": \"What is Cloudflare?\"\n        }\n      ]\n    }\n  },\n  {\n    \"provider\": \"openai\",\n    \"endpoint\": \"chat/completions\",\n    \"headers\": {\n      \"Authorization\": \"Bearer {open_ai_token}\",\n      \"Content-Type\": \"application/json\"\n    },\n    \"query\": {\n      \"model\": \"gpt-4o-mini\",\n      \"stream\": true,\n      \"messages\": [\n        {\n          \"role\": \"user\",\n          \"content\": \"What is Cloudflare?\"\n        }\n      ]\n    }\n  }\n]'\njavascript\nimport WebSocket from \"ws\";\nconst ws = new WebSocket(\n  \"wss://gateway.ai.cloudflare.com/v1/my-account-id/my-gateway/\",\n  {\n    headers: {\n      \"cf-aig-authorization\": \"Bearer AI_GATEWAY_TOKEN\",\n    },\n  },\n);\n\nws.send(\n  JSON.stringify({\n    type: \"universal.create\",\n    request: {\n      eventId: \"my-request\",\n      provider: \"workers-ai\",\n      endpoint: \"@cf/meta/llama-3.1-8b-instruct\",\n      headers: {\n        Authorization: \"Bearer WORKERS_AI_TOKEN\",\n        \"Content-Type\": \"application/json\",\n      },\n      query: {\n        prompt: \"tell me a joke\",\n      },\n    },\n  }),\n);\n\nws.on(\"message\", function incoming(message) {\n  console.log(message.toString());\n});\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"ai\": {\n      \"binding\": \"AI\"\n    }\n  }\n  toml\n  [ai]\n  binding = \"AI\"\n  typescript\ntype Env = {\n  AI: Ai;\n};\n\nexport default {\n  async fetch(request: Request, env: Env) {\n    return env.AI.gateway(\"my-gateway\").run({\n      provider: \"workers-ai\",\n      endpoint: \"@cf/meta/llama-3.1-8b-instruct\",\n      headers: {\n        authorization: \"Bearer my-api-token\",\n      },\n      query: {\n        prompt: \"tell me a joke\",\n      },\n    });\n  },\n};\nbash\ncurl https://gateway.ai.cloudflare.com/v1/{account_id}/{gateway_id} \\\n  --header 'Content-Type: application/json' \\\n  --header 'cf-aig-cache-ttl: 3600' \\\n  --data '[\n    {\n      \"provider\": \"workers-ai\",\n      \"endpoint\": \"@cf/meta/llama-3.1-8b-instruct\",\n      \"headers\": {\n        \"Authorization\": \"Bearer {cloudflare_token}\",\n        \"Content-Type\": \"application/json\"\n      },\n      \"query\": {\n        \"messages\": [\n          {\n            \"role\": \"system\",\n            \"content\": \"You are a friendly assistant\"\n          },\n          {\n            \"role\": \"user\",\n            \"content\": \"What is Cloudflare?\"\n          }\n        ]\n      }\n    },\n    {\n      \"provider\": \"openai\",\n      \"endpoint\": \"chat/completions\",\n      \"headers\": {\n        \"Authorization\": \"Bearer {open_ai_token}\",\n        \"Content-Type\": \"application/json\",\n        \"cf-aig-cache-ttl\": \"0\"\n      },\n      \"query\": {\n        \"model\": \"gpt-4o-mini\",\n        \"stream\": true,\n        \"messages\": [\n          {\n            \"role\": \"user\",\n            \"content\": \"What is Cloudflare?\"\n          }\n        ]\n      }\n    }\n  ]'\nmermaid\ngraph LR\nA[Traffic] --> B[WAF custom rules<br>AI Crawl Control: Crawler blocks]\nB --> C[Cloudflare<br>Bot Solutions]\nC --> D[AI Crawl Control:<br>Pay Per Crawl]\nclassDef highlight fill:#F6821F,color:white\nmermaid\ngraph LR\nA[Traffic] --> B[WAF custom rules<br>AI Crawl Control: Crawler blocks]\nB --> C[Cloudflare<br>Bot Solutions]\nC --> D[AI Crawl Control:<br>Pay Per Crawl]\nclassDef highlight fill:#F6821F,color:white\njs\nconst answer = await env.AI.autorag(\"my-autorag\").search({\n  query: \"How do I train a llama to deliver coffee?\",\n  filters: {\n    type: \"and\",\n    filters: [\n      {\n        type: \"eq\",\n        key: \"folder\",\n        value: \"llama/logistics/\",\n      },\n      {\n        type: \"gte\",\n        key: \"timestamp\",\n        value: \"1735689600000\", // unix timestamp for 2025-01-01\n      },\n    ],\n  },\n});\njs\nfilters: {\n  type: \"operator\",\n  key: \"metadata_attribute\",\n  value: \"target_value\"\n}\njs\nfilters: {\n  type: \"compound_operator\",\n  filters: [...]\n}\njs\nfilters: {\n    type: \"and\",\n    filters: [\n      {\n        type: \"gt\",\n        key: \"folder\",\n        value: \"customer-a//\",\n      },\n      {\n        type: \"lte\",\n        key: \"folder\",\n        value: \"customer-a/z\",\n      },\n    ],\n  },\njavascript\nawait env.MY_BUCKET.put(\"cat.png\", file, {\n  customMetadata: {\n    context: \"This is a picture of Joe's cat. His name is Max.\"\n  }\n});\njs\n\"data\": [\n  {\n    \"file_id\": \"llama001\",\n    \"filename\": \"llama/logistics/llama-logistics.md\",\n    \"score\": 0.45,\n    \"attributes\": {\n      \"timestamp\": 1735689600000,   // unix timestamp for 2025-01-01\n      \"folder\": \"llama/logistics/\",\n      \"file\": {\n        \"url\": \"www.llamasarethebest.com/logistics\"\n        \"context\": \"This file contains information about how llamas can logistically deliver coffee.\"\n      }\n    },\n    \"content\": [\n      {\n        \"id\": \"llama001\",\n        \"type\": \"text\",\n        \"text\": \"Llamas can carry 3 drinks max.\"\n      }\n    ]\n  }\n]\njavascript\nconst answer = await env.AI.autorag(\"my-autorag\").aiSearch({\n  query: \"How do I train a llama to deliver coffee?\",\n  model: \"@cf/meta/llama-3.3-70b-instruct-fp8-fast\",\n  reranking: {\n    enabled: true,\n    model: \"@cf/baai/bge-reranker-base\"\n  }\n});\njavascript\nconst answer = await env.AI.autorag(\"my-autorag\").aiSearch({\n  query: \"How do I train a llama to deliver coffee?\",\n  model: \"@cf/meta/llama-3.3-70b-instruct-fp8-fast\",\n  system_prompt: \"You are a helpful assistant.\"\n});\ntext\nYou are a search query optimizer for vector database searches. Your task is to reformulate user queries into more effective search terms.\n\nGiven a user's search query, you must:\n1. Identify the core concepts and intent\n2. Add relevant synonyms and related terms\n3. Remove irrelevant filler words\n4. Structure the query to emphasize key terms\n5. Include technical or domain-specific terminology if applicable\n\nProvide only the optimized search query without any explanations, greetings, or additional commentary.\n\nExample input: \"how to fix a bike tire that's gone flat\"\nExample output: \"bicycle tire repair puncture fix patch inflate maintenance flat tire inner tube replacement\"\n\nConstraints:\n- Output only the enhanced search terms\n- Keep focus on searchable concepts\n- Include both specific and general related terms\n- Maintain all important meaning from original query\nplaintext\nYou are a helpful AI assistant specialized in answering questions using retrieved documents.\nYour task is to provide accurate, relevant answers based on the matched content provided.\nFor each query, you will receive:\nUser's question/query\nA set of matched documents, each containing:\n  - File name\n  - File content\n\nYou should:\n1. Analyze the relevance of matched documents\n2. Synthesize information from multiple sources when applicable\n3. Acknowledge if the available documents don't fully answer the query\n4. Format the response in a way that maximizes readability, in Markdown format\n\nAnswer only with direct reply to the user question, be concise, omit everything which is not directly relevant, focus on answering the question directly and do not redirect the user to read the content.\n\nIf the available documents don't contain enough information to fully answer the query, explicitly state this and provide an answer based on what is available.\n\nImportant:\n- Cite which document(s) you're drawing information from\n- Present information in order of relevance\n- If documents contradict each other, note this and explain your reasoning for the chosen answer\n- Do not repeat the instructions\njs\n  import { openai } from \"@ai-sdk/openai\";\n  import { generateText } from \"ai\";\n\nexport default {\n    async fetch(request, env) {\n      // Parse incoming url\n      const url = new URL(request.url);\n\n// Get the user query or default to a predefined one\n      const userQuery =\n        url.searchParams.get(\"query\") ??\n        \"How do I train a llama to deliver coffee?\";\n\n// Search for documents in AI Search\n      const searchResult = await env.AI.autorag(\"my-rag\").search({\n        query: userQuery,\n      });\n\nif (searchResult.data.length === 0) {\n        // No matching documents\n        return Response.json({ text: `No data found for query \"${userQuery}\"` });\n      }\n\n// Join all document chunks into a single string\n      const chunks = searchResult.data\n        .map((item) => {\n          const data = item.content\n            .map((content) => {\n              return content.text;\n            })\n            .join(\"\\n\\n\");\n\nreturn `<file name=\"${item.filename}\">${data}</file>`;\n        })\n        .join(\"\\n\\n\");\n\n// Send the user query + matched documents to openai for answer\n      const generateResult = await generateText({\n        model: openai(\"gpt-4o-mini\"),\n        messages: [\n          {\n            role: \"system\",\n            content:\n              \"You are a helpful assistant and your task is to answer the user question using the provided files.\",\n          },\n          { role: \"user\", content: chunks },\n          { role: \"user\", content: userQuery },\n        ],\n      });\n\n// Return the generated answer\n      return Response.json({ text: generateResult.text });\n    },\n  };\n  ts\n  import { openai } from \"@ai-sdk/openai\";\n  import { generateText } from \"ai\";\n\nexport interface Env {\n    AI: Ai;\n    OPENAI_API_KEY: string;\n  }\n\nexport default {\n    async fetch(request, env): Promise<Response> {\n      // Parse incoming url\n      const url = new URL(request.url);\n\n// Get the user query or default to a predefined one\n      const userQuery =\n        url.searchParams.get(\"query\") ??\n        \"How do I train a llama to deliver coffee?\";\n\n// Search for documents in AI Search\n      const searchResult = await env.AI.autorag(\"my-rag\").search({\n        query: userQuery,\n      });\n\nif (searchResult.data.length === 0) {\n        // No matching documents\n        return Response.json({ text: `No data found for query \"${userQuery}\"` });\n      }\n\n// Join all document chunks into a single string\n      const chunks = searchResult.data\n        .map((item) => {\n          const data = item.content\n            .map((content) => {\n              return content.text;\n            })\n            .join(\"\\n\\n\");\n\nreturn `<file name=\"${item.filename}\">${data}</file>`;\n        })\n        .join(\"\\n\\n\");\n\n// Send the user query + matched documents to openai for answer\n      const generateResult = await generateText({\n        model: openai(\"gpt-4o-mini\"),\n        messages: [\n          {\n            role: \"system\",\n            content:\n              \"You are a helpful assistant and your task is to answer the user question using the provided files.\",\n          },\n          { role: \"user\", content: chunks },\n          { role: \"user\", content: userQuery },\n        ],\n      });\n\n// Return the generated answer\n      return Response.json({ text: generateResult.text });\n    },\n  } satisfies ExportedHandler<Env>;\n  js\nconst response = await env.AI.autorag(\"my-autorag\").search({\n  query: \"When did I sign my agreement contract?\",\n  filters: {\n    type: \"eq\",\n    key: \"folder\",\n    value: `customer-a/contracts/`,\n  },\n});\njs\nfilters: {\n    type: \"and\",\n    filters: [\n      {\n        type: \"gt\",\n        key: \"folder\",\n        value: \"customer-a//\",\n      },\n      {\n        type: \"lte\",\n        key: \"folder\",\n        value: \"customer-a/z\",\n      },\n    ],\n  },\nhtml\n<!-- Add css on head -->\n    <link rel=\"stylesheet\" href=\"https://ask.example.com/nlweb-dropdown-chat.css\">\n    <link rel=\"stylesheet\" href=\"https://ask.example.com/common-chat-styles.css\">\n\n<!-- Add container on body -->\n    <div id=\"docs-search-container\"></div>\n\n<!-- Include JavaScript -->\n    <script type=\"module\">\n      import { NLWebDropdownChat } from 'https://ask.example.com/nlweb-dropdown-chat.js';\n\nconst chat = new NLWebDropdownChat({\n        containerId: 'docs-search-container',\n        site: 'https://ask.example.com',\n        placeholder: 'Search for docs...',\n        endpoint: 'https://ask.example.com'\n      });\n    </script>\njs\n  export default {\n    async fetch(request, env) {\n      const url = new URL(request.url);\n      const userQuery =\n        url.searchParams.get(\"query\") ??\n        \"How do I train a llama to deliver coffee?\";\n      const searchResult = await env.AI.autorag(\"my-rag\").search({\n        query: userQuery,\n        rewrite_query: false,\n      });\n\nreturn Response.json({\n        files: searchResult.data.map((obj) => obj.filename),\n      });\n    },\n  };\n  ts\n  export interface Env {\n    AI: Ai;\n  }\n\nexport default {\n    async fetch(request, env): Promise<Response> {\n      const url = new URL(request.url);\n      const userQuery =\n        url.searchParams.get(\"query\") ??\n        \"How do I train a llama to deliver coffee?\";\n      const searchResult = await env.AI.autorag(\"my-rag\").search({\n        query: userQuery,\n        rewrite_query: false,\n      });\n\nreturn Response.json({\n        files: searchResult.data.map((obj) => obj.filename),\n      });\n    },\n  } satisfies ExportedHandler<Env>;\n  bash\nnpm create cloudflare@latest -- browser-r2-worker\nbash\nnpm i @cloudflare/puppeteer\nbash\nnpx wrangler r2 bucket create html-bucket\njsonc\n{\n  \"compatibility_flags\": [\"nodejs_compat\"],\n  \"browser\": {\n    \"binding\": \"MY_BROWSER\",\n  },\n  \"r2_buckets\": [\n    {\n      \"binding\": \"HTML_BUCKET\",\n      \"bucket_name\": \"html-bucket\",\n    },\n  ],\n}\njs\n  import puppeteer from \"@cloudflare/puppeteer\";\n\n// Define our environment bindings\n  // Define request body structure\n  export default {\n    async fetch(request, env) {\n      // Only accept POST requests\n      if (request.method !== \"POST\") {\n        return new Response(\"Please send a POST request with a target URL\", {\n          status: 405,\n        });\n      }\n\n// Get URL from request body\n      const body = await request.json();\n      // Note: Only use this parser for websites you own\n      const targetUrl = new URL(body.url);\n\n// Launch browser and create new page\n      const browser = await puppeteer.launch(env.MY_BROWSER);\n      const page = await browser.newPage();\n\n// Navigate to the page and fetch its html\n      await page.goto(targetUrl.href);\n      const htmlPage = await page.content();\n\n// Create filename and store in R2\n      const key = targetUrl.hostname + \"_\" + Date.now() + \".html\";\n      await env.HTML_BUCKET.put(key, htmlPage);\n\n// Close browser\n      await browser.close();\n\n// Return success response\n      return new Response(\n        JSON.stringify({\n          success: true,\n          message: \"Page rendered and stored successfully\",\n          key: key,\n        }),\n        {\n          headers: { \"Content-Type\": \"application/json\" },\n        },\n      );\n    },\n  };\n  ts\n  import puppeteer from \"@cloudflare/puppeteer\";\n\n// Define our environment bindings\n  interface Env {\n    MY_BROWSER: any;\n    HTML_BUCKET: R2Bucket;\n  }\n\n// Define request body structure\n  interface RequestBody {\n    url: string;\n  }\n\nexport default {\n    async fetch(request: Request, env: Env): Promise<Response> {\n      // Only accept POST requests\n      if (request.method !== \"POST\") {\n        return new Response(\"Please send a POST request with a target URL\", {\n          status: 405,\n        });\n      }\n\n// Get URL from request body\n      const body = (await request.json()) as RequestBody;\n      // Note: Only use this parser for websites you own\n      const targetUrl = new URL(body.url);\n\n// Launch browser and create new page\n      const browser = await puppeteer.launch(env.MY_BROWSER);\n      const page = await browser.newPage();\n\n// Navigate to the page and fetch its html\n      await page.goto(targetUrl.href);\n      const htmlPage = await page.content();\n\n// Create filename and store in R2\n      const key = targetUrl.hostname + \"_\" + Date.now() + \".html\";\n      await env.HTML_BUCKET.put(key, htmlPage);\n\n// Close browser\n      await browser.close();\n\n// Return success response\n      return new Response(\n        JSON.stringify({\n          success: true,\n          message: \"Page rendered and stored successfully\",\n          key: key,\n        }),\n        {\n          headers: { \"Content-Type\": \"application/json\" },\n        },\n      );\n    },\n  } satisfies ExportedHandler<Env>;\n  bash\nnpx wrangler deploy\nbash\ncurl -X POST https://browser-r2-worker.<YOUR_SUBDOMAIN>.workers.dev \\\n-H \"Content-Type: application/json\" \\\n-d '{\"url\": \"https://developers.cloudflare.com/ai-search/tutorial/brower-rendering-autorag-tutorial/\"}'\njsonc\n{\n  \"ai\": {\n    \"binding\": \"AI\",\n  },\n}\njavascript\nconst answer = await env.AI.autorag(\"my-rag\").aiSearch({\n  query: \"What is AI Search?\",\n});\nbash\ncurl https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/autorag/rags/{AUTORAG_NAME}/ai-search \\\n-H 'Content-Type: application/json' \\\n-H \"Authorization: Bearer {API_TOKEN}\" \\\n-d '{\n  \"query\": \"How do I train a llama to deliver coffee?\",\n  \"model\": @cf/meta/llama-3.3-70b-instruct-fp8-fast,\n  \"rewrite_query\": false,\n  \"max_num_results\": 10,\n  \"ranking_options\": {\n    \"score_threshold\": 0.3,\n  },\n  \"reranking\": {\n    \"enabled\": true,\n      \"model\": \"@cf/baai/bge-reranker-base\"\n  },\n  \"stream\": true,\n}'\nsh\n{\n  \"success\": true,\n  \"result\": {\n    \"object\": \"vector_store.search_results.page\",\n    \"search_query\": \"How do I train a llama to deliver coffee?\",\n    \"response\": \"To train a llama to deliver coffee:\\n\\n1. **Build trust** — Llamas appreciate patience (and decaf).\\n2. **Know limits** — Max 3 cups per llama, per `llama-logistics.md`.\\n3. **Use voice commands** — Start with \\\"Espresso Express!\\\"\\n4.\",\n    \"data\": [\n      {\n        \"file_id\": \"llama001\",\n        \"filename\": \"llama/logistics/llama-logistics.md\",\n        \"score\": 0.45,\n        \"attributes\": {\n          \"modified_date\": 1735689600000,   // unix timestamp for 2025-01-01\n          \"folder\": \"llama/logistics/\",\n        },\n        \"content\": [\n          {\n            \"id\": \"llama001\",\n            \"type\": \"text\",\n            \"text\": \"Llamas can carry 3 drinks max.\"\n          }\n        ]\n      },\n      {\n        \"file_id\": \"llama042\",\n        \"filename\": \"llama/llama-commands.md\",\n        \"score\": 0.4,\n        \"attributes\": {\n          \"modified_date\": 1735689600000,   // unix timestamp for 2025-01-01\n          \"folder\": \"llama/\",\n        },\n        \"content\": [\n          {\n            \"id\": \"llama042\",\n            \"type\": \"text\",\n            \"text\": \"Start with basic commands like 'Espresso Express!' Llamas love alliteration.\"\n          }\n        ]\n      },\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n  }\n}\nbash\ncurl https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/autorag/rags/{AUTORAG_NAME}/search \\\n-H 'Content-Type: application/json' \\\n-H \"Authorization: Bearer {API_TOKEN}\" \\\n-d '{\n  \"query\": \"How do I train a llama to deliver coffee?\",\n  \"rewrite_query\": true,\n  \"max_num_results\": 10,\n  \"ranking_options\": {\n    \"score_threshold\": 0.3,\n  },\n  \"reranking\": {\n    \"enabled\": true,\n      \"model\": \"@cf/baai/bge-reranker-base\"\n  }'\nsh\n{\n  \"success\": true,\n  \"result\": {\n    \"object\": \"vector_store.search_results.page\",\n    \"search_query\": \"How do I train a llama to deliver coffee?\",\n    \"data\": [\n      {\n        \"file_id\": \"llama001\",\n        \"filename\": \"llama/logistics/llama-logistics.md\",\n        \"score\": 0.45,\n        \"attributes\": {\n          \"modified_date\": 1735689600000,   // unix timestamp for 2025-01-01\n          \"folder\": \"llama/logistics/\",\n        },\n        \"content\": [\n          {\n            \"id\": \"llama001\",\n            \"type\": \"text\",\n            \"text\": \"Llamas can carry 3 drinks max.\"\n          }\n        ]\n      },\n      {\n        \"file_id\": \"llama042\",\n        \"filename\": \"llama/llama-commands.md\",\n        \"score\": 0.4,\n        \"attributes\": {\n          \"modified_date\": 1735689600000,   // unix timestamp for 2025-01-01\n          \"folder\": \"llama/\",\n        },\n        \"content\": [\n          {\n            \"id\": \"llama042\",\n            \"type\": \"text\",\n            \"text\": \"Start with basic commands like 'Espresso Express!' Llamas love alliteration.\"\n          }\n        ]\n      },\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n  }\n}\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"ai\": {\n      \"binding\": \"AI\"\n    }\n  }\n  toml\n  [ai]\n  binding = \"AI\" # i.e. available in your Worker on env.AI\n  js\nconst answer = await env.AI.autorag(\"my-autorag\").aiSearch({\n  query: \"How do I train a llama to deliver coffee?\",\n  model: \"@cf/meta/llama-3.3-70b-instruct-fp8-fast\",\n  rewrite_query: true,\n  max_num_results: 2,\n  ranking_options: {\n    score_threshold: 0.3\n  },\n  reranking: {\n    enabled: true,\n    model: \"@cf/baai/bge-reranker-base\"\n  },\n  stream: true,\n});\nsh\n{\n    \"object\": \"vector_store.search_results.page\",\n    \"search_query\": \"How do I train a llama to deliver coffee?\",\n    \"response\": \"To train a llama to deliver coffee:\\n\\n1. **Build trust** — Llamas appreciate patience (and decaf).\\n2. **Know limits** — Max 3 cups per llama, per `llama-logistics.md`.\\n3. **Use voice commands** — Start with \\\"Espresso Express!\\\"\\n4.\",\n    \"data\": [\n      {\n        \"file_id\": \"llama001\",\n        \"filename\": \"llama/logistics/llama-logistics.md\",\n        \"score\": 0.45,\n        \"attributes\": {\n          \"modified_date\": 1735689600000,   // unix timestamp for 2025-01-01\n          \"folder\": \"llama/logistics/\",\n        },\n        \"content\": [\n          {\n            \"id\": \"llama001\",\n            \"type\": \"text\",\n            \"text\": \"Llamas can carry 3 drinks max.\"\n          }\n        ]\n      },\n      {\n        \"file_id\": \"llama042\",\n        \"filename\": \"llama/llama-commands.md\",\n        \"score\": 0.4,\n        \"attributes\": {\n          \"modified_date\": 1735689600000,   // unix timestamp for 2025-01-01\n          \"folder\": \"llama/\",\n        },\n        \"content\": [\n          {\n            \"id\": \"llama042\",\n            \"type\": \"text\",\n            \"text\": \"Start with basic commands like 'Espresso Express!' Llamas love alliteration.\"\n          }\n        ]\n      },\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\njs\nconst answer = await env.AI.autorag(\"my-autorag\").search({\n  query: \"How do I train a llama to deliver coffee?\",\n  rewrite_query: true,\n  max_num_results: 2,\n  ranking_options: {\n    score_threshold: 0.3\n  },\n  reranking: {\n    enabled: true,\n    model: \"@cf/baai/bge-reranker-base\"\n  }\n});\nsh\n{\n    \"object\": \"vector_store.search_results.page\",\n    \"search_query\": \"How do I train a llama to deliver coffee?\",\n    \"data\": [\n      {\n        \"file_id\": \"llama001\",\n        \"filename\": \"llama/logistics/llama-logistics.md\",\n        \"score\": 0.45,\n        \"attributes\": {\n          \"modified_date\": 1735689600000,   // unix timestamp for 2025-01-01\n          \"folder\": \"llama/logistics/\",\n        },\n        \"content\": [\n          {\n            \"id\": \"llama001\",\n            \"type\": \"text\",\n            \"text\": \"Llamas can carry 3 drinks max.\"\n          }\n        ]\n      },\n      {\n        \"file_id\": \"llama042\",\n        \"filename\": \"llama/llama-commands.md\",\n        \"score\": 0.4,\n        \"attributes\": {\n          \"modified_date\": 1735689600000,   // unix timestamp for 2025-01-01\n          \"folder\": \"llama/\",\n        },\n        \"content\": [\n          {\n            \"id\": \"llama042\",\n            \"type\": \"text\",\n            \"text\": \"Start with basic commands like 'Espresso Express!' Llamas love alliteration.\"\n          }\n        ]\n      },\n    ],\n    \"has_more\": false,\n    \"next_page\": null\n}\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"analytics_engine_datasets\": [\n      {\n        \"binding\": \"<BINDING_NAME>\",\n        \"dataset\": \"<DATASET_NAME>\"\n      }\n    ]\n  }\n  toml\n  [[analytics_engine_datasets]]\n  binding = \"<BINDING_NAME>\"\n  dataset = \"<DATASET_NAME>\"\n  js\nasync fetch(request, env) {\n  env.WEATHER.writeDataPoint({\n    'blobs': [\"Seattle\", \"USA\", \"pro_sensor_9000\"], // City, State\n    'doubles': [25, 0.5],\n    'indexes': [\"a3cd45\"]\n  });\n  return new Response(\"OK!\");\n}\nsql\nSELECT\n  blob1 AS city,\n  SUM(_sample_interval * double2) / SUM(_sample_interval) AS avg_humidity\nFROM WEATHER\nWHERE double1 > 0\nGROUP BY city\nORDER BY avg_humidity DESC\nLIMIT 10\nbash\ncurl \"https://api.cloudflare.com/client/v4/accounts/{account_id}/analytics_engine/sql\" \\\n--header \"Authorization: Bearer <API_TOKEN>\" \\\n--data \"SELECT blob1 AS city, SUM(_sample_interval * double2) / SUM(_sample_interval) AS avg_humidity FROM WEATHER WHERE double1 > 0 GROUP BY city ORDER BY avg_humidity DESC LIMIT 10\"\nsql\nSELECT\n  intDiv(toUInt32(timestamp), 300) * 300 AS t,\n  blob1 AS city,\n  SUM(_sample_interval * double2) / SUM(_sample_interval) AS avg_humidity\nFROM WEATHER\nWHERE\n  timestamp >= NOW() - INTERVAL '1' DAY\n  AND double1 > 0\nGROUP BY t, city\nORDER BY t, avg_humidity DESC\nsql\nSELECT\n    intDiv(toUInt32(timestamp), 60) * 60 AS t,\n    blob1 AS label,\n    SUM(_sample_interval * double1) / SUM(_sample_interval) AS average_metric\nFROM dataset_name\nWHERE\n    timestamp <= NOW()\n    AND timestamp > NOW() - INTERVAL '1' DAY\nGROUP BY blob1, t\nORDER BY t\nsql\nSELECT\n    $timeSeries AS t,\n    blob1 AS label,\n    SUM(_sample_interval * double1) / SUM(_sample_interval) AS average_metric\nFROM dataset_name\nWHERE $timeFilter\nGROUP BY blob1, t\nORDER BY t\nbash\ncurl \"https://api.cloudflare.com/client/v4/accounts/{account_id}/analytics_engine/sql\" \\\n--header \"Authorization: Bearer <API_TOKEN>\" \\\n--data \"SELECT 'Hello Workers Analytics Engine' AS message\"\nbash\ncurl \"https://api.cloudflare.com/client/v4/accounts/{account_id}/analytics_engine/sql\" \\\n--header \"Authorization: Bearer <API_TOKEN>\" \\\n--data \"SHOW TABLES\"\nsql\nSELECT\n    timestamp,\n    blob1 AS location_id,\n    double1 AS inside_temp,\n    double2 AS outside_temp\nFROM temperatures\nWHERE timestamp > NOW() - INTERVAL '1' DAY\nsql\nSELECT\n    index1 AS location_id,\n    SUM(_sample_interval) AS n_readings\nFROM temperatures\nWHERE timestamp > NOW() - INTERVAL '7' DAY\nGROUP BY index1\nsql\nSELECT\n    index1 AS location_id,\n    SUM(_sample_interval * double1) / SUM(_sample_interval) AS average_temp\nFROM temperatures\nWHERE timestamp > NOW() - INTERVAL '7' DAY\nGROUP BY index1\njs\nconst query = \"SELECT * FROM my_dataset\";\nconst API = `https://api.cloudflare.com/client/v4/accounts/${env.ACCOUNT_ID}/analytics_engine/sql`;\nconst response = await fetch(API, {\n  method: \"POST\",\n  headers: {\n    Authorization: `Bearer ${env.API_TOKEN}`,\n  },\n  body: query,\n});\nconst responseJSON = await response.json();\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"vars\": {\n      \"ACCOUNT_ID\": \"<account_id>\"\n    }\n  }\n  toml\n  [vars]\n  ACCOUNT_ID = \"<account_id>\"\n  sh\nnpx wrangler secret put API_TOKEN\njs\nexport default {\n  async fetch(request, env) {\n    // This worker only responds to requests at the root.\n    if (new URL(request.url).pathname != \"/\") {\n      return new Response(\"Not found\", { status: 404 });\n    }\n\n// SQL string to be executed.\n    const query = `\n            SELECT\n                blob1 AS city,\n                max(double1) as max_temp,\n                min(double1) as min_temp\n            FROM weather\n            WHERE timestamp > NOW() - INTERVAL '1' DAY\n            GROUP BY city\n            ORDER BY city`;\n\n// Build the API endpoint URL and make a POST request with the query string\n    const API = `https://api.cloudflare.com/client/v4/accounts/${env.ACCOUNT_ID}/analytics_engine/sql`;\n    const queryResponse = await fetch(API, {\n      method: \"POST\",\n      headers: {\n        Authorization: `Bearer ${env.API_TOKEN}`,\n      },\n      body: query,\n    });\n\n// The API will return a 200 status code if the query succeeded.\n    // In case of failure we log the error message and return a failure message.\n    if (queryResponse.status != 200) {\n      console.error(\"Error querying:\", await queryResponse.text());\n      return new Response(\"An error occurred!\", { status: 500 });\n    }\n\n// Read the JSON data from the query response and render the data as HTML.\n    const queryJSON = await queryResponse.json();\n    return new Response(renderResponse(queryJSON.data), {\n      headers: { \"content-type\": \"text/html\" },\n    });\n  },\n};\n\n// renderCity renders a table row as HTML from a data row.\nfunction renderCity(row) {\n  return `<tr><td>${row.city}</td><td>${row.min_temp}</td><td>${row.max_temp}</td></tr>`;\n}\n\n// renderResponse renders a simple HTML table of results.\nfunction renderResponse(data) {\n  return `<!DOCTYPE html>\n<html>\n    <body>\n        <table>\n            <tr><th>City</th><th>Min Temp</th><th>Max Temp</th></tr>\n            ${data.map(renderCity).join(\"\\n\")}\n        </table>\n    </body>\n<html>`;\n}\njson\n{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"Policy\",\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"logs:CreateLogGroup\"\n        \"s3:GetObject\",\n        \"logs:CreateLogStream\",\n        \"logs:PutLogEvents\"\n      ],\n      \"Resource\": [\n        \"arn:aws:logs:your-region:your-account-number:*\",\n        \"arn:aws:s3:your-region::cloudflare-bucket-name/*\"\n      ]\n    }\n  ]\n}\nsql\n\"<protocol>://input-<host>:<port>/<endpoint>\" or \"<protocol>://http-inputs-<host>:<port>/<endpoint>\"\ngraphql\ndatetime_geq: \"2024-09-01T00:00:00Z\"\ndatetime_lt: \"2024-10-01T00:00:00Z\"\ngraphql\ndatetime_geq: \"2024-09-01T00:00:00Z\"\ndatetime_lt: \"2024-09-02T00:00:00Z\"\ngraphql\norderBy: [datetime_ASC]\ngraphql\nconfidence(level: 0.95) {\n  count {\n    estimate\n    lower\n    upper\n    sampleSize\n  }\n}\njson\n{\n  \"data\": null,\n  \"errors\": [\n    {\n      \"message\": \"cannot request data older than 2678400s\",\n      \"path\": [\"viewer\", \"zones\", \"0\", \"firewallEventsAdaptiveGroups\"],\n      \"extensions\": {\n        \"timestamp\": \"2019-12-09T21:27:19.195060142Z\"\n      }\n    }\n  ]\n}\ntxt\n{hostVar1}.example.com\n\nfoo.{hostVar1}.example.com\n\n{hostVar2}.{hostVar1}.example.com\ntxt\nfoo-{hostVar1}.example.com\ntf\nresource \"cloudflare_api_shield\" \"session_identifiers\" {\n  zone_id = var.zone_id\n  auth_id_characteristics = [{\n    name = \"authorization\"\n    type = \"header\"\n  }]\n}\ntf\nresource \"cloudflare_api_shield_operation\" \"get_image\" {\n  zone_id  = var.zone_id\n  method   = \"GET\"\n  host     = \"example.com\"\n  endpoint = \"/api/images/{var1}\"\n}\n\nresource \"cloudflare_api_shield_operation\" \"post_image\" {\n  zone_id  = var.zone_id\n  method   = \"POST\"\n  host     = \"example.com\"\n  endpoint = \"/api/images/{var1}\"\n}\ntf",
  "code_samples": [
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "Review the [documentation on testing](https://developers.cloudflare.com/workers/testing/vitest-integration/write-your-first-test/) for additional examples and test configuration.\n\n## Running Agents locally\n\nYou can also run an Agent locally using the `wrangler` CLI:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "This spins up a local development server that runs the same runtime as Cloudflare Workers, and allows you to iterate on your Agent's code and test it locally without deploying it.\n\nVisit the [`wrangler dev`](https://developers.cloudflare.com/workers/wrangler/commands/#dev) docs to review the CLI flags and configuration options.\n\n</page>\n\n<page>\n---\ntitle: Implement Effective Agent Patterns · Cloudflare Agents docs\ndescription: Implement common agent patterns using the Agents SDK framework.\nlastUpdated: 2025-12-03T14:53:41.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/agents/guides/anthropic-agent-patterns/\n  md: https://developers.cloudflare.com/agents/guides/anthropic-agent-patterns/index.md\n---\n\n\n</page>\n\n<page>\n---\ntitle: Build a Remote MCP Client · Cloudflare Agents docs\ndescription: Build an AI Agent that acts as a remote MCP client.\nlastUpdated: 2025-04-09T15:16:54.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/agents/guides/build-mcp-client/\n  md: https://developers.cloudflare.com/agents/guides/build-mcp-client/index.md\n---\n\n\n</page>\n\n<page>\n---\ntitle: Build an Interactive ChatGPT App · Cloudflare Agents docs\ndescription: \"This guide will show you how to build and deploy an interactive\n  ChatGPT App on Cloudflare Workers that can:\"\nlastUpdated: 2025-11-07T18:20:42.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/agents/guides/chatgpt-app/\n  md: https://developers.cloudflare.com/agents/guides/chatgpt-app/index.md\n---\n\n## Deploy your first ChatGPT App\n\nThis guide will show you how to build and deploy an interactive ChatGPT App on Cloudflare Workers that can:\n\n* Render rich, interactive UI widgets directly in ChatGPT conversations\n* Maintain real-time, multi-user state using Durable Objects\n* Enable bidirectional communication between your app and ChatGPT\n* Build multiplayer experiences that run entirely within ChatGPT\n\nYou will build a real-time multiplayer chess game that demonstrates these capabilities. Players can start or join games, make moves on an interactive chessboard, and even ask ChatGPT for strategic advice—all without leaving the conversation.\n\nYour ChatGPT App will use the **Model Context Protocol (MCP)** to expose tools and UI resources that ChatGPT can invoke on your behalf.\n\nYou can view the full code for this example [here](https://github.com/cloudflare/agents/tree/main/openai-sdk/chess-app).\n\n## Prerequisites\n\nBefore you begin, you will need:\n\n* A [Cloudflare account](https://dash.cloudflare.com/sign-up)\n* [Node.js](https://nodejs.org/) installed (v18 or later)\n* A [ChatGPT Plus or Team account](https://chat.openai.com/) with developer mode enabled\n* Basic knowledge of React and TypeScript\n\n## 1. Enable ChatGPT Developer Mode\n\nTo use ChatGPT Apps (also called connectors), you need to enable developer mode:\n\n1. Open [ChatGPT](https://chat.openai.com/).\n2. Go to **Settings** > **Apps & Connectors** > **Advanced Settings**\n3. Toggle **Developer mode ON**\n\nOnce enabled, you will be able to install custom apps during development and testing.\n\n## 2. Create your ChatGPT App project\n\n1. Create a new project for your Chess App:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "1. Navigate into your project:",
      "language": "unknown"
    },
    {
      "code": "1. Install the required dependencies:",
      "language": "unknown"
    },
    {
      "code": "1. Install development dependencies:",
      "language": "unknown"
    },
    {
      "code": "## 3. Configure your project\n\n1. Update your `wrangler.jsonc` to configure Durable Objects and assets:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "1. Create a `vite.config.ts` for building your React UI:",
      "language": "unknown"
    },
    {
      "code": "1. Update your `package.json` scripts:",
      "language": "unknown"
    },
    {
      "code": "## 4. Create the Chess game engine\n\n1. Create the game logic using Durable Objects at `src/chess.tsx`:",
      "language": "unknown"
    },
    {
      "code": "## 5. Create the MCP server and UI resource\n\n1. Create your main worker at `src/index.ts`:",
      "language": "unknown"
    },
    {
      "code": "## 6. Build the React UI\n\n1. Create the HTML entry point at `index.html`:",
      "language": "unknown"
    },
    {
      "code": "1. Create the React app at `src/app.tsx`:",
      "language": "unknown"
    },
    {
      "code": "Note\n\nThis is a simplified version of the UI. For the complete implementation with player slots, better styling, and game state management, check out the [full example on GitHub](https://github.com/cloudflare/agents/tree/main/openai-sdk/chess-app/src/app.tsx).\n\n## 7. Build and deploy\n\n1. Build your React UI:",
      "language": "unknown"
    },
    {
      "code": "This compiles your React app into a single HTML file in the `dist` directory.\n\n1. Deploy to Cloudflare:",
      "language": "unknown"
    },
    {
      "code": "After deployment, you will see your app URL:",
      "language": "unknown"
    },
    {
      "code": "## 8. Connect to ChatGPT\n\nNow connect your deployed app to ChatGPT:\n\n1. Open [ChatGPT](https://chat.openai.com/).\n2. Go to **Settings** > **Apps & Connectors** > **Create**\n3. Give your app a **name**, and optionally a **description** and **icon**.\n4. Enter your MCP endpoint: `https://my-chess-app.YOUR_SUBDOMAIN.workers.dev/mcp`.\n5. Select **\"No authentication\"**.\n6. Select **\"Create\"**.\n\n## 9. Play chess in ChatGPT\n\nTry it out:\n\n1. In your ChatGPT conversation, type: \"Let's play chess\".\n2. ChatGPT will call the `playChess` tool and render your interactive chess widget.\n3. Select **\"Start a new game\"** to create a game.\n4. Share the game ID with a friend who can join via their own ChatGPT conversation.\n5. Make moves by dragging pieces on the board.\n6. Select **\"Ask for help\"** to get strategic advice from ChatGPT\n\nNote\n\nYou might need to manually select the connector in the prompt box the first time you use it. Select **\"+\"** > **\"More\"** > **\\[App name]**.\n\n## Key concepts\n\n### MCP Server\n\nThe Model Context Protocol (MCP) server defines tools and resources that ChatGPT can access:",
      "language": "unknown"
    },
    {
      "code": "### Game Engine with Agents\n\nThe `ChessGame` class extends `Agent` to create a stateful game engine:",
      "language": "unknown"
    },
    {
      "code": "Each game gets its own Agent instance, enabling:\n\n* **Isolated state** per game\n* **Real-time synchronization** across players\n* **Persistent storage** that survives worker restarts\n\n### Callable methods\n\nUse the `@callable()` decorator to expose methods that clients can invoke:",
      "language": "unknown"
    },
    {
      "code": "### React integration\n\nThe `useAgent` hook connects your React app to the Durable Object:",
      "language": "unknown"
    },
    {
      "code": "Call methods on the agent:",
      "language": "unknown"
    },
    {
      "code": "### Bidirectional communication\n\nYour app can send messages to ChatGPT:",
      "language": "unknown"
    },
    {
      "code": "This creates a new message in the ChatGPT conversation with context about the current game state.\n\n## Next steps\n\nNow that you have a working ChatGPT App, you can:\n\n* Add more tools: Expose additional capabilities and UIs through MCP tools and resources.\n* Enhance the UI: Build more sophisticated interfaces with React.\n\n## Related resources\n\n* [Agents documentation](https://developers.cloudflare.com/agents/api-reference/agents-api)\n* [Durable Objects documentation](https://developers.cloudflare.com/durable-objects/)\n* [Model Context Protocol (MCP)](https://modelcontextprotocol.io/)\n* [OpenAI Apps SDK Reference](https://developers.openai.com/apps-sdk/)\n\n</page>\n\n<page>\n---\ntitle: Connect to an MCP server · Cloudflare Agents docs\ndescription: Your Agent can connect to external Model Context Protocol (MCP)\n  servers to access their tools and extend your Agent's capabilities. In this\n  tutorial, you'll create an Agent that connects to an MCP server and uses one\n  of its tools.\nlastUpdated: 2025-11-04T18:23:20.000Z\nchatbotDeprioritize: false\ntags: MCP\nsource_url:\n  html: https://developers.cloudflare.com/agents/guides/connect-mcp-client/\n  md: https://developers.cloudflare.com/agents/guides/connect-mcp-client/index.md\n---\n\nYour Agent can connect to external [Model Context Protocol (MCP)](https://modelcontextprotocol.io) servers to access their tools and extend your Agent's capabilities. In this tutorial, you'll create an Agent that connects to an MCP server and uses one of its tools.\n\n## What you will build\n\nAn Agent with endpoints to:\n\n* Connect to an MCP server\n* List available tools from connected servers\n* Get the connection status\n\n## Prerequisites\n\nAn MCP server to connect to (or use the public example in this tutorial).\n\n## 1. Create a basic Agent\n\n1. Create a new Agent project using the `hello-world` template:\n\n   * npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "2. Move into the project directory:",
      "language": "unknown"
    },
    {
      "code": "Your Agent is ready! The template includes a minimal Agent in `src/index.ts`:\n\n   * JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "## 2. Add MCP connection endpoint\n\n1. Add an endpoint to connect to MCP servers. Update your Agent class in `src/index.ts`:\n\n   * JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "The `addMcpServer()` method connects to an MCP server. If the server requires OAuth authentication, it returns an `authUrl` that users must visit to complete authorization.\n\n## 3. Test the connection\n\n1. Start your development server:",
      "language": "unknown"
    },
    {
      "code": "2. In a new terminal, connect to an MCP server (using a public example):",
      "language": "unknown"
    },
    {
      "code": "You should see a response with the server ID:",
      "language": "unknown"
    },
    {
      "code": "## 4. List available tools\n\n1. Add an endpoint to see which tools are available from connected servers:\n\n   * JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "2. Test it:",
      "language": "unknown"
    },
    {
      "code": "You'll see all connected servers, their connection states, and available tools:",
      "language": "unknown"
    },
    {
      "code": "## Summary\n\nYou created an Agent that can:\n\n* Connect to external MCP servers dynamically\n* Handle OAuth authentication flows when required\n* List all available tools from connected servers\n* Monitor connection status\n\nConnections persist in the Agent's [SQL storage](https://developers.cloudflare.com/agents/api-reference/store-and-sync-state/), so they remain active across requests.\n\n## Next steps\n\n* [Handle OAuth flows](https://developers.cloudflare.com/agents/guides/oauth-mcp-client) — Configure OAuth callbacks and error handling\n* [McpClient — API reference](https://developers.cloudflare.com/agents/model-context-protocol/mcp-client-api/) — Complete API documentation\n\n</page>\n\n<page>\n---\ntitle: Build a Human-in-the-loop Agent · Cloudflare Agents docs\ndescription: Implement human-in-the-loop functionality using Cloudflare Agents,\n  allowing AI agents to request human approval before executing certain actions\nlastUpdated: 2025-12-02T14:54:33.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/agents/guides/human-in-the-loop/\n  md: https://developers.cloudflare.com/agents/guides/human-in-the-loop/index.md\n---\n\n## Build an AI Agent with Human Oversight\n\nThis guide will show you how to build and deploy an AI agent on Cloudflare Workers that implements human-in-the-loop functionality, allowing AI agents to request human approval before executing certain actions.\n\nYour Human-in-the-Loop Agent will be able to:\n\n* Request human approval for sensitive tool executions\n* Stream real-time responses using WebSocket connections\n* Persist conversation state across sessions\n* Differentiate between automatic and confirmation-required tools\n\nThis pattern is crucial for scenarios where human oversight and confirmation are required before taking important actions like making purchases, sending emails, or modifying data.\n\nYou can view the full code for this example [here](https://github.com/cloudflare/agents/tree/main/guides/human-in-the-loop).\n\n## Prerequisites\n\nBefore you begin, you will need:\n\n* A [Cloudflare account](https://dash.cloudflare.com/sign-up)\n* [Node.js](https://nodejs.org/) installed (v18 or later)\n* An [OpenAI API key](https://platform.openai.com/api-keys) (or another LLM provider)\n\n## 1. Create your project\n\n1. Create a new project for your Human-in-the-Loop Agent:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "1. Navigate into your project:",
      "language": "unknown"
    },
    {
      "code": "1. Install the required dependencies:",
      "language": "unknown"
    },
    {
      "code": "## 2. Set up your environment variables\n\n1. Create a `.dev.vars` file in your project root for local development secrets:",
      "language": "unknown"
    },
    {
      "code": "1. Add your credentials to `.dev.vars`:",
      "language": "unknown"
    },
    {
      "code": "1. Update your `wrangler.toml` to configure your Agent:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "## 3. Define your tools\n\nCreate your tool definitions at `src/tools.ts`. Tools can be configured to either require human confirmation or execute automatically:",
      "language": "unknown"
    },
    {
      "code": "Note\n\nTools **without** an `execute` function require human approval before they can run. The server will handle execution after the user confirms. Tools **with** an `execute` function can either run automatically or require confirmation based on your configuration.\n\n## 4. Create utility functions\n\nCreate helper functions at `src/utils.ts` to handle tool confirmations and processing:",
      "language": "unknown"
    },
    {
      "code": "## 5. Create your Agent\n\nCreate your agent implementation at `src/server.ts`:",
      "language": "unknown"
    },
    {
      "code": "## 6. Build the React frontend\n\nCreate your React chat interface at `src/app.tsx`:",
      "language": "unknown"
    },
    {
      "code": "## 7. Test locally\n\nStart your development server:",
      "language": "unknown"
    },
    {
      "code": "Your agent is now running at `http://localhost:8787`.\n\n### Test the approval flow\n\n1. Open `http://localhost:8787` in your browser.\n2. Ask the agent about the weather: \"What's the weather in San Francisco?\"\n3. The agent will attempt to call the `getWeatherInformation` tool.\n4. You will see an approval prompt with **Approve** and **Reject** buttons.\n5. Click **Approve** to allow the tool execution, or **Reject** to deny it.\n6. The agent will respond with the result or acknowledge the rejection.\n\n### Test automatic tools\n\n1. Ask the agent for news: \"What's the news in London?\"\n2. The `getLocalNews` tool will execute automatically without requiring approval.\n\n## 8. Deploy to production\n\n1. Before deploying, add your secrets to Cloudflare:",
      "language": "unknown"
    },
    {
      "code": "1. Build and deploy your agent:",
      "language": "unknown"
    },
    {
      "code": "After deploying, you will get a production URL like:",
      "language": "unknown"
    },
    {
      "code": "## How it works\n\n### Tool approval flow\n\nThe human-in-the-loop pattern works by intercepting tool calls before execution:\n\n1. **Tool invocation**: The AI decides to call a tool based on user input.\n2. **Approval check**: The system checks if the tool requires human confirmation.\n3. **Confirmation prompt**: If approval is required, the UI displays the tool name and arguments with Approve/Reject buttons.\n4. **User decision**: The user reviews the action and makes a decision.\n5. **Execution or rejection**: Based on the user's choice, the tool either executes or returns a rejection message.\n\n### Message streaming with confirmations\n\nThe agent uses the Vercel AI SDK's streaming capabilities:\n\n* `createUIMessageStream` creates a stream for processing tool confirmations.\n* `streamText` handles normal AI responses with tool calls.\n* The `hasToolConfirmation` function detects when a message contains a tool confirmation response.\n\n### State persistence\n\nYour agent uses [Durable Objects](https://developers.cloudflare.com/durable-objects/) to maintain conversation state:\n\n* Conversation history persists across browser refreshes.\n* Each agent instance has isolated storage.\n* Tool confirmation states are tracked in the message history.\n\n## Customizing your agent\n\n### Add more tools requiring confirmation\n\nAdd new tools to the `toolsRequiringConfirmation` array in `src/utils.ts`:",
      "language": "unknown"
    },
    {
      "code": "### Implement custom tool handlers\n\nFor server-side tools requiring confirmation, add execute functions in your agent:",
      "language": "unknown"
    },
    {
      "code": "### Customize the approval UI\n\nEnhance the confirmation interface with more context:",
      "language": "unknown"
    },
    {
      "code": "### Use different LLM providers\n\nReplace OpenAI with [Workers AI](https://developers.cloudflare.com/workers-ai/):",
      "language": "unknown"
    },
    {
      "code": "## Best practices\n\n* **Define clear approval workflows** — Only require confirmation for actions with meaningful consequences (payments, emails, data changes).\n* **Provide detailed context** — Show users exactly what the tool will do, including all arguments.\n* **Implement timeouts** — Consider auto-rejecting tools after a reasonable timeout period.\n* **Handle connection drops** — Ensure the UI can recover if the WebSocket connection is interrupted.\n* **Log all decisions** — Track approval/rejection decisions for audit trails.\n* **Graceful degradation** — Provide fallback behavior if tools are rejected.\n\n## Next steps\n\n* Add [email notifications](https://developers.cloudflare.com/email-routing/email-workers/send-email-workers/) for pending approvals\n* Implement approval timeouts with [Schedules](https://developers.cloudflare.com/agents/api-reference/schedule-tasks)\n* Connect your Agent to an [MCP server](https://developers.cloudflare.com/agents/model-context-protocol/mcp-client-api/)\n* Add [analytics](https://developers.cloudflare.com/analytics/analytics-engine/) to track approval patterns\n* Implement multi-user approval workflows\n\n## Related resources\n\n* [Agents Framework documentation](https://developers.cloudflare.com/agents/)\n* [Durable Objects documentation](https://developers.cloudflare.com/durable-objects/)\n* [Vercel AI SDK documentation](https://sdk.vercel.ai/docs)\n* [OpenAI API documentation](https://platform.openai.com/docs/)\n\n</page>\n\n<page>\n---\ntitle: Handle OAuth with MCP servers · Cloudflare Agents docs\ndescription: When connecting to OAuth-protected MCP servers (like Slack or\n  Notion), your users need to authenticate before your Agent can access their\n  data. This guide covers implementing OAuth flows for seamless authorization.\nlastUpdated: 2025-12-03T18:59:32.000Z\nchatbotDeprioritize: false\ntags: MCP\nsource_url:\n  html: https://developers.cloudflare.com/agents/guides/oauth-mcp-client/\n  md: https://developers.cloudflare.com/agents/guides/oauth-mcp-client/index.md\n---\n\nWhen connecting to OAuth-protected MCP servers (like Slack or Notion), your users need to authenticate before your Agent can access their data. This guide covers implementing OAuth flows for seamless authorization.\n\n## How it works\n\n1. Call `addMcpServer()` with the server URL\n2. If OAuth is required, an `authUrl` is returned instead of connecting immediately\n3. Present the `authUrl` to your user (redirect, popup, or link)\n4. User authenticates on the provider's site\n5. Provider redirects back to your Agent's callback URL\n6. Your Agent completes the connection automatically\n\nThe MCP client uses a built-in `DurableObjectOAuthClientProvider` to manage OAuth state securely — storing a nonce and server ID, validating on callback, and cleaning up after use or expiration.\n\n## Initiate OAuth\n\nWhen connecting to an OAuth-protected server, check if `authUrl` is returned. If present, redirect your user to complete authorization:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "### Alternative approaches\n\nInstead of an automatic redirect, you can present the `authUrl` to your user as a:\n\n* **Popup window**: `window.open(authUrl, '_blank', 'width=600,height=700')` for dashboard-style apps\n* **Clickable link**: Display as a button or link for multi-step flows\n* **Deep link**: Use custom URL schemes for mobile apps\n\n## Configure callback behavior\n\nAfter OAuth completes, the provider redirects back to your Agent's callback URL. Configure what happens next.\n\n### Redirect to your application\n\nRedirect users back to your application after OAuth completes:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Users return to `/dashboard` on success or `/auth-error?error=<message>` on failure.\n\n### Close popup window\n\nIf you opened OAuth in a popup, close it automatically when complete:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Your main application can detect the popup closing and refresh the connection status.\n\n## Monitor connection status\n\n### React applications\n\nUse the `useAgent` hook for real-time updates via WebSocket:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "The `onMcpUpdate` callback fires automatically when MCP state changes — no polling needed.\n\n### Other frameworks\n\nPoll the connection status via an endpoint:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Connection states flow: `authenticating` (needs OAuth) → `connecting` (completing setup) → `ready` (available for use)\n\n## Handle failures\n\nWhen OAuth fails, the connection state becomes `\"failed\"`. Detect this in your UI and allow users to retry:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Common failure reasons:\n\n* **User canceled**: Closed OAuth window before completing authorization\n* **Invalid credentials**: Provider credentials were incorrect\n* **Permission denied**: User lacks required permissions\n* **Expired session**: OAuth session timed out\n\nFailed connections remain in state until removed with `removeMcpServer(serverId)`.\n\n## Complete example\n\nThis example demonstrates a complete OAuth integration with Cloudflare Observability. Users connect, authorize in a popup window, and the connection becomes available.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "## Related\n\n* [Connect to an MCP server](https://developers.cloudflare.com/agents/guides/connect-mcp-client) — Get started (no OAuth)\n* [MCP Client API reference](https://developers.cloudflare.com/agents/model-context-protocol/mcp-client-api/)\n\n</page>\n\n<page>\n---\ntitle: Build a Remote MCP server · Cloudflare Agents docs\ndescription: \"This guide will show you how to deploy your own remote MCP server\n  on Cloudflare, with two options:\"\nlastUpdated: 2025-10-08T16:13:27.000Z\nchatbotDeprioritize: false\ntags: MCP\nsource_url:\n  html: https://developers.cloudflare.com/agents/guides/remote-mcp-server/\n  md: https://developers.cloudflare.com/agents/guides/remote-mcp-server/index.md\n---\n\n## Deploy your first MCP server\n\nThis guide will show you how to deploy your own remote MCP server on Cloudflare, with two options:\n\n* **Without authentication** — anyone can connect and use the server (no login required).\n* **With [authentication and authorization](https://developers.cloudflare.com/agents/guides/remote-mcp-server/#add-authentication)** — users sign in before accessing tools, and you can control which tools an agent can call based on the user's permissions.\n\nYou can start by deploying a [public MCP server](https://github.com/cloudflare/ai/tree/main/demos/remote-mcp-authless) without authentication, then add user authentication and scoped authorization later. If you already know your server will require authentication, you can skip ahead to the [next section](https://developers.cloudflare.com/agents/guides/remote-mcp-server/#add-authentication).\n\nThe button below will guide you through everything you need to do to deploy this [example MCP server](https://github.com/cloudflare/ai/tree/main/demos/remote-mcp-authless) to your Cloudflare account:\n\n[![Deploy to Workers](https://deploy.workers.cloudflare.com/button)](https://deploy.workers.cloudflare.com/?url=https://github.com/cloudflare/ai/tree/main/demos/remote-mcp-authless)\n\nOnce deployed, this server will be live at your workers.dev subdomain (e.g. remote-mcp-server-authless.your-account.workers.dev/sse). You can connect to it immediately using the [AI Playground](https://playground.ai.cloudflare.com/) (a remote MCP client), [MCP inspector](https://github.com/modelcontextprotocol/inspector) or [other MCP clients](https://developers.cloudflare.com/agents/guides/remote-mcp-server/#connect-your-remote-mcp-server-to-claude-and-other-mcp-clients-via-a-local-proxy). Then, once you're ready, you can customize the MCP server and add your own [tools](https://developers.cloudflare.com/agents/model-context-protocol/tools/).\n\nIf you're using the \"Deploy to Cloudflare\" button, a new git repository will be set up on your GitHub or GitLab account for your MCP server, configured to automatically deploy to Cloudflare each time you push a change or merge a pull request to the main branch of the repository. You can then clone this repository, [develop locally](https://developers.cloudflare.com/agents/guides/remote-mcp-server/#local-development), and start writing code and building.\n\n### Set up and deploy your MCP server via CLI\n\nAlternatively, you can use the command line as shown below to create a new MCP Server on your local machine.\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Now, you have the MCP server setup, with dependencies installed. Move into that project folder:",
      "language": "unknown"
    },
    {
      "code": "#### Local development\n\nIn the directory of your new project, run the following command to start the development server:",
      "language": "unknown"
    },
    {
      "code": "Your MCP server is now running on `http://localhost:8788/sse`.\n\nIn a new terminal, run the [MCP inspector](https://github.com/modelcontextprotocol/inspector). The MCP inspector is an interactive MCP client that allows you to connect to your MCP server and invoke tools from a web browser.",
      "language": "unknown"
    },
    {
      "code": "Open the MCP inspector in your web browser:",
      "language": "unknown"
    },
    {
      "code": "In the inspector, enter the URL of your MCP server, `http://localhost:8788/sse`, and click **Connect**. You should see the \"List Tools\" button, which will list the tools that your MCP server exposes.\n\n![MCP inspector — authenticated](https://developers.cloudflare.com/_astro/mcp-inspector-authenticated.BCabYwDA_ezC3N.webp)\n\n#### Deploy your MCP server\n\nYou can deploy your MCP server to Cloudflare using the following [Wrangler CLI command](https://developers.cloudflare.com/workers/wrangler) within the example project:",
      "language": "unknown"
    },
    {
      "code": "If you have already [connected a git repository](https://developers.cloudflare.com/workers/ci-cd/builds/) to the Worker with your MCP server, you can deploy your MCP server by pushing a change or merging a pull request to the main branch of the repository.\n\nAfter deploying, take the URL of your deployed MCP server, and enter it in the MCP inspector running on `http://localhost:5173`. You now have a remote MCP server, deployed to Cloudflare, that MCP clients can connect to.\n\n### Connect your Remote MCP server to Claude and other MCP Clients via a local proxy\n\nNow that your MCP server is running, you can use the [`mcp-remote` local proxy](https://www.npmjs.com/package/mcp-remote) to connect Claude Desktop or other MCP clients to it — even though these tools aren't yet *remote* MCP clients, and don't support remote transport or authorization on the client side. This lets you test what an interaction with your MCP server will be like with a real MCP client.\n\nUpdate your Claude Desktop configuration to point to the URL of your MCP server. You can use either the `localhost:8787/sse` URL, or the URL of your deployed MCP server:",
      "language": "unknown"
    },
    {
      "code": "Restart Claude Desktop after updating your config file to load the MCP Server. Once this is done, Claude will be able to make calls to your remote MCP server. You can test this by asking Claude to use one of your tools. For example: \"Could you use the math tool to add 23 and 19?\". Claude should invoke the tool and show the result generated by the MCP server.\n\nLearn more about other ways of using remote MCP servers with MCP clients here in [this section](https://developers.cloudflare.com/agents/guides/test-remote-mcp-server).\n\n## Add Authentication\n\nNow that you’ve deployed a public MCP server, let’s walk through how to enable user authentication using OAuth.\n\nThe public server example you deployed earlier allows any client to connect and invoke tools without logging in. To add authentication, you’ll update your MCP server to act as an OAuth provider, handling secure login flows and issuing access tokens that MCP clients can use to make authenticated tool calls.\n\nThis is especially useful if users already need to log in to use your service. Once authentication is enabled, users can sign in with their existing account and grant their AI agent permission to interact with the tools exposed by your MCP server, using scoped permissions.\n\nIn this example, we use GitHub as an OAuth provider, but you can connect your MCP server with any [OAuth provider](https://developers.cloudflare.com/agents/model-context-protocol/authorization/#2-third-party-oauth-provider) that supports the OAuth 2.0 specification, including Google, Slack, [Stytch](https://developers.cloudflare.com/agents/model-context-protocol/authorization/#stytch), [Auth0](https://developers.cloudflare.com/agents/model-context-protocol/authorization/#stytch), [WorkOS](https://developers.cloudflare.com/agents/model-context-protocol/authorization/#stytch), and more.\n\n### Step 1 — Create a new MCP server\n\nRun the following command to create a new MCP server:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Now, you have the MCP server setup, with dependencies installed. Move into that project folder:",
      "language": "unknown"
    },
    {
      "code": "You'll notice that in the example MCP server, if you open `src/index.ts`, the primary difference is that the `defaultHandler` is set to the `GitHubHandler`:",
      "language": "unknown"
    },
    {
      "code": "This will ensure that your users are redirected to GitHub to authenticate. To get this working though, you need to create OAuth client apps in the steps below.\n\n### Step 2 — Create an OAuth App\n\nYou'll need to create two [GitHub OAuth Apps](https://docs.github.com/en/apps/oauth-apps/building-oauth-apps/creating-an-oauth-app) to use GitHub as an authentication provider for your MCP server — one for local development, and one for production.\n\n#### First create a new OAuth App for local development\n\nNavigate to [github.com/settings/developers](https://github.com/settings/developers) to create a new OAuth App with the following settings:\n\n* **Application name**: `My MCP Server (local)`\n* **Homepage URL**: `http://localhost:8788`\n* **Authorization callback URL**: `http://localhost:8788/callback`\n\nFor the OAuth app you just created, add the client ID of the OAuth app as `GITHUB_CLIENT_ID` and generate a client secret, adding it as `GITHUB_CLIENT_SECRET` to a `.dev.vars` file in the root of your project, which [will be used to set secrets in local development](https://developers.cloudflare.com/workers/configuration/secrets/).",
      "language": "unknown"
    },
    {
      "code": "#### Next, run your MCP server locally\n\nRun the following command to start the development server:",
      "language": "unknown"
    },
    {
      "code": "Your MCP server is now running on `http://localhost:8788/sse`.\n\nIn a new terminal, run the [MCP inspector](https://github.com/modelcontextprotocol/inspector). The MCP inspector is an interactive MCP client that allows you to connect to your MCP server and invoke tools from a web browser.",
      "language": "unknown"
    },
    {
      "code": "Open the MCP inspector in your web browser:",
      "language": "unknown"
    },
    {
      "code": "In the inspector, set **Transport Type** to `SSE` and enter the URL of your MCP server, `http://localhost:8788/sse`\n\nIn the main panel on the right, click the **Open OAuth Settings** button and then click **Quick OAuth Flow**.\n\nYou should be redirected to a GitHub login or authorization page. After authorizing the MCP Client (the inspector) access to your GitHub account, you will be redirected back to the inspector.\n\nClick **Connect** in the sidebar and you should see the \"List Tools\" button, which will list the tools that your MCP server exposes.\n\n#### Second — create a new OAuth App for production\n\nYou'll need to repeat these steps to create a new OAuth App for production.\n\nNavigate to [github.com/settings/developers](https://github.com/settings/developers) to create a new OAuth App with the following settings:\n\n* **Application name**: `My MCP Server (production)`\n* **Homepage URL**: Enter the workers.dev URL of your deployed MCP server (ex: `worker-name.account-name.workers.dev`)\n* **Authorization callback URL**: Enter the `/callback` path of the workers.dev URL of your deployed MCP server (ex: `worker-name.account-name.workers.dev/callback`)\n\nFor the OAuth app you just created, add the client ID and client secret, using Wrangler CLI:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "Warning\n\nWhen you create the first secret, Wrangler will ask if you want to create a new Worker. Submit \"Y\" to create a new Worker and save the secret.\n\n#### Set up a KV namespace\n\n* Create the KV namespace:",
      "language": "unknown"
    },
    {
      "code": "* Update the `wrangler.jsonc` file with the resulting KV ID:",
      "language": "unknown"
    },
    {
      "code": "#### Deploy your server\n\nDeploy the MCP server to your Cloudflare `workers.dev` domain:",
      "language": "unknown"
    },
    {
      "code": "#### Finally, connect to your MCP server\n\nNow that you've added the ID and secret of your production OAuth app, you should now be able to connect to your MCP server running at `worker-name.account-name.workers.dev/sse` using the [AI Playground](https://playground.ai.cloudflare.com/), MCP inspector or ([other MCP clients](https://developers.cloudflare.com/agents/guides/remote-mcp-server/#connect-your-mcp-server-to-claude-and-other-mcp-clients)), and authenticate with GitHub.\n\n## Next steps\n\n* Add [tools](https://developers.cloudflare.com/agents/model-context-protocol/tools/) to your MCP server.\n* Customize your MCP Server's [authentication and authorization](https://developers.cloudflare.com/agents/model-context-protocol/authorization/).\n\n</page>\n\n<page>\n---\ntitle: Build a Slack Agent · Cloudflare Agents docs\ndescription: \"This guide will show you how to build and deploy an AI-powered\n  Slack bot on Cloudflare Workers that can:\"\nlastUpdated: 2025-11-07T18:20:34.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/agents/guides/slack-agent/\n  md: https://developers.cloudflare.com/agents/guides/slack-agent/index.md\n---\n\n## Deploy your first Slack Agent\n\nThis guide will show you how to build and deploy an AI-powered Slack bot on Cloudflare Workers that can:\n\n* Respond to direct messages\n* Reply when mentioned in channels\n* Maintain conversation context in threads\n* Use AI to generate intelligent responses\n\nYour Slack Agent will be a multi-tenant application, meaning a single deployment can serve multiple Slack workspaces. Each workspace gets its own isolated agent instance with dedicated storage, powered by the [Agents SDK](https://developers.cloudflare.com/agents/).\n\nYou can view the full code for this example [here](https://github.com/cloudflare/awesome-agents/tree/69963298b359ddd66331e8b3b378bb9ae666629f/agents/slack).\n\n## Prerequisites\n\nBefore you begin, you will need:\n\n* A [Cloudflare account](https://dash.cloudflare.com/sign-up)\n* [Node.js](https://nodejs.org/) installed (v18 or later)\n* A [Slack workspace](https://slack.com/create) where you have permission to install apps\n* An [OpenAI API key](https://platform.openai.com/api-keys) (or another LLM provider)\n\n## 1. Create a Slack App\n\nFirst, create a new Slack App that your agent will use to interact with Slack:\n\n1. Go to [api.slack.com/apps](https://api.slack.com/apps) and select **Create New App**.\n2. Select **From scratch**.\n3. Give your app a name (for example, \"My AI Assistant\") and select your workspace.\n4. Select **Create App**.\n\n### Configure OAuth & Permissions\n\nIn your Slack App settings, go to **OAuth & Permissions** and add the following **Bot Token Scopes**:\n\n* `chat:write` — Send messages as the bot\n* `chat:write.public` — Send messages to channels without joining\n* `channels:history` — View messages in public channels\n* `app_mentions:read` — Receive mentions\n* `im:write` — Send direct messages\n* `im:history` — View direct message history\n\n### Enable Event Subscriptions\n\nYou will later configure the Event Subscriptions URL after deploying your agent. But for now, go to **Event Subscriptions** in your Slack App settings and prepare to enable it.\n\nSubscribe to the following bot events:\n\n* `app_mention` — When the bot is @mentioned\n* `message.im` — Direct messages to the bot\n\nDo not enable it yet. You will enable it after deployment.\n\n### Get your Slack credentials\n\nFrom your Slack App settings, collect these values:\n\n1. **Basic Information** > **App Credentials**:\n\n   * **Client ID**\n   * **Client Secret**\n   * **Signing Secret**\n\nKeep these handy — you will need them in the next step.\n\n## 2. Create your Slack Agent project\n\n1. Create a new project for your Slack Agent:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "1. Navigate into your project:",
      "language": "unknown"
    },
    {
      "code": "1. Install the required dependencies:",
      "language": "unknown"
    },
    {
      "code": "## 3. Set up your environment variables\n\n1. Create a `.dev.vars` file in your project root for local development secrets:",
      "language": "unknown"
    },
    {
      "code": "1. Add your credentials to `.dev.vars`:",
      "language": "unknown"
    },
    {
      "code": "Note\n\nThe `OPENAI_BASE_URL` is optional but recommended. Using [Cloudflare AI Gateway](https://developers.cloudflare.com/ai-gateway/) gives you caching, rate limiting, and analytics for your AI requests.\n\n1. Update your `wrangler.jsonc` to configure your Agent:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "## 4. Create your Slack Agent\n\n1. First, create the base `SlackAgent` class at `src/slack.ts`. This class handles OAuth, request verification, and event routing. You can view the [full implementation on GitHub](https://github.com/cloudflare/awesome-agents/blob/69963298b359ddd66331e8b3b378bb9ae666629f/agents/slack/src/slack.ts).\n\n2. Now create your agent implementation at `src/index.ts`:",
      "language": "unknown"
    },
    {
      "code": "## 5. Test locally\n\nStart your development server:",
      "language": "unknown"
    },
    {
      "code": "Your agent is now running at `http://localhost:8787`.\n\n### Configure Slack Event Subscriptions\n\nNow that your agent is running locally, you need to expose it to Slack. Use [Cloudflare Tunnel](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/do-more-with-tunnels/trycloudflare/) to create a secure tunnel:",
      "language": "unknown"
    },
    {
      "code": "This will output a public URL like `https://random-subdomain.trycloudflare.com`.\n\nGo back to your Slack App settings:\n\n1. Go to **Event Subscriptions**.\n\n2. Toggle **Enable Events** to **On**.\n\n3. Enter your Request URL: `https://random-subdomain.trycloudflare.com/slack`.\n\n4. Slack will send a verification request — if your agent is running correctly, it should show **Verified**.\n\n5. Under **Subscribe to bot events**, add:\n\n   * `app_mention`\n   * `message.im`\n\n6. Select **Save Changes**.\n\nNote\n\nCloudflare Tunnel URLs are temporary. When testing locally, you will need to update the Request URL each time you restart the tunnel.\n\n### Install your app to Slack\n\nVisit `http://localhost:8787/install` in your browser. This will redirect you to Slack's authorization page. Select **Allow** to install the app to your workspace.\n\nAfter authorization, you should see \"Successfully registered!\" in your browser.\n\n### Test your agent\n\nOpen Slack. Then:\n\n1. Send a DM to your bot — it should respond with an AI-generated message.\n2. Mention your bot in a channel (e.g., `@My AI Assistant hello`) — it should reply in a thread.\n\nIf everything works, you're ready to deploy to production!\n\n## 6. Deploy to production\n\n1. Before deploying, add your secrets to Cloudflare:",
      "language": "unknown"
    },
    {
      "code": "Note\n\nYou can skip `OPENAI_BASE_URL` if you're not using AI Gateway.\n\n1. Deploy your agent:",
      "language": "unknown"
    },
    {
      "code": "After deploying, you will get a production URL like:",
      "language": "unknown"
    },
    {
      "code": "### Update Slack Event Subscriptions\n\nGo back to your Slack App settings:\n\n1. Go to **Event Subscriptions**.\n2. Update the Request URL to your production URL: `https://my-slack-agent.your-account.workers.dev/slack`.\n3. Select **Save Changes**.\n\n### Distribute your app\n\nNow that your agent is deployed, you can share it with others:\n\n* **Single workspace**: Install it via `https://my-slack-agent.your-account.workers.dev/install`.\n* **Public distribution**: Submit your app to the [Slack App Directory](https://api.slack.com/start/distributing).\n\nEach workspace that installs your app will get its own isolated agent instance with dedicated storage.\n\n## How it works\n\n### Multi-tenancy with Durable Objects\n\nYour Slack Agent uses [Durable Objects](https://developers.cloudflare.com/durable-objects/) to provide isolated, stateful instances for each Slack workspace:\n\n* Each workspace's `team_id` is used as the Durable Object ID.\n* Each agent instance stores its own Slack access token in KV storage.\n* Conversations are fetched on-demand from Slack's API.\n* All agent logic runs in an isolated, consistent environment.\n\n### OAuth flow\n\nThe agent handles Slack's OAuth 2.0 flow:\n\n1. User visits `/install` > redirected to Slack authorization.\n2. User selects **Allow** > Slack redirects to `/accept` with an authorization code.\n3. Agent exchanges code for access token.\n4. Agent stores token in the workspace's Durable Object.\n\n### Event handling\n\nWhen Slack sends an event:\n\n1. Request arrives at `/slack` endpoint.\n2. Agent verifies the request signature using HMAC-SHA256.\n3. Agent routes the event to the correct workspace's Durable Object.\n4. `onSlackEvent` method processes the event and generates a response.\n\n## Customizing your agent\n\n### Change the AI model\n\nUpdate the model in `src/index.ts`:",
      "language": "unknown"
    },
    {
      "code": "### Add conversation memory\n\nStore conversation history in Durable Object storage:",
      "language": "unknown"
    },
    {
      "code": "### React to specific keywords\n\nAdd custom logic in `onSlackEvent`:",
      "language": "unknown"
    },
    {
      "code": "### Use different LLM providers\n\nReplace OpenAI with [Workers AI](https://developers.cloudflare.com/workers-ai/):",
      "language": "unknown"
    },
    {
      "code": "## Next steps\n\n* Add [Slack Interactive Components](https://api.slack.com/interactivity) (buttons, modals)\n* Connect your Agent to an [MCP server](https://developers.cloudflare.com/agents/model-context-protocol/mcp-client-api/)\n* Add rate limiting to prevent abuse\n* Implement conversation state management\n* Use [Workers Analytics Engine](https://developers.cloudflare.com/analytics/analytics-engine/) to track usage\n* Add [schedules](https://developers.cloudflare.com/agents/api-reference/schedule-tasks/) for scheduled tasks\n\n## Related resources\n\n* [Agents Framework documentation](https://developers.cloudflare.com/agents/)\n* [Durable Objects documentation](https://developers.cloudflare.com/durable-objects/)\n* [Slack API documentation](https://api.slack.com/)\n* [OpenAI API documentation](https://platform.openai.com/docs/)\n\n</page>\n\n<page>\n---\ntitle: Test a Remote MCP Server · Cloudflare Agents docs\ndescription: Remote, authorized connections are an evolving part of the Model\n  Context Protocol (MCP) specification. Not all MCP clients support remote\n  connections yet.\nlastUpdated: 2025-12-03T19:05:12.000Z\nchatbotDeprioritize: false\ntags: MCP\nsource_url:\n  html: https://developers.cloudflare.com/agents/guides/test-remote-mcp-server/\n  md: https://developers.cloudflare.com/agents/guides/test-remote-mcp-server/index.md\n---\n\nRemote, authorized connections are an evolving part of the [Model Context Protocol (MCP) specification](https://spec.modelcontextprotocol.io/specification/draft/basic/authorization/). Not all MCP clients support remote connections yet.\n\nThis guide will show you options for how to start using your remote MCP server with MCP clients that support remote connections. If you haven't yet created and deployed a remote MCP server, you should follow the [Build a Remote MCP Server](https://developers.cloudflare.com/agents/guides/remote-mcp-server/) guide first.\n\n## The Model Context Protocol (MCP) inspector\n\nThe [`@modelcontextprotocol/inspector` package](https://github.com/modelcontextprotocol/inspector) is a visual testing tool for MCP servers.\n\nYou can run it locally by running the following command:",
      "language": "unknown"
    },
    {
      "code": "Then, enter the URL of your remote MCP server. You can use an MCP server running on your local machine on localhost, or you can use a remote MCP server running on Cloudflare.\n\n![MCP inspector](https://developers.cloudflare.com/_astro/mcp-inspector-enter-url.Chu-Nz-A_Z2xJ68.webp)\n\nOnce you have authenticated, you will be redirected back to the inspector. You should see the \"List Tools\" button, which will list the tools that your MCP server exposes.\n\n![MCP inspector — authenticated](https://developers.cloudflare.com/_astro/mcp-inspector-authenticated.BCabYwDA_ezC3N.webp)\n\n## Connect your remote MCP server to Cloudflare Workers AI Playground\n\nVisit the [Workers AI Playground](https://playground.ai.cloudflare.com/), enter your MCP server URL, and click \"Connect\". Once authenticated (if required), you should see your tools listed and they will be available to the AI model in the chat.\n\n## Connect your remote MCP server to Claude Desktop via a local proxy\n\nEven though [Claude Desktop](https://claude.ai/download) doesn't yet support remote MCP clients, you can use the [`mcp-remote` local proxy](https://www.npmjs.com/package/mcp-remote) to connect it to your remote MCP server. This lets you to test what an interaction with your remote MCP server will be like with a real-world MCP client.\n\n1. Open Claude Desktop and navigate to Settings -> Developer -> Edit Config. This opens the configuration file that controls which MCP servers Claude can access.\n2. Replace the content with a configuration like this:",
      "language": "unknown"
    },
    {
      "code": "1. Save the file and restart Claude Desktop (command/ctrl + R). When Claude restarts, a browser window will open showing your OAuth login page. Complete the authorization flow to grant Claude access to your MCP server.\n\nOnce authenticated, you'll be able to see your tools by clicking the tools icon in the bottom right corner of Claude's interface.\n\n## Connect your remote MCP server to Cursor\n\nConnect [Cursor](https://cursor.com/docs/context/mcp) to your remote MCP server by editing the project's `.cursor/mcp.json` file or a global `~/.cursor/mcp.json` file and adding the following configuration:",
      "language": "unknown"
    },
    {
      "code": "## Connect your remote MCP server to Windsurf\n\nYou can connect your remote MCP server to [Windsurf](https://docs.windsurf.com) by editing the [`mcp_config.json` file](https://docs.windsurf.com/windsurf/cascade/mcp), and adding the following configuration:",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Authorization · Cloudflare Agents docs\ndescription: When building a Model Context Protocol (MCP) server, you need both\n  a way to allow users to login (authentication) and allow them to grant the MCP\n  client access to resources on their account (authorization).\nlastUpdated: 2025-10-24T20:47:24.000Z\nchatbotDeprioritize: true\ntags: MCP\nsource_url:\n  html: https://developers.cloudflare.com/agents/model-context-protocol/authorization/\n  md: https://developers.cloudflare.com/agents/model-context-protocol/authorization/index.md\n---\n\nWhen building a [Model Context Protocol (MCP)](https://modelcontextprotocol.io) server, you need both a way to allow users to login (authentication) and allow them to grant the MCP client access to resources on their account (authorization).\n\nThe Model Context Protocol uses [a subset of OAuth 2.1 for authorization](https://spec.modelcontextprotocol.io/specification/draft/basic/authorization/). OAuth allows your users to grant limited access to resources, without them having to share API keys or other credentials.\n\nCloudflare provides an [OAuth Provider Library](https://github.com/cloudflare/workers-oauth-provider) that implements the provider side of the OAuth 2.1 protocol, allowing you to easily add authorization to your MCP server.\n\nYou can use the OAuth Provider Library in three ways:\n\n1. **Your Worker handles authorization itself.** Your MCP server, running on Cloudflare, handles the complete OAuth flow. ([Example](https://developers.cloudflare.com/agents/guides/remote-mcp-server/))\n2. **Integrate directly with a third-party OAuth provider**, such as GitHub or Google.\n3. **Integrate with your own OAuth provider**, including authorization-as-a-service providers you might already rely on, such as Stytch, Auth0, or WorkOS.\n\nThe following sections describe each of these options and link to runnable code examples for each.\n\n## Authorization options\n\n### (1) Your MCP Server handles authorization and authentication itself\n\nYour MCP Server, using the [OAuth Provider Library](https://github.com/cloudflare/workers-oauth-provider), can handle the complete OAuth authorization flow, without any third-party involvement.\n\nThe [Workers OAuth Provider Library](https://github.com/cloudflare/workers-oauth-provider) is a Cloudflare Worker that implements a [`fetch()` handler](https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch/), and handles incoming requests to your MCP server.\n\nYou provide your own handlers for your MCP Server's API, and authentication and authorization logic, and URI paths for the OAuth endpoints, as shown below:",
      "language": "unknown"
    },
    {
      "code": "Refer to the [getting started example](https://developers.cloudflare.com/agents/guides/remote-mcp-server/) for a complete example of the `OAuthProvider` in use, with a mock authentication flow.\n\nThe authorization flow in this case works like this:",
      "language": "unknown"
    },
    {
      "code": "Remember — [authentication is different from authorization](https://www.cloudflare.com/learning/access-management/authn-vs-authz/). Your MCP Server can handle authorization itself, while still relying on an external authentication service to first authenticate users. The [example](https://developers.cloudflare.com/agents/guides/remote-mcp-server) in getting started provides a mock authentication flow. You will need to implement your own authentication handler — either handling authentication yourself, or using an external authentication services.\n\n### (2) Cloudflare Access integration\n\nYou can use Cloudflare Access as a Single Sign-On (SSO) provider to authorize users to your MCP server. Users log in using a [configured identity provider](https://developers.cloudflare.com/cloudflare-one/integrations/identity-providers/) or a [one-time PIN](https://developers.cloudflare.com/cloudflare-one/integrations/identity-providers/one-time-pin/), and they are only granted access if their identity matches your [Access policies](https://developers.cloudflare.com/cloudflare-one/access-controls/policies/).\n\nTo deploy an [example MCP server](https://github.com/cloudflare/ai/tree/main/demos/remote-mcp-cf-access) with Cloudflare Access as the OAuth provider, refer to [Secure MCP servers with Access for SaaS](https://developers.cloudflare.com/cloudflare-one/access-controls/ai-controls/saas-mcp/).\n\n### (3) Third-party OAuth Provider\n\nThe [OAuth Provider Library](https://github.com/cloudflare/workers-oauth-provider) can be configured to use a third-party OAuth provider, such as GitHub or Google. You can see a complete example of this in the [GitHub example](https://developers.cloudflare.com/agents/guides/remote-mcp-server/#add-authentication).\n\nWhen you use a third-party OAuth provider, you must provide a handler to the `OAuthProvider` that implements the OAuth flow for the third-party provider.",
      "language": "unknown"
    },
    {
      "code": "Note that as [defined in the Model Context Protocol specification](https://spec.modelcontextprotocol.io/specification/draft/basic/authorization/#292-flow-description) when you use a third-party OAuth provider, the MCP Server (your Worker) generates and issues its own token to the MCP client:",
      "language": "unknown"
    },
    {
      "code": "Read the docs for the [Workers oAuth Provider Library](https://github.com/cloudflare/workers-oauth-provider) for more details.\n\n### (4) Bring your own OAuth Provider\n\nIf your application already implements an OAuth Provider itself, or you use authorization-as-a-service provider, you can use this in the same way that you would use a third-party OAuth provider, described above in (2).\n\nYou can use the auth provider to:\n\n* Allow users to authenticate to your MCP server through email, social logins, SSO (single sign-on), and MFA (multi-factor authentication).\n* Define scopes and permissions that directly map to your MCP tools.\n* Present users with a consent page corresponding with the requested permissions.\n* Enforce the permissions so that agents can only invoke permitted tools.\n\n#### Stytch\n\nGet started with a [remote MCP server that uses Stytch](https://stytch.com/docs/guides/connected-apps/mcp-servers) to allow users to sign in with email, Google login or enterprise SSO and authorize their AI agent to view and manage their company's OKRs on their behalf. Stytch will handle restricting the scopes granted to the AI agent based on the user's role and permissions within their organization. When authorizing the MCP Client, each user will see a consent page that outlines the permissions that the agent is requesting that they are able to grant based on their role.\n\n[![Deploy to Cloudflare](https://deploy.workers.cloudflare.com/button)](https://deploy.workers.cloudflare.com/?url=https://github.com/cloudflare/ai/tree/main/demos/mcp-stytch-b2b-okr-manager)\n\nFor more consumer use cases, deploy a remote MCP server for a To Do app that uses Stytch for authentication and MCP client authorization. Users can sign in with email and immediately access the To Do lists associated with their account, and grant access to any AI assistant to help them manage their tasks.\n\n[![Deploy to Cloudflare](https://deploy.workers.cloudflare.com/button)](https://deploy.workers.cloudflare.com/?url=https://github.com/cloudflare/ai/tree/main/demos/mcp-stytch-consumer-todo-list)\n\n#### Auth0\n\nGet started with a remote MCP server that uses Auth0 to authenticate users through email, social logins, or enterprise SSO to interact with their todos and personal data through AI agents. The MCP server securely connects to API endpoints on behalf of users, showing exactly which resources the agent will be able to access once it gets consent from the user. In this implementation, access tokens are automatically refreshed during long running interactions.\n\nTo set it up, first deploy the protected API endpoint:\n\n[![Deploy to Cloudflare](https://deploy.workers.cloudflare.com/button)](https://deploy.workers.cloudflare.com/?url=https://github.com/cloudflare/ai/tree/main/demos/remote-mcp-auth0/todos-api)\n\nThen, deploy the MCP server that handles authentication through Auth0 and securely connects AI agents to your API endpoint.\n\n[![Deploy to Cloudflare](https://deploy.workers.cloudflare.com/button)](https://deploy.workers.cloudflare.com/?url=https://github.com/cloudflare/ai/tree/main/demos/remote-mcp-auth0/mcp-auth0-oidc)\n\n#### WorkOS\n\nGet started with a remote MCP server that uses WorkOS's AuthKit to authenticate users and manage the permissions granted to AI agents. In this example, the MCP server dynamically exposes tools based on the user's role and access rights. All authenticated users get access to the `add` tool, but only users who have been assigned the `image_generation` permission in WorkOS can grant the AI agent access to the image generation tool. This showcases how MCP servers can conditionally expose capabilities to AI agents based on the authenticated user's role and permission.\n\n[![Deploy to Cloudflare](https://deploy.workers.cloudflare.com/button)](https://deploy.workers.cloudflare.com/?url=https://github.com/cloudflare/ai/tree/main/demos/remote-mcp-authkit)\n\n#### Descope\n\nGet started with a remote MCP server that uses [Descope](https://www.descope.com/) Inbound Apps to authenticate and authorize users (for example, email, social login, SSO) to interact with their data through AI agents. Leverage Descope custom scopes to define and manage permissions for more fine-grained control.\n\n[![Deploy to Cloudflare](https://deploy.workers.cloudflare.com/button)](https://deploy.workers.cloudflare.com/?url=https://github.com/cloudflare/ai/tree/main/demos/remote-mcp-server-descope-auth)\n\n## Using Authentication Context in Your MCP Server\n\nWhen a user authenticates to your MCP server through Cloudflare's OAuth Provider, their identity information and tokens are made available through the `props` parameter.",
      "language": "unknown"
    },
    {
      "code": "The authentication context can be used for:\n\n* Accessing user-specific data by using the user ID (this.props.claims.sub) as a key\n* Checking user permissions before performing operations\n* Customizing responses based on user preferences or attributes\n* Using authentication tokens to make requests to external services on behalf of the user\n* Ensuring consistency when users interact with your application through different interfaces (dashboard, API, MCP server)\n\n## Implementing Permission-Based Access for MCP Tools\n\nYou can implement fine-grained authorization controls for your MCP tools based on user permissions. This allows you to restrict access to certain tools based on the user's role or specific permissions.",
      "language": "unknown"
    },
    {
      "code": "Benefits:\n\n* Authorization check at the tool level ensures proper access control\n* Allows you to define permission checks once and reuse them across tools\n* Provides clear feedback to users when permission is denied\n* Can choose to only present tools that the agent is able to call\n\n## Next steps\n\n* [Learn how to use the Workers OAuth Provider Library](https://github.com/cloudflare/workers-oauth-provider)\n* Learn how to use a third-party OAuth provider, using the [GitHub](https://developers.cloudflare.com/agents/guides/remote-mcp-server/#add-authentication) example MCP server.\n\n</page>\n\n<page>\n---\ntitle: McpAgent — API Reference · Cloudflare Agents docs\ndescription: \"When you build MCP Servers on Cloudflare, you extend the McpAgent\n  class, from the Agents SDK, like this:\"\nlastUpdated: 2025-08-15T20:11:52.000Z\nchatbotDeprioritize: false\ntags: MCP\nsource_url:\n  html: https://developers.cloudflare.com/agents/model-context-protocol/mcp-agent-api/\n  md: https://developers.cloudflare.com/agents/model-context-protocol/mcp-agent-api/index.md\n---\n\nWhen you build MCP Servers on Cloudflare, you extend the [`McpAgent` class](https://github.com/cloudflare/agents/blob/5881c5d23a7f4580600029f69307cfc94743e6b8/packages/agents/src/mcp.ts), from the Agents SDK, like this:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "This means that each instance of your MCP server has its own durable state, backed by a [Durable Object](https://developers.cloudflare.com/durable-objects/), with its own [SQL database](https://developers.cloudflare.com/agents/api-reference/store-and-sync-state).\n\nYour MCP server doesn't necessarily have to be an Agent. You can build MCP servers that are stateless, and just add [tools](https://developers.cloudflare.com/agents/model-context-protocol/tools) to your MCP server using the `@modelcontextprotocol/typescript-sdk` package.\n\nBut if you want your MCP server to:\n\n* remember previous tool calls, and responses it provided\n* provide a game to the MCP client, remembering the state of the game board, previous moves, and the score\n* cache the state of a previous external API call, so that subsequent tool calls can reuse it\n* do anything that an Agent can do, but allow MCP clients to communicate with it\n\nYou can use the APIs below in order to do so.\n\n#### Hibernation Support\n\n`McpAgent` instances automatically support [WebSockets Hibernation](https://developers.cloudflare.com/durable-objects/best-practices/websockets/#websocket-hibernation-api), allowing stateful MCP servers to sleep during inactive periods while preserving their state. This means your agents only consume compute resources when actively processing requests, optimizing costs while maintaining the full context and conversation history.\n\nHibernation is enabled by default and requires no additional configuration.\n\n#### Authentication & Authorization\n\nThe McpAgent class provides seamless integration with the [OAuth Provider Library](https://github.com/cloudflare/workers-oauth-provider) for [authentication and authorization](https://developers.cloudflare.com/agents/model-context-protocol/authorization/).\n\nWhen a user authenticates to your MCP server, their identity information and tokens are made available through the `props` parameter, allowing you to:\n\n* access user-specific data\n* check user permissions before performing operations\n* customize responses based on user attributes\n* use authentication tokens to make requests to external services on behalf of the user\n\n### State synchronization APIs\n\nThe `McpAgent` class makes the following subset of methods from the [Agents SDK](https://developers.cloudflare.com/agents/api-reference/agents-api/) available:\n\n* [`state`](https://developers.cloudflare.com/agents/api-reference/store-and-sync-state/)\n* [`initialState`](https://developers.cloudflare.com/agents/api-reference/store-and-sync-state/#set-the-initial-state-for-an-agent)\n* [`setState`](https://developers.cloudflare.com/agents/api-reference/store-and-sync-state/)\n* [`onStateUpdate`](https://developers.cloudflare.com/agents/api-reference/store-and-sync-state/#synchronizing-state)\n* [`sql`](https://developers.cloudflare.com/agents/api-reference/agents-api/#sql-api)\n\nState resets after the session ends\n\nCurrently, each client session is backed by an instance of the `McpAgent` class. This is handled automatically for you, as shown in the [getting started guide](https://developers.cloudflare.com/agents/guides/remote-mcp-server). This means that when the same client reconnects, they will start a new session, and the state will be reset.\n\nFor example, the following code implements an MCP server that remembers a counter value, and updates the counter when the `add` tool is called:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "### Not yet supported APIs\n\nThe following APIs from the Agents SDK are not yet available on `McpAgent`:\n\n* [WebSocket APIs](https://developers.cloudflare.com/agents/api-reference/websockets/) (`onMessage`, `onError`, `onClose`, `onConnect`)\n* [Scheduling APIs](https://developers.cloudflare.com/agents/api-reference/schedule-tasks/) `this.schedule`\n\n</page>\n\n<page>\n---\ntitle: McpClient — API reference · Cloudflare Agents docs\ndescription: \"Your Agent can connect to external Model Context Protocol (MCP)\n  servers to access tools, resources, and prompts. The Agent class provides\n  three methods to manage MCP connections:\"\nlastUpdated: 2025-11-27T20:02:07.000Z\nchatbotDeprioritize: false\ntags: MCP\nsource_url:\n  html: https://developers.cloudflare.com/agents/model-context-protocol/mcp-client-api/\n  md: https://developers.cloudflare.com/agents/model-context-protocol/mcp-client-api/index.md\n---\n\nYour Agent can connect to external [Model Context Protocol (MCP)](https://modelcontextprotocol.io) servers to access tools, resources, and prompts. The `Agent` class provides three methods to manage MCP connections:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Connections persist in the Agent's [SQL storage](https://developers.cloudflare.com/agents/api-reference/store-and-sync-state), and when an Agent connects to an MCP server, all tools from that server become available automatically.\n\n## Agent MCP Client Methods\n\n### `addMcpServer()`\n\nAdd a connection to an MCP server and make its tools available to your Agent.",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* **`serverName`** (string, required) — Display name for the MCP server\n\n* **`url`** (string, required) — URL of the MCP server endpoint\n\n* **`callbackHost`** (string, optional) — Host for OAuth callback URL. If omitted, automatically derived from the incoming request\n\n* **`agentsPrefix`** (string, optional) — URL prefix for OAuth callback path. Default: `\"agents\"`\n\n* **`options`** (object, optional) — Connection configuration:\n\n  * **`client`** — MCP client configuration options (passed to `@modelcontextprotocol/sdk` Client constructor). By default, includes `CfWorkerJsonSchemaValidator` for validating tool parameters against JSON schemas.\n\n  * **`transport`** — Transport layer configuration:\n\n    * **`headers`** — Custom HTTP headers for authentication\n    * **`type`** — Transport type: `\"sse\"`, `\"streamable-http\"`, or `\"auto\"` (tries streamable-http first, falls back to sse)\n\n#### Returns\n\nA Promise that resolves to a discriminated union based on connection state:\n\n* **When `state` is `\"authenticating\"`:**\n\n  * **`id`** (string) — Unique identifier for this server connection\n  * **`state`** (`\"authenticating\"`) — Server is waiting for OAuth authorization\n  * **`authUrl`** (string) — OAuth authorization URL for user authentication\n\n* **When `state` is `\"ready\"`:**\n\n  * **`id`** (string) — Unique identifier for this server connection\n  * **`state`** (`\"ready\"`) — Server is fully connected and operational\n  * **`authUrl`** (undefined) — Not present when already authenticated\n\n#### Example\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "If the MCP server requires OAuth authentication, `authUrl` will be returned for user authentication. Connections persist across requests and the Agent will automatically reconnect if the connection is lost.\n\nDefault JSON Schema Validation\n\nAll MCP client connections automatically include JSON schema validation using `CfWorkerJsonSchemaValidator`. This ensures that tool parameters are validated against their schemas before execution, improving reliability and catching errors early. You can override this default by providing custom client options.\n\n**Related:**\n\n* [OAuth handling guide](https://developers.cloudflare.com/agents/guides/oauth-mcp-client)\n* [Transport options](https://developers.cloudflare.com/agents/model-context-protocol/transport)\n* [removeMcpServer()](#removemcpserver)\n\n### `removeMcpServer()`\n\nDisconnect from an MCP server and clean up its resources.",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* **`id`** (string, required) — Server connection ID returned from `addMcpServer()`\n\n#### Returns\n\nA Promise that resolves when disconnection is complete.\n\n#### Example\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Disconnects from the MCP server, removes all related resources, and deletes the server record from storage.\n\n### `getMcpServers()`\n\nGet the current state of all MCP server connections.",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\nNone.\n\n#### Returns\n\nAn `MCPServersState` object containing:",
      "language": "unknown"
    },
    {
      "code": "#### Example\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "The `state` field indicates the connection lifecycle:\n\n* `authenticating` — Waiting for OAuth authorization to complete\n* `connecting` — Establishing transport connection\n* `connected` — Transport connection established\n* `discovering` — Discovering server capabilities (tools, resources, prompts)\n* `ready` — Fully connected and operational\n* `failed` — Connection failed\n\nUse this method to monitor connection status, list available tools, or build UI for connected servers.\n\n## Lifecycle Methods\n\nThe `this.mcp` property exposes additional methods for fine-grained control over MCP server connections.\n\n### `this.mcp.registerServer()`\n\nRegister a server without immediately connecting. Useful for pre-configuring servers that will be connected later.",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* **`id`** (string, required) — Unique identifier for the server\n\n* **`options`** (object, required) — Server configuration:\n\n  * **`url`** — MCP server endpoint URL\n  * **`name`** — Display name for the server\n  * **`callbackUrl`** — OAuth callback URL\n  * **`clientOptions`** — MCP client configuration\n  * **`transportOptions`** — Transport layer settings\n\n#### Returns\n\nA Promise that resolves to the server ID.\n\n### `this.mcp.connectToServer()`\n\nEstablish a connection to a previously registered server.",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* **`id`** (string, required) — Server ID from `registerServer()`\n\n#### Returns\n\nA Promise that resolves to an `MCPConnectionResult`:",
      "language": "unknown"
    },
    {
      "code": "### `this.mcp.discoverIfConnected()`\n\nCheck server capabilities if a connection is active.",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* **`serverId`** (string, required) — Server ID to check\n* **`options`** (object, optional):\n  * **`timeoutMs`** — Discovery timeout in milliseconds\n\n#### Returns\n\nA Promise that resolves to `MCPDiscoverResult` if connected, or `undefined` if not connected:",
      "language": "unknown"
    },
    {
      "code": "### `this.mcp.closeConnection()`\n\nClose the connection to a specific server while keeping it registered.",
      "language": "unknown"
    },
    {
      "code": "### `this.mcp.closeAllConnections()`\n\nClose all active server connections while preserving registrations.",
      "language": "unknown"
    },
    {
      "code": "## Capabilities\n\n### `this.mcp.getAITools()`\n\nGet all discovered MCP tools in a format compatible with the [AI SDK](https://ai-sdk.dev/).",
      "language": "unknown"
    },
    {
      "code": "#### Returns\n\nA `ToolSet` object containing all tools from connected MCP servers, ready to use with AI SDK functions like `generateText()` or `streamText()`.\n\n#### Example\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Tools are automatically namespaced by server ID to prevent conflicts when multiple MCP servers expose tools with the same name.\n\n## OAuth Configuration\n\nCustomize OAuth callback behavior using `this.mcp.configureOAuthCallback()`:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "You can also provide a `customHandler` function for full control over the callback response. Refer to the [OAuth handling guide](https://developers.cloudflare.com/agents/guides/oauth-mcp-client) for details.\n\n## Error Handling\n\nUse error detection utilities to handle connection errors:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "## Next Steps\n\n* [Connect your first MCP server](https://developers.cloudflare.com/agents/guides/connect-mcp-client) — Tutorial to get started\n* [Handle OAuth flows](https://developers.cloudflare.com/agents/guides/oauth-mcp-client) — Complete OAuth integration guide\n\n</page>\n\n<page>\n---\ntitle: createMcpHandler — API Reference · Cloudflare Agents docs\ndescription: The createMcpHandler function creates a fetch handler to serve your\n  MCP server. You can use it as an alternative to the McpAgent class when you\n  don't need the deprecated SSE transport.\nlastUpdated: 2025-11-27T17:17:53.000Z\nchatbotDeprioritize: false\ntags: MCP\nsource_url:\n  html: https://developers.cloudflare.com/agents/model-context-protocol/mcp-handler-api/\n  md: https://developers.cloudflare.com/agents/model-context-protocol/mcp-handler-api/index.md\n---\n\nThe `createMcpHandler` function creates a fetch handler to serve your MCP server. You can use it as an alternative to the [`McpAgent`](https://developers.cloudflare.com/agents/model-context-protocol/mcp-agent-api) class when you don't need the deprecated SSE transport.\n\nIt uses an implementation of the MCP Transport interface, `WorkerTransport`, built on top of web standards, which conforms to the [streamable-http](https://modelcontextprotocol.io/specification/draft/basic/transports/#streamable-http) transport specification.",
      "language": "unknown"
    },
    {
      "code": "#### Parameters\n\n* **server** — An instance of [`McpServer`](https://modelcontextprotocol.io/docs/develop/build-server#node) from the `@modelcontextprotocol/sdk` package\n* **options** — Optional configuration object (see [`CreateMcpHandlerOptions`](#createmcphandleroptions))\n\n#### Returns\n\nA Worker fetch handler function with the signature `(request: Request, env: unknown, ctx: ExecutionContext) => Promise<Response>`.\n\n### CreateMcpHandlerOptions\n\nConfiguration options for creating an MCP handler.",
      "language": "unknown"
    },
    {
      "code": "#### Options\n\n##### route\n\nThe URL path where the MCP handler responds. Requests to other paths return a 404 response.\n\n**Default:** `\"/mcp\"`\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "#### authContext\n\nAn authentication context object that will be available to MCP tools via [`getMcpAuthContext()`](https://developers.cloudflare.com/agents/model-context-protocol/mcp-handler-api#authentication-context).\n\nWhen using the [`OAuthProvider`](https://developers.cloudflare.com/agents/model-context-protocol/authorization/) from `@cloudflare/workers-oauth-provider`, the authentication context is automatically populated with information from the OAuth flow. You typically don't need to set this manually.\n\n#### transport\n\nA custom `WorkerTransport` instance. If not provided, a new transport is created on every request.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "## Stateless MCP Servers\n\nMany MCP Servers are stateless, meaning they don't maintain any session state between requests. The `createMcpHandler` function is a lightweight alternative to the `McpAgent` class that can be used to serve an MCP server straight from a Worker. View the [complete example on GitHub](https://github.com/cloudflare/agents/tree/main/examples/mcp-worker).\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Each request to this MCP server creates a new session. The server doesn't maintain state between requests. This is the simplest way to implement an MCP server.\n\n## Stateful MCP Servers\n\nFor stateful MCP servers that need to maintain session state across multiple requests, you can use the `createMcpHandler` function with a `WorkerTransport` instance directly in an `Agent`. This is useful if you want to make use of advanced client features like elicitation and sampling.\n\nProvide a custom `WorkerTransport` with persistent storage. View the [complete example on GitHub](https://github.com/cloudflare/agents/tree/main/examples/mcp-elicitation).\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "In this case we are defining the `sessionIdGenerator` to return the Agent name as the session ID. To make sure we route to the correct Agent we can use `getAgentByName` in the Worker handler:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "With persistent storage, the transport preserves:\n\n* Session ID across reconnections\n* Protocol version negotiation state\n* Initialization status\n\nThis allows MCP clients to reconnect and resume their session in the event of a connection loss.\n\n### WorkerTransport\n\nThe `WorkerTransport` class implements the MCP Transport interface, handling HTTP request/response cycles, Server-Sent Events (SSE) streaming, session management, and CORS.",
      "language": "unknown"
    },
    {
      "code": "#### Constructor Options",
      "language": "unknown"
    },
    {
      "code": "#### sessionIdGenerator\n\nProvides a custom session identifier. This session identifier is used to identify the session in the MCP Client.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "#### enableJsonResponse\n\nDisables SSE streaming and returns responses as standard JSON.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "#### onsessioninitialized\n\nA callback that fires when a session is initialized, either by creating a new session or restoring from storage.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "#### corsOptions\n\nConfigure CORS headers for cross-origin requests.",
      "language": "unknown"
    },
    {
      "code": "* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "#### storage\n\nPersist transport state to survive Durable Object hibernation or restarts.",
      "language": "unknown"
    },
    {
      "code": "* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "## Authentication Context\n\nWhen using [OAuth authentication](https://developers.cloudflare.com/agents/model-context-protocol/authorization/) with `createMcpHandler`, user information is made available to your MCP tools through `getMcpAuthContext()`. Under the hood this uses `AsyncLocalStorage` to pass the request to the tool handler, keeping the authentication context available.",
      "language": "unknown"
    },
    {
      "code": "### getMcpAuthContext\n\nRetrieve the current authentication context within an MCP tool handler. This returns user information that was populated by the OAuth provider. Note that if using `McpAgent`, this information is accessable directly on `this.props` instead.",
      "language": "unknown"
    },
    {
      "code": "* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "Note\n\nFor a complete guide on setting up OAuth authentication with MCP servers, see the [MCP Authorization documentation](https://developers.cloudflare.com/agents/model-context-protocol/authorization/). View the [complete authenticated MCP server in a Worker example on GitHub](https://github.com/cloudflare/agents/tree/main/examples/mcp-worker-authenticated).\n\n## Error Handling\n\nThe `createMcpHandler` automatically catches errors and returns JSON-RPC error responses with code `-32603` (Internal error).\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "## Related Resources\n\n* [Building MCP Servers](https://developers.cloudflare.com/agents/guides/remote-mcp-server/) — Learn how to build and deploy MCP servers on Cloudflare\n* [MCP Tools](https://developers.cloudflare.com/agents/model-context-protocol/tools/) — Add tools to your MCP server\n* [MCP Authorization](https://developers.cloudflare.com/agents/model-context-protocol/authorization/) — Authenticate users with OAuth\n* [McpAgent API Reference](https://developers.cloudflare.com/agents/model-context-protocol/mcp-agent-api/) — Build stateful MCP servers with the McpAgent class\n\n</page>\n\n<page>\n---\ntitle: MCP server portals · Cloudflare Agents docs\ndescription: Centralize multiple MCP servers onto a single endpoint and\n  customize the tools, prompts, and resources available to users.\nlastUpdated: 2025-10-24T20:47:24.000Z\nchatbotDeprioritize: false\ntags: MCP\nsource_url:\n  html: https://developers.cloudflare.com/agents/model-context-protocol/mcp-portal/\n  md: https://developers.cloudflare.com/agents/model-context-protocol/mcp-portal/index.md\n---\n\n\n</page>\n\n<page>\n---\ntitle: Cloudflare's own MCP servers · Cloudflare Agents docs\ndescription: Cloudflare runs a catalog of managed remote MCP Servers which you\n  can connect to using OAuth on clients like Claude, Windsurf, our own AI\n  Playground or any SDK that supports MCP.\nlastUpdated: 2025-10-14T11:50:10.000Z\nchatbotDeprioritize: false\ntags: MCP\nsource_url:\n  html: https://developers.cloudflare.com/agents/model-context-protocol/mcp-servers-for-cloudflare/\n  md: https://developers.cloudflare.com/agents/model-context-protocol/mcp-servers-for-cloudflare/index.md\n---\n\nCloudflare runs a catalog of managed remote MCP Servers which you can connect to using OAuth on clients like [Claude](https://modelcontextprotocol.io/quickstart/user), [Windsurf](https://docs.windsurf.com/windsurf/cascade/mcp), our own [AI Playground](https://playground.ai.cloudflare.com/) or any [SDK that supports MCP](https://github.com/cloudflare/agents/tree/main/packages/agents/src/mcp).\n\nThese MCP servers allow your MCP Client to read configurations from your account, process information, make suggestions based on data, and even make those suggested changes for you. All of these actions can happen across Cloudflare's many services including application development, security and performance. They support both the `streamble-http` transport via `/mcp` and the `sse` transport (deprecated) via `/sse`.\n\n| Server Name | Description | Server URL |\n| - | - | - |\n| [Documentation server](https://github.com/cloudflare/mcp-server-cloudflare/tree/main/apps/docs-vectorize) | Get up to date reference information on Cloudflare | `https://docs.mcp.cloudflare.com/mcp` |\n| [Workers Bindings server](https://github.com/cloudflare/mcp-server-cloudflare/tree/main/apps/workers-bindings) | Build Workers applications with storage, AI, and compute primitives | `https://bindings.mcp.cloudflare.com/mcp` |\n| [Workers Builds server](https://github.com/cloudflare/mcp-server-cloudflare/tree/main/apps/workers-builds) | Get insights and manage your Cloudflare Workers Builds | `https://builds.mcp.cloudflare.com/mcp` |\n| [Observability server](https://github.com/cloudflare/mcp-server-cloudflare/tree/main/apps/workers-observability) | Debug and get insight into your application's logs and analytics | `https://observability.mcp.cloudflare.com/mcp` |\n| [Radar server](https://github.com/cloudflare/mcp-server-cloudflare/tree/main/apps/radar) | Get global Internet traffic insights, trends, URL scans, and other utilities | `https://radar.mcp.cloudflare.com/mcp` |\n| [Container server](https://github.com/cloudflare/mcp-server-cloudflare/tree/main/apps/sandbox-container) | Spin up a sandbox development environment | `https://containers.mcp.cloudflare.com/mcp` |\n| [Browser rendering server](https://github.com/cloudflare/mcp-server-cloudflare/tree/main/apps/browser-rendering) | Fetch web pages, convert them to markdown and take screenshots | `https://browser.mcp.cloudflare.com/mcp` |\n| [Logpush server](https://github.com/cloudflare/mcp-server-cloudflare/tree/main/apps/logpush) | Get quick summaries for Logpush job health | `https://logs.mcp.cloudflare.com/mcp` |\n| [AI Gateway server](https://github.com/cloudflare/mcp-server-cloudflare/tree/main/apps/ai-gateway) | Search your logs, get details about the prompts and responses | `https://ai-gateway.mcp.cloudflare.com/mcp` |\n| [AI Search server](https://github.com/cloudflare/mcp-server-cloudflare/tree/main/apps/autorag) | List and search documents on your AI Searchs | `https://autorag.mcp.cloudflare.com/mcp` |\n| [Audit Logs server](https://github.com/cloudflare/mcp-server-cloudflare/tree/main/apps/auditlogs) | Query audit logs and generate reports for review | `https://auditlogs.mcp.cloudflare.com/mcp` |\n| [DNS Analytics server](https://github.com/cloudflare/mcp-server-cloudflare/tree/main/apps/dns-analytics) | Optimize DNS performance and debug issues based on current set up | `https://dns-analytics.mcp.cloudflare.com/mcp` |\n| [Digital Experience Monitoring server](https://github.com/cloudflare/mcp-server-cloudflare/tree/main/apps/dex-analysis) | Get quick insight on critical applications for your organization | `https://dex.mcp.cloudflare.com/mcp` |\n| [Cloudflare One CASB server](https://github.com/cloudflare/mcp-server-cloudflare/tree/main/apps/cloudflare-one-casb) | Quickly identify any security misconfigurations for SaaS applications to safeguard users & data | `https://casb.mcp.cloudflare.com/mcp` |\n| [GraphQL server](https://github.com/cloudflare/mcp-server-cloudflare/tree/main/apps/graphql/) | Get analytics data using Cloudflare’s GraphQL API | `https://graphql.mcp.cloudflare.com/mcp` |\n\nCheck our [GitHub page](https://github.com/cloudflare/mcp-server-cloudflare) to know how to use Cloudflare's remote MCP servers with different MCP clients.\n\n</page>\n\n<page>\n---\ntitle: Tools · Cloudflare Agents docs\ndescription: Model Context Protocol (MCP) tools are functions that a MCP Server\n  provides and MCP clients can call.\nlastUpdated: 2025-11-24T11:51:24.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/agents/model-context-protocol/tools/\n  md: https://developers.cloudflare.com/agents/model-context-protocol/tools/index.md\n---\n\nModel Context Protocol (MCP) tools are functions that a [MCP Server](https://developers.cloudflare.com/agents/model-context-protocol) provides and MCP clients can call.\n\nWhen you build MCP Servers with the `agents` package, you can define tools the [same way as shown in the `@modelcontextprotocol/typescript-sdk` package's examples](https://github.com/modelcontextprotocol/typescript-sdk?tab=readme-ov-file#tools).\n\nFor example, the following code from [this example MCP server](https://github.com/cloudflare/ai/tree/main/demos/remote-mcp-server) defines a simple MCP server that adds two numbers together:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Transport · Cloudflare Agents docs\ndescription: \"The Model Context Protocol (MCP) specification defines two\n  standard transport mechanisms for communication between clients and servers:\"\nlastUpdated: 2025-11-27T20:01:09.000Z\nchatbotDeprioritize: false\ntags: MCP\nsource_url:\n  html: https://developers.cloudflare.com/agents/model-context-protocol/transport/\n  md: https://developers.cloudflare.com/agents/model-context-protocol/transport/index.md\n---\n\nThe Model Context Protocol (MCP) specification defines two standard [transport mechanisms](https://spec.modelcontextprotocol.io/specification/draft/basic/transports/) for communication between clients and servers:\n\n1. **stdio** — Communication over standard in and standard out, designed for local MCP connections.\n2. **Streamable HTTP** — The standard transport method for remote MCP connections, [introduced](https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#streamable-http) in March 2025. It uses a single HTTP endpoint for bidirectional messaging.\n\nNote\n\nServer-Sent Events (SSE) was previously used for remote MCP connections but has been deprecated in favor of Streamable HTTP. If you need SSE support for legacy clients, use the [`McpAgent`](https://developers.cloudflare.com/agents/model-context-protocol/mcp-agent-api/) class.\n\nMCP servers built with the [Agents SDK](https://developers.cloudflare.com/agents) use [`createMcpHandler`](https://developers.cloudflare.com/agents/model-context-protocol/mcp-handler-api/) to handle Streamable HTTP transport.\n\n## Implementing remote MCP transport\n\nUse [`createMcpHandler`](https://developers.cloudflare.com/agents/model-context-protocol/mcp-handler-api/) to create an MCP server that handles Streamable HTTP transport. This is the recommended approach for new MCP servers.\n\n#### Get started quickly\n\nYou can use the \"Deploy to Cloudflare\" button to create a remote MCP server.\n\n[![Deploy to Workers](https://deploy.workers.cloudflare.com/button)](https://deploy.workers.cloudflare.com/?url=https://github.com/cloudflare/agents/tree/main/examples/mcp-worker)\n\n#### Remote MCP server (without authentication)\n\nCreate an MCP server using `createMcpHandler`. View the [complete example on GitHub](https://github.com/cloudflare/agents/tree/main/examples/mcp-worker).\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "#### MCP server with authentication\n\nIf your MCP server implements authentication & authorization using the [Workers OAuth Provider](https://github.com/cloudflare/workers-oauth-provider) library, use `createMcpHandler` with the `apiRoute` and `apiHandler` properties. View the [complete example on GitHub](https://github.com/cloudflare/agents/tree/main/examples/mcp-worker-authenticated).\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "### Stateful MCP servers\n\nIf your MCP server needs to maintain state across requests, use `createMcpHandler` with a `WorkerTransport` inside an [Agent](https://developers.cloudflare.com/agents/) class. This allows you to persist session state in Durable Object storage and use advanced MCP features like [elicitation](https://modelcontextprotocol.io/specification/draft/client/elicitation) and [sampling](https://modelcontextprotocol.io/specification/draft/client/sampling).\n\nSee [Stateful MCP Servers](https://developers.cloudflare.com/agents/model-context-protocol/mcp-handler-api#stateful-mcp-servers) for implementation details.\n\n### Migrating from McpAgent\n\nIf you have an existing MCP server using the `McpAgent` class:\n\n* **Not using state?** Replace your `McpAgent` class with `McpServer` from `@modelcontextprotocol/sdk` and use `createMcpHandler(server)` in a Worker `fetch` handler.\n* **Using state?** Use `createMcpHandler` with a `WorkerTransport` inside an [Agent](https://developers.cloudflare.com/agents/) class. See [Stateful MCP Servers](https://developers.cloudflare.com/agents/model-context-protocol/mcp-handler-api#stateful-mcp-servers) for details.\n* **Need SSE support?** Continue using `McpAgent` with `serveSSE()` for legacy client compatibility. See the [McpAgent API reference](https://developers.cloudflare.com/agents/model-context-protocol/mcp-agent-api/).\n\n### Testing with MCP clients\n\nYou can test your MCP server using an MCP client that supports remote connections, or use [`mcp-remote`](https://www.npmjs.com/package/mcp-remote), an adapter that lets MCP clients that only support local connections work with remote MCP servers.\n\nFollow [this guide](https://developers.cloudflare.com/agents/guides/test-remote-mcp-server/) for instructions on how to connect to your remote MCP server to Claude Desktop, Cursor, Windsurf, and other MCP clients.\n\n</page>\n\n<page>\n---\ntitle: Limits · Cloudflare Agents docs\ndescription: Limits that apply to authoring, deploying, and running Agents are\n  detailed below.\nlastUpdated: 2025-07-30T08:17:23.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/agents/platform/limits/\n  md: https://developers.cloudflare.com/agents/platform/limits/index.md\n---\n\nLimits that apply to authoring, deploying, and running Agents are detailed below.\n\nMany limits are inherited from those applied to Workers scripts and/or Durable Objects, and are detailed in the [Workers limits](https://developers.cloudflare.com/workers/platform/limits/) documentation.\n\n| Feature | Limit |\n| - | - |\n| Max concurrent (running) Agents per account | Tens of millions+ [1](#user-content-fn-1) |\n| Max definitions per account | \\~250,000+ [2](#user-content-fn-2) |\n| Max state stored per unique Agent | 1 GB |\n| Max compute time per Agent | 30 seconds (refreshed per HTTP request / incoming WebSocket message) [3](#user-content-fn-3) |\n| Duration (wall clock) per step [3](#user-content-fn-3) | Unlimited (for example, waiting on a database call or an LLM response) |\n\n***\n\nNeed a higher limit?\n\nTo request an adjustment to a limit, complete the [Limit Increase Request Form](https://forms.gle/ukpeZVLWLnKeixDu7). If the limit can be increased, Cloudflare will contact you with next steps.\n\n## Footnotes\n\n1. Yes, really. You can have tens of millions of Agents running concurrently, as each Agent is mapped to a [unique Durable Object](https://developers.cloudflare.com/durable-objects/concepts/what-are-durable-objects/) (actor). [↩](#user-content-fnref-1)\n\n2. You can deploy up to [500 scripts per account](https://developers.cloudflare.com/workers/platform/limits/), but each script (project) can define multiple Agents. Each deployed script can be up to 10 MB on the [Workers Paid Plan](https://developers.cloudflare.com/workers/platform/pricing/#workers) [↩](#user-content-fnref-2)\n\n3. Compute (CPU) time per Agent is limited to 30 seconds, but this is refreshed when an Agent receives a new HTTP request, runs a [scheduled task](https://developers.cloudflare.com/agents/api-reference/schedule-tasks/), or an incoming WebSocket message. [↩](#user-content-fnref-3) [↩2](#user-content-fnref-3-2)\n\n</page>\n\n<page>\n---\ntitle: Prompt Engineering · Cloudflare Agents docs\ndescription: Learn how to prompt engineer your AI models & tools when building\n  Agents & Workers on Cloudflare.\nlastUpdated: 2025-02-25T13:55:21.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/agents/platform/prompting/\n  md: https://developers.cloudflare.com/agents/platform/prompting/index.md\n---\n\n\n</page>\n\n<page>\n---\ntitle: prompt.txt · Cloudflare Agents docs\ndescription: Provide context to your AI models & tools when building on Cloudflare.\nlastUpdated: 2025-02-28T08:13:41.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/agents/platform/prompttxt/\n  md: https://developers.cloudflare.com/agents/platform/prompttxt/index.md\n---\n\n\n</page>\n\n<page>\n---\ntitle: Authenticated Gateway · Cloudflare AI Gateway docs\ndescription: Add security by requiring a valid authorization token for each request.\nlastUpdated: 2025-10-07T18:26:33.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/configuration/authentication/\n  md: https://developers.cloudflare.com/ai-gateway/configuration/authentication/index.md\n---\n\nUsing an Authenticated Gateway in AI Gateway adds security by requiring a valid authorization token for each request. This feature is especially useful when storing logs, as it prevents unauthorized access and protects against invalid requests that can inflate log storage usage and make it harder to find the data you need. With Authenticated Gateway enabled, only requests with the correct token are processed.\n\nNote\n\nWe recommend enabling Authenticated Gateway when opting to store logs with AI Gateway.\n\nIf Authenticated Gateway is enabled but a request does not include the required `cf-aig-authorization` header, the request will fail. This setting ensures that only verified requests pass through the gateway. To bypass the need for the `cf-aig-authorization` header, make sure to disable Authenticated Gateway.\n\n## Setting up Authenticated Gateway using the Dashboard\n\n1. Go to the Settings for the specific gateway you want to enable authentication for.\n2. Select **Create authentication token** to generate a custom token with the required `Run` permissions. Be sure to securely save this token, as it will not be displayed again.\n3. Include the `cf-aig-authorization` header with your API token in each request for this gateway.\n4. Return to the settings page and toggle on Authenticated Gateway.\n\n## Example requests with OpenAI",
      "language": "unknown"
    },
    {
      "code": "Using the OpenAI SDK:",
      "language": "unknown"
    },
    {
      "code": "## Example requests with the Vercel AI SDK",
      "language": "unknown"
    },
    {
      "code": "## Expected behavior\n\nNote\n\nWhen an AI Gateway is accessed from a Cloudflare Worker using a **binding**, the `cf-aig-authorization` header does not need to be manually included.\\\nRequests made through bindings are **pre-authenticated** within the associated Cloudflare account.\n\nThe following table outlines gateway behavior based on the authentication settings and header status:\n\n| Authentication Setting | Header Info | Gateway State | Response |\n| - | - | - | - |\n| On | Header present | Authenticated gateway | Request succeeds |\n| On | No header | Error | Request fails due to missing authorization |\n| Off | Header present | Unauthenticated gateway | Request succeeds |\n| Off | No header | Unauthenticated gateway | Request succeeds |\n\n</page>\n\n<page>\n---\ntitle: BYOK (Store Keys) · Cloudflare AI Gateway docs\ndescription: Bring your own keys (BYOK) is a feature in Cloudflare AI Gateway\n  that allows you to securely store your AI provider API keys directly in the\n  Cloudflare dashboard. Instead of including API keys in every request to your\n  AI models, you can configure them once in the dashboard, and reference them in\n  your gateway configuration.\nlastUpdated: 2025-09-03T14:48:22.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/configuration/bring-your-own-keys/\n  md: https://developers.cloudflare.com/ai-gateway/configuration/bring-your-own-keys/index.md\n---\n\n## Introduction\n\nBring your own keys (BYOK) is a feature in Cloudflare AI Gateway that allows you to securely store your AI provider API keys directly in the Cloudflare dashboard. Instead of including API keys in every request to your AI models, you can configure them once in the dashboard, and reference them in your gateway configuration.\n\nThe keys are stored securely with [Secrets Store](https://developers.cloudflare.com/secrets-store/) and allows for:\n\n* Secure storage and limit exposure\n* Easier key rotation\n* Rate limit, budget limit and other restrictions with [Dynamic Routes](https://developers.cloudflare.com/ai-gateway/features/dynamic-routing/)\n\n## Setting up BYOK\n\n### Prerequisites\n\n* Ensure your gateway is [authenticated](https://developers.cloudflare.com/ai-gateway/configuration/authentication/).\n* Ensure you have appropriate [permissions](https://developers.cloudflare.com/secrets-store/access-control/) to create and deploy secrets on Secrets Store.\n\n### Configure API keys\n\n1. Log into the [Cloudflare dashboard](https://dash.cloudflare.com/) and select your account.\n2. Go to **AI** > **AI Gateway**.\n3. Select your gateway or create a new one.\n4. Go to the **Provider Keys** section.\n5. Click **Add API Key**.\n6. Select your AI provider from the dropdown.\n7. Enter your API key and optionally provide a description.\n8. Click **Save**.\n\n### Update your applications\n\nOnce you've configured your API keys in the dashboard:\n\n1. **Remove API keys from your code**: Delete any hardcoded API keys or environment variables.\n2. **Update request headers**: Remove provider authorization headers from your requests. Note that you still need to pass `cf-aig-authorization`.\n3. **Test your integration**: Verify that requests work without including API keys.\n\n## Example\n\nWith BYOK enabled, your workflow changes from:\n\n1. **Traditional approach**: Include API key in every request header",
      "language": "unknown"
    },
    {
      "code": "2. **BYOK approach**: Configure key once in dashboard, make requests without exposing keys",
      "language": "unknown"
    },
    {
      "code": "## Managing API keys\n\n### Viewing configured keys\n\nIn the AI Gateway dashboard, you can:\n\n* View all configured API keys by provider\n* See when each key was last used\n* Check the status of each key (active, expired, invalid)\n\n### Rotating keys\n\nTo rotate an API key:\n\n1. Generate a new API key from your AI provider\n2. In the Cloudflare dashboard, edit the existing key entry\n3. Replace the old key with the new one\n4. Save the changes\n\nYour applications will immediately start using the new key without any code changes or downtime.\n\n### Revoking access\n\nTo remove an API key:\n\n1. In the AI Gateway dashboard, find the key you want to remove\n2. Click the **Delete** button\n3. Confirm the deletion\n\nImpact of key deletion\n\nDeleting an API key will immediately stop all requests that depend on it. Make sure to update your applications or configure alternative keys before deletion.\n\n</page>\n\n<page>\n---\ntitle: Custom costs · Cloudflare AI Gateway docs\ndescription: Override default or public model costs on a per-request basis.\nlastUpdated: 2025-03-05T12:30:57.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/configuration/custom-costs/\n  md: https://developers.cloudflare.com/ai-gateway/configuration/custom-costs/index.md\n---\n\nAI Gateway allows you to set custom costs at the request level. By using this feature, the cost metrics can accurately reflect your unique pricing, overriding the default or public model costs.\n\nNote\n\nCustom costs will only apply to requests that pass tokens in their response. Requests without token information will not have costs calculated.\n\n## Custom cost\n\nTo add custom costs to your API requests, use the `cf-aig-custom-cost` header. This header enables you to specify the cost per token for both input (tokens sent) and output (tokens received).\n\n* **per\\_token\\_in**: The negotiated input token cost (per token).\n* **per\\_token\\_out**: The negotiated output token cost (per token).\n\nThere is no limit to the number of decimal places you can include, ensuring precise cost calculations, regardless of how small the values are.\n\nCustom costs will appear in the logs with an underline, making it easy to identify when custom pricing has been applied.\n\nIn this example, if you have a negotiated price of $1 per million input tokens and $2 per million output tokens, include the `cf-aig-custom-cost` header as shown below.",
      "language": "unknown"
    },
    {
      "code": "Note\n\nIf a response is served from cache (cache hit), the cost is always `0`, even if you specified a custom cost. Custom costs only apply when the request reaches the model provider.\n\n</page>\n\n<page>\n---\ntitle: Custom Providers · Cloudflare AI Gateway docs\ndescription: Create and manage custom AI providers for your account.\nlastUpdated: 2025-11-24T10:12:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/configuration/custom-providers/\n  md: https://developers.cloudflare.com/ai-gateway/configuration/custom-providers/index.md\n---\n\n## Overview\n\nCustom Providers allow you to integrate AI providers that are not natively supported by AI Gateway. This feature enables you to use AI Gateway's observability, caching, rate limiting, and other features with any AI provider that has an HTTPS API endpoint.\n\n## Use cases\n\n* **Internal AI models**: Connect to your organization's self-hosted AI models\n* **Regional providers**: Integrate with AI providers specific to your region\n* **Specialized models**: Use domain-specific AI services not available through standard providers\n* **Custom endpoints**: Route requests to your own AI infrastructure\n\n## Before you begin\n\n### Prerequisites\n\n* An active Cloudflare account with AI Gateway access\n* A valid API key from your custom AI provider\n* The HTTPS base URL for your provider's API\n\n### Authentication\n\nThe API endpoints for creating, reading, updating, or deleting custom providers require authentication. You need to create a Cloudflare API token with the appropriate permissions.\n\nTo create an API token:\n\n1. Go to the [Cloudflare dashboard API tokens page](https://dash.cloudflare.com/?to=:account/api-tokens)\n2. Click **Create Token**\n3. Select **Custom Token** and add the following permissions:\n   * `AI Gateway - Edit`\n4. Click **Continue to summary** and then **Create Token**\n5. Copy the token - you'll use it in the `Authorization: Bearer $CLOUDFLARE_API_TOKEN` header\n\n## Create a custom provider\n\n* API\n\n  To create a new custom provider using the API:\n\n  1. Get your [Account ID](https://developers.cloudflare.com/fundamentals/account/find-account-and-zone-ids/) and Account Tag.\n\n  2. Send a `POST` request to create a new custom provider:",
      "language": "unknown"
    },
    {
      "code": "**Required fields:**\n\n  * `name` (string): Display name for your provider\n  * `slug` (string): Unique identifier (alphanumeric with hyphens). Must be unique within your account.\n  * `base_url` (string): HTTPS URL for your provider's API endpoint. Must start with `https://`.\n\n  **Optional fields:**\n\n  * `description` (string): Description of the provider\n  * `link` (string): URL to provider documentation\n  * `enable` (boolean): Whether the provider is active (default: `false`)\n  * `beta` (boolean): Mark as beta feature (default: `false`)\n  * `curl_example` (string): Example cURL command for using the provider\n  * `js_example` (string): Example JavaScript code for using the provider\n\n  **Response:**",
      "language": "unknown"
    },
    {
      "code": "Auto-generated logo\n\n  A default SVG logo is automatically generated for each custom provider. The logo is returned as a base64-encoded string.\n\n* Dashboard\n\n  To create a new custom provider using the dashboard:\n\n  1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com) and select your account.\n\n  2. Go to [**Compute & AI** > **AI Gateway** > **Custom Providers**](https://dash.cloudflare.com/?to=/:account/ai/ai-gateway/custom-providers).\n\n  3. Select **Add Custom Provider**.\n\n  4. Enter the following information:\n\n     * **Provider Name**: Display name for your provider\n     * **Provider Slug**: Unique identifier (alphanumeric with hyphens)\n     * **Base URL**: HTTPS URL for your provider's API endpoint (e.g., `https://api.myprovider.com/v1`)\n\n  5. Select **Save** to create your custom provider.\n\n## List custom providers\n\n* API\n\n  Retrieve all custom providers with optional filtering and pagination:",
      "language": "unknown"
    },
    {
      "code": "**Query parameters:**\n\n  * `page` (number): Page number (default: `1`)\n  * `per_page` (number): Items per page (default: `20`, max: `100`)\n  * `enable` (boolean): Filter by enabled status\n  * `beta` (boolean): Filter by beta status\n  * `search` (string): Search in id, name, or slug fields\n  * `order_by` (string): Sort field and direction (default: `\"name ASC\"`)\n\n  **Examples:**\n\n  List only enabled providers:",
      "language": "unknown"
    },
    {
      "code": "Search for specific providers:",
      "language": "unknown"
    },
    {
      "code": "**Response:**",
      "language": "unknown"
    },
    {
      "code": "* Dashboard\n\n  To view all your custom providers:\n\n  1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com) and select your account.\n  2. Go to [**Compute & AI** > **AI Gateway** > **Custom Providers**](https://dash.cloudflare.com/?to=/:account/ai/ai-gateway/custom-providers).\n  3. You will see a list of all your custom providers with their names, slugs, base URLs, and status.\n\n## Get a specific custom provider\n\n* API\n\n  Retrieve details for a specific custom provider by its ID:",
      "language": "unknown"
    },
    {
      "code": "**Response:**",
      "language": "unknown"
    },
    {
      "code": "## Update a custom provider\n\n* API\n\n  Update an existing custom provider. All fields are optional - only include the fields you want to change:",
      "language": "unknown"
    },
    {
      "code": "**Updatable fields:**\n\n  * `name` (string): Provider display name\n  * `slug` (string): Provider identifier\n  * `base_url` (string): API endpoint URL (must be HTTPS)\n  * `description` (string): Provider description\n  * `link` (string): Documentation URL\n  * `enable` (boolean): Active status\n  * `beta` (boolean): Beta flag\n  * `curl_example` (string): Example cURL command\n  * `js_example` (string): Example JavaScript code\n\n  **Examples:**\n\n  Enable a provider:",
      "language": "unknown"
    },
    {
      "code": "Update provider URL:",
      "language": "unknown"
    },
    {
      "code": "Cache invalidation\n\n  Updates to custom providers automatically invalidate any cached entries related to that provider.\n\n* Dashboard\n\n  To update an existing custom provider:\n\n  1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com) and select your account.\n  2. Go to [**Compute & AI** > **AI Gateway** > **Custom Providers**](https://dash.cloudflare.com/?to=/:account/ai/ai-gateway/custom-providers).\n  3. Find the custom provider you want to update and select **Edit**.\n  4. Update the fields you want to change (name, slug, base URL, etc.).\n  5. Select **Save** to apply your changes.\n\n## Delete a custom provider\n\n* API\n\n  Delete a custom provider:",
      "language": "unknown"
    },
    {
      "code": "**Response:**",
      "language": "unknown"
    },
    {
      "code": "Impact of deletion\n\n  Deleting a custom provider will immediately stop all requests routed through it. Ensure you have updated your applications before deleting a provider. Cache entries related to the provider will also be invalidated.\n\n* Dashboard\n\n  To delete a custom provider:\n\n  1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com) and select your account.\n  2. Go to [**Compute & AI** > **AI Gateway** > **Custom Providers**](https://dash.cloudflare.com/?to=/:account/ai/ai-gateway/custom-providers).\n  3. Find the custom provider you want to delete and select **Delete**.\n  4. Confirm the deletion when prompted.\n\n  Impact of deletion\n\n  Deleting a custom provider will immediately stop all requests routed through it. Ensure you have updated your applications before deleting a provider.\n\n## Using custom providers with AI Gateway\n\nOnce you've created a custom provider, you can route requests through AI Gateway. When referencing your custom provider, you must prefix the slug with `custom-`.\n\nCustom provider prefix\n\nAll custom provider slugs must be prefixed with `custom-` when making requests through AI Gateway. For example, if your provider slug is `some-provider`, you must use `custom-some-provider` in your requests.\n\n### Via Unified API",
      "language": "unknown"
    },
    {
      "code": "In the Unified API, specify the model using the format: `custom-{slug}/{model-name}`\n\n### Via provider-specific endpoint",
      "language": "unknown"
    },
    {
      "code": "The request will be proxied to: `https://api.myprovider.com/your-endpoint`\n\n**Path structure:** `/{account_id}/{gateway_id}/custom-{slug}/{provider-path}`\n\n## Common errors\n\n### 409 Conflict - Duplicate slug",
      "language": "unknown"
    },
    {
      "code": "Each custom provider slug must be unique within your account. Choose a different slug or update the existing provider.\n\n### 404 Not Found",
      "language": "unknown"
    },
    {
      "code": "The specified provider ID does not exist or you don't have access to it. Verify the provider ID and your authentication credentials.\n\n### 400 Bad Request - Invalid base\\_url",
      "language": "unknown"
    },
    {
      "code": "The `base_url` field must be a valid HTTPS URL. HTTP URLs are not supported for security reasons.\n\n## Best practices\n\n1. **Use descriptive slugs**: Choose slugs that clearly identify the provider (e.g., `internal-gpt`, `regional-ai`)\n2. **Document your integrations**: Use the `curl_example` and `js_example` fields to provide usage examples\n3. **Enable gradually**: Test with `enable: false` before making the provider active\n4. **Monitor usage**: Use AI Gateway's analytics to track requests to your custom providers\n5. **Secure your endpoints**: Ensure your custom provider's base URL implements proper authentication and authorization\n6. **Use BYOK**: Store provider API keys securely using [BYOK](https://developers.cloudflare.com/ai-gateway/configuration/bring-your-own-keys/) instead of including them in every request\n\n## Limitations\n\n* Custom providers are account-specific and not shared across Cloudflare accounts\n* The `base_url` must use HTTPS (HTTP is not supported)\n* Provider slugs must be unique within each account\n* Cache and rate limiting settings apply globally to the provider, not per-model\n\n## Related resources\n\n* [Get started with AI Gateway](https://developers.cloudflare.com/ai-gateway/get-started/)\n* [Configure authentication](https://developers.cloudflare.com/ai-gateway/configuration/authentication/)\n* [BYOK (Store Keys)](https://developers.cloudflare.com/ai-gateway/configuration/bring-your-own-keys/)\n* [Dynamic routing](https://developers.cloudflare.com/ai-gateway/features/dynamic-routing/)\n* [Caching](https://developers.cloudflare.com/ai-gateway/features/caching/)\n* [Rate limiting](https://developers.cloudflare.com/ai-gateway/features/rate-limiting/)\n\n</page>\n\n<page>\n---\ntitle: Fallbacks · Cloudflare AI Gateway docs\ndescription: Specify model or provider fallbacks with your Universal endpoint to\n  handle request failures and ensure reliability.\nlastUpdated: 2025-08-20T18:25:25.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/configuration/fallbacks/\n  md: https://developers.cloudflare.com/ai-gateway/configuration/fallbacks/index.md\n---\n\nSpecify model or provider fallbacks with your [Universal endpoint](https://developers.cloudflare.com/ai-gateway/usage/universal/) to handle request failures and ensure reliability.\n\nCloudflare can trigger your fallback provider in response to [request errors](#request-failures) or [predetermined request timeouts](https://developers.cloudflare.com/ai-gateway/configuration/request-handling#request-timeouts). The [response header `cf-aig-step`](#response-headercf-aig-step) indicates which step successfully processed the request.\n\n## Request failures\n\nBy default, Cloudflare triggers your fallback if a model request returns an error.\n\n### Example\n\nIn the following example, a request first goes to the [Workers AI](https://developers.cloudflare.com/workers-ai/) Inference API. If the request fails, it falls back to OpenAI. The response header `cf-aig-step` indicates which provider successfully processed the request.\n\n1. Sends a request to Workers AI Inference API.\n2. If that request fails, proceeds to OpenAI.",
      "language": "unknown"
    },
    {
      "code": "You can add as many fallbacks as you need, just by adding another object in the array.",
      "language": "unknown"
    },
    {
      "code": "## Response header(cf-aig-step)\n\nWhen using the [Universal endpoint](https://developers.cloudflare.com/ai-gateway/usage/universal/) with fallbacks, the response header `cf-aig-step` indicates which model successfully processed the request by returning the step number. This header provides visibility into whether a fallback was triggered and which model ultimately processed the response.\n\n* `cf-aig-step:0` – The first (primary) model was used successfully.\n* `cf-aig-step:1` – The request fell back to the second model.\n* `cf-aig-step:2` – The request fell back to the third model.\n* Subsequent steps – Each fallback increments the step number by 1.\n\n</page>\n\n<page>\n---\ntitle: Manage gateways · Cloudflare AI Gateway docs\ndescription: You have several different options for managing an AI Gateway.\nlastUpdated: 2025-08-20T18:25:25.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/configuration/manage-gateway/\n  md: https://developers.cloudflare.com/ai-gateway/configuration/manage-gateway/index.md\n---\n\nYou have several different options for managing an AI Gateway.\n\n## Create gateway\n\n* Dashboard\n\n  [Create a Gateway](https://dash.cloudflare.com/?to=/:account/ai/ai-gateway#create)\n\n  1. Log into the [Cloudflare dashboard](https://dash.cloudflare.com/) and select your account.\n  2. Go to **AI** > **AI Gateway**.\n  3. Select **Create Gateway**.\n  4. Enter your **Gateway name**. Note: Gateway name has a 64 character limit.\n  5. Select **Create**.\n\n* API\n\n  To set up an AI Gateway using the API:\n\n  1. [Create an API token](https://developers.cloudflare.com/fundamentals/api/get-started/create-token/) with the following permissions:\n\n     * `AI Gateway - Read`\n     * `AI Gateway - Edit`\n\n  2. Get your [Account ID](https://developers.cloudflare.com/fundamentals/account/find-account-and-zone-ids/).\n\n  3. Using that API token and Account ID, send a [`POST` request](https://developers.cloudflare.com/api/resources/ai_gateway/methods/create/) to the Cloudflare API.\n\n## Edit gateway\n\n* Dashboard\n\n  To edit an AI Gateway in the dashboard:\n\n  1. Log into the [Cloudflare dashboard](https://dash.cloudflare.com/) and select your account.\n  2. Go to **AI** > **AI Gateway**.\n  3. Select your gateway.\n  4. Go to **Settings** and update as needed.\n\n* API\n\n  To edit an AI Gateway, send a [`PUT` request](https://developers.cloudflare.com/api/resources/ai_gateway/methods/update/) to the Cloudflare API.\n\nNote\n\nFor more details about what settings are available for editing, refer to [Configuration](https://developers.cloudflare.com/ai-gateway/configuration/).\n\n## Delete gateway\n\nDeleting your gateway is permanent and can not be undone.\n\n* Dashboard\n\n  To delete an AI Gateway in the dashboard:\n\n  1. Log into the [Cloudflare dashboard](https://dash.cloudflare.com/) and select your account.\n  2. Go to **AI** > **AI Gateway**.\n  3. Select your gateway from the list of available options.\n  4. Go to **Settings**.\n  5. For **Delete Gateway**, select **Delete** (and confirm your deletion).\n\n* API\n\n  To delete an AI Gateway, send a [`DELETE` request](https://developers.cloudflare.com/api/resources/ai_gateway/methods/delete/) to the Cloudflare API.\n\n</page>\n\n<page>\n---\ntitle: Request handling · Cloudflare AI Gateway docs\ndescription: Your AI gateway supports different strategies for handling requests\n  to providers, which allows you to manage AI interactions effectively and\n  ensure your applications remain responsive and reliable.\nlastUpdated: 2025-08-19T11:42:14.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/configuration/request-handling/\n  md: https://developers.cloudflare.com/ai-gateway/configuration/request-handling/index.md\n---\n\nDeprecated\n\nWhile the request handling features described on this page still work, [Dynamic Routing](https://developers.cloudflare.com/ai-gateway/features/dynamic-routing/) is now the preferred way to achieve advanced request handling, including timeouts, retries, and fallbacks. Dynamic Routing provides a more powerful and flexible approach with a visual interface for managing complex routing scenarios.\n\nYour AI gateway supports different strategies for handling requests to providers, which allows you to manage AI interactions effectively and ensure your applications remain responsive and reliable.\n\n## Request timeouts\n\nA request timeout allows you to trigger fallbacks or a retry if a provider takes too long to respond.\n\nThese timeouts help:\n\n* Improve user experience, by preventing users from waiting too long for a response\n* Proactively handle errors, by detecting unresponsive providers and triggering a fallback option\n\nRequest timeouts can be set on a Universal Endpoint or directly on a request to any provider.\n\n### Definitions\n\nA timeout is set in milliseconds. Additionally, the timeout is based on when the first part of the response comes back. As long as the first part of the response returns within the specified timeframe - such as when streaming a response - your gateway will wait for the response.\n\n### Configuration\n\n#### Universal Endpoint\n\nIf set on a [Universal Endpoint](https://developers.cloudflare.com/ai-gateway/usage/universal/), a request timeout specifies the timeout duration for requests and triggers a fallback.\n\nFor a Universal Endpoint, configure the timeout value by setting a `requestTimeout` property within the provider-specific `config` object. Each provider can have a different `requestTimeout` value for granular customization.",
      "language": "unknown"
    },
    {
      "code": "#### Direct provider\n\nIf set on a [provider](https://developers.cloudflare.com/ai-gateway/usage/providers/) request, request timeout specifies the timeout duration for a request and - if exceeded - returns an error.\n\nFor a provider-specific endpoint, configure the timeout value by adding a `cf-aig-request-timeout` header.",
      "language": "unknown"
    },
    {
      "code": "***\n\n## Request retries\n\nAI Gateway also supports automatic retries for failed requests, with a maximum of five retry attempts.\n\nThis feature improves your application's resiliency, ensuring you can recover from temporary issues without manual intervention.\n\nRequest timeouts can be set on a Universal Endpoint or directly on a request to any provider.\n\n### Definitions\n\nWith request retries, you can adjust a combination of three properties:\n\n* Number of attempts (maximum of 5 tries)\n* How long before retrying (in milliseconds, maximum of 5 seconds)\n* Backoff method (constant, linear, or exponential)\n\nOn the final retry attempt, your gateway will wait until the request completes, regardless of how long it takes.\n\n### Configuration\n\n#### Universal endpoint\n\nIf set on a [Universal Endpoint](https://developers.cloudflare.com/ai-gateway/usage/universal/), a request retry will automatically retry failed requests up to five times before triggering any configured fallbacks.\n\nFor a Universal Endpoint, configure the retry settings with the following properties in the provider-specific `config`:",
      "language": "unknown"
    },
    {
      "code": "As with the [request timeout](https://developers.cloudflare.com/ai-gateway/configuration/request-handling/#universal-endpoint), each provider can have a different retry settings for granular customization.",
      "language": "unknown"
    },
    {
      "code": "#### Direct provider\n\nIf set on a [provider](https://developers.cloudflare.com/ai-gateway/usage/universal/) request, a request retry will automatically retry failed requests up to five times. On the final retry attempt, your gateway will wait until the request completes, regardless of how long it takes.\n\nFor a provider-specific endpoint, configure the retry settings by adding different header values:\n\n* `cf-aig-max-attempts` (number)\n* `cf-aig-retry-delay` (number)\n* `cf-aig-backoff` (\"constant\" | \"linear\" | \"exponential)\n\n</page>\n\n<page>\n---\ntitle: Add Human Feedback using Dashboard · Cloudflare AI Gateway docs\ndescription: Human feedback is a valuable metric to assess the performance of\n  your AI models. By incorporating human feedback, you can gain deeper insights\n  into how the model's responses are perceived and how well it performs from a\n  user-centric perspective. This feedback can then be used in evaluations to\n  calculate performance metrics, driving optimization and ultimately enhancing\n  the reliability, accuracy, and efficiency of your AI application.\nlastUpdated: 2025-09-05T08:34:36.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/evaluations/add-human-feedback/\n  md: https://developers.cloudflare.com/ai-gateway/evaluations/add-human-feedback/index.md\n---\n\nHuman feedback is a valuable metric to assess the performance of your AI models. By incorporating human feedback, you can gain deeper insights into how the model's responses are perceived and how well it performs from a user-centric perspective. This feedback can then be used in evaluations to calculate performance metrics, driving optimization and ultimately enhancing the reliability, accuracy, and efficiency of your AI application.\n\nHuman feedback measures the performance of your dataset based on direct human input. The metric is calculated as the percentage of positive feedback (thumbs up) given on logs, which are annotated in the Logs tab of the Cloudflare dashboard. This feedback helps refine model performance by considering real-world evaluations of its output.\n\nThis tutorial will guide you through the process of adding human feedback to your evaluations in AI Gateway using the Cloudflare dashboard.\n\nOn the next guide, you can [learn how to add human feedback via the API](https://developers.cloudflare.com/ai-gateway/evaluations/add-human-feedback-api/).\n\n## 1. Log in to the dashboard\n\nIn the Cloudflare dashboard, go to the **AI Gateway** page.\n\n[Go to **AI Gateway**](https://dash.cloudflare.com/?to=/:account/ai/ai-gateway)\n\n## 2. Access the Logs tab\n\n1. Go to **Logs**.\n\n2. The Logs tab displays all logs associated with your datasets. These logs show key information, including:\n\n   * Timestamp: When the interaction occurred.\n   * Status: Whether the request was successful, cached, or failed.\n   * Model: The model used in the request.\n   * Tokens: The number of tokens consumed by the response.\n   * Cost: The cost based on token usage.\n   * Duration: The time taken to complete the response.\n   * Feedback: Where you can provide human feedback on each log.\n\n## 3. Provide human feedback\n\n1. Click on the log entry you want to review. This expands the log, allowing you to see more detailed information.\n\n2. In the expanded log, you can view additional details such as:\n\n   * The user prompt.\n   * The model response.\n   * HTTP response details.\n   * Endpoint information.\n\n3. You will see two icons:\n\n   * Thumbs up: Indicates positive feedback.\n   * Thumbs down: Indicates negative feedback.\n\n4. Click either the thumbs up or thumbs down icon based on how you rate the model response for that particular log entry.\n\n## 4. Evaluate human feedback\n\nAfter providing feedback on your logs, it becomes a part of the evaluation process.\n\nWhen you run an evaluation (as outlined in the [Set Up Evaluations](https://developers.cloudflare.com/ai-gateway/evaluations/set-up-evaluations/) guide), the human feedback metric will be calculated based on the percentage of logs that received thumbs-up feedback.\n\nNote\n\nYou need to select human feedback as an evaluator to receive its metrics.\n\n## 5. Review results\n\nAfter running the evaluation, review the results on the Evaluations tab. You will be able to see the performance of the model based on cost, speed, and now human feedback, represented as the percentage of positive feedback (thumbs up).\n\nThe human feedback score is displayed as a percentage, showing the distribution of positively rated responses from the database.\n\nFor more information on running evaluations, refer to the documentation [Set Up Evaluations](https://developers.cloudflare.com/ai-gateway/evaluations/set-up-evaluations/).\n\n</page>\n\n<page>\n---\ntitle: Add Human Feedback using API · Cloudflare AI Gateway docs\ndescription: This guide will walk you through the steps of adding human feedback\n  to an AI Gateway request using the Cloudflare API. You will learn how to\n  retrieve the relevant request logs, and submit feedback using the API.\nlastUpdated: 2025-08-19T11:42:14.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/evaluations/add-human-feedback-api/\n  md: https://developers.cloudflare.com/ai-gateway/evaluations/add-human-feedback-api/index.md\n---\n\nThis guide will walk you through the steps of adding human feedback to an AI Gateway request using the Cloudflare API. You will learn how to retrieve the relevant request logs, and submit feedback using the API.\n\nIf you prefer to add human feedback via the dashboard, refer to [Add Human Feedback](https://developers.cloudflare.com/ai-gateway/evaluations/add-human-feedback/).\n\n## 1. Create an API Token\n\n1. [Create an API token](https://developers.cloudflare.com/fundamentals/api/get-started/create-token/) with the following permissions:\n\n* `AI Gateway - Read`\n* `AI Gateway - Edit`\n\n1. Get your [Account ID](https://developers.cloudflare.com/fundamentals/account/find-account-and-zone-ids/).\n2. Using that API token and Account ID, send a [`POST` request](https://developers.cloudflare.com/api/resources/ai_gateway/methods/create/) to the Cloudflare API.\n\n## 2. Retrieve the `cf-aig-log-id`\n\nThe `cf-aig-log-id` is a unique identifier for the specific log entry to which you want to add feedback. Below are two methods to obtain this identifier.\n\n### Method 1: Locate the `cf-aig-log-id` in the request response\n\nThis method allows you to directly find the `cf-aig-log-id` within the header of the response returned by the AI Gateway. This is the most straightforward approach if you have access to the original API response.\n\nThe steps below outline how to do this.\n\n1. **Make a Request to the AI Gateway**: This could be a request your application sends to the AI Gateway. Once the request is made, the response will contain various pieces of metadata.\n2. **Check the Response Headers**: The response will include a header named `cf-aig-log-id`. This is the identifier you will need to submit feedback.\n\nIn the example below, the `cf-aig-log-id` is `01JADMCQQQBWH3NXZ5GCRN98DP`.",
      "language": "unknown"
    },
    {
      "code": "### Method 2: Retrieve the `cf-aig-log-id` via API (GET request)\n\nIf you do not have the `cf-aig-log-id` in the response body or you need to access it after the fact, you are able to retrieve it by querying the logs using the [Cloudflare API](https://developers.cloudflare.com/api/resources/ai_gateway/subresources/logs/methods/list/).\n\nSend a `GET` request to get a list of logs and then find a specific ID\n\nRequired API token permissions\n\nAt least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n* `AI Gateway Write`\n* `AI Gateway Read`",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "### Method 3: Retrieve the `cf-aig-log-id` via a binding\n\nYou can also retrieve the `cf-aig-log-id` using a binding, which streamlines the process. Here's how to retrieve the log ID directly:",
      "language": "unknown"
    },
    {
      "code": "Note:\n\nThe `aiGatewayLogId` property, will only hold the last inference call log id.\n\n## 3. Submit feedback via PATCH request\n\nOnce you have both the API token and the `cf-aig-log-id`, you can send a PATCH request to submit feedback.\n\nRequired API token permissions\n\nAt least one of the following [token permissions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) is required:\n\n* `AI Gateway Write`",
      "language": "unknown"
    },
    {
      "code": "If you had negative feedback, adjust the body of the request to be `-1`.",
      "language": "unknown"
    },
    {
      "code": "## 4. Verify the feedback submission\n\nYou can verify the feedback submission in two ways:\n\n* **Through the [Cloudflare dashboard ](https://dash.cloudflare.com)**: check the updated feedback on the AI Gateway interface.\n* **Through the API**: Send another GET request to retrieve the updated log entry and confirm the feedback has been recorded.\n\n</page>\n\n<page>\n---\ntitle: Add human feedback using Worker Bindings · Cloudflare AI Gateway docs\ndescription: This guide explains how to provide human feedback for AI Gateway\n  evaluations using Worker bindings.\nlastUpdated: 2025-08-19T11:42:14.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/evaluations/add-human-feedback-bindings/\n  md: https://developers.cloudflare.com/ai-gateway/evaluations/add-human-feedback-bindings/index.md\n---\n\nThis guide explains how to provide human feedback for AI Gateway evaluations using Worker bindings.\n\n## 1. Run an AI Evaluation\n\nStart by sending a prompt to the AI model through your AI Gateway.",
      "language": "unknown"
    },
    {
      "code": "Let the user interact with or evaluate the AI response. This interaction will inform the feedback you send back to the AI Gateway.\n\n## 2. Send Human Feedback\n\nUse the [`patchLog()`](https://developers.cloudflare.com/ai-gateway/integrations/worker-binding-methods/#31-patchlog-send-feedback) method to provide feedback for the AI evaluation.",
      "language": "unknown"
    },
    {
      "code": "## Feedback parameters explanation\n\n* `feedback`: is either `-1` for negative or `1` to positive, `0` is considered not evaluated.\n* `score`: A number between 0 and 100.\n* `metadata`: An object containing additional contextual information.\n\n### patchLog: Send Feedback\n\nThe `patchLog` method allows you to send feedback, score, and metadata for a specific log ID. All object properties are optional, so you can include any combination of the parameters:",
      "language": "unknown"
    },
    {
      "code": "Returns: `Promise<void>` (Make sure to `await` the request.)\n\n</page>\n\n<page>\n---\ntitle: Set up Evaluations · Cloudflare AI Gateway docs\ndescription: This guide walks you through the process of setting up an\n  evaluation in AI Gateway. These steps are done in the Cloudflare dashboard.\nlastUpdated: 2025-08-19T11:42:14.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/evaluations/set-up-evaluations/\n  md: https://developers.cloudflare.com/ai-gateway/evaluations/set-up-evaluations/index.md\n---\n\nThis guide walks you through the process of setting up an evaluation in AI Gateway. These steps are done in the [Cloudflare dashboard](https://dash.cloudflare.com/).\n\n## 1. Select or create a dataset\n\nDatasets are collections of logs stored for analysis that can be used in an evaluation. You can create datasets by applying filters in the Logs tab. Datasets will update automatically based on the set filters.\n\n### Set up a dataset from the Logs tab\n\n1. Apply filters to narrow down your logs. Filter options include provider, number of tokens, request status, and more.\n2. Select **Create Dataset** to store the filtered logs for future analysis.\n\nYou can manage datasets by selecting **Manage datasets** from the Logs tab.\n\nNote\n\nPlease keep in mind that datasets currently use `AND` joins, so there can only be one item per filter (for example, one model or one provider). Future updates will allow more flexibility in dataset creation.\n\n### List of available filters\n\n| Filter category | Filter options | Filter by description |\n| - | - | - |\n| Status | error, status | error type or status. |\n| Cache | cached, not cached | based on whether they were cached or not. |\n| Provider | specific providers | the selected AI provider. |\n| AI Models | specific models | the selected AI model. |\n| Cost | less than, greater than | cost, specifying a threshold. |\n| Request type | Universal, Workers AI Binding, WebSockets | the type of request. |\n| Tokens | Total tokens, Tokens In, Tokens Out | token count (less than or greater than). |\n| Duration | less than, greater than | request duration. |\n| Feedback | equals, does not equal (thumbs up, thumbs down, no feedback) | feedback type. |\n| Metadata Key | equals, does not equal | specific metadata keys. |\n| Metadata Value | equals, does not equal | specific metadata values. |\n| Log ID | equals, does not equal | a specific Log ID. |\n| Event ID | equals, does not equal | a specific Event ID. |\n\n## 2. Select evaluators\n\nAfter creating a dataset, choose the evaluation parameters:\n\n* Cost: Calculates the average cost of inference requests within the dataset (only for requests with [cost data](https://developers.cloudflare.com/ai-gateway/observability/costs/)).\n* Speed: Calculates the average duration of inference requests within the dataset.\n* Performance:\n  * Human feedback: measures performance based on human feedback, calculated by the % of thumbs up on the logs, annotated from the Logs tab.\n\nNote\n\nAdditional evaluators will be introduced in future updates to expand performance analysis capabilities.\n\n## 3. Name, review, and run the evaluation\n\n1. Create a unique name for your evaluation to reference it in the dashboard.\n2. Review the selected dataset and evaluators.\n3. Select **Run** to start the process.\n\n## 4. Review and analyze results\n\nEvaluation results will appear in the Evaluations tab. The results show the status of the evaluation (for example, in progress, completed, or error). Metrics for the selected evaluators will be displayed, excluding any logs with missing fields. You will also see the number of logs used to calculate each metric.\n\nWhile datasets automatically update based on filters, evaluations do not. You will have to create a new evaluation if you want to evaluate new logs.\n\nUse these insights to optimize based on your application's priorities. Based on the results, you may choose to:\n\n* Change the model or [provider](https://developers.cloudflare.com/ai-gateway/usage/providers/)\n* Adjust your prompts\n* Explore further optimizations, such as setting up [Retrieval Augmented Generation (RAG)](https://developers.cloudflare.com/reference-architecture/diagrams/ai/ai-rag/)\n\n</page>\n\n<page>\n---\ntitle: Caching · Cloudflare AI Gateway docs\ndescription: Override caching settings on a per-request basis.\nlastUpdated: 2025-08-19T11:42:14.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/features/caching/\n  md: https://developers.cloudflare.com/ai-gateway/features/caching/index.md\n---\n\nAI Gateway can cache responses from your AI model providers, serving them directly from Cloudflare's cache for identical requests.\n\n## Benefits of Using Caching\n\n* **Reduced Latency:** Serve responses faster to your users by avoiding a round trip to the origin AI provider for repeated requests.\n* **Cost Savings:** Minimize the number of paid requests made to your AI provider, especially for frequently accessed or non-dynamic content.\n* **Increased Throughput:** Offload repetitive requests from your AI provider, allowing it to handle unique requests more efficiently.\n\nNote\n\nCurrently caching is supported only for text and image responses, and it applies only to identical requests.\n\nThis configuration benefits use cases with limited prompt options. For example, a support bot that asks \"How can I help you?\" and lets the user select an answer from a limited set of options works well with the current caching configuration. We plan on adding semantic search for caching in the future to improve cache hit rates.\n\n## Default configuration\n\n* Dashboard\n\n  To set the default caching configuration in the dashboard:\n\n  1. Log into the [Cloudflare dashboard](https://dash.cloudflare.com/) and select your account.\n  2. Select **AI** > **AI Gateway**.\n  3. Select **Settings**.\n  4. Enable **Cache Responses**.\n  5. Change the default caching to whatever value you prefer.\n\n* API\n\n  To set the default caching configuration using the API:\n\n  1. [Create an API token](https://developers.cloudflare.com/fundamentals/api/get-started/create-token/) with the following permissions:\n\n  * `AI Gateway - Read`\n  * `AI Gateway - Edit`\n\n  1. Get your [Account ID](https://developers.cloudflare.com/fundamentals/account/find-account-and-zone-ids/).\n  2. Using that API token and Account ID, send a [`POST` request](https://developers.cloudflare.com/api/resources/ai_gateway/methods/create/) to create a new Gateway and include a value for the `cache_ttl`.\n\nThis caching behavior will be uniformly applied to all requests that support caching. If you need to modify the cache settings for specific requests, you have the flexibility to override this setting on a per-request basis.\n\nTo check whether a response comes from cache or not, **cf-aig-cache-status** will be designated as `HIT` or `MISS`.\n\n## Per-request caching\n\nWhile your gateway's default cache settings provide a good baseline, you might need more granular control. These situations could be data freshness, content with varying lifespans, or dynamic or personalized responses.\n\nTo address these needs, AI Gateway allows you to override default cache behaviors on a per-request basis using specific HTTP headers. This gives you the precision to optimize caching for individual API calls.\n\nThe following headers allow you to define this per-request cache behavior:\n\nNote\n\nThe following headers have been updated to new names, though the old headers will still function. We recommend updating to the new headers to ensure future compatibility:\n\n`cf-cache-ttl` is now `cf-aig-cache-ttl`\n\n`cf-skip-cache` is now `cf-aig-skip-cache`\n\n### Skip cache (cf-aig-skip-cache)\n\nSkip cache refers to bypassing the cache and fetching the request directly from the original provider, without utilizing any cached copy.\n\nYou can use the header **cf-aig-skip-cache** to bypass the cached version of the request.\n\nAs an example, when submitting a request to OpenAI, include the header in the following manner:",
      "language": "unknown"
    },
    {
      "code": "### Cache TTL (cf-aig-cache-ttl)\n\nCache TTL, or Time To Live, is the duration a cached request remains valid before it expires and is refreshed from the original source. You can use **cf-aig-cache-ttl** to set the desired caching duration in seconds. The minimum TTL is 60 seconds and the maximum TTL is one month.\n\nFor example, if you set a TTL of one hour, it means that a request is kept in the cache for an hour. Within that hour, an identical request will be served from the cache instead of the original API. After an hour, the cache expires and the request will go to the original API for a fresh response, and that response will repopulate the cache for the next hour.\n\nAs an example, when submitting a request to OpenAI, include the header in the following manner:",
      "language": "unknown"
    },
    {
      "code": "### Custom cache key (cf-aig-cache-key)\n\nCustom cache keys let you override the default cache key in order to precisely set the cacheability setting for any resource. To override the default cache key, you can use the header **cf-aig-cache-key**.\n\nWhen you use the **cf-aig-cache-key** header for the first time, you will receive a response from the provider. Subsequent requests with the same header will return the cached response. If the **cf-aig-cache-ttl** header is used, responses will be cached according to the specified Cache Time To Live. Otherwise, responses will be cached according to the cache settings in the dashboard. If caching is not enabled for the gateway, responses will be cached for 5 minutes by default.\n\nAs an example, when submitting a request to OpenAI, include the header in the following manner:",
      "language": "unknown"
    },
    {
      "code": "AI Gateway caching behavior\n\nCache in AI Gateway is volatile. If two identical requests are sent simultaneously, the first request may not cache in time for the second request to use it, which may result in the second request retrieving data from the original source.\n\n</page>\n\n<page>\n---\ntitle: Data Loss Prevention (DLP) · Cloudflare AI Gateway docs\ndescription: Data Loss Prevention (DLP) for AI Gateway helps protect your\n  organization from inadvertent exposure of sensitive data through AI\n  interactions. By integrating with Cloudflare's proven DLP technology, AI\n  Gateway can scan both incoming prompts and outgoing AI responses for sensitive\n  information, ensuring your AI applications maintain security and compliance\n  standards.\nlastUpdated: 2025-10-22T21:11:06.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/features/dlp/\n  md: https://developers.cloudflare.com/ai-gateway/features/dlp/index.md\n---\n\nData Loss Prevention (DLP) for AI Gateway helps protect your organization from inadvertent exposure of sensitive data through AI interactions. By integrating with Cloudflare's proven DLP technology, AI Gateway can scan both incoming prompts and outgoing AI responses for sensitive information, ensuring your AI applications maintain security and compliance standards.\n\n## How it works\n\nAI Gateway DLP leverages the same powerful detection engines used in [Cloudflare's Data Loss Prevention](https://developers.cloudflare.com/cloudflare-one/data-loss-prevention/) solution to scan AI traffic in real-time. The system analyzes both user prompts sent to AI models and responses received from AI providers, identifying sensitive data patterns and taking appropriate protective actions.\n\n## Key benefits\n\n* **Prevent data leakage**: Stop sensitive information from being inadvertently shared with AI providers or exposed in AI responses\n* **Maintain compliance**: Help meet regulatory requirements like GDPR, HIPAA, and PCI DSS\n* **Consistent protection**: Apply the same DLP policies across all AI providers and models\n* **Audit visibility**: Comprehensive logging and reporting for security and compliance teams\n* **Zero-code integration**: Enable protection without modifying existing AI applications\n\n## Supported AI traffic\n\nAI Gateway DLP can scan:\n\n* **User prompts** - Content submitted to AI models, including text, code, and structured data\n* **AI responses** - Output generated by AI models before being returned to users\n\nThe system works with all AI providers supported by AI Gateway, providing consistent protection regardless of which models or services you use.\n\n## Integration with Cloudflare DLP\n\nAI Gateway DLP uses the same detection profiles and policies as Cloudflare's enterprise DLP solution. This means:\n\n* **Unified management** - Configure DLP policies once and apply them across web traffic, email, SaaS applications, and AI interactions\n* **Consistent detection** - The same sensitive data patterns are detected across all channels\n* **Centralized reporting** - All DLP events appear in the same dashboard and logs\n* **Shared profiles** - Reuse existing DLP detection profiles for AI traffic\n\nFor more information about Cloudflare's DLP capabilities, refer to the [Data Loss Prevention documentation](https://developers.cloudflare.com/cloudflare-one/data-loss-prevention/).\n\n## Getting started\n\nTo enable DLP for your AI Gateway:\n\n1. [Set up DLP policies](https://developers.cloudflare.com/ai-gateway/features/dlp/set-up-dlp/) for your AI Gateway\n2. Configure detection profiles and response actions\n3. Monitor DLP events through the Cloudflare dashboard\n\n## Related resources\n\n* [Set up DLP for AI Gateway](https://developers.cloudflare.com/ai-gateway/features/dlp/set-up-dlp/)\n* [Cloudflare Data Loss Prevention](https://developers.cloudflare.com/cloudflare-one/data-loss-prevention/)\n* [AI Gateway Security Features](https://developers.cloudflare.com/ai-gateway/features/guardrails/)\n* [DLP Detection Profiles](https://developers.cloudflare.com/cloudflare-one/data-loss-prevention/dlp-profiles/)\n\n</page>\n\n<page>\n---\ntitle: Dynamic routing · Cloudflare AI Gateway docs\ndescription: \"Dynamic routing enables you to create request routing flows\n  through a visual interface or a JSON-based configuration. Instead of\n  hard-coding a single model, with Dynamic Routing you compose a small flow that\n  evaluates conditions, enforces quotas, and chooses models with fallbacks. You\n  can iterate without touching application code—publish a new route version and\n  you’re done. With dynamic routing, you can easily implement advanced use cases\n  such as:\"\nlastUpdated: 2025-08-23T11:12:09.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/features/dynamic-routing/\n  md: https://developers.cloudflare.com/ai-gateway/features/dynamic-routing/index.md\n---\n\n## Introduction\n\nDynamic routing enables you to create request routing flows through a **visual interface** or a **JSON-based configuration**. Instead of hard-coding a single model, with Dynamic Routing you compose a small flow that evaluates conditions, enforces quotas, and chooses models with fallbacks. You can iterate without touching application code—publish a new route version and you’re done. With dynamic routing, you can easily implement advanced use cases such as:\n\n* Directing different segments (paid/not-paid user) to different models\n* Restricting each user/project/team with budget/rate limits\n* A/B and gradual rollouts\n\nwhile making it accessible to both developers and non-technical team members.\n\n![Dynamic Routing Overview](https://developers.cloudflare.com/_astro/dynamic-routing.BtwkWywo_ZkRSjM.webp)\n\n## Core Concepts\n\n* **Route**: A named, versioned flow (for example, dynamic/support) that you can use as instead of the model name in your requests.\n\n* **Nodes**\n\n  * **Start**: Entry point for the route.\n  * **Conditional**: If/Else branch based on expressions that reference request body, headers, or metadata (for example, user\\_plan == \"paid\").\n  * **Percentage**: Routes requests probabilistically across multiple outputs, useful for A/B testing and gradual rollouts.\n  * **Model**: Calls a provider/model with the request parameters\n  * **Rate Limit**: Enforces number of requests quotas (per your key, per period) and switches to fallback when exceeded.\n  * **Budget Limit**: Enforces cost quotas (per your key, per period) and switches to fallback when exceeded.\n  * **End**: Terminates the flow and returns the final model response.\n\n* **Metadata**: Arbitrary key-value context attached to the request (for example, userId, orgId, plan). You can pass this from your app so rules can reference it.\n\n* **Versions**: Each change produces a new draft. Deploy to make it live with instant rollback.\n\n## Getting Started\n\nWarning\n\nEnsure your gateway has [authentication](https://developers.cloudflare.com/ai-gateway/configuration/authentication/) turned on, and you have your upstream providers keys stored with [BYOK](https://developers.cloudflare.com/ai-gateway/configuration/bring-your-own-keys/).\n\n1. Create a route.\n\n   * Go to **(Select your gateway)** > **Dynamic Routes** > **Add Route**, and name it (for example, `support`).\n   * Open **Editor**.\n\n2. Define conditionals, limits and other settings.\n\n3. Configure model nodes.\n\n   * Example:\n\n     * Node A: Provider OpenAI, Model `o4-mini-high`\n     * Node B: Provider OpenAI, Model `gpt-4.1`\n\n4. Save a version.\n\n   * Click **Save** to save the state. You can always roll back to earlier versions from **Versions**.\n   * Deploy the version to make it live.\n\n5. Call the route from your code.\n   * Use the [OpenAI compatible](https://developers.cloudflare.com/ai-gateway/usage/chat-completion/) endpoint, and use the route name in place of the model, for example, `dynamic/support`.\n\n</page>\n\n<page>\n---\ntitle: Guardrails · Cloudflare AI Gateway docs\ndescription: Guardrails help you deploy AI applications safely by intercepting\n  and evaluating both user prompts and model responses for harmful content.\n  Acting as a proxy between your application and model providers (such as\n  OpenAI, Anthropic, DeepSeek, and others), AI Gateway's Guardrails ensure a\n  consistent and secure experience across your entire AI ecosystem.\nlastUpdated: 2025-08-19T11:42:14.000Z\nchatbotDeprioritize: false\ntags: AI\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/features/guardrails/\n  md: https://developers.cloudflare.com/ai-gateway/features/guardrails/index.md\n---\n\nGuardrails help you deploy AI applications safely by intercepting and evaluating both user prompts and model responses for harmful content. Acting as a proxy between your application and [model providers](https://developers.cloudflare.com/ai-gateway/usage/providers/) (such as OpenAI, Anthropic, DeepSeek, and others), AI Gateway's Guardrails ensure a consistent and secure experience across your entire AI ecosystem.\n\nGuardrails proactively monitor interactions between users and AI models, giving you:\n\n* **Consistent moderation**: Uniform moderation layer that works across models and providers.\n* **Enhanced safety and user trust**: Proactively protect users from harmful or inappropriate interactions.\n* **Flexibility and control over allowed content**: Specify which categories to monitor and choose between flagging or outright blocking.\n* **Auditing and compliance capabilities**: Receive updates on evolving regulatory requirements with logs of user prompts, model responses, and enforced guardrails.\n\n## Video demo\n\n## How Guardrails work\n\nAI Gateway inspects all interactions in real time by evaluating content against predefined safety parameters. Guardrails work by:\n\n1. Intercepting interactions: AI Gateway proxies requests and responses, sitting between the user and the AI model.\n\n2. Inspecting content:\n\n   * User prompts: AI Gateway checks prompts against safety parameters (for example, violence, hate, or sexual content). Based on your settings, prompts can be flagged or blocked before reaching the model.\n   * Model responses: Once processed, the AI model response is inspected. If hazardous content is detected, it can be flagged or blocked before being delivered to the user.\n\n3. Applying actions: Depending on your configuration, flagged content is logged for review, while blocked content is prevented from proceeding.\n\n## Related resource\n\n* [Cloudflare Blog: Keep AI interactions secure and risk-free with Guardrails in AI Gateway](https://blog.cloudflare.com/guardrails-in-ai-gateway/)\n\n</page>\n\n<page>\n---\ntitle: Rate limiting · Cloudflare AI Gateway docs\ndescription: Rate limiting controls the traffic that reaches your application,\n  which prevents expensive bills and suspicious activity.\nlastUpdated: 2025-08-19T11:42:14.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/features/rate-limiting/\n  md: https://developers.cloudflare.com/ai-gateway/features/rate-limiting/index.md\n---\n\nRate limiting controls the traffic that reaches your application, which prevents expensive bills and suspicious activity.\n\n## Parameters\n\nYou can define rate limits as the number of requests that get sent in a specific time frame. For example, you can limit your application to 100 requests per 60 seconds.\n\nYou can also select if you would like a **fixed** or **sliding** rate limiting technique. With rate limiting, we allow a certain number of requests within a window of time. For example, if it is a fixed rate, the window is based on time, so there would be no more than `x` requests in a ten minute window. If it is a sliding rate, there would be no more than `x` requests in the last ten minutes.\n\nTo illustrate this, let us say you had a limit of ten requests per ten minutes, starting at 12:00. So the fixed window is 12:00-12:10, 12:10-12:20, and so on. If you sent ten requests at 12:09 and ten requests at 12:11, all 20 requests would be successful in a fixed window strategy. However, they would fail in a sliding window strategy since there were more than ten requests in the last ten minutes.\n\n## Handling rate limits\n\nWhen your requests exceed the allowed rate, you will encounter rate limiting. This means the server will respond with a `429 Too Many Requests` status code and your request will not be processed.\n\n## Default configuration\n\n* Dashboard\n\n  To set the default rate limiting configuration in the dashboard:\n\n  1. Log into the [Cloudflare dashboard](https://dash.cloudflare.com/) and select your account.\n  2. Go to **AI** > **AI Gateway**.\n  3. Go to **Settings**.\n  4. Enable **Rate-limiting**.\n  5. Adjust the rate, time period, and rate limiting method as desired.\n\n* API\n\n  To set the default rate limiting configuration using the API:\n\n  1. [Create an API token](https://developers.cloudflare.com/fundamentals/api/get-started/create-token/) with the following permissions:\n\n  * `AI Gateway - Read`\n  * `AI Gateway - Edit`\n\n  1. Get your [Account ID](https://developers.cloudflare.com/fundamentals/account/find-account-and-zone-ids/).\n  2. Using that API token and Account ID, send a [`POST` request](https://developers.cloudflare.com/api/resources/ai_gateway/methods/create/) to create a new Gateway and include a value for the `rate_limiting_interval`, `rate_limiting_limit`, and `rate_limiting_technique`.\n\nThis rate limiting behavior will be uniformly applied to all requests for that gateway.\n\n</page>\n\n<page>\n---\ntitle: Unified Billing · Cloudflare AI Gateway docs\ndescription: Use the Cloudflare billing to pay for and authenticate your inference requests.\nlastUpdated: 2025-11-25T17:13:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/features/unified-billing/\n  md: https://developers.cloudflare.com/ai-gateway/features/unified-billing/index.md\n---\n\nUnified Billing allows users to connect to various AI providers (such as OpenAI, Anthropic, and Google AI Studio) and receive a single Cloudflare bill. To use Unified Billing, you must purchase and load credits into your Cloudflare account in the Cloudflare dashboard, which you can then spend with AI Gateway.\n\n## Pre-requisites\n\n* Ensure your Cloudflare account has [sufficient credits loaded](#load-credits).\n* Ensure you have [authenticated](https://developers.cloudflare.com/ai-gateway/configuration/authentication/) your AI Gateway.\n\n## Load credits\n\nTo load credits for AI Gateway:\n\n1. In the Cloudflare dashboard, go to the **AI Gateway** page.\n\n   [Go to **AI Gateway**](https://dash.cloudflare.com/?to=/:account/ai/ai-gateway)\n\n   The **Credits Available** card on the top right shows how many AI gateway credits you have on your account currently.\n\n2. In **Credits Available**, select **Manage**.\n\n3. If your account does not have an available payment method, AI Gateway will prompt you to add a payment method to purchase credits. Add a payment method.\n\n4. Select **Top-up credits**.\n\n5. Add the amount of credits you want to purchase, then select **Confirm and pay**.\n\n### Auto-top up\n\nYou can configure AI Gateway to automatically replenish your credits when they fall below a certain threshold. To configure auto top-up:\n\n1. In the Cloudflare dashboard, go to the **AI Gateway** page.\n\n   [Go to **AI Gateway**](https://dash.cloudflare.com/?to=/:account/ai/ai-gateway)\n\n2. In **Credits Available**, select **Manage**.\n\n3. Select **Setup auto top-up credits**.\n\n4. Choose a threshold and a recharge amount for auto top-up.\n\nWhen your balance falls below the set threshold, AI Gateway will automatically apply the auto top-up amount to your account.\n\n## Use Unified Billing\n\nCall any supported provider without passing an API Key. The request will automatically use Cloudflare's key and deduct credits from your account.\n\nFor example, you can use the Unified API:",
      "language": "unknown"
    },
    {
      "code": "### Spend limits\n\nSet spend limits to prevent unexpected charges on your loaded credits. You can define daily, weekly, or monthly limits. When a limit is reached, the AI Gateway automatically stops processing requests until the period resets or you increase the limit.\n\n### Supported providers\n\nUnified Billing supports the following AI providers:\n\n* [OpenAI](https://developers.cloudflare.com/ai-gateway/usage/providers/openai/)\n* [Anthropic](https://developers.cloudflare.com/ai-gateway/usage/providers/anthropic/)\n* [Google AI Studio](https://developers.cloudflare.com/ai-gateway/usage/providers/google-ai-studio/)\n* [xAI](https://developers.cloudflare.com/ai-gateway/usage/providers/grok/)\n* [Groq](https://developers.cloudflare.com/ai-gateway/usage/providers/groq/)\n\n</page>\n\n<page>\n---\ntitle: Workers AI · Cloudflare AI Gateway docs\ndescription: This guide will walk you through setting up and deploying a Workers\n  AI project. You will use Workers, an AI Gateway binding, and a large language\n  model (LLM) to deploy your first AI-powered application on the Cloudflare\n  global network.\nlastUpdated: 2025-10-09T15:47:46.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/integrations/aig-workers-ai-binding/\n  md: https://developers.cloudflare.com/ai-gateway/integrations/aig-workers-ai-binding/index.md\n---\n\nThis guide will walk you through setting up and deploying a Workers AI project. You will use [Workers](https://developers.cloudflare.com/workers/), an AI Gateway binding, and a large language model (LLM), to deploy your first AI-powered application on the Cloudflare global network.\n\n## Prerequisites\n\n1. Sign up for a [Cloudflare account](https://dash.cloudflare.com/sign-up/workers-and-pages).\n2. Install [`Node.js`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm).\n\nNode.js version manager\n\nUse a Node version manager like [Volta](https://volta.sh/) or [nvm](https://github.com/nvm-sh/nvm) to avoid permission issues and change Node.js versions. [Wrangler](https://developers.cloudflare.com/workers/wrangler/install-and-update/), discussed later in this guide, requires a Node version of `16.17.0` or later.\n\n## 1. Create a Worker Project\n\nYou will create a new Worker project using the create-Cloudflare CLI (C3). C3 is a command-line tool designed to help you set up and deploy new applications to Cloudflare.\n\nCreate a new project named `hello-ai` by running:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Running `npm create cloudflare@latest` will prompt you to install the create-cloudflare package and lead you through setup. C3 will also install [Wrangler](https://developers.cloudflare.com/workers/wrangler/), the Cloudflare Developer Platform CLI.\n\nFor setup, select the following options:\n\n* For *What would you like to start with?*, choose `Hello World example`.\n* For *Which template would you like to use?*, choose `Worker only`.\n* For *Which language do you want to use?*, choose `TypeScript`.\n* For *Do you want to use git for version control?*, choose `Yes`.\n* For *Do you want to deploy your application?*, choose `No` (we will be making some changes before deploying).\n\nThis will create a new `hello-ai` directory. Your new `hello-ai` directory will include:\n\n* A \"Hello World\" Worker at `src/index.ts`.\n* A [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/)\n\nGo to your application directory:",
      "language": "unknown"
    },
    {
      "code": "## 2. Connect your Worker to Workers AI\n\nYou must create an AI binding for your Worker to connect to Workers AI. Bindings allow your Workers to interact with resources, like Workers AI, on the Cloudflare Developer Platform.\n\nTo bind Workers AI to your Worker, add the following to the end of your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/):\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Your binding is [available in your Worker code](https://developers.cloudflare.com/workers/reference/migrate-to-module-workers/#bindings-in-es-modules-format) on [`env.AI`](https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch/).\n\nYou will need to have your `gateway id` for the next step. You can learn [how to create an AI Gateway in this tutorial](https://developers.cloudflare.com/ai-gateway/get-started/).\n\n## 3. Run an inference task containing AI Gateway in your Worker\n\nYou are now ready to run an inference task in your Worker. In this case, you will use an LLM, [`llama-3.1-8b-instruct-fast`](https://developers.cloudflare.com/workers-ai/models/llama-3.1-8b-instruct-fast/), to answer a question. Your gateway ID is found on the dashboard.\n\nUpdate the `index.ts` file in your `hello-ai` application directory with the following code:",
      "language": "unknown"
    },
    {
      "code": "Up to this point, you have created an AI binding for your Worker and configured your Worker to be able to execute the Llama 3.1 model. You can now test your project locally before you deploy globally.\n\n## 4. Develop locally with Wrangler\n\nWhile in your project directory, test Workers AI locally by running [`wrangler dev`](https://developers.cloudflare.com/workers/wrangler/commands/#dev):",
      "language": "unknown"
    },
    {
      "code": "Workers AI local development usage charges\n\nUsing Workers AI always accesses your Cloudflare account in order to run AI models and will incur usage charges even in local development.\n\nYou will be prompted to log in after you run `wrangler dev`. When you run `npx wrangler dev`, Wrangler will give you a URL (most likely `localhost:8787`) to review your Worker. After you go to the URL Wrangler provides, you will see a message that resembles the following example:",
      "language": "unknown"
    },
    {
      "code": "main()\n{\n  printf(\\\"Hello, World!\\\");\n}",
      "language": "unknown"
    },
    {
      "code": "## 5. Deploy your AI Worker\n\nBefore deploying your AI Worker globally, log in with your Cloudflare account by running:",
      "language": "unknown"
    },
    {
      "code": "You will be directed to a web page asking you to log in to the Cloudflare dashboard. After you have logged in, you will be asked if Wrangler can make changes to your Cloudflare account. Scroll down and select **Allow** to continue.\n\nFinally, deploy your Worker to make your project accessible on the Internet. To deploy your Worker, run:",
      "language": "unknown"
    },
    {
      "code": "Once deployed, your Worker will be available at a URL like:",
      "language": "unknown"
    },
    {
      "code": "Your Worker will be deployed to your custom [`workers.dev`](https://developers.cloudflare.com/workers/configuration/routing/workers-dev/) subdomain. You can now visit the URL to run your AI Worker.\n\nBy completing this tutorial, you have created a Worker, connected it to Workers AI through an AI Gateway binding, and successfully ran an inference task using the Llama 3.1 model.\n\n</page>\n\n<page>\n---\ntitle: Agents · Cloudflare AI Gateway docs\ndescription: Build AI-powered Agents on Cloudflare\nlastUpdated: 2025-01-29T20:30:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/integrations/agents/\n  md: https://developers.cloudflare.com/ai-gateway/integrations/agents/index.md\n---\n\n\n</page>\n\n<page>\n---\ntitle: Vercel AI SDK · Cloudflare AI Gateway docs\ndescription: >-\n  The Vercel AI SDK is a TypeScript library for building AI applications. The\n  SDK supports many different AI providers, tools for streaming completions, and\n  more.\n\n  To use Cloudflare AI Gateway with Vercel AI SDK, you will need to use the\n  ai-gateway-provider package.\nlastUpdated: 2025-12-08T07:14:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/integrations/vercel-ai-sdk/\n  md: https://developers.cloudflare.com/ai-gateway/integrations/vercel-ai-sdk/index.md\n---\n\nThe [Vercel AI SDK](https://sdk.vercel.ai/) is a TypeScript library for building AI applications. The SDK supports many different AI providers, tools for streaming completions, and more. To use Cloudflare AI Gateway with Vercel AI SDK, you will need to use the `ai-gateway-provider` package.\n\n## Installation",
      "language": "unknown"
    },
    {
      "code": "## Examples\n\nWith Key in Request\n\n* With Authenticated Gateway",
      "language": "unknown"
    },
    {
      "code": "* Unauthenticated Gateway",
      "language": "unknown"
    },
    {
      "code": "With Stored Keys (BYOK) / Unified Billing",
      "language": "unknown"
    },
    {
      "code": "### Fallback Providers\n\nTo specify model or provider fallbacks to handle request failures and ensure reliability, you can pass an array of models to the `model` option.",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: AI Gateway Binding Methods · Cloudflare AI Gateway docs\ndescription: This guide provides an overview of how to use the latest Cloudflare\n  Workers AI Gateway binding methods. You will learn how to set up an AI Gateway\n  binding, access new methods, and integrate them into your Workers.\nlastUpdated: 2025-10-09T15:47:46.000Z\nchatbotDeprioritize: false\ntags: Bindings\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/integrations/worker-binding-methods/\n  md: https://developers.cloudflare.com/ai-gateway/integrations/worker-binding-methods/index.md\n---\n\nThis guide provides an overview of how to use the latest Cloudflare Workers AI Gateway binding methods. You will learn how to set up an AI Gateway binding, access new methods, and integrate them into your Workers.\n\n## 1. Add an AI Binding to your Worker\n\nTo connect your Worker to Workers AI, add the following to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/):\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "This configuration sets up the AI binding accessible in your Worker code as `env.AI`.\n\nIf you're using TypeScript, run [`wrangler types`](https://developers.cloudflare.com/workers/wrangler/commands/#types) whenever you modify your Wrangler configuration file. This generates types for the `env` object based on your bindings, as well as [runtime types](https://developers.cloudflare.com/workers/languages/typescript/).\n\n## 2. Basic Usage with Workers AI + Gateway\n\nTo perform an inference task using Workers AI and an AI Gateway, you can use the following code:",
      "language": "unknown"
    },
    {
      "code": "Additionally, you can access the latest request log ID with:",
      "language": "unknown"
    },
    {
      "code": "## 3. Access the Gateway Binding\n\nYou can access your AI Gateway binding using the following code:",
      "language": "unknown"
    },
    {
      "code": "Once you have the gateway instance, you can use the following methods:\n\n### 3.1. `patchLog`: Send Feedback\n\nThe `patchLog` method allows you to send feedback, score, and metadata for a specific log ID. All object properties are optional, so you can include any combination of the parameters:",
      "language": "unknown"
    },
    {
      "code": "* **Returns**: `Promise<void>` (Make sure to `await` the request.)\n* **Example Use Case**: Update a log entry with user feedback or additional metadata.\n\n### 3.2. `getLog`: Read Log Details\n\nThe `getLog` method retrieves details of a specific log ID. It returns an object of type `Promise<AiGatewayLog>`. If this type is missing, ensure you have run [`wrangler types`](https://developers.cloudflare.com/workers/languages/typescript/#generate-types).",
      "language": "unknown"
    },
    {
      "code": "* **Returns**: `Promise<AiGatewayLog>`\n* **Example Use Case**: Retrieve log information for debugging or analytics.\n\n### 3.3. `getUrl`: Get Gateway URLs\n\nThe `getUrl` method allows you to retrieve the base URL for your AI Gateway, optionally specifying a provider to get the provider-specific endpoint.",
      "language": "unknown"
    },
    {
      "code": "* **Parameters**: Optional `provider` (string or `AIGatewayProviders` enum)\n* **Returns**: `Promise<string>`\n* **Example Use Case**: Dynamically construct URLs for direct API calls or debugging configurations.\n\n#### SDK Integration Examples\n\nThe `getUrl` method is particularly useful for integrating with popular AI SDKs:\n\n**OpenAI SDK:**",
      "language": "unknown"
    },
    {
      "code": "**Vercel AI SDK with OpenAI:**",
      "language": "unknown"
    },
    {
      "code": "**Vercel AI SDK with Anthropic:**",
      "language": "unknown"
    },
    {
      "code": "### 3.4. `run`: Universal Requests\n\nThe `run` method allows you to execute universal requests. Users can pass either a single universal request object or an array of them. This method supports all AI Gateway providers.\n\nRefer to the [Universal endpoint documentation](https://developers.cloudflare.com/ai-gateway/usage/universal/) for details about the available inputs.",
      "language": "unknown"
    },
    {
      "code": "* **Returns**: `Promise<Response>`\n* **Example Use Case**: Perform a [universal request](https://developers.cloudflare.com/ai-gateway/usage/universal/) to any supported provider.\n\n## Conclusion\n\nWith these AI Gateway binding methods, you can now:\n\n* Send feedback and update metadata with `patchLog`.\n* Retrieve detailed log information using `getLog`.\n* Get gateway URLs for direct API access with `getUrl`, making it easy to integrate with popular AI SDKs.\n* Execute universal requests to any AI Gateway provider with `run`.\n\nThese methods offer greater flexibility and control over your AI integrations, empowering you to build more sophisticated applications on the Cloudflare Workers platform.\n\n</page>\n\n<page>\n---\ntitle: Analytics · Cloudflare AI Gateway docs\ndescription: >-\n  Your AI Gateway dashboard shows metrics on requests, tokens, caching, errors,\n  and cost. You can filter these metrics by time.\n\n  These analytics help you understand traffic patterns, token consumption, and\n\n  potential issues across AI providers. You can\n\n  view the following analytics:\nlastUpdated: 2025-08-20T18:25:25.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/observability/analytics/\n  md: https://developers.cloudflare.com/ai-gateway/observability/analytics/index.md\n---\n\nYour AI Gateway dashboard shows metrics on requests, tokens, caching, errors, and cost. You can filter these metrics by time. These analytics help you understand traffic patterns, token consumption, and potential issues across AI providers. You can view the following analytics:\n\n* **Requests**: Track the total number of requests processed by AI Gateway.\n* **Token Usage**: Analyze token consumption across requests, giving insight into usage patterns.\n* **Costs**: Gain visibility into the costs associated with using different AI providers, allowing you to track spending, manage budgets, and optimize resources.\n* **Errors**: Monitor the number of errors across the gateway, helping to identify and troubleshoot issues.\n* **Cached Responses**: View the percentage of responses served from cache, which can help reduce costs and improve speed.\n\n## View analytics\n\n* Dashboard\n\n  To view analytics in the dashboard:\n\n  1. Log into the [Cloudflare dashboard](https://dash.cloudflare.com) and select your account.\n  2. Go to **AI** > **AI Gateway**.\n  3. Make sure you have your gateway selected.\n\n* graphql\n\n  You can use GraphQL to query your usage data outside of the AI Gateway dashboard. See the example query below. You will need to use your Cloudflare token when making the request, and change `{account_id}` to match your account tag.",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Costs · Cloudflare AI Gateway docs\ndescription: Cost metrics are only available for endpoints where the models\n  return token data and the model name in their responses.\nlastUpdated: 2025-05-15T16:26:01.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/observability/costs/\n  md: https://developers.cloudflare.com/ai-gateway/observability/costs/index.md\n---\n\nCost metrics are only available for endpoints where the models return token data and the model name in their responses.\n\n## Track costs across AI providers\n\nAI Gateway makes it easier to monitor and estimate token based costs across all your AI providers. This can help you:\n\n* Understand and compare usage costs between providers.\n* Monitor trends and estimate spend using consistent metrics.\n* Apply custom pricing logic to match negotiated rates.\n\nNote\n\nThe cost metric is an **estimation** based on the number of tokens sent and received in requests. While this metric can help you monitor and predict cost trends, refer to your provider's dashboard for the most **accurate** cost details.\n\nCaution\n\nProviders may introduce new models or change their pricing. If you notice outdated cost data or are using a model not yet supported by our cost tracking, please [submit a request](https://forms.gle/8kRa73wRnvq7bxL48)\n\n## Custom costs\n\nAI Gateway allows users to set custom costs when operating under special pricing agreements or negotiated rates. Custom costs can be applied at the request level, and when applied, they will override the default or public model costs. For more information on configuration of custom costs, please visit the [Custom Costs](https://developers.cloudflare.com/ai-gateway/configuration/custom-costs/) configuration page.\n\n</page>\n\n<page>\n---\ntitle: Custom metadata · Cloudflare AI Gateway docs\ndescription: Custom metadata in AI Gateway allows you to tag requests with user\n  IDs or other identifiers, enabling better tracking and analysis of your\n  requests. Metadata values can be strings, numbers, or booleans, and will\n  appear in your logs, making it easy to search and filter through your data.\nlastUpdated: 2025-08-19T11:42:14.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/observability/custom-metadata/\n  md: https://developers.cloudflare.com/ai-gateway/observability/custom-metadata/index.md\n---\n\nCustom metadata in AI Gateway allows you to tag requests with user IDs or other identifiers, enabling better tracking and analysis of your requests. Metadata values can be strings, numbers, or booleans, and will appear in your logs, making it easy to search and filter through your data.\n\n## Key Features\n\n* **Custom Tagging**: Add user IDs, team names, test indicators, and other relevant information to your requests.\n* **Enhanced Logging**: Metadata appears in your logs, allowing for detailed inspection and troubleshooting.\n* **Search and Filter**: Use metadata to efficiently search and filter through logged requests.\n\nNote\n\nAI Gateway allows you to pass up to five custom metadata entries per request. If more than five entries are provided, only the first five will be saved; additional entries will be ignored. Ensure your custom metadata is limited to five entries to avoid unprocessed or lost data.\n\n## Supported Metadata Types\n\n* String\n* Number\n* Boolean\n\nNote\n\nObjects are not supported as metadata values.\n\n## Implementations\n\n### Using cURL\n\nTo include custom metadata in your request using cURL:",
      "language": "unknown"
    },
    {
      "code": "### Using SDK\n\nTo include custom metadata in your request using the OpenAI SDK:",
      "language": "unknown"
    },
    {
      "code": "### Using Binding\n\nTo include custom metadata in your request using [Bindings](https://developers.cloudflare.com/workers/runtime-apis/bindings/):",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Logging · Cloudflare AI Gateway docs\ndescription: Logging is a fundamental building block for application\n  development. Logs provide insights during the early stages of development and\n  are often critical to understanding issues occurring in production.\nlastUpdated: 2025-08-20T18:25:25.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/observability/logging/\n  md: https://developers.cloudflare.com/ai-gateway/observability/logging/index.md\n---\n\nLogging is a fundamental building block for application development. Logs provide insights during the early stages of development and are often critical to understanding issues occurring in production.\n\nYour AI Gateway dashboard shows logs of individual requests, including the user prompt, model response, provider, timestamp, request status, token usage, cost, and duration. These logs persist, giving you the flexibility to store them for your preferred duration and do more with valuable request data.\n\nBy default, each gateway can store up to 10 million logs. You can customize this limit per gateway in your gateway settings to align with your specific requirements. If your storage limit is reached, new logs will stop being saved. To continue saving logs, you must delete older logs to free up space for new logs. To learn more about your plan limits, refer to [Limits](https://developers.cloudflare.com/ai-gateway/reference/limits/).\n\nWe recommend using an authenticated gateway when storing logs to prevent unauthorized access and protects against invalid requests that can inflate log storage usage and make it harder to find the data you need. Learn more about setting up an [authenticated gateway](https://developers.cloudflare.com/ai-gateway/configuration/authentication/).\n\n## Default configuration\n\nLogs, which include metrics as well as request and response data, are enabled by default for each gateway. This logging behavior will be uniformly applied to all requests in the gateway. If you are concerned about privacy or compliance and want to turn log collection off, you can go to settings and opt out of logs. If you need to modify the log settings for specific requests, you can override this setting on a per-request basis.\n\nTo change the default log configuration in the dashboard:\n\n1. In the Cloudflare dashboard, go to the **AI Gateway** page.\n\n   [Go to **AI Gateway**](https://dash.cloudflare.com/?to=/:account/ai/ai-gateway)\n\n2. Select **Settings**.\n\n3. Change the **Logs** setting to your preference.\n\n## Per-request logging\n\nTo override the default logging behavior set in the settings tab, you can define headers on a per-request basis.\n\n### Collect logs (`cf-aig-collect-log`)\n\nThe `cf-aig-collect-log` header allows you to bypass the default log setting for the gateway. If the gateway is configured to save logs, the header will exclude the log for that specific request. Conversely, if logging is disabled at the gateway level, this header will save the log for that request.\n\nIn the example below, we use `cf-aig-collect-log` to bypass the default setting to avoid saving the log.",
      "language": "unknown"
    },
    {
      "code": "## Managing log storage\n\nTo manage your log storage effectively, you can:\n\n* Set Storage Limits: Configure a limit on the number of logs stored per gateway in your gateway settings to ensure you only pay for what you need.\n* Enable Automatic Log Deletion: Activate the Automatic Log Deletion feature in your gateway settings to automatically delete the oldest logs once the log limit you've set or the default storage limit of 10 million logs is reached. This ensures new logs are always saved without manual intervention.\n\n## How to delete logs\n\nTo manage your log storage effectively and ensure continuous logging, you can delete logs using the following methods:\n\n### Automatic Log Deletion\n\n​To maintain continuous logging within your gateway's storage constraints, enable Automatic Log Deletion in your Gateway settings. This feature automatically deletes the oldest logs once the log limit you've set or the default storage limit of 10 million logs is reached, ensuring new logs are saved without manual intervention.\n\n### Manual deletion\n\nTo manually delete logs through the dashboard, navigate to the Logs tab in the dashboard. Use the available filters such as status, cache, provider, cost, or any other options in the dropdown to refine the logs you wish to delete. Once filtered, select Delete logs to complete the action.\n\nSee full list of available filters and their descriptions below:\n\n| Filter category | Filter options | Filter by description |\n| - | - | - |\n| Status | error, status | error type or status. |\n| Cache | cached, not cached | based on whether they were cached or not. |\n| Provider | specific providers | the selected AI provider. |\n| AI Models | specific models | the selected AI model. |\n| Cost | less than, greater than | cost, specifying a threshold. |\n| Request type | Universal, Workers AI Binding, WebSockets | the type of request. |\n| Tokens | Total tokens, Tokens In, Tokens Out | token count (less than or greater than). |\n| Duration | less than, greater than | request duration. |\n| Feedback | equals, does not equal (thumbs up, thumbs down, no feedback) | feedback type. |\n| Metadata Key | equals, does not equal | specific metadata keys. |\n| Metadata Value | equals, does not equal | specific metadata values. |\n| Log ID | equals, does not equal | a specific Log ID. |\n| Event ID | equals, does not equal | a specific Event ID. |\n\n### API deletion\n\nYou can programmatically delete logs using the AI Gateway API. For more comprehensive information on the `DELETE` logs endpoint, check out the [Cloudflare API documentation](https://developers.cloudflare.com/api/resources/ai_gateway/subresources/logs/methods/delete/).\n\n</page>\n\n<page>\n---\ntitle: Limits · Cloudflare AI Gateway docs\ndescription: The following limits apply to gateway configurations, logs, and\n  related features in Cloudflare's platform.\nlastUpdated: 2025-08-19T11:42:14.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/reference/limits/\n  md: https://developers.cloudflare.com/ai-gateway/reference/limits/index.md\n---\n\nThe following limits apply to gateway configurations, logs, and related features in Cloudflare's platform.\n\n| Feature | Limit |\n| - | - |\n| [Cacheable request size](https://developers.cloudflare.com/ai-gateway/features/caching/) | 25 MB per request |\n| [Cache TTL](https://developers.cloudflare.com/ai-gateway/features/caching/#cache-ttl-cf-aig-cache-ttl) | 1 month |\n| [Custom metadata](https://developers.cloudflare.com/ai-gateway/observability/custom-metadata/) | 5 entries per request |\n| [Datasets](https://developers.cloudflare.com/ai-gateway/evaluations/set-up-evaluations/) | 10 per gateway |\n| Gateways free plan | 10 per account |\n| Gateways paid plan | 20 per account |\n| Gateway name length | 64 characters |\n| Log storage rate limit | 500 logs per second per gateway |\n| Logs stored [paid plan](https://developers.cloudflare.com/ai-gateway/reference/pricing/) | 10 million per gateway 1 |\n| Logs stored [free plan](https://developers.cloudflare.com/ai-gateway/reference/pricing/) | 100,000 per account 2 |\n| [Log size stored](https://developers.cloudflare.com/ai-gateway/observability/logging/) | 10 MB per log 3 |\n| [Logpush jobs](https://developers.cloudflare.com/ai-gateway/observability/logging/logpush/) | 4 per account |\n| [Logpush size limit](https://developers.cloudflare.com/ai-gateway/observability/logging/logpush/) | 1MB per log |\n\n1 If you have reached 10 million logs stored per gateway, new logs will stop being saved. To continue saving logs, you must delete older logs in that gateway to free up space or create a new gateway. Refer to [Auto Log Cleanup](https://developers.cloudflare.com/ai-gateway/observability/logging/#auto-log-cleanup) for more details on how to automatically delete logs.\n\n2 If you have reached 100,000 logs stored per account, across all gateways, new logs will stop being saved. To continue saving logs, you must delete older logs. Refer to [Auto Log Cleanup](https://developers.cloudflare.com/ai-gateway/observability/logging/#auto-log-cleanup) for more details on how to automatically delete logs.\n\n3 Logs larger than 10 MB will not be stored.\n\nNeed a higher limit?\n\nTo request an increase to a limit, complete the [Limit Increase Request Form](https://forms.gle/cuXu1QnQCrSNkkaS8). If the limit can be increased, Cloudflare will contact you with next steps.\n\n</page>\n\n<page>\n---\ntitle: Audit logs · Cloudflare AI Gateway docs\ndescription: Audit logs provide a comprehensive summary of changes made within\n  your Cloudflare account, including those made to gateways in AI Gateway. This\n  functionality is available on all plan types, free of charge, and is enabled\n  by default.\nlastUpdated: 2025-09-05T08:34:36.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/reference/audit-logs/\n  md: https://developers.cloudflare.com/ai-gateway/reference/audit-logs/index.md\n---\n\n[Audit logs](https://developers.cloudflare.com/fundamentals/account/account-security/review-audit-logs/) provide a comprehensive summary of changes made within your Cloudflare account, including those made to gateways in AI Gateway. This functionality is available on all plan types, free of charge, and is enabled by default.\n\n## Viewing Audit Logs\n\nTo view audit logs for AI Gateway, in the Cloudflare dashboard, go to the **Audit logs** page.\n\n[Go to **Audit logs**](https://dash.cloudflare.com/?to=/:account/audit-log)\n\nFor more information on how to access and use audit logs, refer to [review audit logs documentation](https://developers.cloudflare.com/fundamentals/account/account-security/review-audit-logs/).\n\n## Logged Operations\n\nThe following configuration actions are logged:\n\n| Operation | Description |\n| - | - |\n| gateway created | Creation of a new gateway. |\n| gateway deleted | Deletion of an existing gateway. |\n| gateway updated | Edit of an existing gateway. |\n\n## Example Log Entry\n\nBelow is an example of an audit log entry showing the creation of a new gateway:",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Pricing · Cloudflare AI Gateway docs\ndescription: AI Gateway is available to use on all plans.\nlastUpdated: 2025-11-10T11:01:10.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/reference/pricing/\n  md: https://developers.cloudflare.com/ai-gateway/reference/pricing/index.md\n---\n\nAI Gateway is available to use on all plans.\n\nAI Gateway's core features available today are offered for free, and all it takes is a Cloudflare account and one line of code to [get started](https://developers.cloudflare.com/ai-gateway/get-started/). Core features include: dashboard analytics, caching, and rate limiting.\n\nWe will continue to build and expand AI Gateway. Some new features may be additional core features that will be free while others may be part of a premium plan. We will announce these as they become available.\n\nYou can monitor your usage in the AI Gateway dashboard.\n\n## Persistent logs\n\nPersistent logs are available on all plans, with a free allocation for both free and paid plans. Charges for additional logs beyond those limits are based on the number of logs stored per month.\n\n### Free allocation and overage pricing\n\n| Plan | Free logs stored | Overage pricing |\n| - | - | - |\n| Workers Free | 100,000 logs total | N/A - Upgrade to Workers Paid |\n| Workers Paid | 1,000,000 logs total | N/A |\n\nAllocations are based on the total logs stored across all gateways. For guidance on managing or deleting logs, please see our [documentation](https://developers.cloudflare.com/ai-gateway/observability/logging).\n\n## Logpush\n\nLogpush is only available on the Workers Paid plan.\n\n| | Paid plan |\n| - | - |\n| Requests | 10 million / month, +$0.05/million |\n\n## Fine print\n\nPrices subject to change. If you are an Enterprise customer, reach out to your account team to confirm pricing details.\n\n</page>\n\n<page>\n---\ntitle: Create your first AI Gateway using Workers AI · Cloudflare AI Gateway docs\ndescription: This tutorial guides you through creating your first AI Gateway\n  using Workers AI on the Cloudflare dashboard.\nlastUpdated: 2025-10-09T15:47:46.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/tutorials/create-first-aig-workers/\n  md: https://developers.cloudflare.com/ai-gateway/tutorials/create-first-aig-workers/index.md\n---\n\nThis tutorial guides you through creating your first AI Gateway using Workers AI on the Cloudflare dashboard. The intended audience is beginners who are new to AI Gateway and Workers AI. Creating an AI Gateway enables the user to efficiently manage and secure AI requests, allowing them to utilize AI models for tasks such as content generation, data processing, or predictive analysis with enhanced control and performance.\n\n## Sign up and log in\n\n1. **Sign up**: If you do not have a Cloudflare account, [sign up](https://cloudflare.com/sign-up).\n2. **Log in**: Access the Cloudflare dashboard by logging in to the [Cloudflare dashboard](https://dash.cloudflare.com/login).\n\n## Create gateway\n\nThen, create a new AI Gateway.\n\n* Dashboard\n\n  [Create a Gateway](https://dash.cloudflare.com/?to=/:account/ai/ai-gateway#create)\n\n  1. Log into the [Cloudflare dashboard](https://dash.cloudflare.com/) and select your account.\n  2. Go to **AI** > **AI Gateway**.\n  3. Select **Create Gateway**.\n  4. Enter your **Gateway name**. Note: Gateway name has a 64 character limit.\n  5. Select **Create**.\n\n* API\n\n  To set up an AI Gateway using the API:\n\n  1. [Create an API token](https://developers.cloudflare.com/fundamentals/api/get-started/create-token/) with the following permissions:\n\n     * `AI Gateway - Read`\n     * `AI Gateway - Edit`\n\n  2. Get your [Account ID](https://developers.cloudflare.com/fundamentals/account/find-account-and-zone-ids/).\n\n  3. Using that API token and Account ID, send a [`POST` request](https://developers.cloudflare.com/api/resources/ai_gateway/methods/create/) to the Cloudflare API.\n\n## Connect Your AI Provider\n\n1. In the AI Gateway section, select the gateway you created.\n2. Select **Workers AI** as your provider to set up an endpoint specific to Workers AI. You will receive an endpoint URL for sending requests.\n\n## Configure Your Workers AI\n\n1. Go to **AI** > **Workers AI** in the Cloudflare dashboard.\n\n2. Select **Use REST API** and follow the steps to create and copy the API token and Account ID.\n\n3. **Send Requests to Workers AI**: Use the provided API endpoint. For example, you can run a model via the API using a curl command. Replace `{account_id}`, `{gateway_id}` and `{cf_api_token}` with your actual account ID and API token:",
      "language": "unknown"
    },
    {
      "code": "The expected output would be similar to :",
      "language": "unknown"
    },
    {
      "code": "## View Analytics\n\nMonitor your AI Gateway to view usage metrics.\n\n1. Go to **AI** > **AI Gateway** in the dashboard.\n2. Select your gateway to view metrics such as request counts, token usage, caching efficiency, errors, and estimated costs. You can also turn on additional configurations like logging and rate limiting.\n\n## Optional - Next steps\n\nTo build more with Workers, refer to [Tutorials](https://developers.cloudflare.com/workers/tutorials/).\n\nIf you have any questions, need assistance, or would like to share your project, join the Cloudflare Developer community on [Discord](https://discord.cloudflare.com) to connect with other developers and the Cloudflare team.\n\n</page>\n\n<page>\n---\ntitle: Deploy a Worker that connects to OpenAI via AI Gateway · Cloudflare AI\n  Gateway docs\ndescription: Learn how to deploy a Worker that makes calls to OpenAI through AI Gateway\nlastUpdated: 2025-11-14T10:07:26.000Z\nchatbotDeprioritize: false\ntags: AI,JavaScript\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/tutorials/deploy-aig-worker/\n  md: https://developers.cloudflare.com/ai-gateway/tutorials/deploy-aig-worker/index.md\n---\n\nIn this tutorial, you will learn how to deploy a Worker that makes calls to OpenAI through AI Gateway. AI Gateway helps you better observe and control your AI applications with more analytics, caching, rate limiting, and logging.\n\nThis tutorial uses the most recent v4 OpenAI node library, an update released in August 2023.\n\n## Before you start\n\nAll of the tutorials assume you have already completed the [Get started guide](https://developers.cloudflare.com/workers/get-started/guide/), which gets you set up with a Cloudflare Workers account, [C3](https://github.com/cloudflare/workers-sdk/tree/main/packages/create-cloudflare), and [Wrangler](https://developers.cloudflare.com/workers/wrangler/install-and-update/).\n\n## 1. Create an AI Gateway and OpenAI API key\n\nOn the AI Gateway page in the Cloudflare dashboard, create a new AI Gateway by clicking the plus button on the top right. You should be able to name the gateway as well as the endpoint. Click on the API Endpoints button to copy the endpoint. You can choose from provider-specific endpoints such as OpenAI, HuggingFace, and Replicate. Or you can use the universal endpoint that accepts a specific schema and supports model fallback and retries.\n\nFor this tutorial, we will be using the OpenAI provider-specific endpoint, so select OpenAI in the dropdown and copy the new endpoint.\n\nYou will also need an OpenAI account and API key for this tutorial. If you do not have one, create a new OpenAI account and create an API key to continue with this tutorial. Make sure to store your API key somewhere safe so you can use it later.\n\n## 2. Create a new Worker\n\nCreate a Worker project in the command line:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "For setup, select the following options:\n\n* For *What would you like to start with?*, choose `Hello World example`.\n* For *Which template would you like to use?*, choose `Worker only`.\n* For *Which language do you want to use?*, choose `JavaScript`.\n* For *Do you want to use git for version control?*, choose `Yes`.\n* For *Do you want to deploy your application?*, choose `No` (we will be making some changes before deploying).\n\nGo to your new open Worker project:",
      "language": "unknown"
    },
    {
      "code": "Inside of your new openai-aig directory, find and open the `src/index.js` file. You will configure this file for most of the tutorial.\n\nInitially, your generated `index.js` file should look like this:",
      "language": "unknown"
    },
    {
      "code": "## 3. Configure OpenAI in your Worker\n\nWith your Worker project created, we can learn how to make your first request to OpenAI. You will use the OpenAI node library to interact with the OpenAI API. Install the OpenAI node library with `npm`:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "In your `src/index.js` file, add the import for `openai` above `export default`:",
      "language": "unknown"
    },
    {
      "code": "Within your `fetch` function, set up the configuration and instantiate your `OpenAIApi` client with the AI Gateway endpoint you created:",
      "language": "unknown"
    },
    {
      "code": "To make this work, you need to use [`wrangler secret put`](https://developers.cloudflare.com/workers/wrangler/commands/#secret-put) to set your `OPENAI_API_KEY`. This will save the API key to your environment so your Worker can access it when deployed. This key is the API key you created earlier in the OpenAI dashboard:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "To make this work in local development, create a new file `.dev.vars` in your Worker project and add this line. Make sure to replace `OPENAI_API_KEY` with your own OpenAI API key:",
      "language": "unknown"
    },
    {
      "code": "## 4. Make an OpenAI request\n\nNow we can make a request to the OpenAI [Chat Completions API](https://platform.openai.com/docs/guides/gpt/chat-completions-api).\n\nYou can specify what model you'd like, the role and prompt, as well as the max number of tokens you want in your total request.",
      "language": "unknown"
    },
    {
      "code": "## 5. Deploy your Worker application\n\nTo deploy your application, run the `npx wrangler deploy` command to deploy your Worker application:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "You can now preview your Worker at \\<YOUR\\_WORKER>.\\<YOUR\\_SUBDOMAIN>.workers.dev.\n\n## 6. Review your AI Gateway\n\nWhen you go to AI Gateway in your Cloudflare dashboard, you should see your recent request being logged. You can also [tweak your settings](https://developers.cloudflare.com/ai-gateway/configuration/) to manage your logs, caching, and rate limiting settings.\n\n</page>\n\n<page>\n---\ntitle: Unified API (OpenAI compat) · Cloudflare AI Gateway docs\ndescription: Cloudflare's AI Gateway offers an OpenAI-compatible\n  /chat/completions endpoint, enabling integration with multiple AI providers\n  using a single URL. This feature simplifies the integration process, allowing\n  for seamless switching between different models without significant code\n  modifications.\nlastUpdated: 2025-12-08T07:14:56.000Z\nchatbotDeprioritize: false\ntags: AI\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/usage/chat-completion/\n  md: https://developers.cloudflare.com/ai-gateway/usage/chat-completion/index.md\n---\n\nCloudflare's AI Gateway offers an OpenAI-compatible `/chat/completions` endpoint, enabling integration with multiple AI providers using a single URL. This feature simplifies the integration process, allowing for seamless switching between different models without significant code modifications.\n\n## Endpoint URL",
      "language": "unknown"
    },
    {
      "code": "Replace `{account_id}` and `{gateway_id}` with your Cloudflare account and gateway IDs.\n\n## Parameters\n\nSwitch providers by changing the `model` and `apiKey` parameters.\n\nSpecify the model using `{provider}/{model}` format. For example:\n\n* `openai/gpt-5-mini`\n* `google-ai-studio/gemini-2.5-flash`\n* `anthropic/claude-sonnet-4-5`\n\n## Examples\n\n### OpenAI SDK\n\nWith Key in Request\n\n* With Authenticated Gateway",
      "language": "unknown"
    },
    {
      "code": "* Unauthenticated Gateway",
      "language": "unknown"
    },
    {
      "code": "With Stored Keys (BYOK) / Unified Billing",
      "language": "unknown"
    },
    {
      "code": "### cURL\n\nWith Key in Request\n\n* With Authenticated Gateway",
      "language": "unknown"
    },
    {
      "code": "* Unauthenticated Gateway",
      "language": "unknown"
    },
    {
      "code": "With Stored Keys (BYOK) / Unified Billing",
      "language": "unknown"
    },
    {
      "code": "## Supported Providers\n\nThe OpenAI-compatible endpoint supports models from the following providers:\n\n* [Anthropic](https://developers.cloudflare.com/ai-gateway/usage/providers/anthropic/)\n* [OpenAI](https://developers.cloudflare.com/ai-gateway/usage/providers/openai/)\n* [Groq](https://developers.cloudflare.com/ai-gateway/usage/providers/groq/)\n* [Mistral](https://developers.cloudflare.com/ai-gateway/usage/providers/mistral/)\n* [Cohere](https://developers.cloudflare.com/ai-gateway/usage/providers/cohere/)\n* [Perplexity](https://developers.cloudflare.com/ai-gateway/usage/providers/perplexity/)\n* [Workers AI](https://developers.cloudflare.com/ai-gateway/usage/providers/workersai/)\n* [Google-AI-Studio](https://developers.cloudflare.com/ai-gateway/usage/providers/google-ai-studio/)\n* [Google Vertex AI](https://developers.cloudflare.com/ai-gateway/usage/providers/vertex/)\n* [xAI](https://developers.cloudflare.com/ai-gateway/usage/providers/grok/)\n* [DeepSeek](https://developers.cloudflare.com/ai-gateway/usage/providers/deepseek/)\n* [Cerebras](https://developers.cloudflare.com/ai-gateway/usage/providers/cerebras/)\n* [Baseten](https://developers.cloudflare.com/ai-gateway/usage/providers/baseten/)\n* [Parallel](https://developers.cloudflare.com/ai-gateway/usage/providers/parallel/)\n\n</page>\n\n<page>\n---\ntitle: Provider Native · Cloudflare AI Gateway docs\ndescription: \"Here is a quick list of the providers we support:\"\nlastUpdated: 2025-08-27T13:32:22.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/usage/providers/\n  md: https://developers.cloudflare.com/ai-gateway/usage/providers/index.md\n---\n\nHere is a quick list of the providers we support:\n\n* [Amazon Bedrock](https://developers.cloudflare.com/ai-gateway/usage/providers/bedrock/)\n* [Anthropic](https://developers.cloudflare.com/ai-gateway/usage/providers/anthropic/)\n* [Azure OpenAI](https://developers.cloudflare.com/ai-gateway/usage/providers/azureopenai/)\n* [Baseten](https://developers.cloudflare.com/ai-gateway/usage/providers/baseten/)\n* [Cartesia](https://developers.cloudflare.com/ai-gateway/usage/providers/cartesia/)\n* [Cerebras](https://developers.cloudflare.com/ai-gateway/usage/providers/cerebras/)\n* [Cohere](https://developers.cloudflare.com/ai-gateway/usage/providers/cohere/)\n* [Deepgram](https://developers.cloudflare.com/ai-gateway/usage/providers/deepgram/)\n* [DeepSeek](https://developers.cloudflare.com/ai-gateway/usage/providers/deepseek/)\n* [ElevenLabs](https://developers.cloudflare.com/ai-gateway/usage/providers/elevenlabs/)\n* [Fal AI](https://developers.cloudflare.com/ai-gateway/usage/providers/fal/)\n* [Google AI Studio](https://developers.cloudflare.com/ai-gateway/usage/providers/google-ai-studio/)\n* [Google Vertex AI](https://developers.cloudflare.com/ai-gateway/usage/providers/vertex/)\n* [Groq](https://developers.cloudflare.com/ai-gateway/usage/providers/groq/)\n* [HuggingFace](https://developers.cloudflare.com/ai-gateway/usage/providers/huggingface/)\n* [Ideogram](https://developers.cloudflare.com/ai-gateway/usage/providers/ideogram/)\n* [Mistral AI](https://developers.cloudflare.com/ai-gateway/usage/providers/mistral/)\n* [OpenAI](https://developers.cloudflare.com/ai-gateway/usage/providers/openai/)\n* [OpenRouter](https://developers.cloudflare.com/ai-gateway/usage/providers/openrouter/)\n* [Parallel](https://developers.cloudflare.com/ai-gateway/usage/providers/parallel/)\n* [Perplexity](https://developers.cloudflare.com/ai-gateway/usage/providers/perplexity/)\n* [Replicate](https://developers.cloudflare.com/ai-gateway/usage/providers/replicate/)\n* [xAI](https://developers.cloudflare.com/ai-gateway/usage/providers/grok/)\n* [Workers AI](https://developers.cloudflare.com/ai-gateway/usage/providers/workersai/)\n\n</page>\n\n<page>\n---\ntitle: Universal Endpoint · Cloudflare AI Gateway docs\ndescription: You can use the Universal Endpoint to contact every provider.\nlastUpdated: 2025-08-20T18:25:25.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/usage/universal/\n  md: https://developers.cloudflare.com/ai-gateway/usage/universal/index.md\n---\n\nNote\n\nIt is recommended to use the Dynamic Routes to implement model fallback feature\n\nYou can use the Universal Endpoint to contact every provider.",
      "language": "unknown"
    },
    {
      "code": "AI Gateway offers multiple endpoints for each Gateway you create - one endpoint per provider, and one Universal Endpoint. The Universal Endpoint requires some adjusting to your schema, but supports additional features. Some of these features are, for example, retrying a request if it fails the first time, or configuring a [fallback model/provider](https://developers.cloudflare.com/ai-gateway/configuration/fallbacks/).\n\nYou can use the Universal endpoint to contact every provider. The payload is expecting an array of message, and each message is an object with the following parameters:\n\n* `provider` : the name of the provider you would like to direct this message to. Can be OpenAI, workers-ai, or any of our supported providers.\n* `endpoint`: the pathname of the provider API you’re trying to reach. For example, on OpenAI it can be `chat/completions`, and for Workers AI this might be [`@cf/meta/llama-3.1-8b-instruct`](https://developers.cloudflare.com/workers-ai/models/llama-3.1-8b-instruct/). See more in the sections that are specific to [each provider](https://developers.cloudflare.com/ai-gateway/usage/providers/).\n* `authorization`: the content of the Authorization HTTP Header that should be used when contacting this provider. This usually starts with 'Token' or 'Bearer'.\n* `query`: the payload as the provider expects it in their official API.\n\n## cURL example",
      "language": "unknown"
    },
    {
      "code": "The above will send a request to Workers AI Inference API, if it fails it will proceed to OpenAI. You can add as many fallbacks as you need, just by adding another JSON in the array.\n\n## WebSockets API beta\n\nThe Universal Endpoint can also be accessed via a [WebSockets API](https://developers.cloudflare.com/ai-gateway/usage/websockets-api/) which provides a single persistent connection, enabling continuous communication. This API supports all AI providers connected to AI Gateway, including those that do not natively support WebSockets.\n\n## WebSockets example",
      "language": "unknown"
    },
    {
      "code": "## Workers Binding example\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "## Header configuration hierarchy\n\nThe Universal Endpoint allows you to set fallback models or providers and customize headers for each provider or request. You can configure headers at three levels:\n\n1. **Provider level**: Headers specific to a particular provider.\n2. **Request level**: Headers included in individual requests.\n3. **Gateway settings**: Default headers configured in your gateway dashboard.\n\nSince the same settings can be configured in multiple locations, AI Gateway applies a hierarchy to determine which configuration takes precedence:\n\n* **Provider-level headers** override all other configurations.\n* **Request-level headers** are used if no provider-level headers are set.\n* **Gateway-level settings** are used only if no headers are configured at the provider or request levels.\n\nThis hierarchy ensures consistent behavior, prioritizing the most specific configurations. Use provider-level and request-level headers for fine-tuned control, and gateway settings for general defaults.\n\n## Hierarchy example\n\nThis example demonstrates how headers set at different levels impact caching behavior:\n\n* **Request-level header**: The `cf-aig-cache-ttl` is set to `3600` seconds, applying this caching duration to the request by default.\n* **Provider-level header**: For the fallback provider (OpenAI), `cf-aig-cache-ttl` is explicitly set to `0` seconds, overriding the request-level header and disabling caching for responses when OpenAI is used as the provider.\n\nThis shows how provider-level headers take precedence over request-level headers, allowing for granular control of caching behavior.",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: WebSockets API · Cloudflare AI Gateway docs\ndescription: \"The AI Gateway WebSockets API provides a persistent connection for\n  AI interactions, eliminating repeated handshakes and reducing latency. This\n  API is divided into two categories:\"\nlastUpdated: 2025-08-19T11:42:14.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-gateway/usage/websockets-api/\n  md: https://developers.cloudflare.com/ai-gateway/usage/websockets-api/index.md\n---\n\nThe AI Gateway WebSockets API provides a persistent connection for AI interactions, eliminating repeated handshakes and reducing latency. This API is divided into two categories:\n\n* **Realtime APIs** - Designed for AI providers that offer low-latency, multimodal interactions over WebSockets.\n* **Non-Realtime APIs** - Supports standard WebSocket communication for AI providers, including those that do not natively support WebSockets.\n\n## When to use WebSockets\n\nWebSockets are long-lived TCP connections that enable bi-directional, real-time and non realtime communication between client and server. Unlike HTTP connections, which require repeated handshakes for each request, WebSockets maintain the connection, supporting continuous data exchange with reduced overhead. WebSockets are ideal for applications needing low-latency, real-time data, such as voice assistants.\n\n## Key benefits\n\n* **Reduced overhead**: Avoid overhead of repeated handshakes and TLS negotiations by maintaining a single, persistent connection.\n* **Provider compatibility**: Works with all AI providers in AI Gateway. Even if your chosen provider does not support WebSockets, Cloudflare handles it for you, managing the requests to your preferred AI provider.\n\n## Key differences\n\n| Feature | Realtime APIs | Non-Realtime APIs |\n| - | - | - |\n| **Purpose** | Enables real-time, multimodal AI interactions for providers that offer dedicated WebSocket endpoints. | Supports WebSocket-based AI interactions with providers that do not natively support WebSockets. |\n| **Use Case** | Streaming responses for voice, video, and live interactions. | Text-based queries and responses, such as LLM requests. |\n| **AI Provider Support** | [Limited to providers offering real-time WebSocket APIs.](https://developers.cloudflare.com/ai-gateway/usage/websockets-api/realtime-api/#supported-providers) | [All AI providers in AI Gateway.](https://developers.cloudflare.com/ai-gateway/usage/providers/) |\n| **Streaming Support** | Providers natively support real-time data streaming. | AI Gateway handles streaming via WebSockets. |\n\nFor details on implementation, refer to the next sections:\n\n* [Realtime WebSockets API](https://developers.cloudflare.com/ai-gateway/usage/websockets-api/realtime-api/)\n* [Non-Realtime WebSockets API](https://developers.cloudflare.com/ai-gateway/usage/websockets-api/non-realtime-api/)\n\n</page>\n\n<page>\n---\ntitle: AI Crawl Control with Cloudflare Bots · Cloudflare AI Crawl Control docs\ndescription: AI Crawl Control works alongside other Cloudflare products, such as\n  Cloudflare bot solutions. Bot solutions identifies traffic matching patterns\n  of known bots, and can challenge or block the bots as you wish.\nlastUpdated: 2025-08-27T16:00:59.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-crawl-control/configuration/ai-crawl-control-with-bots/\n  md: https://developers.cloudflare.com/ai-crawl-control/configuration/ai-crawl-control-with-bots/index.md\n---\n\nAI Crawl Control works alongside other Cloudflare products, such as Cloudflare [bot solutions](https://developers.cloudflare.com/bots/). Bot solutions identifies traffic matching patterns of known bots, and can challenge or block the bots as you wish.\n\n## Order of precedence\n\n* AI Crawl Control's AI crawler blocking uses [WAF custom rules](https://developers.cloudflare.com/waf/custom-rules/), which take place before Cloudflare bot solutions.\n* AI Crawl Control's pay per crawl takes place after Cloudflare bot solutions.",
      "language": "unknown"
    },
    {
      "code": "For more information on how Cloudflare bot solutions works with WAF custom rules, refer to [How it works](https://developers.cloudflare.com/bots/concepts/bot/#how-it-works).\n\n## Examples\n\nConsider the following examples.\n\n### Bot rule which blocks all AI bots vs pay per crawl\n\nYou may have both of the following enabled:\n\n* A selection of AI crawlers to be charged through AI Crawl Control's pay per crawl\n* Bot configuration option to [Block AI Bots](https://developers.cloudflare.com/bots/get-started/bot-fight-mode/#block-ai-bots).\n\nSince pay per crawl happens after bot solutions, you need to first turn off **Block AI Bots** to ensure pay per crawl works as intended.\n\n</page>\n\n<page>\n---\ntitle: AI Crawl Control with Cloudflare WAF · Cloudflare AI Crawl Control docs\ndescription: AI Crawl Control works alongside other Cloudflare products, such as\n  Cloudflare Web Application Firewall (WAF). WAF checks incoming web and API\n  requests, and filters undesired traffic based on rules. WAF custom rules allow\n  you to perform certain actions such as enforcing robots.txt.\nlastUpdated: 2025-09-17T08:17:19.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-crawl-control/configuration/ai-crawl-control-with-waf/\n  md: https://developers.cloudflare.com/ai-crawl-control/configuration/ai-crawl-control-with-waf/index.md\n---\n\nAI Crawl Control works alongside other Cloudflare products, such as Cloudflare [Web Application Firewall (WAF)](https://developers.cloudflare.com/waf/). WAF checks incoming web and API requests, and filters undesired traffic based on rules. [WAF custom rules](https://developers.cloudflare.com/waf/custom-rules/) allow you to perform certain actions such as enforcing `robots.txt`.\n\n## Order of precedence\n\n* AI Crawl Control uses WAF custom rules to block the selection of AI crawlers the site owner has decided to block.\n* AI Crawl Control's pay per crawl feature takes place after WAF.",
      "language": "unknown"
    },
    {
      "code": "For this reason, if you plan on using AI Crawl Control to manage AI crawlers, you may wish to modify your existing WAF custom rules such that it does not affect AI crawlers. This will allow you to manage AI crawlers only from AI Crawl Control, thereby streamlining your workflow.\n\nHow AI Crawl Control uses WAF custom rules\n\nWhen you block AI crawlers via AI Crawl Control (either all or some), you are using **one** WAF custom rule to block those AI crawlers.\n\nIf you choose to allow all AI crawlers, AI Crawl Control does not utilize any WAF custom rules.\n\nDepending on the type of account you have, you may have a limited number of WAF custom rules.\n\n## Examples of using WAF vs AI Crawl Control\n\nConsider the following examples.\n\n### Traffic from a restricted country vs pay per crawl\n\nYou may have both of the following features enabled:\n\n* [WAF custom rule to block traffic from specific countries](https://developers.cloudflare.com/waf/custom-rules/use-cases/block-traffic-from-specific-countries/)\n* AI Crawl Control's [pay per crawl](https://developers.cloudflare.com/ai-crawl-control/features/pay-per-crawl/what-is-pay-per-crawl/) to charge AI crawlers when they request access to your content\n\nSince WAF custom rules are enforced before pay per crawl, traffic (including AI crawlers) from your blocked countries will continue to be blocked, even if they provide the [required headers](https://developers.cloudflare.com/ai-crawl-control/features/pay-per-crawl/use-pay-per-crawl-as-ai-owner/crawl-pages/#1-include-required-headers) for pay per crawl.\n\n### Allowed search engine bots via WAF custom rule vs pay per crawl\n\nYou may have both of the following features enabled:\n\n* [WAF custom rule to allow search engine bots](https://developers.cloudflare.com/waf/custom-rules/use-cases/allow-traffic-from-verified-bots/)\n* AI Crawl Control's [pay per crawl](https://developers.cloudflare.com/ai-crawl-control/features/pay-per-crawl/what-is-pay-per-crawl/) to charge all AI crawlers when they request access to your content (including search engine bots).\n\nSince custom rules are enforced before pay per crawl:\n\n* Only search engine bots will be able to access your site (enforced by custom rule).\n* The search engine bots will then be charged for access to your content (enforced by AI Crawl Control's pay per crawl).\n\nNote\n\nThis example only serves to highlight the order of precedence between WAF and AI Crawl Control.\n\nPractically, it may be beneficial to allow well-behaved search engine bots to access your content to ensure your content is indexed.\n\n### Conflict in AI crawler blocking logic\n\nYou may have both of the following features enabled:\n\n* A WAF custom rule which blocks all bots.\n* AI Crawl Control selection which allows certain AI crawlers.\n\nIn this scenario, you have two custom rules, each directing a different logic for handling AI crawlers. To resolve this issue:\n\n* Old dashboard\n\n  1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com/), and select your account and domain.\n  2. Go to **Security** > **WAF** > **Custom rules** tab.\n  3. Identify your WAF custom rule and the AI Crawl Control rule.\n  4. Drag the rule you wish to prioritize to the top, or modify your WAF custom rule to ensure it does not conflict with your AI Crawl Control configurations.\n\n* New dashboard\n\n  1. In the Cloudflare dashboard, go to the **Security rules** page.\n\n     [Go to **Security rules**](https://dash.cloudflare.com/?to=/:account/:zone/security/security-rules)\n\n  2. Filter by *Custom rules*.\n\n  3. Identify your custom rule and the AI Crawl Control rule.\n\n  4. Drag the rule you wish to prioritize to the top, or modify your custom rule to ensure it does not conflict with your AI Crawl Control configurations.\n\n</page>\n\n<page>\n---\ntitle: Analyze AI traffic · Cloudflare AI Crawl Control docs\ndescription: AI Crawl Control metrics provide you with insight on how AI\n  crawlers are interacting with your website (Cloudflare zone).\nlastUpdated: 2025-12-18T09:52:15.000Z\nchatbotDeprioritize: false\ntags: AI\nsource_url:\n  html: https://developers.cloudflare.com/ai-crawl-control/features/analyze-ai-traffic/\n  md: https://developers.cloudflare.com/ai-crawl-control/features/analyze-ai-traffic/index.md\n---\n\nAI Crawl Control metrics provide you with insight on how AI crawlers are interacting with your website ([Cloudflare zone](https://developers.cloudflare.com/fundamentals/concepts/accounts-and-zones/#zones)).\n\nTo view AI Crawl Control metrics:\n\n1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com/), and select your account and domain.\n\n2. Go to **AI Crawl Control**.\n\n   [Go to **AI Crawl Control**](https://dash.cloudflare.com/?to=/:account/:zone/ai)\n\nYou can find meaningful information across the **Overview**, **Crawlers**, and **Metrics** tabs.\n\n## View the Overview tab\n\nThe **Overview** tab provides a snapshot of AI crawler activity:\n\n| Component | What you can do |\n| - | - |\n| **Executive summary** | Review total request volume, volume change, most common status code, most popular path, and high-volume crawler activity. |\n| **Managed robots.txt status** | Check whether [Cloudflare managed robots.txt](https://developers.cloudflare.com/bots/additional-configurations/managed-robots-txt/) is enabled for your zone. |\n| **Metrics with trend charts** | Monitor total requests, allowed requests, unsuccessful requests, and total referrals (paid plans only). |\n| **Crawlers grouped by operators** | Explore crawlers organized by company (OpenAI, Microsoft, Google, ByteDance, Anthropic, Meta) with allowed requests, referrals (paid plans only), and activity change percentages. Select a crawler or operator to drill down in the **Crawlers** tab. |\n| **Filters** | Customize your view by date range, crawler, operator, hostname, or path. All metrics update dynamically. |\n\n## View the Crawlers tab\n\nThe **Crawlers** tab provides detailed information about individual AI crawlers and allows you to set **Block** or **Allow** controls:\n\n| Metric | Description |\n| - | - |\n| **Total requests** | Total number of requests to crawl your website from common AI crawlers. |\n| **Requests by crawler** | Number of requests made by each AI crawler. |\n\nFor more information on managing crawler access, refer to [Manage AI crawlers](https://developers.cloudflare.com/ai-crawl-control/features/manage-ai-crawlers/).\n\n## View the Metrics tab\n\nThe **Metrics** tab provides detailed analytics and charts to help you understand how AI crawlers are interacting with your website.\n\n### Analyze referrer data\n\nNote\n\nThis feature is available for customers on a paid plan.\n\nIdentify traffic sources with referrer analytics to understand discovery patterns and content popularity from AI operators.\n\n* View top referrers driving traffic to your site.\n* Understand discovery patterns and content popularity from AI operators.\n\n### Track successful crawler requests over time\n\nVisualize successful crawler activity patterns over time using the **Successful requests over time** chart, which shows requests with status codes 200-300. You can group data by different dimensions to get more specific insights:\n\n| Dimension | Description |\n| - | - |\n| **Crawler** | Track activity from individual AI crawlers (like GPTBot, ClaudeBot, and Bytespider). |\n| **Category** | Analyze crawlers by their purpose or type. |\n| **Operator** | Discover which companies (such as OpenAI, Anthropic, and ByteDance) are crawling your site. |\n| **Host** | Break down activity across multiple subdomains. |\n\n### Monitor status code distribution\n\nThe **Status code distribution** chart shows HTTP response codes (2xx, 3xx, 4xx, 5xx) for AI crawler requests over time. This provides detailed visibility beyond the sparkline charts shown in the **Crawlers** tab.\n\nThe chart displays:\n\n* Total request counts for each status code category (2xx, 3xx, 4xx, 5xx)\n* Time series visualization showing status code trends over your selected time period\n* Filtering by crawler, category, operator, and time range\n\nUse this chart to identify patterns in how your site responds to AI crawlers in areas such as the distribution of error codes or the volume of redirects.\n\n### Understand what content is crawled\n\nThe **Most popular paths** table shows you which pages on your site are most frequently requested by AI crawlers. This can help you understand what content is most popular with different AI models.\n\n| Column | Description |\n| - | - |\n| **Path** | The path of the page on your website that was requested. |\n| **Hostname** | The hostname of the requested page. |\n| **Crawler** | The name of the AI crawler that made the request. |\n| **Operator** | The company that operates the AI crawler. |\n| **Allowed requests** | The number of times the path was successfully requested by the crawler. |\n\nYou can also filter the results by path or content type to narrow down your analysis.\n\n## Filter and export data\n\nYou can use the date filter to choose the period of time you wish to analyze. To export your data, select **Download CSV**. The downloaded file will include all applied filters and groupings.\n\n* Free plans\n\n  Filter options:\n\n  * Past 24 hours\n\n* Paid plans\n\n  Filter options:\n\n  * Past 24 hours\n  * Past 7 days\n  * Past 14 days\n  * Past month\n\nThe values of the AI Crawl Control metrics will update according to your filter.\n\n## Per-crawler drilldowns\n\nThe **Crawlers** tab includes an actions menu for each crawler with the following options:\n\n| Action | Description |\n| - | - |\n| **View Metrics** | Filter the **Metrics** tab to the selected crawler. |\n| **View on Cloudflare Radar** | Learn more about each verified crawler on Cloudflare Radar. |\n| **View in Security Analytics** | Filter Security Analytics by detection IDs ([Bot Management](https://developers.cloudflare.com/bots/get-started/bot-management/) customers). |\n| **Copy User Agent** | Copy user agent strings for use in [WAF custom rules](https://developers.cloudflare.com/waf/custom-rules/), [Redirect Rules](https://developers.cloudflare.com/rules/url-forwarding/), or robots.txt files. |\n| **Copy Detection ID** | Copy detection IDs for use in [WAF custom rules](https://developers.cloudflare.com/waf/custom-rules/) ([Bot Management](https://developers.cloudflare.com/bots/get-started/bot-management/) customers). |\n\n</page>\n\n<page>\n---\ntitle: Manage AI crawlers · Cloudflare AI Crawl Control docs\ndescription: AI Crawl Control enables you to take specific action for each AI crawler.\nlastUpdated: 2025-09-17T08:17:19.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-crawl-control/features/manage-ai-crawlers/\n  md: https://developers.cloudflare.com/ai-crawl-control/features/manage-ai-crawlers/index.md\n---\n\nAI Crawl Control enables you to take specific action for each AI crawler.\n\nTo manage AI crawlers:\n\n1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com/), and select your account and domain.\n\n2. Go to **AI Crawl Control**.\n\n   [Go to **AI Crawl Control**](https://dash.cloudflare.com/?to=/:account/:zone/ai)\n\n3. Go to the **Crawlers** tab.\n\n## Review AI crawler activity\n\nThe **Crawlers** tab displays a table of AI crawlers that are requesting access to your content, and how they interact with your pages. The table provides the following information.\n\n| Column | Details |\n| - | - |\n| Crawler | The name of the AI crawler and the operator that owns it. |\n| Category | The category of the AI crawler. Refer to [Verified bot categories](https://developers.cloudflare.com/bots/concepts/bot/verified-bots/#categories). |\n| Requests | The total number of allowed and unsuccessful requests, with trend chart. Unsuccessful requests may come from any rule or response error, not just the block action in AI Crawl Control. |\n| Robots.txt violations | The number of times the AI crawler has violated your `robots.txt` file. |\n| Action | The action you wish to take for the AI crawler. Refer to [Take action for each AI crawler](https://developers.cloudflare.com/ai-crawl-control/features/manage-ai-crawlers/#take-action-for-each-ai-crawler). |\n\nQuality of AI crawler detection\n\nOn the free plan, AI Crawl Control identifies AI crawlers based on their [user agent strings](https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/User-Agent). This enables AI Crawl Control to detect well-known, self-identifying AI crawlers.\n\nUpgrade your plan to enable a more thorough detection using Cloudflare's [Bot Management detection ID](https://developers.cloudflare.com/bots/reference/bot-management-variables/#ruleset-engine-fields) field.\n\n### Filter AI crawler data\n\nYou can use filters to narrow the scope of your result:\n\n* **Name:** Search the name of the AI crawler.\n* **Operator:** Filter by the AI crawler operator.\n* **Category:** Filter by the category of the AI crawler (for example, AI crawler, AI assistant, or archiver).\n\nThe values of the table will update according to your filter.\n\n## Take action for each AI crawler\n\n* Without pay per crawl\n\n  For each AI crawler, you can choose to allow or block access.\n\n  Allow access\n\n  * **Summary:** You can allow an AI crawler to scrape your content.\n  * **When to use:** Allow AI crawlers that offer services which provide value through citations, referrals, or existing agreements.\n  * **Implementation:** From the **Actions** column, select **Allow**.\n\n  Note that you can still choose to [Enforce `robots.txt`](https://developers.cloudflare.com/ai-crawl-control/features/manage-ai-crawlers/#take-action-for-each-ai-crawler).\n\n  Block access\n\n  * **Summary:** You can block an AI crawler to completely stop the AI crawler from scraping your webpage.\n  * **When to use:** Block AI crawlers when their behavior do not align with your content strategy, or violate your policies.\n  * **Implementation:** From the **Actions** column, select **Block**.\n\n  Note that you can configure the response that gets returned when blocking an AI crawler. Refer to [Configure block response](https://developers.cloudflare.com/ai-crawl-control/features/manage-ai-crawlers/#configure-block-response).\n\n* With pay per crawl\n\n  Pay per crawl closed beta\n\n  Pay per crawl is currently in closed beta.\n\n  To find out how to join the beta program, reach out to us at [Pay per crawl signup](http://www.cloudflare.com/paypercrawl-signup/), or contact your account executive if you are an existing Enterprise customer.\n\n  To learn more about pay per crawl, refer to Cloudflare blog: [Introducing pay per crawl: enabling content owners to charge AI crawlers for access](https://blog.cloudflare.com/introducing-pay-per-crawl/).\n\n  For each AI crawler, you can take one of three actions: allow, charge, or block.\n\n  Allow access\n\n  * **Summary:** You can allow an AI crawler to scrape your content.\n  * **When to use:** Allow AI crawlers that offer services which provide value through citations, referrals, or existing agreements.\n  * **Implementation:** From the **Actions** column, select **Allow**. Note that you can still choose to [Enforce `robots.txt`](https://developers.cloudflare.com/ai-crawl-control/features/manage-ai-crawlers/#take-action-for-each-ai-crawler).\n\n  For more details on how this rule interacts with other Cloudflare settings, refer to [How it works](https://developers.cloudflare.com/bots/concepts/bot/#how-it-works).\n\n  Block access\n\n  * **Summary:** You can block an AI crawler to completely stop the AI crawler from scraping your webpage.\n  * **When to use:** Block AI crawlers when their behavior do not align with your content strategy, or violate your policies.\n  * **Implementation:** From the **Actions** column, select **Block**.\n\n  Note that you can configure the response that gets returned when blocking an AI crawler. Refer to [Configure block response](https://developers.cloudflare.com/ai-crawl-control/features/manage-ai-crawlers/#configure-block-response).\n\n  Charge for crawl (private beta)\n\n  * **Summary:** You can charge the owner of the AI crawler for each successful crawl request.\n  * **When to use:** Charge AI crawlers when your content has training value, and you want to explore monetization options.\n  * **Implementation:** From the **Actions** column, select **Charge**.\n\n  For more information, refer to [What is Pay Per Crawl?](https://developers.cloudflare.com/ai-crawl-control/features/pay-per-crawl/what-is-pay-per-crawl/).\n\nNeed more advanced control?\n\nYou can also create more complex rules when taking action on AI crawlers, using [Cloudflare WAF](https://developers.cloudflare.com/waf/). For more information on creating more specific rules, refer to [Create a custom rule in the dashboard](https://developers.cloudflare.com/waf/custom-rules/create-dashboard/).\n\n## Configure block response\n\nAvailable on Paid plans\n\nWhen blocking an AI crawler, you can configure the details of the response that gets returned to the AI crawler. Specifically, you can configure:\n\n* The response code\n* The response body\n\nThis provides you with a channel to open dialogue with the AI crawler owner, and to inform the AI crawler how to properly license their content, thereby creating a direct path from crawling attempt to commercial agreement.\n\nTo edit these values:\n\n1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com/), and select your account and domain.\n\n2. Go to **AI Crawl Control**.\n\n   [Go to **AI Crawl Control**](https://dash.cloudflare.com/?to=/:account/:zone/ai)\n\n3. Go to the **Settings** tab.\n\n4. Under **Block response**, select **Edit**.\n\n5. Once you have edited the values, select **Save**.\n\nNote\n\nYou must have opted to block at least one AI crawler to configure a custom block response.\n\n### Edit the response code\n\nYou can choose which HTTP response code to return when blocking an AI crawler.\n\nUse the dropdown menu to select the desired response code. You can choose from:\n\n* `403 Forbidden`: Use this option if you wish to indicate that you do not want the AI crawler to access your content.\n* `402 Payment Required`: Use this option if you wish to indicate that the AI crawler must pay to access your content.\n\nNote\n\nBehind the scenes, AI Crawl Control uses [Cloudflare WAF](https://developers.cloudflare.com/waf/) to return custom block responses.\n\nIf you have manually configured a WAF rule to return a response code other than `403` or `402`, AI Crawl Control will not be able to enforce the response code you have selected, and the dropdown will appear blank. Ensure you have selected either `403` or `402`.\n\nRefer to [Configure a custom response for blocked requests](https://developers.cloudflare.com/waf/custom-rules/create-dashboard/#configure-a-custom-response-for-blocked-requests) for more information.\n\n### Edit the response body\n\nYou can write a custom message (HTTP response body) to return when blocking an AI crawler.\n\nIn the **Response body** text field, enter the response you wish to display for the AI crawler in plain text.\n\n## Related resources\n\n* Use [pay per crawl](https://developers.cloudflare.com/ai-crawl-control/features/pay-per-crawl/what-is-pay-per-crawl/) to charge AI crawlers every time they access your content.\n\n</page>\n\n<page>\n---\ntitle: Track robots.txt · Cloudflare AI Crawl Control docs\ndescription: The Robots.txt tab in AI Crawl Control provide insights into how AI\n  crawlers interact with your robots.txt files across your hostnames. You can\n  monitor request patterns, verify file availability, and identify crawlers that\n  violate your directives.\nlastUpdated: 2025-10-24T00:15:37.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-crawl-control/features/track-robots-txt/\n  md: https://developers.cloudflare.com/ai-crawl-control/features/track-robots-txt/index.md\n---\n\nThe **Robots.txt** tab in AI Crawl Control provide insights into how AI crawlers interact with your `robots.txt` files across your hostnames. You can monitor request patterns, verify file availability, and identify crawlers that violate your directives.\n\nTo access robots.txt insights:\n\n1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com/), and select your account and domain.\n\n2. Go to **AI Crawl Control**.\n\n   [Go to **AI Crawl Control**](https://dash.cloudflare.com/?to=/:account/:zone/ai)\n\n3. Go to the **Robots.txt** tab.\n\n## Check managed robots.txt status\n\nThe status card at the top of the tab shows whether Cloudflare is managing your `robots.txt` file.\n\nWhen enabled, Cloudflare will include directives to block common AI crawlers used for training and include its [Content Signals Policy](https://developers.cloudflare.com/bots/additional-configurations/managed-robots-txt/#content-signals-policy) in your `robots.txt`. For more details on how Cloudflare manages your `robots.txt` file, refer to [Managed `robots.txt`](https://developers.cloudflare.com/bots/additional-configurations/managed-robots-txt/).\n\n## Filter robots.txt request data\n\nYou can apply filters at the top of the tab to narrow your analysis of robots.txt requests:\n\n* Filter by specific crawler name (for example, Googlebot or specific AI bots).\n* Filter by the entity running the crawler to understand direct licensing opportunities or existing agreements.\n* Filter by general use cases (for example, AI training, general search, or AI assistant).\n* Select a custom time frame for historical analysis.\n\nThe values in all tables and metrics will update according to your filters.\n\n## Monitor robots.txt availability\n\nThe **Availability** table shows the historical request frequency and health status of `robots.txt` files across your hostnames over the selected time frame.\n\n| Column | Description |\n| - | - |\n| Path | The specific hostname's `robots.txt` file being requested. Paths are listed from the most requested to the least. |\n| Requests | The total number of requests made to this path. Requests are broken down into: - **Successful:** HTTP status codes below 400 (including **200 OK** and redirects). - **Unsuccessful:** HTTP status codes of 400 or above. |\n| Status | The HTTP status code from pinging the `robots.txt` file. |\n| Content Signals | An indicator showing whether the `robots.txt` file contains [Content Signals](https://contentsignals.org/), directives for usage in AI training, search, or AI input. |\n\nFrom this table, you can take the following actions:\n\n* Monitor for a high number of unsuccessful requests, which suggests that crawlers are having trouble accessing your `robots.txt` file.\n\n  * If the **Status** is `404 Not Found`, create a `robots.txt` file to provide clear directives.\n  * If the file exists, check for upstream WAF rules or other security settings that may be blocking access.\n\n* If the **Content Signals** column indicates that signals are missing, add them to your `robots.txt` file. You can do this by following the [Content Signals](https://contentsignals.org/) instructions or by enabling [Managed `robots.txt`](https://developers.cloudflare.com/bots/additional-configurations/managed-robots-txt/) to have Cloudflare manage them for you.\n\n## Track robots.txt violations\n\nThe **Violations** table identifies AI crawlers that have requested paths explicitly disallowed by your `robots.txt` file. This helps you identify non-compliant crawlers and take appropriate action.\n\nHow violations are calculated\n\nThe Violations table identifies mismatches between your **current** `robots.txt` directives and past crawler requests. Because violations are not logged in real-time, recently added or changed rules may cause previously legitimate requests to be flagged as violations.\n\nFor example, if you add a new `Disallow` rule, all past requests to that path will appear as violations, even though they were not violations at the time of the request.\n\n| Column | Description |\n| - | - |\n| Crawler | The name of the bot that violated your `robots.txt` directives. The operator of the crawler is listed directly beneath the crawler name. |\n| Path | The specific URL or path the crawler attempted to access that was disallowed by your `robots.txt` file. |\n| Directive | The exact line from your `robots.txt` file that disallowed access to the path. |\n| Violations | The count of HTTP requests made to the disallowed path/directive pair within the selected time frame. |\n\nWhen you identify crawlers violating your `robots.txt` directives, you have several options:\n\n* Navigate to the [**Crawlers** tab](https://developers.cloudflare.com/ai-crawl-control/features/manage-ai-crawlers/) to permanently block the non-compliant crawler.\n* Use [Cloudflare WAF](https://developers.cloudflare.com/waf/) to create a path-specific security rules for the violating crawler.\n* Use [Redirect Rules](https://developers.cloudflare.com/rules/url-forwarding/) to guide violating crawlers to an appropriate area of your site.\n\n## Related resources\n\n* [Manage AI crawlers](https://developers.cloudflare.com/ai-crawl-control/features/manage-ai-crawlers/)\n* [Analyze AI traffic](https://developers.cloudflare.com/ai-crawl-control/features/analyze-ai-traffic/)\n* [Cloudflare WAF](https://developers.cloudflare.com/waf/)\n\n</page>\n\n<page>\n---\ntitle: Pay Per Crawl · Cloudflare AI Crawl Control docs\nlastUpdated: 2025-08-27T16:00:59.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/ai-crawl-control/features/pay-per-crawl/\n  md: https://developers.cloudflare.com/ai-crawl-control/features/pay-per-crawl/index.md\n---\n\n* [What is Pay Per Crawl?](https://developers.cloudflare.com/ai-crawl-control/features/pay-per-crawl/what-is-pay-per-crawl/)\n* [Use pay per crawl as a site owner](https://developers.cloudflare.com/ai-crawl-control/features/pay-per-crawl/use-pay-per-crawl-as-site-owner/)\n* [Use pay per crawl as an AI owner](https://developers.cloudflare.com/ai-crawl-control/features/pay-per-crawl/use-pay-per-crawl-as-ai-owner/)\n* [Pay Per Crawl FAQ](https://developers.cloudflare.com/ai-crawl-control/features/pay-per-crawl/faq/)\n\n</page>\n\n<page>\n---\ntitle: Glossary · Cloudflare AI Crawl Control docs\ndescription: Review the definitions for terms used across Cloudflare's AI Crawl\n  Control documentation.\nlastUpdated: 2025-08-27T16:00:59.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-crawl-control/reference/glossary/\n  md: https://developers.cloudflare.com/ai-crawl-control/reference/glossary/index.md\n---\n\nReview the definitions for terms used across Cloudflare's AI Crawl Control documentation.\n\n| Term | Definition |\n| - | - |\n| AI crawler | A bot which scrapes content from websites in support of an AI model, including by scraping content for indexing, retrieval augmented generation, or training. |\n| In-band pricing | A pricing model where pricing information is transmitted within the same communication channel as the content itself. In Pay Per Crawl, in-band pricing means the price is included in the HTTP response headers (`crawler-price`) alongside the actual content, rather than being retrieved from a separate system or API call. When custom pricing is enabled, Cloudflare sets the `cf-pay-per-crawl` header to `pricing=in-band`, indicating that the origin server or Worker can dynamically set prices by including a `crawler-price` header in the response. |\n| Merchant of Record | The entity who facilitates \"buying and selling\". For pay per crawl, Cloudflare is the merchant of record. |\n| Operator | The company or organization that owns and operates an AI crawler. Examples include OpenAI, Microsoft, Google, ByteDance, Anthropic, and Meta. In AI Crawl Control, crawlers are grouped by their operators. |\n| Referrals | Traffic referred to your website by AI services, identified by the referrer URL and whether it is owned by an AI operator. |\n| robots.txt | A text file which lists pages in your website that are off-limits for bots. Well-behaved bots respect this file, but some bots may violate it. You can enforce `robots.txt` with Cloudflare WAF custom rules. |\n\n</page>\n\n<page>\n---\ntitle: How AI Search works · Cloudflare AI Search docs\ndescription: AI Search (formerly AutoRAG) is Cloudflare’s managed search\n  service. You can connect your data such as websites or unstructured content,\n  and it automatically creates a continuously updating index that you can query\n  with natural language in your applications or AI agents.\nlastUpdated: 2025-09-24T17:03:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/concepts/how-ai-search-works/\n  md: https://developers.cloudflare.com/ai-search/concepts/how-ai-search-works/index.md\n---\n\nAI Search (formerly AutoRAG) is Cloudflare’s managed search service. You can connect your data such as websites or unstructured content, and it automatically creates a continuously updating index that you can query with natural language in your applications or AI agents.\n\nAI Search consists of two core processes:\n\n* **Indexing:** An asynchronous background process that monitors your data source for changes and converts your data into vectors for search.\n* **Querying:** A synchronous process triggered by user queries. It retrieves the most relevant content and generates context-aware responses.\n\n## How indexing works\n\nIndexing begins automatically when you create an AI Search instance and connect a data source.\n\nHere is what happens during indexing:\n\n1. **Data ingestion:** AI Search reads from your connected data source.\n2. **Markdown conversion:** AI Search uses [Workers AI’s Markdown Conversion](https://developers.cloudflare.com/workers-ai/features/markdown-conversion/) to convert [supported data types](https://developers.cloudflare.com/ai-search/configuration/data-source/) into structured Markdown. This ensures consistency across diverse file types. For images, Workers AI is used to perform object detection followed by vision-to-language transformation to convert images into Markdown text.\n3. **Chunking:** The extracted text is [chunked](https://developers.cloudflare.com/ai-search/configuration/chunking/) into smaller pieces to improve retrieval granularity.\n4. **Embedding:** Each chunk is embedded using Workers AI’s embedding model to transform the content into vectors.\n5. **Vector storage:** The resulting vectors, along with metadata like file name, are stored in a the [Vectorize](https://developers.cloudflare.com/vectorize/) database created on your Cloudflare account.\n\nAfter the initial data set is indexed, AI Search will regularly check for updates in your data source (e.g. additions, updates, or deletes) and index changes to ensure your vector database is up to date.\n\n![Indexing](https://developers.cloudflare.com/_astro/indexing.CQ13F9Js_1Pewmk.webp)\n\n## How querying works\n\nOnce indexing is complete, AI Search is ready to respond to end-user queries in real time.\n\nHere is how the querying pipeline works:\n\n1. **Receive query from AI Search API:** The query workflow begins when you send a request to either the AI Search’s [AI Search](https://developers.cloudflare.com/ai-search/usage/rest-api/#ai-search) or [Search](https://developers.cloudflare.com/ai-search/usage/rest-api/#search) endpoints.\n2. **Query rewriting (optional):** AI Search provides the option to [rewrite the input query](https://developers.cloudflare.com/ai-search/configuration/query-rewriting/) using one of Workers AI’s LLMs to improve retrieval quality by transforming the original query into a more effective search query.\n3. **Embedding the query:** The rewritten (or original) query is transformed into a vector via the same embedding model used to embed your data so that it can be compared against your vectorized data to find the most relevant matches.\n4. **Querying Vectorize index:** The query vector is [queried](https://developers.cloudflare.com/vectorize/best-practices/query-vectors/) against stored vectors in the associated Vectorize database for your AI Search.\n5. **Content retrieval:** Vectorize returns the metadata of the most relevant chunks, and the original content is retrieved from the R2 bucket. If you are using the Search endpoint, the content is returned at this point.\n6. **Response generation:** If you are using the AI Search endpoint, then a text-generation model from Workers AI is used to generate a response using the retrieved content and the original user’s query, combined via a [system prompt](https://developers.cloudflare.com/ai-search/configuration/system-prompt/). The context-aware response from the model is returned.\n\n![Querying](https://developers.cloudflare.com/_astro/querying.c_RrR1YL_Z1CePPB.webp)\n\n</page>\n\n<page>\n---\ntitle: What is RAG · Cloudflare AI Search docs\ndescription: Retrieval-Augmented Generation (RAG) is a way to use your own data\n  with a large language model (LLM). Instead of relying only on what the model\n  was trained on, RAG searches for relevant information from your data source\n  and uses it to help answer questions.\nlastUpdated: 2025-09-24T17:03:07.000Z\nchatbotDeprioritize: false\ntags: LLM\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/concepts/what-is-rag/\n  md: https://developers.cloudflare.com/ai-search/concepts/what-is-rag/index.md\n---\n\nRetrieval-Augmented Generation (RAG) is a way to use your own data with a large language model (LLM). Instead of relying only on what the model was trained on, RAG searches for relevant information from your data source and uses it to help answer questions.\n\n## How RAG works\n\nHere’s a simplified overview of the RAG pipeline:\n\n1. **Indexing:** Your content (e.g. docs, wikis, product information) is split into smaller chunks and converted into vectors using an embedding model. These vectors are stored in a vector database.\n2. **Retrieval:** When a user asks a question, it’s also embedded into a vector and used to find the most relevant chunks from the vector database.\n3. **Generation:** The retrieved content and the user’s original question are combined into a single prompt. An LLM uses that prompt to generate a response.\n\nThe resulting response should be accurate, relevant, and based on your own data.\n\n![What is RAG](https://developers.cloudflare.com/_astro/RAG.Br2ehjiz_2lPBPi.webp)\n\nHow does AI Search work\n\nTo learn more details about how AI Search uses RAG under the hood, reference [How AI Search works](https://developers.cloudflare.com/ai-search/concepts/how-ai-search-works/).\n\n## Why use RAG?\n\nRAG lets you bring your own data into LLM generation without retraining or fine-tuning a model. It improves both accuracy and trust by retrieving relevant content at query time and using that as the basis for a response.\n\nBenefits of using RAG:\n\n* **Accurate and current answers:** Responses are based on your latest content, not outdated training data.\n* **Control over information sources:** You define the knowledge base so answers come from content you trust.\n* **Fewer hallucinations:** Responses are grounded in real, retrieved data, reducing made-up or misleading answers.\n* **No model training required:** You can get high-quality results without building or fine-tuning your own LLM which can be time consuming and costly.\n\nRAG is ideal for building AI-powered apps like:\n\n* AI assistants for internal knowledge\n* Support chatbots connected to your latest content\n* Enterprise search across documentation and files\n\n</page>\n\n<page>\n---\ntitle: Similarity cache · Cloudflare AI Search docs\ndescription: Similarity-based caching in AI Search lets you serve responses from\n  Cloudflare’s cache for queries that are similar to previous requests, rather\n  than creating new, unique responses for every request. This speeds up response\n  times and cuts costs by reusing answers for questions that are close in\n  meaning.\nlastUpdated: 2025-09-24T17:03:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/configuration/cache/\n  md: https://developers.cloudflare.com/ai-search/configuration/cache/index.md\n---\n\nSimilarity-based caching in AI Search lets you serve responses from Cloudflare’s cache for queries that are similar to previous requests, rather than creating new, unique responses for every request. This speeds up response times and cuts costs by reusing answers for questions that are close in meaning.\n\n## How It Works\n\nUnlike with basic caching, which creates a new response with every request, this is what happens when a request is received using similarity-based caching:\n\n1. AI Search checks if a *similar* prompt (based on your chosen threshold) has been answered before.\n2. If a match is found, it returns the cached response instantly.\n3. If no match is found, it generates a new response and caches it.\n\nTo see if a response came from the cache, check the `cf-aig-cache-status` header: `HIT` for cached and `MISS` for new.\n\n## What to consider when using similarity cache\n\nConsider these behaviors when using similarity caching:\n\n* **Volatile Cache**: If two similar requests hit at the same time, the first might not cache in time for the second to use it, resulting in a `MISS`.\n* **30-Day Cache**: Cached responses last 30 days, then expire automatically. No custom durations for now.\n* **Data Dependency**: Cached responses are tied to specific document chunks. If those chunks change or get deleted, the cache clears to keep answers fresh.\n\n## How similarity matching works\n\nAI Search’s similarity cache uses **MinHash and Locality-Sensitive Hashing (LSH)** to find and reuse responses for prompts that are worded similarly.\n\nHere’s how it works when a new prompt comes in:\n\n1. The prompt is split into small overlapping chunks of words (called shingles), like “what’s the” or “the weather.”\n2. These shingles are turned into a “fingerprint” using MinHash. The more overlap two prompts have, the more similar their fingerprints will be.\n3. Fingerprints are placed into LSH buckets, which help AI Search quickly find similar prompts without comparing every single one.\n4. If a past prompt in the same bucket is similar enough (based on your configured threshold), AI Search reuses its cached response.\n\n## Choosing a threshold\n\nThe similarity threshold decides how close two prompts need to be to reuse a cached response. Here are the available thresholds:\n\n| Threshold | Description | Example Match |\n| - | - | - |\n| Exact | Near-identical matches only | \"What’s the weather like today?\" matches with \"What is the weather like today?\" |\n| Strong (default) | High semantic similarity | \"What’s the weather like today?\" matches with \"How’s the weather today?\" |\n| Broad | Moderate match, more hits | \"What’s the weather like today?\" matches with \"Tell me today’s weather\" |\n| Loose | Low similarity, max reuse | \"What’s the weather like today?\" matches with \"Give me the forecast\" |\n\nTest these values to see which works best with your [RAG application](https://developers.cloudflare.com/ai-search/).\n\n</page>\n\n<page>\n---\ntitle: Chunking · Cloudflare AI Search docs\ndescription: Chunking is the process of splitting large data into smaller\n  segments before embedding them for search. AI Search uses recursive chunking,\n  which breaks your content at natural boundaries (like paragraphs or\n  sentences), and then further splits it if the chunks are too large.\nlastUpdated: 2025-09-24T17:03:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/configuration/chunking/\n  md: https://developers.cloudflare.com/ai-search/configuration/chunking/index.md\n---\n\nChunking is the process of splitting large data into smaller segments before embedding them for search. AI Search uses **recursive chunking**, which breaks your content at natural boundaries (like paragraphs or sentences), and then further splits it if the chunks are too large.\n\n## What is recursive chunking\n\nRecursive chunking tries to keep chunks meaningful by:\n\n* **Splitting at natural boundaries:** like paragraphs, then sentences.\n* **Checking the size:** if a chunk is too long (based on token count), it’s split again into smaller parts.\n\nThis way, chunks are easy to embed and retrieve, without cutting off thoughts mid-sentence.\n\n## Chunking controls\n\nAI Search exposes two parameters to help you control chunking behavior:\n\n* **Chunk size**: The number of tokens per chunk.\n\n  * Minimum: `64`\n  * Maximum: `512`\n\n* **Chunk overlap**: The percentage of overlapping tokens between adjacent chunks.\n\n  * Minimum: `0%`\n  * Maximum: `30%`\n\nThese settings apply during the indexing step, before your data is embedded and stored in Vectorize.\n\n## Choosing chunk size and overlap\n\nChunking affects both how your content is retrieved and how much context is passed into the generation model. Try out this external [chunk visualizer tool](https://huggingface.co/spaces/m-ric/chunk_visualizer) to help understand how different chunk settings could look.\n\nFor chunk size, consider how:\n\n* **Smaller chunks** create more precise vector matches, but may split relevant ideas across multiple chunks.\n* **Larger chunks** retain more context, but may dilute relevance and reduce retrieval precision.\n\nFor chunk overlap, consider how:\n\n* **More overlap** helps preserve continuity across boundaries, especially in flowing or narrative content.\n* **Less overlap** reduces indexing time and cost, but can miss context if key terms are split between chunks.\n\n### Additional considerations:\n\n* **Vector index size:** Smaller chunk sizes produce more chunks and more total vectors. Refer to the [Vectorize limits](https://developers.cloudflare.com/vectorize/platform/limits/) to ensure your configuration stays within the maximum allowed vectors per index.\n* **Generation model context window:** Generation models have a limited context window that must fit all retrieved chunks (`topK` × `chunk size`), the user query, and the model’s output. Be careful with large chunks or high topK values to avoid context overflows.\n* **Cost and performance:** Larger chunks and higher topK settings result in more tokens passed to the model, which can increase latency and cost. You can monitor this usage in [AI Gateway](https://developers.cloudflare.com/ai-gateway/).\n\n</page>\n\n<page>\n---\ntitle: Data source · Cloudflare AI Search docs\ndescription: \"AI Search can directly ingest data from the following sources:\"\nlastUpdated: 2025-09-24T17:03:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/configuration/data-source/\n  md: https://developers.cloudflare.com/ai-search/configuration/data-source/index.md\n---\n\nAI Search can directly ingest data from the following sources:\n\n| Data Source | Description |\n| - | - |\n| [Website](https://developers.cloudflare.com/ai-search/configuration/data-source/website/) | Connect a domain you own to index website pages. |\n| [R2 Bucket](https://developers.cloudflare.com/ai-search/configuration/data-source/r2/) | Connect a Cloudflare R2 bucket to index stored documents. |\n\n</page>\n\n<page>\n---\ntitle: Indexing · Cloudflare AI Search docs\ndescription: AI Search automatically indexes your data into vector embeddings\n  optimized for semantic search. Once a data source is connected, indexing runs\n  continuously in the background to keep your knowledge base fresh and\n  queryable.\nlastUpdated: 2025-09-24T17:03:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/configuration/indexing/\n  md: https://developers.cloudflare.com/ai-search/configuration/indexing/index.md\n---\n\nAI Search automatically indexes your data into vector embeddings optimized for semantic search. Once a data source is connected, indexing runs continuously in the background to keep your knowledge base fresh and queryable.\n\n## Jobs\n\nAI Search automatically monitors your data source for updates and reindexes your content every **6 hours**. During each cycle, new or modified files are reprocessed to keep your Vectorize index up to date.\n\nYou can monitor the status and history of all indexing activity in the Jobs tab, including real-time logs for each job to help you troubleshoot and verify successful syncs.\n\n## Controls\n\nYou can control indexing behavior through the following actions on the dashboard:\n\n* **Sync Index**: Force AI Search to scan your data source for new or modified files and initiate an indexing job to update the associated Vectorize index. A new indexing job can be initiated every 30 seconds.\n* **Pause Indexing**: Temporarily stop all scheduled indexing checks and reprocessing. Useful for debugging or freezing your knowledge base.\n\n## Performance\n\nThe total time to index depends on the number and type of files in your data source. Factors that affect performance include:\n\n* Total number of files and their sizes\n* File formats (for example, images take longer than plain text)\n* Latency of Workers AI models used for embedding and image processing\n\n## Best practices\n\nTo ensure smooth and reliable indexing:\n\n* Make sure your files are within the [**size limit**](https://developers.cloudflare.com/ai-search/platform/limits-pricing/#limits) and in a supported format to avoid being skipped.\n* Keep your Service API token valid to prevent indexing failures.\n* Regularly clean up outdated or unnecessary content in your knowledge base to avoid hitting [Vectorize index limits](https://developers.cloudflare.com/vectorize/platform/limits/).\n\n</page>\n\n<page>\n---\ntitle: Metadata · Cloudflare AI Search docs\ndescription: Use metadata to filter documents before retrieval and provide\n  context to guide AI responses. This page covers how to apply filters and\n  attach optional context metadata to your files.\nlastUpdated: 2025-09-24T17:03:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/configuration/metadata/\n  md: https://developers.cloudflare.com/ai-search/configuration/metadata/index.md\n---\n\nUse metadata to filter documents before retrieval and provide context to guide AI responses. This page covers how to apply filters and attach optional context metadata to your files.\n\n## Metadata filtering\n\nMetadata filtering narrows down search results based on metadata, so only relevant content is retrieved. The filter narrows down results prior to retrieval, so that you only query the scope of documents that matter.\n\nHere is an example of metadata filtering using [Workers Binding](https://developers.cloudflare.com/ai-search/usage/workers-binding/) but it can be easily adapted to use the [REST API](https://developers.cloudflare.com/ai-search/usage/rest-api/) instead.",
      "language": "unknown"
    },
    {
      "code": "### Metadata attributes\n\n| Attribute | Description | Example |\n| - | - | - |\n| `filename` | The name of the file. | `dog.png` or `animals/mammals/cat.png` |\n| `folder` | The folder or prefix to the object. | For the object `animals/mammals/cat.png`, the folder is `animals/mammals/` |\n| `timestamp` | The timestamp for when the object was last modified. Comparisons are supported using a 13-digit Unix timestamp (milliseconds), but values will be rounded down to 10 digits (seconds). | The timestamp `2025-01-01 00:00:00.999 UTC` is `1735689600999` and it will be rounded down to `1735689600000`, corresponding to `2025-01-01 00:00:00 UTC` |\n\n### Filter schema\n\nYou can create simple comparison filters or an array of comparison filters using a compound filter.\n\n#### Comparison filter\n\nYou can compare a metadata attribute (for example, `folder` or `timestamp`) with a target value using a comparison filter.",
      "language": "unknown"
    },
    {
      "code": "The available operators for the comparison are:\n\n| Operator | Description |\n| - | - |\n| `eq` | Equals |\n| `ne` | Not equals |\n| `gt` | Greater than |\n| `gte` | Greater than or equals to |\n| `lt` | Less than |\n| `lte` | Less than or equals to |\n\n#### Compound filter\n\nYou can use a compound filter to combine multiple comparison filters with a logical operator.",
      "language": "unknown"
    },
    {
      "code": "The available compound operators are: `and`, `or`.\n\nNote the following limitations with the compound operators:\n\n* No nesting combinations of `and`'s and `or`'s, meaning you can only pick 1 `and` or 1 `or`.\n\n* When using `or`:\n\n  * Only the `eq` operator is allowed.\n  * All conditions must filter on the **same key** (for example, all on `folder`)\n\n#### \"Starts with\" filter for folders\n\nYou can use \"starts with\" filtering on the `folder` metadata attribute to search for all files and subfolders within a specific path.\n\nFor example, consider this file structure:\n\nIf you were to filter using an `eq` (equals) operator with `value: \"customer-a/\"`, it would only match files directly within that folder, like `profile.md`. It would not include files in subfolders like `customer-a/contracts/`.\n\nTo recursively filter for all items starting with the path `customer-a/`, you can use the following compound filter:",
      "language": "unknown"
    },
    {
      "code": "This filter identifies paths starting with `customer-a/` by using:\n\n* The `and` condition to combine the effects of the `gt` and `lte` conditions.\n* The `gt` condition to include paths greater than the `/` ASCII character.\n* The `lte` condition to include paths less than and including the lower case `z` ASCII character.\n\nTogether, these conditions effectively select paths that begin with the provided path value.\n\n## Add `context` field to guide AI Search\n\nYou can optionally include a custom metadata field named `context` when uploading an object to your R2 bucket.\n\nThe `context` field is attached to each chunk and passed to the LLM during an `/ai-search` query. It does not affect retrieval but helps the LLM interpret and frame the answer.\n\nThe field can be used for providing document summaries, source links, or custom instructions without modifying the file content.\n\nYou can add [custom metadata](https://developers.cloudflare.com/r2/api/workers/workers-api-reference/#r2putoptions) to an object in the `/PUT` operation when uploading the object to your R2 bucket. For example if you are using the [Workers binding with R2](https://developers.cloudflare.com/r2/api/workers/workers-api-usage/):",
      "language": "unknown"
    },
    {
      "code": "During `/ai-search`, this context appears in the response under `attributes.file.context`, and is included in the data passed to the LLM for generating a response.\n\n## Response\n\nYou can see the metadata attributes of your retrieved data in the response under the property `attributes` for each retrieved chunk. For example:",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Models · Cloudflare AI Search docs\ndescription: AI Search uses models at multiple stages. You can configure which\n  models are used, or let AI Search automatically select a smart default for\n  you.\nlastUpdated: 2025-09-24T17:03:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/configuration/models/\n  md: https://developers.cloudflare.com/ai-search/configuration/models/index.md\n---\n\nAI Search uses models at multiple stages. You can configure which models are used, or let AI Search automatically select a smart default for you.\n\n## Models usage\n\nAI Search leverages Workers AI models in the following stages:\n\n* Image to markdown conversion (if images are in data source): Converts image content to Markdown using object detection and captioning models.\n* Embedding: Transforms your documents and queries into vector representations for semantic search.\n* Query rewriting (optional): Reformulates the user’s query to improve retrieval accuracy.\n* Generation: Produces the final response from retrieved context.\n\n## Model providers\n\nAll AI Search instances support models from [Workers AI](https://developers.cloudflare.com/workers-ai). You can use other providers (such as OpenAI or Anthropic) in AI Search by adding their API keys to an [AI Gateway](https://developers.cloudflare.com/ai-gateway) and connecting that gateway to your AI Search.\n\nTo use AI Search with other model providers:\n\n1. Add provider keys to AI Gateway\n\n* Go to **AI > AI Gateway** in the dashboard.\n* Select or create an AI gateway.\n* In **Provider Keys**, choose your provider, click **Add**, and enter the key.\n\n1. Connect the gateway to AI Search\n\n* When creating a new AI Search, select the AI Gateway with your provider keys.\n* For an existing AI Search, go to **Settings** and switch to a gateway that has your keys under **Resources**.\n\n1. Select models\n\n* Embedding model: Only available to be changed when creating a new AI Search.\n* Generation model: Can be selected when creating a new AI Search and can be changed at any time in **Settings**.\n\nAI Search supports a subset of models that have been selected to provide the best experience. See list of [supported models](https://developers.cloudflare.com/ai-search/configuration/models/supported-models/).\n\n### Smart default\n\nIf you choose **Smart Default** in your model selection, then AI Search will select a Cloudflare recommended model and will update it automatically for you over time. You can switch to explicit model configuration at any time by visiting **Settings**.\n\n### Per-request generation model override\n\nWhile the generation model can be set globally at the AI Search instance level, you can also override it on a per-request basis in the [AI Search API](https://developers.cloudflare.com/ai-search/usage/rest-api/#ai-search). This is useful if your [RAG application](https://developers.cloudflare.com/ai-search/) requires dynamic selection of generation models based on context or user preferences.\n\n## Model deprecation\n\nAI Search may deprecate support for a given model in order to provide support for better-performing models with improved capabilities. When a model is being deprecated, we announce the change and provide an end-of-life date after which the model will no longer be accessible. Applications that depend on AI Search may therefore require occasional updates to continue working reliably.\n\n### Model lifecycle\n\nAI Search models follow a defined lifecycle to ensure stability and predictable deprecation:\n\n1. **Production:** The model is actively supported and recommended for use. It is included in Smart Defaults and receives ongoing updates and maintenance.\n2. **Announcement & Transition:** The model remains available but has been marked for deprecation. An end-of-life date is communicated through documentation, release notes, and other official channels. During this phase, users are encouraged to migrate to the recommended replacement model.\n3. **Automatic Upgrade (if applicable):** If you have selected the Smart Default option, AI Search will automatically upgrade requests to a recommended replacement.\n4. **End of life:** The model is no longer available. Any requests to the retired model return a clear error message, and the model is removed from documentation and Smart Defaults.\n\nSee models are their lifecycle status in [supported models](https://developers.cloudflare.com/ai-search/configuration/models/supported-models/).\n\n### Best practices\n\n* Regularly check the [release note](https://developers.cloudflare.com/ai-search/platform/release-note/) for updates.\n* Plan migration efforts according to the communicated end-of-life date.\n* Migrate and test the recommended replacement models before the end-of-life date.\n\n</page>\n\n<page>\n---\ntitle: Query rewriting · Cloudflare AI Search docs\ndescription: Query rewriting is an optional step in the AI Search pipeline that\n  improves retrieval quality by transforming the original user query into a more\n  effective search query.\nlastUpdated: 2025-09-24T17:03:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/configuration/query-rewriting/\n  md: https://developers.cloudflare.com/ai-search/configuration/query-rewriting/index.md\n---\n\nQuery rewriting is an optional step in the AI Search pipeline that improves retrieval quality by transforming the original user query into a more effective search query.\n\nInstead of embedding the raw user input directly, AI Search can use a large language model (LLM) to rewrite the query based on a system prompt. The rewritten query is then used to perform the vector search.\n\n## Why use query rewriting?\n\nThe wording of a user’s question may not match how your documents are written. Query rewriting helps bridge this gap by:\n\n* Rephrasing informal or vague queries into precise, information-dense terms\n* Adding synonyms or related keywords\n* Removing filler words or irrelevant details\n* Incorporating domain-specific terminology\n\nThis leads to more relevant vector matches which improves the accuracy of the final generated response.\n\n## Example\n\n**Original query:** `how do i make this work when my api call keeps failing?`\n\n**Rewritten query:** `API call failure troubleshooting authentication headers rate limiting network timeout 500 error`\n\nIn this example, the original query is conversational and vague. The rewritten version extracts the core problem (API call failure) and expands it with relevant technical terms and likely causes. These terms are much more likely to appear in documentation or logs, improving semantic matching during vector search.\n\n## How it works\n\nIf query rewriting is enabled, AI Search performs the following:\n\n1. Sends the **original user query** and the **query rewrite system prompt** to the configured LLM\n2. Receives the **rewritten query** from the model\n3. Embeds the rewritten query using the selected embedding model\n4. Performs vector search in your AI Search’s Vectorize index\n\nFor details on how to guide model behavior during this step, see the [system prompt](https://developers.cloudflare.com/ai-search/configuration/system-prompt/) documentation.\n\n</page>\n\n<page>\n---\ntitle: Reranking · Cloudflare AI Search docs\ndescription: Reranking can help improve the quality of AI Search results by\n  reordering retrieved documents based on semantic relevance to the user’s\n  query. It applies a secondary model after retrieval to \"rerank\" the top\n  results before they are outputted.\nlastUpdated: 2025-10-28T15:46:27.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/configuration/reranking/\n  md: https://developers.cloudflare.com/ai-search/configuration/reranking/index.md\n---\n\nReranking can help improve the quality of AI Search results by reordering retrieved documents based on semantic relevance to the user’s query. It applies a secondary model after retrieval to \"rerank\" the top results before they are outputted.\n\n## How it works\n\nBy default, reranking is **disabled** for all AI Search instances. You can enable it during creation or later from the settings page.\n\nWhen enabled, AI Search will:\n\n1. Retrieve a set of relevant results from your index, constrained by your `max_num_of_results` and `score_threshold` parameters.\n2. Pass those results through a [reranking model](https://developers.cloudflare.com/ai-search/configuration/models/supported-models/).\n3. Return the reranked results, which the text generation model can use for answer generation.\n\nReranking helps improve accuracy, especially for large or noisy datasets where vector similarity alone may not produce the optimal ordering.\n\n## Configuration\n\nYou can configure reranking in several ways:\n\n### Configure via API\n\nWhen you make a `/search` or `/ai-search` request using the [Workers Binding](https://developers.cloudflare.com/ai-search/usage/workers-binding/) or [REST API](https://developers.cloudflare.com/ai-search/usage/rest-api/), you can:\n\n* Enable or disable reranking per request\n* Specify the reranking model\n\nFor example:",
      "language": "unknown"
    },
    {
      "code": "### Configure in dashboard for new AI Search\n\nWhen creating a new RAG in the dashboard:\n\n1. Go to **AI Search** in the Cloudflare dashboard.\n\n   [Go to **AI Search (AutoRAG)**](https://dash.cloudflare.com/?to=/:account/ai/ai-search)\n\n2. Select **Create** > **Get started**.\n\n3. In the **Retrieval configuration** step, open the **Reranking** dropdown.\n\n4. Toggle **Reranking** on.\n\n5. Select the reranking model.\n\n6. Complete your setup.\n\n### Configure in dashboard for existing AI Search\n\nTo update reranking for an existing instance:\n\n1. Go to **AI Search** in the Cloudflare dashboard.\n\n   [Go to **AI Search (AutoRAG)**](https://dash.cloudflare.com/?to=/:account/ai/ai-search)\n\n2. Select an existing AI Search instance.\n\n3. Go to the **Settings** tab.\n\n4. Under **Reranking**, toggle reranking on.\n\n5. Select the reranking model.\n\n</page>\n\n<page>\n---\ntitle: Retrieval configuration · Cloudflare AI Search docs\ndescription: \"AI Search allows you to configure how content is retrieved from\n  your vector index and used to generate a final response. Two options control\n  this behavior:\"\nlastUpdated: 2025-09-24T17:03:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/configuration/retrieval-configuration/\n  md: https://developers.cloudflare.com/ai-search/configuration/retrieval-configuration/index.md\n---\n\nAI Search allows you to configure how content is retrieved from your vector index and used to generate a final response. Two options control this behavior:\n\n* **Match threshold**: Minimum similarity score required for a vector match to be considered relevant.\n* **Maximum number of results**: Maximum number of top-matching results to return (`top_k`).\n\nAI Search uses the [`query()`](https://developers.cloudflare.com/vectorize/best-practices/query-vectors/) method from [Vectorize](https://developers.cloudflare.com/vectorize/) to perform semantic search. This function compares the embedded query vector against the stored vectors in your index and returns the most similar results.\n\n## Match threshold\n\nThe `match_threshold` sets the minimum similarity score (for example, cosine similarity) that a document chunk must meet to be included in the results. Threshold values range from `0` to `1`.\n\n* A higher threshold means stricter filtering, returning only highly similar matches.\n* A lower threshold allows broader matches, increasing recall but possibly reducing precision.\n\n## Maximum number of results\n\nThis setting controls the number of top-matching chunks returned by Vectorize after filtering by similarity score. It corresponds to the `topK` parameter in `query()`. The maximum allowed value is 50.\n\n* Use a higher value if you want to synthesize across multiple documents. However, providing more input to the model can increase latency and cost.\n* Use a lower value if you prefer concise answers with minimal context.\n\n## How they work together\n\nAI Search's retrieval step follows this sequence:\n\n1. Your query is embedded using the configured Workers AI model.\n2. `query()` is called to search the Vectorize index, with `topK` set to the `maximum_number_of_results`.\n3. Results are filtered using the `match_threshold`.\n4. The filtered results are passed into the generation step as context.\n\nIf no results meet the threshold, AI Search will not generate a response.\n\n## Configuration\n\nThese values can be configured at the AI Search instance level or overridden on a per-request basis using the [REST API](https://developers.cloudflare.com/ai-search/usage/rest-api/) or the [Workers Binding](https://developers.cloudflare.com/ai-search/usage/workers-binding/).\n\nUse the parameters `match_threshold` and `max_num_results` to customize retrieval behavior per request.\n\n</page>\n\n<page>\n---\ntitle: System prompt · Cloudflare AI Search docs\ndescription: \"System prompts allow you to guide the behavior of the\n  text-generation models used by AI Search at query time. AI Search supports\n  system prompt configuration in two steps:\"\nlastUpdated: 2025-10-28T15:46:27.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/configuration/system-prompt/\n  md: https://developers.cloudflare.com/ai-search/configuration/system-prompt/index.md\n---\n\nSystem prompts allow you to guide the behavior of the text-generation models used by AI Search at query time. AI Search supports system prompt configuration in two steps:\n\n* **Query rewriting**: Reformulates the original user query to improve semantic retrieval. A system prompt can guide how the model interprets and rewrites the query.\n* **Generation**: Generates the final response from retrieved context. A system prompt can help define how the model should format, filter, or prioritize information when constructing the answer.\n\n## What is a system prompt?\n\nA system prompt is a special instruction sent to a large language model (LLM) that guides how it behaves during inference. The system prompt defines the model's role, context, or rules it should follow.\n\nSystem prompts are particularly useful for:\n\n* Enforcing specific response formats\n* Constraining behavior (for example, it only responds based on the provided content)\n* Applying domain-specific tone or terminology\n* Encouraging consistent, high-quality output\n\n## System prompt configuration\n\n### Default system prompt\n\nWhen configuring your AI Search instance, you can provide your own system prompts. If you do not provide a system prompt, AI Search will use the **default system prompt** provided by Cloudflare.\n\nYou can view the effective system prompt used for any AI Search's model call through AI Gateway logs, where model inputs and outputs are recorded.\n\nNote\n\nThe default system prompt can change and evolve over time to improve performance and quality.\n\n### Configure via API\n\nWhen you make a `/ai-search` request using the [Workers Binding](https://developers.cloudflare.com/ai-search/usage/workers-binding/) or [REST API](https://developers.cloudflare.com/ai-search/usage/rest-api/), you can set the system prompt programmatically.\n\nFor example:",
      "language": "unknown"
    },
    {
      "code": "### Configure via Dashboard\n\nThe system prompt for your AI Search can be set after it has been created:\n\n1. Go to **AI Search** in the Cloudflare dashboard. [Go to **AI Search (AutoRAG)**](https://dash.cloudflare.com/?to=/:account/ai/ai-search)\n2. Select an existing AI Search instance.\n3. Go to the **Settings** tab.\n4. Go to **Query rewrite** or **Generation**, and edit the **System prompt**.\n\n## Query rewriting system prompt\n\nIf query rewriting is enabled, you can provide a custom system prompt to control how the model rewrites user queries. In this step, the model receives:\n\n* The query rewrite system prompt\n* The original user query\n\nThe model outputs a rewritten query optimized for semantic retrieval.\n\n### Example",
      "language": "unknown"
    },
    {
      "code": "## Generation system prompt\n\nIf you are using the AI Search API endpoint, you can use the system prompt to influence how the LLM responds to the final user query using the retrieved results. At this step, the model receives:\n\n* The user's original query\n* Retrieved document chunks (with metadata)\n* The generation system prompt\n\nThe model uses these inputs to generate a context-aware response.\n\n### Example",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Bring your own generation model · Cloudflare AI Search docs\ndescription: When using AI Search, AI Search leverages a Workers AI model to\n  generate the response. If you want to use a model outside of Workers AI, you\n  can use AI Search for search while leveraging a model outside of Workers AI to\n  generate responses.\nlastUpdated: 2025-09-24T17:03:07.000Z\nchatbotDeprioritize: false\ntags: AI\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/how-to/bring-your-own-generation-model/\n  md: https://developers.cloudflare.com/ai-search/how-to/bring-your-own-generation-model/index.md\n---\n\nWhen using `AI Search`, AI Search leverages a Workers AI model to generate the response. If you want to use a model outside of Workers AI, you can use AI Search for `search` while leveraging a model outside of Workers AI to generate responses.\n\nHere is an example of how you can use an OpenAI model to generate your responses. This example uses [Workers Binding](https://developers.cloudflare.com/ai-search/usage/workers-binding/), but can be easily adapted to use the [REST API](https://developers.cloudflare.com/ai-search/usage/rest-api/) instead.\n\nNote\n\nAI Search now supports [bringing your own models natively](https://developers.cloudflare.com/ai-search/configuration/models/). You can attach provider keys through AI Gateway and select third-party models directly in your AI Search settings. The example below still works, but the recommended way is to configure your external model through AI Gateway.\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Create multitenancy · Cloudflare AI Search docs\ndescription: AI Search supports multitenancy by letting you segment content by\n  tenant, so each user, customer, or workspace can only access their own data.\n  This is typically done by organizing documents into per-tenant folders and\n  applying metadata filters at query time.\nlastUpdated: 2025-09-24T17:03:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/how-to/multitenancy/\n  md: https://developers.cloudflare.com/ai-search/how-to/multitenancy/index.md\n---\n\nAI Search supports multitenancy by letting you segment content by tenant, so each user, customer, or workspace can only access their own data. This is typically done by organizing documents into per-tenant folders and applying [metadata filters](https://developers.cloudflare.com/ai-search/configuration/metadata/) at query time.\n\n## 1. Organize Content by Tenant\n\nWhen uploading files to R2, structure your content by tenant using unique folder paths.\n\nExample folder structure:\n\nWhen indexing, AI Search will automatically store the folder path as metadata under the `folder` attribute. It is recommended to enforce folder separation during upload or indexing to prevent accidental data access across tenants.\n\n## 2. Search Using Folder Filters\n\nTo ensure a tenant only retrieves their own documents, apply a `folder` filter when performing a search.\n\nExample using [Workers Binding](https://developers.cloudflare.com/ai-search/usage/workers-binding/):",
      "language": "unknown"
    },
    {
      "code": "To filter across multiple folders, or to add date-based filtering, you can use a compound filter with an array of [comparison filters](https://developers.cloudflare.com/ai-search/configuration/metadata/#compound-filter).\n\n## Tip: Use \"Starts with\" filter\n\nWhile an `eq` filter targets files at the specific folder, you'll often want to retrieve all documents belonging to a tenant regardless if there are files in its subfolders. For example, all files in `customer-a/` with a structure like:\n\nTo achieve this [starts with](https://developers.cloudflare.com/ai-search/configuration/metadata/#starts-with-filter-for-folders) behavior, use a compound filter like:",
      "language": "unknown"
    },
    {
      "code": "This filter identifies paths starting with `customer-a/` by using:\n\n* The `and` condition to combine the effects of the `gt` and `lte` conditions.\n* The `gt` condition to include paths greater than the `/` ASCII character.\n* The `lte` condition to include paths less than and including the lower case `z` ASCII character.\n\nThis filter captures both files `profile.md` and `contract-1.pdf`.\n\n</page>\n\n<page>\n---\ntitle: NLWeb · Cloudflare AI Search docs\ndescription: Enable conversational search on your website with NLWeb and\n  Cloudflare AI Search. This template crawls your site, indexes the content, and\n  deploys NLWeb-standard endpoints to serve both people and AI agents.\nlastUpdated: 2025-09-24T17:03:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/how-to/nlweb/\n  md: https://developers.cloudflare.com/ai-search/how-to/nlweb/index.md\n---\n\nEnable conversational search on your website with NLWeb and Cloudflare AI Search. This template crawls your site, indexes the content, and deploys NLWeb-standard endpoints to serve both people and AI agents.\n\nNote\n\nThis is a public preview ideal for experimentation. If you're interested in running this in production workflows, please contact us at <nlweb@cloudflare.com>.\n\n## What is NLWeb\n\n[NLWeb](https://github.com/nlweb-ai/NLWeb) is an open project developed by Microsoft that defines a standard protocol for natural language queries on websites. Its goal is to make every website as accessible and interactive as a conversational AI app, so both people and AI agents can reliably query site content. It does this by exposing two key endpoints:\n\n* `/ask`: Conversational endpoint for user queries\n* `/mcp`: Structured Model Context Protocol (MCP) endpoint for AI agents\n\n## How to use it\n\nYou can deploy NLWeb on your website directly through the AI Search dashboard:\n\n1. Log in to your [Cloudflare dashboard](https://dash.cloudflare.com/).\n2. Go to **Compute & AI** > **AI Search**.\n3. Select **Create AI Search**, then choose the **NLWeb Website** option.\n4. Select your domain from your Cloudflare account.\n5. Click **Start indexing**.\n\nOnce complete, AI Search will crawl and index your site, then deploy an NLWeb Worker for you.\n\n## What this template includes\n\nChoosing the NLWeb Website option extends a normal AI Search by tailoring it for content‑heavy websites and giving you everything that is required to adopt NLWeb as the standard for conversational search on your site. Specifically, the template provides:\n\n* **Website as a data source:** Uses [Website](https://developers.cloudflare.com/ai-search/configuration/data-source/website/) as data source option to crawl and ingest pages with the Rendered Sites option.\n* **Defaults for content-heavy websites:** Applies tuned embedding and retrieval configurations ideal for publishing and content‑rich websites.\n* **NLWeb Worker deployment:** Automatically spins up a Cloudflare Worker from the [NLWeb Worker template](https://github.com/cloudflare/templates).\n\n## What the Worker includes\n\nYour deployed Worker provides two endpoints:\n\n* `/ask` — NLWeb’s standard conversational endpoint\n\n  * Powers the conversational UI at the root (`/`)\n  * Powers the embeddable preview widget (`/snippet.html`)\n\n* `/mcp` — NLWeb’s MCP server endpoint for trusted AI agents\n\nThese endpoints give both people and agents structured access to your content.\n\n## Using It on Your Website\n\nTo integrate NLWeb search directly into your site you can:\n\n1. Find your deployed Worker in the [Cloudflare dashboard](https://dash.cloudflare.com/):\n\n* Go to **Compute & AI** > **AI Search**.\n* Select **Connect**, then go to the **NLWeb** tab.\n* Select **Go to Worker**.\n\n1. Add a [custom domain](https://developers.cloudflare.com/workers/configuration/routing/custom-domains/) to your Worker (for example, ask.example.com)\n2. Use the `/ask` endpoint on your custom domain to power the search (for example, ask.example.com/ask)\n\nYou can also use the embeddable snippet to add a search UI directly into your website. For example:",
      "language": "unknown"
    },
    {
      "code": "This lets you serve conversational AI search directly from your own domain, with control over how people and agents access your content.\n\n## Modifying or updating the Worker\n\nYou may want to customize your Worker, for example, to adjust the UI for the embeddable snippet. In those cases, we recommend calling the `/ask` endpoint for queries and building your own UI on top of it, however, you may also choose to modify the Worker's code for the embeddable UI.\n\nIf the NLWeb standard is updated, you can update your Worker to stay compatible and recieve the latest updates.\n\nThe simplest way to apply changes or updates is to redeploy the Worker template:\n\n[![Deploy to Cloudflare](https://deploy.workers.cloudflare.com/button)](https://deploy.workers.cloudflare.com/?url=https://github.com/cloudflare/templates/tree/main/nlweb-template)\n\nTo do so:\n\n1. Select the **Deploy to Cloudflare** button from above to deploy the Worker template to your Cloudflare account.\n2. Enter the name of your AI Search in the `RAG_ID` environment variable field.\n3. Click **Deploy**.\n4. Select the **GitHub/GitLab** icon on the Workers Dashboard.\n5. Clone the repository that is created for your Worker.\n6. Make your modifications, then commit and push changes to the repository to update your Worker.\n\nNow you can use this Worker as the new NLWeb endpoint for your website.\n\n</page>\n\n<page>\n---\ntitle: Create a simple search engine · Cloudflare AI Search docs\ndescription: By using the search method, you can implement a simple but fast\n  search engine. This example uses Workers Binding, but can be easily adapted to\n  use the REST API instead.\nlastUpdated: 2025-09-24T17:03:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/how-to/simple-search-engine/\n  md: https://developers.cloudflare.com/ai-search/how-to/simple-search-engine/index.md\n---\n\nBy using the `search` method, you can implement a simple but fast search engine. This example uses [Workers Binding](https://developers.cloudflare.com/ai-search/usage/workers-binding/), but can be easily adapted to use the [REST API](https://developers.cloudflare.com/ai-search/usage/rest-api/) instead.\n\nTo replicate this example remember to:\n\n* Disable `rewrite_query`, as you want to match the original user query\n* Configure your AI Search to have small chunk sizes, usually 256 tokens is enough\n\n- JavaScript",
      "language": "unknown"
    },
    {
      "code": "- TypeScript",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Limits & pricing · Cloudflare AI Search docs\ndescription: \"During the open beta, AI Search is free to enable. When you create\n  an AI Search instance, it provisions and runs on top of Cloudflare services in\n  your account. These resources are billed as part of your Cloudflare usage, and\n  includes:\"\nlastUpdated: 2025-11-06T19:11:47.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/platform/limits-pricing/\n  md: https://developers.cloudflare.com/ai-search/platform/limits-pricing/index.md\n---\n\n## Pricing\n\nDuring the open beta, AI Search is **free to enable**. When you create an AI Search instance, it provisions and runs on top of Cloudflare services in your account. These resources are **billed as part of your Cloudflare usage**, and includes:\n\n| Service & Pricing | Description |\n| - | - |\n| [**R2**](https://developers.cloudflare.com/r2/pricing/) | Stores your source data |\n| [**Vectorize**](https://developers.cloudflare.com/vectorize/platform/pricing/) | Stores vector embeddings and powers semantic search |\n| [**Workers AI**](https://developers.cloudflare.com/workers-ai/platform/pricing/) | Handles image-to-Markdown conversion, embedding, query rewriting, and response generation |\n| [**AI Gateway**](https://developers.cloudflare.com/ai-gateway/reference/pricing/) | Monitors and controls model usage |\n| [**Browser Rendering**](https://developers.cloudflare.com/browser-rendering/pricing/) | Loads dynamic JavaScript content during [website](https://developers.cloudflare.com/ai-search/configuration/data-source/website/) crawling with the Render option |\n\nFor more information about how each resource is used within AI Search, reference [How AI Search works](https://developers.cloudflare.com/ai-search/concepts/how-ai-search-works/).\n\n## Limits\n\nThe following limits currently apply to AI Search during the open beta:\n\nNeed a higher limit?\n\nTo request an adjustment to a limit, complete the [Limit Increase Request Form](https://forms.gle/wnizxrEUW33Y15CT8). If the limit can be increased, Cloudflare will contact you with next steps.\n\n| Limit | Value |\n| - | - |\n| Max AI Search instances per account | 10 |\n| Max files per AI Search | 100,000 |\n| Max file size | 4 MB |\n\nThese limits are subject to change as AI Search evolves beyond open beta.\n\n</page>\n\n<page>\n---\ntitle: Release note · Cloudflare AI Search docs\ndescription: Review recent changes to Cloudflare AI Search.\nlastUpdated: 2025-09-24T17:03:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/platform/release-note/\n  md: https://developers.cloudflare.com/ai-search/platform/release-note/index.md\n---\n\nThis release notes section covers regular updates and minor fixes. For major feature releases or significant updates, see the [changelog](https://developers.cloudflare.com/changelog).\n\n## 2025-09-25\n\n**AI Search (formerly AutoRAG) now supports more models**\n\nConnect your provider keys through AI Gateway to use models like from OpenAI and Anthropic for both embeddings and inference. API updates to align with the new name are coming soon, with existing APIs still supported.\n\n## 2025-09-23\n\n**Support document file types in AutoRAG**\n\nOur [conversion utility](https://developers.cloudflare.com/workers-ai/features/markdown-conversion/) can now convert `.docx` and `.odt` files to Markdown, making these files available to index inside your AutoRAG instance.\n\n## 2025-08-20\n\n**Increased maximum query results to 50**\n\nThe maximum number of results returned from a query has been increased from **20** to **50**. This allows you to surface more relevant matches in a single request.\n\n## 2025-07-16\n\n**Deleted files now removed from index on next sync**\n\nWhen a file is deleted from your R2 bucket, its corresponding chunks are now automatically removed from the Vectorize index linked to your AI Search instance during the next sync.\n\n## 2025-07-08\n\n**Reduced cooldown between syncs**\n\nThe cooldown period between sync jobs has been reduced to **3 minutes**, allowing you to trigger syncs more frequently when updating your data. If a sync is requested during the cooldown window, the dashboard and API now return clear response indicating that the sync cannot proceed due to the cooldown.\n\n## 2025-06-16\n\n**Rich format file size limit increased to 4 MB**\n\nYou can now index rich format files (e.g., PDF) up to 4 MB in size, up from the previous 1 MB limit.\n\n## 2025-06-12\n\n**Index processing status displayed on dashboard**\n\nThe dashboard now includes a new “Processing” step for the indexing pipeline that displays the files currently being processed.\n\n## 2025-06-12\n\n**Sync AI Search REST API published**\n\nYou can now trigger a sync job for an AI Search using the [Sync REST API](https://developers.cloudflare.com/api/resources/ai-search/subresources/rags/methods/sync/). This scans your data source for changes and queues updated or previously errored files for indexing.\n\n## 2025-06-10\n\n**Files modified in the data source will now be updated**\n\nFiles modified in your source R2 bucket will now be updated in the AI Search index during the next sync. For example, if you upload a new version of an existing file, the changes will be reflected in the index after the subsequent sync job. Please note that deleted files are not yet removed from the index. We are actively working on this functionality.\n\n## 2025-05-31\n\n**Errored files will now be retried in next sync**\n\nFiles that failed to index will now be automatically retried in the next indexing job. For instance, if a file initially failed because it was oversized but was then corrected (e.g. replaced with a file of the same name/key within the size limit), it will be re-attempted during the next scheduled sync.\n\n## 2025-05-31\n\n**Fixed character cutoff in recursive chunking**\n\nResolved an issue where certain characters (e.g. '#') were being cut off during the recursive chunking and embedding process. This fix ensures complete character processing in the indexing process.\n\n## 2025-05-25\n\n**EU jurisdiction R2 buckets now supported**\n\nAI Search now supports R2 buckets configured with European Union (EU) jurisdiction restrictions. Previously, files in EU-restricted R2 buckets would not index when linked. This issue has been resolved, and all EU-restricted R2 buckets should now function as expected.\n\n## 2025-04-23\n\n**Response streaming in AI Search binding added**\n\nAI Search now supports response streaming in the `AI Search` method of the [Workers binding](https://developers.cloudflare.com/ai-search/usage/workers-binding/), allowing you to stream results as they’re retrieved by setting `stream: true`.\n\n## 2025-04-07\n\n**AI Search is now in open beta!**\n\nAI Search allows developers to create fully-managed retrieval-augmented generation (RAG) pipelines powered by Cloudflare allowing developers to integrate context-aware AI into their applications without managing infrastructure. Get started today on the [Cloudflare Dashboard](https://dash.cloudflare.com/?to=/:account/ai/autorag).\n\n</page>\n\n<page>\n---\ntitle: Build a RAG from your website · Cloudflare AI Search docs\ndescription: AI Search is designed to work out of the box with data in R2\n  buckets. But what if your content lives on a website or needs to be rendered\n  dynamically?\nlastUpdated: 2025-09-25T12:33:53.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/tutorial/brower-rendering-autorag-tutorial/\n  md: https://developers.cloudflare.com/ai-search/tutorial/brower-rendering-autorag-tutorial/index.md\n---\n\nAI Search is designed to work out of the box with data in R2 buckets. But what if your content lives on a website or needs to be rendered dynamically?\n\nIn this tutorial, we’ll walk through how to:\n\n1. Render your website using Cloudflare's Browser Rendering API\n2. Store the rendered HTML in R2\n3. Connect it to AI Search for querying\n\nNote\n\nAI Search now lets you use your [website](https://developers.cloudflare.com/ai-search/configuration/data-source/website/) as a data source. When enabled, AI Search will automatically crawl and parse your site content for you.\n\n## Step 1. Create a Worker to fetch webpages and upload into R2\n\nWe’ll create a Cloudflare Worker that uses Puppeteer to visit your URL, render it, and store the full HTML in your R2 bucket. If you already have an R2 bucket with content you’d like to build a RAG for then you can skip this step.\n\n1. Create a new Worker project named `browser-r2-worker` by running:",
      "language": "unknown"
    },
    {
      "code": "For setup, select the following options:\n\n* For *What would you like to start with*?, choose `Hello World example`.\n* For *Which template would you like to use*?, choose `Worker only`.\n* For *Which language do you want to use*?, choose `TypeScript`.\n* For *Do you want to use git for version control*?, choose `Yes`.\n* For *Do you want to deploy your application*?, choose `No` (we will be making some changes before deploying).\n\n1. Install `@cloudflare/puppeteer`, which allows you to control the Browser Rendering instance:",
      "language": "unknown"
    },
    {
      "code": "1. Create a new R2 bucket named `html-bucket` by running:",
      "language": "unknown"
    },
    {
      "code": "1. Add the following configurations to your Wrangler configuration file so your Worker can use browser rendering and your new R2 bucket:",
      "language": "unknown"
    },
    {
      "code": "1. Replace the contents of `src/index.ts` with the following skeleton script:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "1. Once the code is ready, you can deploy it to your Cloudflare account by running:",
      "language": "unknown"
    },
    {
      "code": "1. To test your Worker, you can use the following cURL request to fetch the HTML file of a page. In this example we are fetching this page to upload into the `html-bucket` bucket:",
      "language": "unknown"
    },
    {
      "code": "## Step 2. Create your AI Search and monitor the indexing\n\nNow that you have created your R2 bucket and filled it with your content that you’d like to query from, you are ready to create an AI Search instance:\n\n1. In your [Cloudflare Dashboard](https://dash.cloudflare.com/?to=/:account/ai/autorag), navigate to AI > AI Search\n\n2. Select Create AI Search and complete the setup process:\n\n   1. Select the **R2 bucket** which contains your knowledge base, in this case, select the `html-bucket`.\n   2. Select an **embedding model** used to convert your data to vector representation. It is recommended to use the Default.\n   3. Select an **LLM** to use to generate your responses. It is recommended to use the Default.\n   4. Select or create an **AI Gateway** to monitor and control your model usage.\n   5. **Name** your AI Search as `my-rag`\n   6. Select or create a **Service API** token to grant AI Search access to create and access resources in your account.\n\n3. Select Create to spin up your AI Search.\n\nOnce you’ve created your AI Search, it will automatically create a Vectorize database in your account and begin indexing the data.\n\n## Step 3. Test and add to your application\n\nOnce AI Search finishes indexing your content, you’re ready to start asking it questions. You can open up your AI Search instance, navigate to the Playground tab, and ask a question based on your uploaded content, like “What is AI Search?”.\n\nOnce you’re happy with the results in the Playground, you can integrate AI Search directly into the application that you are building. If you are using a Worker to build your [RAG application](https://developers.cloudflare.com/ai-search/), then you can use the AI binding to directly call your AI Search:",
      "language": "unknown"
    },
    {
      "code": "Then, query your AI Search instance from your Worker code by calling the `aiSearch()` method.",
      "language": "unknown"
    },
    {
      "code": "For more information on how to add AI Search into your application, go to your AI Search then navigate to Use AI Search for more instructions.\n\n</page>\n\n<page>\n---\ntitle: REST API · Cloudflare AI Search docs\ndescription: This guide will instruct you through how to use the AI Search REST\n  API to make a query to your AI Search.\nlastUpdated: 2025-11-19T23:05:28.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/usage/rest-api/\n  md: https://developers.cloudflare.com/ai-search/usage/rest-api/index.md\n---\n\nThis guide will instruct you through how to use the AI Search REST API to make a query to your AI Search.\n\nAI Search is the new name for AutoRAG\n\nAPI endpoints may still reference `autorag` for the time being. Functionality remains the same, and support for the new naming will be introduced gradually.\n\n## Prerequisite: Get AI Search API token\n\nYou need an API token with the `AI Search - Read` and `AI Search Edit` permissions to use the REST API. To create a new token:\n\n1. In the Cloudflare dashboard, go to the **AI Search** page.\n\n[Go to **AI Search (AutoRAG)**](https://dash.cloudflare.com/?to=/:account/ai/ai-search)\n\n1. Select your AI Search.\n2. Select **Use AI Search** and then select **API**.\n3. Select **Create an API Token**.\n4. Review the prefilled information then select **Create API Token**.\n5. Select **Copy API Token** and save that value for future use.\n\n## AI Search\n\nThis REST API searches for relevant results from your data source and generates a response using the model and the retrieved relevant context:",
      "language": "unknown"
    },
    {
      "code": "Note\n\nYou can get your `ACCOUNT_ID` by navigating to [Workers & Pages on the dashboard](https://developers.cloudflare.com/fundamentals/account/find-account-and-zone-ids/#find-account-id-workers-and-pages).\n\n### Parameters\n\n`query` string required\n\nThe input query.\n\n`model` string optional\n\nThe text-generation model that is used to generate the response for the query. For a list of valid options, check the AI Search Generation model Settings. Defaults to the generation model selected in the AI Search Settings.\n\n`system_prompt` string optional\n\nThe system prompt for generating the answer.\n\n`rewrite_query` boolean optional\n\nRewrites the original query into a search optimized query to improve retrieval accuracy. Defaults to `false`.\n\n`max_num_results` number optional\n\nThe maximum number of results that can be returned from the Vectorize database. Defaults to `10`. Must be between `1` and `50`.\n\n`ranking_options` object optional\n\nConfigurations for customizing result ranking. Defaults to `{}`.\n\n* `score_threshold` number optional\n  * The minimum match score required for a result to be considered a match. Defaults to `0`. Must be between `0` and `1`.\n\n`reranking` object optional\n\nConfigurations for customizing reranking. Defaults to `{}`.\n\n* `enabled` boolean optional\n\n  * Enables or disables reranking, which reorders retrieved results based on semantic relevance using a reranking model. Defaults to `false`.\n\n* `model` string optional\n\n  * The reranking model to use when reranking is enabled.\n\n`stream` boolean optional\n\nReturns a stream of results as they are available. Defaults to `false`.\n\n`filters` object optional\n\nNarrow down search results based on metadata, like folder and date, so only relevant content is retrieved. For more details, refer to [Metadata filtering](https://developers.cloudflare.com/ai-search/configuration/metadata/).\n\n### Response\n\nThis is the response structure without `stream` enabled.",
      "language": "unknown"
    },
    {
      "code": "## Search\n\nThis REST API searches for results from your data source and returns the relevant results:",
      "language": "unknown"
    },
    {
      "code": "Note\n\nYou can get your `ACCOUNT_ID` by navigating to Workers & Pages on the dashboard, and copying the Account ID under Account Details.\n\n### Parameters\n\n`query` string required\n\nThe input query.\n\n`rewrite_query` boolean optional\n\nRewrites the original query into a search optimized query to improve retrieval accuracy. Defaults to `false`.\n\n`max_num_results` number optional\n\nThe maximum number of results that can be returned from the Vectorize database. Defaults to `10`. Must be between `1` and `50`.\n\n`ranking_options` object optional\n\nConfigurations for customizing result ranking. Defaults to `{}`.\n\n* `score_threshold` number optional\n  * The minimum match score required for a result to be considered a match. Defaults to `0`. Must be between `0` and `1`.\n\n`reranking` object optional\n\nConfigurations for customizing reranking. Defaults to `{}`.\n\n* `enabled` boolean optional\n\n  * Enables or disables reranking, which reorders retrieved results based on semantic relevance using a reranking model. Defaults to `false`.\n\n* `model` string optional\n\n  * The reranking model to use when reranking is enabled.\n\n`filters` object optional\n\nNarrow down search results based on metadata, like folder and date, so only relevant content is retrieved. For more details, refer to [Metadata filtering](https://developers.cloudflare.com/ai-search/configuration/metadata).\n\n### Response",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Workers Binding · Cloudflare AI Search docs\ndescription: Cloudflare’s serverless platform allows you to run code at the edge\n  to build full-stack applications with Workers. A binding enables your Worker\n  or Pages Function to interact with resources on the Cloudflare Developer\n  Platform.\nlastUpdated: 2025-10-28T15:46:27.000Z\nchatbotDeprioritize: false\ntags: Bindings\nsource_url:\n  html: https://developers.cloudflare.com/ai-search/usage/workers-binding/\n  md: https://developers.cloudflare.com/ai-search/usage/workers-binding/index.md\n---\n\nCloudflare’s serverless platform allows you to run code at the edge to build full-stack applications with [Workers](https://developers.cloudflare.com/workers/). A [binding](https://developers.cloudflare.com/workers/runtime-apis/bindings/) enables your Worker or Pages Function to interact with resources on the Cloudflare Developer Platform.\n\nTo use your AI Search with Workers or Pages, create an AI binding either in the Cloudflare dashboard (refer to [AI bindings](https://developers.cloudflare.com/pages/functions/bindings/#workers-ai) for instructions), or you can update your [Wrangler file](https://developers.cloudflare.com/workers/wrangler/configuration/). To bind AI Search to your Worker, add the following to your Wrangler file:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "AI Search is the new name for AutoRAG\n\nAPI endpoints may still reference `autorag` for the time being. Functionality remains the same, and support for the new naming will be introduced gradually.\n\n## `aiSearch()`\n\nThis method searches for relevant results from your data source and generates a response using your default model and the retrieved context, for an AI Search named `my-autorag`:",
      "language": "unknown"
    },
    {
      "code": "### Parameters\n\n`query` string required\n\nThe input query.\n\n`model` string optional\n\nThe text-generation model that is used to generate the response for the query. For a list of valid options, check the AI Search Generation model Settings. Defaults to the generation model selected in the AI Search Settings.\n\n`system_prompt` string optional\n\nThe system prompt for generating the answer.\n\n`rewrite_query` boolean optional\n\nRewrites the original query into a search optimized query to improve retrieval accuracy. Defaults to `false`.\n\n`max_num_results` number optional\n\nThe maximum number of results that can be returned from the Vectorize database. Defaults to `10`. Must be between `1` and `50`.\n\n`ranking_options` object optional\n\nConfigurations for customizing result ranking. Defaults to `{}`.\n\n* `score_threshold` number optional\n  * The minimum match score required for a result to be considered a match. Defaults to `0`. Must be between `0` and `1`.\n\n`reranking` object optional\n\nConfigurations for customizing reranking. Defaults to `{}`.\n\n* `enabled` boolean optional\n\n  * Enables or disables reranking, which reorders retrieved results based on semantic relevance using a reranking model. Defaults to `false`.\n\n* `model` string optional\n\n  * The reranking model to use when reranking is enabled.\n\n`stream` boolean optional\n\nReturns a stream of results as they are available. Defaults to `false`.\n\n`filters` object optional\n\nNarrow down search results based on metadata, like folder and date, so only relevant content is retrieved. For more details, refer to [Metadata filtering](https://developers.cloudflare.com/ai-search/configuration/metadata/).\n\n### Response\n\nThis is the response structure without `stream` enabled.",
      "language": "unknown"
    },
    {
      "code": "## `search()`\n\nThis method searches for results from your corpus and returns the relevant results, for the AI Search instance named `my-autorag`:",
      "language": "unknown"
    },
    {
      "code": "### Parameters\n\n`query` string required\n\nThe input query.\n\n`rewrite_query` boolean optional\n\nRewrites the original query into a search optimized query to improve retrieval accuracy. Defaults to `false`.\n\n`max_num_results` number optional\n\nThe maximum number of results that can be returned from the Vectorize database. Defaults to `10`. Must be between `1` and `50`.\n\n`ranking_options` object optional\n\nConfigurations for customizing result ranking. Defaults to `{}`.\n\n* `score_threshold` number optional\n  * The minimum match score required for a result to be considered a match. Defaults to `0`. Must be between `0` and `1`.\n\n`reranking` object optional\n\nConfigurations for customizing reranking. Defaults to `{}`.\n\n* `enabled` boolean optional\n\n  * Enables or disables reranking, which reorders retrieved results based on semantic relevance using a reranking model. Defaults to `false`.\n\n* `model` string optional\n\n  * The reranking model to use when reranking is enabled.\n\n`filters` object optional\n\nNarrow down search results based on metadata, like folder and date, so only relevant content is retrieved. For more details, refer to [Metadata filtering](https://developers.cloudflare.com/ai-search/configuration/metadata).\n\n### Response",
      "language": "unknown"
    },
    {
      "code": "## Local development\n\nLocal development is supported by proxying requests to your deployed AI Search instance. When running in local mode, your application forwards queries to the configured remote AI Search instance and returns the generated responses as if they were served locally.\n\n</page>\n\n<page>\n---\ntitle: Account analytics (beta) · Cloudflare Analytics docs\ndescription: Cloudflare account analytics lets you access a wide range of\n  aggregated metrics from all the sites under a specific Cloudflare account.\nlastUpdated: 2025-09-04T10:57:42.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/account-and-zone-analytics/account-analytics/\n  md: https://developers.cloudflare.com/analytics/account-and-zone-analytics/account-analytics/index.md\n---\n\nCloudflare account analytics lets you access a wide range of aggregated metrics from all the sites under a specific Cloudflare account.\n\nNote\n\nFor general information about all of Cloudflare's analytics offerings, refer to [About Cloudflare Analytics](https://developers.cloudflare.com/analytics/faq/about-analytics/).\n\n***\n\n## View your account analytics\n\nTo view metrics for your site, in the Cloudflare dashboard, go to the **Account Analytics** page.\n\n[Go to **Account analytics**](https://dash.cloudflare.com/?to=/:account/analytics)\n\nOnce it loads, the Account Analytics app displays a collection of categorized charts with aggregated metrics for your account. To understand the various metrics available, refer to *Review your account metrics* below.\n\n***\n\n## Review your account metrics\n\nThis section outlines the aggregated metrics under each category. Before reviewing your metrics, let's define a couple of concepts used in some panels:\n\n* *Rate* -  Reflects the ratio between the amount for a specific data category and the total.\n* *Bandwidth* - Refers to the number of bytes sent from the Cloudflare edge network to the requesting client.\n\nAlso, note that:\n\n* To filter metrics for a specific time period, use the dropdown in the top right.\n* Most metrics are grouped into panels representing different aspects of the underlying data.\n\n### Summary of metrics\n\nBelow is a brief description of the major elements comprising the metrics available.\n\n#### HTTP Traffic\n\nThese charts aggregate data for HTTP traffic, and include:\n\n![Chart showing last week's data for HTTP traffic](https://developers.cloudflare.com/_astro/hc-dash-account-analytics-map.CcPRTQU-_ZfK8qO.webp)\n\n* Spark lines for *Requests*, *Bandwidth*, *Page views*, and *Visitors* (*Unique IPs)*\n* An interactive map that breaks down the number of requests by country\n* A table combining numerical and spark line data, sorted by total number of requests per country\n\n#### Security\n\n![Panel displaying lines highlighting encryption metrics: requests, requests rate, bandwidth, and bandwidth rate](https://developers.cloudflare.com/_astro/hc-dash-account-analytics_security_panel.5rFJ7hHV_1uWeuE.webp)\n\nThis panel features spark lines highlighting various encryption metrics, including: *requests*, *requests rate*, *bandwidth*, and *bandwidth rate*.  These also include a comparative percentage change based on the previous period.\n\n#### Cache\n\n![Panel displaying lines for caching metrics: requests, requests rate, bandwidth, and bandwidth rate](https://developers.cloudflare.com/_astro/hc-dash-account-analytics_cache_card.BOCedSTx_g6Jww.webp)\n\nThis panel features spark lines for various caching metrics, including: *requests*, *requests rate*, *bandwidth*, and *bandwidth rate*.  These also include a comparative percentage change based on the previous equivalent period.  For example, if you selected *Last week* as your time period, the previous period refers to the *week* before.\n\n#### Errors\n\n![Panel displaying lines for 4xx and 5xx error rates](https://developers.cloudflare.com/_astro/hc-account-analytics_errors_card.D2i2BrS9_Z26qzOn.webp)\n\nThis panel displays spark lines for 4xx and 5xx error rates, respectively. Learn more about [HTTP Status Codes](https://developers.cloudflare.com/support/troubleshooting/http-status-codes/). \n\n#### Network\n\n![Statistics showing the percentage of requests that use a specific version of HTTP](https://developers.cloudflare.com/_astro/hc-dash-account-analytics_network_card.Fso_4DUE_Z1tQwHn.webp)\n\n#### Client HTTP Version Used\n\nThese statistics show the percentage of requests that use a specific version of HTTP.\n\n#### Traffic Served Over SSL\n\nThese statistics show the percentage of traffic that is encrypted using a specific version of SSL or TLS.\n\n#### Content Type Breakdown\n\nThese statistics show the number of requests based on the resource content type.\n\n</page>\n\n<page>\n---\ntitle: Cloudflare analytics with Workers · Cloudflare Analytics docs\ndescription: Learn how Cloudflare analytics tracks requests made by Cloudflare Workers.\nlastUpdated: 2025-05-15T13:55:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/account-and-zone-analytics/analytics-with-workers/\n  md: https://developers.cloudflare.com/analytics/account-and-zone-analytics/analytics-with-workers/index.md\n---\n\nLearn how Cloudflare analytics tracks requests made by [Cloudflare Workers](https://developers.cloudflare.com/workers/).\n\n## What is a subrequest\n\nWith a no-op Worker (a Worker that simply proxies traffic by passing on the original client request to the origin and proxying the response) running on a particular route, the request to the origin is counted as a 'subrequest', separate from initial client to edge request. Thus, unless the Worker responds with a static response and never hits an origin, the eyeball → edge request, and edge → origin request will each be counted separately towards the request or bandwidth count in Analytics. Subrequests are not included in the **Requests** or **Bandwidth** graphs of the Cloudflare **Analytics** app.\n\n***\n\n## Zone analytics\n\nIn the dashboard, the numbers in zone analytics reflect visitor traffic. That is, the number of requests shown in zone analytics (under the Analytics tabs in the dashboard) is the number of requests that were served to the client.\n\nSimilarly, the bandwidth is counted based on the bandwidth that is sent to the client, and status codes reflect the status codes that were served back to the client (so if a subrequest received a 500, but you respond with a 200, a 200 will be shown in the status codes breakdown).\n\n***\n\n## Worker analytics\n\nFor a breakdown of subrequest traffic (origin facing traffic), you may go to the Cloudflare **Analytics** app and select the **Workers** tab. Under the **Workers** tab, below the Service Workers panel, are a **Subrequests** breakdown by count, **Bandwidth** and **Status Codes**. This will help you spot and debug errors at your origin (such as spikes in 500s), and identify your cache-hit ratio to help you understand traffic going to your origin.\n\n***\n\n## FAQ\n\n**Why do I not have any analytics for Workers?**\n\n* If you are not currently using Workers (do not have Workers deployed on any routes or filters), we will not have any information to show you.\n* If your Worker sends a static response back to the client without ever calling fetch() to an origin, you are not making any subrequests, thus, all traffic will be shown in zone Analytics\n\n**Will this impact billing?** \n\nNo, [billing for Workers](https://developers.cloudflare.com/workers/platform/pricing/) is based on requests that go through a Worker. \n\n**Why am I seeing such a high cache hit ratio?**\n\nRequests served by a Worker always show as cached. For an accurate cache hit ratio on subrequests, refer to the **Subrequests** graph in the **Analytics** app under the **Workers** analytics tab.\n\n</page>\n\n<page>\n---\ntitle: Status codes · Cloudflare Analytics docs\ndescription: Status Codes metrics in the Cloudflare dashboard Analytics app\n  provide customers with a deeper insight into the distribution of errors that\n  are occurring on their website per data center. A data center facility is\n  where Cloudflare runs its servers that make up our edge network (current\n  locations).\nlastUpdated: 2025-05-15T13:55:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/account-and-zone-analytics/status-codes/\n  md: https://developers.cloudflare.com/analytics/account-and-zone-analytics/status-codes/index.md\n---\n\nNote\n\nStatus Codes analytics by data center is exclusive to the [enterprise level of service](https://www.cloudflare.com/plans/enterprise/contact/).\n\nStatus Codes metrics in the Cloudflare dashboard **Analytics** app provide customers with a deeper insight into the distribution of errors that are occurring on their website per data center. A data center facility is where Cloudflare runs its servers that make up our edge network ([current locations](https://www.cloudflare.com/network/)).\n\nHTTP status codes that appear in a response passing through our edge are displayed in analytics.\n\nThe `Origin Status Code` can help you investigate issues on your origin. If your origin returns a `5xx` error, Cloudflare's edge will forward this error to the end user. Comparing the `Edge Status Code` and `Origin Status Code` can help determine whether the issue is occurring on your origin or on the Cloudflare edge.\n\nErrors that originate from our edge servers (blank `502`, `503`, or `504` error page with just `Cloudflare`) are not reported as part of the error analytics.\n\nYou can filter out specific error(s) by selecting one or more in the legend. You can also exclude a particular error and it will no longer display as part of the graph.\n\nNote\n\nUsers may also see `100x` errors which are not reported. These will be displayed as either `403` or `409` (edge) errors.\n\n![Error analytics by Cloudflare data center](https://developers.cloudflare.com/_astro/status-codes.BbTZPg-P_Z2aCyaH.webp)\n\n***\n\n## Common edge status codes\n\n* `400` - Bad Request intercepted at the Cloudflare Edge (for example, missing or bad HTTP header)\n* `403` - Security functionality (for example, Web Application Firewall, Browser Integrity Check, [Cloudflare challenges](https://developers.cloudflare.com/cloudflare-challenges/), and most 1xxx error codes)\n* `409` - DNS errors typically in the form of 1000 or 1001 error code\n* `413` - File size upload exceeded the maximum size allowed (configured in the dashboard under **Network** > **Maximum Upload Size**.)\n* `444` - Used by Nginx to indicate that the server has returned no information to the client, and closed the connection. This error code is internal to Nginx and is **not** returned to the client.\n* `499` - Used by Nginx to indicate when a connection has been closed by the client while the server is still processing its request, making the server unable to send a status code back.\n\nFor more information, refer to [4xx Client Error](https://developers.cloudflare.com/support/troubleshooting/http-status-codes/4xx-client-error/).\n\n***\n\n## Common origin status codes\n\n* `400` - Origin rejected the request due to bad, or unsupported syntax sent by the application.\n* `404` - Only if the origin triggered a 404 response for a request.\n* `4xx`\n* `50x`\n\nFor more information, refer to [4xx Client Error](https://developers.cloudflare.com/support/troubleshooting/http-status-codes/4xx-client-error/) and [Troubleshooting Cloudflare 5XX errors](https://developers.cloudflare.com/support/troubleshooting/http-status-codes/cloudflare-5xx-errors/).\n\n***\n\n## 52x errors\n\n* `520` - This is essentially a \"catch-all\" response for when the origin server returns something unexpected, or something that is not tolerated/cannot be interpreted by our edge (that is, protocol violation or empty response).\n* `522` - Our edge could not establish a TCP connection to the origin server.\n* `523` - Origin server is unreachable (for example, the origin IP changed but DNS was not updated, or due to network issues between our edge and the origin).\n* `524` - Our edge established a TCP connection, but the origin did not reply with a HTTP response before the connection timed out.\n* `525` - This error indicates that the SSL handshake between Cloudflare and the origin web server failed, either due to a network issue or a certificate issue at the origin.\n* `526` - The certificate configured at the origin is not valid.\n\nFor more information, refer to [Troubleshooting Cloudflare 5XX errors](https://developers.cloudflare.com/support/troubleshooting/http-status-codes/cloudflare-5xx-errors/).\n\n</page>\n\n<page>\n---\ntitle: Threat types · Cloudflare Analytics docs\ndescription: \"Cloudflare classifies the threats that it blocks or challenges. To\n  help you understand more about your site’s traffic, the 'Type of Threats\n  Mitigated' metric on the analytics page measures threats blocked or challenged\n  by the following categories:\"\nlastUpdated: 2025-05-15T14:14:09.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/account-and-zone-analytics/threat-types/\n  md: https://developers.cloudflare.com/analytics/account-and-zone-analytics/threat-types/index.md\n---\n\nCloudflare classifies the threats that it blocks or challenges. To help you understand more about your site’s traffic, the 'Type of Threats Mitigated' metric on the analytics page measures threats blocked or challenged by the following categories:\n\n## Bad browser\n\nThe source of the request was not legitimate or the request itself was malicious. Users would receive a [1010 error page](https://developers.cloudflare.com/support/troubleshooting/http-status-codes/cloudflare-1xxx-errors/error-1010/) in their browser.\n\nCloudflare's [Browser Integrity Check](https://developers.cloudflare.com/waf/tools/browser-integrity-check/) looks for common HTTP headers abused most commonly by spammers and denies them access to your page. It will also challenge visitors that do not have a user agent or a non standard user agent (also commonly used by bots, crawlers, or visitors).\n\n## Blocked hotlink\n\n[Hotlink Protection](https://developers.cloudflare.com/waf/tools/scrape-shield/hotlink-protection/) ensures that other sites cannot use your bandwidth by building pages that link to images hosted on your origin server. This feature can be turned on and off by Cloudflare's customers.\n\n## Human challenged\n\nVisitors were presented with an interactive challenge page and failed to pass.\n\n*Note: An interactive challenge page is a difficult to read word or set of numbers that only a human can translate. If entered incorrectly or not answered in a timely fashion, the request is blocked.*\n\n## Browser challenge\n\nA bot gave an invalid answer to the JavaScript challenge (in most cases this will not happen, bots typically do not respond to the challenge at all, so \"failed\" JavaScript challenges would not get logged).\n\n*Note: During a JavaScript challenge you will be shown an interstitial page for about five seconds while Cloudflare performs a series of mathematical challenges to make sure it is a legitimate human visitor.*\n\n## Bad IP\n\nA request that came from an IP address that is not trusted by Cloudflare based on the threat score.\n\nPreviously, the threat score was a score from `0` (zero risk) to `100` (high risk) classifying the IP reputation of a visitor. Currently, the threat score is always `0` (zero).\n\n## Country block\n\nRequests from countries that were blocked based on the [user configuration](https://developers.cloudflare.com/waf/tools/ip-access-rules/) set in the WAF.\n\n## IP block (user)\n\nRequests from specific IP addresses that were blocked based on the [user configuration](https://developers.cloudflare.com/waf/tools/ip-access-rules/) set in the WAF.\n\n## IP range block (/16)\n\nA /16 IP range that was blocked based on the [user configuration](https://developers.cloudflare.com/waf/tools/ip-access-rules/) set in the WAF.\n\n## IP range block (/24)\n\nA /24 IP range that was blocked based on the [user configuration](https://developers.cloudflare.com/waf/tools/ip-access-rules/) set in the WAF.\n\n## New Challenge (user)\n\n[Challenge](https://developers.cloudflare.com/cloudflare-challenges/) based on user configurations set for visitor's IP in either WAF managed rules or custom rules, configured in **Security** > **WAF**.\n\n## Challenge error\n\nRequests made by a bot that failed to pass the challenge.\n\n*Note: An interactive challenge page is a difficult to read word or set of numbers that only a human can translate. If entered incorrectly or not answered in a timely fashion, the request is blocked.*\n\n## Bot Request\n\nRequest that came from a bot.\n\n## Unclassified\n\nUnclassified threats comprises a number of automatic blocks that are not related to the Browser Integrity Challenge (Bad Browser). These threats usually relate to Hotlink Protection, and other actions that happen on Cloudflare's global network based on the composition of the request (and not its content).\n\nUnclassified means a number of conditions under which we group common threats related to Hotlink Protection as well as specific requests that are blocked at Cloudflare's global network before reaching your servers.\n\n</page>\n\n<page>\n---\ntitle: Total threats stopped · Cloudflare Analytics docs\ndescription: \"Total Threats Stopped measures the number of 'suspicious' and\n  'bad' requests that were aimed at your site. Requests receive these labels as\n  they enter Cloudflare's network:\"\nlastUpdated: 2025-05-14T16:28:40.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/account-and-zone-analytics/total-threats-stopped/\n  md: https://developers.cloudflare.com/analytics/account-and-zone-analytics/total-threats-stopped/index.md\n---\n\nTotal Threats Stopped measures the number of 'suspicious' and 'bad' requests that were aimed at your site. Requests receive these labels as they enter Cloudflare's network:\n\n* **Legitimate:** Request passed directly to your site.\n* **Suspicious:** Request has been challenged with a [Cloudflare challenge](https://developers.cloudflare.com/cloudflare-challenges/).\n* **Bad:** Request has been blocked because our Browser Integrity Check, or because of user configured settings like WAF rules or IP Access rules.\n\nIn addition to threat analytics you can also monitor search engine crawlers going to your websites. For most websites, threats and crawlers make up 20% to 50% of traffic.\n\n</page>\n\n<page>\n---\ntitle: Zone Analytics · Cloudflare Analytics docs\ndescription: The Cloudflare zone analytics is a major component of the overall\n  Cloudflare Analytics product line.  Specifically, this app gives you access to\n  a wide range of metrics, collected at the website or domain level.\nlastUpdated: 2025-11-17T14:08:01.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/account-and-zone-analytics/zone-analytics/\n  md: https://developers.cloudflare.com/analytics/account-and-zone-analytics/zone-analytics/index.md\n---\n\nThe Cloudflare zone analytics is a major component of the overall Cloudflare Analytics product line.  Specifically, this app gives you access to a wide range of metrics, collected at the website or domain level.\n\nNote\n\nRead [Cloudflare Analytics](https://developers.cloudflare.com/analytics/faq/about-analytics/) for general information about all of Cloudflare's analytics offerings. You can also understand the characteristics of the data that Cloudflare captures and processes.\n\n***\n\n## View your website analytics\n\nTo view metrics for your website, in the Cloudflare dashboard, go to the **Analytis & Logs** page.\n\n[Go to **HTTP Traffic**](https://dash.cloudflare.com/?to=/:account/:zone/analytics/traffic)\n\nOnce it loads, you can find tabs for **Traffic**, **Security**, **Performance**, **DNS**, **Workers**, and **Logs** (Enterprise domains only). To understand the various metrics available, refer to *Review your website metrics* below.\n\n***\n\n## Review your website metrics\n\nThis section outlines the metrics available under each Analytics app tab. Before proceeding, note that each tab may contain:\n\n* One or more panels to further categorize the underlying metrics.\n* A dropdown (on the panel's top right) to filter metrics for a specific time period. The time period you can select may vary based on the Cloudflare plan that your domain is associated with.\n\nBelow is a summary of each Analytics app tab.\n\n### HTTP Traffic\n\n#### Free plan\n\nThese metrics include legitimate user requests as well as crawlers and threats. The HTTP Traffic tab features the following panels: \n\n* **Web Traffic** - Displays metrics for *Requests*, *Bandwidth*, and *Unique Visitors*. If you are using Cloudflare Workers, subrequests data will not be visible in zone Traffic Analytics. Instead, you can find subrequests analytics under the **Workers & Pages** tab in the **Overview** section. Refer to [Worker Analytics](https://developers.cloudflare.com/analytics/account-and-zone-analytics/analytics-with-workers/#worker-analytics) for more information.\n* **Web Traffic Requests by Country** - Is an interactive map that breaks down the number of requests by country.  This panel also includes a data table for **Top Traffic Countries / Regions** that display the countries with the most number of requests (up to five, if the data exists).\n\n#### Pro, Business, or Enterprise plan\n\nNote\n\nPrivacy-first HTTP Traffic Analytics are available on the Pro, Business, and Enterprise plans.\n\nAnalytics are based on Cloudflare's edge logs, with no need for third party scripts or trackers. The HTTP Traffic tab features the following metrics:\n\n* **Requests** - An HTTP request. A typical page view requires many requests. If you are using Cloudflare Workers, subrequests data will not be visible in zone HTTP Traffic Analytics. Instead, you can find subrequests analytics under the **Workers & Pages** tab in the **Overview** section. Refer to [Worker Analytics](https://developers.cloudflare.com/analytics/account-and-zone-analytics/analytics-with-workers/#worker-analytics) for more information.\n* **Data Transfer** - Total HTTP data transferred in responses.\n* []()**Page views** - A page view is defined as a successful HTTP response with a content-type of HTML.\n* **Visits** - A visit is defined as a [page view](#page-views) that originated from a different website, or direct link. Cloudflare checks where the HTTP referer does not match the hostname. One visit can consist of multiple page views.\n* **API Requests** - An HTTP request for API data.\n\nTo receive more detailed metrics, **Add filter**. You can also filter each metric by:\n\n* Cache status\n* Data center\n* Source ASN\n* Country\n* Source device type\n* Source IP\n* Referer host\n* Host\n* HTTP method\n* HTTP version\n* Path\n* Query string\n* Content type\n* Edge status code\n* Origin status code\n* Security Action\n* Security Source\n* Source browser\n* Source operating system\n* Source user agent\n* X-Requested-With header\n\nIn addition, the following filters are available to Enterprise [Bot Management](https://developers.cloudflare.com/bots/get-started/bot-management/) customers only.\n\n* Source JA4 fingerprint\n* Source JA3 fingerprint\n\nTo change the time period, use the dropdown menu on the right-hand side above the graph. You can also drag to zoom on the graph.\n\n### Security\n\nFor this tab, the number and type of charts may vary based on existing data and customer plan. Most of the metrics in this tab come from the Cloudflare Firewall app. The panels available include:\n\n* **Threats** - Displays a data summary and an area chart showing threats against the site.\n* **Threats by Country** - Is an interactive map highlighting the countries where threats originated. It also includes data tables with statistics on **Top Threat Countries / Regions** and **Top Crawlers / Bots.**\n* **Rate Limiting** (add-on service) - Features a line chart highlighting matching and blocked requests, based on rate limits.  To learn more, consult [Rate Limiting Analytics](https://developers.cloudflare.com/waf/reference/legacy/old-rate-limiting/#analytics).\n* **Overview** - Displays a set of pie charts for: **Total Threats Stopped**, **Traffic Served Over SSL**, and **Types of Threats Mitigated**. If available, the expandable **Details** link display a table with numerical data.\n\n### Performance\n\nThe metrics aggregated under this tab span multiple Cloudflare services.  The panels available include:\n\n* **Origin Performance (Argo)** (add-on service) - Displays metrics related to response time between the Cloudflare edge network and origin servers for the last 48 hours.  For additional details, refer to [Argo Analytics](https://developers.cloudflare.com/argo-smart-routing/analytics/).\n* **Overview** - Displays a set of pie charts for: **Client HTTP Version Used**, **Bandwidth Saved**, and **Content Type Breakdown**. If available, the expandable **Details** link display a table with numerical data.\n\n### Workers\n\nThis panel features metrics for Cloudflare Workers. To learn more, read [Cloudflare analytics with Workers](https://developers.cloudflare.com/analytics/account-and-zone-analytics/analytics-with-workers/).\n\n### Logs\n\nThe Logs tab is not a metrics feature. Instead, Customers in the Enterprise plan can enable the [Cloudflare Logs Logpush](https://developers.cloudflare.com/logs/logpush/) service. You can use Logpush to download and analyze data using any analytics tool of your choice. \n\n</page>\n\n<page>\n---\ntitle: Get started with Workers Analytics Engine · Cloudflare Analytics docs\ndescription: \"Add the following to your Wrangler configuration file to create a\n  binding to a Workers Analytics Engine dataset. A dataset is like a table in\n  SQL: the rows and columns should have consistent meaning.\"\nlastUpdated: 2025-08-28T09:39:38.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/analytics-engine/get-started/\n  md: https://developers.cloudflare.com/analytics/analytics-engine/get-started/index.md\n---\n\n## 1. Name your dataset and add it to your Worker\n\nAdd the following to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/) to create a [binding](https://developers.cloudflare.com/workers/runtime-apis/bindings/) to a Workers Analytics Engine dataset. A dataset is like a table in SQL: the rows and columns should have consistent meaning.\n\nNote\n\nYou do not need to manually create a dataset in the Cloudflare dashboard. Workers Analytics Engine datasets are created automatically the first time you write to them after defining the binding in your Wrangler configuration.\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "## 2. Write data points from your Worker\n\nYou can write data points to your Worker by calling the `writeDataPoint()` method that is exposed on the binding that you just created.",
      "language": "unknown"
    },
    {
      "code": "Note\n\nYou do not need to await `writeDataPoint()` — it will return immediately, and the Workers runtime handles writing your data in the background.\n\nA data point is a structured event that consists of:\n\n* **Blobs** (strings) — The dimensions used for grouping and filtering. Sometimes called labels in other metrics systems.\n* **Doubles** (numbers) — The numeric values that you want to record in your data point.\n* **Indexes** — (strings) — Used as a [sampling](https://developers.cloudflare.com/analytics/analytics-engine/sql-api/#sampling) key.\n\nIn the example above, suppose you are collecting air quality samples. Each data point written represents a reading from your weather sensor. The blobs define city, state, and sensor model — the dimensions you want to be able to filter queries on later. The doubles define the numeric temperature and air pressure readings. And the index is the ID of your customer. You may want to include [context about the incoming request](https://developers.cloudflare.com/workers/runtime-apis/request/), such as geolocation, to add additional data to your datapoint.\n\nCurrently, the `writeDataPoint()` API accepts ordered arrays of values. This means that you must provide fields in a consistent order. While the `indexes` field accepts an array, you currently must only provide a single index. If you attempt to provide multiple indexes, your data point will not be recorded.\n\n## 3. Query data using the SQL API\n\nYou can query the data you have written in two ways:\n\n* [**SQL API**](https://developers.cloudflare.com/analytics/analytics-engine/sql-api) — Best for writing your own queries and integrating with external tools like Grafana.\n* [**GraphQL API**](https://developers.cloudflare.com/analytics/graphql-api/) — This is the same API that powers the Cloudflare dashboard.\n\nFor the purpose of this example, we will use the SQL API.\n\n### Create an API token\n\nCreate an [API Token](https://dash.cloudflare.com/profile/api-tokens) that has the `Account Analytics Read` permission.\n\n### Write your first query\n\nThe following query returns the top 10 cities that had the highest average humidity readings when the temperature was above zero:",
      "language": "unknown"
    },
    {
      "code": "Note\n\nWe are using a custom averaging function to take [sampling](https://developers.cloudflare.com/analytics/analytics-engine/sql-api/#sampling) into account.\n\nYou can run this query by making an HTTP request to the SQL API:",
      "language": "unknown"
    },
    {
      "code": "Refer to the [Workers Analytics Engine SQL Reference](https://developers.cloudflare.com/analytics/analytics-engine/sql-reference/) for a full list of supported SQL functionality.\n\n### Working with time series data\n\nWorkers Analytics Engine is optimized for powering time series analytics that can be visualized using tools like Grafana. Every event written from the runtime is automatically populated with a `timestamp` field. It is expected that most time series will round, and then `GROUP BY` the `timestamp`. For example:",
      "language": "unknown"
    },
    {
      "code": "This query first rounds the `timestamp` field to the nearest five minutes. Then, it groups by that field and city and calculates the average humidity in each city for a five minute period.\n\nRefer to [Querying Workers Analytics Engine from Grafana](https://developers.cloudflare.com/analytics/analytics-engine/grafana/) for more details on how to create efficient Grafana queries against Workers Analytics Engine.\n\n## Further reading\n\n* [Get started](https://developers.cloudflare.com/analytics/analytics-engine/get-started/)\n* [Examples](https://developers.cloudflare.com/analytics/analytics-engine/recipes/)\n* [SQL API](https://developers.cloudflare.com/analytics/analytics-engine/sql-api/)\n* [SQL Reference](https://developers.cloudflare.com/analytics/analytics-engine/sql-reference/)\n* [Querying from Grafana](https://developers.cloudflare.com/analytics/analytics-engine/grafana/)\n* [Querying from a Worker](https://developers.cloudflare.com/analytics/analytics-engine/worker-querying/)\n* [Sampling with WAE](https://developers.cloudflare.com/analytics/analytics-engine/sampling/)\n* [Pricing](https://developers.cloudflare.com/analytics/analytics-engine/pricing/)\n* [Limits](https://developers.cloudflare.com/analytics/analytics-engine/limits/)\n\n</page>\n\n<page>\n---\ntitle: Querying Workers Analytics Engine from Grafana · Cloudflare Analytics docs\ndescription: Workers Analytics Engine is optimized for powering time series\n  analytics that can be visualized using tools like Grafana. Every event written\n  from the runtime is automatically populated with a timestamp field.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/analytics-engine/grafana/\n  md: https://developers.cloudflare.com/analytics/analytics-engine/grafana/index.md\n---\n\nWorkers Analytics Engine is optimized for powering time series analytics that can be visualized using tools like Grafana. Every event written from the runtime is automatically populated with a `timestamp` field.\n\n## Grafana plugin setup\n\nWe recommend the use of the [Altinity plugin for Clickhouse](https://grafana.com/grafana/plugins/vertamedia-clickhouse-datasource/) for querying Workers Analytics Engine from Grafana.\n\nConfigure the plugin as follows:\n\n* URL: `https://api.cloudflare.com/client/v4/accounts/<account_id>/analytics_engine/sql`. Replace `<account_id>` with your 32 character account ID (available in the Cloudflare dashboard).\n* Leave all auth settings off.\n* Add a custom header with a name of `Authorization` and value set to `Bearer <token>`. Replace `<token>` with suitable API token string (refer to the [SQL API docs](https://developers.cloudflare.com/analytics/analytics-engine/sql-api/#authentication) for more information on this).\n* No other options need to be set.\n\n## Querying timeseries data\n\nFor use in a dashboard, you usually want to aggregate some metric per time interval. This can be achieved by rounding and then grouping by the `timestamp` field. The following query rounds and groups in this way, and then computes an average across each time interval whilst taking into account [sampling](https://developers.cloudflare.com/analytics/analytics-engine/sql-api/#sampling).",
      "language": "unknown"
    },
    {
      "code": "The Altinity plugin provides some useful macros that can simplify writing queries of this type. The macros require setting `Column:DateTime` to `timestamp` in the query builder, then they can be used like this:",
      "language": "unknown"
    },
    {
      "code": "This query will automatically adjust the rounding time depending on the zoom level and filter to the correct time range that is currently being displayed.\n\n</page>\n\n<page>\n---\ntitle: Workers Analytics Engine — Limits · Cloudflare Analytics docs\ndescription: \"The following limits apply to Workers Analytics Engine:\"\nlastUpdated: 2025-12-16T23:42:32.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/analytics-engine/limits/\n  md: https://developers.cloudflare.com/analytics/analytics-engine/limits/index.md\n---\n\nThe following limits apply to Workers Analytics Engine:\n\n* Analytics Engine will accept up to twenty blobs, twenty doubles, and one index per call to `writeDataPoint`.\n* The total size of all blobs in a request must not exceed **16 KB**. The 16 KB size limit for the blobs field applies to **each individual data point**, regardless of how many are included in a single request using writeDataPoints().\n* Each index must not be more than 96 bytes.\n* You can write a maximum of 250 data points per Worker invocation (client HTTP request). Each call to `writeDataPoint` counts towards this limit.\n\n## Data retention\n\nData written to Workers Analytics Engine is stored for three months.\n\nInterested in longer retention periods? Join the `#analytics-engine` channel in the [Cloudflare Developers Discord](https://discord.cloudflare.com/) and tell us more about what you are building.\n\n</page>\n\n<page>\n---\ntitle: Workers Analytics Engine — Pricing · Cloudflare Analytics docs\ndescription: Workers Analytics Engine is priced based on two metrics — data\n  points written, and read queries.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/analytics-engine/pricing/\n  md: https://developers.cloudflare.com/analytics/analytics-engine/pricing/index.md\n---\n\nWorkers Analytics Engine is priced based on two metrics — data points written, and read queries.\n\n| Plan | Data points written | Read queries |\n| - | - | - |\n| **Workers Paid** | 10 million included per month (+$0.25 per additional million) | 1 million included per month (+$1.00 per additional million) |\n| **Workers Free** | 100,000 included per day | 10,000 included per day |\n\nPricing availability\n\nCurrently, you will not be billed for your use of Workers Analytics Engine. Pricing information here is shared in advance, so that you can estimate what your costs will be once Cloudflare starts billing for usage in the coming months.\n\nIf you are an Enterprise customer, contact your account team for information about Workers Analytics Engine pricing and billing.\n\n### Data points written\n\nEvery time you call [`writeDataPoint()`](https://developers.cloudflare.com/analytics/analytics-engine/get-started/#2-write-data-points-from-your-worker) in a Worker, this counts as one data point written.\n\nEach data point written costs the same amount. There is no extra cost to add dimensions or cardinality, and no additional cost for writing more data in a single data point.\n\n### Read queries\n\nEvery time you post to Workers Analytics Engine's [SQL API](https://developers.cloudflare.com/analytics/analytics-engine/sql-api/), this counts as one read query.\n\nEach read query costs the same amount. There is no extra cost for more or less complex queries, and no extra cost for reading only a few rows of data versus many rows of data.\n\n</page>\n\n<page>\n---\ntitle: Example projects · Cloudflare Analytics docs\ndescription: \"Example implementations of common use cases for Workers Analytics Engine:\"\nlastUpdated: 2024-09-11T11:09:20.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/analytics/analytics-engine/recipes/\n  md: https://developers.cloudflare.com/analytics/analytics-engine/recipes/index.md\n---\n\nExample implementations of common use cases for Workers Analytics Engine:\n\n* [Usage-based billing](https://developers.cloudflare.com/analytics/analytics-engine/recipes/usage-based-billing-for-your-saas-product/)\n\n</page>\n\n<page>\n---\ntitle: Sampling with Workers Analytics Engine · Cloudflare Analytics docs\ndescription: How data written to Workers Analytics Engine is automatically sampled at scale\nlastUpdated: 2025-10-01T10:02:32.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/analytics-engine/sampling/\n  md: https://developers.cloudflare.com/analytics/analytics-engine/sampling/index.md\n---\n\nWorkers Analytics Engine offers the ability to write an extensive amount of data and retrieve it quickly, at minimal or no cost. To facilitate writing large amounts of data at a reasonable cost, Workers Analytics Engine employs weighted adaptive [sampling](https://en.wikipedia.org/wiki/Sampling_\\(statistics\\)).\n\nWhen utilizing sampling, you do not need every single data point to answer questions about a dataset. For a sufficiently large dataset, the [necessary sample size](https://select-statistics.co.uk/blog/importance-effect-sample-size/) does not depend on the size of the original population. Necessary sample size depends on the variance of your measure, the size of the subgroups you analyze, and how accurate your estimate must be.\n\nThe implication for Analytics Engine is that we can compress very large datasets into many fewer observations, yet still answer most queries with very high accuracy. This enables us to offer an analytics service that can measure very high rates of usage, with unbounded cardinality, at a low and predictable price.\n\nAt a high level, the way sampling works is:\n\n1. At write time, we sample if data points are written too quickly into one index.\n2. We sample again at query time if the query is too complex.\n\nIn the following sections, you will learn:\n\n* [How sampling works](https://developers.cloudflare.com/analytics/analytics-engine/sampling/#how-sampling-works).\n* [How to read sampled data](https://developers.cloudflare.com/analytics/analytics-engine/sampling/#how-to-read-sampled-data).\n* [How is data sampled](https://developers.cloudflare.com/analytics/analytics-engine/sampling/#how-is-data-sampled).\n* [How Adaptive Bit Rate Sampling works](https://developers.cloudflare.com/analytics/analytics-engine/sampling/#adaptive-bit-rate-sampling-at-read-time).\n* [How to pick your index such that your data is sampled in a usable way](https://developers.cloudflare.com/analytics/analytics-engine/sampling/#how-to-select-an-index).\n\n## How sampling works\n\nCloudflare's data sampling is similar to how online mapping services like Google Maps render maps at different zoom levels. When viewing satellite imagery of a whole continent, the mapping service provides appropriately sized images based on the user's screen and Internet speed.\n\n![The image on the left shows a satellite view from OpenStreetMap. On the right, the same image is zoomed in. In these two images, each pixel represents the same area; however the image on the right has many fewer pixels.](https://developers.cloudflare.com/_astro/zoom-less-pixels.CTBizcEW_Z12dHRa.webp)\n\nEach pixel on the map represents a large area, such as several square kilometers. If a user tries to zoom in using a screenshot, the resulting image would be blurry. Instead, the mapping service selects higher-resolution images when a user zooms in on a specific city. The total number of pixels remains relatively constant, but each pixel now represents a smaller area, like a few square meters.\n\n![Now the image on the right is of a much higher resolution. Each pixel represents a much smaller area; however, the total number of pixels in both images is roughly the same.](https://developers.cloudflare.com/_astro/zoom-more-pixels.CFR4ChGF_1SYmLi.webp)\n\nThe key point is that the map's quality does not solely depend on the resolution or the area represented by each pixel. It is determined by the total number of pixels used to render the final view.\n\nThere are similarities between the how a mapping services handles resolution and Cloudflare Analytics delivers analytics using adaptive samples:\n\n* **How data is stored**:\n\n  * **Mapping service**: Imagery stored at different resolutions.\n  * **Cloudflare Analytics**: Events stored at different sample rates.\n\n* **How data is displayed to user**:\n\n  * **Mapping service**: The total number of pixels is \\~constant for a given screen size, regardless of the area selected.\n  * **Cloudflare Analytics**: A similar number of events are read for each query, regardless of the size of the dataset or length of time selected.\n\n* **How a resolution is selected**:\n\n  * **Mapping service**: The area represented by each pixel will depend on the size of the map being rendered. In a more zoomed out map, each pixel will represent a larger area.\n  * **Cloudflare Analytics**: The sample interval of each event in the result depends on the size of the underlying dataset and length of time selected. For a query over a large dataset or long length of time, each sampled event may stand in for many similar events.\n\n## How to read sampled data\n\nTo effectively write queries and analyze the data, it is helpful to first learn how sampled data is read in Workers Analytics Engine.\n\nIn Workers Analytics Engine, every event is recorded with the `_sample_interval` field. The sample interval is the inverse of the sample rate. For example, if a one percent (1%) sample rate is applied, the `sample_interval` will be set to `100`.\n\nUsing the mapping example in simple terms, the sample interval represents the \"number of unsampled data points\" (kilometers or meters) that a given sampled data point (pixel) represents.\n\nThe sample interval is a property associated with each individual row stored in Workers Analytics Engine. Due to the implementation of equitable sampling, the sample interval can vary for each row. As a result, when querying the data, you need to consider the sample interval field. Simply multiplying the query result by a constant sampling factor is not sufficient.\n\nHere are some examples of how to express some common queries over sampled data.\n\n| Use case | Example without sampling | Example with sampling |\n| - | - | - |\n| Count events in a dataset | `count()` | `sum(_sample_interval)` |\n| Sum a quantity, for example, bytes | `sum(bytes)` | `sum(bytes * _sample_interval)` |\n| Average a quantity | `avg(bytes)` | `sum(bytes * _sample_interval) / sum(_sample_interval)` |\n| Compute quantiles | `quantile(0.50)(bytes)` | `quantileExactWeighted(0.50)(bytes, _sample_interval)` |\n\nNote that the accuracy of results is not determined by the sample interval, similar to the mapping analogy mentioned earlier. A high sample interval can still provide precise results. Instead, accuracy depends on the total number of data points queried and their distribution.\n\n## How is data sampled\n\nTo determine the sample interval for each event, note that most analytics have some important type of subgroup that must be analyzed with accurate results. For example, you may want to analyze user usage or traffic to specific hostnames. Analytics Engine users can define these groups by populating the `index` field when writing an event. This allows for more targeted and precise analysis within the specified groups.\n\nThe next observation is that these index values likely have a very different number of events written to them. In fact, the usage of most web services follows a [Pareto distribution](https://en.wikipedia.org/wiki/Pareto_distribution), meaning that the top few users will account for the vast majority of the usage. Pareto distributions are common and look like this:\n\n![In this graphic, each bar represents a user; the height of the bar is their total usage.](https://developers.cloudflare.com/_astro/total-usage.DT9rN3Uq_1NB5pj.webp)\n\nIf we took a [simple random sample](https://en.wikipedia.org/wiki/Simple_random_sample) of one percent (1%) of this data, and we applied that to the whole population, you may be able to track your largest customers accurately — but you would lose visibility into what your smaller customers are doing:\n\n![The same graphic as above, but now based on a 1% sample of the data.](https://developers.cloudflare.com/_astro/sample-data.Db8bZbVI_m3Ixa.webp)\n\nNotice that the larger bars look more or less unchanged, and yet they are still quite accurate. But as you analyze smaller customers, results get [quantized](https://en.wikipedia.org/wiki/Quantization_\\(signal_processing\\)) and may even be rounded to 0 entirely.\n\nThis shows that while a one percent (1%) or even smaller sample of a large population may be sufficient, we may need to store a larger proportion of events for a small population to get accurate results.\n\nWe do this through a technique called equitable sampling. This means that we will equalize the number of events we store for each unique index value. For relatively uncommon index values, we may write all of the data points that we get via `writeDataPoint()`. But if you write lots of data points to a single index value, we will start to sample.\n\nHere is the same distribution, but now with (a simulation of) equitable sampling applied:\n\n![This graphic shows the same population, but with equitable sampling.](https://developers.cloudflare.com/_astro/equitable-sampling.CzViMd9X_2bvUeI.webp)\n\nYou may notice that this graphic is very similar to the first graph. However, it only requires `<10%` of the data to be stored overall. The sample rate is actually much lower than `10%` for the larger series (that is, we store larger sample intervals), but the sample rate is higher for the smaller series.\n\nRefer back to the mapping analogy above. Regardless of the map area shown, the total number of pixels in the map stays constant. Similarly, we always want to store a similar number of data points for each index value. However, the resolution of the map — how much area is represented by each pixel — will change based on the area being shown. Similarly here, the amount of data represented by each stored data point will vary, based on the total number of data points in the index.\n\n## Adaptive Bit Rate Sampling at Read Time\n\nEquitable sampling ensures that an equal amount of data is maintained for each index within a specific time frame. However, queries can vary significantly in the duration of time they target. Some queries may only require a 10-minute data snapshot, while others might need to analyze data spanning 10 weeks — a period which is 10,000 times longer.\n\nTo address this issue, we employ a method called [adaptive bit rate](https://blog.cloudflare.com/explaining-cloudflares-abr-analytics/) (ABR). With ABR, queries that cover longer time ranges will retrieve data from a higher sample interval, allowing them to be completed within a fixed time limit. In simpler terms, just as screen size or bandwidth is a fixed resource in our mapping analogy, the time required to complete a query is also fixed. Therefore, irrespective of the volume of data involved, we need to limit the total number of rows scanned to provide an answer to the query. This helps to ensure fairness: regardless of the size of the underlying dataset being queried, we ensure that all queries receive an equivalent share of the available computing time.\n\nTo achieve this, we store the data in multiple resolutions (that is, with different levels of detail, for instance, 100%, 10%, 1%) derived from the equitably sampled data. At query time, we select the most suitable data resolution to read based on the query's complexity. The query's complexity is determined by the number of rows to be retrieved and the probability of the query completing within a specified time limit of N seconds. By dynamically selecting the appropriate resolution, we optimize the query performance and ensure it stays within the allotted time budget.\n\nABR offers a significant advantage by enabling us to consistently provide query results within a fixed query budget, regardless of the data size or time span involved. This sets it apart from systems that struggle with timeouts, errors, or high costs when dealing with extensive datasets.\n\n## How to select an index\n\nIn order to get accurate results with sampled data, select an appropriate value to use as your index. The index should match how users will query and view data. For example, if users frequently view data based on a specific device or hostname, it is recommended to incorporate those attributes into your index.\n\nThe index has the following properties, which are important to consider when choosing an index:\n\n* Get accurate summary statistics about your entire dataset, across all index values.\n* Get an accurate count of the number of unique values of your index.\n* Get accurate summary statistics (for example, count, sum) within a particular index value.\n* See the `Top N` values of specific fields that are not in your index.\n* Filter on most fields.\n* Run other aggregations like quantiles.\n\nSome limitations and trade-offs to consider are:\n\n* You may not be able to get accurate unique counts of fields that are not in your index.\n  * For example, if you index on `hostname`, you may not be able to count the number of unique URLs.\n* You may not be able to observe very rare values of fields not in the index.\n  * For example, a particular URL for a hostname, if you index on host and have millions of unique URLs.\n* You may not be able to run accurate queries across multiple indices at once.\n  * For example, you may only be able to query for one host at a time (or all of them) and expect accurate results.\n* There is no guarantee you can retrieve any one individual record.\n* You cannot necessarily reconstruct exact sequences of events.\n\nIt is not recommended to write a unique index value on every row (like a UUID) for most use cases. While this will make it possible to retrieve individual data points very quickly, it will slow down most queries for aggregations and time series.\n\nRefer to the Workers Analytics Engine FAQs, for common question about [Sampling](https://developers.cloudflare.com/analytics/faq/wae-faqs/#sampling).\n\n</page>\n\n<page>\n---\ntitle: Workers Analytics Engine SQL API · Cloudflare Analytics docs\ndescription: The SQL API for Workers Analytics Engine\nlastUpdated: 2025-10-01T10:02:32.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/analytics-engine/sql-api/\n  md: https://developers.cloudflare.com/analytics/analytics-engine/sql-api/index.md\n---\n\nThe Workers Analytics Engine SQL API is an HTTP API that allows executing SQL queries against your Workers Analytics Engine datasets.\n\nThe API is hosted at `https://api.cloudflare.com/client/v4/accounts/<account_id>/analytics_engine/sql`.\n\n## Authentication\n\nAuthentication is done via bearer token. An `Authorization: Bearer <token>` header must be supplied with every request to the API.\n\nUse the dashboard to create a token with permission to read analytics data on your account:\n\n1. Visit the [API tokens](https://dash.cloudflare.com/profile/api-tokens) page in the Cloudflare dashboard.\n\n2. Select **Create Token**.\n\n3. Select **Create Custom Token**.\n\n4. Complete the **Create Custom Token** form as follows:\n\n   * Give your token a descriptive name.\n   * For **Permissions** select *Account* | *Account Analytics* | *Read*\n   * Optionally configure account and IP restrictions and TTL.\n   * Submit and confirm the form to create the token.\n\n5. Make a note of the token string.\n\n## Querying the API\n\nSubmit the query text in the body of a `POST` request to the API address. The format of the data returned can be selected using the [`FORMAT`](https://developers.cloudflare.com/analytics/analytics-engine/sql-reference/statements/#format-clause) option in your query.\n\nYou can use cURL to test the API as follows, replacing the `<account_id>` with your 32 character account ID (available in the dashboard) and the `<token>` with the token string you generated above.",
      "language": "unknown"
    },
    {
      "code": "If you have already published some data, you might try executing the following to confirm that the dataset has been created in the DB.",
      "language": "unknown"
    },
    {
      "code": "Refer to the Workers Analytics Engine [SQL reference](https://developers.cloudflare.com/analytics/analytics-engine/sql-reference/), for the full supported query syntax.\n\n## Table structure\n\nA new table will automatically be created for each dataset once you start writing events to it from your worker.\n\nThe table will have the following columns:\n\n| Name | Type | Description |\n| - | - | - |\n| dataset | string | This column will contain the dataset name in every row. |\n| timestamp | DateTime | The timestamp at which the event was logged in your worker. |\n| \\_sample\\_interval | integer | In case that the data has been sampled, this column indicates what the sample rate is for this row (that is, how many rows of the original data are represented by this row). Refer to the [sampling](#sampling) section below for more information. |\n| index1 | string | The index value that was logged with the event. The value in this column is used as the key for sampling. |\n| blob1 ... blob20 | string | The blob values that were logged with the event. |\n| double1 ... double20 | double | The double values that were logged with the event. |\n\n## Sampling\n\nAt very high volumes of data, Analytics Engine will downsample data in order to be able to maintain performance. Sampling can occur on write and on read. Sampling is based on the index of your dataset so that only indexes that receive large numbers of events will be sampled. For example, if your worker serves multiple customers, you might consider making customer ID the index field. This would mean that if one customer starts making a high rate of requests then events from that customer could be sampled while other customers data remains unsampled.\n\nWe have tested this system of sampling over a number of years at Cloudflare and it has enabled us to scale our web analytics systems to very high throughput, while still providing statistically meaningful results irrespective of the amount of traffic a website receives.\n\nThe rate at which the data is sampled is exposed via the `_sample_interval` column. This means that if you are doing statistical analysis of your data, you may need to take this column into account. For example:\n\n| Original query | Query taking into account sampling |\n| - | - |\n| `SELECT COUNT() FROM ...` | `SELECT SUM(_sample_interval) FROM ...` |\n| `SELECT SUM(double1) FROM ...` | `SELECT SUM(_sample_interval * double1) FROM ...` |\n| `SELECT AVG(double1) FROM ...` | `SELECT SUM(_sample_interval * double1) / SUM(_sample_interval) FROM ...` |\n\nAdditionally, the [QUANTILEEXACTWEIGHTED](https://developers.cloudflare.com/analytics/analytics-engine/sql-reference/aggregate-functions/#quantileexactweighted) function is designed to be used with sample interval as the third argument.\n\n## Example queries\n\n### Select data with column aliases\n\nColumn aliases can be used in queries to give names to the blobs and doubles in your dataset:",
      "language": "unknown"
    },
    {
      "code": "### Aggregation taking into account sample interval\n\nCalculate number of readings taken at each location in the last 7 days. In this case, we are grouping by the index field so an exact count can be calculated even in the case that the data has been sampled:",
      "language": "unknown"
    },
    {
      "code": "Calculate the average temperature over the last 7 days at each location. Sample interval is taken into account:",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: SQL Reference · Cloudflare Analytics docs\ndescription: \"Reference documentation describing the SQL supported by Workers\n  Analytics Engine:\"\nlastUpdated: 2025-10-01T10:02:32.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/analytics/analytics-engine/sql-reference/\n  md: https://developers.cloudflare.com/analytics/analytics-engine/sql-reference/index.md\n---\n\nReference documentation describing the SQL supported by Workers Analytics Engine:\n\n* [Statements](https://developers.cloudflare.com/analytics/analytics-engine/sql-reference/statements/)\n* [Operators](https://developers.cloudflare.com/analytics/analytics-engine/sql-reference/operators/)\n* [Literals](https://developers.cloudflare.com/analytics/analytics-engine/sql-reference/literals/)\n* [Aggregate functions](https://developers.cloudflare.com/analytics/analytics-engine/sql-reference/aggregate-functions/)\n* [Bit functions](https://developers.cloudflare.com/analytics/analytics-engine/sql-reference/bit-functions/)\n* [Conditional functions](https://developers.cloudflare.com/analytics/analytics-engine/sql-reference/conditional-functions/)\n* [Date and Time functions](https://developers.cloudflare.com/analytics/analytics-engine/sql-reference/date-time-functions/)\n* [Encoding functions](https://developers.cloudflare.com/analytics/analytics-engine/sql-reference/encoding-functions/)\n* [Mathematical functions](https://developers.cloudflare.com/analytics/analytics-engine/sql-reference/mathematical-functions/)\n* [String functions](https://developers.cloudflare.com/analytics/analytics-engine/sql-reference/string-functions/)\n* [Type conversion functions](https://developers.cloudflare.com/analytics/analytics-engine/sql-reference/type-conversion-functions/)\n\n</page>\n\n<page>\n---\ntitle: Querying Workers Analytics Engine from a Worker · Cloudflare Analytics docs\ndescription: If you want to access Analytics Engine data from within a Worker\n  you can use fetch to access the SQL API. The API can return JSON data that is\n  easy to interact with in JavaScript.\nlastUpdated: 2025-10-01T10:02:32.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/analytics-engine/worker-querying/\n  md: https://developers.cloudflare.com/analytics/analytics-engine/worker-querying/index.md\n---\n\nIf you want to access Analytics Engine data from within a Worker you can use `fetch` to access the SQL API. The API can return JSON data that is easy to interact with in JavaScript.\n\n## Authentication\n\nIn order that your Worker can authenticate with the API you will need your account ID and an API token.\n\n* Your 32 character account ID can be obtained from the Cloudflare dashboard.\n* An API token can also be generated in the dashboard. Refer to the [SQL API docs](https://developers.cloudflare.com/analytics/analytics-engine/sql-api/#authentication) for more information on this.\n\nWe recommend storing the account ID as an environment variable and the API token as a secret in your worker. This can be done through the dashboard or through Wrangler. Refer to the [Workers documentation](https://developers.cloudflare.com/workers/configuration/environment-variables/) for more details on this.\n\n## Querying\n\nUse the JavaScript `fetch` API as follows to execute a query:",
      "language": "unknown"
    },
    {
      "code": "The data will be returned in the format described in the [FORMAT](https://developers.cloudflare.com/analytics/analytics-engine/sql-reference/statements/#json) section of the documentation, allowing you to extract meta information about the names and types of returned columns in addition to the data itself and a row count.\n\n## Example Worker\n\nThe following is a sample Worker which executes a query against a dataset of weather readings and displays minimum and maximum values for each city.\n\n### Environment variable setup\n\nFirst the environment variables are set up with the account ID and API token.\n\nThe account ID is set in the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/):\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "The API\\_TOKEN can be set as a secret, using the wrangler command line tool, by running the following and entering your token string:",
      "language": "unknown"
    },
    {
      "code": "### Worker script\n\nThe worker script itself executes a query and formats the result:",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Datadog · Cloudflare Analytics docs\ndescription: This tutorial explains how to analyze Cloudflare metrics using the\n  Cloudflare Integration tile for Datadog\nlastUpdated: 2025-10-09T15:47:46.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/analytics-integrations/datadog/\n  md: https://developers.cloudflare.com/analytics/analytics-integrations/datadog/index.md\n---\n\nThis tutorial explains how to analyze Cloudflare metrics using the [Cloudflare Integration tile for Datadog](https://docs.datadoghq.com/integrations/cloudflare/).\n\n## Overview\n\nBefore viewing the Cloudflare dashboard in Datadog, note that this integration:\n\n* Is available to all Cloudflare customer plans (Free, Pro, Business and Enterprise)\n* Is based on the Cloudflare Analytics API\n* Provides Cloudflare web traffic and DNS metrics only\n* Does not feature data coming from request logs stored in Cloudflare Logs\n\n## Task 1 - Install the Cloudflare App\n\nTo install the Cloudflare App for Datadog:\n\n1. Log in to **Datadog**.\n\n2. Click the **Integrations** tab.\n\n3. In the **search box**, start typing *Cloudflare*. The app tile should appear below the search box. ![Searching for Cloudflare App in the Datadog Integrations tab](https://developers.cloudflare.com/_astro/datadog-integrations.BJs60jr6_ZJeSJH.webp)\n\n4. Click the **Cloudflare** tile to begin the installation.\n\n5. Next, click **Configuration** and then complete the following:\n\n   * **Account name**: (Optional) This can be any value. It has not impact on the site data pulled from Cloudflare.\n\n   * **Email**: This value helps keep your account safe. We recommend creating a dedicated Cloudflare user for analytics with the [*Analytics* role](https://developers.cloudflare.com/fundamentals/manage-members/roles/) (read-only). Note that the *Analytics* role is available to Enterprise customers only.\n\n   * **API Key**: Enter your Cloudflare Global API key. For details refer to [API Keys](https://developers.cloudflare.com/fundamentals/api/get-started/keys/).\n\n6. Click **Install Integration**. ![Configuring and installing the Datadog integration](https://developers.cloudflare.com/_astro/cloudflare-tile-datadog-fill-details.Bd14uPIs_1KCUtO.webp)\n\nThe Cloudflare App for Datadog should be installed now and you can view the dashboard.\n\n## Task 2 - View the dashboard\n\nBy default, the dashboard displays metrics for all sites in your Cloudflare account. Use the dashboard filters see metrics for a specific domain.\n\nThe dashboard displays the following metrics:\n\n* **Threats** (threats by type, threats by country)\n* **Requests** (total requests, cached requests, uncached requests, top countries by request, requests by IP class, top content types)\n* **Bandwidth** (total bandwidth, encrypted and unencrypted traffic cached bandwidth, uncached bandwidth)\n* **Caching** (Cache hit rate, request caching rate over time)\n* **HTTP response status errors**\n* **Page views**\n* **Search Engine Bot Traffic**\n* **DNS** (DNS queries, response time, top hostnames, queries by type, stale vs. uncached queries)\n\n![Dashboard displaying metrics for a site on a Cloudflare account](https://developers.cloudflare.com/_astro/cloudflare-dashboard-datadog.BETjd10H_1LPAqa.webp)\n\n</page>\n\n<page>\n---\ntitle: Graylog · Cloudflare Analytics docs\ndescription: This tutorial explains how to analyze Cloudflare Logs using\n  Graylog. The Graylog integration is available on GitHub.\nlastUpdated: 2025-10-09T15:47:46.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/analytics-integrations/graylog/\n  md: https://developers.cloudflare.com/analytics/analytics-integrations/graylog/index.md\n---\n\nThis tutorial explains how to analyze [Cloudflare Logs](https://www.cloudflare.com/products/cloudflare-logs/) using [Graylog](https://github.com/Graylog2/graylog-s3-lambda/blob/master/content-packs/cloudflare/cloudflare-logpush-content-pack.json).\n\n## Overview\n\nIf you haven't used Cloudflare Logs before, visit our [Logs documentation](https://developers.cloudflare.com/logs/) for more details. Contact your Cloudflare Customer Account Team to enable logs for your account.\n\n### Prerequisites\n\nBefore sending your Cloudflare log data to Graylog, make sure that you:\n\n* Have an existing Graylog installation. Both single-node and cluster configurations are supported\n* Have a Cloudflare Enterprise account with Cloudflare Logs enabled\n* Configure [Logpush](https://developers.cloudflare.com/logs/logpush/)\n\nNote\n\nCloudflare logs are HTTP/HTTPS request logs in JSON format and are gathered from our 200+ data centers globally. By default, timestamps are returned as UNIX nanosecond integers. All timestamp formats are supported by Graylog.\n\n## Task 1 - Preparation\n\nBefore getting Cloudflare logs into Graylog:\n\n1. Configure Cloudflare [Logpush](https://developers.cloudflare.com/logs/logpush/) to push logs with all desired fields to an AWS S3 bucket of your choice.\n2. Download the latest [Graylog Integration for Cloudflare](https://github.com/Graylog2/graylog-s3-lambda/blob/master/content-packs/cloudflare/cloudflare-logpush-content-pack.json).\n3. Decompress the zip file.\n\nOnce decompressed, the integration package includes:\n\n* *graylog-s3-lambda.jar*\n* *content-packs/cloudflare/cloudflare-logpush-content-pack.json*\n* *content-packs/cloudflare/threat-lookup.csv*\n\n## Task 2 - Create and configure the AWS Lambda Function\n\n1. Navigate to the Lambda service page in the AWS web console.\n2. Create a new Lambda function and specify a *function name* of your choice and the *Java-8 runtime*.\n3. Create or specify an execution role with the following permissions. You can also further restrict the resource permissions as desired for your specific set-up.",
      "language": "unknown"
    },
    {
      "code": "**Note:** If your Graylog cluster is running in a VPC, you may need to add the *AWSLambdaVPCAccessExecutionRole* managed role to allow the Lambda function to route traffic to the VPC.\n\n1. Once you've created the Lambda function, upload the function code ***graylog-s3-lambda.jar*** downloaded in [Task 1](#task-1---preparation).  Specify the following method for the Handler: *org.graylog.integrations.s3.GraylogS3Function::handleRequest*.\n\n2. Specify at least the following required environment variables to configure the Lambda function for your Graylog cluster:\n\n   * **CONTENT\\_TYPE** (required) - *application/x.cloudflare.log* value to indicate that the Lambda function will process Cloudflare logs.\n\n   * **COMPRESSION\\_TYPE** ***(required*** **)** - *gzip* since Cloudflare logs are gzip compressed.\n\n   * **GRAYLOG\\_HOST** *(required)* - hostname or IP address of the Graylog host or cluster load balancer.\n\n   * **GRAYLOG\\_PORT** *(optional - defaults to 12201)* - The Graylog service port.\n\n   * **CONNECT\\_TIMEOUT** *(optional - defaults to 10000)* - The number of milliseconds to wait for the connection to be established.\n\n   * **LOG\\_LEVEL** *(optional - defaults to INFO)* - The level of detail to include in the CloudWatch logs generated from the Lambda function. Supported values are *OFF*, *ERROR*, *WARN*, *INFO*, *DEBUG*, *TRACE*, and *ALL*. Increase the logging level to help with troubleshooting. See [Defining Custom Log Levels in Code](https://logging.apache.org/log4j/2.0/manual/customloglevels.html) for more information.\n\n   * **CLOUDFLARE\\_LOGPUSH\\_MESSAGE\\_FIELDS** *(optional - defaults to all)* - The fields to parse from the message. Specify as a comma-separated list of field names.\n\n   * **CLOUDFLARE\\_LOGPUSH\\_MESSAGE\\_SUMMARY\\_FIELDS** *(optional - defaults to ClientRequestHost, ClientRequestPath, OriginIP, ClientSrcPort, EdgeServerIP, EdgeResponseBytes)* - The fields to include in the message summary that appears above the parsed fields at the top of each message in Graylog. Specify as a comma-separated list of field names. ![List of required Graylog environment variables](https://developers.cloudflare.com/_astro/graylog-environment-variables.Db3fSAfE_Z17rprI.webp)\n\n     **Note:** More configuration variables are available to fine-tune the function configuration in the Graylog Lambda S3 [README](https://github.com/Graylog2/graylog-s3-lambda/blob/master/README.md#step-2-specify-configuration) file.\n\n3. Create an AWS S3 Trigger for the Lambda function so that the function can process each Cloudflare log field that is written. Specify the same S3 bucket from [Task 1](#task-1---preparation) and choose the *All object create events* option. Any other desired file filters can be applied here. ![Add trigger dialog with an example AWS S3 Trigger](https://developers.cloudflare.com/_astro/aws-s3-add-trigger.CKwYBqmZ_1yQcPD.webp)\n\n4. If your Graylog cluster is located within a VPC, you will need to [configure your Lambda function to access resources in a VPC](https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html). You may also need to create a [VPC endpoint for the AWS S3 service](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html#create-vpc-endpoint). This allows the Lambda function to access S3 directly when running in a VPC.\n\nNote\n\nBy default, all log messages are sent over TCPt. TLS encryption between the Lambda function and Graylog is not currently supported. We recommend taking appropriate measures to secure the log messages in transit, such as placing the Lambda function within a secure VPC subnet where the Graylog node or cluster is running.\n\n## Task 3 - Import the content pack in Graylog\n\nImporting the Cloudflare Logpush content pack into Graylog loads the necessary configuration to receive Cloudflare logs and installs the Cloudflare dashboards.\n\nThe following components install with the content pack:\n\n* Cloudflare dashboards ([Task 4](#task-4---view-the-cloudflare-dashboards)).\n* A Cloudflare GELF (TCP) input that allows Graylog to receive Cloudflare logs.\n* A Cloudflare message [stream](https://docs.graylog.org/en/3.1/pages/streams.html).\n* [Pipeline](https://docs.graylog.org/en/3.1/pages/pipelines/pipelines.html) rules that help to process and parse Cloudflare log fields.\n\nTo import the content pack:\n\n1. Locate the *cloudflare-logpush-content-pack.json* file that you downloaded and extracted in [Task 1](#task-1---preparation).\n\n2. In Graylog, go to **System** > **Content Packs** and click **Upload** in the top right. Once uploaded, the Cloudflare Logpush content pack will appear in the list of uploaded content packs. ![Uploading Graylog content packs](https://developers.cloudflare.com/_astro/graylog-content-packs.D1kZ2lWL_Z3btKA.webp)\n\n3. Click **Install**. ![Installing Graylog content packs](https://developers.cloudflare.com/_astro/graylog-content-packs-uploaded.DEaypq4Q_1Uysn6.webp)\n\n4. In the **Install** dialog, enter an optional install comment, and verify that the correct values are entered for all configuration parameters.\n\n   * A path is required for the MaxMind™️ database, available at <https://dev.maxmind.com/geoip/>.\n   * A path is also required for the *Threat Lookup* CSV file, extracted in [Task 1](#task-1---preparation).\n\n   ![Adding an install comment and configuring parameters in Install Dialog screen](https://developers.cloudflare.com/_astro/graylog-content-pack-install.B5_Hmivu_UwUwC.webp)\n\n5. Once installed, your Graylog cluster will be ready to receive Cloudflare logs from the Lambda function.\n\nRefer to the Graylog Lambda S3 [README](https://github.com/Graylog2/graylog-s3-lambda/blob/master/README.md) for additional information and troubleshooting tips.\n\n## Task 4 - View the Cloudflare Dashboards\n\nYou can view your dashboard in the [Graylog Cloudflare integration page](https://go.graylog.com/cloudflare). The dashboards include:\n\n### Cloudflare - Snapshot\n\nThis is an at-a-glance overview of the most important metrics from your websites and applications on the Cloudflare network. You can use dashboard filters to further slice and dice the information for granular analysis of events and trends.\n\nUse this dashboard to:\n\n* Monitor the most important web traffic metrics of your websites and applications on the Cloudflare network\n* View which countries and IPs your traffic is coming from, and analyze the breakdown between mobile and desktop traffic, protocol, methods, and content types\n\n![Visualizing Cloudflare log metrics in the Graylog dashboard](https://developers.cloudflare.com/_astro/snapshot-cloudflare-dashboard-graylog.CRVPLE-B_Z1FQtTu.webp)\n\n### Cloudflare - Security\n\nThis overview provides insights into threats to your websites and applications, including number of threats stopped,threats over time, top threat countries, and more.\n\nUse this dashboard to:\n\n* Monitor the most important security and threat metrics for your websites and applications\n* Fine-tune and configure your IP firewall\n\n![Visualizing an analysis of Cloudflare threat traffic in the Graylog dashboard](https://developers.cloudflare.com/_astro/security-cloudflare-dashboard-graylog.Bm8-7dyC_kpEKT.webp)\n\n### Cloudflare - Performance\n\nThis dashboard helps to identify and address performance issues and caching misconfigurations. Metrics include total vs. cached bandwidth, saved bandwidth, total requests, cache ratio, top uncached requests, and more.\n\nUse this dashboard to:\n\n* Monitor caching behavior and identify misconfigurations\n* Improve configuration and caching ratio\n\n![Visualizing Cloudflare Performance metrics in the Graylog dashboard](https://developers.cloudflare.com/_astro/performance-cloudflare-dashboard-graylog.BJk_tceI_Z2wfoj4.webp)\n\n### Cloudflare - Reliability\n\nThis dashboard provides insights on the availability of your websites and applications. Metrics include origin response error ratio, origin response status over time, percentage of 3xx/4xx/5xx errors over time, and more.\n\nUse this dashboard to:\n\n* Investigate errors on your websites and applications by viewing edge and origin response status codes\n* Further analyze errors based on status codes by countries, client IPs, hostnames, and other metrics\n\n![Graylog dashboard Cloudflare Reliability](https://developers.cloudflare.com/_astro/reliability-cloudflare-dashboard-graylog.9KgmAZJm_Z1oKY0M.webp)\n\n### Cloudflare - Bots\n\nUse this dashboard to detect and mitigate bad bots so that you can prevent credential stuffing, spam registration, content scraping, click fraud, inventory hoarding, and other malicious activities.\n\nNote\n\nTo get bot requests identified correctly, use only one WAF custom rule (or firewall rule), configured with the action *Interactive Challenge*. To learn more about custom rules, refer to the [WAF documentation](https://developers.cloudflare.com/waf/custom-rules/).\n\nUse this dashboard to:\n\n* Investigate bot activity on your website and prevent content scraping, checkout fraud, spam registration, and other malicious activities.\n* Use insight to tune Cloudflare to prevent bots from excessive usage and abuse across websites, applications, and API endpoints.\n\n![Graylog dashboard Cloudflare Bot Management](https://developers.cloudflare.com/_astro/bot-management-cloudflare-dashboard-graylog.DUQmn7po_21QoxX.webp)\n\n</page>\n\n<page>\n---\ntitle: New Relic · Cloudflare Analytics docs\ndescription: This tutorial explains how to analyze Cloudflare metrics using the\n  New Relic One Cloudflare Quickstart.\nlastUpdated: 2025-10-09T15:47:46.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/analytics-integrations/new-relic/\n  md: https://developers.cloudflare.com/analytics/analytics-integrations/new-relic/index.md\n---\n\nThis tutorial explains how to analyze Cloudflare metrics using the [New Relic One Cloudflare Quickstart](https://newrelic.com/instant-observability/cloudflare/fc2bb0ac-6622-43c6-8c1f-6a4c26ab5434).\n\n## Prerequisites\n\nBefore sending your Cloudflare log data to New Relic, make sure that you:\n\n* Have a Cloudflare Enterprise account with Cloudflare Logs enabled.\n* Have a New Relic account.\n* Configure [Logpush to New Relic](https://developers.cloudflare.com/logs/logpush/logpush-job/enable-destinations/new-relic/).\n\n## Task 1 - Install the Cloudflare Network Logs quickstart\n\n1. Log in to New Relic.\n2. Click the Instant Observability button (top right).\n3. Search for **Cloudflare Network Logs**.\n\n![Cloudflare Network Logs install screen](https://developers.cloudflare.com/_astro/cloudflare-network-logs.CYJYSb1Z_ZhmS1X.webp)\n\n1. Click **Install this quickstart**.\n2. Follow the steps to deploy.\n\n## Task 2 - View the Cloudflare Dashboards\n\nYou can view your dashboards on the New Relic dashboard page. The dashboards include the following information:\n\n### Overview\n\nGet a quick overview of the most important metrics from your websites and applications on the Cloudflare network.\n\n![Cloudflare Network Logs install screen](https://developers.cloudflare.com/_astro/dash-1.CTd2mveX_1JHfvS.webp)\n\n### Security\n\nGet insights on threats to your websites and applications, including number of threats taken action on by the Web Application Firewall (WAF), threats over time, top threat countries, and more.\n\n![Cloudflare Network security metrics screen](https://developers.cloudflare.com/_astro/dash-2.DpiyWwxC_oROsl.webp)\n\n### Performance\n\nIdentify and address performance issues and caching misconfigurations. Metrics include total requests, total versus cached requests, total versus origin requests.\n\n![Cloudflare Network Logs performance metrics screen](https://developers.cloudflare.com/_astro/dash-3.DMdRroU0_1nTb5S.webp)\n\n### Reliability\n\nGet insights on the availability of your websites and Applications. Metrics include, edge response status over time, percentage of `3xx`/`4xx`/`5xx` errors over time, and more.\n\n![Cloudflare Network Logs reliability metrics screen](https://developers.cloudflare.com/_astro/dash-4.BIqk6bUl_1rwwgr.webp)\n\n</page>\n\n<page>\n---\ntitle: Sentinel · Cloudflare Analytics docs\ndescription: Cloudflare has integrations with Microsoft Sentinel to make\n  analyzing your Cloudflare data easier and in a centralized space. Cloudflare\n  has two versions of this connector available. We recommend utilizing the\n  latest Codeless Connector integration as it provides easier setup, cost\n  management, and integrates with Sentinel Data Lake.\nlastUpdated: 2025-11-20T23:13:05.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/analytics-integrations/sentinel/\n  md: https://developers.cloudflare.com/analytics/analytics-integrations/sentinel/index.md\n---\n\nCloudflare has integrations with Microsoft Sentinel to make analyzing your Cloudflare data easier and in a centralized space. Cloudflare has two versions of this connector available. We recommend utilizing the latest Codeless Connector integration as it provides easier setup, cost management, and integrates with [Sentinel Data Lake](https://learn.microsoft.com/en-us/azure/sentinel/datalake/sentinel-lake-overview).\n\n**[Sentinel CCF Solution](https://marketplace.microsoft.com/en-us/product/azure-application/cloudflare.azure-sentinel-solution-cloudflare-ccf?tab=Overview)** (recommended): The Codeless Connector Framework (CCF) provides partners, advanced users, and developers the ability to create custom connectors for ingesting data to Microsoft Sentinel.\n\n**[Sentinel Function Based Connector](https://azuremarketplace.microsoft.com/en-us/marketplace/apps/cloudflare.cloudflare_sentinel?tab=Overview)**: The Cloudflare connector for Microsoft Sentinel uses [Azure Functions](https://azure.microsoft.com/en-us/products/functions) to process security logs from Cloudflare's Logpush service and ingest them directly into the SIEM platform.\n\nThis guide provides clear, step-by-step instructions for integrating Cloudflare logs with the new CCF connector for Microsoft Sentinel using Azure Blob Storage. By following these steps, you will be able to securely collect, store, and analyse your Cloudflare logs within Microsoft Sentinel, enhancing your organisation's security monitoring and incident response capabilities.\n\n## Step 1: Prerequisites\n\n* Azure Subscription with permission to create and manage resources (Contributor/Owner role recommended).\n* Microsoft Sentinel Workspace already set up in your Azure environment.\n* Azure Storage Account with a Blob container for storing Cloudflare logs.\n* Cloudflare Account with access to the domain whose logs you wish to export, and permission to configure Logpush jobs.\n\n## Step 2: Set up a logpush job\n\n1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com/), and select your account and domain.\n\n2. Go to **Analytics** > **Logs** and select **Logpush**.\n\n3. Select **Create Logpush Job**. Choose the log type you want to export (for example, **HTTP requests**).\n\n4. For the destination, select **Azure Blob Storage**.\n\n5. Enter your Azure Blob Storage details:\n\n   * SAS Token (Shared Access Signature)\n\n   To generate a SAS token from the Azure portal, first navigate to your storage account. Under the **Data Storage** section, select **Containers** and choose the relevant container. Within the settings, locate and select **Shared access signature**. Configure the required permissions, such as `write` and `create`, and specify the start and expiration dates for the token. Once configured, generate the SAS token accordingly.\n\n6. Save and activate the Logpush job.\n\nFor complete details, refer to the [Cloudflare Logpush to Azure documentation](https://developers.cloudflare.com/logs/logpush/logpush-job/enable-destinations/azure/).\n\n## Step 3: Configure Azure and deploy the Data Connector in Microsoft Sentinel\n\n1. Log in to the Azure Portal and go to your **Microsoft Sentinel** workspace.\n2. Select **Content Hub** in the navigation bar and search for **Cloudflare**.\n3. Select the **Cloudflare** solution from the results.\n4. Select **Install** in the right pane.\n5. In your **Sentinel workspace**, go to **Data connectors**.\n6. Search for the **Cloudflare connector** (may appear as **Cloudflare (using Azure Blob Storage)**).\n7. Selecte the connector to configure it.\n\n![Azure portal](https://developers.cloudflare.com/_astro/azure-portal.DumVF0xP_Z1Xc42s.webp)\n\n## Step 4: Fill out required fields\n\nWhen configuring the Cloudflare data connector, you will need to provide the following information:\n\n* Blob container URL\n\nTo obtain the container URL within your Azure storage account, access the Azure Portal and navigate to your storage account. Under **Data Storage**, select **Containers**, then choose the relevant container receiving logs from Cloudflare. The container properties section will display the URL link.\n\n* Resource group name for the storage account\n* Storage account location\n* Subscription ID\n* Event grid topic name (only if reconfiguring; not needed for initial setup)\n\nAfter entering all information, select **Connect**.\n\nEnsure all fields are correctly filled to enable seamless log ingestion.\n\n![Configuration fields](https://developers.cloudflare.com/_astro/configuration.ypRscF1K_29xnwE.webp)\n\n## Step 5: Complete deployment\n\n1. Select **Apply changes** or **Connect** to finalise the connector setup.\n2. Monitor the Data connectors page in Sentinel to confirm that the Cloudflare connector status is **Connected**.\n3. Verify that Cloudflare logs are appearing in your Sentinel workspace under **Log Analytics** > **Logs**.\n4. If logs are not appearing, review your Blob Storage permissions, Cloudflare Logpush configuration, and Sentinel connector settings.\n\n![Data connectors](https://developers.cloudflare.com/_astro/data-connectors.By58rEfp_2tvi35.webp)\n\nBy following these steps, you have successfully integrated Cloudflare logs with Microsoft Sentinel using Azure Blob Storage. This integration enables advanced security analytics and incident response capabilities for your Cloudflare-protected environments. If you encounter issues, review each configuration step, check permissions, and review Microsoft's official documentation.\n\n![Cloudflare traffic overview](https://developers.cloudflare.com/_astro/traffic-overview.C9qSRy0T_Z20YDsB.webp)\n\n## Supported Logs\n\nWe support the following fields to be utilized within the Sentinel Connectors (CCF & Function based). You can push all log fields to Azure using our logpush function as described in [Enable Microsoft Azure](https://developers.cloudflare.com/logs/logpush/logpush-job/enable-destinations/azure/) documentation.\n\nParser fields\n\nClientDeviceType\\\nSource\\\nClientSSLCipher\\\nClientTlsCipher\\\nClientSSLProtocol\\\nClientTlsProtocol\\\nFirewallMatchesActions\\\nEvent\\\nFirewallMatchesRuleIDs\\\nRuleID\\\nClientRequestBytes\\\nClientBytes\\\nClientSrcPort\\\nClientPort\\\nEdgeResponseBytes\\\nOriginBytes\\\nBotScore\\\nBotScoreSrc\\\nCacheCacheStatus\\\nCacheResponseBytes\\\nCacheResponseStatus\\\nCacheTieredFill\\\nClientASN\\\nClientCountry\\\nClientIP\\\nClientIPClass\\\nClientRequestHost\\\nClientRequestMethod\\\nClientRequestPath\\\nClientRequestProtocol\\\nClientRequestReferer\\\nClientRequestURI\\\nClientRequestUserAgent\\\nClientXRequestedWith\\\nEdgeColoCode\\\nEdgeColoID\\\nEdgeEndTimestamp\\\nEdgePathingOp\\\nEdgePathingSrc\\\nEdgePathingStatus\\\nEdgeRateLimitAction\\\nEdgeRateLimitID\\\nEdgeRequestHost\\\nEdgeResponseCompressionRatio\\\nEdgeResponseContentType\\\nEdgeResponseStatus\\\nEdgeServerIP\\\nEdgeStartTimestamp\\\nFirewallMatchesSources\\\nOriginIP\\\nOriginResponseBytes\\\nOriginResponseHTTPExpires\\\nOriginResponseHTTPLastModified\\\nOriginResponseStatus\\\nOriginResponseTime\\\nOriginSSLProtocol\\\nParentRayID\\\nRayID\\\nSecurityLevel\\\nWAFAction\\\nWAFFlags\\\nWAFMatchedVar\\\nWAFProfile\\\nWAFRuleID\\\nWAFRuleMessage\\\nWorkerCPUTime\\\nWorkerStatus\\\nWorkerSubrequest\\\nWorkerSubrequestCount\\\nZoneID\\\nApplication\\\nClientMatchedIpFirewall\\\nClientProto\\\nClientTcpRtt\\\nClientTlsClientHelloServerName\\\nClientTlsStatus\\\nColoCode\\\nConnectTimestamp\\\nDisconnectTimestamp\\\nIpFirewall\\\nOriginPort\\\nOriginProto\\\nOriginTcpRtt\\\nOriginTlsCipher\\\nOriginTlsFingerprint\\\nOriginTlsMode\\\nOriginTlsProtocol\\\nOriginTlsStatus\\\nProxyProtocol\\\nStatus\\\nTimestamp\\\nClientASNDescription\\\nClientRefererHost\\\nClientRefererPath\\\nClientRefererQuery\\\nClientRefererScheme\\\nClientRequestQuery\\\nClientRequestScheme\\\nDatetime\\\nKind\\\nMatchIndex\\\nOriginatorRayID\\\nTimeGenerated\n\nWorkBook fields\n\nClientCountry\\_s\\\nClientDeviceType\\_s\\\nClientIP\\_s\\\nClientIPClass\\_s\\\nClientRequestMethod\\_s\\\nClientRequestProtocol\\_s\\\nClientRequestReferer\\_s\\\nClientRequestURI\\_s\\\nClientRequestUserAgent\\_s\\\nEdgePathingOp\\_s\\\nEdgePathingSrc\\_s\\\nEdgePathingStatus\\_s\\\nEdgeResponseContentType\\_s\\\nthreat\\\nTimeGenerated\\\nEdgePathingSrc\\_s\\\nEdgePathingOp\\_s\\\nEdgePathingStatus\\_s\\\nEdgeResponseStatus\\_d\\\nOriginResponseStatus\\_d\\\nTimeGenerated\n\nAnalytic rules\n\nClientIPClass\\\nSrcIpAddr\\\nClientRequestURI\\\nHttpUserAgentOriginal\\\nHttpRequestMethod\\\nTimeGenerated\\\nSrcGeoCountry\\\nClientRequestURI\\\nHttpRequestMethod\\\nHttpStatusCode\\\nDstBytes\\\nSrcBytes\\\nWAFRuleID\\\nWAFRuleMessage\\\nWAFAction\n\nHunting queries\n\nTimeGenerated\\\nHttpStatusCode\\\nSrcIpAddr\\\nClientRequestURI\\\nClientTlsStatus\\\nHttpUserAgentOriginal\\\nOriginTlsStatus\\\nNetworkRuleName\\\nEdgeRequestHost\\\nSrcGeoCountry\\\nEdgeResponseStatus\\\nClientCountry\\\nClientDeviceType\\\nstatus\\\nOriginResponseStatus\\\nWorkerSubrequest\\\nhttp\\_method\\\ndest\\_ip\\\ndest\\_host\\\nuri\\_path\\\nhttp\\_user\\_agent\\\nstatus\\\nsrc\\_ip\\\nOriginResponseStatus\\\nRayID\\\nWorkerSubrequest\\\nhttp\\_method\\\nbytes\\_out\\\nbytes\\_cached\\_requests\\\nthreat\\\nClientRequestProtocol\\\nhttp\\_referrer\\\nClientIPClass\\\ncf\\_http\\_status\\_codes\\\nhttp\\_content\\_type\\\ncf\\_http\\_status\\_codes\\\ncached\\_requests\\\nCacheCacheStatus\\\nClientASN\\\nEdgePathingSrc\\\nEdgePathingOp\\\nEdgePathingStatus\\\nClientRequestUserAgent\\\nSecurityAction\\\nSecurityRuleID\\\nSecurityRuleDescription\n\n## Resources\n\n[Download Cloudflare's CCF Sentinel Solution](https://marketplace.microsoft.com/en-us/product/azure-application/cloudflare.azure-sentinel-solution-cloudflare-ccf?tab=Overview)\\\n[Microsoft Data Lake Overview](https://learn.microsoft.com/en-us/azure/sentinel/datalake/sentinel-lake-overview)\\\n[About the CCF Platform](https://learn.microsoft.com/en-us/azure/sentinel/create-codeless-connector)\n\n</page>\n\n<page>\n---\ntitle: Splunk · Cloudflare Analytics docs\ndescription: This tutorial explains how to analyze Cloudflare Logs using the\n  Cloudflare App for Splunk.\nlastUpdated: 2025-10-09T15:47:46.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/analytics-integrations/splunk/\n  md: https://developers.cloudflare.com/analytics/analytics-integrations/splunk/index.md\n---\n\nThis tutorial explains how to analyze [Cloudflare Logs](https://www.cloudflare.com/products/cloudflare-logs/) using the [Cloudflare App for Splunk](https://splunkbase.splunk.com/app/4501/).\n\n## Prerequisites\n\nBefore sending your Cloudflare log data to Splunk, ensure that you:\n\n* Have an existing Splunk Enterprise or Cloud account\n* Have a Cloudflare Enterprise account\n* Consult the [Splunk documentation](https://splunkbase.splunk.com/app/4501/) for the Cloudflare App\n\n## Task 1 - Install and Configure the Cloudflare App for Splunk\n\nTo install the [Cloudflare App for Splunk](https://splunkbase.splunk.com/app/4501/):\n\n1. Log in to your Splunk instance.\n2. Under **Apps** > **Find More Apps**, search for *Cloudflare App for Splunk.*\n3. Click **Install**.\n\n![Splunk website with Apps menu expanded and Search & Reporting menu item along with Cloudflare App for Splunk](https://developers.cloudflare.com/_astro/splunk-cloudflare-app-for-splunk.CSImDJTK_Z1luCrz.webp)\n\n1. Restart and reopen your Splunk instance.\n\n2. Edit the `cloudflare:json` source type in the Cloudflare App for Splunk. To edit the source type:\n\n   1. Click the **Settings** dropdown and select **Source types**.\n   2. Uncheck **Show only popular** and search for *cloudflare*.\n   3. Click **Edit** and change the Regex expression to `([\\r\\n]+)`.\n   4. Save your edits.\n\n3. Create an index on Splunk to store the HTTP Event logs. To create an index:\n\n   1. Open the setup screen by clicking the **Settings** dropdown, then click **Indexes**.\n   2. Select **New Index**. Note that the **Indexes** page also gives you the status of all your existing indexes so that you can see whether you're about to use up your licensed amount of space.\n   3. Name the index **cloudflare**, which is the default index that the Cloudflare App will use.\n\n4. Set up the HTTP Event Collector (HEC) on Splunk. To create an HEC:\n\n   1. Click the **Settings** dropdown and select **Data inputs**.\n\n   2. Click **+Add new** and follow the wizard. When prompted, submit the following responses:\n\n      * Name: Cloudflare\n      * Source Type: Select > \"cloudflare:json\"\n      * App Context: Cloudflare App for Splunk (cloudflare)\n      * Index: cloudflare\n\n   3. At the end of the wizard you will see a **Token Value**. This token authorizes the Cloudflare Logpush job to send data to your Splunk instance. If you forget to copy it now, Splunk allows you to get the value at any time.\n\n5. Verify whether Splunk is using a self-signed certificate. You'll need this information when creating the Logpush job.\n\n6. Determine the endpoint to use to send the data to. The endpoint should be:",
      "language": "unknown"
    },
    {
      "code": "Where:\n\n* `protocol`: HTTP or HTTPS\n* `input`: `input` or `http-inputs` based on whether you have a self-service or managed cloud plan\n* `host`: The hostname of your Splunk instance. The easiest way to determine the hostname is to look at the URL you went to when you logged in to Splunk.\n* `port`: 443 or 8088\n* `endpoint`: services/collector/raw\n\nFor example: `https://prd-p-0qk3h.splunkcloud.com:8088/services/collector/raw`. Refer to the [Splunk Documentation](https://docs.splunk.com/Documentation/SplunkCloud/latest/Data/UsetheHTTPEventCollector) for more details and examples.\n\n**Post Installation Notes**\n\nYou can change the **Index Name** after the initial configuration by clicking on the **Settings** dropdown and navigating to **Advanced search**. There you can select **Search macros** and look for the Cloudflare App for Splunk.\n\n![Splunk interface highlighting Apps menu and Manage Apps option along with Enable Acceleration checkbox](https://developers.cloudflare.com/_astro/splunk-settings-advanced-search-search-macros.Bt1szjjM_ZMjtQL.webp)\n\nThe Cloudflare App for Splunk comes with a custom Cloudflare Data Model that has an acceleration time frame of 1 day but is not accelerated by default. If you enable [Data Model acceleration](https://docs.splunk.com/Documentation/Splunk/latest/Knowledge/Acceleratedatamodels), we recommend that the Data Model is only accelerated for 1 or 7 days to ensure there are no adverse effects within your Splunk environment.\n\nEnable or disable acceleration after the initial configuration by accessing the app Set up page by clicking the **Apps** dropdown, then **Manage Apps** > **Cloudflare Set Up**.\n\n![Splunk Advanced Search page highlighted Search macros and Advanced search](https://developers.cloudflare.com/_astro/splunk-apps-manage-apps-cloudflare-set-up-enable-data-model-acceleration.KQW0iwYr_Z2eEDj.webp)\n\nYou can also manually configure Data Models by going to **Settings** > **Data models**. Learn more about data model acceleration in the [Splunk documentation](https://docs.splunk.com/Documentation/Splunk/latest/Knowledge/Acceleratedatamodels).\n\n## Task 2 - Make the API call to create the Logpush job\n\nCreate the Logpush job by following the instructions on [Enable Logpush to Splunk](https://developers.cloudflare.com/logs/logpush/logpush-job/enable-destinations/splunk/). The API call creates a Logpush job but does not enable it.\n\nEnable the Logpush job through the Cloudflare dashboard or through the API by following the instructions on [Enable Logpush to Splunk](https://developers.cloudflare.com/logs/logpush/logpush-job/enable-destinations/splunk/). To enable through the dashboard:\n\n1. Navigate to the Cloudflare dashboard and select **Analytics & Logs** > **Logs**.\n2. Select **Edit** and select the fields referenced in the Dashboard section below to fully populate all tables and graphs.\n3. Enable the Logpush job by toggling on the switch next to the Edit link. Data takes a few minutes to populate.\n\nTo validate that you are receiving data, search `index=cloudflare` in Splunk.\n\n## Task 3 - View the Dashboards\n\nYou can analyze Cloudflare logs with the thirteen (13) dashboards listed below.\n\nYou can use filters within these dashboards to help narrow the analysis by date and time, device type, country, user agent, client IP, hostname, and more to further help with debugging and tracing.\n\n### About the Dashboards\n\nThe following dashboards outlined below are available as part of the Cloudflare App for Splunk.\n\n#### Cloudflare - Snapshot\n\n![Splunk dashboard with Web Traffic Overview metrics](https://developers.cloudflare.com/_astro/splunk-cloudflare-snapshot-dashboard.Du4lsJw__1jP8K4.webp)\n\n#### Cloudflare - Reliability\n\n![Splunk dashboard with a high level summary of Reliability metrics](https://developers.cloudflare.com/_astro/splunk-cloudflare-reliability-summary-dashboard.C1py_8XX_Z2oMlNC.webp) ![Splunk dashboard with a detailed summary of Reliability metrics](https://developers.cloudflare.com/_astro/splunk-cloudflare-reliability-detailed-dashboard.jeSlAQnq_Z1L2PRJ.webp)\n\n#### Cloudflare - Security\n\n![Splunk dashboard with an overview of Security metrics](https://developers.cloudflare.com/_astro/splunk-cloudflare-security-overview.D-c4Punh_ZL52JI.webp) ![Splunk dashboard with an overview of Security metrics for WAF](https://developers.cloudflare.com/_astro/splunk-cloudflare-security-waf-dashboard.DTZrF-bl_ZDIO4I.webp) ![Splunk dashboard with an overview of Security metrics for Rate Limiting](https://developers.cloudflare.com/_astro/splunk-cloudflare-security-rate-limiting-dashboard.CRoUKWVc_Z2tjfgR.webp) ![Splunk dashboard with a high level summary of Security metrics for Bots](https://developers.cloudflare.com/_astro/splunk-cloudflare-security-bot-summary-dashboard.S5k4rphZ_Z22vPJo.webp) ![Splunk dashboard with a detailed summary of Security metrics for Bots](https://developers.cloudflare.com/_astro/splunk-cloudflare-security-bots-detailed-dashboard.x_RSBUYB_ZCpd2V.webp)\n\n#### Cloudflare - Performance\n\n![Splunk dashboard with Performance metrics for Requests and Cache](https://developers.cloudflare.com/_astro/splunk-cloudflare-performance-requests-and-cache-dashboard.CzCMXwsS_ZBX9kq.webp) ![Splunk dashboard with Performance metrics for Bandwidth](https://developers.cloudflare.com/_astro/splunk-cloudflare-performance-bandwidth-dashboard.B0Io0qTc_2r9XgC.webp)\n\n*Hostname, Content Type, Request Methods, Connection Type*: Get insights into your most popular hostnames, most requested content types, breakdown of request methods, and connection type.\n\n![Splunk dashboard with Cloudflare Performance metrics including for Hostname, Content Type, Request Methods, Connection Type](https://developers.cloudflare.com/_astro/splunk-cloudflare-performance-hostname-dashboard.BNc0Yvsw_YPhNG.webp) ![Splunk dashboard with Cloudflare Performance metrics for Static vs. Dynamic Content](https://developers.cloudflare.com/_astro/splunk-cloudflare-performance-static-vs-dynamic-dashboard.Dx9F5klY_2c3VNR.webp)\n\n### Filters\n\nAll dashboard have a set of filters that you can apply to the entire dashboard, as shown in the following example. Filters are applied across the entire dashboard.\n\n![Available dashboard filters from the Splunk dashboard](https://developers.cloudflare.com/_astro/splunk-filters.D7I8q-lv_vdPSO.webp)\n\nYou can use filters to drill down and examine the data at a granular level. Filters include client country, client device type, client IP, client request host, client request URI, client request user agent, edge response status, origin IP, and origin response status.\n\nThe default time interval is set to 24 hours. Note that for correct calculations filter will need to exclude Worker subrequests (**WorkerSubrequest** = *false*) and purge requests (**ClientRequestMethod** is not *PURGE*).\n\nAvailable Filters:\n\n* Time Range (EdgeStartTimestamp)\n\n* Client Country\n\n* Client Device type\n\n* Client IP\n\n* Client Request Host\n\n* Client Request URI\n\n* Client Request User Agent\n\n* Edge response status\n\n* Origin IP\n\n* Origin Response Status\n\n* RayID\n\n* Worker Subrequest\n\n* Client Request Method\n\n## Debugging tips\n\n### Incomplete dashboards\n\nThe Splunk Cloudflare App relies on data from the Cloudflare Enterprise Logs fields outlined below. Depending on which fields you have enabled, certain dashboards might not populate fully.\n\nIf that is the case, verify and test the Cloudflare App filters below each dashboard (these filters are the same across all dashboards). You can delete any filters that you do not need, even if such filters include data fields already contained in your logs.\n\nAlso, you could compare the list of fields you are getting in Cloudflare Logs with the fields listed in **Splunk** > **Settings** > **Data Model** > **Cloudflare**.\n\nThe available fields are:\n\n* CacheCacheStatus\n\n* CacheResponseBytes\n\n* CacheResponseStatus (deprecated)\n\n* ClientASN\n\n* ClientCountry\n\n* ClientDeviceType\n\n* ClientIP\n\n* ClientIPClass\n\n* ClientRequestBytes\n\n* ClientRequestHost\n\n* ClientRequestMethod\n\n* ClientRequestPath\n\n* ClientRequestProtocol\n\n* ClientRequestReferer\n\n* ClientRequestURI\n\n* ClientRequestUserAgent\n\n* ClientSSLCipher\n\n* ClientSSLProtocol\n\n* ClientSrcPort\n\n* EdgeColoCode\n\n* EdgeColoID\n\n* EdgeEndTimestamp\n\n* EdgePathingOp\n\n* EdgePathingSrc\n\n* EdgePathingStatus\n\n* EdgeRequestHost\n\n* EdgeResponseBytes\n\n* EdgeResponseContentType\n\n* EdgeResponseStatus\n\n* EdgeServerIP\n\n* EdgeStartTimestamp\n\n* OriginIP\n\n* OriginResponseStatus\n\n* OriginResponseTime\n\n* OriginSSLProtocol\n\n* RayID\n\n* SecurityAction\n\n* SecurityActions\n\n* SecurityRuleDescription\n\n* SecurityRuleID\n\n* SecurityRuleIDs\n\n* SecuritySources\n\n* WAFFlags\n\n* WAFMatchedVar\n\n* WorkerSubrequest\n\n* ZoneID\n\n</page>\n\n<page>\n---\ntitle: A quick overview of Cloudflare Analytics · Cloudflare Analytics docs\ndescription: In an effort to make analytics an ubiquitous component of all\n  Cloudflare's products, Cloudflare has implemented, and continues to evolve,\n  several ways in which customers can access and gain insights from Internet\n  properties on Cloudflare.\nlastUpdated: 2025-07-29T10:04:06.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/analytics/faq/about-analytics/\n  md: https://developers.cloudflare.com/analytics/faq/about-analytics/index.md\n---\n\nIn an effort to make analytics an ubiquitous component of all Cloudflare's products, Cloudflare has implemented, and continues to evolve, several ways in which customers can access and gain insights from Internet properties on Cloudflare.\n\nYou can access root-level analytics that give you an overview of metadata related to your Cloudflare account, analytics related to specific properties and products, and the GraphQL API that gives you more control over how you visualize the analytics and log information available on the Cloudflare dashboard.\n\nRefer to [Types of analytics](https://developers.cloudflare.com/analytics/types-of-analytics/) for more information regarding this subject.\n\n## How Cloudflare captures and processes analytics data\n\nThe underlying datasets that Cloudflare Analytics captures and processes share the following characteristics:\n\n* All metrics reflect traffic proxied through the Cloudflare network (also known as orange-clouded), as configured via DNS records in the Cloudflare DNS app. Note that for a [CNAME setup](https://developers.cloudflare.com/dns/zone-setups/partial-setup/), Cloudflare is unable to offer DNS metrics.\n* Cloudflare does not count traffic for unproxied DNS records. However, if your site is not proxied through Cloudflare but Cloudflare is your authoritative DNS server, then we are able to collect DNS metrics.\n* Cloudflare can only proxy information for traffic targeting [specific ports](https://developers.cloudflare.com/fundamentals/reference/network-ports/).\n* In determining the originating country, Cloudflare uses the IP address associated with each request. Learn about [Configuring Cloudflare IP Geolocation](https://developers.cloudflare.com/network/ip-geolocation/).\n\n## Apparent data discrepancies\n\nIt is possible that your Cloudflare metrics do not fully align with data for the same site as reported by other analytics sources, such as Google Analytics and web server logs.\n\nOnce Cloudflare identifies a unique IP address for a request, we identify such request as a visit. Therefore, the number of visitors Cloudflare Analytics shows is probably higher than what other analytics services may report.\n\nFor example, Google Analytics and other web-based analytics programs use JavaScript on the web browser to track visitors. As a result, Google Analytics does not record threats, bots, and automated crawlers because those requests typically do not trigger JavaScript. Also, these services do not track visitors who disable JavaScript on their browser or who leave a page before it fully loads.\n\nFinally, it is likely that unique visitor data from the Cloudflare Analytics app is greater than your search analytics unique pageviews. This is because pageviews reflect when someone visits a page via a web browser and loads the entire page. However, when another site or service like a bot, plugin, or API is consuming partial content from your site (but not loading a full page), this counts as a unique visitor in Cloudflare and not as a pageview.\n\n## About missing metrics\n\nYou may not be seeing metrics on Cloudflare Analytics for the following reasons:\n\n* You only recently signed up for Cloudflare. Metrics are delayed 24 hours for domains on a free Cloudflare plan.\n* If you signed up directly with Cloudflare, your nameservers might not be pointing to Cloudflare at your registrar just yet. Registrars can take 24-72 hours to update their nameservers. Metrics will not start gathering until we detect the nameservers pointing to Cloudflare.\n* If you signed up through a Cloudflare [hosting partner option](https://www.cloudflare.com/partners/), something might not be configured correctly. Contact the hosting partner for support.\n* Some browser extensions designed to block ads may prevent analytics from loading. To address this issue, disable the ad block extension or allow `cloudflare.com` on it.\n\nNote\n\nActivations through a hosting partner works via a [CNAME setup](https://developers.cloudflare.com/dns/zone-setups/partial-setup/) on the `www` record. If most of your traffic actually goes to `domain.com`, [forward your traffic](https://developers.cloudflare.com/rules/url-forwarding/bulk-redirects/) from `domain.com` to `www.domain.com`.\n\n## Why does the analytics data on the **Overview** page not match what I have under **View More Analytics**?\n\nThe Overview page shows analytics based on all traffic, including subrequests. However, when you navigate to **Analytics & Logs** > **HTTP Traffic**, the metrics (for example, `Requests`, `Data`, `Visits`) are filtered to show only end user traffic (that is, `requestSource = eyeball`).\n\nAs a result, subrequests are excluded from the **HTTP Traffic** view, which can lead to discrepancies between the numbers shown in **Overview** and those displayed in other analytics sections of the dashboard.\n\n</page>\n\n<page>\n---\ntitle: GraphQL API inconsistent results · Cloudflare Analytics docs\ndescription: If you run the same GraphQL Analytics API query multiple times and\n  receive slightly different results, this is caused by Adaptive Bit Rate (ABR)\n  sampling. ABR dynamically adjusts data resolution based on query complexity\n  and timing, which can result in slight variations between query runs.\nlastUpdated: 2025-12-10T19:46:21.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/faq/graphql-api-inconsistent-results/\n  md: https://developers.cloudflare.com/analytics/faq/graphql-api-inconsistent-results/index.md\n---\n\nIf you run the same GraphQL Analytics API query multiple times and receive slightly different results, this is caused by Adaptive Bit Rate (ABR) sampling. ABR dynamically adjusts data resolution based on query complexity and timing, which can result in slight variations between query runs.\n\nTo reduce variation, query shorter timeframes (daily or weekly instead of monthly), use aggregated datasets (nodes with the `Groups` suffix), and request confidence intervals to understand data quality. For more information, refer to [Sampling](https://developers.cloudflare.com/analytics/graphql-api/sampling/).\n\n## What is sampling?\n\nCloudflare's data pipeline handles over 700 million events per second across the global network. Processing all this data in real-time for every query would be prohibitively expensive and time-consuming.\n\nSampling analyzes a subset of data rather than every individual data point. Cloudflare uses Adaptive Bit Rate (ABR) sampling to ensure queries complete quickly, even when working with large datasets.\n\nABR stores data at multiple resolutions:\n\n* **100%** — Full data (used for smaller datasets)\n* **10%** — 10% sample (medium resolution)\n* **1%** — 1% sample (lower resolution)\n\nWhen you run a query, ABR dynamically selects the best resolution based on query complexity, time range requested, number of rows to retrieve, and current system load.\n\n## Why do results vary between query runs?\n\nResults can vary for several reasons:\n\n* **Dynamic resolution selection** — ABR may choose different sampling resolutions on different query runs based on system conditions.\n* **Long time ranges** — Querying 30 days at once is an expensive operation that triggers more aggressive sampling.\n* **High query complexity** — Complex queries with many filters or aggregations may be sampled differently.\n* **System load** — During high-traffic periods, the system may apply more aggressive sampling to ensure fair resource distribution.\n\nFor example, running the same 30-day query twice might return 3,500 objects one time and 3,600 objects another time. This indicates different sampling resolutions were used.\n\n## Can I trust sampled data?\n\nYes. Sampled data is highly reliable and provides insights as dependable as those derived from full datasets. Cloudflare's sampling techniques capture the essential characteristics of the entire dataset.\n\nAggregated metrics (totals, averages, percentiles) are extrapolated based on the sample size, so reported metrics accurately represent the entire dataset. Results based on thousands of rows are highly likely to be representative.\n\nNote\n\nSampling may not capture extremely rare events with very low occurrence rates.\n\n## How can I reduce variation in my query results?\n\n### Query shorter time ranges\n\nInstead of querying an entire month at once, break queries into smaller intervals (daily or weekly).\n\nBefore (more variable):",
      "language": "unknown"
    },
    {
      "code": "After (more consistent):",
      "language": "unknown"
    },
    {
      "code": "Then aggregate the results client-side. Smaller time windows are less likely to trigger aggressive sampling thresholds.\n\n### Use aggregated datasets\n\nPrefer data nodes with the `Groups` suffix over raw adaptive datasets. Aggregated data is pre-processed and less subject to sampling variability.\n\nFor example, use `httpRequestsAdaptiveGroups` instead of raw event data.\n\n### Add explicit sorting\n\nAlways include `orderBy` in your queries to ensure consistent result ordering:",
      "language": "unknown"
    },
    {
      "code": "### Use confidence intervals\n\nFor adaptive datasets, request [confidence intervals](https://developers.cloudflare.com/analytics/graphql-api/features/confidence-intervals/) to understand data quality and verify sampling:",
      "language": "unknown"
    },
    {
      "code": "A higher `sampleSize` indicates more reliable results.\n\n## Quick reference\n\n| Issue | Mitigation |\n| - | - |\n| Results vary between runs | Query shorter time ranges (daily or weekly instead of monthly) |\n| Aggressive sampling on large queries | Break queries into smaller time intervals and aggregate client-side |\n| Need consistent ordering | Add `orderBy` clause to all queries |\n| Need to verify data quality | Request `confidence` intervals to check sample size and accuracy |\n| Using raw adaptive data | Switch to aggregated datasets (nodes with `Groups` suffix) |\n\n## Related resources\n\n* [Understanding Sampling in Cloudflare Analytics](https://developers.cloudflare.com/analytics/sampling/)\n* [GraphQL API Sampling](https://developers.cloudflare.com/analytics/graphql-api/sampling/)\n* [Confidence Intervals](https://developers.cloudflare.com/analytics/graphql-api/features/confidence-intervals/)\n* [GraphQL API Limits](https://developers.cloudflare.com/analytics/graphql-api/limits/)\n* [Adaptive Bit Rate blog post](https://blog.cloudflare.com/explaining-cloudflares-abr-analytics/)\n\n</page>\n\n<page>\n---\ntitle: Other FAQs · Cloudflare Analytics docs\ndescription: There is a number of different types of traffic which may originate\n  from CLOUDFLARENET ASN 13335; just because there is a lot of traffic from this\n  AS, it likely does not indicate a DDoS attack.\nlastUpdated: 2024-09-11T11:09:20.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/faq/other-faqs/\n  md: https://developers.cloudflare.com/analytics/faq/other-faqs/index.md\n---\n\n## Why do I see a large amount of traffic from CLOUDFLARENET ASN 13335 in Analytics? Does this indicate a DDoS attack?\n\nThere is a number of different types of traffic which may originate from **CLOUDFLARENET ASN 13335**; just because there is a lot of traffic from this AS, it likely does not indicate a DDoS attack.\n\nSome sources of traffic from ASN13335 include:\n\n* [Workers subrequests](https://developers.cloudflare.com/workers/runtime-apis/fetch/)\n* [WARP](https://developers.cloudflare.com/warp-client/known-issues-and-faq/#does-warp-reveal-my-ip-address-to-websites-i-visit)\n* [iCloud Private Relay](https://blog.cloudflare.com/icloud-private-relay/) (For reference, iCloud Private Relay’s egress IP addresses are available in this [CSV form](https://mask-api.icloud.com/egress-ip-ranges.csv))\n* [Cloudflare Privacy Proxy](https://blog.cloudflare.com/building-privacy-into-internet-standards-and-how-to-make-your-app-more-private-today/)\n* Other Cloudflare features like [Health Checks](https://developers.cloudflare.com/health-checks/)\n\n</page>\n\n<page>\n---\ntitle: Workers Analytics Engine FAQs · Cloudflare Analytics docs\ndescription: Below you will find answers to our most commonly asked questions.\nlastUpdated: 2024-09-11T11:09:20.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/faq/wae-faqs/\n  md: https://developers.cloudflare.com/analytics/faq/wae-faqs/index.md\n---\n\nBelow you will find answers to our most commonly asked questions.\n\n## Sampling\n\n### Could I just use many unique index values to get better unique counts?\n\nNo, adding a large number of index values does not come without drawbacks. The tradeoff is that reading across many indices is slow.\n\nIn practice, due to how ABR works, reading from many indices in one query will result in low-resolution data – possibly unusably low.\n\nOn the other hand, if you pick a good index that aligns with how you read the data, your queries will run faster and you will get higher resolution results.\n\n### What if I need to index on multiple values?\n\nIt is possible to concatenate multiple values in your index field. So if you want to index on user ID and hostname, you can write, for example `\"$userID:$hostname\"` into your index field.\n\nNote that, based on your query pattern, it may make sense to write the same dataset with different indices. It is a common misconception that one should avoid \"double-writing\" data.\n\nThanks to sampling, the cost of writing data multiple times can be relatively low. However, reading data inefficiently can result in significant expenses or low-quality results due to sampling.\n\n### How do I know if my data is sampled?\n\nYou can use the `_sample_interval` field — again, note that this does not tell you if the results are accurate.\n\nYou can tell when data is sampled at read time because sample intervals will be multiples of powers of 10, for example `20` or `700`. There is no hard and fast rule for when sampling starts at read time, but in practice reading longer periods (or more index values) will result in a higher sample interval.\n\n### Why is data missing?\n\nSampling is based largely on the choice of index, as well as other factors like the time range queried and number of indices read. If you are reading from a larger index over a longer time period, and have filtered to a relatively small subgroup within that index, it may not be present due to sampling.\n\nIf you need to read accurate results for that subgroup, we suggest that you add that field to your index (refer to [What if I need to index on multiple values](https://developers.cloudflare.com/analytics/faq/wae-faqs/#what-if-i-need-to-index-on-multiple-values)).\n\n### Can I trust sampled data? Are my results accurate?\n\nSampled data is highly reliable, particularly when a carefully selected index is used.\n\nAdmittedly, it is difficult at present to prove that the results returned by ABR queries are within a certain error bound. As a rule of thumb, it is good to check the number of rows read by using count() — think of this like the count of pixels in your image. A higher number of rows read will result in more accurate results. (The flipside is that the `_sample_interval` field does not tell you very much about whether your results are accurate). If you are extrapolating from only one or two rows, it is unlikely you have a representative result; if you are extrapolating from thousands of rows, it is very likely that your results are quite accurate.\n\nIn the near future, we plan to expose the [margin of error](https://en.wikipedia.org/wiki/Margin_of_error) along with query results so that you can see precisely how accurate your results are.\n\n### How are bursts handled?\n\nEquitable sampling exists both to normalize differences between groups, and also to handle large spikes of traffic to a given index. Equalization happens every few seconds; if you are writing many events very close in time, then it is expected that they will be sampled at write time. The sample interval for a given index will vary from moment to moment, based on the current rate of data being written.\n\n### How much traffic will trigger sampling?\n\nThere is no fixed rule determining when sampling will be triggered.\n\nWe have observed that for workloads like our global CDN, which distribute load around our network, each index value needs about 100 data points per second before sampling is noticeable at all.\n\nDepending on your workload and how you use Workers Analytics Engine, sampling may start at a higher or lower threshold than this. For example, if you are writing out many data points from a single worker execution, it is more likely that your data will be sampled.\n\n</page>\n\n<page>\n---\ntitle: Error responses · Cloudflare Analytics docs\ndescription: The GraphQL Analytics API is a RESTful API based on HTTPS requests\n  and JSON responses, and will return familiar HTTP status codes (for example,\n  404, 500, 504). However, in contrast to the common REST approach, a 200\n  response can contain an error, conforming to the GraphQL specification.\nlastUpdated: 2025-06-23T09:00:12.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/graphql-api/errors/\n  md: https://developers.cloudflare.com/analytics/graphql-api/errors/index.md\n---\n\nThe GraphQL Analytics API is a RESTful API based on HTTPS requests and JSON responses, and will return familiar HTTP status codes (for example, `404`, `500`, `504`). However, in contrast to the common REST approach, a `200` response can contain an error, conforming to the [GraphQL specification](https://graphql.github.io/graphql-spec/June2018/#sec-Errors).\n\nAll responses contain an `errors` array, which will be `null` if there are no errors, and include at least one error object if there was an error. Non-null error objects will contain the following fields:\n\n* `message`: a string describing the error.\n* `path`: the nodes associated with the error, starting from the root. Note that the number included in the path array, for example, `0` or `1`, specifies to which zone the error applies; `0` indicates the first zone in the list (or only zone, if only one is being queried).\n* `timestamp`: UTC datetime when the error occurred.\n\n## Example",
      "language": "unknown"
    },
    {
      "code": "## Common error types\n\n### Dataset accessibility limits exceeded\n\nSample error messages:\n\n* \"cannot request data older than...\"\n* \"number of fields cannot be more than...\"\n* \"does not have access to the path...\"\n* \"not available for your plan. Upgrade to...\"\n\nThese messages indicate that the query exceeds what is allowed for the particular dataset under the current [plan](https://www.cloudflare.com/plans/), and an upgrade should be considered. Refer to [Node limits](https://developers.cloudflare.com/analytics/graphql-api/limits/#node-limits-and-availability) for details.\n\n### Parsing issues\n\nSample error messages:\n\n* \"error parsing args...\"\n* \"scalar fields must have not selections\"\n\nThese messages indicate that the query cannot be processed because it is malformed.\n\n### Rate limits exceeded\n\nSample error messages:\n\n* \"limit reached, please try reduced time period\"\n* \"quota exceeded, please repeat your request in the next minute\"\n* \"rate limiter budget depleted, try again after 5 minutes\"\n\nRefer to the [Limits](https://developers.cloudflare.com/analytics/graphql-api/limits/) section for more details about rate limits.\n\n</page>\n\n<page>\n---\ntitle: Features · Cloudflare Analytics docs\ndescription: \"The GraphQL Analytics API offers the following features:\"\nlastUpdated: 2024-09-11T11:09:20.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/analytics/graphql-api/features/\n  md: https://developers.cloudflare.com/analytics/graphql-api/features/index.md\n---\n\nThe GraphQL Analytics API offers the following features:\n\n* [Confidence Intervals](https://developers.cloudflare.com/analytics/graphql-api/features/confidence-intervals/)\n* [Datasets (tables)](https://developers.cloudflare.com/analytics/graphql-api/features/data-sets/)\n* [Discovery](https://developers.cloudflare.com/analytics/graphql-api/features/discovery/)\n* [Filtering](https://developers.cloudflare.com/analytics/graphql-api/features/filtering/)\n* [Sorting](https://developers.cloudflare.com/analytics/graphql-api/features/sorting/)\n* [Pagination](https://developers.cloudflare.com/analytics/graphql-api/features/pagination/)\n* [Nested Structures](https://developers.cloudflare.com/analytics/graphql-api/features/nested-structures/)\n\n</page>\n\n<page>\n---\ntitle: Get started · Cloudflare Analytics docs\ndescription: \"Use these articles to get started with the Cloudflare GraphQL API:\"\nlastUpdated: 2025-08-20T18:25:25.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/graphql-api/getting-started/\n  md: https://developers.cloudflare.com/analytics/graphql-api/getting-started/index.md\n---\n\nUse these articles to get started with the Cloudflare GraphQL API:\n\n* [Authentication](https://developers.cloudflare.com/analytics/graphql-api/getting-started/authentication/) - walks you through the options and the steps required to set up your access to Cloudflare API successfully,\n* [Querying basics](https://developers.cloudflare.com/analytics/graphql-api/getting-started/querying-basics/) - brings simple query examples for you to start exploring the GraphQL API,\n* [Introspect the GraphQL schema](https://developers.cloudflare.com/analytics/graphql-api/getting-started/explore-graphql-schema/) - explains how-to surf the schema with GraphQL client,\n* [Create a query in a GraphQL client](https://developers.cloudflare.com/analytics/graphql-api/getting-started/compose-graphql-query/) - describes how to build and run a query against the Cloudflare GraphQL API in the GraphQL clients,\n* [Use curl to query the GraphQL API](https://developers.cloudflare.com/analytics/graphql-api/getting-started/execute-graphql-query/) - walks you through running a query against the Cloudflare GraphQL API from the command line.\n\nFor examples of how to build your own GraphQL Analytics dashboard and query specific information, such as Firewall and Workers events, please refer to [Tutorials](https://developers.cloudflare.com/analytics/graphql-api/tutorials/).\n\nData unavailability: Customer Metadata Boundary configuration\n\nIf you encounter a message on the dashboard indicating that your data is unavailable due to your account's Metadata Boundary configuration, this is because you are trying to access data that is not stored in your region (that is, you are in the US and trying to access data that is only stored in the EU, or vice versa). If you receive this error message while being in the region where your data is stored, there are two potential reasons why you might get this message:\n\n* Your account has Customer Metadata Boundary (CMB) enabled, and your request is being directed to an incorrect region. For example, if you are in the EU and CMB is configured to store your data in the US.\n\n* If you are trying to access your data from the correct region, such as being in the EU with CMB configured to save your data in the EU, the issue may be caused by network congestion. Typically, this problem resolves within a few minutes.\n\n</page>\n\n<page>\n---\ntitle: GraphQL API - Limits · Cloudflare Analytics docs\ndescription: >-\n  Cloudflare GraphQL API exposes more than 70 datasets representing products\n  with\n\n  different configurations and data availability for different zones and\n  accounts\n\n  plans.\nlastUpdated: 2025-06-23T09:00:12.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/graphql-api/limits/\n  md: https://developers.cloudflare.com/analytics/graphql-api/limits/index.md\n---\n\nCloudflare GraphQL API exposes more than 70 datasets representing products with different configurations and data availability for different zones and accounts plans.\n\nTo support this variety of products, Cloudflare GraphQL API has three layers of limits:\n\n* global limits\n* user limits\n* node (dataset) limits\n\n## Global limits\n\nThese limits are applied to every query for every plan:\n\n* A zone-scoped query can include up to **10 zones**\n* An account-scoped query can include only **1 account**\n\nAdditionally, there is a limited number of queries you can make per request. The total number of queries in a request is equal to the number of zone/account scopes, multiplied by the number of nodes to which they are applied.\n\n## User limits\n\nCloudflare GraphQL API limits the number of GraphQL requests each user can send. The default quota is **300 GraphQL queries over 5-minute window**. It allows a user to run at least **1 query every second** or do a burst of 300 queries and then wait 5 minutes before issuing another query.\n\nThat rate limit is applied in addition to the [general rate limits enforced by the Cloudflare API](https://developers.cloudflare.com/fundamentals/api/reference/limits/).\n\n## Node limits and availability\n\nEach data node has its limits, such as:\n\n* how far back in time can data be requested,\n* the maximum time period (in seconds) that can be requested in one query,\n* the maximum number of fields that can be requested in one query,\n* the maximum number of records that can be returned in one query.\n\nNode limits are tied to requested `zoneTag` or `accountTag`. Higher plans have access to a greater selection of datasets or fields, and can query over broader historical intervals.\n\nTo get exact boundaries and availability for your zone(s) or account, please refer to [settings](https://developers.cloudflare.com/analytics/graphql-api/features/discovery/settings/).\n\n</page>\n\n<page>\n---\ntitle: MCP server · Cloudflare Analytics docs\nlastUpdated: 2025-10-09T17:32:08.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/graphql-api/mcp-server/\n  md: https://developers.cloudflare.com/analytics/graphql-api/mcp-server/index.md\n---\n\n\n</page>\n\n<page>\n---\ntitle: Migration guides · Cloudflare Analytics docs\ndescription: If you are currently using the deprecated\n  httpRequests1mByColoGroups or httpRequests1dByColoGroups GraphQL API nodes,\n  the HTTP Requests by Colo Groups to HTTP Requests by Adaptive Groups guide\n  will help you migrate your queries to use the httpRequestsAdaptiveGroups node.\nlastUpdated: 2024-12-16T22:33:26.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/graphql-api/migration-guides/\n  md: https://developers.cloudflare.com/analytics/graphql-api/migration-guides/index.md\n---\n\n## GraphQL migrations\n\nIf you are currently using the deprecated `httpRequests1mByColoGroups` or `httpRequests1dByColoGroups` GraphQL API nodes, the [HTTP Requests by Colo Groups to HTTP Requests by Adaptive Groups](https://developers.cloudflare.com/analytics/graphql-api/migration-guides/graphql-api-analytics/) guide will help you migrate your queries to use the `httpRequestsAdaptiveGroups` node.\n\n## Zone Analytics migrations\n\nIf you are currently using the Zone Analytics API, the following guide will help you migrate your queries to the new GraphQL Analytics API:\n\n* [Zone Analytics to GraphQL Analytics](https://developers.cloudflare.com/analytics/graphql-api/migration-guides/zone-analytics/)\n* [Zone Analytics Colos Endpoint to GraphQL Analytics](https://developers.cloudflare.com/analytics/graphql-api/migration-guides/zone-analytics-colos/)\n\n## Network Analytics migrations\n\nIf you are currently using the Network Analytics v1 (NAv1) GraphQL nodes, the [Network Analytics v1 to Network Analytics v2](https://developers.cloudflare.com/analytics/graphql-api/migration-guides/network-analytics-v2/) guide will help you migrate your queries to the new Network Analytics v2.\n\n</page>\n\n<page>\n---\ntitle: Sampling · Cloudflare Analytics docs\ndescription: For a deep-dive on how sampling at Cloudflare works, see\n  Understanding sampling in Cloudflare Analytics.\nlastUpdated: 2025-03-31T18:54:49.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/graphql-api/sampling/\n  md: https://developers.cloudflare.com/analytics/graphql-api/sampling/index.md\n---\n\nFor a deep-dive on how sampling at Cloudflare works, see [Understanding sampling in Cloudflare Analytics](https://developers.cloudflare.com/analytics/sampling/).\n\n## Overview\n\nIn a small number of cases, the analytics provided on the Cloudflare dashboard and GraphQL Analytics API are based on a **sample** — a subset of the dataset. In these cases, Cloudflare Analytics returns an estimate derived from the sampled value. For example, suppose that during an attack the sampling rate is 10% and 5,000 events are sampled. Cloudflare will estimate 50,000 total events (5,000 × 10) and report this value in Analytics.\n\n## Sampled datasets\n\nCloudflare GraphQL API exposes datasets that powered by adaptive sampling. These nodes have **Adaptive** in the name and can be discovered through [introspection](https://developers.cloudflare.com/analytics/graphql-api/features/discovery/introspection/).\n\nThe presence of sampled data is also called out in the Cloudflare dashboard and in the description of the dataset in the API.\n\n## Why sampling is applied\n\nAnalytics is designed to provide requested data, at the appropriate level of detail, as quickly as possible. Sampling allows Cloudflare to deliver analytics within seconds, even when datasets scale quickly and unpredictably, such as a burst of Firewall events generated during an attack. And because the volume of underlying data is large, the value estimated from the sample should still be statistically significant – meaning you can rely on sampled data with a high degree of confidence. Without sampling, it might take several minutes or longer to answer a query — a long time to wait when validating mitigation efforts.\n\n## Types of sampling\n\n### Adaptive sampling\n\nCloudflare almost always uses **adaptive sampling**, which means the sample rate fluctuates depending on the volume of data ingested or queried. If the number of records is relatively small, sampling is not used. However, as the volume of records grows larger, progressively lower sample rates are applied. Security Events (also known as Firewall Events) and the Security Event Log follow this model. Data nodes that use adaptive sampling are easy to identify by the `Adaptive` suffix in the node name, as in `firewallEventsAdaptive`.\n\n### Fixed sampling\n\nThe following data nodes are based on fixed sampling, where the sample rate does not vary:\n\n| Data set | Rate | Notes |\n| - | - | - |\n| Firewall Rules Preview **Nodes:** `firewallRulePreviewGroups` | 1% | Use with caution. A 1% sample rate does not provide accurate estimates for datasets smaller than a certain threshold, a scenario the Cloudflare dashboard calls out explicitly but the API does not. |\n| Network Analytics **Nodes:** `ipFlows1mGroups` `ipFlows1hGroups` `ipFlows1dGroups` `ipFlows1mAttacksGroups` | 0.012% | Sampling rate is in terms of packet count (1 of every 8,192 packets). |\n\n## Access to raw data\n\nBecause sampling is primarily adaptive and automatically adjusts to provide an accurate estimate, the sampling rate cannot be directly controlled. Enterprise customers have access to raw data via Cloudflare Logs.\n\n</page>\n\n<page>\n---\ntitle: Configure Cloudflare Network Analytics · Cloudflare Analytics docs\nlastUpdated: 2024-09-11T11:09:20.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/analytics/network-analytics/configure/\n  md: https://developers.cloudflare.com/analytics/network-analytics/configure/index.md\n---\n\n* [Adjust the time range](https://developers.cloudflare.com/analytics/network-analytics/configure/time-range/)\n* [Adjust the displayed data](https://developers.cloudflare.com/analytics/network-analytics/configure/displayed-data/)\n* [Share and export data](https://developers.cloudflare.com/analytics/network-analytics/configure/share-export/)\n\n</page>\n\n<page>\n---\ntitle: Tutorials · Cloudflare Analytics docs\ndescription: \"The following resources will help you start exploring your data\n  and creating analytics dashboards:\"\nlastUpdated: 2024-09-11T11:09:20.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/analytics/graphql-api/tutorials/\n  md: https://developers.cloudflare.com/analytics/graphql-api/tutorials/index.md\n---\n\nThe following resources will help you start exploring your data and creating analytics dashboards:\n\n* [Capture GraphQL queries with Chrome DevTools](https://developers.cloudflare.com/analytics/graphql-api/tutorials/capture-graphql-queries-from-dashboard/)\n* [Querying Access login events with GraphQL](https://developers.cloudflare.com/analytics/graphql-api/tutorials/querying-access-login-events/)\n* [Querying Firewall Events with GraphQL](https://developers.cloudflare.com/analytics/graphql-api/tutorials/querying-firewall-events/)\n* [Querying HTTP events by hostname with GraphQL](https://developers.cloudflare.com/analytics/graphql-api/tutorials/end-customer-analytics/)\n* [Querying Magic Firewall Intrusion Detection System (IDS) samples with GraphQL](https://developers.cloudflare.com/analytics/graphql-api/tutorials/querying-magic-firewall-ids-samples/)\n* [Querying Magic Firewall Samples with GraphQL](https://developers.cloudflare.com/analytics/graphql-api/tutorials/querying-magic-firewall-samples/)\n* [Querying Magic Transit and Magic WAN tunnel bandwidth analytics with GraphQL](https://developers.cloudflare.com/analytics/graphql-api/tutorials/querying-magic-transit-tunnel-bandwidth-analytics/)\n* [Querying Magic Transit and Magic WAN tunnel health check results with GraphQL](https://developers.cloudflare.com/analytics/graphql-api/tutorials/querying-magic-transit-tunnel-healthcheck-results/)\n* [Querying Workers Metrics with GraphQL](https://developers.cloudflare.com/analytics/graphql-api/tutorials/querying-workers-metrics/)\n* [Use GraphQL to create widgets](https://developers.cloudflare.com/analytics/graphql-api/tutorials/use-graphql-create-widgets/)\n\n</page>\n\n<page>\n---\ntitle: Get started with Network Analytics · Cloudflare Analytics docs\ndescription: Learn how to view and use data from Network Analytics.\nlastUpdated: 2025-09-04T10:57:42.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/analytics/network-analytics/get-started/\n  md: https://developers.cloudflare.com/analytics/network-analytics/get-started/index.md\n---\n\nRequirements\n\nNetwork Analytics requires the following:\n\n* A Cloudflare Enterprise plan.\n* Cloudflare Magic Transit or Spectrum.\n* Cloudflare Magic WAN.\n\n## View the Network Analytics dashboard\n\n1. In the Cloudflare dashboard, go to the **Network Analytics** page.\n\n   [Go to **Network analytics**](https://dash.cloudflare.com/?to=/:account/network-analytics)\n\n2. Select an account that has access to Magic Transit or Spectrum.\n\n3. Configure the displayed data. You can [adjust the time range](https://developers.cloudflare.com/analytics/network-analytics/configure/time-range/), [select the main metric](https://developers.cloudflare.com/analytics/network-analytics/configure/displayed-data/#select-high-level-metric) (total packets or total bytes), [apply filters](https://developers.cloudflare.com/analytics/network-analytics/configure/displayed-data/#apply-filters), and more.\n\n## Get Network Analytics data via API\n\nUse the [GraphQL Analytics API](https://developers.cloudflare.com/analytics/graphql-api/) to query data using the available [Network Analytics nodes](https://developers.cloudflare.com/analytics/graphql-api/migration-guides/network-analytics-v2/node-reference/).\n\n## Send Network Analytics logs to a third-party service\n\n[Create a Logpush job](https://developers.cloudflare.com/logs/logpush/logpush-job/enable-destinations/) that sends Network analytics logs to your storage service, SIEM solution, or log management provider.\n\n## Limitations\n\nUsers with the `Analytics` role will have visibility to IDs but will not see the following on the Network Analytics dashboard:\n\n* Tunnel names\n* Prefix names\n* [Magic Firewall](https://developers.cloudflare.com/magic-firewall/) rules\n* [DDoS managed rulesets](https://developers.cloudflare.com/ddos-protection/managed-rulesets/)\n* Override names\n\n</page>\n\n<page>\n---\ntitle: Reference - Network analytics · Cloudflare Analytics docs\ndescription: \"Review reference information about Cloudflare Network Analytics:\"\nlastUpdated: 2024-09-11T11:09:20.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/analytics/network-analytics/reference/\n  md: https://developers.cloudflare.com/analytics/network-analytics/reference/index.md\n---\n\nReview reference information about Cloudflare Network Analytics:\n\n* [Data collection](https://developers.cloudflare.com/analytics/network-analytics/reference/data-collection/)\n\n</page>\n\n<page>\n---\ntitle: Understand Cloudflare Network Analytics · Cloudflare Analytics docs\nlastUpdated: 2024-09-11T11:09:20.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/analytics/network-analytics/understand/\n  md: https://developers.cloudflare.com/analytics/network-analytics/understand/index.md\n---\n\n* [Concepts](https://developers.cloudflare.com/analytics/network-analytics/understand/concepts/)\n* [Main dashboard](https://developers.cloudflare.com/analytics/network-analytics/understand/main-dashboard/)\n\n</page>\n\n<page>\n---\ntitle: API Routing · Cloudflare API Shield docs\ndescription: API Shield Routing enables customers to create a unified\n  external-facing API that routes requests to different back-end services that\n  may have different paths and hosts than the existing zone and DNS\n  configuration.\nlastUpdated: 2025-09-26T21:09:24.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/api-shield/management-and-monitoring/api-routing/\n  md: https://developers.cloudflare.com/api-shield/management-and-monitoring/api-routing/index.md\n---\n\nAPI Shield Routing enables customers to create a unified external-facing API that routes requests to different back-end services that may have different paths and hosts than the existing zone and DNS configuration.\n\nNote\n\nThe term **Source Endpoint** refers to the endpoint managed by API Shield in Endpoint Management. The term **Target Endpoint** refers to the ultimate destination the request is sent to by the Routing feature.\n\n## Process\n\nYou must add Source Endpoints to Endpoint Management through established methods, including [uploading a schema](https://developers.cloudflare.com/api-shield/security/schema-validation/#add-validation-by-uploading-a-schema), via [API Discovery](https://developers.cloudflare.com/api-shield/security/api-discovery/), or by [adding manually](https://developers.cloudflare.com/api-shield/management-and-monitoring/#add-endpoints-manually), before creating a route.\n\nTo create a route, you will need the operation ID of the Source Endpoint. To find the operation ID in the dashboard:\n\n* Old dashboard\n\n  1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com/), and select your account and domain.\n  2. Select **Security** > **API Shield**.\n  3. Filter the endpoints to find your **Source Endpoint**.\n  4. Expand the row for your Source Endpoint and note the **operation ID** field.\n  5. Select the copy icon to copy the operation ID to your clipboard.\n\n* New dashboard\n\n  1. In the Cloudflare dashboard, go to the **Web Assets** page.\n\n     [Go to **Web assets**](https://dash.cloudflare.com/?to=/:account/:zone/security/web-assets)\n\n  2. Filter the endpoints to find your **Source Endpoint**.\n\n  3. Expand the row for your Source Endpoint and note the **operation ID** field.\n\n  4. Select the copy icon to copy the operation ID to your clipboard.\n\nOnce your Source Endpoints are added to Endpoint Management, use the following steps to create and verify routes on any given operation ID:\n\n### Create a route\n\n* Old dashboard\n\n  1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com/), and select your account and domain.\n  2. Go to **Security** > **API Shield**.\n  3. In **Endpoint Management**, select an existing endpoint and expand its details.\n  4. Under **Routing**, select **Create route**.\n  5. Enter the target URL or IP address to route your endpoint to.\n  6. Select **Deploy route**.\n\n* New dashboard\n\n  1. In the Cloudflare dashboard, go to the **Web Assets** page.\n\n     [Go to **Web assets**](https://dash.cloudflare.com/?to=/:account/:zone/security/web-assets)\n\n  2. In **Endpoints**, select an existing endpoint and expand its details.\n\n  3. Under **Routing**, select **Create route**.\n\n  4. Enter the target URL or IP address to route your endpoint to.\n\n  5. Select **Deploy route**.\n\nNote\n\nYou can reorder path variables if they are present. For example, you can route `/api/{var1}/users/{var2}` to `/{var2}/users/{var1}`. Segments of the path that are not variables may be added or omitted entirely.\n\nYou can also edit or delete a route by selecting **Edit route** on an existing route.\n\n### Test a route\n\nAfter sending a request to your Source Endpoint, you should see the contents of the back-end service as if you called the Target Endpoint directly.\n\nIf API Shield returns unexpected results, check your Source Endpoint host, method, and path and [verify the Route](https://developers.cloudflare.com/api-shield/management-and-monitoring/api-routing/#verify-a-route) to ensure the Target Endpoint value is correct.\n\nNote\n\nYou may need to wait up to five minutes for Route changes to synchronize across the Cloudflare network.\n\n## Availability\n\nAPI Shield Routing is currently in an open beta and is only available for Enterprise customers subscribed to API Shield. Enterprise customers who have not purchased API Shield can preview [API Shield as a non-contract service](https://dash.cloudflare.com/?to=/:account/:zone/security/api-shield) in the Cloudflare dashboard or by contacting your account team.\n\n## Limitations\n\nThe Target Endpoint cannot be routed to a Worker if the route is to the same zone.\n\nYou cannot change the method of a request. For example, a `GET` Source Endpoint will always send a `GET` request to the Target Endpoint.\n\nYou must use all of the variables in the Target Endpoint that appear in the Source Endpoint. For example, routing `/api/{var1}/users/{var2}` to `/api/users/{var2}` is not allowed and will result in an error since `{var1}` is present in the Source Endpoint but not in the Target Endpoint.\n\n</page>\n\n<page>\n---\ntitle: Endpoint labeling service · Cloudflare API Shield docs\ndescription: API Shield's labeling service will help you organize your endpoints\n  and address vulnerabilities in your API. The labeling service comes with\n  managed and user-defined labels.\nlastUpdated: 2025-11-06T19:39:43.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/api-shield/management-and-monitoring/endpoint-labels/\n  md: https://developers.cloudflare.com/api-shield/management-and-monitoring/endpoint-labels/index.md\n---\n\nAPI Shield's labeling service will help you organize your endpoints and address vulnerabilities in your API. The labeling service comes with managed and user-defined labels.\n\nToday, managed labels are useful for organizing endpoints by use case. In a future release, managed labels will automatically label endpoints by use case and those with informative or security risks, alerting you on endpoints that need attention.\n\nUser-defined labels can also be added to endpoints in API Shield by creating a label and adding it to an individual endpoint or multiple endpoints. User-defined labels will be useful for organizing your endpoints by owner, version, or type.\n\nYou can filter your endpoints based on the labels.\n\n## Categories\n\n### Managed labels\n\nUse managed labels to identify endpoints by use case. Cloudflare may automatically apply these labels in a future release.\n\n`cf-log-in`: Add this label to endpoints that accept user credentials. You may have multiple endpoints if you accept username, password, and multi-factor authentication (MFA) across multiple endpoints or requests.\n\n`cf-sign-up`: Add this label to endpoints that are the final step in creating user accounts for your site or application.\n\n`cf-content`: Add this label to endpoints that provide unique content, such as product details, user reviews, pricing, or other unique information.\n\n`cf-purchase`: Add this label to endpoints that are the final step in purchasing goods or services online.\n\n`cf-password-reset`: Add this label to endpoints that participate in the user password reset process. This includes initial password reset requests and final password reset submissions.\n\n`cf-add-cart`: Add this label to endpoints that add items to a user's shopping cart or verify item availability.\n\n`cf-add-payment`: Add this label to endpoints that accept credit card or bank account details where fraudsters may iterate through account numbers to guess valid combinations of payment information.\n\n`cf-check-value`: Add this label to endpoints that check the balance of rewards points, in-game currency, or other stored value products that can be earned, transferred, and redeemed for cash or physical goods.\n\n`cf-add-post`: Add this label to endpoints that post messages in a communication forum, or product or merchant reviews.\n\n`cf-account-update`: Add this label to endpoints that participate in user account or profile updates.\n\n`cf-llm`: Services that are (partially) powered by Large Language Model (LLM).\n\n`cf-rss-feed`: Add this label to endpoints that expect traffic from RSS clients.\n\n`cf-web-page`: Add this label to endpoints that serve HTML pages.\n\nNote\n\n[Bot Fight Mode](https://developers.cloudflare.com/bots/get-started/bot-fight-mode/) will not block requests to endpoints labeled as `cf-rss-feed`.\n\n[Super Bot Fight Mode rules](https://developers.cloudflare.com/bots/get-started/super-bot-fight-mode/#ruleset-engine) will not match or challenge requests labeled as `cf-rss-feed`.\n\n### Risk labels\n\nCloudflare automatically runs risk scans every 24 hours on your saved endpoints. API Shield applies these labels when a scan finds security risks on your endpoints. A corresponding Security Center Insight is also raised when risks are found.\n\n`cf-risk-missing-auth`: Automatically added when all successful requests lack a session identifier. Refer to the table below for more information.\n\n`cf-risk-mixed-auth`: Automatically added when some successful requests contain a session identifier and some successful requests lack a session identifier. Refer to the table below for more information.\n\n`cf-risk-sensitive`: Automatically added to endpoints when HTTP responses match the WAF's [Sensitive Data Detection](https://developers.cloudflare.com/api-shield/management-and-monitoring/#sensitive-data-detection) ruleset.\n\n`cf-risk-missing-schema`: Automatically added when a learned schema is available for an endpoint that has no active schema.\n\n`cf-risk-error-anomaly`: Automatically added when an endpoint experiences a recent increase in response errors over the last 24 hours.\n\n`cf-risk-latency-anomaly`: Automatically added when an endpoint experiences a recent increase in response latency over the last 24 hours.\n\n`cf-risk-size-anomaly`: Automatically added when an endpoint experiences a spike in response body size over the last 24 hours.\n\n`cf-risk-bola-enumeration`: Automatically added when an endpoint experiences successful responses with drastic differences in the number of unique elements requested by different user sessions.\n\n`cf-risk-bola-pollution`: Automatically added when an endpoint experiences successful responses where parameters are found in multiple places in the request, as opposed to what is expected from the API's schema.\n\nNote\n\nCloudflare will only add authentication labels to endpoints with successful response codes. Refer to the below table for more details.\n\n| Description | 2xx response codes | 4xx, 5xx response codes |\n| - | - | - |\n| If all requests are missing authentication, Cloudflare will apply the label: | `cf-missing-auth` | Without successful responses, no label will be added. |\n| If only some requests are missing authentication, Cloudflare will apply the label: | `cf-mixed-auth` | Without successful responses, no label will be added. |\n\n## Create a label\n\n* Old dashboard\n\n  1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com/), and select your account and domain.\n  2. Go to **Security** > **Settings** > **Labels**.\n  3. Under **Security labels**, select **Create label**.\n  4. Name the label and add an optional label description.\n  5. Apply the label to your selected endpoints.\n  6. Select **Create label**.\n\n  Alternatively, you can create a user-defined label via Endpoint Management in API Shield:\n\n  1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com/), and select your account and domain.\n  2. Go to **Security** > **Settings** > **Labels**.\n  3. Choose the endpoint that you want to label.\n  4. Select **Edit labels**.\n  5. Under **User**, select **Create user label**.\n  6. Enter the label name.\n  7. Select **Create**.\n\n* New dashboard\n\n  1. In the Cloudflare dashboard, go to the **Security Settings** page.\n\n     [Go to **Settings**](https://dash.cloudflare.com/?to=/:account/:zone/security/settings)\n\n  2. Filter by **API abuse**.\n\n  3. Under **Endpoint labels**, select **Manage labels**.\n\n  4. Name the label and add an optional label description.\n\n  5. Apply the label to your selected endpoints.\n\n  6. Select **Create label**.\n\n  Alternatively, you can create a user-defined label via **Security** > **Web Assets**.\n\n  1. In the Cloudflare dashboard, go to the **Web Assets** page.\n\n     [Go to **Web assets**](https://dash.cloudflare.com/?to=/:account/:zone/security/web-assets)\n\n  2. Go to the **Endpoints** tab.\n\n  3. Choose the endpoint that you want to label.\n\n  4. Select **Edit endpoint labels**.\n\n  5. Under **User**, select **Create user label**.\n\n  6. Enter the label name.\n\n  7. Select **Create**.\n\n## Apply a label to an individual endpoint\n\n* Old dashboard\n\n  1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com/), and select your account and domain.\n  2. Go to **Security** > **API Shield**.\n  3. In the **Endpoint Management** tab, choose the endpoint that you want to label.\n  4. Select **Edit labels**.\n  5. Add the label(s) that you want to use for the endpoint from the list of managed and user-defined labels.\n  6. Select **Save labels**.\n\n* New dashboard\n\n  1. In the Cloudflare dashboard, go to the **Web assets** page.\n\n     [Go to **Web assets**](https://dash.cloudflare.com/?to=/:account/:zone/security/web-assets)\n\n  2. In the **Endpoints** tab, choose the endpoint that you want to label.\n\n  3. Select **Edit endpoint labels**.\n\n  4. Add the label(s) that you want to use for the endpoint from the list of managed and user-defined labels.\n\n  5. Select **Save labels**.\n\n## Bulk apply labels to multiple endpoints\n\n* Old dashboard\n\n  1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com/), and select your account and domain.\n  2. Go to **Security** > **Settings** > **Labels**.\n  3. On the existing label that you want to apply to multiple endpoints, select **Bulk apply**.\n  4. Choose the endpoints that you want to label by selecting its checkbox.\n  5. Select **Save label**.\n\n* New dashboard\n\n  1. In the Cloudflare dashboard, go to the **Security Settings** page.\n\n     [Go to **Settings**](https://dash.cloudflare.com/?to=/:account/:zone/security/settings)\n\n  2. Filter by **API abuse**.\n\n  3. On **Endpoint labels**, select **Manage labels**.\n\n  4. On the existing label that you want to apply to multiple endpoints, select **Bulk apply**.\n\n  5. Choose the endpoints that you want to label by selecting its checkbox.\n\n  6. Select **Apply label**.\n\n## Availability\n\nEndpoint labeling is available to all customers.\n\n</page>\n\n<page>\n---\ntitle: Build developer portals · Cloudflare API Shield docs\ndescription: Once your endpoints are saved, API Shield doubles as an API\n  catalog. API Shield can build an interactive documentation portal with the\n  knowledge it has of your APIs, or you can upload a new OpenAPI schema file to\n  build a documentation portal ad-hoc.\nlastUpdated: 2025-09-26T21:09:24.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/api-shield/management-and-monitoring/developer-portal/\n  md: https://developers.cloudflare.com/api-shield/management-and-monitoring/developer-portal/index.md\n---\n\nOnce your endpoints are saved, API Shield doubles as an API catalog. API Shield can build an interactive documentation portal with the knowledge it has of your APIs, or you can upload a new OpenAPI schema file to build a documentation portal ad-hoc.\n\nTo create a developer portal:\n\n* Old dashboard\n\n  1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com/), and select your account and domain.\n\n  2. Go to **Security** > **API Shield** > **Settings**.\n\n  3. Under **Create a developer portal**, select **Create site**.\n\n  4. Upload an OpenAPI v3.0 schema file or choose to select an existing schema from API Shield.\n\n     Note\n\n     If you do not have a schema to upload or to select from a pre-existing schema, export your Endpoint Management schema. For best results, include the learned parameters.\n\n     Only API schemas uploaded to Schema validation 2.0 are available when selecting existing schemas.\n\n  5. Select **Download project files** to save a local copy of the files that will be uploaded to Cloudflare Pages. Downloading the project files can be helpful if you wish to modify the project in any way and then upload the new version manually to Pages.\n\n  6. Select **Create pages project** to begin project creation. A new Pages project will be automatically created and your API schema will be automatically uploaded to the project along with other supporting static content.\n\n  7. Select **Deploy site**.\n\n* New dashboard\n\n  1. In the Cloudflare dashboard, go to the **Security Settings** page.\n\n     [Go to **Settings**](https://dash.cloudflare.com/?to=/:account/:zone/security/settings)\n\n  2. Filter by **API abuse**.\n\n  3. On **Create a developer portal**, select **Create site**.\n\n  4. Upload an OpenAPI v3.0 schema file or choose to select an existing schema from API Shield.\n\n     Note\n\n     If you do not have a schema to upload or to select from a pre-existing schema, export your Endpoint Management schema. For best results, include the learned parameters.\n\n     Only API schemas uploaded to Schema validation 2.0 are available when selecting existing schemas.\n\n  5. Select **Download project files** to save a local copy of the files that will be uploaded to Cloudflare Pages. Downloading the project files can be helpful if you wish to modify the project in any way and then upload the new version manually to Pages.\n\n  6. Select **Create pages project** to begin project creation. A new Pages project will be automatically created and your API schema will be automatically uploaded to the project along with other supporting static content.\n\n  7. Select **Deploy site**.\n\n### Custom domains\n\nTo create a vanity domain instead of using the pages.dev domain, refer to the [Pages custom domain documentation](https://developers.cloudflare.com/pages/configuration/custom-domains/).\n\n## Availability\n\nBuilding developer portals is available to all API Shield subscribers. This feature uses Cloudflare Pages to host the resulting portal. Refer to [Pages](https://developers.cloudflare.com/pages/) for any limitations of your current subscription plan.\n\n## Limitations\n\nThis feature currently uses the open source [Redoc](https://github.com/Redocly/redoc) project from [Redocly](https://redocly.com/). For custom theme and branding options, visit the [Redoc GitHub repository](https://github.com/Redocly/redoc).\n\nTo modify the resulting page, download the project files before creating the Pages project. You can create a new Pages project with the modified files you have made to meet your branding guidelines.\n\n</page>\n\n<page>\n---\ntitle: Endpoint Management · Cloudflare API Shield docs\ndescription: Monitor the health of your API endpoints by saving, updating, and\n  monitoring performance metrics using API Shield’s Endpoint Management.\nlastUpdated: 2025-10-08T15:21:13.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/api-shield/management-and-monitoring/endpoint-management/\n  md: https://developers.cloudflare.com/api-shield/management-and-monitoring/endpoint-management/index.md\n---\n\nAvailable on all plans\n\nMonitor the health of your API endpoints by saving, updating, and monitoring performance metrics using API Shield’s Endpoint Management.\n\n**Add endpoints** allows customers to save endpoints directly from [API Discovery](https://developers.cloudflare.com/api-shield/security/api-discovery/) or manually by method, path, and host.\n\nThis will add the specified endpoints to your list of managed endpoints. You can view your list of saved endpoints in the **Endpoint Management** page.\n\nCloudflare will start collecting [performance data](https://developers.cloudflare.com/api-shield/management-and-monitoring/#endpoint-analysis) on your endpoint when you save an endpoint.\n\nNote\n\nWhen an endpoint is using [Cloudflare Workers](https://developers.cloudflare.com/workers/), the metrics data will not be populated.\n\n## Access\n\n* Old dashboard\n\n  1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com/login), and select your account and domain.\n  2. Select **Security** > **API Shield**.\n  3. Add your endpoints [manually](#add-endpoints-manually), from [Schema validation](#add-endpoints-from-schema-validation), or from [API Discovery](#add-endpoints-from-api-discovery).\n\n* New dashboard\n\n  1. In the Cloudflare dashboard, go to the **Web Assets** page.\n\n     [Go to **Web assets**](https://dash.cloudflare.com/?to=/:account/:zone/security/web-assets)\n\n  2. Go to the **Endpoints** tab.\n\n  3. Select **Add endpoints**.\n\n  4. Add your endpoints [manually](#add-endpoints-manually), from [Schema validation](#add-endpoints-from-schema-validation), or from [API Discovery](#add-endpoints-from-api-discovery).\n\n### Add endpoints from API Discovery\n\nThere are two ways to add API endpoints from Discovery.\n\n#### Add from the Endpoints tab\n\n* Old dashboard\n\n  1. From **Endpoint Management**, select **Add endpoints** > **Select from Discovery** tab.\n  2. Select the discovered endpoints you would like to add.\n  3. Select **Add endpoints**.\n\n* New dashboard\n\n  1. From **Endpoints**, go to **Add endpoints** > **Select from Discovery** tab.\n  2. Select the discovered endpoints you would like to add.\n  3. Select **Add endpoints**.\n\n#### Add from the Discovery tab\n\n* Old dashboard\n\n  1. From Endpoint Management, select the **Discovery** tab.\n  2. Select the discovered endpoints you would like to add.\n  3. Select **Save selected endpoints**.\n\n* New dashboard\n\n  1. From **Web assets**, go to the **Discovery** tab.\n  2. Select the discovered endpoints you would like to add.\n  3. Select **Save selected endpoints**.\n\n### Add endpoints from Schema validation\n\n* Old dashboard\n\n  1. Add a schema by [configuring Schema validation](https://developers.cloudflare.com/api-shield/security/schema-validation/).\n  2. On **Review schema endpoints**, save new endpoints to endpoint management by checking the box.\n  3. Select **Save as draft** or **Save and Deploy**. Endpoints will be saved regardless of whether the schema is saved as a draft or published.\n\n* New dashboard\n\n  1. From **Web assets**, go to the **Endpoints** tab.\n  2. Select **Add endpoints** > **Upload Schema**.\n  3. Upload a schema file.\n  4. Select **Add schema and endpoints**.\n\nAPI Shield will look for duplicate endpoints that have the same host, method, and path. Duplicate endpoints will not be saved to endpoint management.\n\nNote\n\nIf you deselect **Save new endpoints to endpoint management**, the endpoints will not be added.\n\n### Add endpoints manually\n\n* Old dashboard\n\n  1. From Endpoint Management, select **Add endpoints** > **Manually add**.\n  2. Choose the method from the dropdown menu and add the path and hostname for the endpoint.\n  3. Select **Add endpoints**.\n\n* New dashboard\n\n  1. From **Web assets**, go to the **Endpoints** tab.\n  2. Select **Add endpoints** > **Manually add**.\n  3. Choose the method from the dropdown menu and add the path and hostname for the endpoint.\n  4. Select **Add endpoints**.\n\nNote\n\nBy selecting multiple checkboxes, you can add several endpoints from Discovery at once instead of individually.\n\nWhen adding an endpoint manually, you can specify variable fields in the path or host by enclosing them in braces, `/api/user/{var1}/details` or `{hostVar1}.example.com`.\n\nCloudflare supports hostname variables in the following formats:",
      "language": "unknown"
    },
    {
      "code": "Hostname variables must comprise the entire domain field and must not be used with other text in the field.\n\nThe following format is not supported:",
      "language": "unknown"
    },
    {
      "code": "For more information on how Cloudflare uses variables in API Shield, refer to the examples from [API Discovery](https://developers.cloudflare.com/api-shield/security/api-discovery/).\n\n### Delete endpoints manually\n\nYou can delete endpoints one at a time or in bulk.\n\n* Old dashboard\n\n  1. From Endpoint Management, select the checkboxes for the endpoints that you want to delete.\n  2. Select **Delete endpoints**.\n\n* New dashboard\n\n  1. From **Web assets**, go to the **Endpoints** tab.\n  2. Select the checkboxes for the endpoints that you want to delete.\n  3. Select **Delete endpoints**.\n\nWarning\n\nWhen you delete an endpoint from Endpoint Management, Cloudflare immediately stops tracking all associated performance and analytics data. The endpoint's previous historical metrics are permanently removed and cannot be restored. If you later save this endpoint again, metric tracking will resume, starting from the point the endpoint is re-saved.\n\n## Endpoint Analysis\n\nFor each saved endpoint, customers can view:\n\n* **Request count**: The total number of requests to the endpoint over time.\n* **Rate limiting recommendation**: per 10 minutes. This is guided by the request count.\n* **Latency**: The average origin response time in milliseconds (ms). This metric shows how long it takes from the moment a visitor makes a request to the moment the visitor gets a response back from the origin.\n* **Error rate** vs. overall traffic: grouped by 4xx, 5xx, and their sum.\n* **Response size**: The average size of the response (in bytes) returned to the request.\n* **Labels**: The current [labels](https://developers.cloudflare.com/api-shield/management-and-monitoring/endpoint-labels/) assigned to the endpoint.\n* **[Authentication status](https://developers.cloudflare.com/api-shield/security/authentication-posture/)**: The breakdown of which [session identifiers](https://developers.cloudflare.com/api-shield/get-started/#session-identifiers) were seen on successful requests to this endpoint.\n* **Sequences**: The number of [Sequence Analytics](https://developers.cloudflare.com/api-shield/security/sequence-analytics/) sequences the endpoint was found in.\n\nNote\n\nCustomers viewing analytics have the ability to toggle detailed metrics view between the last 24 hours and 7 days.\n\n## Using the Cloudflare API\n\nYou can interact with Endpoint Management through the Cloudflare API. Refer to [Endpoint Management’s API documentation](https://developers.cloudflare.com/api/resources/api_gateway/subresources/discovery/subresources/operations/methods/list/) for more information.\n\n## Sensitive Data Detection\n\nSensitive data comprises various personally identifiable information and financial data. Cloudflare created this ruleset to address common data loss threats, and the WAF can search for this data in HTTP response bodies from your origin.\n\nAPI Shield will alert users to the presence of sensitive data in the response body of API endpoints listed in Endpoint Management if the zone is also subscribed to the [Sensitive Data Detection managed ruleset](https://developers.cloudflare.com/waf/managed-rules/reference/sensitive-data-detection/).\n\nSensitive Data Detection is available to Enterprise customers on our Advanced application security plan.\n\nOnce Sensitive Data Detection is enabled for your zone, API Shield queries firewall events from the WAF for the last seven days and places a notification icon on the Endpoint Management table row if there are any matched sensitive responses for your endpoint.\n\nAPI Shield displays the types of sensitive data found if you expand the Endpoint Management table row to view further details. Select **Explore Events** to view the matched events in Security Events.\n\nAfter Sensitive Data Detection is enabled for your zone, you can [browse the Sensitive Data Detection ruleset](https://dash.cloudflare.com/?to=/:account/:zone/security/data/ruleset/e22d83c647c64a3eae91b71b499d988e/rules). The link will not work if Sensitive Data Detection is not enabled.\n\n## Limitations\n\nCertain performance metrics, such as latency, are not supported when a request is handled by a Cloudflare service in a way that prevents it from being passed directly to your origin server.\n\nThis limitation is specifically observed when:\n\n* A Cloudflare Worker is running on the URL path.\n* Other products built on top of Workers, such as [Waiting Room](https://developers.cloudflare.com/waiting-room/), are active on the application.\n\nIn these scenarios, the system is unable to accurately measure the origin response time, and the metric will not be populated in the dashboard.\n\n</page>\n\n<page>\n---\ntitle: Session identifiers · Cloudflare API Shield docs\ndescription: While not strictly required, it is recommended that you configure\n  your session identifiers when getting started with API Shield. When Cloudflare\n  inspects your API traffic for individual sessions, we can offer more tools for\n  visibility, management, and control.\nlastUpdated: 2025-08-20T18:25:25.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/api-shield/management-and-monitoring/session-identifiers/\n  md: https://developers.cloudflare.com/api-shield/management-and-monitoring/session-identifiers/index.md\n---\n\nWhile not strictly required, it is recommended that you configure your session identifiers when getting started with API Shield. When Cloudflare inspects your API traffic for individual sessions, we can offer more tools for visibility, management, and control.\n\nIf you are unsure of the session identifiers that your API uses, consult with your development team.\n\nSession identifiers should uniquely identify API clients. A common session identifier for API traffic is the `Authorization` header. When a [JSON Web Token (JWT)](https://developers.cloudflare.com/api-shield/security/jwt-validation/) is used by the API for client authentication, its value may change over time. You can use a claim value inside the JWT such as `sub` or `email` as a session ID to uniquely identify the session over time.\n\nIf your API uses the `Authorization` header on more than 1% of successful requests to your zone, Cloudflare will automatically set it as the API Shield session identifier.\n\nNote\n\nYou must have specific entitlements to configure session identifiers or cookies as a form of identifiers, such as an Enterprise subscription, for features such as [API Discovery](https://developers.cloudflare.com/api-shield/security/api-discovery/), [Sequence Mitigation](https://developers.cloudflare.com/api-shield/security/sequence-mitigation/) or [rate limiting recommendations](https://developers.cloudflare.com/api-shield/security/volumetric-abuse-detection/), and to see results in [Sequence Analytics](https://developers.cloudflare.com/api-shield/security/sequence-analytics/) and [Authentication Posture](https://developers.cloudflare.com/api-shield/security/authentication-posture/).\n\n## To set up session identifiers\n\n* Old dashboard\n\n  1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com/login), and select your account and domain.\n\n  2. Go to **Security** > **API Shield**.\n\n  3. Select **Settings**.\n\n  4. On **Endpoint settings**, select **Manage identifiers**.\n\n  5. Choose the type of session identifier (cookie, HTTP header, or JWT claim).\n\n     Note\n\n     The session identifier cookie must comply with RFC 6265. Otherwise, it will be rejected.\n\n     If you are using a JWT claim, choose the [Token Configuration](https://developers.cloudflare.com/api-shield/security/jwt-validation/api/#token-configurations) that will verify the JWT. Token Configurations are required to use JWT claims as session identifiers. Refer to [JWT Validation](https://developers.cloudflare.com/api-shield/security/jwt-validation/) for more information.\n\n  6. Enter the name of the session identifier.\n\n  7. Select **Save**.\n\n* New dashboard\n\n  1. In the Cloudflare dashboard, go to the **Security Settings** page.\n\n     [Go to **Settings**](https://dash.cloudflare.com/?to=/:account/:zone/security/settings)\n\n  2. Filter by **API abuse**.\n\n  3. On **Session identifiers**, select **Configure session identifiers**.\n\n  4. Select **Manage identifiers**.\n\n  5. Choose the type of session identifier (cookie, HTTP header, or JWT claim).\n\n     Note\n\n     The session identifier cookie must comply with RFC 6265. Otherwise, it will be rejected.\n\n     If you are using a JWT claim, choose the [Token Configuration](https://developers.cloudflare.com/api-shield/security/jwt-validation/api/#token-configurations) that will verify the JWT. Token Configurations are required to use JWT claims as session identifiers. Refer to [JWT Validation](https://developers.cloudflare.com/api-shield/security/jwt-validation/) for more information.\n\n  6. Enter the name of the session identifier.\n\n  7. Select **Save**.\n\nAfter setting up session identifiers and allowing some time for Cloudflare to learn your traffic patterns, you can view your per endpoint and per session rate limiting recommendations, as well as enforce per endpoint and per session rate limits by creating new rules. Session identifiers will allow you to view API Discovery results from session ID-based discovery and session traffic patterns in Sequence Analytics.\n\n</page>\n\n<page>\n---\ntitle: Configure Classic Schema validation (deprecated) · Cloudflare API Shield docs\ndescription: Use the API Shield interface to configure API Schema validation,\n  which validates requests according to the API schema you provide.\nlastUpdated: 2025-08-18T14:27:42.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/api-shield/reference/classic-schema-validation/\n  md: https://developers.cloudflare.com/api-shield/reference/classic-schema-validation/index.md\n---\n\nDeprecation notice\n\nClassic Schema validation has been deprecated.\n\nUpload all new schemas to [Schema validation 2.0](https://developers.cloudflare.com/api-shield/security/schema-validation/).\n\nUse the **API Shield** interface to configure [API Schema validation](https://developers.cloudflare.com/api-shield/security/schema-validation/), which validates requests according to the API schema you provide.\n\nBefore you can configure Schema validation for an API, you must obtain an API Schema file matching our [specifications](https://developers.cloudflare.com/api-shield/security/schema-validation/#specifications).\n\nIf you are in the Schema validation 2.0, you can make changes to your settings but you cannot add any new Classic Schema validation schemas.\n\nNote\n\nThis feature is only available for customers on an Enterprise plan. Contact your Cloudflare Customer Success Manager to get access.\n\n## Create an API Shield with Schema validation\n\nTo configure Schema validation in the Cloudflare dashboard:\n\n1. Log in to the [Cloudflare dashboard](https://dash.cloudflare.com) and select your account and domain.\n2. Select **Security** > **API Shield**.\n3. Go to **Schema validation** and select **Add schema**.\n4. Enter a descriptive name for your policy and optionally edit the expression to trigger Schema validation. For example, if your API is available at `http://api.example.com/v1`, include a check for the *Hostname* field — equal to `api.example.com` — and a check for the *URI Path* field using a regular expression — matching the regex `^/v1`.\n\nImportant\n\nTo validate the hostname, you must include the *Hostname* field explicitly in the rule, even if the hostname value is in the schema file. Any hostname value present in the schema file will be ignored.\n\n1. Select **Next**.\n2. Upload your schema file.\n3. Select **Save** to validate the content of the schema file and deploy the Schema validation rule. If you get a validation error, ensure that you are using one of the [supported file formats](https://developers.cloudflare.com/api-shield/security/schema-validation/#specifications) and that each endpoint and method pair has a unique operation ID.\n\nAfter deploying your API Shield rule, Cloudflare displays a summary of all API endpoints organized by their protection level and actions that will occur for non-compliant and unprotected requests.\n\n1. In the **Endpoint action** dropdown, select an action for every request that targets a protected endpoint and fails Schema validation.\n2. In the **Fallthrough action** dropdown, select an action for every request that targets an unprotected endpoint.\n3. Optionally, you can save the endpoints to Endpoint Management at the same time the Schema is saved by selecting **Save new endpoints to [endpoint management](https://developers.cloudflare.com/api-shield/management-and-monitoring/)**. Endpoints will be saved regardless of whether the Schema is saved as a draft or published live.\n4. Select **Done**.\n\n</page>\n\n<page>\n---\ntitle: Terraform · Cloudflare API Shield docs\ndescription: Get started with API Shield using Terraform from the examples\n  below. For more information on how to use Terraform with Cloudflare, refer to\n  the Terraform documentation.\nlastUpdated: 2025-11-21T16:32:37.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/api-shield/reference/terraform/\n  md: https://developers.cloudflare.com/api-shield/reference/terraform/index.md\n---\n\nGet started with API Shield using Terraform from the examples below. For more information on how to use Terraform with Cloudflare, refer to the [Terraform documentation](https://developers.cloudflare.com/terraform/).\n\nThe following resources are available to configure through Terraform:\n\n**Session identifiers**\n\n* [`api_shield`](https://registry.terraform.io/providers/cloudflare/cloudflare/latest/docs/resources/api_shield) for configuring session identifiers in API Shield.\n\n**Endpoint Management**\n\n* [`api_shield_operation`](https://registry.terraform.io/providers/cloudflare/cloudflare/latest/docs/resources/api_shield_operation) for configuring endpoints in Endpoint Management.\n\n**Schema validation**\n\n* [`cloudflare_schema_validation_schemas`](https://registry.terraform.io/providers/cloudflare/cloudflare/latest/docs/resources/schema_validation_schemas) for configuring a schema in [Schema validation](https://developers.cloudflare.com/api-shield/security/schema-validation/). has been deprecated and will be removed in a future version of the terraform provider.\n* [`cloudflare_schema_validation_settings`](https://registry.terraform.io/providers/cloudflare/cloudflare/latest/docs/resources/schema_validation_settings) for configuring zone-level Schema validation settings. has been deprecated and will be removed in a future version of the terraform provider.\n* [`cloudflare_schema_validation_operation_settings`](https://registry.terraform.io/providers/cloudflare/cloudflare/latest/docs/resources/schema_validation_operation_settings) for configuring operation-level Schema validation settings. has been deprecated and will be removed in a future version of the terraform provider.\n\n**JWT Validation**\n\n* [`cloudflare_token_validation_config`](https://registry.terraform.io/providers/cloudflare/cloudflare/latest/docs/resources/token_validation_config) for setting up JWT validation with specific keying material and token locations.\n* [`cloudflare_token_validation_rules`](https://registry.terraform.io/providers/cloudflare/cloudflare/latest/docs/resources/token_validation_rules) for setting up rules to action on the validation result.\n\n## Manage API Shield session identifiers\n\nRefer to the example configuration below to set up [session identifiers](https://developers.cloudflare.com/api-shield/get-started/#to-set-up-session-identifiers) on your zone.",
      "language": "unknown"
    },
    {
      "code": "## Manage API Shield Endpoint Management\n\nRefer to the example configuration below to [manage endpoints](https://developers.cloudflare.com/api-shield/management-and-monitoring/) on your zone.",
      "language": "unknown"
    },
    {
      "code": "## Manage Schema validation\n\nNote\n\nIt is required to configure Endpoint Management if you want to set up Schema validation using Terraform.\n\nRefer to the example configuration below to manage [Schema validation](https://developers.cloudflare.com/api-shield/security/schema-validation/api/) on your zone.",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Running Agents locally",
      "id": "running-agents-locally"
    },
    {
      "level": "h2",
      "text": "Deploy your first ChatGPT App",
      "id": "deploy-your-first-chatgpt-app"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "1. Enable ChatGPT Developer Mode",
      "id": "1.-enable-chatgpt-developer-mode"
    },
    {
      "level": "h2",
      "text": "2. Create your ChatGPT App project",
      "id": "2.-create-your-chatgpt-app-project"
    },
    {
      "level": "h2",
      "text": "3. Configure your project",
      "id": "3.-configure-your-project"
    },
    {
      "level": "h2",
      "text": "4. Create the Chess game engine",
      "id": "4.-create-the-chess-game-engine"
    },
    {
      "level": "h2",
      "text": "5. Create the MCP server and UI resource",
      "id": "5.-create-the-mcp-server-and-ui-resource"
    },
    {
      "level": "h2",
      "text": "6. Build the React UI",
      "id": "6.-build-the-react-ui"
    },
    {
      "level": "h2",
      "text": "7. Build and deploy",
      "id": "7.-build-and-deploy"
    },
    {
      "level": "h2",
      "text": "8. Connect to ChatGPT",
      "id": "8.-connect-to-chatgpt"
    },
    {
      "level": "h2",
      "text": "9. Play chess in ChatGPT",
      "id": "9.-play-chess-in-chatgpt"
    },
    {
      "level": "h2",
      "text": "Key concepts",
      "id": "key-concepts"
    },
    {
      "level": "h3",
      "text": "MCP Server",
      "id": "mcp-server"
    },
    {
      "level": "h3",
      "text": "Game Engine with Agents",
      "id": "game-engine-with-agents"
    },
    {
      "level": "h3",
      "text": "Callable methods",
      "id": "callable-methods"
    },
    {
      "level": "h3",
      "text": "React integration",
      "id": "react-integration"
    },
    {
      "level": "h3",
      "text": "Bidirectional communication",
      "id": "bidirectional-communication"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "What you will build",
      "id": "what-you-will-build"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "1. Create a basic Agent",
      "id": "1.-create-a-basic-agent"
    },
    {
      "level": "h2",
      "text": "2. Add MCP connection endpoint",
      "id": "2.-add-mcp-connection-endpoint"
    },
    {
      "level": "h2",
      "text": "3. Test the connection",
      "id": "3.-test-the-connection"
    },
    {
      "level": "h2",
      "text": "4. List available tools",
      "id": "4.-list-available-tools"
    },
    {
      "level": "h2",
      "text": "Summary",
      "id": "summary"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "Build an AI Agent with Human Oversight",
      "id": "build-an-ai-agent-with-human-oversight"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "1. Create your project",
      "id": "1.-create-your-project"
    },
    {
      "level": "h2",
      "text": "2. Set up your environment variables",
      "id": "2.-set-up-your-environment-variables"
    },
    {
      "level": "h2",
      "text": "3. Define your tools",
      "id": "3.-define-your-tools"
    },
    {
      "level": "h2",
      "text": "4. Create utility functions",
      "id": "4.-create-utility-functions"
    },
    {
      "level": "h2",
      "text": "5. Create your Agent",
      "id": "5.-create-your-agent"
    },
    {
      "level": "h2",
      "text": "6. Build the React frontend",
      "id": "6.-build-the-react-frontend"
    },
    {
      "level": "h2",
      "text": "7. Test locally",
      "id": "7.-test-locally"
    },
    {
      "level": "h3",
      "text": "Test the approval flow",
      "id": "test-the-approval-flow"
    },
    {
      "level": "h3",
      "text": "Test automatic tools",
      "id": "test-automatic-tools"
    },
    {
      "level": "h2",
      "text": "8. Deploy to production",
      "id": "8.-deploy-to-production"
    },
    {
      "level": "h2",
      "text": "How it works",
      "id": "how-it-works"
    },
    {
      "level": "h3",
      "text": "Tool approval flow",
      "id": "tool-approval-flow"
    },
    {
      "level": "h3",
      "text": "Message streaming with confirmations",
      "id": "message-streaming-with-confirmations"
    },
    {
      "level": "h3",
      "text": "State persistence",
      "id": "state-persistence"
    },
    {
      "level": "h2",
      "text": "Customizing your agent",
      "id": "customizing-your-agent"
    },
    {
      "level": "h3",
      "text": "Add more tools requiring confirmation",
      "id": "add-more-tools-requiring-confirmation"
    },
    {
      "level": "h3",
      "text": "Implement custom tool handlers",
      "id": "implement-custom-tool-handlers"
    },
    {
      "level": "h3",
      "text": "Customize the approval UI",
      "id": "customize-the-approval-ui"
    },
    {
      "level": "h3",
      "text": "Use different LLM providers",
      "id": "use-different-llm-providers"
    },
    {
      "level": "h2",
      "text": "Best practices",
      "id": "best-practices"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "How it works",
      "id": "how-it-works"
    },
    {
      "level": "h2",
      "text": "Initiate OAuth",
      "id": "initiate-oauth"
    },
    {
      "level": "h3",
      "text": "Alternative approaches",
      "id": "alternative-approaches"
    },
    {
      "level": "h2",
      "text": "Configure callback behavior",
      "id": "configure-callback-behavior"
    },
    {
      "level": "h3",
      "text": "Redirect to your application",
      "id": "redirect-to-your-application"
    },
    {
      "level": "h3",
      "text": "Close popup window",
      "id": "close-popup-window"
    },
    {
      "level": "h2",
      "text": "Monitor connection status",
      "id": "monitor-connection-status"
    },
    {
      "level": "h3",
      "text": "React applications",
      "id": "react-applications"
    },
    {
      "level": "h3",
      "text": "Other frameworks",
      "id": "other-frameworks"
    },
    {
      "level": "h2",
      "text": "Handle failures",
      "id": "handle-failures"
    },
    {
      "level": "h2",
      "text": "Complete example",
      "id": "complete-example"
    },
    {
      "level": "h2",
      "text": "Related",
      "id": "related"
    },
    {
      "level": "h2",
      "text": "Deploy your first MCP server",
      "id": "deploy-your-first-mcp-server"
    },
    {
      "level": "h3",
      "text": "Set up and deploy your MCP server via CLI",
      "id": "set-up-and-deploy-your-mcp-server-via-cli"
    },
    {
      "level": "h3",
      "text": "Connect your Remote MCP server to Claude and other MCP Clients via a local proxy",
      "id": "connect-your-remote-mcp-server-to-claude-and-other-mcp-clients-via-a-local-proxy"
    },
    {
      "level": "h2",
      "text": "Add Authentication",
      "id": "add-authentication"
    },
    {
      "level": "h3",
      "text": "Step 1 — Create a new MCP server",
      "id": "step-1-—-create-a-new-mcp-server"
    },
    {
      "level": "h3",
      "text": "Step 2 — Create an OAuth App",
      "id": "step-2-—-create-an-oauth-app"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "Deploy your first Slack Agent",
      "id": "deploy-your-first-slack-agent"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "1. Create a Slack App",
      "id": "1.-create-a-slack-app"
    },
    {
      "level": "h3",
      "text": "Configure OAuth & Permissions",
      "id": "configure-oauth-&-permissions"
    },
    {
      "level": "h3",
      "text": "Enable Event Subscriptions",
      "id": "enable-event-subscriptions"
    },
    {
      "level": "h3",
      "text": "Get your Slack credentials",
      "id": "get-your-slack-credentials"
    },
    {
      "level": "h2",
      "text": "2. Create your Slack Agent project",
      "id": "2.-create-your-slack-agent-project"
    },
    {
      "level": "h2",
      "text": "3. Set up your environment variables",
      "id": "3.-set-up-your-environment-variables"
    },
    {
      "level": "h2",
      "text": "4. Create your Slack Agent",
      "id": "4.-create-your-slack-agent"
    },
    {
      "level": "h2",
      "text": "5. Test locally",
      "id": "5.-test-locally"
    },
    {
      "level": "h3",
      "text": "Configure Slack Event Subscriptions",
      "id": "configure-slack-event-subscriptions"
    },
    {
      "level": "h3",
      "text": "Install your app to Slack",
      "id": "install-your-app-to-slack"
    },
    {
      "level": "h3",
      "text": "Test your agent",
      "id": "test-your-agent"
    },
    {
      "level": "h2",
      "text": "6. Deploy to production",
      "id": "6.-deploy-to-production"
    },
    {
      "level": "h3",
      "text": "Update Slack Event Subscriptions",
      "id": "update-slack-event-subscriptions"
    },
    {
      "level": "h3",
      "text": "Distribute your app",
      "id": "distribute-your-app"
    },
    {
      "level": "h2",
      "text": "How it works",
      "id": "how-it-works"
    },
    {
      "level": "h3",
      "text": "Multi-tenancy with Durable Objects",
      "id": "multi-tenancy-with-durable-objects"
    },
    {
      "level": "h3",
      "text": "OAuth flow",
      "id": "oauth-flow"
    },
    {
      "level": "h3",
      "text": "Event handling",
      "id": "event-handling"
    },
    {
      "level": "h2",
      "text": "Customizing your agent",
      "id": "customizing-your-agent"
    },
    {
      "level": "h3",
      "text": "Change the AI model",
      "id": "change-the-ai-model"
    },
    {
      "level": "h3",
      "text": "Add conversation memory",
      "id": "add-conversation-memory"
    },
    {
      "level": "h3",
      "text": "React to specific keywords",
      "id": "react-to-specific-keywords"
    },
    {
      "level": "h3",
      "text": "Use different LLM providers",
      "id": "use-different-llm-providers"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "The Model Context Protocol (MCP) inspector",
      "id": "the-model-context-protocol-(mcp)-inspector"
    },
    {
      "level": "h2",
      "text": "Connect your remote MCP server to Cloudflare Workers AI Playground",
      "id": "connect-your-remote-mcp-server-to-cloudflare-workers-ai-playground"
    },
    {
      "level": "h2",
      "text": "Connect your remote MCP server to Claude Desktop via a local proxy",
      "id": "connect-your-remote-mcp-server-to-claude-desktop-via-a-local-proxy"
    },
    {
      "level": "h2",
      "text": "Connect your remote MCP server to Cursor",
      "id": "connect-your-remote-mcp-server-to-cursor"
    },
    {
      "level": "h2",
      "text": "Connect your remote MCP server to Windsurf",
      "id": "connect-your-remote-mcp-server-to-windsurf"
    },
    {
      "level": "h2",
      "text": "Authorization options",
      "id": "authorization-options"
    },
    {
      "level": "h3",
      "text": "(1) Your MCP Server handles authorization and authentication itself",
      "id": "(1)-your-mcp-server-handles-authorization-and-authentication-itself"
    },
    {
      "level": "h3",
      "text": "(2) Cloudflare Access integration",
      "id": "(2)-cloudflare-access-integration"
    },
    {
      "level": "h3",
      "text": "(3) Third-party OAuth Provider",
      "id": "(3)-third-party-oauth-provider"
    },
    {
      "level": "h3",
      "text": "(4) Bring your own OAuth Provider",
      "id": "(4)-bring-your-own-oauth-provider"
    },
    {
      "level": "h2",
      "text": "Using Authentication Context in Your MCP Server",
      "id": "using-authentication-context-in-your-mcp-server"
    },
    {
      "level": "h2",
      "text": "Implementing Permission-Based Access for MCP Tools",
      "id": "implementing-permission-based-access-for-mcp-tools"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h3",
      "text": "State synchronization APIs",
      "id": "state-synchronization-apis"
    },
    {
      "level": "h3",
      "text": "Not yet supported APIs",
      "id": "not-yet-supported-apis"
    },
    {
      "level": "h2",
      "text": "Agent MCP Client Methods",
      "id": "agent-mcp-client-methods"
    },
    {
      "level": "h3",
      "text": "`addMcpServer()`",
      "id": "`addmcpserver()`"
    },
    {
      "level": "h3",
      "text": "`removeMcpServer()`",
      "id": "`removemcpserver()`"
    },
    {
      "level": "h3",
      "text": "`getMcpServers()`",
      "id": "`getmcpservers()`"
    },
    {
      "level": "h2",
      "text": "Lifecycle Methods",
      "id": "lifecycle-methods"
    },
    {
      "level": "h3",
      "text": "`this.mcp.registerServer()`",
      "id": "`this.mcp.registerserver()`"
    },
    {
      "level": "h3",
      "text": "`this.mcp.connectToServer()`",
      "id": "`this.mcp.connecttoserver()`"
    },
    {
      "level": "h3",
      "text": "`this.mcp.discoverIfConnected()`",
      "id": "`this.mcp.discoverifconnected()`"
    },
    {
      "level": "h3",
      "text": "`this.mcp.closeConnection()`",
      "id": "`this.mcp.closeconnection()`"
    },
    {
      "level": "h3",
      "text": "`this.mcp.closeAllConnections()`",
      "id": "`this.mcp.closeallconnections()`"
    },
    {
      "level": "h2",
      "text": "Capabilities",
      "id": "capabilities"
    },
    {
      "level": "h3",
      "text": "`this.mcp.getAITools()`",
      "id": "`this.mcp.getaitools()`"
    },
    {
      "level": "h2",
      "text": "OAuth Configuration",
      "id": "oauth-configuration"
    },
    {
      "level": "h2",
      "text": "Error Handling",
      "id": "error-handling"
    },
    {
      "level": "h2",
      "text": "Next Steps",
      "id": "next-steps"
    },
    {
      "level": "h3",
      "text": "CreateMcpHandlerOptions",
      "id": "createmcphandleroptions"
    },
    {
      "level": "h2",
      "text": "Stateless MCP Servers",
      "id": "stateless-mcp-servers"
    },
    {
      "level": "h2",
      "text": "Stateful MCP Servers",
      "id": "stateful-mcp-servers"
    },
    {
      "level": "h3",
      "text": "WorkerTransport",
      "id": "workertransport"
    },
    {
      "level": "h2",
      "text": "Authentication Context",
      "id": "authentication-context"
    },
    {
      "level": "h3",
      "text": "getMcpAuthContext",
      "id": "getmcpauthcontext"
    },
    {
      "level": "h2",
      "text": "Error Handling",
      "id": "error-handling"
    },
    {
      "level": "h2",
      "text": "Related Resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Implementing remote MCP transport",
      "id": "implementing-remote-mcp-transport"
    },
    {
      "level": "h3",
      "text": "Stateful MCP servers",
      "id": "stateful-mcp-servers"
    },
    {
      "level": "h3",
      "text": "Migrating from McpAgent",
      "id": "migrating-from-mcpagent"
    },
    {
      "level": "h3",
      "text": "Testing with MCP clients",
      "id": "testing-with-mcp-clients"
    },
    {
      "level": "h2",
      "text": "Footnotes",
      "id": "footnotes"
    },
    {
      "level": "h2",
      "text": "Setting up Authenticated Gateway using the Dashboard",
      "id": "setting-up-authenticated-gateway-using-the-dashboard"
    },
    {
      "level": "h2",
      "text": "Example requests with OpenAI",
      "id": "example-requests-with-openai"
    },
    {
      "level": "h2",
      "text": "Example requests with the Vercel AI SDK",
      "id": "example-requests-with-the-vercel-ai-sdk"
    },
    {
      "level": "h2",
      "text": "Expected behavior",
      "id": "expected-behavior"
    },
    {
      "level": "h2",
      "text": "Introduction",
      "id": "introduction"
    },
    {
      "level": "h2",
      "text": "Setting up BYOK",
      "id": "setting-up-byok"
    },
    {
      "level": "h3",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h3",
      "text": "Configure API keys",
      "id": "configure-api-keys"
    },
    {
      "level": "h3",
      "text": "Update your applications",
      "id": "update-your-applications"
    },
    {
      "level": "h2",
      "text": "Example",
      "id": "example"
    },
    {
      "level": "h2",
      "text": "Managing API keys",
      "id": "managing-api-keys"
    },
    {
      "level": "h3",
      "text": "Viewing configured keys",
      "id": "viewing-configured-keys"
    },
    {
      "level": "h3",
      "text": "Rotating keys",
      "id": "rotating-keys"
    },
    {
      "level": "h3",
      "text": "Revoking access",
      "id": "revoking-access"
    },
    {
      "level": "h2",
      "text": "Custom cost",
      "id": "custom-cost"
    },
    {
      "level": "h2",
      "text": "Overview",
      "id": "overview"
    },
    {
      "level": "h2",
      "text": "Use cases",
      "id": "use-cases"
    },
    {
      "level": "h2",
      "text": "Before you begin",
      "id": "before-you-begin"
    },
    {
      "level": "h3",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h3",
      "text": "Authentication",
      "id": "authentication"
    },
    {
      "level": "h2",
      "text": "Create a custom provider",
      "id": "create-a-custom-provider"
    },
    {
      "level": "h2",
      "text": "List custom providers",
      "id": "list-custom-providers"
    },
    {
      "level": "h2",
      "text": "Get a specific custom provider",
      "id": "get-a-specific-custom-provider"
    },
    {
      "level": "h2",
      "text": "Update a custom provider",
      "id": "update-a-custom-provider"
    },
    {
      "level": "h2",
      "text": "Delete a custom provider",
      "id": "delete-a-custom-provider"
    },
    {
      "level": "h2",
      "text": "Using custom providers with AI Gateway",
      "id": "using-custom-providers-with-ai-gateway"
    },
    {
      "level": "h3",
      "text": "Via Unified API",
      "id": "via-unified-api"
    },
    {
      "level": "h3",
      "text": "Via provider-specific endpoint",
      "id": "via-provider-specific-endpoint"
    },
    {
      "level": "h2",
      "text": "Common errors",
      "id": "common-errors"
    },
    {
      "level": "h3",
      "text": "409 Conflict - Duplicate slug",
      "id": "409-conflict---duplicate-slug"
    },
    {
      "level": "h3",
      "text": "404 Not Found",
      "id": "404-not-found"
    },
    {
      "level": "h3",
      "text": "400 Bad Request - Invalid base\\_url",
      "id": "400-bad-request---invalid-base\\_url"
    },
    {
      "level": "h2",
      "text": "Best practices",
      "id": "best-practices"
    },
    {
      "level": "h2",
      "text": "Limitations",
      "id": "limitations"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Request failures",
      "id": "request-failures"
    },
    {
      "level": "h3",
      "text": "Example",
      "id": "example"
    },
    {
      "level": "h2",
      "text": "Response header(cf-aig-step)",
      "id": "response-header(cf-aig-step)"
    },
    {
      "level": "h2",
      "text": "Create gateway",
      "id": "create-gateway"
    },
    {
      "level": "h2",
      "text": "Edit gateway",
      "id": "edit-gateway"
    },
    {
      "level": "h2",
      "text": "Delete gateway",
      "id": "delete-gateway"
    },
    {
      "level": "h2",
      "text": "Request timeouts",
      "id": "request-timeouts"
    },
    {
      "level": "h3",
      "text": "Definitions",
      "id": "definitions"
    },
    {
      "level": "h3",
      "text": "Configuration",
      "id": "configuration"
    },
    {
      "level": "h2",
      "text": "Request retries",
      "id": "request-retries"
    },
    {
      "level": "h3",
      "text": "Definitions",
      "id": "definitions"
    },
    {
      "level": "h3",
      "text": "Configuration",
      "id": "configuration"
    },
    {
      "level": "h2",
      "text": "1. Log in to the dashboard",
      "id": "1.-log-in-to-the-dashboard"
    },
    {
      "level": "h2",
      "text": "2. Access the Logs tab",
      "id": "2.-access-the-logs-tab"
    },
    {
      "level": "h2",
      "text": "3. Provide human feedback",
      "id": "3.-provide-human-feedback"
    },
    {
      "level": "h2",
      "text": "4. Evaluate human feedback",
      "id": "4.-evaluate-human-feedback"
    },
    {
      "level": "h2",
      "text": "5. Review results",
      "id": "5.-review-results"
    },
    {
      "level": "h2",
      "text": "1. Create an API Token",
      "id": "1.-create-an-api-token"
    },
    {
      "level": "h2",
      "text": "2. Retrieve the `cf-aig-log-id`",
      "id": "2.-retrieve-the-`cf-aig-log-id`"
    },
    {
      "level": "h3",
      "text": "Method 1: Locate the `cf-aig-log-id` in the request response",
      "id": "method-1:-locate-the-`cf-aig-log-id`-in-the-request-response"
    },
    {
      "level": "h3",
      "text": "Method 2: Retrieve the `cf-aig-log-id` via API (GET request)",
      "id": "method-2:-retrieve-the-`cf-aig-log-id`-via-api-(get-request)"
    },
    {
      "level": "h3",
      "text": "Method 3: Retrieve the `cf-aig-log-id` via a binding",
      "id": "method-3:-retrieve-the-`cf-aig-log-id`-via-a-binding"
    },
    {
      "level": "h2",
      "text": "3. Submit feedback via PATCH request",
      "id": "3.-submit-feedback-via-patch-request"
    },
    {
      "level": "h2",
      "text": "4. Verify the feedback submission",
      "id": "4.-verify-the-feedback-submission"
    },
    {
      "level": "h2",
      "text": "1. Run an AI Evaluation",
      "id": "1.-run-an-ai-evaluation"
    },
    {
      "level": "h2",
      "text": "2. Send Human Feedback",
      "id": "2.-send-human-feedback"
    },
    {
      "level": "h2",
      "text": "Feedback parameters explanation",
      "id": "feedback-parameters-explanation"
    },
    {
      "level": "h3",
      "text": "patchLog: Send Feedback",
      "id": "patchlog:-send-feedback"
    },
    {
      "level": "h2",
      "text": "1. Select or create a dataset",
      "id": "1.-select-or-create-a-dataset"
    },
    {
      "level": "h3",
      "text": "Set up a dataset from the Logs tab",
      "id": "set-up-a-dataset-from-the-logs-tab"
    },
    {
      "level": "h3",
      "text": "List of available filters",
      "id": "list-of-available-filters"
    },
    {
      "level": "h2",
      "text": "2. Select evaluators",
      "id": "2.-select-evaluators"
    },
    {
      "level": "h2",
      "text": "3. Name, review, and run the evaluation",
      "id": "3.-name,-review,-and-run-the-evaluation"
    },
    {
      "level": "h2",
      "text": "4. Review and analyze results",
      "id": "4.-review-and-analyze-results"
    },
    {
      "level": "h2",
      "text": "Benefits of Using Caching",
      "id": "benefits-of-using-caching"
    },
    {
      "level": "h2",
      "text": "Default configuration",
      "id": "default-configuration"
    },
    {
      "level": "h2",
      "text": "Per-request caching",
      "id": "per-request-caching"
    },
    {
      "level": "h3",
      "text": "Skip cache (cf-aig-skip-cache)",
      "id": "skip-cache-(cf-aig-skip-cache)"
    },
    {
      "level": "h3",
      "text": "Cache TTL (cf-aig-cache-ttl)",
      "id": "cache-ttl-(cf-aig-cache-ttl)"
    },
    {
      "level": "h3",
      "text": "Custom cache key (cf-aig-cache-key)",
      "id": "custom-cache-key-(cf-aig-cache-key)"
    },
    {
      "level": "h2",
      "text": "How it works",
      "id": "how-it-works"
    },
    {
      "level": "h2",
      "text": "Key benefits",
      "id": "key-benefits"
    },
    {
      "level": "h2",
      "text": "Supported AI traffic",
      "id": "supported-ai-traffic"
    },
    {
      "level": "h2",
      "text": "Integration with Cloudflare DLP",
      "id": "integration-with-cloudflare-dlp"
    },
    {
      "level": "h2",
      "text": "Getting started",
      "id": "getting-started"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Introduction",
      "id": "introduction"
    },
    {
      "level": "h2",
      "text": "Core Concepts",
      "id": "core-concepts"
    },
    {
      "level": "h2",
      "text": "Getting Started",
      "id": "getting-started"
    },
    {
      "level": "h2",
      "text": "Video demo",
      "id": "video-demo"
    },
    {
      "level": "h2",
      "text": "How Guardrails work",
      "id": "how-guardrails-work"
    },
    {
      "level": "h2",
      "text": "Related resource",
      "id": "related-resource"
    },
    {
      "level": "h2",
      "text": "Parameters",
      "id": "parameters"
    },
    {
      "level": "h2",
      "text": "Handling rate limits",
      "id": "handling-rate-limits"
    },
    {
      "level": "h2",
      "text": "Default configuration",
      "id": "default-configuration"
    },
    {
      "level": "h2",
      "text": "Pre-requisites",
      "id": "pre-requisites"
    },
    {
      "level": "h2",
      "text": "Load credits",
      "id": "load-credits"
    },
    {
      "level": "h3",
      "text": "Auto-top up",
      "id": "auto-top-up"
    },
    {
      "level": "h2",
      "text": "Use Unified Billing",
      "id": "use-unified-billing"
    },
    {
      "level": "h3",
      "text": "Spend limits",
      "id": "spend-limits"
    },
    {
      "level": "h3",
      "text": "Supported providers",
      "id": "supported-providers"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "1. Create a Worker Project",
      "id": "1.-create-a-worker-project"
    },
    {
      "level": "h2",
      "text": "2. Connect your Worker to Workers AI",
      "id": "2.-connect-your-worker-to-workers-ai"
    },
    {
      "level": "h2",
      "text": "3. Run an inference task containing AI Gateway in your Worker",
      "id": "3.-run-an-inference-task-containing-ai-gateway-in-your-worker"
    },
    {
      "level": "h2",
      "text": "4. Develop locally with Wrangler",
      "id": "4.-develop-locally-with-wrangler"
    },
    {
      "level": "h2",
      "text": "5. Deploy your AI Worker",
      "id": "5.-deploy-your-ai-worker"
    },
    {
      "level": "h2",
      "text": "Installation",
      "id": "installation"
    },
    {
      "level": "h2",
      "text": "Examples",
      "id": "examples"
    },
    {
      "level": "h3",
      "text": "Fallback Providers",
      "id": "fallback-providers"
    },
    {
      "level": "h2",
      "text": "1. Add an AI Binding to your Worker",
      "id": "1.-add-an-ai-binding-to-your-worker"
    },
    {
      "level": "h2",
      "text": "2. Basic Usage with Workers AI + Gateway",
      "id": "2.-basic-usage-with-workers-ai-+-gateway"
    },
    {
      "level": "h2",
      "text": "3. Access the Gateway Binding",
      "id": "3.-access-the-gateway-binding"
    },
    {
      "level": "h3",
      "text": "3.1. `patchLog`: Send Feedback",
      "id": "3.1.-`patchlog`:-send-feedback"
    },
    {
      "level": "h3",
      "text": "3.2. `getLog`: Read Log Details",
      "id": "3.2.-`getlog`:-read-log-details"
    },
    {
      "level": "h3",
      "text": "3.3. `getUrl`: Get Gateway URLs",
      "id": "3.3.-`geturl`:-get-gateway-urls"
    },
    {
      "level": "h3",
      "text": "3.4. `run`: Universal Requests",
      "id": "3.4.-`run`:-universal-requests"
    },
    {
      "level": "h2",
      "text": "Conclusion",
      "id": "conclusion"
    },
    {
      "level": "h2",
      "text": "View analytics",
      "id": "view-analytics"
    },
    {
      "level": "h2",
      "text": "Track costs across AI providers",
      "id": "track-costs-across-ai-providers"
    },
    {
      "level": "h2",
      "text": "Custom costs",
      "id": "custom-costs"
    },
    {
      "level": "h2",
      "text": "Key Features",
      "id": "key-features"
    },
    {
      "level": "h2",
      "text": "Supported Metadata Types",
      "id": "supported-metadata-types"
    },
    {
      "level": "h2",
      "text": "Implementations",
      "id": "implementations"
    },
    {
      "level": "h3",
      "text": "Using cURL",
      "id": "using-curl"
    },
    {
      "level": "h3",
      "text": "Using SDK",
      "id": "using-sdk"
    },
    {
      "level": "h3",
      "text": "Using Binding",
      "id": "using-binding"
    },
    {
      "level": "h2",
      "text": "Default configuration",
      "id": "default-configuration"
    },
    {
      "level": "h2",
      "text": "Per-request logging",
      "id": "per-request-logging"
    },
    {
      "level": "h3",
      "text": "Collect logs (`cf-aig-collect-log`)",
      "id": "collect-logs-(`cf-aig-collect-log`)"
    },
    {
      "level": "h2",
      "text": "Managing log storage",
      "id": "managing-log-storage"
    },
    {
      "level": "h2",
      "text": "How to delete logs",
      "id": "how-to-delete-logs"
    },
    {
      "level": "h3",
      "text": "Automatic Log Deletion",
      "id": "automatic-log-deletion"
    },
    {
      "level": "h3",
      "text": "Manual deletion",
      "id": "manual-deletion"
    },
    {
      "level": "h3",
      "text": "API deletion",
      "id": "api-deletion"
    },
    {
      "level": "h2",
      "text": "Viewing Audit Logs",
      "id": "viewing-audit-logs"
    },
    {
      "level": "h2",
      "text": "Logged Operations",
      "id": "logged-operations"
    },
    {
      "level": "h2",
      "text": "Example Log Entry",
      "id": "example-log-entry"
    },
    {
      "level": "h2",
      "text": "Persistent logs",
      "id": "persistent-logs"
    },
    {
      "level": "h3",
      "text": "Free allocation and overage pricing",
      "id": "free-allocation-and-overage-pricing"
    },
    {
      "level": "h2",
      "text": "Logpush",
      "id": "logpush"
    },
    {
      "level": "h2",
      "text": "Fine print",
      "id": "fine-print"
    },
    {
      "level": "h2",
      "text": "Sign up and log in",
      "id": "sign-up-and-log-in"
    },
    {
      "level": "h2",
      "text": "Create gateway",
      "id": "create-gateway"
    },
    {
      "level": "h2",
      "text": "Connect Your AI Provider",
      "id": "connect-your-ai-provider"
    },
    {
      "level": "h2",
      "text": "Configure Your Workers AI",
      "id": "configure-your-workers-ai"
    },
    {
      "level": "h2",
      "text": "View Analytics",
      "id": "view-analytics"
    },
    {
      "level": "h2",
      "text": "Optional - Next steps",
      "id": "optional---next-steps"
    },
    {
      "level": "h2",
      "text": "Before you start",
      "id": "before-you-start"
    },
    {
      "level": "h2",
      "text": "1. Create an AI Gateway and OpenAI API key",
      "id": "1.-create-an-ai-gateway-and-openai-api-key"
    },
    {
      "level": "h2",
      "text": "2. Create a new Worker",
      "id": "2.-create-a-new-worker"
    },
    {
      "level": "h2",
      "text": "3. Configure OpenAI in your Worker",
      "id": "3.-configure-openai-in-your-worker"
    },
    {
      "level": "h2",
      "text": "4. Make an OpenAI request",
      "id": "4.-make-an-openai-request"
    },
    {
      "level": "h2",
      "text": "5. Deploy your Worker application",
      "id": "5.-deploy-your-worker-application"
    },
    {
      "level": "h2",
      "text": "6. Review your AI Gateway",
      "id": "6.-review-your-ai-gateway"
    },
    {
      "level": "h2",
      "text": "Endpoint URL",
      "id": "endpoint-url"
    },
    {
      "level": "h2",
      "text": "Parameters",
      "id": "parameters"
    },
    {
      "level": "h2",
      "text": "Examples",
      "id": "examples"
    },
    {
      "level": "h3",
      "text": "OpenAI SDK",
      "id": "openai-sdk"
    },
    {
      "level": "h3",
      "text": "cURL",
      "id": "curl"
    },
    {
      "level": "h2",
      "text": "Supported Providers",
      "id": "supported-providers"
    },
    {
      "level": "h2",
      "text": "cURL example",
      "id": "curl-example"
    },
    {
      "level": "h2",
      "text": "WebSockets API beta",
      "id": "websockets-api-beta"
    },
    {
      "level": "h2",
      "text": "WebSockets example",
      "id": "websockets-example"
    },
    {
      "level": "h2",
      "text": "Workers Binding example",
      "id": "workers-binding-example"
    },
    {
      "level": "h2",
      "text": "Header configuration hierarchy",
      "id": "header-configuration-hierarchy"
    },
    {
      "level": "h2",
      "text": "Hierarchy example",
      "id": "hierarchy-example"
    },
    {
      "level": "h2",
      "text": "When to use WebSockets",
      "id": "when-to-use-websockets"
    },
    {
      "level": "h2",
      "text": "Key benefits",
      "id": "key-benefits"
    },
    {
      "level": "h2",
      "text": "Key differences",
      "id": "key-differences"
    },
    {
      "level": "h2",
      "text": "Order of precedence",
      "id": "order-of-precedence"
    },
    {
      "level": "h2",
      "text": "Examples",
      "id": "examples"
    },
    {
      "level": "h3",
      "text": "Bot rule which blocks all AI bots vs pay per crawl",
      "id": "bot-rule-which-blocks-all-ai-bots-vs-pay-per-crawl"
    },
    {
      "level": "h2",
      "text": "Order of precedence",
      "id": "order-of-precedence"
    },
    {
      "level": "h2",
      "text": "Examples of using WAF vs AI Crawl Control",
      "id": "examples-of-using-waf-vs-ai-crawl-control"
    },
    {
      "level": "h3",
      "text": "Traffic from a restricted country vs pay per crawl",
      "id": "traffic-from-a-restricted-country-vs-pay-per-crawl"
    },
    {
      "level": "h3",
      "text": "Allowed search engine bots via WAF custom rule vs pay per crawl",
      "id": "allowed-search-engine-bots-via-waf-custom-rule-vs-pay-per-crawl"
    },
    {
      "level": "h3",
      "text": "Conflict in AI crawler blocking logic",
      "id": "conflict-in-ai-crawler-blocking-logic"
    },
    {
      "level": "h2",
      "text": "View the Overview tab",
      "id": "view-the-overview-tab"
    },
    {
      "level": "h2",
      "text": "View the Crawlers tab",
      "id": "view-the-crawlers-tab"
    },
    {
      "level": "h2",
      "text": "View the Metrics tab",
      "id": "view-the-metrics-tab"
    },
    {
      "level": "h3",
      "text": "Analyze referrer data",
      "id": "analyze-referrer-data"
    },
    {
      "level": "h3",
      "text": "Track successful crawler requests over time",
      "id": "track-successful-crawler-requests-over-time"
    },
    {
      "level": "h3",
      "text": "Monitor status code distribution",
      "id": "monitor-status-code-distribution"
    },
    {
      "level": "h3",
      "text": "Understand what content is crawled",
      "id": "understand-what-content-is-crawled"
    },
    {
      "level": "h2",
      "text": "Filter and export data",
      "id": "filter-and-export-data"
    },
    {
      "level": "h2",
      "text": "Per-crawler drilldowns",
      "id": "per-crawler-drilldowns"
    },
    {
      "level": "h2",
      "text": "Review AI crawler activity",
      "id": "review-ai-crawler-activity"
    },
    {
      "level": "h3",
      "text": "Filter AI crawler data",
      "id": "filter-ai-crawler-data"
    },
    {
      "level": "h2",
      "text": "Take action for each AI crawler",
      "id": "take-action-for-each-ai-crawler"
    },
    {
      "level": "h2",
      "text": "Configure block response",
      "id": "configure-block-response"
    },
    {
      "level": "h3",
      "text": "Edit the response code",
      "id": "edit-the-response-code"
    },
    {
      "level": "h3",
      "text": "Edit the response body",
      "id": "edit-the-response-body"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Check managed robots.txt status",
      "id": "check-managed-robots.txt-status"
    },
    {
      "level": "h2",
      "text": "Filter robots.txt request data",
      "id": "filter-robots.txt-request-data"
    },
    {
      "level": "h2",
      "text": "Monitor robots.txt availability",
      "id": "monitor-robots.txt-availability"
    },
    {
      "level": "h2",
      "text": "Track robots.txt violations",
      "id": "track-robots.txt-violations"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "How indexing works",
      "id": "how-indexing-works"
    },
    {
      "level": "h2",
      "text": "How querying works",
      "id": "how-querying-works"
    },
    {
      "level": "h2",
      "text": "How RAG works",
      "id": "how-rag-works"
    },
    {
      "level": "h2",
      "text": "Why use RAG?",
      "id": "why-use-rag?"
    },
    {
      "level": "h2",
      "text": "How It Works",
      "id": "how-it-works"
    },
    {
      "level": "h2",
      "text": "What to consider when using similarity cache",
      "id": "what-to-consider-when-using-similarity-cache"
    },
    {
      "level": "h2",
      "text": "How similarity matching works",
      "id": "how-similarity-matching-works"
    },
    {
      "level": "h2",
      "text": "Choosing a threshold",
      "id": "choosing-a-threshold"
    },
    {
      "level": "h2",
      "text": "What is recursive chunking",
      "id": "what-is-recursive-chunking"
    },
    {
      "level": "h2",
      "text": "Chunking controls",
      "id": "chunking-controls"
    },
    {
      "level": "h2",
      "text": "Choosing chunk size and overlap",
      "id": "choosing-chunk-size-and-overlap"
    },
    {
      "level": "h3",
      "text": "Additional considerations:",
      "id": "additional-considerations:"
    },
    {
      "level": "h2",
      "text": "Jobs",
      "id": "jobs"
    },
    {
      "level": "h2",
      "text": "Controls",
      "id": "controls"
    },
    {
      "level": "h2",
      "text": "Performance",
      "id": "performance"
    },
    {
      "level": "h2",
      "text": "Best practices",
      "id": "best-practices"
    },
    {
      "level": "h2",
      "text": "Metadata filtering",
      "id": "metadata-filtering"
    },
    {
      "level": "h3",
      "text": "Metadata attributes",
      "id": "metadata-attributes"
    },
    {
      "level": "h3",
      "text": "Filter schema",
      "id": "filter-schema"
    },
    {
      "level": "h2",
      "text": "Add `context` field to guide AI Search",
      "id": "add-`context`-field-to-guide-ai-search"
    },
    {
      "level": "h2",
      "text": "Response",
      "id": "response"
    },
    {
      "level": "h2",
      "text": "Models usage",
      "id": "models-usage"
    },
    {
      "level": "h2",
      "text": "Model providers",
      "id": "model-providers"
    },
    {
      "level": "h3",
      "text": "Smart default",
      "id": "smart-default"
    },
    {
      "level": "h3",
      "text": "Per-request generation model override",
      "id": "per-request-generation-model-override"
    },
    {
      "level": "h2",
      "text": "Model deprecation",
      "id": "model-deprecation"
    },
    {
      "level": "h3",
      "text": "Model lifecycle",
      "id": "model-lifecycle"
    },
    {
      "level": "h3",
      "text": "Best practices",
      "id": "best-practices"
    },
    {
      "level": "h2",
      "text": "Why use query rewriting?",
      "id": "why-use-query-rewriting?"
    },
    {
      "level": "h2",
      "text": "Example",
      "id": "example"
    },
    {
      "level": "h2",
      "text": "How it works",
      "id": "how-it-works"
    },
    {
      "level": "h2",
      "text": "How it works",
      "id": "how-it-works"
    },
    {
      "level": "h2",
      "text": "Configuration",
      "id": "configuration"
    },
    {
      "level": "h3",
      "text": "Configure via API",
      "id": "configure-via-api"
    },
    {
      "level": "h3",
      "text": "Configure in dashboard for new AI Search",
      "id": "configure-in-dashboard-for-new-ai-search"
    },
    {
      "level": "h3",
      "text": "Configure in dashboard for existing AI Search",
      "id": "configure-in-dashboard-for-existing-ai-search"
    },
    {
      "level": "h2",
      "text": "Match threshold",
      "id": "match-threshold"
    },
    {
      "level": "h2",
      "text": "Maximum number of results",
      "id": "maximum-number-of-results"
    },
    {
      "level": "h2",
      "text": "How they work together",
      "id": "how-they-work-together"
    },
    {
      "level": "h2",
      "text": "Configuration",
      "id": "configuration"
    },
    {
      "level": "h2",
      "text": "What is a system prompt?",
      "id": "what-is-a-system-prompt?"
    },
    {
      "level": "h2",
      "text": "System prompt configuration",
      "id": "system-prompt-configuration"
    },
    {
      "level": "h3",
      "text": "Default system prompt",
      "id": "default-system-prompt"
    },
    {
      "level": "h3",
      "text": "Configure via API",
      "id": "configure-via-api"
    },
    {
      "level": "h3",
      "text": "Configure via Dashboard",
      "id": "configure-via-dashboard"
    },
    {
      "level": "h2",
      "text": "Query rewriting system prompt",
      "id": "query-rewriting-system-prompt"
    },
    {
      "level": "h3",
      "text": "Example",
      "id": "example"
    },
    {
      "level": "h2",
      "text": "Generation system prompt",
      "id": "generation-system-prompt"
    },
    {
      "level": "h3",
      "text": "Example",
      "id": "example"
    },
    {
      "level": "h2",
      "text": "1. Organize Content by Tenant",
      "id": "1.-organize-content-by-tenant"
    },
    {
      "level": "h2",
      "text": "2. Search Using Folder Filters",
      "id": "2.-search-using-folder-filters"
    },
    {
      "level": "h2",
      "text": "Tip: Use \"Starts with\" filter",
      "id": "tip:-use-\"starts-with\"-filter"
    },
    {
      "level": "h2",
      "text": "What is NLWeb",
      "id": "what-is-nlweb"
    },
    {
      "level": "h2",
      "text": "How to use it",
      "id": "how-to-use-it"
    },
    {
      "level": "h2",
      "text": "What this template includes",
      "id": "what-this-template-includes"
    },
    {
      "level": "h2",
      "text": "What the Worker includes",
      "id": "what-the-worker-includes"
    },
    {
      "level": "h2",
      "text": "Using It on Your Website",
      "id": "using-it-on-your-website"
    },
    {
      "level": "h2",
      "text": "Modifying or updating the Worker",
      "id": "modifying-or-updating-the-worker"
    },
    {
      "level": "h2",
      "text": "Pricing",
      "id": "pricing"
    },
    {
      "level": "h2",
      "text": "Limits",
      "id": "limits"
    },
    {
      "level": "h2",
      "text": "2025-09-25",
      "id": "2025-09-25"
    },
    {
      "level": "h2",
      "text": "2025-09-23",
      "id": "2025-09-23"
    },
    {
      "level": "h2",
      "text": "2025-08-20",
      "id": "2025-08-20"
    },
    {
      "level": "h2",
      "text": "2025-07-16",
      "id": "2025-07-16"
    },
    {
      "level": "h2",
      "text": "2025-07-08",
      "id": "2025-07-08"
    },
    {
      "level": "h2",
      "text": "2025-06-16",
      "id": "2025-06-16"
    },
    {
      "level": "h2",
      "text": "2025-06-12",
      "id": "2025-06-12"
    },
    {
      "level": "h2",
      "text": "2025-06-12",
      "id": "2025-06-12"
    },
    {
      "level": "h2",
      "text": "2025-06-10",
      "id": "2025-06-10"
    },
    {
      "level": "h2",
      "text": "2025-05-31",
      "id": "2025-05-31"
    },
    {
      "level": "h2",
      "text": "2025-05-31",
      "id": "2025-05-31"
    },
    {
      "level": "h2",
      "text": "2025-05-25",
      "id": "2025-05-25"
    },
    {
      "level": "h2",
      "text": "2025-04-23",
      "id": "2025-04-23"
    },
    {
      "level": "h2",
      "text": "2025-04-07",
      "id": "2025-04-07"
    },
    {
      "level": "h2",
      "text": "Step 1. Create a Worker to fetch webpages and upload into R2",
      "id": "step-1.-create-a-worker-to-fetch-webpages-and-upload-into-r2"
    },
    {
      "level": "h2",
      "text": "Step 2. Create your AI Search and monitor the indexing",
      "id": "step-2.-create-your-ai-search-and-monitor-the-indexing"
    },
    {
      "level": "h2",
      "text": "Step 3. Test and add to your application",
      "id": "step-3.-test-and-add-to-your-application"
    },
    {
      "level": "h2",
      "text": "Prerequisite: Get AI Search API token",
      "id": "prerequisite:-get-ai-search-api-token"
    },
    {
      "level": "h2",
      "text": "AI Search",
      "id": "ai-search"
    },
    {
      "level": "h3",
      "text": "Parameters",
      "id": "parameters"
    },
    {
      "level": "h3",
      "text": "Response",
      "id": "response"
    },
    {
      "level": "h2",
      "text": "Search",
      "id": "search"
    },
    {
      "level": "h3",
      "text": "Parameters",
      "id": "parameters"
    },
    {
      "level": "h3",
      "text": "Response",
      "id": "response"
    },
    {
      "level": "h2",
      "text": "`aiSearch()`",
      "id": "`aisearch()`"
    },
    {
      "level": "h3",
      "text": "Parameters",
      "id": "parameters"
    },
    {
      "level": "h3",
      "text": "Response",
      "id": "response"
    },
    {
      "level": "h2",
      "text": "`search()`",
      "id": "`search()`"
    },
    {
      "level": "h3",
      "text": "Parameters",
      "id": "parameters"
    },
    {
      "level": "h3",
      "text": "Response",
      "id": "response"
    },
    {
      "level": "h2",
      "text": "Local development",
      "id": "local-development"
    },
    {
      "level": "h2",
      "text": "View your account analytics",
      "id": "view-your-account-analytics"
    },
    {
      "level": "h2",
      "text": "Review your account metrics",
      "id": "review-your-account-metrics"
    },
    {
      "level": "h3",
      "text": "Summary of metrics",
      "id": "summary-of-metrics"
    },
    {
      "level": "h2",
      "text": "What is a subrequest",
      "id": "what-is-a-subrequest"
    },
    {
      "level": "h2",
      "text": "Zone analytics",
      "id": "zone-analytics"
    },
    {
      "level": "h2",
      "text": "Worker analytics",
      "id": "worker-analytics"
    },
    {
      "level": "h2",
      "text": "FAQ",
      "id": "faq"
    },
    {
      "level": "h2",
      "text": "Common edge status codes",
      "id": "common-edge-status-codes"
    },
    {
      "level": "h2",
      "text": "Common origin status codes",
      "id": "common-origin-status-codes"
    },
    {
      "level": "h2",
      "text": "52x errors",
      "id": "52x-errors"
    },
    {
      "level": "h2",
      "text": "Bad browser",
      "id": "bad-browser"
    },
    {
      "level": "h2",
      "text": "Blocked hotlink",
      "id": "blocked-hotlink"
    },
    {
      "level": "h2",
      "text": "Human challenged",
      "id": "human-challenged"
    },
    {
      "level": "h2",
      "text": "Browser challenge",
      "id": "browser-challenge"
    },
    {
      "level": "h2",
      "text": "Bad IP",
      "id": "bad-ip"
    },
    {
      "level": "h2",
      "text": "Country block",
      "id": "country-block"
    },
    {
      "level": "h2",
      "text": "IP block (user)",
      "id": "ip-block-(user)"
    },
    {
      "level": "h2",
      "text": "IP range block (/16)",
      "id": "ip-range-block-(/16)"
    },
    {
      "level": "h2",
      "text": "IP range block (/24)",
      "id": "ip-range-block-(/24)"
    },
    {
      "level": "h2",
      "text": "New Challenge (user)",
      "id": "new-challenge-(user)"
    },
    {
      "level": "h2",
      "text": "Challenge error",
      "id": "challenge-error"
    },
    {
      "level": "h2",
      "text": "Bot Request",
      "id": "bot-request"
    },
    {
      "level": "h2",
      "text": "Unclassified",
      "id": "unclassified"
    },
    {
      "level": "h2",
      "text": "View your website analytics",
      "id": "view-your-website-analytics"
    },
    {
      "level": "h2",
      "text": "Review your website metrics",
      "id": "review-your-website-metrics"
    },
    {
      "level": "h3",
      "text": "HTTP Traffic",
      "id": "http-traffic"
    },
    {
      "level": "h3",
      "text": "Security",
      "id": "security"
    },
    {
      "level": "h3",
      "text": "Performance",
      "id": "performance"
    },
    {
      "level": "h3",
      "text": "Workers",
      "id": "workers"
    },
    {
      "level": "h3",
      "text": "Logs",
      "id": "logs"
    },
    {
      "level": "h2",
      "text": "1. Name your dataset and add it to your Worker",
      "id": "1.-name-your-dataset-and-add-it-to-your-worker"
    },
    {
      "level": "h2",
      "text": "2. Write data points from your Worker",
      "id": "2.-write-data-points-from-your-worker"
    },
    {
      "level": "h2",
      "text": "3. Query data using the SQL API",
      "id": "3.-query-data-using-the-sql-api"
    },
    {
      "level": "h3",
      "text": "Create an API token",
      "id": "create-an-api-token"
    },
    {
      "level": "h3",
      "text": "Write your first query",
      "id": "write-your-first-query"
    },
    {
      "level": "h3",
      "text": "Working with time series data",
      "id": "working-with-time-series-data"
    },
    {
      "level": "h2",
      "text": "Further reading",
      "id": "further-reading"
    },
    {
      "level": "h2",
      "text": "Grafana plugin setup",
      "id": "grafana-plugin-setup"
    },
    {
      "level": "h2",
      "text": "Querying timeseries data",
      "id": "querying-timeseries-data"
    },
    {
      "level": "h2",
      "text": "Data retention",
      "id": "data-retention"
    },
    {
      "level": "h3",
      "text": "Data points written",
      "id": "data-points-written"
    },
    {
      "level": "h3",
      "text": "Read queries",
      "id": "read-queries"
    },
    {
      "level": "h2",
      "text": "How sampling works",
      "id": "how-sampling-works"
    },
    {
      "level": "h2",
      "text": "How to read sampled data",
      "id": "how-to-read-sampled-data"
    },
    {
      "level": "h2",
      "text": "How is data sampled",
      "id": "how-is-data-sampled"
    },
    {
      "level": "h2",
      "text": "Adaptive Bit Rate Sampling at Read Time",
      "id": "adaptive-bit-rate-sampling-at-read-time"
    },
    {
      "level": "h2",
      "text": "How to select an index",
      "id": "how-to-select-an-index"
    },
    {
      "level": "h2",
      "text": "Authentication",
      "id": "authentication"
    },
    {
      "level": "h2",
      "text": "Querying the API",
      "id": "querying-the-api"
    },
    {
      "level": "h2",
      "text": "Table structure",
      "id": "table-structure"
    },
    {
      "level": "h2",
      "text": "Sampling",
      "id": "sampling"
    },
    {
      "level": "h2",
      "text": "Example queries",
      "id": "example-queries"
    },
    {
      "level": "h3",
      "text": "Select data with column aliases",
      "id": "select-data-with-column-aliases"
    },
    {
      "level": "h3",
      "text": "Aggregation taking into account sample interval",
      "id": "aggregation-taking-into-account-sample-interval"
    },
    {
      "level": "h2",
      "text": "Authentication",
      "id": "authentication"
    },
    {
      "level": "h2",
      "text": "Querying",
      "id": "querying"
    },
    {
      "level": "h2",
      "text": "Example Worker",
      "id": "example-worker"
    },
    {
      "level": "h3",
      "text": "Environment variable setup",
      "id": "environment-variable-setup"
    },
    {
      "level": "h3",
      "text": "Worker script",
      "id": "worker-script"
    },
    {
      "level": "h2",
      "text": "Overview",
      "id": "overview"
    },
    {
      "level": "h2",
      "text": "Task 1 - Install the Cloudflare App",
      "id": "task-1---install-the-cloudflare-app"
    },
    {
      "level": "h2",
      "text": "Task 2 - View the dashboard",
      "id": "task-2---view-the-dashboard"
    },
    {
      "level": "h2",
      "text": "Overview",
      "id": "overview"
    },
    {
      "level": "h3",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "Task 1 - Preparation",
      "id": "task-1---preparation"
    },
    {
      "level": "h2",
      "text": "Task 2 - Create and configure the AWS Lambda Function",
      "id": "task-2---create-and-configure-the-aws-lambda-function"
    },
    {
      "level": "h2",
      "text": "Task 3 - Import the content pack in Graylog",
      "id": "task-3---import-the-content-pack-in-graylog"
    },
    {
      "level": "h2",
      "text": "Task 4 - View the Cloudflare Dashboards",
      "id": "task-4---view-the-cloudflare-dashboards"
    },
    {
      "level": "h3",
      "text": "Cloudflare - Snapshot",
      "id": "cloudflare---snapshot"
    },
    {
      "level": "h3",
      "text": "Cloudflare - Security",
      "id": "cloudflare---security"
    },
    {
      "level": "h3",
      "text": "Cloudflare - Performance",
      "id": "cloudflare---performance"
    },
    {
      "level": "h3",
      "text": "Cloudflare - Reliability",
      "id": "cloudflare---reliability"
    },
    {
      "level": "h3",
      "text": "Cloudflare - Bots",
      "id": "cloudflare---bots"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "Task 1 - Install the Cloudflare Network Logs quickstart",
      "id": "task-1---install-the-cloudflare-network-logs-quickstart"
    },
    {
      "level": "h2",
      "text": "Task 2 - View the Cloudflare Dashboards",
      "id": "task-2---view-the-cloudflare-dashboards"
    },
    {
      "level": "h3",
      "text": "Overview",
      "id": "overview"
    },
    {
      "level": "h3",
      "text": "Security",
      "id": "security"
    },
    {
      "level": "h3",
      "text": "Performance",
      "id": "performance"
    },
    {
      "level": "h3",
      "text": "Reliability",
      "id": "reliability"
    },
    {
      "level": "h2",
      "text": "Step 1: Prerequisites",
      "id": "step-1:-prerequisites"
    },
    {
      "level": "h2",
      "text": "Step 2: Set up a logpush job",
      "id": "step-2:-set-up-a-logpush-job"
    },
    {
      "level": "h2",
      "text": "Step 3: Configure Azure and deploy the Data Connector in Microsoft Sentinel",
      "id": "step-3:-configure-azure-and-deploy-the-data-connector-in-microsoft-sentinel"
    },
    {
      "level": "h2",
      "text": "Step 4: Fill out required fields",
      "id": "step-4:-fill-out-required-fields"
    },
    {
      "level": "h2",
      "text": "Step 5: Complete deployment",
      "id": "step-5:-complete-deployment"
    },
    {
      "level": "h2",
      "text": "Supported Logs",
      "id": "supported-logs"
    },
    {
      "level": "h2",
      "text": "Resources",
      "id": "resources"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "Task 1 - Install and Configure the Cloudflare App for Splunk",
      "id": "task-1---install-and-configure-the-cloudflare-app-for-splunk"
    },
    {
      "level": "h2",
      "text": "Task 2 - Make the API call to create the Logpush job",
      "id": "task-2---make-the-api-call-to-create-the-logpush-job"
    },
    {
      "level": "h2",
      "text": "Task 3 - View the Dashboards",
      "id": "task-3---view-the-dashboards"
    },
    {
      "level": "h3",
      "text": "About the Dashboards",
      "id": "about-the-dashboards"
    },
    {
      "level": "h3",
      "text": "Filters",
      "id": "filters"
    },
    {
      "level": "h2",
      "text": "Debugging tips",
      "id": "debugging-tips"
    },
    {
      "level": "h3",
      "text": "Incomplete dashboards",
      "id": "incomplete-dashboards"
    },
    {
      "level": "h2",
      "text": "How Cloudflare captures and processes analytics data",
      "id": "how-cloudflare-captures-and-processes-analytics-data"
    },
    {
      "level": "h2",
      "text": "Apparent data discrepancies",
      "id": "apparent-data-discrepancies"
    },
    {
      "level": "h2",
      "text": "About missing metrics",
      "id": "about-missing-metrics"
    },
    {
      "level": "h2",
      "text": "Why does the analytics data on the **Overview** page not match what I have under **View More Analytics**?",
      "id": "why-does-the-analytics-data-on-the-**overview**-page-not-match-what-i-have-under-**view-more-analytics**?"
    },
    {
      "level": "h2",
      "text": "What is sampling?",
      "id": "what-is-sampling?"
    },
    {
      "level": "h2",
      "text": "Why do results vary between query runs?",
      "id": "why-do-results-vary-between-query-runs?"
    },
    {
      "level": "h2",
      "text": "Can I trust sampled data?",
      "id": "can-i-trust-sampled-data?"
    },
    {
      "level": "h2",
      "text": "How can I reduce variation in my query results?",
      "id": "how-can-i-reduce-variation-in-my-query-results?"
    },
    {
      "level": "h3",
      "text": "Query shorter time ranges",
      "id": "query-shorter-time-ranges"
    },
    {
      "level": "h3",
      "text": "Use aggregated datasets",
      "id": "use-aggregated-datasets"
    },
    {
      "level": "h3",
      "text": "Add explicit sorting",
      "id": "add-explicit-sorting"
    },
    {
      "level": "h3",
      "text": "Use confidence intervals",
      "id": "use-confidence-intervals"
    },
    {
      "level": "h2",
      "text": "Quick reference",
      "id": "quick-reference"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Why do I see a large amount of traffic from CLOUDFLARENET ASN 13335 in Analytics? Does this indicate a DDoS attack?",
      "id": "why-do-i-see-a-large-amount-of-traffic-from-cloudflarenet-asn-13335-in-analytics?-does-this-indicate-a-ddos-attack?"
    },
    {
      "level": "h2",
      "text": "Sampling",
      "id": "sampling"
    },
    {
      "level": "h3",
      "text": "Could I just use many unique index values to get better unique counts?",
      "id": "could-i-just-use-many-unique-index-values-to-get-better-unique-counts?"
    },
    {
      "level": "h3",
      "text": "What if I need to index on multiple values?",
      "id": "what-if-i-need-to-index-on-multiple-values?"
    },
    {
      "level": "h3",
      "text": "How do I know if my data is sampled?",
      "id": "how-do-i-know-if-my-data-is-sampled?"
    },
    {
      "level": "h3",
      "text": "Why is data missing?",
      "id": "why-is-data-missing?"
    },
    {
      "level": "h3",
      "text": "Can I trust sampled data? Are my results accurate?",
      "id": "can-i-trust-sampled-data?-are-my-results-accurate?"
    },
    {
      "level": "h3",
      "text": "How are bursts handled?",
      "id": "how-are-bursts-handled?"
    },
    {
      "level": "h3",
      "text": "How much traffic will trigger sampling?",
      "id": "how-much-traffic-will-trigger-sampling?"
    },
    {
      "level": "h2",
      "text": "Example",
      "id": "example"
    },
    {
      "level": "h2",
      "text": "Common error types",
      "id": "common-error-types"
    },
    {
      "level": "h3",
      "text": "Dataset accessibility limits exceeded",
      "id": "dataset-accessibility-limits-exceeded"
    },
    {
      "level": "h3",
      "text": "Parsing issues",
      "id": "parsing-issues"
    },
    {
      "level": "h3",
      "text": "Rate limits exceeded",
      "id": "rate-limits-exceeded"
    },
    {
      "level": "h2",
      "text": "Global limits",
      "id": "global-limits"
    },
    {
      "level": "h2",
      "text": "User limits",
      "id": "user-limits"
    },
    {
      "level": "h2",
      "text": "Node limits and availability",
      "id": "node-limits-and-availability"
    },
    {
      "level": "h2",
      "text": "GraphQL migrations",
      "id": "graphql-migrations"
    },
    {
      "level": "h2",
      "text": "Zone Analytics migrations",
      "id": "zone-analytics-migrations"
    },
    {
      "level": "h2",
      "text": "Network Analytics migrations",
      "id": "network-analytics-migrations"
    },
    {
      "level": "h2",
      "text": "Overview",
      "id": "overview"
    },
    {
      "level": "h2",
      "text": "Sampled datasets",
      "id": "sampled-datasets"
    },
    {
      "level": "h2",
      "text": "Why sampling is applied",
      "id": "why-sampling-is-applied"
    },
    {
      "level": "h2",
      "text": "Types of sampling",
      "id": "types-of-sampling"
    },
    {
      "level": "h3",
      "text": "Adaptive sampling",
      "id": "adaptive-sampling"
    },
    {
      "level": "h3",
      "text": "Fixed sampling",
      "id": "fixed-sampling"
    },
    {
      "level": "h2",
      "text": "Access to raw data",
      "id": "access-to-raw-data"
    },
    {
      "level": "h2",
      "text": "View the Network Analytics dashboard",
      "id": "view-the-network-analytics-dashboard"
    },
    {
      "level": "h2",
      "text": "Get Network Analytics data via API",
      "id": "get-network-analytics-data-via-api"
    },
    {
      "level": "h2",
      "text": "Send Network Analytics logs to a third-party service",
      "id": "send-network-analytics-logs-to-a-third-party-service"
    },
    {
      "level": "h2",
      "text": "Limitations",
      "id": "limitations"
    },
    {
      "level": "h2",
      "text": "Process",
      "id": "process"
    },
    {
      "level": "h3",
      "text": "Create a route",
      "id": "create-a-route"
    },
    {
      "level": "h3",
      "text": "Test a route",
      "id": "test-a-route"
    },
    {
      "level": "h2",
      "text": "Availability",
      "id": "availability"
    },
    {
      "level": "h2",
      "text": "Limitations",
      "id": "limitations"
    },
    {
      "level": "h2",
      "text": "Categories",
      "id": "categories"
    },
    {
      "level": "h3",
      "text": "Managed labels",
      "id": "managed-labels"
    },
    {
      "level": "h3",
      "text": "Risk labels",
      "id": "risk-labels"
    },
    {
      "level": "h2",
      "text": "Create a label",
      "id": "create-a-label"
    },
    {
      "level": "h2",
      "text": "Apply a label to an individual endpoint",
      "id": "apply-a-label-to-an-individual-endpoint"
    },
    {
      "level": "h2",
      "text": "Bulk apply labels to multiple endpoints",
      "id": "bulk-apply-labels-to-multiple-endpoints"
    },
    {
      "level": "h2",
      "text": "Availability",
      "id": "availability"
    },
    {
      "level": "h3",
      "text": "Custom domains",
      "id": "custom-domains"
    },
    {
      "level": "h2",
      "text": "Availability",
      "id": "availability"
    },
    {
      "level": "h2",
      "text": "Limitations",
      "id": "limitations"
    },
    {
      "level": "h2",
      "text": "Access",
      "id": "access"
    },
    {
      "level": "h3",
      "text": "Add endpoints from API Discovery",
      "id": "add-endpoints-from-api-discovery"
    },
    {
      "level": "h3",
      "text": "Add endpoints from Schema validation",
      "id": "add-endpoints-from-schema-validation"
    },
    {
      "level": "h3",
      "text": "Add endpoints manually",
      "id": "add-endpoints-manually"
    },
    {
      "level": "h3",
      "text": "Delete endpoints manually",
      "id": "delete-endpoints-manually"
    },
    {
      "level": "h2",
      "text": "Endpoint Analysis",
      "id": "endpoint-analysis"
    },
    {
      "level": "h2",
      "text": "Using the Cloudflare API",
      "id": "using-the-cloudflare-api"
    },
    {
      "level": "h2",
      "text": "Sensitive Data Detection",
      "id": "sensitive-data-detection"
    },
    {
      "level": "h2",
      "text": "Limitations",
      "id": "limitations"
    },
    {
      "level": "h2",
      "text": "To set up session identifiers",
      "id": "to-set-up-session-identifiers"
    },
    {
      "level": "h2",
      "text": "Create an API Shield with Schema validation",
      "id": "create-an-api-shield-with-schema-validation"
    },
    {
      "level": "h2",
      "text": "Manage API Shield session identifiers",
      "id": "manage-api-shield-session-identifiers"
    },
    {
      "level": "h2",
      "text": "Manage API Shield Endpoint Management",
      "id": "manage-api-shield-endpoint-management"
    },
    {
      "level": "h2",
      "text": "Manage Schema validation",
      "id": "manage-schema-validation"
    }
  ],
  "url": "llms-txt#or-run-vitest-directly",
  "links": []
}