{
  "title": "aura-1",
  "content": "Text-to-Speech • Deepgram\n\nAura is a context-aware text-to-speech (TTS) model that applies natural pacing, expressiveness, and fillers based on the context of the provided text. The quality of your text input directly impacts the naturalness of the audio output.\n\n| Model Info | |\n| - | - |\n| Terms and License | [link](https://deepgram.com/terms) |\n| Batch | Yes |\n| Partner | Yes |\n| Real-time | Yes |\n| Unit Pricing | $0.015 per 1k characters |\n\n\\* indicates a required field\n\n* `speaker` string default angus\n\nSpeaker used to produce the audio.\n\nEncoding of the output audio.\n\nContainer specifies the file format wrapper for the output audio. The available options depend on the encoding type..\n\n* `text` string required\n\nThe text content to be converted to speech\n\n* `sample_rate` number\n\nSample Rate specifies the sample rate for the output audio. Based on the encoding, different sample rates are supported. For some encodings, the sample rate is not configurable\n\nThe bitrate of the audio in bits per second. Choose from predefined ranges or specific values based on the encoding type.\n\nThe binding returns a `ReadableStream` with the image in JPEG or PNG format (check the model's output schema).\n\nThe following schemas are based on JSON Schema\n\n<page>\n---\ntitle: aura-2-en · Cloudflare Workers AI docs\ndescription: Aura-2 is a context-aware text-to-speech (TTS) model that applies\n  natural pacing, expressiveness, and fillers based on the context of the\n  provided text. The quality of your text input directly impacts the naturalness\n  of the audio output.\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers-ai/models/aura-2-en/\n  md: https://developers.cloudflare.com/workers-ai/models/aura-2-en/index.md\n---\n\n![Deepgram logo](https://developers.cloudflare.com/_astro/deepgram.DVGPhlbc.svg)",
  "code_samples": [
    {
      "code": "export default {\n  async fetch(request, env, ctx): Promise<Response> {\n      const resp = await env.AI.run(\"@cf/deepgram/aura-1\", {\n        \"text\":\"Hello World!\"\n      }, {\n        returnRawResponse: true\n      });\n\n\n      return resp;\n  },\n} satisfies ExportedHandler<Env>;",
      "language": "ts"
    },
    {
      "code": "curl --request POST   --url 'https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/ai/run/@cf/deepgram/aura-1'   --header 'Authorization: Bearer {TOKEN}'   --header 'Content-Type: application/json'   --data '{\n    \"text\":\"Hello world!\"\n}'",
      "language": "sh"
    },
    {
      "code": "{\n      \"type\": \"object\",\n      \"properties\": {\n          \"speaker\": {\n              \"type\": \"string\",\n              \"enum\": [\n                  \"angus\",\n                  \"asteria\",\n                  \"arcas\",\n                  \"orion\",\n                  \"orpheus\",\n                  \"athena\",\n                  \"luna\",\n                  \"zeus\",\n                  \"perseus\",\n                  \"helios\",\n                  \"hera\",\n                  \"stella\"\n              ],\n              \"default\": \"angus\",\n              \"description\": \"Speaker used to produce the audio.\"\n          },\n          \"encoding\": {\n              \"type\": \"string\",\n              \"enum\": [\n                  \"linear16\",\n                  \"flac\",\n                  \"mulaw\",\n                  \"alaw\",\n                  \"mp3\",\n                  \"opus\",\n                  \"aac\"\n              ],\n              \"description\": \"Encoding of the output audio.\"\n          },\n          \"container\": {\n              \"type\": \"string\",\n              \"enum\": [\n                  \"none\",\n                  \"wav\",\n                  \"ogg\"\n              ],\n              \"description\": \"Container specifies the file format wrapper for the output audio. The available options depend on the encoding type..\"\n          },\n          \"text\": {\n              \"type\": \"string\",\n              \"description\": \"The text content to be converted to speech\"\n          },\n          \"sample_rate\": {\n              \"type\": \"number\",\n              \"description\": \"Sample Rate specifies the sample rate for the output audio. Based on the encoding, different sample rates are supported. For some encodings, the sample rate is not configurable\"\n          },\n          \"bit_rate\": {\n              \"type\": \"number\",\n              \"description\": \"The bitrate of the audio in bits per second. Choose from predefined ranges or specific values based on the encoding type.\"\n          }\n      },\n      \"required\": [\n          \"text\"\n      ]\n  }",
      "language": "json"
    },
    {
      "code": "{\n      \"type\": \"string\",\n      \"contentType\": \"audio/mpeg\",\n      \"format\": \"binary\",\n      \"description\": \"The generated audio in MP3 format\"\n  }",
      "language": "json"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Usage",
      "id": "usage"
    },
    {
      "level": "h2",
      "text": "Parameters",
      "id": "parameters"
    },
    {
      "level": "h3",
      "text": "Input",
      "id": "input"
    },
    {
      "level": "h3",
      "text": "Output",
      "id": "output"
    },
    {
      "level": "h2",
      "text": "API Schemas",
      "id": "api-schemas"
    }
  ],
  "url": "llms-txt#aura-1",
  "links": []
}