{
  "title": "whisper-large-v3-turbo",
  "content": "Automatic Speech Recognition • OpenAI\n\n@cf/openai/whisper-large-v3-turbo\n\nWhisper is a pre-trained model for automatic speech recognition (ASR) and speech translation.\n\n| Model Info | |\n| - | - |\n| Unit Pricing | $0.00051 per audio minute |\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\n\\* indicates a required field\n\n* `audio` string required\n\nBase64 encoded value of the audio data.\n\n* `task` string default transcribe\n\nSupported tasks are 'translate' or 'transcribe'.\n\nThe language of the audio being transcribed or translated.\n\n* `vad_filter` boolean\n\nPreprocess the audio with a voice activity detection model.\n\n* `initial_prompt` string\n\nA text prompt to help provide context to the model on the contents of the audio.\n\nThe prefix it appended the the beginning of the output of the transcription and can guide the transcription result.\n\n* `transcription_info` object\n\nThe language of the audio being transcribed or translated.\n\n* `language_probability` number\n\nThe confidence level or probability of the detected language being accurate, represented as a decimal between 0 and 1.\n\nThe total duration of the original audio file, in seconds.\n\n* `duration_after_vad` number\n\nThe duration of the audio after applying Voice Activity Detection (VAD) to remove silent or irrelevant sections, in seconds.\n\n* `text` string required\n\nThe complete transcription of the audio.\n\n* `word_count` number\n\nThe total number of words in the transcription.\n\nThe starting time of the segment within the audio, in seconds.\n\nThe ending time of the segment within the audio, in seconds.\n\nThe transcription of the segment.\n\n* `temperature` number\n\nThe temperature used in the decoding process, controlling randomness in predictions. Lower values result in more deterministic outputs.\n\n* `avg_logprob` number\n\nThe average log probability of the predictions for the words in this segment, indicating overall confidence.\n\n* `compression_ratio` number\n\nThe compression ratio of the input to the output, measuring how much the text was compressed during the transcription process.\n\n* `no_speech_prob` number\n\nThe probability that the segment contains no speech, represented as a decimal between 0 and 1.\n\nThe individual word transcribed from the audio.\n\nThe starting time of the word within the audio, in seconds.\n\nThe ending time of the word within the audio, in seconds.\n\nThe transcription in WebVTT format, which includes timing and text information for use in subtitles.\n\nThe following schemas are based on JSON Schema\n\n<page>\n---\ntitle: whisper-tiny-en · Cloudflare Workers AI docs\ndescription: Whisper is a pre-trained model for automatic speech recognition\n  (ASR) and speech translation. Trained on 680k hours of labelled data, Whisper\n  models demonstrate a strong ability to generalize to many datasets and domains\n  without the need for fine-tuning. This is the English-only version of the\n  Whisper Tiny model which was trained on the task of speech recognition.\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers-ai/models/whisper-tiny-en/\n  md: https://developers.cloudflare.com/workers-ai/models/whisper-tiny-en/index.md\n---\n\n![OpenAI logo](https://developers.cloudflare.com/_astro/openai.ChTKThcR.svg)",
  "code_samples": [
    {
      "code": "import { Buffer } from 'node:buffer';\nexport interface Env {\n    AI: Ai;\n}\nconst URL = \"https://pub-dbcf9f0bd3af47ca9d40971179ee62de.r2.dev/02f6edc0-1f7b-4272-bd17-f05335104725/audio.mp3\";\nexport default {\n    async fetch(request, env, ctx): Promise<Response> {\n        const mp3 = await fetch(URL);\n        if (!mp3.ok) {\n          return Response.json({ error: `Failed to fetch MP3: ${mp3.status}` });\n        }\n        const mp3Buffer = await mp3.arrayBuffer();\n        const base64 = Buffer.from(mp3Buffer, 'binary').toString(\"base64\");\n        try {\n            const res = await env.AI.run(\"@cf/openai/whisper-large-v3-turbo\", {\n                \"audio\": base64\n            });\n            return Response.json(res);\n        }\n        catch (e) {\n            console.error(e);\n            return Response.json({ error: \"An unexpected error occurred\" });\n        }\n    },\n} satisfies ExportedHandler<Env>",
      "language": "ts"
    },
    {
      "code": "{\n      \"type\": \"object\",\n      \"properties\": {\n          \"audio\": {\n              \"type\": \"string\",\n              \"description\": \"Base64 encoded value of the audio data.\"\n          },\n          \"task\": {\n              \"type\": \"string\",\n              \"default\": \"transcribe\",\n              \"description\": \"Supported tasks are 'translate' or 'transcribe'.\"\n          },\n          \"language\": {\n              \"type\": \"string\",\n              \"description\": \"The language of the audio being transcribed or translated.\"\n          },\n          \"vad_filter\": {\n              \"type\": \"boolean\",\n              \"default\": false,\n              \"description\": \"Preprocess the audio with a voice activity detection model.\"\n          },\n          \"initial_prompt\": {\n              \"type\": \"string\",\n              \"description\": \"A text prompt to help provide context to the model on the contents of the audio.\"\n          },\n          \"prefix\": {\n              \"type\": \"string\",\n              \"description\": \"The prefix it appended the the beginning of the output of the transcription and can guide the transcription result.\"\n          }\n      },\n      \"required\": [\n          \"audio\"\n      ]\n  }",
      "language": "json"
    },
    {
      "code": "{\n      \"type\": \"object\",\n      \"contentType\": \"application/json\",\n      \"properties\": {\n          \"transcription_info\": {\n              \"type\": \"object\",\n              \"properties\": {\n                  \"language\": {\n                      \"type\": \"string\",\n                      \"description\": \"The language of the audio being transcribed or translated.\"\n                  },\n                  \"language_probability\": {\n                      \"type\": \"number\",\n                      \"description\": \"The confidence level or probability of the detected language being accurate, represented as a decimal between 0 and 1.\"\n                  },\n                  \"duration\": {\n                      \"type\": \"number\",\n                      \"description\": \"The total duration of the original audio file, in seconds.\"\n                  },\n                  \"duration_after_vad\": {\n                      \"type\": \"number\",\n                      \"description\": \"The duration of the audio after applying Voice Activity Detection (VAD) to remove silent or irrelevant sections, in seconds.\"\n                  }\n              }\n          },\n          \"text\": {\n              \"type\": \"string\",\n              \"description\": \"The complete transcription of the audio.\"\n          },\n          \"word_count\": {\n              \"type\": \"number\",\n              \"description\": \"The total number of words in the transcription.\"\n          },\n          \"segments\": {\n              \"type\": \"array\",\n              \"items\": {\n                  \"type\": \"object\",\n                  \"properties\": {\n                      \"start\": {\n                          \"type\": \"number\",\n                          \"description\": \"The starting time of the segment within the audio, in seconds.\"\n                      },\n                      \"end\": {\n                          \"type\": \"number\",\n                          \"description\": \"The ending time of the segment within the audio, in seconds.\"\n                      },\n                      \"text\": {\n                          \"type\": \"string\",\n                          \"description\": \"The transcription of the segment.\"\n                      },\n                      \"temperature\": {\n                          \"type\": \"number\",\n                          \"description\": \"The temperature used in the decoding process, controlling randomness in predictions. Lower values result in more deterministic outputs.\"\n                      },\n                      \"avg_logprob\": {\n                          \"type\": \"number\",\n                          \"description\": \"The average log probability of the predictions for the words in this segment, indicating overall confidence.\"\n                      },\n                      \"compression_ratio\": {\n                          \"type\": \"number\",\n                          \"description\": \"The compression ratio of the input to the output, measuring how much the text was compressed during the transcription process.\"\n                      },\n                      \"no_speech_prob\": {\n                          \"type\": \"number\",\n                          \"description\": \"The probability that the segment contains no speech, represented as a decimal between 0 and 1.\"\n                      },\n                      \"words\": {\n                          \"type\": \"array\",\n                          \"items\": {\n                              \"type\": \"object\",\n                              \"properties\": {\n                                  \"word\": {\n                                      \"type\": \"string\",\n                                      \"description\": \"The individual word transcribed from the audio.\"\n                                  },\n                                  \"start\": {\n                                      \"type\": \"number\",\n                                      \"description\": \"The starting time of the word within the audio, in seconds.\"\n                                  },\n                                  \"end\": {\n                                      \"type\": \"number\",\n                                      \"description\": \"The ending time of the word within the audio, in seconds.\"\n                                  }\n                              }\n                          }\n                      }\n                  }\n              }\n          },\n          \"vtt\": {\n              \"type\": \"string\",\n              \"description\": \"The transcription in WebVTT format, which includes timing and text information for use in subtitles.\"\n          }\n      },\n      \"required\": [\n          \"text\"\n      ]\n  }",
      "language": "json"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Usage",
      "id": "usage"
    },
    {
      "level": "h2",
      "text": "Parameters",
      "id": "parameters"
    },
    {
      "level": "h3",
      "text": "Input",
      "id": "input"
    },
    {
      "level": "h3",
      "text": "Output",
      "id": "output"
    },
    {
      "level": "h2",
      "text": "API Schemas",
      "id": "api-schemas"
    }
  ],
  "url": "llms-txt#whisper-large-v3-turbo",
  "links": []
}