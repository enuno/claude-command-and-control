{
  "title": "Configuration - exported from the prior steps",
  "content": "STREAM_ENDPOINT = os.environ[\"STREAM_ENDPOINT\"]# From the stream you created\nAPI_TOKEN = os.environ[\"WRANGLER_R2_SQL_AUTH_TOKEN\"] #the same one created earlier\nEVENTS_TO_SEND = 1000 # Feel free to adjust this\n\ndef generate_transaction():\n    \"\"\"Generate some random transactions with occasional fraud\"\"\"\n\n# User IDs\n    high_risk_users = [1001, 1002, 1003, 1004, 1005]\n    normal_users = list(range(1006, 2000))\n\nuser_id = random.choice(high_risk_users + normal_users)\n    is_high_risk_user = user_id in high_risk_users\n\n# Generate amounts\n    if random.random() < 0.05:\n        amount = round(random.uniform(5000, 50000), 2)\n    elif random.random() < 0.03:\n        amount = round(random.uniform(0.01, 1.00), 2)\n    else:\n        amount = round(random.uniform(10, 500), 2)\n\n# Locations\n    normal_locations = [\"NEW_YORK\", \"LOS_ANGELES\", \"CHICAGO\", \"MIAMI\", \"SEATTLE\", \"SAN FRANCISCO\"]\n    high_risk_locations = [\"UNKNOWN_LOCATION\", \"VPN_EXIT\", \"MARS\", \"BAT_CAVE\"]\n\nif is_high_risk_user and random.random() < 0.3:\n        location = random.choice(high_risk_locations)\n    else:\n        location = random.choice(normal_locations)\n\n# Merchant categories\n    normal_merchants = [\"GROCERY\", \"GAS_STATION\", \"RESTAURANT\", \"RETAIL\"]\n    high_risk_merchants = [\"GAMBLING\", \"CRYPTO\", \"MONEY_TRANSFER\", \"GIFT_CARDS\"]\n\nif random.random() < 0.1:  # 10% high-risk merchants\n        merchant_category = random.choice(high_risk_merchants)\n    else:\n        merchant_category = random.choice(normal_merchants)\n\n# Series of checks to either increase fraud score by a certain margin\n    fraud_score = 0\n    if amount > 2000: fraud_score += 0.4\n    if amount < 1: fraud_score += 0.3\n    if location in high_risk_locations: fraud_score += 0.5\n    if merchant_category in high_risk_merchants: fraud_score += 0.3\n    if is_high_risk_user: fraud_score += 0.2\n\n# Compare the fraud scores\n    is_fraud = random.random() < min(fraud_score * 0.3, 0.8)\n\n# Generate timestamps (some fraud happens at unusual hours)\n    base_time = datetime.now(timezone.utc)\n    if is_fraud and random.random() < 0.4:  # 40% of fraud at night\n        hour = random.randint(0, 5)  # Late night/early morning\n        transaction_time = base_time.replace(hour=hour)\n    else:\n        transaction_time = base_time - timedelta(\n            hours=random.randint(0, 168)  # Last week\n        )\n\nreturn {\n        \"transaction_id\": str(uuid.uuid4()),\n        \"user_id\": user_id,\n        \"amount\": amount,\n        \"transaction_timestamp\": transaction_time.isoformat(),\n        \"location\": location,\n        \"merchant_category\": merchant_category,\n        \"is_fraud\": True if is_fraud else False\n    }\n\ndef send_batch_to_stream(events, batch_size=100):\n    \"\"\"Send events to Cloudflare Stream in batches\"\"\"\n\nheaders = {\n        \"Authorization\": f\"Bearer {API_TOKEN}\",\n        \"Content-Type\": \"application/json\"\n    }\n\ntotal_sent = 0\n    fraud_count = 0\n\nfor i in range(0, len(events), batch_size):\n        batch = events[i:i + batch_size]\n        fraud_in_batch = sum(1 for event in batch if event[\"is_fraud\"] == True)\n\ntry:\n            response = requests.post(STREAM_ENDPOINT, headers=headers, json=batch)\n\nif response.status_code in [200, 201]:\n                total_sent += len(batch)\n                fraud_count += fraud_in_batch\n                print(f\"Sent batch of {len(batch)} events (Total: {total_sent})\")\n            else:\n                print(f\"Failed to send batch: {response.status_code} - {response.text}\")\n\nexcept Exception as e:\n            print(f\"Error sending batch: {e}\")\n\nreturn total_sent, fraud_count\n\ndef main():\n    print(\"Generating fraud detection data...\")\n\n# Generate events\n    events = []\n    for i in range(EVENTS_TO_SEND):\n        events.append(generate_transaction())\n        if (i + 1) % 100 == 0:\n            print(f\"Generated {i + 1} events...\")\n\nfraud_events = sum(1 for event in events if event[\"is_fraud\"] == True)\n    print(f\"ðŸ“Š Generated {len(events)} total events ({fraud_events} fraud, {fraud_events/len(events)*100:.1f}%)\")\n\n# Send to stream\n    print(\"Sending data to Pipeline stream...\")\n    sent, fraud_sent = send_batch_to_stream(events)\n\nprint(f\"\\nComplete!\")\n    print(f\"   Events sent: {sent:,}\")\n    print(f\"   Fraud events: {fraud_sent:,} ({fraud_sent/sent*100:.1f}%)\")\n    print(f\"   Data is now flowing through your pipeline!\")\n\nif __name__ == \"__main__\":\n    main()\nbash\npip install requests\npython fraud_data_generator.py\nbash\nnpx wrangler r2 sql query \"$WAREHOUSE\" \"\nSELECT\n    transaction_id,\n    user_id,\n    amount,\n    location,\n    merchant_category,\n    is_fraud,\n    transaction_timestamp\nFROM fraud_detection.transactions\nWHERE __ingest_ts > '2025-09-24T01:00:00Z'\nAND is_fraud = true\nLIMIT 10\"\nbash\nnpx wrangler pipelines sinks create fraud_filter_sink \\\n  --type \"r2-data-catalog\" \\\n  --bucket \"fraud-pipeline\" \\\n  --roll-interval 30 \\\n  --namespace \"fraud_detection\" \\\n  --table \"fraud_transactions\" \\\n  --catalog-token $WRANGLER_R2_SQL_AUTH_TOKEN\nbash\nnpx wrangler pipelines create fraud_events_pipeline \\\n  --sql \"INSERT INTO fraud_filter_sink SELECT * FROM raw_events_stream WHERE is_fraud=true and amount > 1000\"\nbash\nnpx wrangler r2 sql query \"$WAREHOUSE\" \"\nSELECT\n    transaction_id,\n    user_id,\n    amount,\n    location,\n    merchant_category,\n    is_fraud,\n    transaction_timestamp\nFROM fraud_detection.fraud_transactions\nLIMIT 10\"\nbash\nnpx wrangler r2 sql query \"$WAREHOUSE\" \"\nSELECT\n    transaction_id,\n    user_id,\n    amount,\n    location,\n    merchant_category,\n    is_fraud,\n    transaction_timestamp\nFROM fraud_detection.fraud_transactions\nWHERE is_fraud = false\nLIMIT 10\"\ntext\nQuery executed successfully with no results\nsh\n  npm create cloudflare@latest -- hello-agent\n  sh\n  yarn create cloudflare hello-agent\n  sh\n  pnpm create cloudflare@latest hello-agent\n  sh\ncd hello-agent\nsh\nnpm i @cloudflare/realtime-agents\njsonc\n  {\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"ai\": {\n      \"binding\": \"AI\"\n    }\n  }\n  toml\n  [ai]\n  binding = \"AI\"\n  js\n  import {\n    DeepgramSTT,\n    TextComponent,\n    RealtimeKitTransport,\n    ElevenLabsTTS,\n    RealtimeAgent,\n  } from \"@cloudflare/realtime-agents\";\n\nclass MyTextProcessor extends TextComponent {\n    env;\n\nconstructor(env) {\n      super();\n      this.env = env;\n    }\n\nasync onTranscript(text, reply) {\n      const { response } = await this.env.AI.run(\n        \"@cf/meta/llama-3.1-8b-instruct\",\n        {\n          prompt: text,\n        },\n      );\n      reply(response);\n    }\n  }\n\nexport class MyAgent extends RealtimeAgent {\n    constructor(ctx, env) {\n      super(ctx, env);\n    }\n\nasync init(agentId, meetingId, authToken, workerUrl, accountId, apiToken) {\n      // Construct your text processor for generating responses to text\n      const textProcessor = new MyTextProcessor(this.env);\n      // Construct a Meeting object to join the RTK meeting\n      const rtkTransport = new RealtimeKitTransport(meetingId, authToken);\n\n// Construct a pipeline to take in meeting audio, transcribe it using\n      // Deepgram, and pass our generated responses through ElevenLabs to\n      // be spoken in the meeting\n      await this.initPipeline(\n        [\n          rtkTransport,\n          new DeepgramSTT(this.env.DEEPGRAM_API_KEY),\n          textProcessor,\n          new ElevenLabsTTS(this.env.ELEVENLABS_API_KEY),\n          rtkTransport,\n        ],\n        agentId,\n        workerUrl,\n        accountId,\n        apiToken,\n      );\n\nconst { meeting } = rtkTransport;\n\n// The RTK meeting object is accessible to us, so we can register handlers\n      // on various events like participant joins/leaves, chat, etc.\n      // This is optional\n      meeting.participants.joined.on(\"participantJoined\", (participant) => {\n        textProcessor.speak(`Participant Joined ${participant.name}`);\n      });\n      meeting.participants.joined.on(\"participantLeft\", (participant) => {\n        textProcessor.speak(`Participant Left ${participant.name}`);\n      });\n\n// Make sure to actually join the meeting after registering all handlers\n      await meeting.join();\n    }\n\nasync deinit() {\n      // Add any other cleanup logic required\n      await this.deinitPipeline();\n    }\n  }\n\nexport default {\n    async fetch(request, env, _ctx) {\n      const url = new URL(request.url);\n      const meetingId = url.searchParams.get(\"meetingId\");\n      if (!meetingId) {\n        return new Response(null, { status: 400 });\n      }\n\nconst agentId = meetingId;\n      const agent = env.MY_AGENT.idFromName(meetingId);\n      const stub = env.MY_AGENT.get(agent);\n      // The fetch method is implemented for handling internal pipeline logic\n      if (url.pathname.startsWith(\"/agentsInternal\")) {\n        return stub.fetch(request);\n      }\n\n// Your logic continues here\n      switch (url.pathname) {\n        case \"/init\":\n          // This is the authToken for joining a meeting, it can be passed\n          // in query parameters as well if needed\n          const authHeader = request.headers.get(\"Authorization\");\n          if (!authHeader) {\n            return new Response(null, { status: 401 });\n          }\n\n// We just need the part after `Bearer `\n          await stub.init(\n            agentId,\n            meetingId,\n            authHeader.split(\" \")[1],\n            url.host,\n            env.ACCOUNT_ID,\n            env.API_TOKEN,\n          );\n\nreturn new Response(null, { status: 200 });\n        case \"/deinit\":\n          await stub.deinit();\n          return new Response(null, { status: 200 });\n      }\n\nreturn new Response(null, { status: 404 });\n    },\n  };\n  ts\n  import { DeepgramSTT, TextComponent, RealtimeKitTransport, ElevenLabsTTS, RealtimeAgent } from '@cloudflare/realtime-agents';\n\nclass MyTextProcessor extends TextComponent {\n    env: Env;\n\nconstructor(env: Env) {\n      super();\n      this.env = env;\n    }\n\nasync onTranscript(text: string, reply: (text: string) => void) {\n      const { response } = await this.env.AI.run('@cf/meta/llama-3.1-8b-instruct', {\n        prompt: text,\n      });\n      reply(response!);\n    }\n  }\n\nexport class MyAgent extends RealtimeAgent<Env> {\n    constructor(ctx: DurableObjectState, env: Env) {\n      super(ctx, env);\n    }\n\nasync init(agentId: string, meetingId: string, authToken: string, workerUrl: string, accountId: string, apiToken: string) {\n      // Construct your text processor for generating responses to text\n      const textProcessor = new MyTextProcessor(this.env);\n      // Construct a Meeting object to join the RTK meeting\n      const rtkTransport = new RealtimeKitTransport(meetingId, authToken);\n\n// Construct a pipeline to take in meeting audio, transcribe it using\n      // Deepgram, and pass our generated responses through ElevenLabs to\n      // be spoken in the meeting\n      await this.initPipeline(\n        [\n          rtkTransport,\n          new DeepgramSTT(this.env.DEEPGRAM_API_KEY),\n          textProcessor,\n          new ElevenLabsTTS(this.env.ELEVENLABS_API_KEY),\n          rtkTransport,\n        ],\n        agentId,\n        workerUrl,\n        accountId,\n        apiToken,\n      );\n\nconst { meeting } = rtkTransport;\n\n// The RTK meeting object is accessible to us, so we can register handlers\n      // on various events like participant joins/leaves, chat, etc.\n      // This is optional\n      meeting.participants.joined.on('participantJoined', (participant) => {\n        textProcessor.speak(`Participant Joined ${participant.name}`);\n      });\n      meeting.participants.joined.on('participantLeft', (participant) => {\n        textProcessor.speak(`Participant Left ${participant.name}`);\n      });\n\n// Make sure to actually join the meeting after registering all handlers\n      await meeting.join();\n    }\n\nasync deinit() {\n      // Add any other cleanup logic required\n      await this.deinitPipeline();\n    }\n  }\n\nexport default {\n    async fetch(request, env, _ctx): Promise<Response> {\n      const url = new URL(request.url);\n      const meetingId = url.searchParams.get('meetingId');\n      if (!meetingId) {\n        return new Response(null, { status: 400 });\n      }\n\nconst agentId = meetingId;\n      const agent = env.MY_AGENT.idFromName(meetingId);\n      const stub = env.MY_AGENT.get(agent);\n      // The fetch method is implemented for handling internal pipeline logic\n      if (url.pathname.startsWith('/agentsInternal')) {\n        return stub.fetch(request);\n      }\n\n// Your logic continues here\n      switch (url.pathname) {\n        case '/init':\n          // This is the authToken for joining a meeting, it can be passed\n          // in query parameters as well if needed\n          const authHeader = request.headers.get('Authorization');\n          if (!authHeader) {\n            return new Response(null, { status: 401 });\n          }\n\n// We just need the part after `Bearer `\n          await stub.init(agentId, meetingId, authHeader.split(' ')[1], url.host, env.ACCOUNT_ID, env.API_TOKEN);\n\nreturn new Response(null, { status: 200 });\n        case '/deinit':\n          await stub.deinit();\n          return new Response(null, { status: 200 });\n      }\n\nreturn new Response(null, { status: 404 });\n    },\n  } satisfies ExportedHandler<Env>;\n  json\n  \"compatibility_flags\": [\"nodejs_compat\"],\n  \"migrations\": [\n    {\n      \"new_sqlite_classes\": [\"MyAgent\"],\n      \"tag\": \"v1\",\n    },\n  ],\n  \"durable_objects\": {\n    \"bindings\": [\n      {\n        \"class_name\": \"MyAgent\",\n        \"name\": \"MY_AGENT\",\n      },\n    ],\n  },\nsh\nnpx wrangler login\nsh\nnpx wrangler deploy\nsh\nhttps://hello-agent.<YOUR_SUBDOMAIN>.workers.dev\nsh\ncurl -X POST https://hello-agent.<YOUR_SUBDOMAIN>.workers.dev/init?meetingId=<REALTIME_KIT_MEETING_ID> -H \"Authorization: Bearer <REALTIME_KIT_AUTH_TOKEN>\"\nts\ninterface AudioQualityConstraints {\n  echoCancellation?: boolean,\n  noiseSupression?: boolean,\n  autoGainControl?: boolean,\n  enableStereo?: boolean,\n  enableHighBitrate?: boolean\n}\n\ninterface VideoQualityConstraints {\n  width: { ideal: number },\n  height: { ideal: number },\n  frameRate?: { ideal: number },\n}\n\ninterface ScreenshareQualityConstraints {\n  width?: { max: number },\n  height?: { max: number },\n  frameRate?: {\n    ideal: number,\n    max: number\n  },\n  displaySurface?: 'window' | 'monitor' | 'browser';\n  selfBrowserSurface?: 'include' | 'exclude'\n}\n\ninterface MediaConfiguration {\n  video?: VideoQualityConstraints,\n  audio?: AudioQualityConstraints,\n  screenshare?: ScreenshareQualityConstraints,\n}\n\ninterface RecordingConfig {\n  fileNamePrefix?: string;\n  videoConfig?: {\n    height?: number;\n    width?: number;\n    codec?: string;\n  };\n}\n\ninterface DefaultOptions {\n  video?: boolean;\n  audio?: boolean;\n  mediaConfiguration?: MediaConfiguration;\n  isNonPreferredDevice?: (device: MediaDeviceInfo) => boolean;\n  autoSwitchAudioDevice?: boolean;\n  recording?: RecordingConfig;\n}\nbash\ncurl https://api.cloudflare.com/client/v4/accounts/{ACCOUNT_ID}/realtime/kit/{APP_ID}/meetings/{MEETING_ID} \\\n--request PATCH \\\n--header \"Authorization: Bearer <CLOUDFLARE_API_TOKEN>\" \\\n--header \"Content-Type: application/json\" \\\n--data '{ \"status\": \"INACTIVE\" }'\nbash\ncurl --location 'https://api.cloudflare.com/client/v4/accounts/<account_id>/realtime/kit/apps' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Bearer <api_token>' \\\n--data '{\"name\": \"My First Cloudflare RealtimeKit app\"}'\nbash\ncurl --location 'https://api.cloudflare.com/client/v4/accounts/<account_id>/realtime/kit/<app_id>/meetings' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Bearer <api_token>' \\\n--data '{\"title\": \"My First Cloudflare RealtimeKit meeting\"}'\nbash\ncurl --location 'https://api.cloudflare.com/client/v4/accounts/<account_id>/realtime/kit/<app_id>/meetings/<meeting_id>/participants' \\\n--header 'Content-Type: application/json' \\\n--header 'Authorization: Bearer <api_token>' \\\n--data '{\n  \"name\": \"Mary Sue\",\n  \"preset_name\": \"<preset_name>\",\n  \"custom_participant_id\": \"<uuid_of_the_user_in_your_system>\"\n}'\nts\n  initMeeting({\n    overrides: {\n      simulcastConfig: {\n        disable: false,\n        encodings: [{ scaleResolutionDownBy: 2 }],\n      },\n    },\n  });\n  ts\n  meeting.participants.broadcastMessage(\"<message_type>\", { message: \"Hi\" }, {\n    meetingIds: [\"<connected_meeting_id>\"],\n  });\n  mermaid\ngraph LR\n    A[Publisher] -->|Arbitrary data| B[Cloudflare Realtime SFU]\n    B -->|Arbitrary data| C@{ shape: procs, label: \"Subscribers\"}\nmermaid\nsequenceDiagram\n    participant WA as WebRTC Agent\n    participant BS as Backend Server\n    participant CA as Realtime API\n\nNote over BS: Client Joins\n\nWA->>BS: Request\n    BS->>CA: POST /sessions/new\n    CA->>BS: newSessionResponse\n    BS->>WA: Response\n\nWA->>BS: Request\n    BS->>CA: POST /sessions/<ID>/tracks/new (Offer)\n    CA->>BS: newTracksResponse (Answer)\n    BS->>WA: Response\n\nWA-->>CA: ICE Connectivity Check\n    Note over WA: iceconnectionstatechange (connected)\n    WA-->>CA: DTLS Handshake\n    Note over WA: connectionstatechange (connected)\n\nWA<<->>CA: *Media Flow*\n\nNote over BS: Remote Client Joins\n\nWA->>BS: Request\n    BS->>CA: POST /sessions/<ID>/tracks/new\n    CA->>BS: newTracksResponse (Offer)\n    BS->>WA: Response\n\nWA->>BS: Request\n    BS->>CA: PUT /sessions/<ID>/renegotiate (Answer)\n    CA->>BS: OK\n    BS->>WA: Response\n\nNote over BS: Remote Client Leaves\n\nWA->>BS: Request\n    BS->>CA: PUT /sessions/<ID>/tracks/close\n    CA->>BS: closeTracksResponse\n    BS->>WA: Response\n\nNote over BS: Client Leaves\n\nWA->>BS: Request\n    BS->>CA: PUT /sessions/<ID>/tracks/close\n    CA->>BS: closeTracksResponse\n    BS->>WA: Response\nmermaid\ngraph LR\n    A[WebRTC Client] <--> B[Realtime SFU Session]\n    B <--> C[Media Transport Adapter]\n    C <--> D[External Endpoint]\nplaintext\nPOST /v1/apps/{appId}/adapters/{adapterType}/new\nPOST /v1/apps/{appId}/adapters/{adapterType}/close\ngraphql\nquery concurrentConnections {\n  viewer {\n    accounts(filter: { accountTag: $accountId }) {\n      callsTurnUsageAdaptiveGroups(\n        limit: 10000\n        filter: { date_geq: $dateFrom, date_leq: $dateTo }\n      ) {\n        dimensions {\n          datetimeFiveMinutes\n        }\n        avg {\n          concurrentConnectionsFiveMinutes\n        }\n        sum {\n          egressBytes\n          ingressBytes\n        }\n      }\n    }\n  }\n}\njson\n{\n  \"data\": {\n    \"viewer\": {\n      \"accounts\": [\n        {\n          \"callsTurnUsageAdaptiveGroups\": [\n            {\n              \"avg\": {\n                \"concurrentConnectionsFiveMinutes\": 816\n              },\n              \"dimensions\": {\n                \"datetimeFiveMinutes\": \"2025-12-02T03:45:00Z\"\n              },\n              \"sum\": {\n                \"egressBytes\": 207314144,\n                \"ingressBytes\": 8534200\n              }\n            },\n            {\n              \"avg\": {\n                \"concurrentConnectionsFiveMinutes\": 1945\n              },\n              \"dimensions\": {\n                \"datetimeFiveMinutes\": \"2025-12-02T16:00:00Z\"\n              },\n              \"sum\": {\n                \"egressBytes\": 462909020,\n                \"ingressBytes\": 128434592\n              }\n            },\n\n]\n        }\n      ]\n    }\n  ]\n}\nplaintext\nquery egressByTurnKey{\n  viewer {\n    usage: accounts(filter: { accountTag: $accountId }) {\n        callsTurnUsageAdaptiveGroups(\n          filter: {\n          date_geq: $dateFrom,\n          date_leq: $dateTo\n        }\n          limit: 2\n          orderBy: [sum_egressBytes_DESC]\n        ) {\n          dimensions {\n            keyId\n          }\n          sum {\n            egressBytes\n          }\n        }\n      }\n    },\n    \"errors\": null\n  }\nplaintext\n{\n  \"data\": {\n    \"viewer\": {\n      \"usage\": [\n        {\n          \"callsTurnUsageAdaptiveGroups\": [\n            {\n              \"dimensions\": {\n                \"keyId\": \"82a58d0aeabfa8f4a4e0c4a9efc9cda5\"\n              },\n              \"sum\": {\n                \"egressBytes\": 160040068147\n              }\n            }\n          ]\n        }\n      ]\n    }\n  },\n  \"errors\": null\n}\ngraphql\nquery topTurnCustomIdentifiers {\n  viewer {\n    accounts(filter: { accountTag: $accountId }) {\n      callsTurnUsageAdaptiveGroups(\n        filter: { date_geq: $dateFrom, date_leq: $dateTo }\n        limit: 1\n        orderBy: [sum_egressBytes_DESC]\n      ) {\n        dimensions {\n          customIdentifier\n        }\n        sum {\n          egressBytes\n        }\n      }\n    }\n  }\n}\nplaintext\n{\n  \"data\": {\n    \"viewer\": {\n      \"accounts\": [\n        {\n          \"callsTurnUsageAdaptiveGroups\": [\n            {\n              \"dimensions\": {\n                \"customIdentifier\": \"some identifier\"\n              },\n              \"sum\": {\n                \"egressBytes\": 160040068147\n              }\n            }\n          ]\n        }\n      ]\n    }\n  },\n  \"errors\": null\n}\ngraphql\nquery {\n  viewer {\n    accounts(filter: { accountTag: $accountId }) {\n      callsTurnUsageAdaptiveGroups(\n        filter: {\n          date_geq: $dateFrom\n          date_leq: $dateTo\n          customIdentifier: \"tango\"\n        }\n        limit: 100\n        orderBy: []\n      ) {\n        dimensions {\n          keyId\n          customIdentifier\n        }\n        sum {\n          egressBytes\n        }\n      }\n    }\n  }\n}\nplaintext\n{\n  \"data\": {\n    \"viewer\": {\n      \"usage\": [\n        {\n          \"callsTurnUsageAdaptiveGroups\": [\n            {\n              \"dimensions\": {\n                \"customIdentifier\": \"tango\",\n                \"keyId\": \"74007022d80d7ebac4815fb776b9d3ed\"\n              },\n              \"sum\": {\n                \"egressBytes\": 162641324\n              }\n            }\n          ]\n        }\n      ]\n    }\n  },\n  \"errors\": null\n}\ngraphql\nquery {\n  viewer {\n    accounts(filter: { accountTag: $accountId }) {\n      callsTurnUsageAdaptiveGroups(\n        filter: { date_geq: $dateFrom, date_leq: $dateTo }\n        limit: 100\n        orderBy: [datetimeMinute_ASC]\n      ) {\n        dimensions {\n          datetimeMinute\n        }\n        sum {\n          egressBytes\n        }\n      }\n    }\n  }\n}\nplaintext\n{\n  \"data\": {\n    \"viewer\": {\n      \"accounts\": [\n        {\n          \"callsTurnUsageAdaptiveGroups\": [\n            {\n              \"dimensions\": {\n                \"datetimeMinute\": \"2025-12-01T00:00:00Z\"\n              },\n              \"sum\": {\n                \"egressBytes\": 159512\n              }\n            },\n            {\n              \"dimensions\": {\n                \"datetimeMinute\": \"2025-12-01T00:01:00Z\"\n              },\n              \"sum\": {\n                \"egressBytes\": 133818\n              }\n            },\n            ... (more data here)\n           ]\n        }\n      ]\n    }\n  },\n  \"errors\": null\n}\ngraphql\nquery {\n  viewer {\n    accounts(filter: { accountTag: $accountId }) {\n      callsTurnUsageAdaptiveGroups(\n        limit: 100\n        filter: { date_geq: $dateFrom, date_leq: $dateTo }\n        orderBy: [sum_egressBytes_DESC]\n      ) {\n        dimensions {\n          datacenterCity\n          datacenterCode\n          datacenterRegion\n          datacenterCountry\n        }\n        sum {\n          egressBytes\n          ingressBytes\n        }\n        avg {\n          concurrentConnectionsFiveMinutes\n        }\n      }\n    }\n  }\n}\njson\n{\n  \"data\": {\n    \"viewer\": {\n      \"accounts\": [\n        {\n          \"callsTurnUsageAdaptiveGroups\": [\n            {\n              \"avg\": {\n                \"concurrentConnectionsFiveMinutes\": 3135\n              },\n              \"dimensions\": {\n                \"datacenterCity\": \"Columbus\",\n                \"datacenterCode\": \"CMH\",\n                \"datacenterCountry\": \"US\",\n                \"datacenterRegion\": \"ENAM\"\n              },\n              \"sum\": {\n                \"egressBytes\": 47720931316,\n                \"ingressBytes\": 19351966366\n              }\n            },\n            ...\n          ]\n        }\n      ]\n    }\n  },\n  \"errors\": null\n}\ngraphql\nquery {\n  viewer {\n    accounts(filter: { accountTag: $accountId }) {\n      callsTurnUsageAdaptiveGroups(\n        limit: 1000\n        filter: {\n          keyId: \"82a58d0aeabfa8f4a4e0c4a9efc9cda5\"\n          date_geq: $dateFrom\n          date_leq: $dateTo\n        }\n        orderBy: [datetimeFiveMinutes_ASC]\n      ) {\n        dimensions {\n          datetimeFiveMinutes\n          keyId\n        }\n        sum {\n          egressBytes\n          ingressBytes\n        }\n        avg {\n          concurrentConnectionsFiveMinutes\n        }\n      }\n    }\n  }\n}\njson\n{\n  \"data\": {\n    \"viewer\": {\n      \"accounts\": [\n        {\n          \"callsTurnUsageAdaptiveGroups\": [\n            {\n              \"avg\": {\n                \"concurrentConnectionsFiveMinutes\": 130\n              },\n              \"dimensions\": {\n                \"datetimeFiveMinutes\": \"2025-12-01T00:00:00Z\",\n                \"keyId\": \"82a58d0aeabfa8f4a4e0c4a9efc9cda5\"\n              },\n              \"sum\": {\n                \"egressBytes\": 609156,\n                \"ingressBytes\": 464326\n              }\n            },\n            {\n              \"avg\": {\n                \"concurrentConnectionsFiveMinutes\": 118\n              },\n              \"dimensions\": {\n                \"datetimeFiveMinutes\": \"2025-12-01T00:05:00Z\",\n                \"keyId\": \"82a58d0aeabfa8f4a4e0c4a9efc9cda5\"\n              },\n              \"sum\": {\n                \"egressBytes\": 534948,\n                \"ingressBytes\": 401286\n              }\n            },\n            ...\n          ]\n        }\n      ]\n    }\n  },\n  \"errors\": null\n}\ngraphql\nquery {\n  viewer {\n    accounts(filter: { accountTag: $accountId }) {\n      callsTurnUsageAdaptiveGroups(\n        limit: 1000\n        filter: {\n          keyId: \"82a58d0aeabfa8f4a4e0c4a9efc9cda5\"\n          date_geq: $dateFrom\n          date_leq: $dateTo\n        }\n        orderBy: [datetimeFiveMinutes_ASC]\n      ) {\n        dimensions {\n          datetimeFiveMinutes\n          keyId\n        }\n        sum {\n          egressBytes\n          ingressBytes\n        }\n        avg {\n          concurrentConnectionsFiveMinutes\n        }\n      }\n    }\n  }\n}\njson\n{\n  \"data\": {\n    \"viewer\": {\n      \"accounts\": [\n        {\n          \"callsTurnUsageAdaptiveGroups\": [\n            {\n              \"avg\": {\n                \"concurrentConnectionsFiveMinutes\": 130\n              },\n              \"dimensions\": {\n                \"datetimeFiveMinutes\": \"2025-12-01T00:00:00Z\",\n                \"keyId\": \"82a58d0aeabfa8f4a4e0c4a9efc9cda5\"\n              },\n              \"sum\": {\n                \"egressBytes\": 609156,\n                \"ingressBytes\": 464326\n              }\n            },\n            {\n              \"avg\": {\n                \"concurrentConnectionsFiveMinutes\": 118\n              },\n              \"dimensions\": {\n                \"datetimeFiveMinutes\": \"2025-12-01T00:05:00Z\",\n                \"keyId\": \"82a58d0aeabfa8f4a4e0c4a9efc9cda5\"\n              },\n              \"sum\": {\n                \"egressBytes\": 534948,\n                \"ingressBytes\": 401286\n              }\n            },\n            ...\n          ]\n        }\n      ]\n    }\n  },\n  \"errors\": null\n}\ngraphql\nquery {\n  viewer {\n    accounts(filter: { accountTag: $accountId }) {\n      callsTurnUsageAdaptiveGroups(\n        limit: 10000\n        filter: { date_geq: $dateFrom, date_leq: $dateTo }\n        orderBy: [datetimeHour_ASC, sum_egressBytes_DESC]\n      ) {\n        dimensions {\n          datetimeHour\n          datacenterCity\n          datacenterCountry\n        }\n        sum {\n          egressBytes\n          ingressBytes\n        }\n      }\n    }\n  }\n}\njson\n{\n  \"data\": {\n    \"viewer\": {\n      \"accounts\": [\n        {\n          \"callsTurnUsageAdaptiveGroups\": [\n            {\n              \"dimensions\": {\n                \"datacenterCity\": \"Chennai\",\n                \"datacenterCountry\": \"IN\",\n                \"datetimeHour\": \"2025-12-01T00:00:00Z\"\n              },\n              \"sum\": {\n                \"egressBytes\": 3416216,\n                \"ingressBytes\": 498927214\n              }\n            },\n            {\n              \"dimensions\": {\n                \"datacenterCity\": \"Mumbai\",\n                \"datacenterCountry\": \"IN\",\n                \"datetimeHour\": \"2025-12-01T00:00:00Z\"\n              },\n              \"sum\": {\n                \"egressBytes\": 1267076,\n                \"ingressBytes\": 1140140\n              }\n            },\n            ...\n          ]\n        }\n      ]\n    }\n  },\n  \"errors\": null\n}\ngraphql\nquery {\n  viewer {\n    accounts(filter: { accountTag: $accountId }) {\n      callsTurnUsageAdaptiveGroups(\n        limit: 10\n        filter: { date_geq: $dateFrom, date_leq: $dateTo }\n        orderBy: [sum_egressBytes_DESC, sum_ingressBytes_DESC]\n      ) {\n        dimensions {\n          keyId\n          customIdentifier\n        }\n        sum {\n          egressBytes\n          ingressBytes\n        }\n        avg {\n          concurrentConnectionsFiveMinutes\n        }\n      }\n    }\n  }\n}\njson\n{\n  \"data\": {\n    \"viewer\": {\n      \"accounts\": [\n        {\n          \"callsTurnUsageAdaptiveGroups\": [\n            {\n              \"avg\": {\n                \"concurrentConnectionsFiveMinutes\": 837305\n              },\n              \"dimensions\": {\n                \"customIdentifier\": \"\",\n                \"keyId\": \"82a58d0aeabfa8f4a4e0c4a9efc9cda5\"\n              },\n              \"sum\": {\n                \"egressBytes\": 160040068147,\n                \"ingressBytes\": 154955460564\n              }\n            }\n          ]\n        }\n      ]\n    }\n  },\n  \"errors\": null\n}\nmermaid\ngraph LR\n    A[Publisher] -->|Low quality| B[Cloudflare Realtime SFU]\n    A -->|Medium quality| B\n    A -->|High quality| B\nB -->|Low quality| C@{ shape: procs, label: \"Subscribers\"}\nB -->|Medium quality| D@{ shape: procs, label: \"Subscribers\"}\nB -->|High quality| E@{ shape: procs, label: \"Subscribers\"}\ntxt\na=simulcast:send f;h;q\na=rid:f send\na=rid:h send\na=rid:q send\njs\nconst transceiver = peerConnection.addTransceiver(track, {\n  direction: \"sendonly\",\n  sendEncodings: [\n    { scaleResolutionDownBy: 1, rid: \"f\" },\n    { scaleResolutionDownBy: 2, rid: \"h\" },\n    { scaleResolutionDownBy: 4, rid: \"q\" },\n  ],\n});\nmermaid\n---\ntitle: Cloudflare Realtime TURN pricing\n---\nflowchart LR\n    Client[TURN Client]\n    Server[TURN Server]\n\nClient -->|\"Ingress (free)\"| Server\n    Server -->|\"Egress (charged)\"| Client\n\nServer <-->|Not part of billing| PeerA[Peer A]\nbash\ncurl https://rtc.live.cloudflare.com/v1/turn/keys/$TURN_KEY_ID/credentials/generate-ice-servers \\\n--header \"Authorization: Bearer $TURN_KEY_API_TOKEN\" \\\n--header \"Content-Type: application/json\" \\\n--data '{\"ttl\": 86400}'\njson\n{\n  \"iceServers\": [\n    {\n      \"urls\": [\n        \"stun:stun.cloudflare.com:3478\",\n        \"stun:stun.cloudflare.com:53\"\n      ]\n    },\n    {\n      \"urls\": [\n        \"turn:turn.cloudflare.com:3478?transport=udp\",\n        \"turn:turn.cloudflare.com:53?transport=udp\",\n        \"turn:turn.cloudflare.com:3478?transport=tcp\",\n        \"turn:turn.cloudflare.com:80?transport=tcp\",\n        \"turns:turn.cloudflare.com:5349?transport=tcp\",\n        \"turns:turn.cloudflare.com:443?transport=tcp\"\n      ],\n      \"username\": \"bc91b63e2b5d759f8eb9f3b58062439e0a0e15893d76317d833265ad08d6631099ce7c7087caabb31ad3e1c386424e3e\",\n      \"credential\": \"ebd71f1d3edbc2b0edae3cd5a6d82284aeb5c3b8fdaa9b8e3bf9cec683e0d45fe9f5b44e5145db3300f06c250a15b4a0\"\n    }\n  ]\n}\njs\nconst myPeerConnection = new RTCPeerConnection({\n  iceServers: [\n    {\n      urls: [\n        \"stun:stun.cloudflare.com:3478\",\n        \"stun:stun.cloudflare.com:53\"\n      ]\n    },\n    {\n      urls: [\n        \"turn:turn.cloudflare.com:3478?transport=udp\",\n        \"turn:turn.cloudflare.com:53?transport=udp\",\n        \"turn:turn.cloudflare.com:3478?transport=tcp\",\n        \"turn:turn.cloudflare.com:80?transport=tcp\",\n        \"turns:turn.cloudflare.com:5349?transport=tcp\",\n        \"turns:turn.cloudflare.com:443?transport=tcp\"\n      ],\n      \"username\": \"bc91b63e2b5d759f8eb9f3b58062439e0a0e15893d76317d833265ad08d6631099ce7c7087caabb31ad3e1c386424e3e\",\n      \"credential\": \"ebd71f1d3edbc2b0edae3cd5a6d82284aeb5c3b8fdaa9b8e3bf9cec683e0d45fe9f5b44e5145db3300f06c250a15b4a0\"\n    },\n  ],\n});\nbash\ncurl --request POST \\\nhttps://rtc.live.cloudflare.com/v1/turn/keys/$TURN_KEY_ID/credentials/$USERNAME/revoke \\\n--header \"Authorization: Bearer $TURN_KEY_API_TOKEN\"\nbash\ncurl https://rtc.live.cloudflare.com/v1/turn/keys/$TURN_KEY_ID/credentials/generate \\\n--header \"Authorization: Bearer $TURN_KEY_API_TOKEN\" \\\n--header \"Content-Type: application/json\" \\\n--data '{\"ttl\": 864000, \"customIdentifier\": \"user4523958\"}'\nplaintext\nquery{\n  viewer {\n    usage: accounts(filter: { accountTag: \"8846293bd06d1af8c106d89ec1454fe6\" }) {\n        callsTurnUsageAdaptiveGroups(\n          filter: {\n          datetimeMinute_gt: \"2024-07-15T02:07:07Z\"\n          datetimeMinute_lt: \"2024-08-10T02:07:05Z\"\n        }\n          limit: 100\n          orderBy: [customIdentifier_ASC]\n        ) {\n          dimensions {\n            customIdentifier\n          }\n          sum {\n            egressBytes\n          }\n        }\n      }\n    }\n  }\nplaintext\nquery{\n  viewer {\n    usage: accounts(filter: { accountTag: \"8846293bd06d1af8c106d89ec1454fe6\" }) {\n        callsTurnUsageAdaptiveGroups(\n          filter: {\n          datetimeMinute_gt: \"2024-07-15T02:07:07Z\"\n          datetimeMinute_lt: \"2024-08-10T02:07:05Z\"\n          customIdentifier: \"myCustomer1111\"\n        }\n          limit: 1\n          orderBy: [customIdentifier_ASC]\n        ) {\n          dimensions {\n            customIdentifier\n          }\n          sum {\n            egressBytes\n          }\n        }\n      }\n    }\n  }\n```\n\n<page>\n---\ntitle: What is TURN? Â· Cloudflare Realtime docs\ndescription: TURN (Traversal Using Relays around NAT) is a protocol that assists\n  in traversing Network Address Translators (NATs) or firewalls in order to\n  facilitate peer-to-peer communications. It is an extension of the STUN\n  (Session Traversal Utilities for NAT) protocol and is defined in RFC 8656.\nlastUpdated: 2025-04-08T20:01:03.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/turn/what-is-turn/\n  md: https://developers.cloudflare.com/realtime/turn/what-is-turn/index.md\n---\n\nTURN (Traversal Using Relays around NAT) is a protocol that assists in traversing Network Address Translators (NATs) or firewalls in order to facilitate peer-to-peer communications. It is an extension of the STUN (Session Traversal Utilities for NAT) protocol and is defined in [RFC 8656](https://datatracker.ietf.org/doc/html/rfc8656).\n\n## How do I use TURN?\n\nJust like you would use a web browser or cURL to use the HTTP protocol, you need to use a tool or a library to use TURN protocol in your application.\n\nMost users of TURN will use it as part of a WebRTC library, such as the one in their browser or part of [Pion](https://github.com/pion/webrtc), [webrtc-rs](https://github.com/webrtc-rs/webrtc) or [libwebrtc](https://webrtc.googlesource.com/src/).\n\nYou can use TURN directly in your application too. [Pion](https://github.com/pion/turn) offers a TURN client library in Golang, so does [webrtc-rs](https://github.com/webrtc-rs/webrtc/tree/master/turn) in Rust.\n\n## Key concepts to know when understanding TURN\n\n1. **NAT (Network Address Translation)**: A method used by routers to map multiple private IP addresses to a single public IP address. This is commonly done by home internet routers so multiple computers in the same network can share a single public IP address.\n\n2. **TURN Server**: A relay server that acts as an intermediary for traffic between clients behind NATs. Cloudflare Realtime TURN service is a example of a TURN server.\n\n3. **TURN Client**: An application or device that uses the TURN protocol to communicate through a TURN server. This is your application. It can be a web application using the WebRTC APIs or a native application running on mobile or desktop.\n\n4. **Allocation**: When a TURN server creates an allocation, the TURN server reserves an IP and a port unique to that client.\n\n5. **Relayed Transport Address**: The IP address and port reserved on the TURN server that others on the Internet can use to send data to the TURN client.\n\n1. A TURN client sends an Allocate request to a TURN server.\n2. The TURN server creates an allocation and returns a relayed transport address to the client.\n3. The client can then give this relayed address to its peers.\n4. When a peer sends data to the relayed address, the TURN server forwards it to the client.\n5. When the client wants to send data to a peer, it sends it through the TURN server, which then forwards it to the peer.\n\nTURN works similar to a VPN (Virtual Private Network). However TURN servers and VPNs serve different purposes and operate in distinct ways.\n\nA VPN is a general-purpose tool that encrypts all internet traffic from a device, routing it through a VPN server to enhance privacy, security, and anonymity. It operates at the network layer, affects all internet activities, and is often used to bypass geographical restrictions or secure connections on public Wi-Fi.\n\nA TURN server is a specialized tool used by specific applications, particularly for real-time communication. It operates at the application layer, only affecting traffic for applications that use it, and serves as a relay to traverse NATs and firewalls when direct connections between peers are not possible. While a VPN impacts overall internet speed and provides anonymity, a TURN server only affects the performance of specific applications using it.\n\n## Why is TURN Useful?\n\nTURN is often valuable in scenarios where direct peer-to-peer communication is impossible due to NAT or firewall restrictions. Here are some key benefits:\n\n1. **NAT Traversal**: TURN provides a way to establish connections between peers that are both behind NATs, which would otherwise be challenging or impossible.\n\n2. **Firewall Bypassing**: In environments with strict firewall policies, TURN can enable communication that would otherwise be blocked.\n\n3. **Consistent Connectivity**: TURN offers a reliable fallback method when direct or NAT-assisted connections fail.\n\n4. **Privacy**: By relaying traffic through a TURN server, the actual IP addresses of the communicating parties can be hidden from each other.\n\n5. **VoIP and Video Conferencing**: TURN is crucial for applications like Voice over IP (VoIP) and video conferencing, ensuring reliable connections regardless of network configuration.\n\n6. **Online Gaming**: TURN can help online games establish peer-to-peer connections between players behind different types of NATs.\n\n7. **IoT Device Communication**: Internet of Things (IoT) devices can use TURN to communicate when they're behind NATs or firewalls.\n\n<page>\n---\ntitle: TURN Feature Matrix Â· Cloudflare Realtime docs\nlastUpdated: 2025-12-05T18:35:45.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/turn/rfc-matrix/\n  md: https://developers.cloudflare.com/realtime/turn/rfc-matrix/index.md\n---\n\n## TURN client to TURN server protocols\n\n| Protocol | Support | Relevant specification |\n| - | - | - |\n| UDP | âœ… | [RFC 5766](https://datatracker.ietf.org/doc/html/rfc5766) |\n| TCP | âœ… | [RFC 5766](https://datatracker.ietf.org/doc/html/rfc5766) |\n| TLS | âœ… | [RFC 5766](https://datatracker.ietf.org/doc/html/rfc5766) |\n| DTLS | No | [draft-petithuguenin-tram-turn-dtls-00](http://tools.ietf.org/html/draft-petithuguenin-tram-turn-dtls-00) |\n\n## TURN client to TURN server protocols\n\n| Protocol | Support | Relevant specification |\n| - | - | - |\n| TURN (base RFC) | âœ… | [RFC 5766](https://datatracker.ietf.org/doc/html/rfc5766) |\n| TURN REST API | âœ… (See [FAQ](https://developers.cloudflare.com/realtime/turn/faq/#does-cloudflare-realtime-turn-support-the-expired-ietf-rfc-draft-draft-uberti-behave-turn-rest-00)) | [draft-uberti-behave-turn-rest-00](http://tools.ietf.org/html/draft-uberti-behave-turn-rest-00) |\n| Origin field in TURN (Multi-tenant TURN Server) | âœ… | [draft-ietf-tram-stun-origin-06](https://tools.ietf.org/html/draft-ietf-tram-stun-origin-06) |\n| ALPN support for STUN & TURN | âœ… | [RFC 7443](https://datatracker.ietf.org/doc/html/rfc7443) |\n| TURN Bandwidth draft specs | No | [draft-thomson-tram-turn-bandwidth-01](http://tools.ietf.org/html/draft-thomson-tram-turn-bandwidth-01) |\n| TURN-bis (with dual allocation) draft specs | No | [draft-ietf-tram-turnbis-04](http://tools.ietf.org/html/draft-ietf-tram-turnbis-04) |\n| TCP relaying TURN extension | No | [RFC 6062](https://datatracker.ietf.org/doc/html/rfc6062) |\n| IPv6 extension for TURN | No | [RFC 6156](https://datatracker.ietf.org/doc/html/rfc6156) |\n| oAuth third-party TURN/STUN authorization | No | [RFC 7635](https://datatracker.ietf.org/doc/html/rfc7635) |\n| DTLS support (for TURN) | No | [draft-petithuguenin-tram-stun-dtls-00](https://datatracker.ietf.org/doc/html/draft-petithuguenin-tram-stun-dtls-00) |\n| Mobile ICE (MICE) support | No | [draft-wing-tram-turn-mobility-02](http://tools.ietf.org/html/draft-wing-tram-turn-mobility-02) |\n\n<page>\n---\ntitle: Background Â· Cloudflare Randomness Beacon docs\ndescription: Over the years, a generation of public randomness (often referred\n  to as common coins) has attracted interest from the cryptography research\n  community. Many distributed systems, including various consensus mechanisms,\n  anonymity networks such as Tor, or blockchain systems, assume access to such\n  public randomness. However, it remained a major unsolved issue to generate\n  public randomness in a distributed, scalable, and robust way. Currently, there\n  is no service deployed to produce this type of randomness. The only choice is\n  a centralized, prototype-only randomness beacon run by NIST.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/randomness-beacon/about/background/\n  md: https://developers.cloudflare.com/randomness-beacon/about/background/index.md\n---\n\nOver the years, a generation of public randomness (often referred to as *common coins*) has attracted interest from the cryptography research community. Many distributed systems, including various consensus mechanisms, anonymity networks such as Tor, or blockchain systems, assume access to such public randomness. However, it remained a major unsolved issue to generate public randomness in a distributed, scalable, and robust way. Currently, there is no service deployed to produce this type of randomness. The only choice is a centralized, prototype-only randomness beacon run by [NIST](https://www.nist.gov/).\n\nRealizing this, [Ewa Syta](http://ewa.syta.us/) started a project on [Scalable Bias-Resistant Distributed Randomness](https://eprint.iacr.org/2016/1067) during her PhD studies under the supervision of [Michael J. Fischer](http://www.cs.yale.edu/homes/fischer/) and [Bryan Ford](https://bford.info/) at Yale University. After Bryan moved to EPFL in 2015, the new members of the DEDIS team at EPFL ([Nicolas Gailly](https://github.com/nikkolasg/), [Linus Gasser](https://people.epfl.ch/linus.gasser), [Philipp Jovanovic](https://jovanovic.io/), [Ismail Khoffi](https://ismailkhoffi.com/), [Eleftherios Kokoris Kogias](https://lefteriskk.github.io/)) joined the project and together published a research paper at the [2017 IEEE Symposium on Security and Privacy](https://ieeexplore.ieee.org/abstract/document/7958592).\n\nThe paper explored the use of key pairings instead of classical elliptic curve cryptography to generate public randomness as a way to simplify the proposed protocol designs and improve performance in terms of randomness generation and verification.\n\nIn early 2017, the [DEDIS](https://dedis.epfl.ch/) team at [EPFL](https://www.epfl.ch/en/) started collaborating with [DFINITY](https://dfinity.org/) on various research topics, including public randomness. The DFINITY architecture is built around a pairing-based randomness beacon sharing similarities to the constructs described in the DEDIS paper. Additionally, DFINITY has already implemented an optimized pairing library in C++. After integrating this implementation into the DEDISâ€™ crypto library [Kyber](https://github.com/dedis/kyber), all major cryptographic components were ready to implement an efficient, distributed randomness generation protocol using pairings.\n\nIn September 2017, Nicolas, a PhD student at DEDIS, started coding drand with the help of Philipp to deploy, for the first time, a distributed service providing public randomness in an application-agnostic, secure, and efficient way. A short time later, Cloudflare released an optimized Golang implementation of the BN256 pairing curve, which is now integrated in both Kyber and drand to simplify development and deployment.\n\nAs drand gained maturity, an increasing number of organizations (including NIST, Cloudflare, Kudelski Security, the University of Chile, and Protocol Labs) started taking interest, and decided to collectively work on setting up a [drand](https://github.com/dedis/drand) network spanning these organizations. To support the use of public randomness in web applications, [Mathilde Raynal](https://people.epfl.ch/mathilde.raynal?lang=en), a master student at DEDIS, started developing a JavaScript proof-of-concept frontend, called [drandjs](https://github.com/PizzaWhisperer/drandjs), to interact with drand servers.\n\nIn spring 2020, a team at Protocol Labs led efforts to take drand from an experimental to production-ready network. These efforts included significant protocol upgrades, establishment of a governance model for the distributed network, and increased operational security of node operators. Check out the [drand blog](https://drand.love/blog/2020/08/10/drand-launches-v1-0/) for more details.\n\n<page>\n---\ntitle: Future of drand Â· Cloudflare Randomness Beacon docs\ndescription: As of spring 2020, the drand network is production-ready and can\n  now be considered foundational Internet infrastructure, much like DNS or BGP.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/randomness-beacon/about/future/\n  md: https://developers.cloudflare.com/randomness-beacon/about/future/index.md\n---\n\nAs of spring 2020, the drand network is production-ready and can now be considered foundational Internet infrastructure, much like DNS or BGP.\n\nWhile the project has reached a mature state, we believe there are several ways for drand to continue to evolve.\n\n* We would like to continue to see reliable partners join the network; the more participants in the network, the stronger the guarantees.\n\n* We would like to investigate how to generate public randomness in a post-quantum secure way (like, through isogeny, lattice, and so on).\n\n* We would like to consider standardization of the core drand protocol.\n\nWe are proud to be a part of these efforts and hope to see even more adoption of drand in third-party applications and systems.\n\n<page>\n---\ntitle: Randomness Generation Â· Cloudflare Randomness Beacon docs\ndescription: In this section, we describe how to use this collective key pair to\n  generate publicly-verifiable, unbiasable, and unpredictable randomness in a\n  distributed manner.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/randomness-beacon/cryptographic-background/randomness-generation/\n  md: https://developers.cloudflare.com/randomness-beacon/cryptographic-background/randomness-generation/index.md\n---\n\nIn this section, we describe how to use this collective key pair to generate publicly-verifiable, unbiasable, and unpredictable randomness in a distributed manner.\n\nFirst, we explain pairing-based cryptography (PBC), which has become quite popular, and is used in many modern consensus protocols or zero-knowledge proofs, such as zk-SNARKs. We will then show how drand uses PBC for the randomness beacon generation phase for threshold Boneh-Lynn-Shacham (BLS) signatures. Finally, we will discuss how drand links the generated threshold BLS signatures into a randomness chain.\n\n## Pairing-based Cryptography\n\nPairing-based cryptography is based on bilinear groups `(ð”¾1,ð”¾2,ð”¾ð‘¡)`, where `ð”¾1`, `ð”¾2`, and `ð”¾ð‘¡` are cyclic groups of prime order `ð‘` with generators `ð‘”1`, `ð‘”2`, and `ð‘”ð‘¡`, respectively, and a pairing operation `ð‘’:ð”¾1Ã—ð”¾2â†’ð”¾ð‘¡` with these properties:\n\n* **Bilinearity:** `âˆ€ð‘Ž,ð‘âˆˆâ„¤âˆ—ð‘,âˆ€ð‘ƒâˆˆð”¾1,âˆ€ð‘„âˆˆð”¾2,` we have `ð‘’(ð‘Žð‘ƒ,ð‘ð‘„)=ð‘’(ð‘ƒ,ð‘„)ð‘Žð‘`\n\n* **Non-degeneracy:** `ð‘’â‰ 1`\n\n* **Computability:** There exists an efficient algorithm to compute `ð‘’`. drand currently uses the Barreto-Lynn-Scott curve BLS12-381.\n\nTo generate publicly-verifiable, unbiasable, distributed randomness, drand utilizes threshold Boneh-Lynn-Shacham (BLS) signatures. First we will describe regular BLS signatures and then the threshold variant.\n\nBLS signatures are short signatures that rely on bilinear pairings and consist only of a single element in `ð”¾1`. They are deterministic in the sense they depend only on the message and the signerâ€™s key, unlike other signature schemes, such as ECDSA, that require a fresh random value for each signed message to be secure. Put differently, any two BLS signatures on a given message produced with the same key are identical. In drand, we utilize this property to achieve unbiasability for randomness generation.\n\nThe BLS signature scheme consists of the these sub-procedures.\n\nTo generate a key pair, a signer first chooses a private key, `ð‘¥âˆˆâ„¤âˆ—ð‘`, at random, and then computes the corresponding public key as `ð‘‹=ð‘”ð‘¥2âˆˆð”¾2`.\n\n### Signature Generation\n\nLet `ð»:{0,1}âˆ—â†’ð”¾1` denote a cryptographic hash function that maps arbitrary bit strings to elements of `ð”¾1`. To compute a BLS signature `ðœŽ` on a message `ð‘š`, the signer computes `ðœŽ=ð‘¥ð»(ð‘š)âˆˆð”¾1`.\n\n### Signature Verification\n\nTo verify that a BLS signature `ðœŽ` on a message `ð‘š` is valid, the verifier checks if `ð‘’(ð»(ð‘š),ð‘‹)=ð‘’(ðœŽ,ð‘”2)` holds using the signerâ€™s public key `ð‘‹`.\n\nNote that this equation holds for valid signatures since `ð‘’(ð»(ð‘š),ð‘‹)=ð‘’(ð»(ð‘š),ð‘”ð‘¥2)=ð‘’(ð»(ð‘š),ð‘”2)ð‘¥=ð‘’(ð‘¥ð»(ð‘š),ð‘”2)=ð‘’(ðœŽ,ð‘”2)`.\n\n## Threshold BLS Signature\n\nThe goal of a threshold signature scheme is to collectively compute a signature by combining individual partial signatures independently generated by the participants. A threshold BLS signature scheme has the following sub-procedures.\n\nThe `ð‘›` participants run a `ð‘¡-of-ð‘›` DKG to setup a collective public key, `ð‘†âˆˆð”¾2`, and private key shares `ð‘ ð‘–âˆˆâ„¤âˆ—ð‘` of the unknown collective private key, `ð‘ `, as described above.\n\n### Partial Signature Generation\n\nTo sign a message, `ð‘š`, each `ð‘–` uses their private key share, `ð‘ ð‘–`, to create a partial BLS signature, `ðœŽð‘–=ð‘ ð‘–ð»(ð‘š)`.\n\n### Partial Signature Verification\n\nTo verify the correctness of a partial signature, `ðœŽð‘–`, on `ð‘š`, a verifier uses the public key share, `ð‘†ð‘–`, generated during the DKG, and verifies that `ð‘’(ð»(ð‘š),ð‘†ð‘–)=ð‘’(ðœŽð‘–,ð‘”2)` holds.\n\n### Signature Reconstruction\n\nTo reconstruct the collective BLS signature, `ðœŽ` on `ð‘š`, a verifier first gathers `ð‘¡` different and valid partial BLS signatures, `ðœŽð‘–`, on `ð‘š` followed by a Lagrange interpolation.\n\n### Signature Verification\n\nTo verify a collective BLS signature, `ðœŽ`, a verifier checks that `ð‘’(ð»(ð‘š),ð‘†)=ð‘’(ðœŽ,ð‘”2)` holds, where `ð‘†` is the collective public key.\n\nThanks to the properties of Lagrange interpolation, the value of `ðœŽ` is independent of the subset of `ð‘¡` valid partial signatures, `ðœŽð‘–`, chosen during signature reconstruction. Additionally, Lagrange interpolation also guarantees that no set of less than `ð‘¡` signers can predict or bias `ðœŽ`.\n\nIn summary, a threshold BLS signature, `ðœŽ`, exhibits all properties required for publicly-verifiable, unbiasable, unpredictable, and distributed randomness.\n\nIn the above, `ð”¾1` and `ð”¾2` could be swapped. The implication is on the relative size of public key and signatures. The first drand chains are constructed as described above, with signatures on `ð”¾2` and public keys on `ð”¾1`. Signature size is 96 bytes, and public key size is 48 bytes.\n\nCertain applications prefer smaller signatures at the cost of a larger public key. This is why certain drand beacons have signatures on `ð”¾1` and public key on `ð”¾2`. Such a change is referred to as `ð”¾1/ð”¾2 swap`.\n\n## Chained Randomness\n\nThe drand randomness beacon operates in discrete rounds, `ð‘Ÿ`. In every round, drand beacons configured to use chained randomness produce a new random value using threshold BLS signatures linked together into a chain of randomness. To extend this chain of randomness, each drand participant, `ð‘–`, creates in round `ð‘Ÿ` the partial BLS signature, `ðœŽð‘Ÿð‘–` on the message `ð‘š=ð»(ð‘Ÿâˆ¥ðœŽð‘Ÿâˆ’1)` where, `ðœŽð‘Ÿâˆ’1` denotes the (full) BLS threshold signature from round `ð‘Ÿâˆ’1` and `ð»`, a cryptographic hash function.\n\nOnce at least `ð‘¡` participants have broadcasted their partial signatures, `ðœŽð‘Ÿð‘–`, on `ð‘š`, anyone can recover the full BLS threshold signature, `ðœŽð‘Ÿ` that corresponds to the random value of round `ð‘Ÿ`. After this, drand nodes move to round `ð‘Ÿ+1` and reiterate the process.\n\nFor round `ð‘Ÿ=0`, drand participants sign a seed fixed during drand setup. This process ensures that every new random value depends on all previously generated signatures. Since the signature is deterministic, there is also no possibility for an adversary forking the chain and presenting two distinct signatures `ðœŽð‘Ÿ` and `ðœŽâ€²ð‘Ÿ` in a given round `ð‘Ÿ` to generate inconsistencies in the systems relying on public randomness.\n\n## Unchained Randomness\n\ndrand beacons can also be configured to use unchained randomness. To extend this chain of randomness, each drand participant, `ð‘–`, creates in round `ð‘Ÿ` the partial BLS signature, `ðœŽð‘Ÿð‘–` on the message `ð‘š=ð»(ð‘Ÿ)` where `ð»` a cryptographic hash function.\n\nThis process allows for a direct precomputation of message `ð‘š` for round `ð‘Ÿ=i`.\n\n<page>\n---\ntitle: Setup Phase Â· Cloudflare Randomness Beacon docs\ndescription: In the drand setup phase, you create a collective private and\n  public key pair shared among ð‘› participants. This is done through a ð‘¡-of-ð‘›\n  Distributed Key Generation (DKG) process and results in each participant\n  receiving a copy of the collective public key plus a private key share of the\n  collective private key â€” no individual node knows the collective private key.\n  Each private key share can then be used to perform cryptographic threshold\n  computations, such as generating threshold signatures, where at least ð‘¡\n  contributions produced using the individual private key shares are required to\n  successfully finish the collective operation.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/randomness-beacon/cryptographic-background/setup-phase/\n  md: https://developers.cloudflare.com/randomness-beacon/cryptographic-background/setup-phase/index.md\n---\n\nIn the drand setup phase, you create a collective private and public key pair shared among *ð‘›* participants. This is done through a `ð‘¡-of-ð‘›` Distributed Key Generation (DKG) process and results in each participant receiving a copy of the collective public key plus a private key share of the collective private key â€” no individual node knows the collective **private** key. Each private key share can then be used to perform cryptographic threshold computations, such as generating threshold signatures, where at least `ð‘¡` contributions produced using the individual private key shares are required to successfully finish the collective operation.\n\nA DKG is performed in a fully distributed manner, avoiding any single points of failure. This is an overview of the different sub-components of the drand DKG implementation.\n\nSecret sharing is an important technique many advanced threshold cryptography mechanisms rely on.\n\nSecret sharing allows you to split a secret value `ð‘ ` into `ð‘›` shares `ð‘ 1,â€¦,ð‘ ð‘›` so that `ð‘ ` can only be reconstructed if a threshold of `ð‘¡` shares is available.\n\n## Shamirâ€™s Secret Sharing (SSS)\n\nThe SSS scheme is one of the most well-known and widely used secret sharing approaches, and a core component of drand. SSS works over an arbitrary finite field, but a simplistic approach uses the integers modulo `ð‘`, denoted by `â„¤ð‘`. Let `ð‘ âˆˆâ„¤ð‘` denote the secret to share.\n\n### Share Distribution\n\nTo share `ð‘ `, a dealer first creates a polynomial, `ð‘ž(ð‘¥)=ð‘Ž0+ð‘Ž1ð‘¥+â‹¯+ð‘Žð‘¡âˆ’1ð‘¥ð‘¡âˆ’1` with `ð‘Ž0=ð‘ ` and (random) `ð‘Žð‘–âˆˆâ„¤ð‘` for `ð‘–=1,â€¦,ð‘¡âˆ’1` and then creates one share ð‘ ð‘– for each participant ð‘– by evaluating ð‘ž(ð‘¥) at the integer ð‘– and setting ð‘ ð‘–=(ð‘–,ð‘ž(ð‘–)).\n\n### Secret Reconstruction\n\nTo recover the secret `ð‘ `, collect at least `ð‘¡` shares, then uniquely reconstruct `ð‘ž(ð‘¥)` using Lagrange interpolation and obtain `ð‘ ` as `ð‘ =ð‘Ž0=ð‘ž(0)`.\n\nNote that you can use any subset of `ð‘¡-of-ð‘›` shares to perform Lagrange interpolation and uniquely determine `ð‘ `; however, having a subset of less than `ð‘¡` shares does not allow to learn anything about `ð‘ `.\n\n## Verifiable Secret Sharing\n\nSSS scheme assumes that the dealer is honest, but this may not always hold in practice. A Verifiable Secret Sharing (VSS) scheme protects against malicious dealers by enabling participants to verify that their shares are consistent with those dealt to other nodes, ensuring that the shared secret can be correctly reconstructed later.\n\ndrand uses Feldmanâ€™s VSS scheme, an extension of SSS. Let `ð”¾` denote a cyclic group of prime order `ð‘` in which computing discrete logarithms is intractable. A *cyclic group* means there exists a generator, `ð‘”`, so that any element `ð‘¥âˆˆð”¾` can be written as `ð‘¥=ð‘”ð‘Ž` for some `ð‘Žâˆˆ{0,â€¦,ð‘âˆ’1}`.\n\n### Share Distribution\n\nIn addition to distributing shares of the secret to participants, the dealer also broadcasts commitments to the coefficients of the polynomial `ð‘ž(ð‘¥)` of the form `(ð´0,ð´1,â€¦,ð´ð‘¡âˆ’1)=(ð‘”ð‘ ,ð‘”ð‘Ž1,â€¦,ð‘”ð‘Žð‘¡âˆ’1)`. These commitments enable individual participants, `ð‘–`, to verify that their share `ð‘ ð‘–=(ð‘–,ð‘ž(ð‘–))` is consistent with respect to the polynomial `ð‘ž(ð‘¥)` by checking that `ð‘”ð‘ž(ð‘–)=âˆð‘¡âˆ’1ð‘—=0(ð´ð‘—)ð‘–ð‘—` holds.\n\n### Secret Reconstruction\n\nThe recovery of secret `ð‘ ` works the same as regular SSS, except that verified to be valid shares are used.\n\n## Distributed Key Generation (DKG)\n\nAlthough VSS schemes protect against a malicious dealer, the dealer still knows the secret. To create a collectively shared secret `ð‘ ` so no individual node gets any information about it, participants can use a DKG protocol. drand uses Pedersenâ€™s DKG scheme, which runs `ð‘›` instances of Feldmanâ€™s VSS in parallel and on top of additional verification steps.\n\n### Share Distribution\n\nIndividual participants, `ð‘–`, create a (random) secret, `ð‘ ð‘–âˆˆâ„¤ð‘`, and share it all participants using VSS, sending a share, `ð‘ ð‘–,ð‘—` to each `ð‘—` and broadcasts the list of commitments `(ð´ð‘–,0,ð´ð‘–,1,â€¦,ð´ð‘–,ð‘¡âˆ’1)` to everyone.\n\n### Share Verification\n\n`ð‘—` verifies the shares received as prescribed by Feldmanâ€™s VSS scheme. If `ð‘—` receives an invalid share, `ð‘ ð‘–,ð‘—`, from `ð‘–`, then `ð‘—` broadcasts a complaint. `ð‘–` must reveal the correct share `ð‘ ð‘–,ð‘—` or they are considered an invalid dealer.\n\n### Share Finalization\n\nAt the end of the protocol, the final share of `ð‘–` is `ð‘ ð‘–=âˆ‘ð‘—ð‘ ð‘—,ð‘–` for all valid participants `ð‘—` , that is, for all `ð‘—`s not excluded during the verification phase.\n\nThe collective public key associated with the valid shares can be computed as `ð‘†=âˆ‘ð‘—ð´ð‘—,0` for all valid `ð‘—`s.\n\n**Note:** Even though the secret created using Pedersenâ€™s DKG can be biased, it is safe to use for threshold signing as shown by Rabin et al.\n\n<page>\n---\ntitle: Content Delivery Network (CDN) Reference Architecture Â· Cloudflare\n  Reference Architecture docs\ndescription: This reference architecture discusses the traditional challenges\n  customers face with web applications, how the Cloudflare CDN resolves these\n  challenges, and CDN architecture and design.\nlastUpdated: 2025-10-13T13:40:40.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/reference-architecture/architectures/cdn/\n  md: https://developers.cloudflare.com/reference-architecture/architectures/cdn/index.md\n---\n\nEvery day, users of the Internet enjoy the benefits of performance and reliability provided by [content delivery networks](https://www.cloudflare.com/learning/cdn/what-is-a-cdn/) (CDNs). CDNs have become a must-have to combat latency and a requirement for any major company delivering content to users on the Internet. While providing performance and reliability for customers, CDNs also enable companies to further secure their applications and cut costs. This document discusses the traditional challenges customers face with web applications, how the Cloudflare CDN resolves these challenges, and CDN architecture and design.\n\n### Who is this document for and what will you learn?\n\nThis reference architecture is designed for IT or network professionals with some responsibility over or familiarity with their organization's existing infrastructure. It is useful to have some experience with technologies and concepts important to content delivery, including caching, DNS and firewalls.\n\nTo build a stronger baseline understanding of Cloudflare, we recommend the following resources:\n\n* What is Cloudflare? | [Website](https://www.cloudflare.com/what-is-cloudflare/) (5 minute read) or [video](https://youtu.be/XHvmX3FhTwU?feature=shared) (2 minutes)\n\n- What is a CDN? | [Website](https://www.cloudflare.com/learning/cdn/what-is-a-cdn/) (5 minute read)\n- Analyst Report: [Cloudflare named Leader in 2024 GigaOm Radar for Content Delivery Networks](https://www.cloudflare.com/lp/gigaom-radar-cdn/) (20 minute read)\n\nThose who read this reference architecture will learn:\n\n* How Cloudflare CDN can significantly improve the delivery of content to your customers\n* How anycast IP routing is important in ensuring reliable CDN performance\n* The range of tiered caching options and how to choose the one for your needs\n\n## Traditional challenges deploying web applications\n\nOver the last several years, especially with the advent of the COVID-19 pandemic and the focus on remote work, there has been a significant growth in Internet traffic, further growing the need to efficiently manage network traffic, cut latency, and increase performance.\n\nCompanies running their applications in the cloud or on-premise are faced with the challenges of:\n\n1. Implementing solutions to increase performance\n2. As demand grows, scaling out their architecture to meet availability and redundancy concerns\n3. Securing their environments and applications from growing Internet threats\n4. Reining in growing costs related to doing all of the above\n\nWith companies serving customers across the globe, the above challenges require a significant undertaking. Traditionally, a website/application is deployed centrally and replicated to another region for availability, or the website/application is deployed across a handful of servers, sometimes across multiple data centers for resiliency.\n\nThe servers hosting the websites are called origin servers. When clients access a website, they make a request for resources from the server. Navigating to one website can generate hundreds of requests from the browser for HTML, CSS, images, videos, etc. With versions of HTTP prior to HTTP/2, each of these HTTP requests would also require a new TCP connection.\n\nEnhancements in HTTP/2 and HTTP/3 allow for multiplexing multiple requests to the same server over a single TCP connection, thus saving server resources. However, compute and network resources are still consumed as servers respond to these requests. As more clients access the website, the following can result:\n\n* The origin server starts to become overloaded with requests, impacting availability; companies start looking at scaling out to handle the additional load\n* As each request has to make its way to the origin server, performance and user experience is impacted due to latency\n* The latency for end users becomes proportional to the distance between the client and origin server, thus resulting in varying experiences based on client location. This is especially true for specific countries that may experience latency due to traffic from or to that country, like China.\n* As origin servers respond to the increasing requests, bandwidth, egress, and compute costs increase drastically\n* Even as customers scale out to handle the increased demand in traffic, they are left exposed to both infrastructure-level and application-level distributed denial-of-service (DDoS) attacks\n\nIn Figure 1 below, there is no CDN present and there is an origin server sitting in the US. As clients access the website, the first step is DNS resolution, typically done by the userâ€™s ISP. The next step is the HTTP request sent directly to the origin server. The user experience will vary depending on their location. For example, you can see the latency is much lower for users in the US, where the origin server is located. For users outside the US, the latency increases, thus resulting in a higher round-trip time (RTT).\n\nAs more clients make requests to the origin server, the load on the network and server increases, resulting in higher latency and higher costs for resource and bandwidth use.\n\nFrom a security perspective, the origin server is also vulnerable to DDoS attacks at both the infrastructure and application layer. A DDoS attack could be initiated from a botnet sending millions of requests to the origin server, consuming resources and preventing it from serving legitimate clients.\n\nFurther, in terms of resiliency, if the origin server temporarily goes offline, all content is inaccessible to users.\n\n![Figure 1: Diagram of HTTP web requests between DNS and origin server without a CDN.](https://developers.cloudflare.com/_astro/ref-arch-cdn-figure1.BH2E9Wnc_Z2dhi1l.svg)\n\n## How a CDN tackles web application challenges\n\nA CDN helps address the challenges customers face around latency, performance, availability, redundancy, security, and costs. A CDN's core goal is to decrease latency and increase performance for websites and applications by caching content as close as possible to end users or those accessing the content.\n\nCDNs decrease latency and increase performance by having many data center locations across the globe that cache the content from the origin. The goal is to have content cached as close as possible to users, so content is cached at the edge of the CDN provider's network.\n\n* **Improved website load time**: Instead of every client making a request to the origin server, which could be located a considerable distance away, the request is routed to a local server that responds with cached content, thus decreasing latency and increasing overall performance. Regardless of where the origin server and clients are located, performance will be more consistent for all users, as the CDN will serve locally cached content when possible.\n\n* **Increased content availability and redundancy:** Because every client request no longer needs to be sent to the origin server, CDNs provide not only performance benefits, but also availability and redundancy. Requests are load balanced over local servers with cached content; these servers respond to local requests, significantly decreasing overall load on the origin server. The origin server only is contacted when needed (when content is not cached or for dynamic non-cacheable content).\n\n* **Improved website security:** A CDN acts as a reverse proxy and sits in front of origin servers. Thus it can provide enhanced security such as DDoS mitigation, improvements to security certificates, and other optimizations.\n\n* **Reduced bandwidth costs:** Because CDNs use cached content to respond to requests, the number of requests sent to the origin server is reduced, thus also reducing associated bandwidth costs.\n\n### Routing requests to CDN nodes\n\nAn important difference in some CDN implementations is how they route traffic to the respective local CDN nodes. Routing requests to CDN nodes can be done via two different methods:\n\n**DNS unicast routing**\n\nIn this method, recursive DNS queries redirect requests to CDN nodes; the clientâ€™s DNS resolver forwards requests to the CDNâ€™s authoritative nameserver. CDNs based on DNS unicast routing are not ideal in that clients may be geographically dispersed from the DNS resolver. Decisions on closest-proximity CDN nodes are based on the client's DNS server instead of clientâ€™s IP address. Also, if any changes are needed for the DNS response, there is a dependency on DNS time to live (TTL) expiration.\n\nFurther, since DNS routing uses unicast addresses, traffic is routed directly to a specific node, creating possible concerns when there are traffic spikes, as in a DDoS attack.\n\nAnother challenge with DNS-based CDNs is that DNS is not very graceful upon failover. Typically a new session or application must be started for the DNS resolver with a different IP address to take over.\n\nThe Cloudflare CDN, which is discussed in more detail in the next section, uses anycast routing. Anycast allows for nodes on a network to have the same IP address. The same IP address is announced from multiple nodes in different locations, and client redirection is handled via the Internetâ€™s routing protocol, BGP.\n\nUsing an anycast-based CDN has several advantages:\n\n* Incoming traffic is routed to the nearest data center with the capacity to process the requests efficiently.\n* Availability and redundancy is inherently provided. Since multiple nodes have the same IP address, if one node were to fail, requests are simply routed to another node in close proximity.\n* Because anycast distributes traffic across multiple data centers, it increases the overall surface area, thus preventing any one location from becoming overwhelmed with requests. For this reason, anycast networks are very resilient to DDoS attacks.\n\n## Introducing the Cloudflare CDN\n\nCloudflare provides a Software as a Service (SaaS) model for CDN. With Cloudflareâ€™s SaaS model, customers benefit from the Cloudflare CDN without having to manage or maintain any infrastructure or software.\n\nThe benefits of the Cloudflare CDN can be attributed to the below two points, discussed in more detail in this section.\n\n1. CDNs inherently increase performance by caching content on servers close to the user\n2. The unique Cloudflare architecture and integrated ecosystem\n\nFigure 2 shows a simplified view of the Cloudflare CDN. Clients are receiving their response back from a server on Cloudflareâ€™s global anycast network closest to where the clients are located, thus drastically reducing the latency and RTT. The diagram depicts a consistent end-user experience regardless of the physical location of the clients and origin.\n\n![Figure 2 is a diagram representing the traffic between a client and a server on Cloudflare's global anycast network at different client locations.](https://developers.cloudflare.com/_astro/ref-arch-cdn-figure2.DP9jXMC9_ZzHUMS.svg)\n\n## Cloudflare CDN architecture and design\n\nFigure 3 is a view of the Cloudflare CDN on the global anycast network. In addition to using anycast for network performance and resiliency, the Cloudflare CDN leverages Tiered Cache to deliver optimized results while saving costs for customers. Customers can also [enable Argo Smart Routing](https://developers.cloudflare.com/argo-smart-routing/get-started/) to find the fastest network path to route requests to the origin server. These capabilities are discussed in detail in the remainder of this document.\n\n![Figure 3: Diagram representing requests coming from an end user, protected by Cloudflare products including WAF and DDoS protection, and traveling through the anycast Network to reach the origin server using Smart Tiered Cache.](https://developers.cloudflare.com/_astro/ref-arch-cdn-figure3.CcIfEHZq_1mhfV1.svg)\n\nIn the above diagram, there are a few important key points to understand about the Cloudflare CDN and the global anycast network it resides on:\n\n* An important differentiator is that Cloudflare utilizes one global network and runs every service on every server in every Cloudflare data center, thus providing end users the closest proximity to Cloudflareâ€™s services, with the highest scale, resiliency, and performance.\n* Cloudflare is a reverse proxy, meaning it receives requests from clients and proxies the requests back to the customerâ€™s origin servers. Thus, every request traverses through Cloudflareâ€™s network before reaching the customerâ€™s network. Since Cloudflare has hardened and protected its infrastructure at the edge (ingress), all customers are consequently also protected from infrastructure-level and volumetric DDoS attacks. Requests and traffic must go through the protected Cloudflare network before reaching the customerâ€™s origin server.\n* The Cloudflare CDN leverages the Cloudflare global anycast network. Thus the incoming request is routed to and answered by the node closest to the user.\n* The inherent benefits of anycast are decreased latency, network resiliency, higher availability, and increased security due to larger surface area for absorbing both legitimate traffic loads and DDoS attacks. Cloudflareâ€™s global anycast network spans [hundreds of cities worldwide](https://www.cloudflare.com/network/), reaching 95% of the worldâ€™s Internet-connected population within 50 milliseconds while providing over 405 Tbps network capacity and DDoS protection capability.\n* Edge nodes within the Cloudflare network cache content from the origin server and are able to respond to requests via a cached copy. Cloudflare also provides [DNS](https://developers.cloudflare.com/dns/), [DDoS protection](https://developers.cloudflare.com/ddos-protection/), [WAF](https://developers.cloudflare.com/waf/), and other performance, reliability, and security services using the same edge architecture.\n* [Argo](https://developers.cloudflare.com/argo-smart-routing/) uses optimized routing and caching technology across the Cloudflare network to deliver responses to users more quickly, reliably, and securely. Argo includes Smart Routing and [Tiered Cache](https://developers.cloudflare.com/cache/how-to/tiered-cache/). Cloudflare leverages Argo to provide an enhanced CDN solution.\n\nOnce a site is onboarded, standard caching is configured by default. With standard caching, each data center acts as a direct reverse proxy for the origin servers. A cache miss in any data center results in a request being sent to the origin server from the ingress data center.\n\nAlthough standard caching works, it is not the most optimal design â€” cached content closer to the client may already exist in other Cloudflare data centers, and origin servers are sometimes unnecessarily overloaded as a result. Thus, it is best to enable Tiered Cache, which is included with every Cloudflare plan. With Tiered Cache, certain data centers are reverse proxies to the origin for other data centers, resulting in more cache hits and faster response times.\n\nTiered Cache leverages the scale of Cloudflareâ€™s network to minimize requests to customer origins. When a request comes into a Cloudflare data center, if the requested content is not locally cached, other Cloudflare data centers are checked for the cached content.\n\nCloudflare data centers have shorter distances and faster paths between them than the connections between data centers and customer origin servers, optimizing the response to the client with a significant improvement in cache hit ratio. The Cloudflare CDN leverages Argo Smart Routing data to determine the best upper tier data centers to use for Tiered Cache. Argo Smart Routing can also be enabled as an add-on to provide the fastest paths between data centers and origin servers for cache misses and other types of dynamic traffic.\n\nThe Cloudflare CDN allows customers to configure tiered caching. Note that depending on the Cloudflare plan, different topologies are available for Tiered Cache. By default, tiered caching is disabled and can be enabled under the caching tab of the main menu. â€‹â€‹\n\n#### Tiered Cache topologies\n\nThe different cache topologies allow customers to control how Cloudflare interacts with origin servers to help ensure higher cache hit ratios, fewer origin connections, and reduced latency.\n\n| **Smart Tiered Cache Topology (all plans)** | **Generic Global Tiered Topology (Enterprise only)** | **Custom Tiered Cache Topology (Enterprise only)** |\n| - | - | - |\n| Recommended for most deployments. It is the default configuration once Tiered Cache is enabled. | Recommended for those who have high traffic that is spread across the globe and desire the highest cache usage and best performance possible. | Recommended for customers who have additional data on their user base and have specific geographic regions they would like to focus on. |\n| Ideal for customers who want to leverage CDN for performance but minimize requests to origin servers and bandwidth utilization between Cloudflare and origin servers. | Generic Global Tiered Topology balances between cache efficiency and latency. Instructs Cloudflare to use all Tier 1 data centers as upper tiers. | Custom Tiered Cache Topology allows customers to set a custom topology that fits specific needs (ex: upper tiers in specific geographic locations serving more customers). |\n| Cloudflare will dynamically find the single best upper tier for an origin using Argo performance and routing data. | | Engage your account team to build a custom topology. |\n\n### Traffic flow: Tiered Cache, Smart Tiered Cache topology\n\nIn Figure 4, Tiered Caching is enabled with Smart Tiered Cache Topology. The diagram depicts two separate traffic flows, summarized below. The first traffic flow (Client 1) is a request from a client that comes into Data Center 1. The second traffic flow (Client 2) is a subsequent request for the same resource into a different data center, Data Center 2.\n\n![Figure 4: The same diagram as Figure 3 demonstrating requests between end users and origin server over the anycast Network, with bidirectional arrows indicating traffic flow enabled by Smart Tiered Cache.](https://developers.cloudflare.com/_astro/ref-arch-cdn-figure4.kIutXMs6_Z1zLO2B.svg)\n\n| Request 1 | Request 2 |\n| - | - |\n| First request received in Data Center 1 results in cache miss, as request had not been made previously by any client. | Second request by a different client received in Data Center 3 results in cache miss, as request had not been made previously by any client served by Data Center 3. |\n| No cached content found, so Data Center 1 checks with its upper tier data center to request a copy of the content. | No cached content found, so Data Center 3 checks with the upper tier data center to request a copy of the content. |\n| Upper tier data center also does not have content cached locally, so it makes a request to the origin server for content. Upon receiving the content, the upper tier data center caches it locally and relays the content to the requesting lower tier data center. The lower tier data center caches the content and responds to the client. | Cached content found at the upper tier data center. Data Center 3 retrieves and caches this content locally and responds to the client. |\n\nIn Figure 4, the top end user traffic flow displays the traffic flow when a client request is received by a data center closest to the client, Data Center 1. Since there is nothing locally cached on the ingress data center and tiered caching is enabled, a request is sent to the upper tier data center to request a copy of the content to cache. Because the upper tier data center also does not have the content cached, it sends the request to the origin server, caches the received content upon response, and responds to the lower tier data center with the cached content. The lower tier data center caches the content and responds to the client.\n\nNotice that when a new request for the same content is made to another data center (bottom end user traffic flow), Data Center 3, the content is not locally cached; however, the content is retrieved from the upper tier data center, where it was cached from the first request for the same content.\n\nWith the upper tier data center returning the cached content for the second request, the trip to the origin server is prevented, resulting in higher cache hit ratios, faster response times, saved bandwidth cost between the Cloudflare network and the origin server, and reduced load on the origin server responding to requests.\n\n### Regional Tiered Cache\n\nThe main difference between Smart Tiered Cache and Global tiered cache is the number of upper tiers that can talk to the origin servers. With Smart Tiered Cache the closest upper tier to the origin is selected using Argo performance and routing data. This means that all requests that experience a cache `MISS` at a lower tier will funnel through this single upper tier and have a higher percentage chance of a cache `HIT` to avoid sending traffic to an origin server. However, the downside to this architecture is that the lower tier could be located across the globe from the upper tier. Even if the upper tier can fulfill the request from its cache, the distance between the upper tier and lower tier could still add latency to the response depending on the distance traveled. To summarize, Smart Tiered Cache ensures that all requests for cache flow through a single upper tier cache location which increases cache `HIT` percentages, and reduces requests to the origin server, however it can result in higher latencies fulfilling those requests since the upper tier could be located far away from the lower tier that originated the request.\n\nWith Generic Global Tiered Cache, Cloudflare uses its largest data centers around the globe as upper tier cache which means, in general, that the upper tier cache is much closer to the lower tier cache. This can greatly reduce latency when lower tiers need to pass requests to upper tiers. However, this ultimately will increase the amount of requests serviced by the origin as each upper tier cache will need to populate from the origin. To summarize, Generic Global Tiered cache can improve response times when cache is populated, but will also increase load on the origin servers.\n\nRegional Tiered Cache combines the best of both of these strategies together by adding an additional layer of cache to the architecture. Using the Regional Tiered Cache option with Smart Tiered Caching means that while a single upper tier cache location exists closest to the origin, a Regional Tier layer has been added between the upper and lower tier that is geographically closer to the lower tier. Now, requests from lower tiers will now check a Regional Tier for cache before being sent to an upper tier. A single Regional Tier can accept requests from several lower tier caches and because of that, can greatly improve performance and latency for globally available applications.\n\nRegional Tiered Caching is recommended for use with Smart Tiered Caching and Custom Tiered Caching. However, Regional Tiered Cache is not beneficial for customers with many upper tiers in many regions like Generic Global Tiered Cache.\n\n#### Traffic flow: Tiered Cache, Smart Tiered Cache with Regional Tiered Cache\n\nIn Figure 5, Tiered Caching is enabled with Smart Tiered Cache Topology. The diagram depicts the topology of Smart Tiered Cache with Regional Tiered Cache enabled. Lower tier caches, when they experience a cache `MISS` will first send those requests to a more local, regional hub data center to see if the cache can handle the request. If not, the request will continue on to the upper tier and then origin server, if necessary.\n\n![Figure 5: Diagram illustrating requests between an end user and origin server with lower, regional and upper tiered caching enabled.](https://developers.cloudflare.com/_astro/ref-arch-cdn-figure5.B3Tq_F2z_Z1zLO2B.svg)\n\n### Argo Smart Routing\n\nArgo Smart Routing is a service that finds optimized routes across the Cloudflare network to deliver responses to users more quickly. As discussed earlier, Cloudflare CDN leverages Argo Smart Routing to determine the best upper tier data centers for Tiered Cache.\n\nIn addition, Argo Smart Routing can be enabled to ensure the fastest paths over the Cloudflare network are taken between upper tier data centers and origin servers at all times. Without Argo Smart Routing, communication between upper tier data centers to origin servers are still intelligently routed around problems on the Internet to ensure origin reachability.\n\nArgo Smart Routing accelerates traffic by taking into account real-time data and network intelligence from routing nearly 50 million HTTP requests per second; it ensures the fastest and most reliable network paths are traversed over the Cloudflare network to the origin server. On average, Argo Smart Routing accounts for 30% faster performance on web assets.\n\n#### Traffic Flow: Tiered Cache, Smart Tiered Cache Topology with Argo Smart Routing\n\nFigure 6 details the traffic flow when Tiered Cache and Argo Smart Routing are not enabled. The request comes into the closest data center, and, because content is not locally cached and Tiered Cache is not enabled, the request is sent directly to the origin server for the content. Also, since Argo Smart Routing is not enabled, a reliable, but perhaps not the fastest, path is taken when communicating with the origin server.\n\n![Figure 6: Diagram with bidirectional arrows indicating a request between an end user and origin server without Argo Smart Routing enabled.](https://developers.cloudflare.com/_astro/ref-arch-cdn-figure6.CUGfxAW8_Z1zLO2B.svg)\n\nFigure 7 articulates the traffic flow with both Tiered Cache and Argo Smart Routing enabled. When a request is received by Data Center 1 and there is a cache miss, the cache of the upper tier data center, Data Center 6, is checked. If the cached content is not found at the upper tier data center, with Argo Smart Routing enabled, the request is sent on the fastest path from the upper tier data center to the origin.\n\nThe fastest path is determined by the Argo network intelligence capabilities, which take into account real-time network data such as congestion, latency, and RTT.\n\n**With the Cloudflare CDN, Argo Smart Routing is used when:**\n\n1. There is a cache miss and the request needs to be sent to the origin server to retrieve the content.\n2. There is a request for non-cacheable content, such as dynamic content (ex: APIs), and the request must go to the origin server.\n\n![Figure 7: Diagram with bidirectional arrows indicating a request between an end user and origin server, with Argo Smart Routing enabled to improve speed.](https://developers.cloudflare.com/_astro/ref-arch-cdn-figure7.Cxfbf7KH_ZL1y5X.svg)\n\nExpanding on the idea of Tiered Cache, Cache Reserve further utilizes the scale and speed of the Cloudflare network while additionally leveraging R2, Cloudflareâ€™s persistent object storage, to cache content even longer. Cache Reserve helps customers reduce bills by eliminating egress fees from origins while also providing multiple layers of resiliency and protection to make sure that content is reliably available which improves website performance by having content load faster. Basically, Cache Reserve is an additional higher tier of cache with longer retention duration.\n\nWhile Cache Reserve can function without Tiered Cache enabled, it is recommended that Tiered Cache be enabled with Cache Reserve. Tiered Cache will funnel, and potentially eliminate, requests to Cache Reserve which eliminates redundant read operations and redundant storage of cached content reducing egress and storage fees. Enabling Cache Reserve via the Cloudflare dashboard will check and provide a warning if you try to use Cache Reserve without Tiered Cache enabled.\n\nCache Reserve has a retention period of 30 days which means it will hold cached content for 30 days regardless of cached headers or TTL policy. The TTL policy still affects the contentâ€™s freshness which means when content cache TTL expires inside of Cache Reserve, the content will need to be revalidated by checking the origin for any updates. The TTL policy can be set by any number of methods, such as Cache-Control, CDN-Cache-Control response headers, Edge Cache TTL, cache TTL by status code, or Cache Rules. Every time cache is read from Cache Reserve, the retention timer is reset to 30 days. After 30 days, if the cached content has not been read from Cache Reserve, the cache will be deleted.\n\nThere are three main criteria to match for content to be considered cacheable via Cache Reserve:\n\n1. The content must be cacheable. See the [Cache documentation](https://developers.cloudflare.com/cache/) for more details on cacheable content.\n2. TTL is set to at least 10 hours. This can be set by any method from the previous paragraph.\n3. The Content-Length header must be used in the response header. Please note, this means that the \\[Transfer-Method â€œchunkedâ€ will prevent Cache Reserve from being populated.\n\nWhen combined with Tiered Caching and Argo Smart Routing, Cache Reserve can be a powerful tool for increasing cache hits and in turn reducing load on origin servers while also improving performance by bringing the content closer to the end user.\n\nUsing [Image Resizing](https://developers.cloudflare.com/images/transform-images/) with Cache Reserve will not result in resized images being stored in Cache Reserve since Image Resizing takes place after reading from Cache Reserve. Resized images will be cached in other available tiers when they are served after resizing.\n\n### Traffic flow: Cache Reserve topology\n\nFigure 8 illustrates how Cache Reserve can help reduce load on an origin server while also helping repopulate cache stores in both upper and lower tier data centers.\n\n![Figure 8: Traffic between end users and an origin server showing Cache Reserve as the final step in the architecture of the Cloudflare CDN solution.](https://developers.cloudflare.com/_astro/ref-arch-cdn-figure8.B8u-UV7X_Z1zLO2B.svg)\n\n### China Network & Global Acceleration for clients in China\n\nLatency depends not just on how far the client is from the origin or cache, but can also be significantly affected by the geographic region of the traffic â€” like China. To address these latency challenges, Cloudflare provides two key solutions:\n\n1. [China Network](https://developers.cloudflare.com/china-network/) provides in-China caching for end users located in China, regardless of the origin location. This solution is provided by collaborating with JD Cloud and uses their data centers to ensure the fastest and most reliable cache performance for Chinese users compared to data centers outside of China.\n2. [Global Acceleration](https://developers.cloudflare.com/china-network/concepts/global-acceleration/) offers reliable and secure connectivity to streamline content from origins to JD Cloud data centers in China. This is particularly beneficial for dynamic content like web applications and API calls.\n\nTo summarize, the Cloudflare CDN is SaaS that helps address the challenges customers face around latency, performance, availability, redundancy, security, and costs. The Cloudflare CDN leverages Cloudflareâ€™s global anycast network and Tiered Cache to deliver optimized results while saving costs for customers. Customers can also (enable Argo Smart)\\[argo-smart-routing/get-started/] Routing to ensure the fastest network path is used to route requests to the origin server and also choose to enable Cache Reserve to increase cache hits to further save costs and increase performance of their website or application.\n\n<page>\n---\ntitle: Reference Architecture using Cloudflare SASE with Microsoft Â· Cloudflare\n  Reference Architecture docs\ndescription: This reference architecture explains how Microsoft and Cloudflare\n  can be integrated together. By leveraging Cloudflare's secure network access,\n  risky user isolation, and application and data visibility, organizations can\n  consolidate management.\nlastUpdated: 2025-10-27T15:00:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/reference-architecture/architectures/cloudflare-sase-with-microsoft/\n  md: https://developers.cloudflare.com/reference-architecture/architectures/cloudflare-sase-with-microsoft/index.md\n---\n\nIn today's rapidly evolving digital landscape, organizations are increasingly embracing cloud migration to modernize their environments and enhance productivity. Microsoft has emerged as a leading provider of cloud applications and services, offering a comprehensive suite of solutions to support hybrid work. However, this shift to the cloud also presents new challenges and risks that must be addressed to ensure the security and integrity of an organization's resources.\n\nAs organizations migrate to hybrid and multi-cloud environments, they often face the complexity of managing a combination of Software as a Service (SaaS), self-hosted, and non-web applications. This heterogeneous ecosystem can complicate the process of securing and controlling access to these resources. Additionally relying on legacy, often on-premises, Virtual Private Network (VPN) solutions to securely connect users to applications can introduce security gaps and hinder employee productivity. To overcome these challenges and achieve greater security outcomes, organizations can benefit from partnering with Cloudflare, a leading provider of cloud security and performance solutions. Cloudflare offers seamless integration with Microsoft's cloud ecosystem, enabling customers to eliminate security gaps, enhance performance, and ensure reliability across their hybrid work environments.\n\nIn this reference architecture diagram, we will explore how the combination of Cloudflare's Secure Access Service Edge (SASE) platform and Microsoft's cloud applications and services can help you attain a Zero Trust security posture and accelerate cloud modernization and productivity while providing comprehensive security for hybrid work. By leveraging Cloudflare's secure network access, risky user isolation, and application and data visibility, organizations can consolidate management through a unified interface and enable secure access to any resource, regardless of location.\n\n### Who is this document for and what will you learn?\n\nThis reference architecture is designed for IT or security professionals with some responsibility over or familiarity with their organization's Microsoft deployments. It is designed to help you understand the different ways in which Microsoft and Cloudflare can be integrated together in terms of your Zero Trust and SASE programs.\n\nTo build a stronger baseline understanding of Cloudflare, we recommend the following resources:\n\n* What is Cloudflare? | [Website](https://www.cloudflare.com/what-is-cloudflare/) (5 minute read) or [video](https://youtu.be/XHvmX3FhTwU?feature=shared) (2 minutes)\n\n- Solution Brief: [Cloudflare One](https://cfl.re/SASE-SSE-platform-brief) (3 minute read)\n- Whitepaper: [Reference Architecture for Internet-Native Transformation](https://cfl.re/internet-native-transformation-wp) (10 minute read)\n- Blog: [Zero Trust, SASE, and SSE: foundational concepts for your next-generation network](https://blog.cloudflare.com/zero-trust-sase-and-sse-foundational-concepts-for-your-next-generation-network/) (14 minute read)\n\nThose who read this reference architecture will learn:\n\n* How Cloudflare and Microsoft can be integrated together to protect users, devices, applications and networks from a Zero Trust perspective\n\nThis document is also accompanied by a reference architecture with a more indepth look at [Cloudflare and SASE](https://developers.cloudflare.com/reference-architecture/architectures/sase/).\n\nWhile this document examines Cloudflare at a technical level, it does not offer fine detail about every product in the platform. Visit the [developer documentation](https://developers.cloudflare.com/) for further information specific to a product area or use case.\n\n## Integration of Cloudflare with Microsoft\n\nCloudflare's [Zero Trust Network Access](https://www.cloudflare.com/zero-trust/products/access/) (ZTNA) provides a faster and safer alternative to traditional VPNs. It replaces on-premises VPN infrastructure and protects any application, regardless of whether it is hosted in an on-premises network, public cloud, or as Software as a Service (SaaS). By integrating with Microsoft Intune and Microsoft Entra ID (formerly Azure Active Directory), Cloudflare's ZTNA service enables organizations to enforce default-deny, Zero Trust rules and provide conditional access to internal resources based on user identity and device posture.\n\nMicrosoft and Cloudflare can be integrated in the following ways.\n\n* Using Microsoft [Entra ID](https://learn.microsoft.com/en-us/entra/fundamentals/whatis) for authentication to all Cloudflare protected resources\n* Leveraging Microsoft [Intune](https://learn.microsoft.com/en-us/mem/intune/fundamentals/what-is-intune) device posture in Cloudflare policies to ensure only managed, trusted devices have access to protected resources\n* Using Cloudflare [CASB](https://developers.cloudflare.com/cloudflare-one/integrations/cloud-and-saas/) to inspect your [Microsoft 365](https://www.microsoft.com/en-us/microsoft-365/what-is-microsoft-365) tenants and alert on security findings for incorrectly configured accounts and shared files containing sensitive data\n* Using Cloudflare's [Secure Web Gateway](https://developers.cloudflare.com/cloudflare-one/traffic-policies/) to control access to Microsoft SaaS applications such as Outlook, OneDrive and Teams\n* Using Cloudflare's [Email security](https://developers.cloudflare.com/email-security/) service to increase protection of email from phishing attacks and business email compromise.\n\n### Microsoft Entra ID with Cloudflare\n\nCloudflare's integration with Entra ID allows you to leverage your identities in Entra for authentication to any Cloudflare protected application. Groups can also be imported via SCIM to be used in access policies, simplifying management and abstracting access control by managing group membership in Entra ID.\n\n* Entra ID enables administrators to create and enforce policies on both applications and users using Conditional Access policies.\n* It offers a wide range of parameters to control user access to applications, such as user risk level, sign-in risk level, device platform, location, client apps, and more.\n* Security teams can define their security controls in Entra ID and enforce them at the network layer, for every request, with Cloudflare's ZTNA service.\n\n![Figure 1: Microsoft Entra ID integrates with Cloudflare for ZTNA access to SaaS and self hosted applications.](https://developers.cloudflare.com/_astro/cloudflare-sase-with-microsoft-fig1.DLUixQrQ_RtHfR.svg)\n\n### Microsoft Intune with Cloudflare\n\nCloudflare is able to enforce access policies that include information about device posture. Intune can be integrated into Cloudflare so that information about Intune managed and protected devices can be used to enforce access control to Cloudflare protected resources.\n\n* With a device connected using our [agent](https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/warp/), Cloudflare's ZTNA service can leverage the enhanced telemetry and context provided by Intune regarding a user's device posture and compliance state.\n* Intune provides detailed information about the security status and configuration of user devices, enabling more informed access control decisions.\n* This integration allows administrators to ensure that only compliant and secure devices are granted access to critical networks and applications.\n\n![Figure 2: Figure 2: Using Intune and Cloudflare device posture data for secure application access.](https://developers.cloudflare.com/_astro/cloudflare-sase-with-microsoft-fig2.B-u59e7U_Z13eFbO.svg)\n\n### Cloudflare CASB for Microsoft 365\n\nAs companies adopt numerous SaaS applications, maintaining consistent security, visibility, and performance becomes increasingly difficult. With each application having unique configurations and security requirements, IT teams face challenges in staying compliant and protecting sensitive data across the diverse landscape.\n\nCloudflare CASB (Cloud Access Security Broker) addresses these challenges by providing extensive visibility across Microsoft 365 and other popular SaaS applications. This visibility enables organizations to quickly identify misconfigurations, exposed files, user access, and third-party access, ensuring a secure and compliant SaaS environment.\n\nLearn more about how our CASB solution can [protect data at rest here](https://developers.cloudflare.com/reference-architecture/diagrams/security/securing-data-at-rest/).\n\n### Cloudflare's Secure Web Gateway for improved security to Microsoft SaaS applications\n\nCloudflare's Secure Web Gateway (SWG) can help organizations achieve safe and secure access to Microsoft 365 in the following ways:\n\n1. Traffic inspection and filtering: Cloudflare's SWG inspects all user and device traffic destined for the Internet, including traffic to Microsoft 365. This allows organizations to apply security policies, content filtering, and threat prevention measures to ensure that only legitimate and authorized traffic reaches Microsoft 365 services. As seen above, policies can be designed so that only managed, secure devices can access any part of the Microsoft 365 and Azure platform.\n2. Data protection with DLP profiles: Traffic is not only inspected based on device posture and identity information, but our DLP engine can also examine the content of the request and allow/block downloads/uploads of confidential information to and from Microsoft 365 and Azure.\n3. Enforce Cloudflare gateway: Microsoft 365 can be configured to accept user traffic only from a specific range of IP addresses. Cloudflare makes it possible to define and associate IP addresses attached to all traffic leaving the SWG. This means that organizations can configure Microsoft 365 to only accept traffic coming from the IP address range designated by Cloudflare SWG, ensuring that all traffic has been inspected and approved by Cloudflare's security policies before reaching Microsoft 365.\n\nBy leveraging Cloudflare SWG as a secure gateway for Microsoft 365 access, organizations can benefit from advanced threat protection, granular access controls, traffic inspection, and centralized visibility, ensuring a safe and secure experience for their users while mitigating risks and maintaining compliance.\n\n### Cloudflare's Email security for improved email protection\n\nPhishing is the root cause of upwards of 90% of breaches that lead to financial loss and brand damage. Cloudflare's email security solution sits in front of all email going to your Microsoft 365 tenant, filtering out spam, bulk, malicious and spoof content. The solution can leverage Microsoft [rules for quarantine actions](https://developers.cloudflare.com/email-security/deployment/inline/setup/office-365-area1-mx/use-cases/four-user-quarantine-admin-quarantine/), allowing you to fine tune how different email detections are handled.\n\n![Figure 3: Cloud email security protects all Microsoft 365 inboxes.](https://developers.cloudflare.com/_astro/cloudflare-sase-with-microsoft-fig3.B5Jderoc_Z2650Bq.svg)\n\nIt is also possible to configure cloud email security to scan [Microsoft 365 inboxes via API](https://developers.cloudflare.com/email-security/deployment/api/), avoiding the need to make changes to existing DNS records.\n\nBy leveraging Cloudflare and its integrations with Microsoft, organizations can establish a Zero Trust security posture that goes beyond the limitations of traditional network security models. With Cloudflare's Zero Trust Network Access (ZTNA), organizations can replace self hosted VPNs and enforce conditional access based on user identity and device posture. The integration with Microsoft Entra ID allows for authentication and access control, while Microsoft Intune provides device posture information. Additionally, Cloudflare's CASB offers visibility into the security of Microsoft 365 configuration, the Secure Web Gateway inspects and filters traffic to Microsoft 365, and Email security protects against phishing attacks, ensuring a secure and compliant environment. This approach enables faster and more secure access to applications, while providing granular control over user access based on identity and device posture.\n\n![Figure 4: A summary of Cloudflare SASE and Microsoft integrations.](https://developers.cloudflare.com/_astro/cloudflare-sase-with-microsoft-fig4.DEjQxEbH_Z13JrsG.svg)\n\n* [Overview of Microsoft and Cloudflare partnership](https://www.cloudflare.com/partners/technology-partners/microsoft/)\n* [Set up Microsoft Entra ID (formerly Azure Active Directory) as an identity provider](https://developers.cloudflare.com/cloudflare-one/integrations/identity-providers/entra-id/#set-up-entra-id-as-an-identity-provider)\n\n<page>\n---\ntitle: Enhancing security posture with SentinelOne and Cloudflare One Â·\n  Cloudflare Reference Architecture docs\ndescription: The integration between Cloudflare One and SentinelOne provides\n  organizations with a comprehensive security solution. The integration works\n  through a service-to-service posture check that identifies devices based on\n  their serial numbers.\nlastUpdated: 2025-10-23T02:03:04.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/reference-architecture/architectures/cloudflare-sase-with-sentinelone/\n  md: https://developers.cloudflare.com/reference-architecture/architectures/cloudflare-sase-with-sentinelone/index.md\n---\n\nThe integration between Cloudflare One and SentinelOne provides organizations with a comprehensive security solution that combines endpoint protection with [Zero Trust Network Access](https://www.cloudflare.com/learning/security/glossary/what-is-zero-trust/). This integration enables organizations to make access decisions based on device security posture, ensuring that only healthy and compliant devices can access protected resources. This reference architecture describes how organizations can implement and leverage this integration to enhance their security posture. The integration can assist in advancing an organization's or agency's Zero Trust Architecture Maturity Model, with the goal of one's organization eventually achieving Advanced or Optimal across all [CISA's 5 Pillars of Zero Trust.](https://www.cisa.gov/sites/default/files/2023-04/CISA_Zero_Trust_Maturity_Model_Version_2_508c.pdf)\n\n## Who is this document for and what will you learn?\n\nThis reference architecture is designed for IT and security professionals who are implementing or planning to implement a Zero Trust security model using Cloudflare and SentinelOne. It provides detailed guidance on integration setup, configuration options, and common deployment scenarios. To build a stronger baseline understanding of these technologies, we recommend reviewing both platforms' core documentation.\n\nRecommended resources for a stronger understanding of Cloudflare's SentinelOne integration:\n\n* [SentinelOne device posture integration](https://developers.cloudflare.com/cloudflare-one/integrations/service-providers/sentinelone/)\n\n## Integration overview\n\nCloudflare One can integrate with SentinelOne to enforce device-based access policies for applications and resources. The integration works through a service-to-service posture check that identifies devices based on their serial numbers. This allows organizations to ensure that only managed and secure devices can access sensitive resources.\n\n## Technical components\n\n### SentinelOne components\n\nThe SentinelOne platform provides critical endpoint security capabilities:\n\nThe SentinelOne agent must be deployed on all managed devices and provides real-time security monitoring and threat detection. Key posture data points include:\n\n* Infection status of the device\n* Number of active threats detected\n* Agent activity status\n* Network connectivity status\n* Operational state of the agent\n\nThe SentinelOne Management Console provides centralized control and visibility, including the APIs necessary for integration with Cloudflare.\n\n### Cloudflare components\n\nCloudflare's Zero Trust infrastructure provides the policy enforcement layer:\n\nThe WARP client must be deployed alongside the SentinelOne agent on managed devices. This client creates the secure connection to Cloudflare's network and enables device posture checking.\n\nThe Cloudflare dashboard provides the configuration interface for:\n\n* Service provider integration settings\n* Device posture policies\n* Access policies that incorporate device posture checks\n\n## Implementation architecture\n\n### Authentication and authorization flow\n\n![Figure 1: SentinelOne is used in Cloudflare policies as part of authorization flow.](https://developers.cloudflare.com/_astro/figure1.DqycNoJs_ixsmT.svg)\n\nWhen a user attempts to access a protected resource, the following sequence occurs:\n\n1. The user's device connects to Cloudflare's network through the WARP client.\n2. Cloudflare queries the SentinelOne API to check the device's security posture.\n3. The SentinelOne platform returns current device status including infection state, threats, and agent health.\n4. Cloudflare evaluates this information against configured policies.\n5. Access is granted or denied based on policy evaluation.\n\n### Integration setup\n\nThe integration requires specific configuration steps:\n\nFirst, a service account must be created in SentinelOne with appropriate permissions. This involves generating an API token and noting the REST API URL for your instance.\n\nNext, SentinelOne must be configured as a service provider in the Cloudflare Zero Trust dashboard. This includes:\n\n* Providing the API token and REST API URL\n* Setting an appropriate polling frequency\n* Testing the connection to ensure proper communication\n\nFinally, device posture checks must be configured to define the security requirements for access. For detailed setup instructions, refer to [SentinelOne device posture integration](https://developers.cloudflare.com/cloudflare-one/integrations/service-providers/sentinelone/).\n\n## Security capabilities\n\n### Device posture verification\n\nThe integration enables robust device security verification through multiple attributes:\n\nInfection Status monitoring ensures that compromised devices cannot access sensitive resources. Active Threat Detection prevents devices with ongoing security incidents from maintaining access. Agent Health Monitoring confirms that the security stack remains functional and properly configured.\n\n### User risk detection\n\nSentinelOne provides [endpoint detection and response (EDR)](https://www.sentinelone.com/cybersecurity-101/endpoint-security/what-is-endpoint-detection-and-response-edr/) signals that help determine user risk scores. This allows organizations to identify and manage users who may present security risks, enabling proactive security measures before incidents occur.\n\n![Figure 2: SentinelOne and Cloudflare Zero Trust technical architecture.](https://developers.cloudflare.com/_astro/figure2.BaY3MgFK_Z2qcC2g.svg)\n\nThe integration architecture begins at the managed endpoint device level, where two critical components coexist. The SentinelOne agent serves as the primary security enforcer, continuously monitoring the device for threats, assessing device health, and providing real-time security status updates. Alongside it, the Cloudflare WARP client establishes secure connectivity and manages the device's interaction with Cloudflare's Zero Trust infrastructure. These components work in tandem to ensure both endpoint security and secure network access.\n\nWhen a user attempts to access protected resources, the architecture initiates a sophisticated verification process. The WARP client first establishes a secure tunnel to Cloudflare's global network, creating an encrypted channel for all communications. This connection ensures that all traffic between the device and protected resources remains secure and can be properly evaluated against security policies.\n\n### Cloudflare Zero Trust platform operations\n\nAt the heart of the architecture lies the Cloudflare Zero Trust platform, which consists of three main engines working in concert. The **Device Posture Engine** serves as the first line of defense, actively querying the SentinelOne platform to verify the device's security status. It checks multiple attributes including infection status, active threats, agent health, and network connectivity state. This information forms the foundation for access decisions.\n\nThe **Access Policy Engine** then takes this device posture information and combines it with other contextual factors to make access decisions. It evaluates predefined policies that can include criteria such as device security status, user identity, location, and other risk factors. This engine ensures that only devices meeting all security requirements can access protected resources.\n\nThe **Secure Web Gateway** adds another layer of protection by filtering all traffic, preventing access to malicious sites, and enforcing data loss prevention policies. This component ensures that even after access is granted, all traffic is continuously monitored and protected.\n\n### SentinelOne platform integration\n\nThe SentinelOne platform plays a crucial role in this architecture through three main components. The **Management Console** provides centralized control over all endpoints, allowing security teams to configure policies, monitor device status, and respond to security events. The **API Services** component facilitates real-time communication with Cloudflare, providing critical security information about managed devices.\n\nThe **Security Analytics** component continuously processes security telemetry from all endpoints, identifying threats, assessing risks, and providing detailed security insights. This information flows to Cloudflare through **API Services**, enabling dynamic access decisions based on the latest security intelligence.\n\n### Authentication and access flow\n\nWhen a user requires access to protected resources, the architecture follows a specific flow:\n\nFirst, the device's security status is evaluated through the **SentinelOne agent**, which reports detailed health and security information to the SentinelOne platform. Simultaneously, the **Cloudflare WARP client** initiates the access request to Cloudflare's Zero Trust platform.\n\nNext, Cloudflare's **Device Posture Engine** queries the SentinelOne platform through its **API Services** to verify the device's security status. This check includes all current security metrics, threat status, and compliance information. The **Access Policy Engine** then evaluates this information against defined security policies.\n\nIf all security requirements are met, access is granted through the secure tunnel established by the WARP client. Throughout the session, continuous monitoring ensures that any change in device security status can trigger immediate reevaluation of access permissions.\n\n### Security and monitoring capabilities\n\nThe architecture provides comprehensive security through multiple mechanisms. At the endpoint level, the SentinelOne agent provides advanced threat detection and response capabilities. The **Security Analytics** component processes this security telemetry in real-time, enabling quick identification of threats and security issues.\n\nCloudflare's **Secure Web Gateway** provides network-level protection, filtering traffic and preventing access to malicious resources. This component works in conjunction with the **Access Policy Engine** to ensure that all traffic, both to internal and external resources, meets security requirements.\n\n## Operational benefits\n\nThis integrated architecture delivers several key operational benefits. It enables organizations to implement true Zero Trust access control, where every access request is verified based on current security status. The integration between SentinelOne and Cloudflare provides seamless security enforcement, combining endpoint protection with network-level access control.\n\nThe architecture also supports dynamic policy enforcement, where changes in device security status can automatically trigger access restrictions. This ensures that compromised or non-compliant devices can be quickly isolated from sensitive resources, maintaining organizational security.\n\n## Deployment considerations\n\n### Network architecture\n\nOrganizations should consider their network architecture when implementing this integration. Key factors include:\n\n* Distribution of endpoints across different networks\n* Bandwidth and latency requirements for posture checks\n* Integration with existing security tools and workflows\n\nThe integration between Cloudflare One and SentinelOne requires thoughtful planning to ensure successful implementation. At its foundation, organizations need to prepare their environment by having the SentinelOne agent and Cloudflare WARP client deployed on all devices that will be subject to posture checks. This foundational step ensures that both security monitoring and secure network connectivity are in place before building additional security controls.\n\nWhen implementing the integration, organizations should approach it as a service provider relationship where SentinelOne acts as a trusted source of device security information. This relationship is established through secure API communications, with careful attention paid to proper credential management and regular verification of the connection between the platforms. The integration relies on SentinelOne's ability to provide real-time device security status, which Cloudflare then uses to make access decisions.\n\nEffective policy design is crucial for security and usability. Consider implementing policies that:\n\n* Start with basic hygiene requirements and gradually increase security requirements\n* Account for different user roles and access needs\n* Include fallback options for exceptional circumstances\n\nPolicy configuration represents another crucial aspect of the deployment. Organizations can leverage SentinelOne's detailed device posture information to create nuanced access policies. These policies can take into account multiple factors such as device infection status, active threats, and agent health. By monitoring these various attributes, organizations can ensure that only devices meeting their security requirements can access protected resources.\n\nRegular testing and monitoring play vital roles in maintaining the effectiveness of the integration. Through Cloudflare's logging and testing capabilities, organizations can verify that posture checks are functioning as intended and that policies are being enforced correctly. This ongoing verification helps ensure that the security benefits of the integration are consistently realized.\n\nThe integration between Cloudflare One and SentinelOne provides organizations with a powerful tool for implementing Zero Trust security principles. By combining endpoint protection with access control, organizations can ensure that only secure and compliant devices can access sensitive resources. This approach significantly reduces the risk of compromised devices accessing corporate resources while maintaining user productivity through seamless authentication and authorization processes.\n\n* [Overview of SentinelOne and Cloudflare partnership](https://www.cloudflare.com/partners/technology-partners/sentinelone/)\n\n<page>\n---\ntitle: Understanding Email Security Deployments Â· Cloudflare Reference\n  Architecture docs\ndescription: This reference architecture describes the key architecture of\n  Cloudflare Email security.\nlastUpdated: 2025-12-02T17:23:00.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/reference-architecture/architectures/email-security-deployments/\n  md: https://developers.cloudflare.com/reference-architecture/architectures/email-security-deployments/index.md\n---\n\nEmail continues to be a mission critical method for communication between people and organizations. This also makes email an ideal channel for attackers to exploit in their attempts to take over accounts, steal data, and gain access to internal systems. Being able to reduce spam, defeat phishing, and malware attacks is critical for the security of your organization. Over 90% of cybersecurity incidents begin with an email attack.\n\nCloudflare Email security service is a market leading solution that can be deployed in a variety of ways to support different needs for each organization. This document outlines the different methods to deploy Email security and why you would choose any specific model.\n\n## Strengthen your email infrastructure with Cloudflare Email security\n\nEmail remains a critical communication channel for businesses of all sizes. However, email also serves as a prime target for cyber attacks, including phishing, spam, and malware. To safeguard your organization sensitive data and reputation, a robust email security solution is essential.\n\nCloudflare Email security offers a comprehensive suite of tools and technologies designed to protect your email infrastructure from a wide range of threats. By implementing Cloudflare Email security, you can significantly enhance your organization security posture and mitigate the risks associated with email-borne attacks.\n\nThis reference architecture provides a detailed overview of how to deploy and configure Cloudflare Email security to optimize your email security posture. This reference architecture will delve into key components and best practices to ensure the seamless integration of this solution into your existing IT infrastructure.\n\n### Who is this reference architecture for and what will you learn?\n\nThis reference architecture is designed for IT or security professionals who are looking at using Cloudflare to secure aspects of their business. This reference architecture is designed for a broad audience, including:\n\n* **IT security professionals**: Security engineers, architects, and administrators responsible for designing, implementing, and managing Email security solutions.\n* **Network engineers**: Network engineers who manage network infrastructure and email gateways.\n* **Cloud architects**: Cloud architects who design and implement cloud-based Email security solutions.\n* **Security and IT decision-makers**: Managers and executives who need to understand the technical aspects of Email security and make informed decisions.\n\nWhether you are a seasoned security expert or a newcomer to Email security, this document will provide you with the necessary information to effectively deploy and manage Cloudflare Email security.\n\nTo build a stronger understanding of Cloudflare, we recommend the following resources:\n\n* What is Cloudflare? | [Website](https://www.cloudflare.com/what-is-cloudflare/) (five-minute read) or [Video](https://www.cloudflare.com/what-is-cloudflare/video) (two minutes)\n* [Cloudflare Blog](https://blog.cloudflare.com/tag/cloud-email-security/) | [Email security](https://blog.cloudflare.com/tag/cloud-email-security/) and [Phishing](https://blog.cloudflare.com/tag/phishing/)\n* CISA | [Phishing Guidance: Stopping the Attack Cycle at Phase One](https://www.cisa.gov/publications/phishing-guidance-stopping-attack-cycle-phase-one)\n\nBy the end of this reference architecture, you will have learned how Cloudflare protects your email and what considerations should be made for choosing how to deploy. You will learn about the specific components, technologies, and configurations involved in the Cloudflare Email security solution. This includes how it integrates with existing email infrastructure and leverages cloud-based services.\n\n## Email security deployment options\n\nCloudflare Email security is a modern approach to solving phishing attacks. Cloudflare solution is built upon AI and Machine Learning utilizing elastics services in addition to benefiting from Cloudflare expansive threat intelligence network. Cloudflare Email security was designed as the only true Cloud Elastic Service with shared intelligence and [Supervised ML](https://www.ibm.com/think/topics/supervised-learning) capable of any deployment method available for email. However, choosing the right deployment model is crucial for maximizing the benefits of Email security.\n\nThis document will discuss the following methods to deploy and where you would use them:\n\n* [Inline or MX](https://developers.cloudflare.com/cloudflare-one/email-security/setup/pre-delivery-deployment/mx-inline-deployment/)\n* [Microsoft 365 API integration](https://developers.cloudflare.com/cloudflare-one/email-security/setup/post-delivery-deployment/api/m365-api/)\n* [Journaling](https://developers.cloudflare.com/cloudflare-one/email-security/setup/post-delivery-deployment/bcc-journaling/journaling-setup/m365-journaling/) or [BCC](https://developers.cloudflare.com/cloudflare-one/email-security/setup/post-delivery-deployment/bcc-journaling/bcc-setup/gmail-bcc-setup/enable-gmail-integration/) with auto-move\n* Hybrid deployment\n\n## Choose a deployment model\n\nBefore you choose a deployment option, it is important to consider your needs and desired experience. Our best practice is typically to go with an MX deployment when we are the primary phishing protection in place. The key reasons for this are as follows:\n\n* [Pre-delivery](https://developers.cloudflare.com/cloudflare-one/email-security/setup/pre-delivery-deployment/mx-inline-deployment/) remediation allows us to tune how messages are delivered by appending to the subject/body, applying URL Rewriting to Cloudflare [Remote Browser Isolation](https://developers.cloudflare.com/cloudflare-one/remote-browser-isolation/), and delivering messages into the junk folder or downstream email quarantine. This enables you to design with a specific user experience in mind.\n* We can remove messages before they are consumed by systems that ingest emails such as a ServiceNow or an Archiving Solution.\n* We remove the risk of dwell time issues where there is a time difference between delivery to the inbox and when the message is moved from the inbox.\n* We can support hybrid deployments such as a mix of Microsoft 365 and Microsoft Exchange or Microsoft 365 and Google Workspace.\n\nIf those needs are not important or you are using layered security that does not include another API-based solution, then our API method is quick and efficient to deploy with no changes to your mail flow. If you want the benefits of API without the risk of API Throttling, then Journal/BCC is the best choice as the ingestion method does not use API calls. However, if you want the protection of an MX deployment along with the benefits of API for internal messaging, then our hybrid deployment is ideal.\n\nShould your needs change, know that you have the flexibility to change deployment methods as you see fit without having to repurchase our solution. The only caveat is that Advantage and CyberSafe customers are limited to Inline deployments while Enterprise licensing benefits from all capabilities.\n\nBefore you commit to a specific deployment, Cloudflare suggests you review all of the options, weigh your needs, and consult with your account team as needed.\n\n## Deployment options\n\nWith an Inline deployment, all emails destined for one or more domains are filtered through Cloudflare before they are delivered to the user's inbox. Cloudflare can be deployed anywhere in your email processing chain. When deployed as the first hop, you will need to update the domain's DNS MX records to point to Cloudflare. If you prefer Cloudflare to inspect messages after your existing SEG (Secure Email Gateway), Cloudflare can be inserted as a hop in the processing chain, and will then forward processed messages downstream to the next hop. Based on policies, messages are blocked and/or quarantined if they are marked as Spam, Malicious, Bulk, and more.\n\n![Inline deployment](https://developers.cloudflare.com/_astro/Inline_MX.CF8OdSfC_1YRlXt.svg)\n\nThe diagram above describes the following:\n\n1. Email arrives at Cloudflare based on [MX records](https://www.cloudflare.com/en-gb/learning/dns/dns-records/dns-mx-record/).\n\n2. Cloudflare inspects email body, header, and attachments and assigns the appropriate disposition:\n\n* Malicious\n   * Spam\n   * Bulk\n   * Suspicious\n   * Spoof\n   * Clean\n\n3. Apply any policy, such as allow or block certain domains.\n\n4. Quarantine high risk emails\n\n5. All messages that received a [disposition](https://developers.cloudflare.com/cloudflare-one/email-security/reference/dispositions-and-attributes/#dispositions) by Cloudflare will have the header `X-CFEmailSecurity-Disposition` added. This header can be used by downstream systems to enact any special handling (rerouting, external quarantining, and more).\n\n6. Forward on all valid email traffic.\n\n7. Subject and/or body modifications can be applied to the messages to add visible information for the end-user about the disposition.\n\nFrom a security perspective, the Inline deployment is the preferred method of deployment, because it scans every email and stops malicious content from reaching the user inbox. This removes all exposure risks to users.\n\n#### Benefits of Inline deployment\n\n* Messages are processed and blocked before delivery to the user mailbox.\n* Inline deployment allows you to modify the message, adding subject or body mark-ups such as appending \\[SPAM] or \\[EXTERNAL SPAM] to the subject.\n* Provides high availability and adaptive message pooling as Cloudflare will continue to accept incoming emails in queue, even when the downstream services are not available. When the downstream services are restored, messages will resume delivery for the queue.\n* Messages with an assigned [disposition](https://developers.cloudflare.com/cloudflare-one/email-security/reference/dispositions-and-attributes/#dispositions) that are not quarantined receive an `X-header` that may be used for advanced handling downstream.\n* Compatible with all mail systems including Microsoft Exchange On-Prem, Postfix, Lotus Notes, Google Workspace, Microsoft 365, and more.\n\nBefore deploying Email security via Inline deployment, you will need to consider the following:\n\n1. Redirecting deployments where mail flows into Microsoft Exchange or Microsoft 365 first, then to an Email security solution by way of mail flow rules for scanning/remediation, and then back into Microsoft 365 is not supported by Microsoft. While Cloudflare is technically capable of this deployment, it creates attribution (recognizing the original sender) and delivery issues.\n2. If Cloudflare is going to be the MX, this will require DNS changes. If there are many domains, each DNS zone needs to be updated.\n3. Inline deployment can increase complexity in the SMTP architecture if Cloudflare is not deployed as MX such as Inline behind a traditional SEG (Mimecast/ProofPoint).\n4. Inline deployment may require policy duplication on multiple solutions and the MTA. For example, Cloudflare, SEGs, and MTA treat allow policies in significantly different ways and may all need exception handling for the same message.\n5. In a layered deployment, some vendors such as Mimecast and Barracuda can only function as the MX. In this scenario, you would configure Cloudflare Inline behind those vendors.\n6. When using Mimecast, it is recommended to disable URL Rewriting as it makes it impossible for Cloudflare to decode and crawl URLs. If this feature remains enabled, our link following capabilities are limited to domain reputation and age.\n\n#### Inline (Cisco Connector)\n\nCisco offers a unique capability to integrate with Cloudflare using a connector as MX or behind Cloudflare with a supportable Hairpin deployment. This deployment functions the same as Inline in all other considerations. Refer to Cisco as MX Record and Cisco - Email security as MX Record.\n\nAn alternative approach is to integrate via the Graph [API](https://developers.cloudflare.com/cloudflare-one/email-security/setup/post-delivery-deployment/api/m365-api/) in Microsoft 365. In this model, emails are delivered directly to the user inbox, where Cloudflare then receives copies of messages, scans them, and moves them as configured by [disposition](https://developers.cloudflare.com/cloudflare-one/email-security/reference/dispositions-and-attributes/#dispositions).\n\nThis is performed by subscribing to all user mailboxes on the authorized domains. You have the ability to choose if the scope should be restricted to the Inbox only, or All Folders during the authorization process. Upon delivery to the mailbox, the subscription triggers an action within Microsoft 365 that sends Cloudflare a copy of the email to be scanned and assigned a disposition. Once the disposition has been assigned, our solution will look at the [auto-move](https://developers.cloudflare.com/cloudflare-one/email-security/settings/auto-moves/) policy and perform the desired action.\n\n![API deployment](https://developers.cloudflare.com/_astro/API.C1s_LKzB_ZIh0Do.svg)\n\nThe diagram above describes the following:\n\n1. An email is delivered directly to the user inbox via an existing route.\n\n2. Cloudflare retrieves messages for inspection via email vendors API. Cloudflare inspects email body, header, and attachments and assigns the appropriate disposition:\n\n* Malicious\n   * Spam\n   * Bulk\n   * Suspicious\n   * Spoof\n   * Clean\n\n3. Apply any policy, such as allow or block certain domains.\n\n4. Messages are moved per policy in the Cloudflare solution. The following actions are available:\n\n* Inbox\n   * Junk\n   * Trash\n   * Soft Delete (User Recoverable)\n   * Hard Delete (Admin Recoverable)\n\nUnder normal circumstances, this process is typically performed in less than 2-3 seconds from inbox delivery to the move request. There is no SLA from Google or Microsoft 365 on how long they will take to perform the action. If the move action is not successful, our solution will retry numerous times every five minutes.\n\n#### Benefits of API deployment\n\n* Easy way to add protection in complex email architectures with no changes to mail flow operations.\n* Agentless deployment for Microsoft 365.\n* Microsoft 365 Defender/ATP operates on the message first.\n* This method can be used for a Proof of Value to collect and report on emails without requiring changes to mail flow. In this scenario you would leave the remediation policy not configured to prevent actions being taken.\n\nBefore deploying Email security via [API deployment](https://developers.cloudflare.com/cloudflare-one/email-security/setup/post-delivery-deployment/api/m365-api/), you will need to consider the following:\n\n* Depending on the API infrastructure, Microsoft 365 or Google outages and maintenance windows will increase message dwell time in the inbox as emails cannot be scanned or remediated until after delivery to the user. This is a limitation of all API vendors.\n\n* Microsoft 365 may throttle API requests to the Graph API on a Service by Service basis. The Mail API with Graph is within the Outlook Services section. These limits could be abused by a threat actor to functionally disable any API based deployment granting an additional window for attack. The limits are as follows:\n\n* 10,000 API requests in a 10 minute period\n  * Four concurrent requests\n  * 150 megabytes (MB) upload (PATCH, POST, PUT) in a five-minute period\n  * Refer to [Outlook service limits](https://learn.microsoft.com/en-us/graph/throttling-limits#outlook-service-limits)\n\n* The Gmail API is subject to a daily usage limit that applies to all requests made from your application, and per-user rate limits. Each limit is identified in terms of quota units, or an abstract unit of measurement representing Gmail resource usage. The main request limits are described as follows:\n\n* Per user rate limit of 250 quota units per user per second, moving average (allows short bursts).\n  * Per-method Quota Usage is based on the number of quota units consumed by a request depending on the method called.\n  * For example, `messages.get` and `messages.attachments.get` consume five quota units. Refer to [Per-method quota usage](https://developers.google.com/gmail/api/reference/quota#per-method_quota_usage)\n\n* Requires read/write access into mailboxes which some security/email teams may not allow.\n\n* Only Microsoft 365 has true API support. Google allows for API remediation but still requires a Compliance Rule to deliver emails using SMTP for scanning. On-prem Exchange requires PowerShell and does not have APIs for auto-moves.\n\n* Messages cannot be modified after delivery as per Microsoft 365/Google requirements. This means we cannot perform URL Rewriting to Cloudflare [email link isolation](https://developers.cloudflare.com/cloudflare-one/email-security/investigation/search-email/#open-links) or append text to the email subject or body. Those features are only available using an Inline deployment.\n\nBCC/Journaling is very similar to API deployments with the exception of how emails are delivered to Cloudflare. As with API the email is delivered to the mailbox first, but at the same time an account specific email address is added to the email so a copy is transmitted via SMTP to Cloudflare for evaluation.\n\nOnce Cloudflare receives the email, it will scan and determine the [disposition](https://developers.cloudflare.com/cloudflare-one/email-security/reference/dispositions-and-attributes/#dispositions) of the email. Once an email has a disposition our solution will look at the API authorizations and [auto-move](https://developers.cloudflare.com/cloudflare-one/email-security/settings/auto-moves/) policy and perform the desired action. This method is less at risk to API Throttling as the APIs for Microsoft 365 and Google are only used to remediate emails.\n\n![BCC/Journaling deployment](https://developers.cloudflare.com/_astro/Journaling_Diagram.Dn7_4rh7_ZkpAyi.svg)\n\nDuring a proof of value, this deployment can be configured with any Email security solution or mail platform that allows for adding a BCC recipient to gain visibility into what those solutions are missing that Cloudflare would block.\n\n#### Benefits of BCC/Journaling deployment\n\n* Easy way to add protection in complex email architectures with no changes to mail flow operations.\n* Agentless deployment for Microsoft 365. Microsoft 365 would transmit emails after delivery to Cloudflare and the API Authorization can be configured with a Remediation policy to move emails with a disposition out of the inbox.\n* Google makes use of Compliance Rules for BCC which can be combined with an API Authorization to move emails after delivery. This provides for the same outcome as the API deployment detailed above.\n* Microsoft 365 and Google operate on the message first. This provides a more layered approach taking advantage of the security capabilities of Microsoft 365/Google in addition to Cloudflare.\n* You can control the scope of messages inspected (external, internal, or both)\n* This method can be used for a Proof of Value to collect and report on emails without requiring changes to mail flow. This does not require an API Authorization to be in place. If the API is configured for Microsoft 365 or Google, you would leave the Remediation policy not configured to prevent actions being taken.\n\nBefore deploying Email security via BCC/Journaling deployment, you will need to consider the following:\n\n* Same limitations of API.\n* Depends on Google or Microsoft 365 to deliver messages via SMTP.\n* May require a Connector in Microsoft 365 to facilitate direct communication.\n* Messages cannot be modified after delivery as per Microsoft 365/Google requirements. This means we cannot perform URL Rewriting to Cloudflare Email Link Isolation or append text to the email Subject or Body. Those features are only available using an Inline deployment.\n\nHybrid utilizes an Inline deployment for external emails and BCC/Journaling for internal emails. This is facilitated by using both deployment methods but configuring Cloudflare for two hops in BCC/Journal mode. This scenario provides all of the added benefits of an MX delivery for external messages, while also providing remediation of bad emails from internal sources. Here are some scenarios where this is helpful.\n\nIf you have mailboxes where emails are consumed by services such as ticketing systems, CRMs (Customer Relationship Management systems), or Legal Archiving. Each of these integrations run the risk of malicious emails being delivered into those systems where no API-based Email security solution can remediate the problem. The only deployment capable of protecting you would be Inline. If you had additional concerns about malware being spread internally or compromised accounts being used to phish users internally, you would have a gap requiring the purchase of both an Inline solution and an API solution. This would create other problems as you may need to manage policies related to email delivery in three different solutions (MX, API, and Microsoft 365/Google).\n\nCloudflare's hybrid deployment allows us to collapse all of those use cases into a single solution by allowing quarantining of messages at the Cloudflare edge in addition to evaluating internal email and removing them when needed. This improves security while decreasing vendor spend, management overhead, and risk due to the complexity of managing three different policy sets.\n\nHybrid deployment combines the benefits of Inline deployment for external emails and BCC/Journaling for internal emails.\n\nWhen you choose hybrid deployment, you need to consider that:\n\n* Internal email detections are limited due to a lack of information such as Email Authentication, Sending Server, and Delivery Path. Only the content within the body of the email can be analyzed.\n* Internal emails may have higher False Positives when using Protecting Users with impersonation registry.\n\n## Automated Post Delivery\n\nCloudflare offers automated workflows based on continuous analysis and submissions. These features enable Cloudflare to move messages using the API [auto-move](https://developers.cloudflare.com/cloudflare-one/email-security/settings/auto-moves/) policy after delivery. This is best paired with the phish submissions or third-party user submissions.\n\n### Post Delivery Response\n\nCloudflare will continue to re-evaluate emails already delivered to your inbox at a fixed time interval in search for phishing sites or campaigns not previously known to Cloudflare. If any email messages fitting these new criteria are found, Cloudflare retracts them.\n\n### Phish Submission Response\n\nCloudflare will [auto-move](https://developers.cloudflare.com/cloudflare-one/email-security/settings/auto-moves/) emails already delivered that are reported by you as phishing, and are found to be malicious by Cloudflare. Auto-move will occur according to your configuration.\n\n### Submission Handling\n\nCloudflare prioritizes Administrator Submissions for false positives and negatives through the Cloudflare dashboard. This approach enables faster review times and helps Cloudflare proactively identify and correct issues that may affect multiple users improving the overall product experience. It is recommended that administrators review user submissions, identify all related messages, and submit as verified false positive/false negatives via the Cloudflare dashboard. These submissions will be reviewed and used to improve Machine Learning Models, Detections, and Engines in the future.\n\nTo summarize, Email security offers three core deployment models: API, BCC/Journaling, and Inline (or MX). Inline is the preferred deployment model as it filters and remediates malicious messages before they reach the user inbox, thereby removing dwell time risk and allowing for features like URL Rewriting and message modification.\n\nAPI and BCC/Journaling models are post-delivery solutions, integrating directly with platforms like Microsoft 365 or Google Workspace to inspect and [auto-move](https://developers.cloudflare.com/cloudflare-one/email-security/settings/auto-moves/) emails after they have landed in the user mailbox. While these post-delivery methods are easier to deploy and require no mail flow changes, they face limitations such as API throttling risks and the inability to modify message content (like subjects or body text).\n\nFinally, the hybrid deployment combines the benefits of Inline for external email protection (critical for systems like CRM or ticketing that ingest email) with BCC/Journaling for internal email evaluation.\n\n<page>\n---\ntitle: Load Balancing Reference Architecture Â· Cloudflare Reference Architecture docs\ndescription: This reference architecture is for organizations looking to deploy\n  both global and local traffic management load balancing solutions. It is\n  designed for IT, web hosting, and network professionals with some\n  responsibility over or familiarity with their organization's existing\n  infrastructure.\nlastUpdated: 2025-11-19T12:11:06.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/reference-architecture/architectures/load-balancing/\n  md: https://developers.cloudflare.com/reference-architecture/architectures/load-balancing/index.md\n---\n\nCloudflare Load Balancing is a SaaS offering that allows organizations to host applications for a global user base while vastly reducing concerns of maintenance, failover, resiliency, and scalability. Using Cloudflare Load Balancing allows organizations to address the following challenges:\n\n* Efficiently handling large volumes of incoming traffic, especially during unexpected surges or spikes.\n* Ensuring applications and services remain accessible to users.\n* Maintaining quick response times and optimal performance for all users, especially during high traffic periods.\n* Adapting to changing traffic demands and ensuring the infrastructure can accommodate growth.\n* Helping applications and services resist Distributed Denial of Service (DDoS) attacks.\n\nCloudflare Load Balancing is built on Cloudflareâ€™s connectivity cloud, â€‹â€‹a unified, intelligent platform of programmable cloud-native services that enable secure any-to-any connectivity between all networks (enterprise and Internet), cloud environments, applications, and users. It is one of the largest global networks, with data centers spanning over 330 cities and interconnection with over 13,000 network peers. It also has a greater presence in core Internet exchanges than many other large technology companies.\n\nAs a result, Cloudflare operates within \\~50 ms of \\~95% of the worldâ€™s Internet-connected population. And since all Cloudflare services are designed to run across every network location, all requests are routed, inspected, and filtered close to their source, resulting in strong performance and consistent user experiences.\n\nThis document describes a reference architecture for organizations looking to deploy both global and local traffic management load balancing solutions.\n\n### Who is this document for and what will you learn?\n\nThis reference architecture is designed for IT, web hosting, and network professionals with some responsibility over or familiarity with their organization's existing infrastructure. It is useful to have some experience with networking concepts such as routing, DNS, and IP addressing, as well as basic understanding of load balancer functionality.\n\nTo build a stronger baseline understanding of Cloudflare and its load balancing solution, we recommend the following resources:\n\n* What is Cloudflare? | [Website](https://www.cloudflare.com/what-is-cloudflare/) (5 minute read) or [video](https://youtu.be/XHvmX3FhTwU?feature=shared) (2 minutes)\n\n- Solution Brief: [Cloudflare Private Network Load Balancing](https://cf-assets.www.cloudflare.com/slt3lc6tev37/4mn2dtdw7TvSwCUJw8mMf5/f1fa6269f4468c432560b2c9f5ebd38a/Cloudflare_Local_Traffic_Manager_Solution_Brief.pdf) (5 minute read)\n- Solution Brief: [Cloudflare GTM Load Balancing](https://cf-assets.www.cloudflare.com/slt3lc6tev37/5OWUduF4YBKYADj3zREAX6/5241a81a3fc4ff1db7c9bade14991b23/Cloudflare_Global_Traffic_Manager__GTM__Solution_Brief.pdf) (5 minute read)\n- Blog: [Elevate load balancing with Private IPs and Cloudflare Tunnels: a secure path to efficient traffic distribution](https://blog.cloudflare.com/elevate-load-balancing-with-private-ips-and-cloudflare-tunnels-a-secure-path-to-efficient-traffic-distribution/) (13 minutes)\n\nThose who read this reference architecture will learn:\n\n* How Cloudflare Load Balancing can address both Private Network Load Balancing and global traffic management use cases.\n* How Cloudflareâ€™s global network enhances the functionality of Cloudflare Load Balancing.\n* The capabilities of Cloudflare Load Balancers, and how they apply to various use cases.\n* The structure of Cloudflare Load Balancers and their various configurations.\n\n## Handling dynamic workloads in modern applications\n\n### Concepts and terminology\n\nIn this document, the term â€œendpointâ€ is any service or hardware that intercepts and processes incoming public or private traffic. Since load balancing can be used for more than just web servers, the term endpoint has been chosen to represent all possible types of origins, hostnames, private or public IP addresses, virtual IP addresses (VIPs), servers, and other dedicated hardware boxes. It could be on-premises or hosted in a public or private cloud â€” and could even be a third-party load balancer.\n\nSteering is a load balancerâ€™s main function â€” the process of handling, sending, and forwarding requests based on a set of policies. These policies generally take many factors into account, including request URL, URL path, HTTP headers, configured weights, priority, and endpoint latency, responsiveness, capacity, and load.\n\n[Layer 7](https://www.cloudflare.com/learning/ddos/what-is-layer-7/) of the [OSI model](https://www.cloudflare.com/learning/ddos/glossary/open-systems-interconnection-model-osi/), also known as the application layer, is where protocols such as SSH, FTP, NTP, SMTP, and HTTP(S) reside. When this document refers to layer 7 or layer 7 load balancers, it means HTTP(S)-based services. The Cloudflare layer 7 stack allows Cloudflare to apply services like DDoS protection, Bot Management. WAF, CDN, Load Balancing and more to a customer's website to improve performance, availability, and security.\n\nLayer 4 of the [OSI model](https://www.cloudflare.com/learning/ddos/glossary/open-systems-interconnection-model-osi/) â€” also called the transport layer â€” is responsible for end-to-end communication between two devices. Network services that operate at layer 4 can support a much broader set of services and protocols. Cloudflareâ€™s public layer 4 load balancers are enabled by a product called Spectrum, which works as a layer 4 reverse proxy. In addition to offering load balancing, Spectrum provides protection from [DDoS attacks](https://www.cloudflare.com/learning/ddos/what-is-a-ddos-attack/) and can conceal the endpoint IP addresses.\n\n#### SSL/TLS Offloading\n\nSSL (Secure Sockets Layer) and its successor TLS (Transport Layer Security) are cryptographic protocols used to secure connections over the Internet. SSL and TLS offloading, also known as SSL/TLS termination or SSL/TLS acceleration, is a technique used in load balancers and web servers to handle the SSL/TLS encryption and decryption process without affecting an endpointâ€™s performance. SSL/TLS offloading improves server performance, simplifies certificate management, and enhances scalability by offloading the resource-intensive encryption and decryption tasks to dedicated devices, helping endpoints remain dedicated to serving content and application logic.\n\n### Challenges addressed by load balancers\n\nModern websites, or any applications for that matter, face three main challenges:\n\n1. **Performance:** Ensuring that the application responds to users requests and input in a timely manner\n2. **Availability:** Maintaining the uptime for the application, so it is always able to respond to user requests\n3. **Scalability:** Growing, shrinking, or relocating application resources based on user behavior or demand.\n\nApplication performance can be affected by several factors, but the most common cause of performance issues is the amount of usage or load placed on an endpoint. An endpoint generally has a finite amount of compute resources it can provide. If too many requests arrive at once, or if the type of requests cause increased CPU/memory usage, the endpoint will respond slower or fail to respond at all.\n\nTo address these challenges, endpoints can be upgraded with more compute resources. But during idle or low-usage times, the organization ends up paying for underutilized resources. Organizations may also deploy multiple endpoints â€” but to seamlessly steer traffic between them, a load balancing solution is needed to make this process seamless to the end user.\n\nFigure 1 shows how load might be distributed without a load balancer:\n\n![Endpoint load is not distributed evenly without a load balancer](https://developers.cloudflare.com/_astro/lb-ref-arch-1.D0yttOOR_Z5jog7.svg)\n\nLoad balancers allow organizations to host several endpoints and portion out traffic between them, ensuring no single endpoint gets overwhelmed. The load balancer handles all incoming requests and forwards them to the appropriate endpoint. The client doesnâ€™t need any knowledge of endpoint availability or load â€” it just needs to send the request to the load balancer and the load balancer handles the rest. Figure 2 shows how a load balancer can evenly distribute traffic from users across a set of endpoints.\n\n![A load balancer helps evenly distribute requests across multiple endpoints](https://developers.cloudflare.com/_astro/lb-ref-arch-2.DiqlVt64_1JJ2DB.svg)\n\nAnother performance-related issue has to do with the distance between a client and an endpoint. Whether due to the mere fact of traveling farther, or having to make more network hops, a request that travels a longer distance generally has a higher round-trip time (RTT).\n\nRTT becomes important at scale. For example, if a client and endpoint are both located in the United States, it would be reasonable to expect a RTT of 25ms. If the client has 20 requests it needs responses to, the total time required to handle them sequentially (not including compute time) would be 500ms (20 x 25ms). And if the same client connected from the APAC region the RTT might be upwards of 150ms, resulting in an undesirable total loading time of 3000ms (20 x 150ms). (Certainly, request streaming enhancements in HTTP/2 and HTTP/3 might change this math â€” but in websites with dynamic or interactive content, where a responseâ€™s information is used to generate additional requests, the example still holds in general.) Figure 3 illustrates how this happens.\n\n![Latency compounds based on the number of requests](https://developers.cloudflare.com/_astro/lb-ref-arch-3.D0FbXMvI_Z2hnSD3.svg)\n\nIn the same way a load balancer can pass traffic to a less-busy endpoint, it can also pass traffic to a geographically closer endpoint, resulting in a more responsive experience for the client. Specifically, the load balancer performs a lookup of the IP address that sent the request, determines its location, and selects the closest or most region-appropriate endpoint to send it to (this is similar to functionality provided by DNS solutions like GeoDNS).\n\nService availability encompasses both unintentional and intentional downtime of endpoints behind a load balancer. Several factors can contribute to unintentional downtime, including hardware failure, software bugs, network issues, and ISP or other vendor issues. Even for the most advanced organizations, these issues are inevitable.\n\nLoad balancers solve these issues by always monitoring the health of endpoints. If an endpoint is slow to respond to a health check, or fails to respond entirely, the endpoint is marked as unhealthy. Several methods exist for monitoring, including basic health tests like ICMP (ping) and TCP connection tests. More advanced health tests can be used like issuing an HTTP GET request and ensuring a specific response code and response body are returned from the endpoint. Once an endpoint is in a degraded state, the load balancer will send fewer or no requests its way in favor of healthier endpoints. As the endpoint becomes operational again and the load balancer is able to receive responses to its health checks, the endpoint is marked as operational and has traffic steered towards it once more.\n\nIntentional downtime comes in a few different forms, including capacity changes, hardware or infrastructure upgrades, and software updates. Load balancers gracefully remove traffic from one or more endpoints to allow for such maintenance.\n\nEffective application scaling helps organizations meet customer or user demand and avoid unnecessary billing or charges. During traffic increases, organizations may need to temporarily deploy more endpoints to ensure the service stays performant and available. However, constantly having enough endpoints online to meet your maximum possible traffic could be costly regardless whether the endpoint is located on-premises or via a cloud provider like AWS, GCP, or Azure. Load balancers allow for dynamic increases or decreases in capacity by monitoring requests, connections, and latency to the endpoints.\n\nAnother type of scale to consider is geographic scale. As services grow in popularity, endpoint location becomes more important. Users in a different geographic region than an endpoint may have slower response times and receive a lower quality of service than users in the same region. As organizations deploy new endpoints in different regions, they have to decide how they want to distribute their traffic. This challenge has been met by different layers of load balancing called global traffic management (GTM) and Private Network Load Balancing. This document describes both of these in detail in the following section â€” but in summary, the GTM load balancer handles the initial request (typically via DNS) and then selects and steers traffic to the Private Network Load Balancer that is deployed close to endpoints in the appropriate geographic region.\n\n### Types of traffic management\n\nAs mentioned, load balancing for global applications and services comes in two layers. The first layer is called Global Traffic Management or Manager (GTM), which may also be called Global Server Load Balancing (GSLB). The second layer is called Private Network Load Balancing, which may also be referred to as Server Load Balancing (SLB). This section will define the purpose of these different types of load balancing and how they work together.\n\n#### Global traffic manager / global traffic management (GTM)\n\nA Global Traffic Manager is responsible for routing requests, generally from the Internet, to the proper region or data center. Many GTM load balancers operate at the DNS layer, allowing them to:\n\n* Resolve a DNS request to an IP address based on geographic region or physical location.\n* Provide the IP of the endpoint or service closest to the client, so it can connect.\n\nFigure 4 shows how a GTM load balancer is used to select a data center based on the client location or region.\n\n![Global traffic management steers traffic to the proper region or data center](https://developers.cloudflare.com/_astro/lb-ref-arch-4.OnwMof7d_Z1K1cGR.svg)\n\nGlobal Traffic Managers can also proxy traffic and perform a variety of inspections, including reading/changing/deleting headers in HTTP requests and modifying URLs based on region or geographic location. GTM functionality is best implemented by cloud-based load balancers (like Cloudflare) since the goal is to steer traffic from anywhere in the world. Hardware load balancers exist in a single physical location, which means the further traffic originates from the load balancer, the slower the end-user experience. A cloud-based load balancer can run in many different geographic locations, helping it provide a performant solution for DNS-only, layer 4, and layer 7 contexts.\n\n#### Private Network Load Balancing\n\nPrivate Network Load Balancing steers traffic within a data center or geographic location. A Private Network Load Balancer can be responsible for load balancing, SSL/TLS offloading, content switching, and other application delivery functions. Private Network Load Balancing ensures efficient distribution of client requests across multiple endpoints to improve performance and ensure high availability. Private Network Load Balancers are usually placed inside private networks and are used to load balance publicly or privately accessible resources. In Figure 5 below, the GTM load balancer has selected the Europe data center to direct a request to the Europe data centerâ€™s Private Network Load Balancer which will then steer it to the appropriate endpoint.\n\n![Private Network Load Balancing is responsible for steering to the final endpoint or destination](https://developers.cloudflare.com/_astro/lb-ref-arch-5.F19YgVWw_1xKcgo.svg)\n\nPrivate Network Load Balancer and their endpoints usually sit behind firewalls. But while endpoints may be protected on private networks, accessibility to the Private Network Load Balancer can be either public or private depending on deployment requirements. A Private Network Load Balancer will monitor total requests, connections, and endpoint health to ensure requests are steered towards endpoints capable of responding in a timely manner.\n\n#### On-premises vs cloud-based load balancers\n\nThere are two main load balancer architectures:\n\n* On-premises load balancers\n\n* Typically hardware-based, but also can be virtualized or software-based\n  * Focused on maximum performance\n\n* Cloud-based load balancers\n\n* Software deployed public cloud infrastructure\n  * Handle requests closer to the originator of the request\n\nEach approach has advantages and disadvantages. On-premises load balancers usually exist inside of private networks completely controlled by the organization. These load balancers are collocated with the endpoints they are load balancing, so latency and RTT time should be minimal. The disadvantage of these on-premises load balancers is that they are restricted to a single physical location. Which means traffic from other regions can have long RTT and high latency in responses. Also, adding another data center requires purchasing and deploying all new equipment. On-premises load balancers also typically require cloud-based load balancers for geographic traffic steering to get requests routed by a geographically local or region-appropriate data center. The advantages of cloud-based load balancers is that they can operate in almost any geographic region without concern for rack space, power, cooling, or maintenance and can scale without concern for new chassis, modules, or larger network connections. Cloud-based load balancers do however increase latency and RTT between the load balancer and the endpoints as they are not typically colocated with the endpoints they are steering traffic toward.\n\n## Cloudflare Load Balancing architecture and design\n\nCloudflare has offered cloud-based GTM since 2016 and started adding Private Network Load Balancing capabilities in 2023. This section will review the entire Cloudflare Load Balancing architecture and dive deep into the different configurations and options available. First, however, it's important to understand the benefits that Cloudflare Load Balancers have simply by running on Cloudflareâ€™s global network.\n\n### Inherent advantages in the Cloudflare architecture\n\nCloudflare Load Balancing is built on Cloudflareâ€™s connectivity cloud, â€‹â€‹a unified, intelligent platform of programmable cloud-native services that enable any-to-any connectivity between all networks (enterprise and Internet), cloud environments, applications, and users. It is one of the largest global networks, with data centers spanning over 330 cities and interconnection with over 13,000 network peers. It also has a greater presence in core Internet exchanges than many other large technology companies.\n\nAs a result, Cloudflare operates within \\~50 ms of \\~95% of the worldâ€™s Internet-connected population. And since all Cloudflare services are designed to run across every network location, all traffic is connected, inspected, and filtered close to the source for the best performance and consistent user experience.\n\nCloudflareâ€™s load balancing solution benefits from our use of anycast technology. Anycast allows Cloudflare to announce the IP addresses of our services from every data center worldwide, so traffic is always routed to the Cloudflare data center closest to the source. This means traffic inspection, authentication, and policy enforcement take place close to the end user, leading to consistently high-quality experiences.\n\nUsing anycast ensures the Cloudflare network is well balanced. If there is a sudden increase in traffic on the network, the load can be distributed across multiple data centers â€“ which in turn, helps maintain consistent and reliable connectivity for users. Further, Cloudflareâ€™s large network capacity and AI/ML-optimized smart routing also help ensure that performance is constantly optimized.\n\nBy contrast, many other SaaS-based load balancing providers use Unicast routing in which a single IP address is associated with a single endpoint and/or data center. In many such architectures, a single IP address is then associated with a specific application, which means requests to access that application may have very different network routing experiences depending on how far that traffic needs to travel. For example, performance may be excellent for employees working in the office next to the applicationâ€™s endpoints, but poor for remote employees or those working overseas. Unicast also complicates scaling traffic loads â€” that single service location must ramp up resources when load increases, whereas anycast networks can share traffic across many data centers and geographies.\n\nFigure 6 shows how using the Cloudflare network allows geographically disparate users to connect to their resources as fast as possible.\n\n![Cloudflareâ€™s global anycast network ensures that the closest data center is always selected](https://developers.cloudflare.com/_astro/lb-ref-arch-6.Bw_DeAYw_1p6IbN.svg)\n\nFigure 6, above, shows other Cloudflare services are also running in each of these data centers since Cloudflare runs every service in every data center so users have a consistent experience everywhere. For example, Cloudflareâ€™s layer 7 load balancer will also be able to take advantage of other services such as DDoS protection, CDN/Cache, Bot Management, or WAF. All of these additional services can help protect your service from unnecessary traffic whether it be malicious requests (blocked by DDoS Protection, Bot Management, or WAF) or requests that can be served via cache rather than a request to endpoint. All of these services can be combined as needed to make a service or offering as protected, resilient, and performant as possible.\n\n![Cloudflare Layer 7 features can be used together to further secure a service](https://developers.cloudflare.com/_astro/lb-ref-arch-7.BB-S-4sn_1aRfuI.svg)\n\nCloudflare also has a [network optimization service](https://blog.cloudflare.com/orpheus-saves-internet-requests-while-maintaining-speed/) that is constantly running at all data centers to ensure that Cloudflare provides the best path between Cloudflare data centers and also track all the available paths to endpoints. This allows Cloudflare to ensure that endpoints can always be reached and reroute traffic to alternate Cloudflare data centers, if necessary, to reach an endpoint. After the load balancer has made a decision on which endpoint to steer the traffic, the traffic is then forwarded to Cloudflareâ€™s network optimization service to determine the best path to reach the destination. The path can be affected by a feature called Argo Smart Routing which, when enabled, uses timed TCP connections to find the Cloudflare data center with the fastest RTT to the endpoint. Figure 8 shows how Argo Smart Routing can help improve connection time to endpoints.\n\n![Argo Smart Routing finds the fastest path between requester and endpoint](https://developers.cloudflare.com/_astro/lb-ref-arch-8.DxPypMMy_22dvJA.svg)\n\nAnother way traffic flow can be affected is by the use of Cloudflare Tunnels. This document covers Cloudflare Tunnels in depth in the following section. Because Cloudflare Tunnels connect endpoints to specific Cloudflare data centers, traffic destined for those endpoints must traverse those data centers to reach the endpoint. Figure 9 shows how connections to private endpoints connected via Cloudflare Tunnel must pass through the data center where the tunnel terminates.\n\n![Requests take different paths depending on whether the endpoint is public or connected over Cloudflare Tunnel](https://developers.cloudflare.com/_astro/lb-ref-arch-9.coisSp9H_1EAgtQ.svg)\n\nUsually, GTM and Private Network Load Balancers are either separate hardware or separate SaaS (GTM) and hardware Private Network Load Balancing components. Cloudflareâ€™s GTM and Private Network Load Balancing capabilities are combined into a single SaaS offering which greatly simplifies configuration and management. There is no need to create a GTM load balancer and steer traffic to more local Private Network Load Balancers. All endpoints can be directly connected to Cloudflare and traffic is steered to the correct region, data center, and endpoint all from a single load balancer configuration. While the concepts of GTM and Private Network Load Balancing features will persist, their implementation in Cloudflare will be done in a way that keeps load balancer configurations as simple and straightforward as possible. Figure 10 illustrates how global traffic can be steered from any geographic region to a specific endpoint as needed.\n\n![Combining GTM and Private Network Load Balancing functions into a single load balancer configuration](https://developers.cloudflare.com/_astro/lb-ref-arch-10.BICXl4Ld_Z1YULLg.svg)\n\n### The structure of a Cloudflare Load Balancer\n\nA Cloudflare Load Balancer, often referred to as a Virtual IP (VIP), is configured with an entrypoint. Typically, this entrypoint is a DNS record. The load balancer first applies a defined traffic steering algorithm to select an endpoint pool, which is a group of endpoints selected based on function, geographic area, or region. A load balancer configuration can have one or multiple endpoint pools, and each endpoint pool can have one or many endpoints. After selecting an endpoint pool, the load balancer applies an endpoint steering algorithm to the list of endpoints and selects an endpoint to steer the traffic towards. Figure 11 shows the basic steps from client request to endpoint within a Cloudflare Load Balancer.\n\n![The steps within a Cloudflare Load Balancer](https://developers.cloudflare.com/_astro/lb-ref-arch-11.Bx2sEYiV_Z1UOFqd.svg)\n\nThe definition of a Cloudflare Load Balancer is divided into three main components:\n\n1. Health monitors: these components are responsible for observing the health of endpoints and categorizing them as healthy or critical (unhealthy).\n2. Endpoint pools: this is where endpoints are defined and where health monitors and endpoint steering are applied.\n3. Load balancers: in this component, lists of endpoint pools and traffic steering policies are applied.\n\nThe following sections detail the options available and considerations for configuring a Cloudflare Load Balancer, starting with steering, which is utilized in both endpoint pool and load balancer configurations.\n\n### Steering types and methods\n\nSteering is the core function of a load balancer and steering methods ultimately determine which endpoint is going to be selected when a load balancer is engaged. From the load balancerâ€™s perspective, steering can be applied in two key areas.\n\nThe first is called â€˜traffic steeringâ€™, and it is responsible for determining which endpoint pool will handle incoming requests, typically based on proximity or geographic region of the requester. The concept of traffic steering closely aligns with the idea of global traffic management.\n\nThe second area where steering is applied is after a region, data center, or endpoint pool has been selected. At this point, the load balancer needs to select the single endpoint responsible for handling the request or connection, referred to as â€˜endpoint steeringâ€™. Steering at both of these levels is done by applying steering methods tailored to the specific needs of the customer deploying the load balancer. There are several different algorithms to choose from, but not all algorithms are applicable to both steering types.\n\nBelow is an in-depth review of all the steering methods Cloudflare offers. At the end of this section, there is a quick reference table which can be helpful in understanding which algorithms are applicable to which use cases.\n\n#### Traffic steering\n\nTraffic steering selects the group of endpoints, also called an endpoint pool. The most common use of traffic steering is to select the endpoint pool based on the least latent response times, geographic region, or physical location. Traffic steering is closely aligned to global traffic management and serves as the initial step in directing traffic to an endpoint.\n\n#### Endpoint steering\n\nEndpoint steering is responsible for selecting which endpoint will receive the request or connection. Endpoint steering can randomly select an endpoint, a previously selected endpoint (if session affinity is enabled), or it can be used to select the least utilized, fastest responding, endpoint for a request or connection. Endpoint steering is closely related to Private Network Load Balancing, as it is responsible for selecting the final destination of a request or connection.\n\n#### Weighted steering\n\nWeighted steering takes into account the differences in endpoint pools and endpoints that will be responsible for handling requests from a load balancer. Endpoint weight, which is a required field for every endpoint, is only used when specific steering methods are chosen. Similarly, endpoint pool weight is only needed when specific steering methods are selected. Please see the [steering options overview](#steering-options-overview) section for a quick reference for when weights are applied.\n\nWeight influences the randomness of endpoint pool or endpoint selection for a single request or connection within a load balancer. Weight does not consider historical data or current connection information, which means that weight may have variations in distribution over shorter timeframes. However, over longer periods of time and with significant traffic, the distribution will more closely resemble the desired weights applied in configuration. Itâ€™s important to note that session affinity will also override weight settings after the initial connection, as session affinity is intended to direct subsequent requests to the same endpoint pool or endpoint. Figure 12 shows a weight example for two endpoint pools with equal capacity and probability of being selected.\n\n![A pair of endpoint pools with equal probability of being selected](https://developers.cloudflare.com/_astro/lb-ref-arch-12.Buje8NxO_OS9v8.svg)\n\nSpecific algorithms, such as Least Outstanding Request Steering, take into account the number of open requests and connections. Weight is used to determine which endpoints or endpoint pools can handle a greater number of open requests or connections. Essentially, weight defines the capacity of endpoints or endpoint pools, regardless of the selected steering method.\n\nWeight is defined as any number between 0.00 and 1.00. Itâ€™s important to note that the total weight of the endpoint pools or the endpoints within an endpoint pool do not need to equal 1. Instead, the weights will be added together, and then an individual weight value is divided by that sum to get the probability of that endpoint being selected.\n\nWeight to percentage equation: (endpoint weight) Ã· (sum of all weights in the pool) = (% of traffic to endpoint)\n\nBelow are some examples with diagrams to help in understanding how weight is used for distributing traffic. In these examples, it is assumed that the goal is to evenly distribute traffic across all endpoints with the same capacity or compute resources. [Random](#random-steering) traffic steering will be used to demonstrate traffic distribution across three endpoint pools.\n\n* There are three endpoint pools defined, all with a weight of 1\n* Each endpoint pool has a 33% probability of being selected\n\nExample math for weight of 1: (1) Ã· (1 + 1 + 1) = (.3333) (or 33.33%)\n\n![A set of three endpoint pools all with equal probability](https://developers.cloudflare.com/_astro/lb-ref-arch-13.BIZS6w9__Z2cTOVH.svg)\n\nIn this example, it was simple to apply 1 to all the weight values for each of the endpoint pools. However, it should be noted that any number between 0.01 and 1.00 could have been used as long as the same number was used across all three endpoint pools. For instance, setting all three pools to .1 or even .7 would have resulted in an equal probability that each pool would be selected to receive traffic.\n\nSince the sum of the weights is used to calculate the probability, organizations can use any number of values to make these inputs easier to understand. In the following examples, since each endpoint has the same capacity, a value of .1 weight is assigned to each endpoint, and the sum of these values is used as the weight for the endpoint pool.\n\n* There are three endpoint pools defined\n* Each endpoint pool has a different number of endpoints, but all endpoints have equal capacity\n* To evenly distribute load across endpoints, each endpoint pool needs a different probability\n\n![Three endpoint pools with different numbers of endpoints](https://developers.cloudflare.com/_astro/lb-ref-arch-14.ChU-xE19_Z2bnfwR.svg)\n\nExample math for weight of .4 : (.4) Ã· (.4 + .5 + .6) = (.2667) (or 26.67%)\n\nExample math for weight of .5 : (.5) Ã· (.4 + .5 + .6) = (.3333) (or 33.33%)\n\nExample math for weight of .6 : (.6) Ã· (.4 + .5 + .6) = (.4000) (or 40.00%)\n\nIt is possible that endpoints do not all have the same capacity. In the following example, one of the endpoint poolâ€™s endpoints has twice the capacity of the endpoints in the other two endpoint pools.\n\n* There are three endpoint pools defined\n* Endpoint pool 1 has endpoints that have double the capacity compared to those in endpoint pool 2 and endpoint pool 3\n* The goal is to place double the amount of traffic to endpoint pool 1 per endpoint\n* Endpoint pool 1 has 4 endpoints but with double capacity, the weight of each endpoint will be valued at .2 for a total of .8 for the endpoint pool\n\n![Three endpoint pools with different numbers of endpoints and endpoints of different capacity](https://developers.cloudflare.com/_astro/lb-ref-arch-15.CJwKtgsv_ZhFknv.svg)\n\nExample math for weight of .8 : (.4) Ã· (.8 + .5 + .6) = (.4211) (or 42.11%)\n\nExample math for weight of .5 : (.5) Ã· (.8 + .5 + .6) = (.2632) (or 26.32%)\n\nExample math for weight of .6 : (.6) Ã· (.8 + .5 + .6) = (.3157) (or 31.57%)\n\nIn this final example, since the four endpoints in endpoint pool 1 are double the capacity of other endpoints, the calculation treats endpoint pool 1 as if it essentially has 8 endpoints instead of 4. Therefore, the weight value of .8 instead of .4 as shown in example 2.\n\nThese are just three simple examples illustrating how weight can be used to distribute load across endpoint pools or endpoints. The same calculations are used for weights applied to endpoints within an endpoint pool as well. However, the impact of using weights within different steering methods is similar, although with slightly modified calculations, as covered in the sections below.\n\nWeights are most useful when one endpoint pool might have more resources than another endpoint pool or when endpoints within an endpoint pool do not have equal capacity. Weight helps to ensure that all resources are used equally given their capabilities.\n\n#### Steering methods\n\nOff - failover is the most basic of traffic steering policies. It uses the order of the endpoint pools as a priority list for selecting which pool to direct traffic towards. If the first pool in the list is healthy and able to receive traffic, that is the pool that will be selected. Since off - failover isnâ€™t available for endpoint steering, another steering method will be used to select an endpoint. Off - failover is commonly used in active/passive failover scenarios where a primary data center or group of endpoints is used to handle traffic, and only under failure conditions, is traffic steered towards a backup endpoint pool.\n\n##### Random steering\n\nRandom steering is available for both traffic steering and endpoint steering. Random spreads traffic across resources based on the weight defined at both the load balancer configuration and within the endpoint pool. The weight values set at the load balancer for each endpoint pool can differ from the weight value set per endpoint within that endpoint pool. For example, within a load balancer configuration, 70% of traffic can be sent to one of two endpoint pools, then within that endpoint pool, the traffic can be evenly distributed across four endpoints. The previous section, [weighted steering](#weighted-steering), provides a detailed explanation of how weight is used and the calculations that determine the selection of an endpoint pool or endpoint.\n\nHash steering is an endpoint steering algorithm that uses endpoint weight and the requestâ€™s source IP address to select an endpoint. The result is that every request from the same IP address will always steer to the same endpoint. Itâ€™s important to note that altering the order of endpoints or adding or removing endpoints from the endpoint pool could result in different outcomes when using the hash algorithm.\n\nGeo steering is a traffic steering algorithm available to enterprise plan customers that is used to tie endpoint pools to specific countries or geographic regions. This option can be useful for improving performance by steering traffic to endpoints closer to users. It also aids in complying with laws and regulations by steering requests from users in specific regions to resources within the same region or to resources designed to meet specific regulatory requirements.\n\n##### Dynamic steering\n\nDynamic steering is a traffic steering algorithm available to enterprise plan customers that creates round trip time (RTT) profiles. RTT values are collected each time a health probe request is made and based on the response from the endpoint to the monitor request. When a request is made, Cloudflare inspects the RTT data and sorts pools by their RTT values. If there is no existing RTT data for your pool in a region or colocation center, Cloudflare directs traffic to the pools in failover order. When enabling dynamic steering the first time for an endpoint pool, allow 10 minutes for the change to take effect as Cloudflare builds an RTT profile for that pool. Dynamic steering doesnâ€™t use geographic boundaries in its decision making process and solely focuses on selecting the lowest RTT endpoint pool.\n\n##### Proximity steering\n\nProximity steering is a traffic steering algorithm available to enterprise plan customers that steers traffic to the closest physical data center based on where the request endpointated.\n\nCloudflare determines the requesterâ€™s physical location using the following methods, in this order:\n\n1. [EDNS Client Subnet](https://developers.google.com/speed/public-dns/docs/ecs) information, if provided in the DNS request\n2. Geolocation information of the resolver used to reach Cloudflare\n3. GPS location of the Cloudflare data center handling the request\n\nProximity steering requires providing GPS coordinates for all endpoint pools, allowing Cloudflare to calculate the closest endpoint pool based on the requesting IP, DNS resolver, or Cloudflare data center.\n\n##### Least outstanding requests steering (LORS)\n\nLeast outstanding request steering (LORS) is available to enterprise plan customers and can be used for both traffic and endpoint steering.\n\nLORS uses the number of unanswered HTTP requests to influence steering and is only functional when used with Cloudflare Layer 7 proxied Cloudflare Load Balancers. If LORS is assigned to any other type of load balancer, its behavior will be equivalent to random steering. LORS uses the counts of open requests, along with weight, to create a new transformed weight that is used for the steering decision.\n\nEquation for LORS transformed weight:\n\n* weight / (count + 1) = transformedWeight\n\nReminder for random weight calculation:\n\n* weight / (total weight) = probability of being selected\n\nHereâ€™s an example of LORS:\n\n* Pool A has a weight of 0.4\n* Pool B has a weight of 0.6\n* Pool A has 3 open requests\n* Pool B has 0 open requests\n* Relevant equation\n  * weight / (count + 1) = transformedWeight\n* Pool A's transformed weight: 0.4 / (3 + 1) = 0.1\n* Pool B's transformed weight: 0.6 / (0 + 1) = 0.6\n* Relevant equation\n  * weight / (total weight) = probability of being selected\n* Pool Aâ€™s probability of being steered toward: 0.1 / (0.1+0.6) = .1429 (14.29%)\n* Pool Bâ€™s probability of being steered toward: 0.6 / (0.1+0.6) = .8571 (85.71%)\n\nIn this example, the next connection has a 14.29% probability of being steered to Pool A and a 85.71% probability of being steered to Pool B. While itâ€™s likely that traffic will be steered towards Pool B, it is still possible for it to be steered to Pool A. In situations with lighter load conditions, there will be more variation in the steering results, which may not precisely match the configured weights. However, as the load increases, the actual steering results will closely match the configured weights.\n\nWhen non-L7 proxied load balancers are used with LORS, the open request count information is not available. As a result, the denominator will always be 1. Since dividing any number by 1 doesnâ€™t change the numerator, and in this case, the numerator is the weight, steering decisions will be made solely on weight. This results in the random method described above.\n\nLORS is best used if endpoint pools or endpoints are easily overwhelmed by spikes in concurrent requests. It is well-suited for applications that value endpoint health over factors like latency, geographic alignment, or other metrics. This is especially useful when some or all requests put a heavy load on an endpoint and take a significant amount of time to generate a response.\n\n#### Steering options overview\n\n| Steering Method | Traffic Steering | Endpoint Steering | Weight-based | Enterprise-only |\n| - | - | - | - | - |\n| Off - Failover | X | | | |\n| Random | X | X | X | |\n| Hash | | X | X | X |\n| Geo | X | | | X |\n| Dynamic | X | | | X |\n| Proximity | X | | | X |\n| Least Outstanding Requests | X | X | X | X |\n\nAll traffic steering methods marked above as Enterprise-only can also be obtained as a self-service add-on as well. All endpoint steering methods marked as Enterprise-Only require an enterprise plan with Cloudflare.\n\nA health monitor determines the health of endpoints once they are configured inside an endpoint pool. Health monitors generate probes, which are connection attempts to endpoints. Health monitors use the responses to the probes to record endpoint health. Health monitors serve as templates that include service type, path, and port, and advanced features such as interval, timeout, and protocol specific settings for evaluating endpoint health. The health monitor template is then applied to the endpoint pool, which contains endpoints hosting similar services. Once a health monitor is attached to the endpoint pool, the endpoint address is used as the destination for the health monitor probe. A single health monitor can be used across many endpoint pools, and health monitors are account-level objects, allowing them to be leveraged by multiple zones within the same Cloudflare account.\n\nBy default, health monitor probes are sent directly to the endpoint address, bypassing the entire layer 7 stack. This means that actual traffic to the endpoint through the load balancer will receive different treatment than the health monitor probe. Depending on the configuration, this could result in a health monitor reporting an endpoint as healthy, even if actual connections or requests are failing.\n\nThe Simulate Zone feature ensures that health monitor probes follow the same path as actual requests, passing through the entire layer 7 stack. This ensures health monitors take the exact same path through the network and through other layer 7 processes to reach the endpoint.\n\nThe Simulate Zone feature is required for health monitors when certain features are enabled, such as [Authenticated Origin Pulls (AOP)](https://developers.cloudflare.com/ssl/origin-configuration/authenticated-origin-pull/), where probes would fail if they werenâ€™t being provided with the proper mTLS certificate for authentication on the origin. Simulate Zone also ensures health monitor probes use the same path provided by [Argo Smart Routing](https://developers.cloudflare.com/argo-smart-routing/) and the same [Dedicated CDN Egress IPs](https://developers.cloudflare.com/smart-shield/configuration/dedicated-egress-ips/) when organizations leverage [Smart Shield Advanced](https://developers.cloudflare.com/smart-shield/get-started/#packages-and-availability) to restrict the edge IP addresses that Cloudflare uses to reach their endpoints.\n\n![HTTPS health monitor to monitor the status of an endpoint](https://developers.cloudflare.com/_astro/lb-ref-arch-16.BYSozQzy_1111Rp.webp)\n\nHealth monitor Probes can be configured as the following types:\n\n* HTTP\n* HTTPS\n* TCP\n* UDP ICMP\n* ICMP Ping\n* SMTP\n* LDAP\n\nOnce a health monitor is defined, it can be assigned to an endpoint and the probes will be sent to the endpoint at the interval defined. There are two additional settings to note in regards to the health monitor configuration within the endpoint pool. The first is the Health Threshold, which is used to determine how many endpoints within the pool need to be healthy in order to consider the endpoint pool to be healthy or degraded.\n\n* Endpoint pool in healthy state\n  * Contains only healthy endpoints\n\n* Endpoint pool in degraded state\n  * Contains at least one critical endpoint but remains at or above the health threshold setting\n\n* Endpoint pool in critical state\n\n* Contains healthy endpoints below the health threshold\n  * Not capable of handling traffic; removed from all steering decisions.\n\n![Comparison of three endpoint pools with different numbers of healthy endpoints](https://developers.cloudflare.com/_astro/lb-ref-arch-17.BM3mVtFf_n523H.svg)\n\nThe second setting after defining the health monitor in the endpoint pool is to define which regions the health monitor probes should source from inside the Cloudflare global network. The available selections are listed below:\n\n* All Regions (Default)\n* All Data Centers (Enterprise Only)\n* Western North America\n* Eastern North America\n* Western Europe\n* Eastern Europe\n* Northern South America\n* Southern South America\n* Oceania\n* Middle East\n* Northern Africa\n* Southern Africa\n* Southern Asia\n* Southeast Asia\n* Northeast Asia\n\n![Endpoint pool settings to further customize the health monitors](https://developers.cloudflare.com/_astro/lb-ref-arch-18.BeeIf21t_2sOzXz.webp)\n\nWith the exception of â€œAll Regionsâ€ and â€œAll Data Centersâ€, health monitor probes will only originate from data centers in the selected region or regions. For locally relevant services, it may not matter whether or not a data center on the other side of the world can reach the endpoints. Therefore, limiting checks to a specific region or a set of regions may make sense. The selection of â€œAll Regionsâ€ or â€œAll Data Centersâ€ is intended to be used for globally available services where reaching a set of endpoints could be crucial to the function of the application.\n\n### Endpoints and endpoint pools\n\nEndpoints are the actual servers that handle connections and requests after a load balancer has applied all its policies. Endpoints can be physical servers, virtual machines, or serverless applications. As long as they can handle a request or connection from a user or client, they can be considered an endpoint. There are several different methods of defining and connecting endpoints to Cloudflare and the next section details those methods.\n\n#### Connecting endpoints to Cloudflare\n\nCloudflare endpoints can be defined in two ways, by IP address or by hostname. IP addresses are the most straightforward and basic of connection methods, hostnames offer a few options to consider. A hostname can be defined in Cloudflare DNS and it can be proxied or DNS-only (unproxied). Another option, of course, is that the hostname is not in a domain which Cloudflare is an authoritative DNS server for which means Cloudflare will rely on outside DNS servers to resolve that hostname to an IP address. Cloudflare Tunnel can also be used and offers two different options as well. These methods are discussed below in this section.\n\n##### Cloudflare proxied, DNS, IP, and non-Cloudflare endpoints\n\nAs mentioned in the â€œHTTP(S) Load Balancingâ€ section above, load balancing is the very last process run before a request is sent to an endpoint. In the case of however, even if an endpoint is proxied via Cloudflareâ€™s edge, after the load balancer, the request is forwarded directly to the endpoint without passing through the layer 7 stack again. This doesnâ€™t mean the endpoint is unprotected or uncached, however. As long as the load balancer itself is proxied then all those protections are provided to the load balancer rather than the endpoints. Any direct communication with the endpoint can still be proxied and treated with Cloudflareâ€™s layer 7 stack, but communication with an endpoint places all the processing in front of the load balancer, not the endpoint. Figure 19 illustrates the difference of where the Cloudflare layer 7 stack is placed in relation to the endpoint(s).\n\n![Load balancing is the last process before dispatching to the endpoint](https://developers.cloudflare.com/_astro/lb-ref-arch-19.CKZfc_hA_rdOtw.svg)\n\nThere are very few differences from a load balancer perspective when it comes to what type of endpoint is defined as part of an endpoint pool. Once the traffic and endpoint steering policies and the load balancer rules are applied, the Cloudflare Load Balancing service instructs the L7 stack where to forward the incoming request or connection. This request is sent directly to the endpoint. Depending on the type of connection to the endpoint, there may be a different path. Features like Argo Smart Routing or tunnel-connected endpoints that are terminated at different Cloudflare data centers will route traffic differently rather than sending the request out of the Cloudflare edge, over the internet, directly to the endpoint. Regardless of the path, however, load balancing is the last process in the stack and this means that traffic doesnâ€™t receive any additional treatment. So while the connection to endpoint can change the path from Cloudflare to the endpoint, the treatment or processing doesnâ€™t change once an endpoint is selected.\n\n##### Cloudflare Tunnel\n\nCloudflare Tunnel is an outbound connection that enables organizations to simplify their firewall configurations, reduce complexity, enhance security, and more easily join their assets to the Cloudflare network. The executable that creates these tunnels is called cloudflared and may be referenced in this document and diagrams that follow.\n\nCloudflare Tunnel (cloudflared) can be installed directly on the endpoint or any server with IP connectivity to the endpoint. And because the connection to Cloudflare is initiated from where Cloudflare Tunnel was installed to Cloudflare, the only access needed is outbound access to Cloudflare. A single Cloudflare Tunnel can transport traffic to one or many different endpoints in one of two different ways, one which results in the endpoint being publicly accessible and one which keeps the endpoint completely only accessible privately.\n\nCloudflare Tunnel can be installed on the endpoint itself or on any server with layer 3 (IP) connectivity to the endpoint or endpoints that need to be connected to Cloudflare. The decision to separate cloudflared could be made for many different reasons including but not limited to isolating the endpoint(s) and ensuring their performance, having separate teams that manage network level connectivity and endpoints, or separation for architectural simplicity where servers have segregated roles or responsibilities.\n\n![A single cloudflared instance tunnels traffic for multiple endpoints](https://developers.cloudflare.com/_astro/lb-ref-arch-20.BehqGz1M_Z2cqnXw.svg)\n\nA single cloudflared instance will create 4 different tunnels, two tunnels in two different Cloudflare data centers. This model ensures high availability and mitigates the risk of individual connection failures. This means in event a single connection, server, or data center goes offline, the endpoints will remain available. Cloudflare Tunnel also allows organizations to deploy additional instances of cloudflared, for availability and failover scenarios. These unique instances are called replicas. Each replica establishes four new connections which serve as additional points of ingress to the endpoint(s). Each of the replicas will point to the same tunnel. This ensures that your network remains up in the event a single host running cloudflared goes down. By design, replicas do not offer any level of traffic steering (random, hash, or round-robin).\n\n###### Public hostname\n\nThe public endpoint method allows organizations to define a tunnel that points to a specific service or port running on an endpoint. The tunnel can terminate on the endpoint or on any server with IP connectivity to the endpoint. Using this public hostname method requires that each service that will be accessed over the tunnel is defined in the tunnel configuration. When configured, a unique tunnel ID, such as d74b3a46-f3a3-4596-9049-da7e72c876f5, will be created for the IP and port or service for which the tunnel is connecting traffic. This tunnel ID is then created into a unique public hostname in the Cloudflare-owned domain of cfargotunnel.com which results in a DNS A record being created that points directly to that service, I.E. d74b3a46-f3a3-4596-9049-da7e72c876f5.cfargotunnel.com. While this hostname is public it can only be accessed or utilized by traffic that is sent through the account that owns the Cloudflare Tunnel configuration. No other accounts would be able to access or send traffic directly to this DNS address. A DNS CNAME record created outside of the account that owns the cfargotunnel.com hostname will not be able to send traffic through that specificCloudflare Tunnel.\n\nWhen configured via the Dashboard, Cloudflare automatically creates a CNAME record in the DNS zone that refers to the cfargotunnel.com hostname. For example, a CNAME record of myTunnelService.example.com could be created to point the A record of d74b3a46-f3a3-4596-9049-da7e72c876f5.cfargotunnel.com. The main benefit being the ease of use and administration as the CNAME record is much more suggestive about its purpose and belongs to the customer DNS zone.\n\nAnother option is to create these tunnels and services on the host running cloudflared. This is called a [locally-managed tunnel](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/do-more-with-tunnels/local-management/). When working with locally-managed tunnels, the CNAME entry is not created automatically however, so the organization would have to configure this manually, after the tunnel and service is defined.\n\nFrom a load balancer perspective, it's very important to understand how these tunnels can be used as an endpoint. An endpoint can only be defined by using the cfargotunnel.com hostname. Using a public CNAME record that points to the cfargotunnel.com address will not work properly and is not supported. This is especially important for endpoint services that donâ€™t operate on ports 80 or 443. Cloudflare Load Balancers default to these two ports to access the services running on the endpoints. If an organization has services running on other ports, they will need to configure a Cloudflare Tunnel with a [catch-all rule](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/do-more-with-tunnels/local-management/configuration-file/#how-traffic-is-matched) to reach that port. This configuration allows a Cloudflare Load Balancer to reach the service via port 443 while having Cloudflare tunnel proxy the connection to the desired port on the endpoint.\n\nThe second method is for private subnets. This method allows organizations to define private IP addresses and a subnet mask which will be used to create a private virtual network within the Cloudflare global network. The private subnet method does not allow the definition of a port and as such, once a subnet and mask are defined, the entire subnet can be reached over that tunnel but only to users within the organization that are allowed access via defined Zero Trust policies.\n\nThis subnet then gets added to the virtual network inside of Cloudflare where the customer can control how users can access it and which users can access it. This subnet can be defined for any desired subnetting or routing, including using a 32-bit mask (single IP address, i.e., 10.0.0.1/32). The allowed subnet does not need to exist on the host that is running the cloudflared process either. All that is required is layer 3 or IP connectivity between the host running cloudflared and the subnet that is going to be reachable over Cloudflare Tunnel.\n\n#### Endpoint pool details\n\nWithin the endpoint pool, there are several configuration options. This section details what these configuration options are and how they alter the behavior of a Cloudflare Load Balancer.\n\n##### Endpoint steering\n\nThe first configuration, besides defining a name and description of the endpoint pool, is to determine the endpoint steering method. Endpoint steering is responsible for ultimately selecting the endpoint or endpoint that will receive the request or connection attempt (please refer to the [Steering methods](#steering-methods) section for a detailed description of each method).\n\nIndividual endpoints are defined within endpoint pools, and the endpoint pool allows for one or more endpoints to be defined per pool.\n\n* The *endpoint name* is primarily used for reference, reporting, and analytics; it does not affect the function of the load balancer or endpoint pool.\n\n* The *endpoint address*, however, defines a resource that the load balancer can use to handle a request or connection.\n\n* Endpoints within an endpoint pool must be accessible over port 80 or 443. If the endpoint is not listening on port 80 or 443, then either a proxy service or network port forwarding device needs to be placed in front of the endpoint to map port 80 or 443 to the port that the service is actually listening on.\n  * Another method for mapping ports of endpoints to 80 or 443 is to connect to the endpoint service using [Cloudflare Tunnel](#cloudflare-tunnel), and then use the hostname created through that process as the endpoint address. This will automatically map the intended endpoint port to port 443.\n\n*Endpoint address* can be defined in one of the following ways:\n\n* Publicly routable IP address\n* Cloudflare-proxied publicly reachable hostname\n* Publicly reachable non-Cloudflare hostname\n* Private, non-publicly routable IP address with the selection of a virtual network\n\n##### Virtual networks\n\nUsing public IPs and hostnames of any type require no additional configuration. In those scenarios, the virtual network should be set to the default value of â€œ*none*â€. The â€œ*none*â€ setting signals that these resources will be accessible on the public Internet, routed via Cloudflareâ€™s global edge network.\n\nThe use of the *virtual network* option is reserved for private IP resources. This setting maps to IP subnets that are hosted behind [Cloudflare Tunnel configurations](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/configure-tunnels/). A virtual network should be selected that has a route to the IP address of the endpoint. To navigate to this setting in the Cloudflare Dashboard, select *Networks - Routes* from the Zero Trust page.\n\n##### Endpoint weight\n\n*Endpoint weight* is only used for the random, hash, and least outstanding request steering methods; it must always be defined as part of the endpoint definition. (Please refer to the [Weighted Steering](#weighted-steering) section for more information on how weights are used for endpoint selection.)\n\n##### Host header modification\n\nEndpoint pools allow for the host header to be modified before dispatching a request to an endpoint. This configuration only applies to the HTTP(S) layer 7 load balancer (it will be ignored when used with layer 4 load balancers, including private IP and Spectrum).\n\nWithin a layer 7 load balancer where requests are HTTP(S)-based, the Host header tells the endpoint which website is being requested, as a single endpoint may host several different web domains. When an endpoint is specifically configured to host a web domain, it may either not respond or send a failure response to a request for a resource, if it does not believe it is hosting the resource requested in the Host header (i.e., if there are mismatched Host headers).\n\n* Say a user tries to reach `www.example.com`. The load balancer will be configured with the hostname of `www.example.com`to receive all the requests.\n* Since the endpoints canâ€™t have the same public hostname in DNS, its hostname is `endpoint1.example.com`.\n* When the user makes a request to `www.example.com,` the Host header will be set to` www.example.com,` as well. The endpoint will need to be configured to respond to Host headers of `www.example.com`.\n* In some cases (such as with certain cloud or SaaS applications), however, endpoints arenâ€™t configurable in that manner, so the endpoint may receive a request with an unknown Host header and fail to respond appropriately.\n* In this example, in the endpoint configuration, setting the Host header for the endpoint to the endpoint address of `endpoint1.example.com` will replace the Host header of `www.example.com` with `endpoint1.example.com`, and will allow the endpoint to properly respond to this request.\n\nFigure 21 highlights the potential problem of mismatched Host headers:\n\n![Mismatched Host headers may result in the endpoint rejecting the request](https://developers.cloudflare.com/_astro/lb-ref-arch-21.Bs0qP_r-_Z2k4TJ6.svg)\n\nAlso, at the endpoint pool, GPS coordinates for the pool (which are used with proximity traffic steering) can be defined. If proximity steering is not being used, then these coordinates are not required (please refer to the [Proximity Steering](#proximity-steering)).\n\n[Load shedding](https://developers.cloudflare.com/load-balancing/additional-options/load-shedding/) â€” a real-time response available to administrators to protect against endpoints in a pool that are [becoming unhealthy ](https://developers.cloudflare.com/load-balancing/understand-basics/health-details/)â€” is also configured on the endpoint pool.\n\nThe load shedding setting is not intended to be enabled unless an administrator is trying to actively protect an endpoint pool from becoming unhealthy. It is activated, for example, when an endpoint that is still responding to requests is experiencing increased CPU or memory usage, increased response times, or occasionally failing to respond at all.\n\nWhen an endpoint poolâ€™s health begins to degrade, load shedding can help direct some of the existing loads from one endpoint pool to another.\n\nDepending on the health of the endpoint pool, it may be enough to simply shed or redirect new requests and connections away from the endpoint pool. This policy applies to traffic, which is not subject to any session affinity rules since these are new connections that havenâ€™t had an endpoint pool or endpoint selected yet (and, therefore, will not potentially affect the end user experience).\n\nShould an endpoint pool approach critical failure due to load, the next option is to shed additional session affinity traffic. This will start to redirect requests and connections that are bound to endpoint pools through session affinity as well. However, please note that because this process can ultimately change the userâ€™s endpoint, it could impact the end userâ€™s experience. Ultimately, the impact is determined by the application that is being load balanced, and how much connection context is shared between endpoints.\n\n##### Health monitors\n\nHealth monitors are attached to endpoints at the endpoint pool as well as health threshold and the health check region selection. Details of these options can be found in the [health monitor](#health-monitors) section.\n\nLoad balancing within Cloudflare combines both GTM and Private Network Load Balancing into a single load balancer configuration. While certain features or terms may align more with GTM or Private Network Load Balancing, for Cloudflare customers, both are combined into a single, easy-to-manage instance.\n\nDepending on their specific use case, organizations can leverage different types of Cloudflare Load Balancers. The following section highlights the main differences between the deployment models, and articulates when each type of load balancer should be implemented.\n\nFigure 22 highlights all the possible combinations of load balancers and endpoints supported by Cloudflare:\n\n![All the possible combinations of load balancer and endpoint types](https://developers.cloudflare.com/_astro/lb-ref-arch-22-ALT.DPr9OdxY_1NmnXS.svg)\n\n#### Deployment models\n\nCloudflare offers three load balancing deployment models, each of which support different use cases, functionality, and privacy requirements.\n\n* [Layer 7 HTTP(S) load balancing](#layer-7-https-load-balancing)\n* [DNS-only load balancing](#dns-only-load-balancing)\n* [Spectrum load balancing](#spectrum-load-balancing)\n\nExcept for the DNS-only load balancing option described in more detail below, all of the deployment models anchor traffic through the load balancer. This means the user or client creating the request or connection is never aware of the endpoints that are being used to service the request or connection. Endpoint information can certainly be exposed â€” if desired â€” through the use of headers, but this is not default behavior for any of these anchored deployment models.\n\nThe following explores the four main deployment models (and their differences) in more detail.\n\n##### Layer 7 HTTP(S) load balancing\n\nFirst, the most common model is the **HTTP(S)-based layer 7 proxied load balancer**. These load balancers exist on Cloudflareâ€™s edge and are publicly reachable. Amongst other features, this model supports [WebSockets](https://developers.cloudflare.com/network/websockets/), which are open connections between the client and endpoint allowing for data to be passed back and forth between the two.\n\nBecause this same layer 7 security stack also provides WAF, DDoS protection, Bot Management, Zero Trust, and other services, accessing these public load balancers can be restricted to authenticated and authorized users as needed. (Please refer to [Securing Load Balancers](#protecting-and-securing-load-balancers) for more information.)\n\nIn this layer 7 stack, load balancing can further improve the performance, reliability, and reachability of an organizationâ€™s public-facing web assets. The endpoints for these load balancers may be deployed in public cloud, private cloud, on-premises, or any combination thereof within the same load balancer. (Please refer to [Connecting endpoints to Cloudflare](#connecting-endpoints-to-cloudflare) for more details about how to connect endpoints to Cloudflareâ€™s edge network).\n\n![Layer 7 load balancing request flow to two different types of endpoints](https://developers.cloudflare.com/_astro/lb-ref-arch-23-ALT.DRZo2XIF_1NmnXS.svg)\n\nAs illustrated in Figure 23 above, the load balancing component of the layer 7 stack is the last process run on a request as it moves towards the endpoint. This can have a large positive impact on increasing performance and reducing load on endpoints.\n\nFor example, caching can prevent requests from ever reaching the endpoint and can be responded to without ever having to engage the load balancers. Also, WAF, DDoS protection, and Bot Management can eliminate attack traffic altogether â€” leaving more capacity for legitimate traffic.\n\nOnce a request reaches the load balancer process, the request is always sent directly to the endpoint that was selected. This means that even if the endpoint is proxied through Cloudflare, the request will be sent directly to the endpoint and receives no further processing.\n\nFor customized treatment after the load balancer selects an endpoint, the load balancerâ€™s Custom Rules are applied. (This is covered in detail in the [Load balancers](#load-balancers) section below).\n\n**Important notes about Layer 7 HTTP(S) load balancers:**\n\n* Layer 7 HTTP(S) load balancers support both public and private endpoints\n* Layer 7 HTTP(S) load balancers will only support HTTP(S) and WebSocket traffic\n* Zero trust policies can be applied to Layer 7 HTTP(S) load balancers\n\n##### DNS-only load balancing\n\nCloudflareâ€™s DNS-only load balancer is an unproxied load balancer. This means that only the initial DNS request for the resource â€” not the actual traffic â€” passes through the Cloudflare edge. Therefore, instead of a DNS request resolving to a Cloudflare IP and then moving through the layer 7 stack as seen earlier in Figure 7, Cloudflare receives a DNS request for a DNS-only load balancer, applies all the appropriate load balancing policies, then returns an IP address to the requesting client to reach out directly.\n\nBecause all the traffic between the client and the endpoint will travel directly between the two and not through Cloudflareâ€™s layer 7 stack, any type of IP traffic can be supported by a DNS-only load balancer.\n\n![The orange cloud icon represents a proxied Layer 7 Cloudflare Load Balancer](https://developers.cloudflare.com/_astro/lb-ref-arch-24.Bw_izDOL_2nwuob.webp)\n\n![The gray cloud icon represents an unproxied (DNS-only) load balancer](https://developers.cloudflare.com/_astro/lb-ref-arch-25.Dz4ThM-k_Z1j5Aba.webp)\n\nEven though Cloudflare does not proxy these types of load balancer connections, the health monitor service is still monitoring the health on all the endpoints in the pool. Based on the health or availability of an endpoint, a Cloudflare DNS-only load balancer will either add or remove an applicable endpoint to a DNS response to ensure that traffic is being steered to healthy endpoints.\n\n![DNS-only load balancers only use Cloudflare to respond to a DNS request](https://developers.cloudflare.com/_astro/lb-ref-arch-26.BB1TuXz__i3C3S.svg)\n\nAfter a DNS-only load balancer has selected an endpoint pool via traffic steering, one or many IP addresses may be returned in the DNS response.\n\nThe decision to send one or many IP addresses within the DNS response is based on the weight assigned to the endpoints within the selected endpoint pool:\n\n* If all the weights are equal across all endpoints, all IP addresses of all the endpoints will be returned in DNS response.\n* If at least one endpoint is specified with a unique weight within the endpoint pool, then only a single IP address will be returned in the DNS response â€” regardless of the endpoint steering method selected on the endpoint pool.\n\nThis gives organizations the flexibility to allow applications to be aware of all the endpoints and perform local failover, or to allow Cloudflare to provide a single IP for an application to utilize.\n\nFigure 27 shows how the defined weight within an endpoint pool can affect how a DNS-only load balancer responds.\n\n![DNS-only load balancers can respond to DNS requests with one or many IP addresses](https://developers.cloudflare.com/_astro/lb-ref-arch-27.CJr7dL0T_17dOG.svg)\n\nPlease note that DNS-only load balancers have a few limitations compared to proxied load balancers:\n\n* The load balancer no longer hides the endpointâ€™s IP address from the client as it is sent back to the client directly.\n* They do not have the built-in layer 7 stack services mentioned in the previous model; i.e., DNS-only load balancers do not include caching, WAF, DDoS protection, or Zero Trust support.\n* Session affinity is limited to `ip_cookie`, which will select an endpoint deterministically and then map that endpoint to the client IP address for all subsequent requests.\n* Finally, because connections are not proxied through the load balancer for DNS only, certain steering methods will not work either. For example, [LORS](#least-outstanding-requests-steering-lors) will not work since Cloudflare will not be aware of the connections to the endpoints. These steering methods will revert to random weighted steering.\n\nFor more information on additional steering methods, please refer to the [Steering](#steering) section.\n\nThere are also client and resolver DNS cache considerations when using DNS-only load balancers. The cache life is determined by the DNS server answering the request. The [Time-to-Live (TTL)](https://www.cloudflare.com/learning/cdn/glossary/time-to-live-ttl/) value tells a DNS requester how long the response is valid before the client should send a new DNS request to see if the destination has changed. The TTL is calculated in seconds, so â€” for example â€” a TTL value of 3600 equates to a TTL of one hour. However, standard DNS TTL values are usually either 12 or 24 hours or 43200 and 86400 respectively.\n\nThe TTL of a DNS-only load balancer is set to 30 (seconds). This ensures that as endpoint health changes or endpoints are added or deleted, the DNS-only load balancer is queried more often to provide the most accurate list of available endpoints possible.\n\n**Important notes about DNS-only load balancers:**\n\n* DNS-only load balancers support only public endpoints\n* DNS-only load balancers do not proxy traffic â€” and â€” as such, are not involved in the connections to endpoint\n* DNS-only load balancers only respond to a DNS request with an IP address or set of IP addresses\n\n##### Spectrum load balancing\n\nCloudflare also offers another ingress method via the [Spectrum](https://developers.cloudflare.com/spectrum/) product.\n\nWhere the layer 7 stack only supported HTTP(S) and WebSockets, Spectrum offers support for any TCP- or UDP-based protocol. A Cloudflare Load Balancer using Spectrum as an ingress for traffic operates at layer 4, where both TCP and UDP protocols exist. Any service that utilizes TCP or UDP for transport can leverage Spectrum with a Cloudflare Load Balancer including SSH, FTP, NTP, SMTP, and more.\n\nGiven the breadth of services and protocols this represents, the treatment provided is more generalized than what is offered with the layer 7 HTTP(S) stack. For example, Cloudflare Spectrum supports features such as TLS/SSL offloading, DDoS protection, IP Access lists, Argo Smart Routing, and session persistence with our layer 4 load balancers.\n\n![Spectrum-based load balancing supports public endpoints](https://developers.cloudflare.com/_astro/lb-ref-arch-28-ALT.Dwf-s8s__1NmnXS.svg)\n\nCloudflare layer 4 Spectrum load balancers are publicly accessible. Access to these load balancing resources can be managed using a Spectrum configuration called *IP Access Rules,* which can be defined as part of a WAF configuration, but are limited to rules created with the â€œallowâ€ or â€œblockâ€ action for specific IP addresses, subnets, countries, or [Border Gateway Protocol (BGP)](https://www.cloudflare.com/learning/security/glossary/what-is-bgp/) Autonomous System Numbers (ASNs).\n\nIn addition to being public, Spectrum load balancers are always proxied. The proxy setting shown earlier (Figures 24 and 25) will be ignored when Spectrum is configured as the ingress path for the load balancer. All traffic destined for Spectrum-based load balancers will always pass through the Cloudflare edge.\n\n**Important notes about Spectrum load balancers:**\n\n* Spectrum load balancers support both public and private endpoints\n* Spectrum load balancers are initially created as Layer 7 HTTP(S) load balancers. A Spectrum application is then created with a Load Balancer endpoint type, and the load balancer that has already been created is selected.\n* Spectrum load balancers are always proxied, regardless of the proxy setting on the load balancer configuration\n* There is no ability to change the ingress port from the Internet via Spectrum to the endpoint; i.e., if the traffic comes in on port 22 to Spectrum, it will be steered to port 22 on the endpoint\n* Spectrum load balancers only support session affinity using the hash endpoint steering method\n* Spectrum load balancers do not support Custom Rules\n\n##### Deployment models at-a-glance\n\n| Load Balancer Model | Public | Proxied | OSI Layer | Traffic Type |\n| - | - | - | - | - |\n| Layer 7 HTTP(S) | X | X | 7 | HTTP(S) |\n| DNS-Only | X | | 7 (DNS) | IP-Based |\n| Spectrum | X | X | 4 | TCP/UDP |\n\n#### Load balancer details\n\nThe hostname setting is the publicly-reachable hostname for the load balancer. The hostname must be created within the zone for which the load balancer is being created.\n\nThe proxy setting determines whether Cloudflare will proxy traffic for the load balancer or simply provide a DNS reply with the endpoints for the client to directly connect. This is covered in detail in the [Deployment models](#deployment-models) section.\n\n##### Session affinity\n\nSession affinity, also known as session persistence or sticky sessions, keeps a client connected to the same endpoint for all subsequent requests after the first request or connection. This can be an important feature for applications that donâ€™t share session data â€” the context of a userâ€™s interaction with a web application â€” between endpoints. For example, if a new endpoint were selected in the middle of a client session and information about the session (e.g. the contents of a userâ€™s shopping cart) were lost, the user experience for that application would be poor.\n\nCloudflare offers three methods for enabling session affinity:\n\n1. **By Cloudflare cookie only (cookie):** On the first request to a proxied load balancer, a cookie is generated, encoding information of which endpoint the request will be forwarded to. Subsequent requests (by the same client to the same load balancer) will be sent to the endpoint that the cookie encodes for a) the duration of the cookie and b) as long as the endpoint remains healthy. If the cookie has expired or the endpoint is unhealthy, a new endpoint will be calculated and used.\n2. **By Cloudflare cookie and Client IP fallback (ip\\_cookie):** This behaves similar to the cookie method above, except that the cookie is generated based on the client IP address. In this case, requests from the same IP address always get steered towards the same endpoint for a) the duration of the cookie and b) as long as the endpoint remains healthy. If the cookie has expired or the endpoint is unhealthy, a new endpoint will be calculated and used.\n3. **By HTTP header (header):** On the first request to a proxied load balancer, a session key is generated based on the configured HTTP headers. Subsequent requests to the load balancer with the same headers will be sent to the same endpoint, for a) the duration of the session or b) as long as the endpoint remains healthy. If the session has been idle for the duration of session affinity time-to-live (TTL) seconds or the endpoint is unhealthy, then a new endpoint will be calculated and used.\n\nThese three session affinity options only apply to layer 7 HTTP(S) load balancers. Session affinity requires a TTL, which determines how long the load balancer will route subsequent requests to a specific endpoint. The default TTL is 82,800 seconds (23 hours), but it can be set for anywhere from 1,800 seconds (30 minutes) to 604,800 seconds (seven days).\n\nFor cookie-based session affinity, the expiration timer is never reset, meaning that the timer is counting down from the start of the session â€” regardless of the session being idle or active. HTTP header-based session affinity will reset the expiration timer every time there is activity in the session.\n\n##### Endpoint draining\n\nEndpoint draining is a subfeature of session affinity. It allows for sessions to gracefully expire from an endpoint while not allowing new sessions to be created on that same endpoint. Endpoint draining is useful for maintenance, as it does not require administrators to arbitrarily or abruptly cut off user sessions in order to remove all active sessions from an endpoint.\n\nThe endpoint drain TTL is the amount of time that endpoints will be allowed to maintain active sessions before being forcefully terminated. Once the endpoint drain TTL is set, endpoint draining is started by disabling an endpoint (or multiple endpoints) within an endpoint pool. As seen in the below image, administrators can monitor the time remaining on an endpoint drawing operation from the load balancer UI.\n\n![Endpoint draining in process from web user interface](https://developers.cloudflare.com/_astro/lb-ref-arch-30.todYN9Ax_Z1UWTmb.webp)\n\nEndpoint draining is only applicable for session affinity because without session affinity, subsequent requests or connections are not guaranteed to be steered to the same endpoint. Thus, disabling an endpoint does not have an impact on user experience.\n\n##### Zero-downtime failover\n\nZero-downtime failover automatically sends traffic to endpoints within an endpoint pool during transient network issues.\n\nZero-downtime failover will trigger a single retry only if there is another healthy endpoint in the pool and a [521, 522, 523, 525 or 526 error code](https://developers.cloudflare.com/support/troubleshooting/http-status-codes/cloudflare-5xx-errors/error-521/) is occurring. No other error codes will trigger a zero-downtime failover operation.\n\nThese response codes are not returned from the endpoint, but from requests made by upstream Cloudflare services to an organization's endpoints.\n\nZero-downtime failover has three modes of operation:\n\n1. **None (Off):** No failover will take place and users may receive error messages or a poor user experience.\n2. **Temporary:** Traffic will be sent to other endpoint(s) until the endpointal endpoint is available again.\n3. **Sticky:** The session affinity cookie is updated and subsequent requests are sent to the new endpoint moving forward as needed. This is not supported when session affinity is using HTTP header mode.\n\n##### Adaptive routing - failover across pools\n\n*Adaptive routing - failover across pools* extends the functionality of zero-downtime failover by allowing failover to extend to endpoints in another endpoint pool, rather than only failing over to an endpoint in the *same* pool.\n\nEndpoint pools are configured in a priority order and can be rearranged as needed. This priority order is only considered when using *Off - Failover traffic steering;* otherwise, endpoint pools will be selected based on the criteria outlined in the [Steering methods](#steering-methods) section.\n\nThe endpoint pools assigned to a load balancer represent the entire collection of endpoints that could possibly handle requests or connections through the load balancer. An endpoint pool typically contains endpoints that all have the same capabilities and are in the data center or geographic region. All endpoints in a pool should be capable of handling any request directed to an endpoint pool. For more information about endpoint pools, please refer to the [Endpoint pools](#endpoint-pools) section.\n\nA fallback pool is the pool of last resort. When all endpoint pools are unavailable or unhealthy, the fallback pool will be used for all requests and connections. While health monitor data is always considered when steering traffic within a load balancer, a fallback pool does not rely on this data and is not subject to it.\n\n##### Health monitors\n\nHealth monitors are usually configured as part of the endpoint pool. Health monitors can be added, changed, or deleted as part of the load balancer configuration. Please see the [Health monitors](#health-monitors) section for more information.\n\n##### Traffic steering\n\nTraffic steering is the method of steering between endpoint pools. For help understanding which traffic steering method to select, please see the [Steering types and methods](#steering-types-and-methods) section.\n\n[Custom rules](https://developers.cloudflare.com/load-balancing/additional-options/load-balancing-rules/) allow users to perform actions on requests or connections before the load balancer finishes its decision process. Custom rules are configured with expressions that match certain [fields](https://developers.cloudflare.com/load-balancing/additional-options/load-balancing-rules/reference/) in requests or connections. Once the expression is created to match traffic, an [action](https://developers.cloudflare.com/load-balancing/additional-options/load-balancing-rules/actions/) is assigned for when a request or connection matches the expression.\n\nCustom rules are a powerful tool for customizing the steering and output from a load balancer before the request or connection is sent to the endpoint. For example, the HTTP method (e.g. GET, PUT, POST) could be matched to ensure that POST messages are sent to a specific endpoint pool dedicated to handling receiving information from clients.\n\nAlternatively, that session affinity TTL could be reset based on a request going to a specific URL path to ensure that the client has enough time to complete the transaction.\n\nIt is not possible to document all of the potential combinations of fields that can be matched and actions that can be taken. However, the following resources describe all of the fields and actions that are currently available:\n\n* [Supported fields and operators](https://developers.cloudflare.com/load-balancing/additional-options/load-balancing-rules/reference/)\n* [Load Balancing actions](https://developers.cloudflare.com/load-balancing/additional-options/load-balancing-rules/actions/)\n\nIf the default behavior of a load balancer is not covered in the documents listed above, it is likely that a custom rule can help meet unique use case requirements.\n\n### Protecting and securing load balancers\n\n#### Inherent security\n\nAll Cloudflare Load Balancer deployment models come with inherent protections. The following section briefly highlights the default security Cloudflare provides, as well as optional protections that can be added in front of Cloudflare Load Balancers:\n\n* Proxied HTTP layer 7 load balancer (Public)\n\n* [DDoS protection](https://developers.cloudflare.com/ddos-protection/managed-rulesets/http/) to protect against attacks\n  * WAF with [Cloudflare managed ruleset](https://developers.cloudflare.com/waf/managed-rules/reference/cloudflare-managed-ruleset/) and [OWASP ruleset](https://developers.cloudflare.com/waf/managed-rules/reference/owasp-core-ruleset/) to block known vulnerabilities and exploits\n\n* DNS-only load balancer (Public)\n  * [DNS DDoS protection](https://www.cloudflare.com/learning/cdn/glossary/anycast-network/) to ensure a DNS-only load balancer is always available\n\n* Spectrum layer 4 load balancer (Public)\n  * [DDoS Protection](https://developers.cloudflare.com/spectrum/about/ddos-for-spectrum/) to protect against layer 4 attacks\n\n#### Additional options\n\nCloudflare offers additional security layers that can be used in conjunction with load balancing to protect any services â€” including websites, APIs, HTTP(S)-based services, and more:\n\n* Proxied HTTP layer 7 load balancer (Public)\n\n* [Bot management](https://developers.cloudflare.com/bots/) to control which bots can access resources\n  * [WAF](https://developers.cloudflare.com/waf/) for creating custom rules for web applications\n  * [Page Shield](https://developers.cloudflare.com/page-shield/) for monitoring script usage on web applications\n  * [API Shield](https://developers.cloudflare.com/api-shield/) for protecting APIs\n\n* DNS-only load balancer (Public)\n  * [DNSSEC](https://developers.cloudflare.com/dns/dnssec/) to ensure authenticity of DNS records\n\n* Spectrum layer 4 load balancer (Public)\n  * [IP Access Rules](https://developers.cloudflare.com/spectrum/reference/configuration-options/#ip-access-rules) for controlling access to public layer 4 load balancers\n\nThe Cloudflare global anycast network is a powerful platform for load balancing. A load balancing configuration in Cloudflare is accessible in over 330 cities across the world and has virtually unlimited capacity and bandwidth.\n\nThese load balancers operate within approximately 50ms of about 95% of the Internet-connected population, including endpoints that allow Cloudflare Load Balancers to perform both GTM and Private Network Load Balancing. Cloudflare now combines these two distinct load balancing concepts into a single load balancer. This helps enable organizations to steer traffic to geographically-relevant data centers, then select the proper endpoint to handle the request.\n\nWith Cloudflare Tunnel, endpoints can be located within private networks and still be utilized by Cloudflare Load Balancers. Cloudflare offers public layer 7 load balancers â€” that supports both HTTP(S) and WebSockets, as well as public layer 4 load balancers that can steer any TCP or UDP traffic. This means that Cloudflare can offer load balancing services to all organizations and users, no matter their location, use cases, or existing configurations.\n\n<page>\n---\ntitle: Magic Transit Reference Architecture Â· Cloudflare Reference Architecture docs\ndescription: This reference architecture describes the key architecture,\n  functionalities, and network deployment options of Cloudflare Magic Transit.\nlastUpdated: 2025-10-13T13:40:40.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/reference-architecture/architectures/magic-transit/\n  md: https://developers.cloudflare.com/reference-architecture/architectures/magic-transit/index.md\n---\n\nThe purpose of this document is to describe the key architecture, functionalities, and network deployment options of [Cloudflare Magic Transit](https://developers.cloudflare.com/magic-transit/) â€” a BGP-based DDoS protection and traffic acceleration service for Internet-facing network infrastructure.\n\n### Who is this document for and what will you learn?\n\nThis reference architecture is designed for IT or network professionals with some responsibility over or familiarity with their organization's existing network infrastructure. It is useful to have some experience with technologies and concepts important to content delivery, including routers, DNS and firewalls.\n\nTo build a stronger baseline understanding of Cloudflare, we recommend the following resources:\n\n* What is Cloudflare? | [Website](https://www.cloudflare.com/what-is-cloudflare/) (5 minute read) or [video](https://youtu.be/XHvmX3FhTwU?feature=shared) (2 minutes)\n\n- Blog: [Magic Transit makes your network smarter, better, stronger, and cheaper to operate](https://blog.cloudflare.com/magic-transit) (14 minute read)\n\nThose who read this reference architecture will learn:\n\n* How Cloudflare Magic Transit protects your network infrastructure from denial of service attacks (DDoS)\n* How to architecture Magic Transit into your existing network infrastructure\n\n## What Is Magic Transit?\n\nProtecting network infrastructure from DDoS attacks demands a unique combination of strength and speed. Volumetric attacks can easily overwhelm hardware boxes and their bandwidth-constrained Internet links. And most cloud-based solutions redirect traffic to centralized scrubbing centers, which impacts network performance significantly.\n\nCloudflare Magic Transit provides DDoS protection and traffic acceleration for on-premise, cloud, and hybrid networks. With data centers spanning [hundreds of cities](https://www.cloudflare.com/network/) and offering hundreds of Tbps in mitigation capacity, Magic Transit can detect and mitigate attacks close to their source of origin in under three seconds globally on average â€” all while routing traffic faster than the public Internet.\n\n![Figure 1: Magic transit overview](https://developers.cloudflare.com/_astro/magic-transit-ref-arch-1.BqSmsUYf_Z1CXccO.webp)\n\nAt a high level, Magic Transit works as follows:\n\n* **Connect:** Using Border Gateway Protocol (BGP) route announcements to the Internet, and the Cloudflare anycast network, customer traffic is ingested at a Cloudflare data center closest to the source.\n\n* **Protect and Process:** All customer traffic is inspected for attacks. Advanced and automated mitigation techniques are applied immediately upon detecting an attack. Additional functions such as load balancing, next-generation firewall, content caching, and serverless compute are also available as a service.\n\n* **Accelerate:** Clean traffic is routed over Cloudflareâ€™s low-latency network links for optimal throughput and handed off over IP tunnels (either GRE or IPsec) or private network interconnects (PNI) to the origin network. Magic Transit uses anycast IP addresses for Cloudflareâ€™s tunnel endpoints, meaning that any server in any data center is capable of encapsulating and decapsulating packets for the same tunnel. For more details specifically on tunnels and encapsulation, refer to [GRE and IPsec tunnels](https://developers.cloudflare.com/magic-transit/reference/gre-ipsec-tunnels/).\n\n### Baking resilience into our network using anycast\n\nMagic Transit uses anycast IP addresses for its end of the network tunnel endpoints â€” so a single tunnel configured from a customerâ€™s network to Cloudflare connects to all Cloudflare global data centers (excluding the [China Network](https://developers.cloudflare.com/china-network/)). This does not add strain on the router; from the routerâ€™s perspective, it is a single tunnel to a single IP endpoint.\n\nThis works because while the tunnel endpoint is technically bound to an IP address, it need not be bound to a specific device. Any device that can strip off the outer headers and then route the inner packet can handle any packet sent over the tunnel.\n\nIn the event of a network outage or other issues, tunnels fail over automatically â€” with no impact to a customerâ€™s network performance.\n\n## Deployment Architectures for Magic Transit\n\n### Default Configuration (Ingress Only, Direct Server Return)\n\nBy default, Magic Transit processes traffic in the ingress direction only (from the Internet to the customer network). The server return traffic back to the clients is routed by the customer's DC edge router via its uplinks to the Internet/ISP based on the edge routerâ€™s default routing table. This server return traffic will not transit through Cloudflare via tunnels. This is referred to as Direct Server Return (DSR).\n\nThe network diagram in Figure 2 illustrates such a Magic Transit setup, and the end-to-end packet flow of Magic Transit-protected traffic. The tunnel in this setup uses GRE for encapsulation.\n\n![Figure 2: Reference Configuration of Magic Transit anycast Tunnel (GRE) With Default DSR Option](https://developers.cloudflare.com/_astro/magic-transit-ref-arch-2.XvKY3pME_Z2GoNl.webp)\n\n* Cloudflare provides the customer with a pair of anycast IP addresses for the Cloudflare end of the tunnel endpoints. These are publicly routable IP addresses from Cloudflare-owned address space. The pair of anycast IP addresses can be used to configure two tunnels for network redundancy, although only one is required for a basic configuration. The above configuration shows a single tunnel, with the Cloudflare end of the tunnel endpoint address being 192.0.2.1.\n\n* The customer end of the anycast GRE tunnel needs to be a publicly routable address. It is typically the IP address of the WAN interface on the customer edge router. In this example it is 192.0.2.153.\n\n* The IP addresses of the tunnel interfaces are RFC 1918 private addresses. These addresses are only \"locally significant\" within the particular Magic Transit service instance that they are part of. Therefore, the customer can select any RFC 1918 addresses they desire, as long as they do not overlap with those of other tunnels configured within the same Magic Transit service instance.\n\n* As best practice, given the tunnels are point-to-point connections, a /31 subnet is sufficient for allocating the 2 IP addresses required for a given tunnel. In the above example, the 10.10.10.0/31 subnet is chosen, with the Cloudflare end of the tunnel interface being 10.10.10.0/31 and the customer's DC edge router side being 10.10.10.1/31.\n\n* Once the tunnel is configured, a route is configured in the Magic Transit service instance to forward traffic destined to a given customer prefix onto the correct tunnel.\n\n* Traffic destined to customer prefix 203.0.113.0/24 is routed onto the tunnel whose remote end (i.e. the customerâ€™s end, from the Cloudflare network's perspective) of the tunnel interface is 10.10.10.1.\n\n* Given this is a Direct Server Return (DSR) setup, the server return traffic follows the default route (ip route 0/0) configured on the customer edge router and is sent to its uplink peer (i.e. customerâ€™s ISP's router), en route back to the clients over the Internet. This return traffic does not traverse Cloudflare network.\n\n**Note:** The smallest IP prefix size (i.e. with the longest IP subnet mask) that most ISPs accept in each other's BGP advertisements is /24; e.g. x.x.x.0/24 or y.y.y.0/23 are okay, but z.z.z.0/25 is not. Therefore, the smallest IP prefix size Cloudflare Magic Transit can advertise on behalf of the customers is /24.\n\n### Magic Transit With Egress Option Enabled\n\nWhen Magic Transit is deployed with the Egress option enabled, egress traffic from the customer's network flows over the Cloudflare network as well. This deployment option provides symmetry to the traffic flow, where both client-to-server and server-return traffic flow through the Cloudflare network. This implementation provides added security and reliability to the server-return traffic, as afforded by the Cloudflare network.\n\nThe following network diagram illustrates the end-to-end packet flow between the end client and customer network when the Magic Transit Egress option is enabled.\n\n![Figure 3: Magic Transit With Egress Option Enabled](https://developers.cloudflare.com/_astro/magic-transit-ref-arch-3._h1mIh77_r8Xu4.webp)\n\n* The ingress traffic flow is the same as in the Default Configuration use case above.\n\n* For egress traffic to be received and processed by Magic Transit, the source IP addresses of the traffic need to be in the range of the Magic Transit-protected IP prefixes, and the destination IP addresses need to be public Internet routable, i.e. non-RFC 1918 addresses.\n\nIt is worth noting that for customers who bring their own public IP addresses ([BYOIP](https://developers.cloudflare.com/byoip/)) for cloud-hosted services, the Magic Transit Egress option can provide additional value by eliminating the need for them to purchase and implement BYOIP services with their cloud providers, reducing their cloud bill and lowering operational costs.\n\nTo accomplish this, the IP tunnels that on-ramps to Magic Transit are configured between the cloud providers' VPCs and the Cloudflare network. With the Magic Transit Egress option, both directions of client-server traffic would flow through these tunnels. The BYOIP addresses in the tunneled packets are hidden behind the outer tunnel endpoint IP addresses and the tunnel header, making them \"invisible\" to the underlying cloud provider network elements between the VPCs and the Cloudflare network.\n\n### Magic Transit Over Cloudflare Network Interconnect (CNI)\n\n[Cloudflare Network Interconnect (CNI)](https://developers.cloudflare.com/network-interconnect/) allows customers to connect their network infrastructure directly to Cloudflare â€“ bypassing the public Internet â€“ for a more reliable, performant, and secure experience.\n\n* CNI is provisioned by the cross-connect providers as a set of layer 2 connections, and Cloudflare allocates a pair of IP addresses from Cloudflareâ€™s own Internet-routable IP address block for each connection.\n\n* Cloudflare coordinates with the customer to configure these links and to establish a BGP peering session over the links during CNI onboarding.\n\n* Once the BGP session is up between the Cloudflare network and the customer edge router that are connected via CNI, Cloudflare-owned prefixes will be advertised over this CNI link to the customer edge router.\n\nFigure 4 illustrates a reference configuration for Magic Transit over CNI, and its associated packet flow.\n\n**Note:** The example demonstrated here is for the default Magic Transit service without the Egress option enabled. As described in earlier sections, in Magic Transit Direct Server Return mode (i.e. Ingress only), the server return traffic will be routed by the customer edge router to the clients via their ISP through the public Internet.\n\n![Figure 4: Reference Configuration of Magic Transit Over CNI (Default DSR Option)](https://developers.cloudflare.com/_astro/magic-transit-ref-arch-4.CCh1ixzi_2vP0v3.webp)\n\nWhen the Magic Transit Egress option is enabled and utilized, the server return traffic can be sent back to the clients through the Cloudflare network, via the IP tunnels that are configured over the CNI connections. Figure 5 illustrates one such example.\n\n![Figure 5: Reference Configuration of Magic Transit Over CNI with Egress Option Enabled](https://developers.cloudflare.com/_astro/magic-transit-ref-arch-5.Dru7wSdW_Z1Qcnn2.webp)\n\n### Magic Transit Protecting Public Cloud-Hosted Services\n\nMagic Transit protects services hosted on-premise and in the cloud. This use case illustrates the configuration for a cloud-hosted deployment.\n\n![Figure 6: Protect Multi-Cloud-Based Services With Magic Transit (Egress Option Enabled)](https://developers.cloudflare.com/_astro/magic-transit-ref-arch-6.Cik4bTwC_w3xvf.webp)\n\n* In this example, a given customer has two cloud VPC deployments spread across two different cloud providers, and in two different geographical regions.\n\n* In this example, the customerâ€™s /24 or larger prefix is split into multiple smaller (i.e. longer subnet mask length) prefixes (e.g. /26) and assigned to the various VPCs in different locations. Upon establishing the tunnels from the Cloudflare network to each of the VPCs, the customer can configure routes centrally in the Magic Transit configuration to route traffic to the respective VPCs. Such configuration can be made via API or UI dashboard.\n\nNote that with the Magic Transit Egress option, the customer can bypass each cloud provider's BYOIP services, its associated fees, and the configuration and operations complexity, by sending egress traffic (i.e. server return or server-to-Internet traffic from the protected prefix) through the Cloudflare global network via the Magic Transit tunnels.\n\n### Magic Transit and Magic WAN\n\nIn addition to protecting and routing traffic for external-facing services of an enterprise (i.e. north-south Internet-routable traffic) with the Cloudflare Magic Transit service, customers can protect east-west \"intra-enterprise\" internal traffic (e.g. RFC 1918 private addresses), interconnecting all the sites of an enterprise, using [Cloudflare Magic WAN](https://developers.cloudflare.com/magic-wan/).\n\nMagic WAN replaces legacy WAN architectures with the Cloudflare network, providing global connectivity, cloud-based security, performance, and control through one simple user interface.\n\nThe Cloudflare Magic Transit and Magic WAN services combined provide a holistic, secure, reliable, and performant global network-as-a-service solution for an entire enterprise, protecting and accelerating north-south as well as east-west traffic.\n\nBoth services can either be deployed in the same service instance, or, for customers who prefer to keep the administration and traffic flow of external, Internet-facing networks and internal corporate networks completely separate, different service instances can be deployed for Magic Transit and Magic WAN.\n\nFigure 7 illustrates an example of deploying Magic Transit and Magic WAN services in separate service instances.\n\n![Figure 7: Magic Transit + Magic WAN Provide Network-as-a-Service for the Entire Enterprise](https://developers.cloudflare.com/_astro/magic-transit-ref-arch-7.DESTWgck_1uQaxo.webp)\n\n* In the example, GRE tunnels are used to connect the customer's various sites over the Cloudflare global anycast network. The Cloudflare anycast IP address for the Magic Transit service instance is 192.0.2.1, while the one for the Magic WAN service instance is 192.0.2.2. The Magic Transit service is enabled with the Egress option.\n\n* The Magic Transit service protects and routes external-facing front-end client-server traffic. The Magic WAN service protects and routes enterprise internal traffic such as that of internal applications, back-end database sync, and branch-to-DC and branch-to-branch traffic.\n\n### Magic Firewall: Control and Filter Unwanted Traffic Before It Reaches the Enterprise Network\n\nWhile Magic Transit protects customersâ€™ services from DDoS attacks, many network administrators want to be able to control and block other unwanted or potentially malicious traffic. [Cloudflare Magic Firewall](https://developers.cloudflare.com/magic-firewall/) enforces consistent network security policies across the entire customer WAN, including headquarters, branch offices, and virtual private clouds, and allows customers to deploy fine-grained filtering rules globally in seconds â€” all from a common dashboard.\n\nMagic Firewall is deployed and configured as part of Magic Transit. All ingress traffic flowing through Cloudflare edge data centers, whose destination prefixes are protected by Magic Transit, can be filtered by Magic Firewall.\n\n![Figure 8: Magic Firewall Blocks Unwanted and Malicious Traffic at the Internet Edge](https://developers.cloudflare.com/_astro/magic-transit-ref-arch-8.BRW-6GQa_Za9Jbz.webp)\n\nIn Magic Firewall rules, administrators can match and filter network traffic not only based on the typical 5-tuple (source/destination IP, source/destination port, protocol) information carried in the IP packet header but also other packet information such as IP packet length, IP header length, TTL, etc. In addition, geographical information such as the name of the Cloudflare data center/colo, the region, and the country the data centers are located in can also be used in configuring Magic Firewall rules (geo-blocking).\n\nFor further details on Magic Firewall and its configuration, please refer to this [blog post](https://blog.cloudflare.com/introducing-magic-firewall/) and our [developer docs](https://developers.cloudflare.com/magic-firewall/).\n\n## A Note on Always-On and On-Demand Deployments\n\nA cloud DDoS mitigation service provider can monitor traffic for threats at all times (the always-on deployment model) or reroute traffic only when an attack is detected (on-demand). This decision affects response time and time-to-mitigation. In some cases, it also has repercussions for latency.\n\nIn an on-demand deployment model, inbound traffic is monitored and measured at the network edge to detect volumetric attacks. During normal operations, or \"peacetime,\" all traffic directly reaches applications and infrastructure without any delay or redirection. Traffic is diverted to the cloud scrubbing provider only in the case of an active DDoS attack. In many cases, a customer is required to call the service provider to redirect traffic, thereby increasing the response time.\n\nThe always-on mode is a hands-off approach to DDoS mitigation that does not require the customer to do anything in the event of an attack. The organizationâ€™s traffic is always routed through the cloud providerâ€™s data centers for threat inspection, even during peacetime. This minimizes the time from detection to mitigation, and there is no service interruption.\n\nOf all approaches and deployment options, the always-on method provides the most comprehensive protection.\n\nHowever, depending on the provider, diverting all traffic through the DDoS mitigation providerâ€™s cloud might add latency that is suboptimal for business-critical applications. Cloudflare is architected so that customers do not incur a latency penalty as a result of attacks â€” even for always-on deployments. Analyzing traffic at the edge is the only way to mitigate at scale without impacting performance.\n\nThis is because ingesting traffic via anycast ensures that traffic travels only to the nearest Cloudflare data center for inspection. With data centers in [hundreds of cities worldwide](https://www.cloudflare.com/network/), it is likely to be a short distance. This eliminates the trombone effect.\n\nIn many cases, [traffic is faster when routed over Cloudflare](https://www.cloudflare.com/static/360e550c8890054d5e5835efb9fb8dd1/Magic_Transit_protects_networks_while_also_improving_performance__1_.pdf) than over the public Internet. We believe customers should not have to sacrifice performance to achieve comprehensive security.\n\nCloudflare offers comprehensive network services to connect and protect on-premise, cloud-hosted, and hybrid enterprise networks. Cloudflare provides various connectivity and deployment options to suit customers' unique architectures.\n\n* Cloudflare Magic Transit is a cloud-native network security solution that uses the power of the Cloudflare global network to protect organizations against DDoS attacks.\n\n* Magic Transit comes with a built-in network firewall that helps customers phase out on-premise firewalls and deploy network security as-a-service that scales.\n\n* In addition to protecting and routing traffic for external-facing services of an enterprise (i.e. north-south Internet-routable traffic), customers can connect and protect east-west â€œintra-enterpriseâ€ internal traffic using Cloudflare Magic WAN.\n\nIf you would like to learn more about Magic Transit, Magic WAN, or Magic Firewall, please [reach out](https://www.cloudflare.com/magic-transit/) to us for a demo.\n\n<page>\n---\ntitle: Multi-vendor Application Security and Performance Reference Architecture\n  Â· Cloudflare Reference Architecture docs\ndescription: This reference architecture describes how a multi-vendor approach\n  for application security and performance can be accomplished.\nlastUpdated: 2025-11-19T12:11:06.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/reference-architecture/architectures/multi-vendor/\n  md: https://developers.cloudflare.com/reference-architecture/architectures/multi-vendor/index.md\n---\n\nOver time and with the rapidly evolving application security and performance industries, companies have come to deploy multiple vendors to provide services. Sometimes customers opt for using multiple vendors for reasons of regulatory/company compliance, resiliency, performance, or cost.\n\nAlthough some customers look to implement multi-vendor solutions for various reasons discussed in this document, multi-vendor deployments can introduce additional complexity, higher operational costs due to multiple dashboards and configurations, and a steeper learning curve. Additionally, while trying to establish a baseline of supported features across multiple vendors, customers can end up having a minimum common denominator setup, not taking advantage of the latest capabilities/innovations from a vendor. Customers should carefully consider the goals and requirements, and weigh pros and cons with all stakeholders, before proceeding with a multi-vendor deployment.\n\nThis document examines why some customers deploy a multiple or dual vendor approach and how Cloudflare can be incorporated into such a solution. Specifically, this document describes how a multi-vendor approach for application security and performance can be accomplished. This document is targeted for architects and those interested in using multi-vendor cloud-based solutions for security and performance.\n\n### Who is this document for and what will you learn?\n\nThis reference architecture is designed for IT, security or network professionals with some responsibility over or familiarity with their organizationâ€™s existing network infrastructure. It is useful to have some experience with technologies and concepts important to application security and performance, including proxies, DNS and firewalls.\n\nTo build a stronger baseline understanding of Cloudflare, we recommend the following resources:\n\n* What is Cloudflare? | [Website](https://www.cloudflare.com/what-is-cloudflare/) (5 minute read) or [video](https://youtu.be/XHvmX3FhTwU?feature=shared) (2 minutes)\n\nThose who read this reference architecture will learn:\n\n* How Cloudflare application security and performance capabilities can work alongside existing technology vendors\n* Understanding the decisions to be made when using many vendors\n\n## Cloud based security and performance providers\n\nBefore discussing multi-vendor security and performance solutions, itâ€™s important to note how cloud-based solutions providing these services work in general and how traffic is routed through them.\n\nCloud-based security and performance providers like Cloudflare work as a reverse proxy. A reverse proxy is a server that sits in front of web servers and forwards client requests to those web servers. Reverse proxies are typically implemented to help increase security, performance, and reliability.\n\n![Figure 1: Client request to origin server](https://developers.cloudflare.com/_astro/Figure_1.DmJWHu1Y_Z20GdDb.webp)\n\nNormal traffic flow without a reverse proxy would involve a client sending a DNS lookup request, receiving the origin IP address, and communicating directly to the origin server(s). This is visualized in Figure 1.\n\nWhen a reverse proxy is introduced, the client still sends a DNS lookup request to its resolver, which is the first stop in the DNS lookup. In this case, the DNS resolver returns a vendorâ€™s reverse proxy IP address to the client and the client then makes a request to the vendorâ€™s reverse proxy. The cloud-based proxy solution can now provide additional security, performance, and reliability services like [CDN](https://www.cloudflare.com/cdn/), [WAF](https://www.cloudflare.com/waf/), [DDoS](https://www.cloudflare.com/ddos/), [API Shield](https://www.cloudflare.com/products/api-shield/), [Bot Management](https://www.cloudflare.com/products/bot-management/) capabilities, etc, before deciding, based on security policy, whether to route the client request to the respective origin server(s). This is visualized in Figure 2.\n\n![Figure 2: Client request routed through reverse proxy for additional security and performance services](https://developers.cloudflare.com/_astro/Figure_2.Ca4wC8bv_Z1yo7bq.webp)\n\nIn some cases, the vendor providing the reverse proxy also provides DNS services; this is visualized in Figure 3 below. This can be beneficial for managing all services from a single dashboard and for operational simplicity.\n\n![Figure 3: Same vendor providing DNS and security/performance services via proxy](https://developers.cloudflare.com/_astro/Figure_3.CznC1gz__Z1LcAPc.webp)\n\n## Cloudflareâ€™s reverse proxy architecture and solution\n\nCloudflare provides a reverse proxy architecture using its global [anycast network](https://www.cloudflare.com/learning/cdn/glossary/anycast-network/) for the respective security, performance, and reliability services it provides. Anycast is a network addressing and routing method in which incoming requests can be routed to a variety of different locations or â€˜nodesâ€™ advertising the same IP address space. Cloudflare is extremely performant and reliable thanks to anycast, as well as its global presence in [hundreds of cities worldwide](https://www.cloudflare.com/network/). Cloudflare is also directly connected to 12,000 networks, including every major ISP, cloud provider, and enterprise, and within \\~50 ms from 95% of the worldâ€™s Internet-connected population.\n\nCloudflare has one global network with every service running on every server in every Cloudflare data center. Since Cloudflareâ€™s network uses anycast, the closest data center to the client will respond to the client request. This decreases latency while improving network resiliency, availability, and security due to the increased overall distribution of traffic across Cloudflare's network.\n\n[Cloudflareâ€™s global anycast network](https://www.cloudflare.com/network/) provides the following advantages:\n\n* Incoming traffic is routed to the nearest data center with the capacity to process the requests efficiently.\n* Availability and redundancy is inherently provided. Since multiple nodes advertise the same IP address, if one node were to fail, requests are simply routed to another node in close proximity.\n* Because anycast distributes traffic across multiple data centers, it increases overall distribution of traffic across Cloudflareâ€™s network, preventing any one location from becoming overwhelmed with requests. For this reason, anycast networks are very resilient to DDoS attacks.\n\n![Figure 4: Cloudflare providing DNS and security/performance services via global anycast network](https://developers.cloudflare.com/_astro/Figure_4.BQ6xEEwJ_29Soyq.webp)\n\n## Cloudflare onboarding options\n\nThis section provides a brief overview of the Cloudflare onboarding options which are useful to understand prior to looking into the details around a multi-vendor solution. The method of onboarding allows for variance in how the multi-vendor solution is deployed/configured. If youâ€™re already familiar with the Cloudflare onboarding options, you can jump to the next section discussing multi-vendor solutions.\n\nCloudflare provides multiple options to easily onboard and consume security, performance, and reliability services. One of the advantages of cloud solutions offered via proxy setup is the ease of onboarding and getting started because it primarily involves DNS configuration to route client requests through the proxy. However, even within the onboarding with DNS configuration, Cloudflare offers multiple options and flexibility.\n\nThe core requirement is, traffic must be proxied through Cloudflare; this is also referred to as â€˜orange-clouded,â€™ because the traffic to the site is being proxied through Cloudflare. Within the dashboard, you will see the status for a specific DNS entry as â€˜Proxiedâ€™ and the orange cloud icon as shown in Figure 5 below.\n\n![Figure 5: Cloudflare configured to proxy traffic for site https://api2.cf-tme.com](https://developers.cloudflare.com/_astro/Figure_5.BkWvJnng_Z1gxDtP.webp)\n\nThere are several methods to proxy traffic through Cloudflare and the method used will depend on customer requirements.\n\n**1. Full DNS setup - Cloudflare as primary DNS provider**\n\nCloudflare is configured as the primary DNS provider and A records are configured to proxy traffic through Cloudflare. When the proxy is enabled on a DNS record, the response will be Cloudflare anycast IP addresses allowing for Cloudflare to be the proxy.\n\n**2. Secondary DNS setup with Secondary DNS override**\n\nCloudflare is configured as a secondary provider and all DNS records are transferred from the primary provider. Cloudflare provides a feature called [Secondary DNS override](https://developers.cloudflare.com/dns/zone-setups/zone-transfers/cloudflare-as-secondary/proxy-traffic/) that allows customers to override the response served from Cloudflare secondary nameservers. This allows for customers to take advantage of leveraging zone transfers to automatically sync between DNS providers. It also provides the flexibility to update select records in Cloudflare DNS to redirect certain traffic to another service provider like Cloudflare. In this case, the response will be Cloudflare anycast IP addresses allowing for Cloudflare to be the proxy.\n\n**3. Partial / CNAME setup**\n\nIn this setup, Cloudflare is not the authoritative DNS provider and the customer manages DNS records externally.\n\nConverting to CNAME setup ensures the hostname eventually resolves to Cloudflare IPs. This is useful when customers donâ€™t want to change their current DNS setup but still want to use other Cloudflare services.\n\nIf a customer's current DNS provider doesnâ€™t support CNAME on the zone apex (sometimes called the \"root domain\" or \"naked domain\") like Cloudflare does with [CNAME Flattening](https://developers.cloudflare.com/dns/cname-flattening/), you must purchase Static IPs from Cloudflare and create an A record to those Static IPs in the provider DNS. In Cloudflare, you can then create an A record to point the zone apex to the origin.\n\nMany customers using Cloudflare services take advantage of the cross-product integration and innovations along with simplicity of a single UI for management and operational simplicity and use multiple Cloudflare services together like CDN and WAF. Although not recommended, itâ€™s also possible to use security services like WAF with other CDN providers by setting up DNS to forward traffic through Cloudflare via CNAME and disabling Cloudflare caching via Cache Rules.\n\nTypically customers opt for a multi-vendor approach for reasons of regulatory/company compliance, resiliency, performance, and cost.\n\n### Regulatory/company compliance\n\nSome customers may have to comply with regulatory/company policy of not being dependent on a single vendor for all security, performance, and reliability services. This could be done for reasons of a companyâ€™s policy of mitigating risk for specific vendor outages/issues and/or for leverage to mitigate against increased vendor pricing/costs. For compliance with these policies, a multi-vendor strategy is required.\n\nWhen a single vendor is used for all security and performance services, this may be perceived as a single point of failure. This can be driven by regulatory pressure to improve reliability in all critical systems, outages experienced with an incumbent vendor, or uncertainty with the long term reliability of a single vendor.\n\nIn many cases a single vendor may be very well connected and provide the expected level of performance within a certain region, but less so in other regions; this could be due to a number of reasons including investment, limited resources, geopolitical reasons, etc. Many customers desire to fully optimize speed in performance critical applications and media by implementing a multi-vendor approach that is often coupled with real time performance monitoring to steer traffic to the most optimal vendor based on that data.\n\nJust like the performance of a particular vendor can vary based on content, time of day, and location, so can the cost, and sending particular traffic through a particular vendor can help optimize the overall cost of the delivery. Typically these benefits are seen driving a multi-vendor strategy in very specific use cases, such as for high volume media traffic, as the cost of onboarding and managing multiple vendors typically increases monetary and resource costs outside of specific niche use cases. Additionally, adopting a multi-vendor approach helps avoid vendor lock-in with any single provider, offering greater flexibility and negotiating power across vendors.\n\n## Multi-vendor solution considerations\n\nAny multi-vendor architecture will contain several components an organization must decide on prior to implementing, both on the business and technical side. Additionally, there are several things to keep in mind to help optimize your setup to align with Cloudflareâ€™s strengths and unique differentiators.\n\nOptimize for feature set and delivery methodology. Cloudflare is able to offer feature parity with most major vendors, with custom features easily delivered through our serverless compute service. For delivery methodology, Cloudflareâ€™s anycast architecture is unique in that every server can deliver every service that Cloudflare offers, making it an optimal candidate for an active/active approach.\n\nLeverage Cloudflareâ€™s API and rapid deployment capabilities wherever possible. Since Cloudflare offers every feature API first, and config changes typically are visible in a few seconds, this makes it easy for teams to test and deploy changes in a programmatic fashion without having to wait for long deployment times.\n\nAvoid a â€œstackedâ€ approach. This means avoid having Cloudflare placed in the request flow behind another vendor. We often hear companies consider stacking vendors with the hope of providing defense in depth by running the same traffic through each layer in a linear fashion. In theory this would allow for both vendors' policies to be run, and any bad traffic not caught by one vendor is hopefully caught by the next. What we see in practice when this setup is used is very different. The main disadvantage is the loss of full traffic visibility when sitting behind another vendor, which hinders many of Cloudflareâ€™s threat intelligence powered services such as Bot Management, Rate Limiting, DDoS mitigation, & IP reputation database. This is also highly suboptimal from the performance side since the traffic must pass through two networks each with their own processing and connection overhead before going back to origin. Also, it creates unnecessary complexity in operations, management, and support.\n\nOne note on a stacked approach is that in certain cases for particular point solutions, it can make sense to place one vendor solution in front of the other, such as particular bot management solutions and API gateways, especially when migrating towards a new vendor/provider. In these scenarios itâ€™s important to understand where each solution falls in the request flow to optimize effectiveness.\n\nWhile Cloudflare and many providers maintain a high degree of availability and a robust fault tolerant architecture, some customers have a further desire to reduce dependency and respectively single vendor point of failures. Itâ€™s important to plan for a worst case scenario where some or all of a vendor's services are down and how to work around that in a short timeframe. Customers must consider how to have redundancy across DNS providers, networks, and origin connectivity to eliminate the risk of a single vendor/component failure cascading into a widespread outage.\n\nWhile the specifics may vary widely depending on the vendor and business case, the technical considerations for a multi-vendor deployment can be bucketed into three areas: routing logic, configuration management and origin connectivity.\n\nThe first and likely most important decision that must be made when looking at a multi-vendor strategy is how to route traffic to each provider. This depends on both the business logic driving the multi-vendor strategy and the technical capabilities of each vendor in question. Traffic to each provider will be routed using DNS and shift depending on the current conditions and needs of the business. Cloudflare can support configurations as an authoritative DNS provider, secondary DNS provider, or non-Cloudflare DNS (CNAME) setups for a zone.\n\n![Figure 6: Client request being routed to origin server(s) in a multi-vendor setup](https://developers.cloudflare.com/_astro/Figure_6.Bij5Z-XO_CqOKb.webp)\n\nDNS based load balancing and health checks can be leveraged here so that client requests to the domain/site are distributed across healthy origin server(s). The DNS provider monitors the health of the servers and DNS responds to the client request using a round-robin approach with the respective IPs.\n\nIf a multi-vendor DNS approach is also desired for DNS-level resiliency, a variety of configurations are possible here with multiple authoritative nameservers from different vendors. See the â€˜Multi-vendor DNS setup optionsâ€™ section in this document for additional details. The key here is ensuring consistent configurations across multiple providers. Depending on the DNS setup/configuration, this consistency can be resolved using different approaches such as zone transfers, automation via tools such as Terraform or OctoDNS, monitoring/automation via scripting, or even manual configuration.\n\nWhile many vendors can deliver a similar end user experience, configuration and management can differ greatly between providers, which drives up the cost of a successful implementation. Ultimately that means the business must become familiar with each vendor's configuration logic and develop a system to map between them. Wherever possible, seek out vendors that optimize for management simplicity, automation support, and rapid deployment to help minimize the cost and management overhead.\n\nAPI support for all vendorâ€™s product functionality becomes critical here. Maintaining consistent configuration is important not only in the routing in certain multi-vendor DNS setups but also for maintaining consistency between all of the respective services such as WAF, API security, etc. as traffic can be routed to either provider. Automation tools such as Terraform or custom scripted automation tools will leverage the APIs to maintain this consistency between vendors.\n\nAnother important decision that must be made is how each provider will connect back into your organization. This will largely depend on the vendor's capabilities plus the technical and security requirements of your organization.\n\nClients will make requests over the Internet and the requests will be routed to the respective vendorâ€™s proxy service on the vendorâ€™s cloud. In the most basic scenario, the proxy will simply route the traffic over the Internet to the origin; this is the default setup.\n\nIf the customer wants more security or additional performance benefits, they may decide to also leverage vendor offered connectivity options such as encrypted tunnels to origin or direct connect options from customer data centers directly to Cloudflare data centers via cross connect from a customerâ€™s equipment to Cloudflare. Vendors may also offer accelerated routing capabilities where they actively monitor the fastest paths over the Internet to ensure the most optimal routes to the origin are used.\n\nCloudflare offers all of these connectivity options along with Smart Routing to ensure the fastest paths to origin are used. These connectivity options are discussed in more detail in the â€˜Cloudflare connectivity optionsâ€™ section of this document.\n\n**Operations and Troubleshooting**\n\nSome important considerations when designing a multi-vendor solution are operations and troubleshooting. Having a multi-vendor solution can raise operational costs and also impact troubleshooting as you now have two different environments to manage and troubleshoot.\n\nA primary focus for Cloudflare has always been operational simplicity and providing visibility. Cloudflare provides a single unified dashboard where all security, performance, and reliability services can be accessed from a consistent operationally simple UI.\n\nAdditionally, Cloudflare offers logging, analytics and security analytics dashboards. Logs with additional details are also accessible from the UI. Customers have granular data that can be used for analysis and troubleshooting.\n\nFigure 7 below shows a view of Cloudflare Security Analytics which brings together all of Cloudflareâ€™s detection capabilities in one place. This provides security engineers and admins with a quick view of current traffic and security insights in regards to their site.\n\n![Figure 7: Cloudflare Security Analytics](https://developers.cloudflare.com/_astro/Figure_7.QuPc0brB_F7baC.webp)\n\nIn addition to analytics for each product and security analytics shown above, you can also view logs within the UI and export logs to Cloudflare or third party clouds or products for additional analysis.\n\nIn Figure 8 below a Logpush is being configured to automatically export logs to an external destination.\n\n![Figure 8: Cloudflare Logpush for exporting logs to external destinations](https://developers.cloudflare.com/_astro/Figure_8.DnHWeRK__2arTtA.webp)\n\nWhen selecting the vendors for a multi-vendor solution you should ensure you select vendors where the below criteria is met:\n\n* The vendor provides for operational simplicity with a single consistent UI for all operations where users can easily manage and get things done in one place.\n* The vendor has useful security analytics to give an understanding of a sitesâ€™ traffic, security insights, and useful data for troubleshooting.\n* The vendor has the ability to export logs/request data to third party clouds/applications.\n* The vendor has an API first approach and provides APIs for all operations so tasks can be easily automated.\n* The vendor is reputable and can provide effective support and help when needed.\n* Employees are trained and have expertise or are comfortable using the vendorâ€™s products.\n\n## Common deployments\n\n### Multi-vendor active-active security and different provider for DNS\n\nThe below diagram describes a typical multi-vendor setup in which both vendors are â€˜activeâ€™ meaning they are both serving traffic for the same resource (`www.example.com`) and traffic is split between the two.\n\nOn the routing front, this example shows the authoritative DNS living outside of the two providers and load balancing between them. This DNS provider could be self hosted or live on another third party provider. Traffic is directed to each provider by responding to queries for `www.example.com` with a provider specific CNAME record or static IP for apex domain traffic. To achieve this traffic split, the third party DNS provider does need to have some ability to load balance the traffic. Most major DNS providers will have some mechanism to perform DNS based load balancing with varying degrees of complexity and configurability. This could mean round robining between records in the simplest case, or varying the response based on client location, health check data and more.\n\n![Figure 9: Multi-vendor setup with Cloudflare and another vendor and different provider for DNS](https://developers.cloudflare.com/_astro/Figure_9.yGPacbGy_ZjFcJV.webp)\n\nDepending on the authoritative DNS provider, traffic can be evenly split between the two or adjusted dynamically. Oftentimes customers will choose to inform the DNS routing with performance/availability data sourced from a third party monitoring service such as Thousandeyes or Catchpoint and adjust DNS responses based on that data. Third party monitoring services are often used to capture full HTTP request/response metrics to route based on real-time performance. Traffic can easily be shifted away from a provider by updating the authoritative DNS and waiting for the record TTL to expire.\n\nItâ€™s important to note here that the third party services are looking at end-to-end application performance metrics, not just DNS response time or limited data used by DNS resolvers. The DNS records will be updated based on the performance data to reflect the correct security vendorâ€™s proxy to point to.\n\nBoth providersâ€™ configurations are kept in sync by the administrators, pushing out changes via Terraform which makes calls to each provider's API. Keep in mind that while Cloudflare does have full API support for every feature, this may not be the case for every provider.\n\nIf only one external DNS provider is used, it does create a single point of failure if that DNS provider has an outage. A way to mitigate this risk is to implement a multi-vendor DNS solution; this is discussed in more detail in the [Multi-vendor DNS options](#multi-vendor-dns-setup-options) section in this document.\n\nAnother challenge of a parallel approach is keeping configurations in sync across providers to deliver a consistent end user experience. This means the administrators need to be familiar with the configuration management of both vendors and understand how feature parity can be achieved.\n\nOnce traffic is routed to the security and performance service provider via DNS, all security and performance services and respective policies are applied, and the traffic is then routed over the Internet back to the origin where the customerâ€™s firewall is allowing IPs specified by each provider.\n\n### Multi-vendor active-active security with multi-vendor DNS from same providers\n\nThe below example describes a setup where the DNS providers are also the security proxy vendors, and DNS records are kept in sync via zone transfers. A multi-vendor DNS solution is recommended as the preferred and most resilient solution.\n\nhere are different setups possible between the different DNS vendors and these are discussed in more detail in the â€˜Multi-vendor DNS setupâ€™ section of this document with advantages/disadvantages of each.\n\nIn this example, there are multiple authoritative DNS providers used where one is primary and the other is secondary. Per the use of secondary DNS and respective standard, zone transfers easily allow DNS configurations between different providers to remain synced.\n\nIn order to point requests to both providers (for the same hosts) in this model, the vendor set up as secondary must be able to overwrite records intended to go through a proxy. Without the ability to overwrite records as a secondary, the destination for all primary records would remain static and reduce the flexibility and resilience of the overall setup; Cloudflare provides this capability with [Secondary DNS override](https://developers.cloudflare.com/dns/zone-setups/zone-transfers/cloudflare-as-secondary/proxy-traffic/). For example, if the provider such as Cloudflare is set up as a secondary, Cloudflare will have DNS automatically synced to them from the primary via zone transfer, and can use Secondary DNS override to update the A record to point to its own proxy/services.\n\nWhile DNS based load balancing isnâ€™t required here, itâ€™s helpful to have at each provider so requests can be predictably split across multiple vendors, otherwise the traffic split is largely dictated by the client resolver nameserver selection.\n\n![Figure 10: Multi-vendor setup with Cloudflare and another vendor with multi-vendor DNS from same providers.](https://developers.cloudflare.com/_astro/Figure_10.C8edWi-O_1vGWHF.webp)\n\nAt the authoritative DNS provider, each vendor has their NS records listed and the client will select a nameserver based on their resolver. The resolver will receive the full set of authoritative nameservers upon request. The logic used by most resolvers typically takes into account resolution time as well as availability. In this scenario, the resolvers are used to make the decision on which name server to use based on performance/availability data they already have.\n\nItâ€™s important to note here that typically the DNS resolvers have already seen queries and responses associated with the nameservers used. For example, the nameserver the vendor assigns to the customer may already be used by other sites for their authoritative DNS and the resolvers already have a strong historical baseline of performance data to start leveraging immediately.\n\nIn this example, we are also seeing records being kept in sync via periodic zone transfers. Cloudflare is able to support both outgoing and incoming zone transfers. Traffic is directed to each proxy by either a provider specific CNAME record or static IP.\n\nThe configuration on the DNS side can vary; the different options are discussed in more detail in the next section. DNS can be set up with one provider acting as primary and the other acting as secondary. The DNS provider acting as primary is where all the DNS configuration is done and the secondary DNS receives the configuration copy via zone transfer.\n\nSome DNS providers like [Cloudflare](https://developers.cloudflare.com/dns/zone-setups/zone-transfers/cloudflare-as-secondary/proxy-traffic/) offer the capability where secondary DNS can overwrite the A and AAAA records. This allows the provider to rewrite the A/AAAA record to proxy traffic through a different vendor as desired. In this case the secondary DNS provider will provide a different response than the primary for the same hostname. This means that depending on what nameserver a client resolver queries, the request will be routed to the vendorâ€™s respective network. This allows for flexibility and reduced complexity by relying on the client resolver for traffic steering and failover if the nameservers are slow or unreachable. This comes at the cost of direct control and predictability over what provider a client selects.\n\nAnother variation is to have specific applications/hostnames hosted through specific providers. That could mean, in the above example, both the primary and secondary DNS servers have `www.example.com` mapped to a Cloudflare address, regardless of which provider resolves the initial DNS query.\n\n## Multi-vendor DNS setup options\n\nThe important routing decision is dictated by DNS. As discussed, there are multiple configurations possible for a multi-DNS setup. The below assumes you are using two DNS providers which are also the providers for the security solution.\n\n**1. Two authoritative - one primary and one secondary**\n\nThis setup involves setting one provider as a primary and the second provider as a secondary. The purpose of secondary DNS is to support multi-DNS solutions where synchronization between the configurations of primary and secondary is automated.\n\nIn this setup both DNS providers are authoritative but only one is primary and the source of truth and where DNS configuration changes/updates are made. The configuration changes/updates on primary are synced to the secondary DNS provider via zone transfers managed by the provider. DNS of both providers answer DNS queries.\n\nThe advantage and main use case with this deployment model is that it uses a standard for syncing DNS across multiple providers and was created for just this reason, and the DNS provider is responsible for the zone transfers. This option provides simplicity in maintaining DNS synchronization between providers.\n\nSometimes customers may decide to use another option due to the following:\n\n* The requirement of updating DNS records when the record management and zone transfer pipeline is down.\n* Not wanting to rely on a third party/vendor for the DNS synchronization and desiring more control.\n* Having specific restrictions/regulations excluding this option.\n\nThis setup is recommended for customers who desire simplicity offered by a secondary DNS and provider for maintaining synchronization.\n\n* Uses standard (AXFR, IXFR) to keep DNS synced and done automatically via Zone Transfers.\n* Simplicity as the DNS provider is responsible for DNS synchronization.\n\n* If the record management and zone transfer pipeline is down, DNS records cannot be updated.\n* Some customers do not want to rely on a vendor/3rd party for DNS sync and desire more control and flexibility.\n\n**2. Two authoritative - both primary**\n\nSome customers may also want to have the added assurance of being able to update DNS records when the record management and zone transfer pipeline is down. They also may not want to rely on a third party/vendor for DNS synchronization and desire more control. In this case, both DNS providers can be used as primary.\n\nIn this setup each DNS provider is authoritative and primary. There is no secondary DNS and changes/updates to DNS can be made at either provider; also, both DNS providers answer DNS queries.\n\nSynchronization of the DNS configuration between providers is critical, and in this setup it now becomes the customerâ€™s responsibility to keep DNS in sync at both providers. Customers typically do this synchronization with automation tools like OctoDNS, Terraform, or via custom automation leveraging the vendorsâ€™ APIs.\n\nThis setup is recommended for customers who desire the most flexible and resilient option that supports updating DNS records even when the record management and zone transfer pipeline is down and/or customers who want more control over DNS synchronization.\n\n* If control plane is down on one provider, DNS records can still be updated at the other.\n* More control and no reliance on DNS provider for DNS synchronization.\n\n* More complexity in keeping DNS between providers synced.\n* Customer is responsible for DNS synchronization which can be done via automation tools, automated via vendor APIs, or manually.\n\n**3. One or more authoritative - hidden primary and multiple secondary**\n\nIn a hidden primary setup, users establish an unlisted primary server to store all zone files and changes, then enable one or more secondary servers to receive and resolve queries. Although most of the time the primary is authoritative, it doesnâ€™t have to be. In this option, the primary is not listed with the registrar. The primary does not respond to queries and its main purpose is being the single source of truth.\n\nAlthough the secondary servers essentially fulfill the function of a primary server, the hidden setup allows users to hide their origin IP and shield it from attacks. Additionally, the primary can be taken offline for maintenance without causing DNS service to be disrupted.\n\nThis setup is recommended for customers who desire simplicity offered by a secondary DNS and provider for maintaining synchronization. This solution also provides for flexibility in taking the primary offline as needed with less impact.\n\n* Allows customers to maintain DNS record management on their infrastructure and use standard to keep DNS synced automatically via Zone Transfers.\n* Primary is used only for source of truth and maintaining DNS records and can be taken offline for maintenance /administration.\n\n* If the record management and zone transfer pipeline is down, DNS records cannot be updated.\n* Some customers do not want to rely on a vendor/3rd party for DNS sync and desire more control.\n\n## Configuration and management best practices\n\n![Figure 11: Configuration via Terraform for multi-vendor setup with Cloudflare and other vendor](https://developers.cloudflare.com/_astro/Figure_11.Dt7KSeKt_Z1AmogL.webp)\n\nFigure 11 depicts a typical pattern seen when managing configurations across both Cloudflare and other providers in parallel. In this example, we are assuming that the same workloads are being split through both providers and the admin team is updating both configurations via API through Terraform. This can also be tied into an internal CI/CD pipeline to match your typical developer workflow. All Cloudflare functions can be configured via API and are delivered first via API. This diagram also depicts logs being sent to a common SIEM and native alerting functions that can be delivered via e-mail, webhook, or PagerDuty for alerts based on performance, security or administrative criteria.\n\nWith the wide variety of customization options Cloudflare provides (Ruleset Engine, native features, Worker customizations), Cloudflare can likely meet feature parity with most other major vendors out in the market, however it's not guaranteed that these features will be configurable in the same manner. This is where working closely with your Cloudflare account team becomes critical in understanding the key differences in operation and best practices to align your workflow with Cloudflare.\n\n## Connectivity options\n\nFor a multi-vendor offering it's important to consider the methods that each provider offers for connectivity to the origin(s) and the trade offs in security, performance, and resiliency. Cloudflare offers several options that fit most use cases and can be deployed in parallel with per application (hostname/DNS record) granularity to fit a hybrid customer environment.\n\n### Internet (default)\n\nIn the most basic scenario, the proxy will simply route the traffic over the Internet to the origin; this is the default setup for all vendors. In this setup the client and origin are both endpoints directly connected to the Internet via their respective ISPs. The request is routed over the Internet from the client to the vendor proxy (via DNS configuration) before the proxy routes the request over the Internet to the customer's origin.\n\nThe below diagram describes the default connectivity to origins as requests flow through the Cloudflare network. When a request hits a proxied DNS record and needs to reach the origin, Cloudflare will send traffic from the network over the Internet from a set of Cloudflare owned addresses.\n\n![Figure 12: Connectivity from Cloudflare to origin server(s) via Internet](https://developers.cloudflare.com/_astro/Figure_12.D0NtsXlk_38Hxx.webp)\n\nOptionally, customers can also choose to leverage [Dedicated CDN Egress IPs](https://developers.cloudflare.com/smart-shield/configuration/dedicated-egress-ips/), which allocates customer-specific IPs that Cloudflare will use to connect back to your origins. We recommend allowlisting traffic from only these networks to avoid direct access. In addition to IP blocking at the origin side firewall, we also strongly recommend additional verification of traffic via either the \"Full (Strict)\" SSL setting or mTLS auth to ensure all traffic is sourced from requests passing through the customer configured zones.\n\nCloudflare also supports [Bring Your Own IP (BYOIP)](https://developers.cloudflare.com/byoip/). When BYOIP is configured, the Cloudflare global network will announce a customerâ€™s own IP prefixes and the prefixes can be used with the respective Cloudflare Layer 7 services.\n\n### Private connection - tunnel or VPN\n\nAnother option is to have a private tunnel/connection over the Internet for additional security. Some vendors offer private connectivity via tunnels or VPNs which can be encrypted or unencrypted; these vary in complexity/management and require additional security/firewall updates to allow for connectivity. A traditional VPN setup is also limited via a centralized vendor location back to the origin.\n\nCloudflare offers [Cloudflare Tunnel](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/) which is tunneling software that provides an encrypted tunnel between your origin(s) and Cloudflareâ€™s network. Also, since Cloudflare leverages anycast on its global network, the origin(s) will, like clients, connect to the closest Cloudflare data center(s).\n\nWhen you run a tunnel, a lightweight daemon in your infrastructure, cloudflared, establishes four outbound-only connections between the origin server and the Cloudflare network. These four connections are made to four different servers spread across at least two distinct data centers providing robust resiliency. It is possible to install many cloudflared instances to increase resilience between your origin servers and the Cloudflare network.\n\nCloudflared creates an encrypted tunnel between your origin web server(s) and Cloudflareâ€™s nearest data center(s), all without opening any public inbound ports. This provides for simplicity and speed of implementation as there are no security changes needed on the firewall. This solution also lowers the risk of firewall misconfigurations which could leave your company vulnerable to attacks.\n\nThe firewall and security posture is hardened by locking down all origin server ports and protocols via your firewall. Once Cloudflare Tunnel is in place and respective security applied, all requests on HTTP/S ports are dropped, including volumetric DDoS attacks. Data breach attempts, such as snooping of data in transit or brute force login attacks, are blocked entirely.\n\n![Figure 13: Connectivity from Cloudflare to origin server(s) via Cloudflare Tunnel](https://developers.cloudflare.com/_astro/Figure_13.CsKShnx8_rs0l1.webp)\n\nThe above diagram describes the connectivity model through Cloudflare Tunnel. Note, this option provides you with a secure way to connect your resources to Cloudflare without a publicly routable IP address. Cloudflare Tunnel can connect HTTP web servers, SSH servers, remote desktops, and other protocols safely to Cloudflare.\n\n### Direct connection\n\nMost vendors also provide an option of directly connecting to their network. Direct connections provide security, reliability, and performance benefits over using the public Internet. These direct connections are done at peering facilities, Internet Exchanges (IXs) where Internet Service Providers (ISPs) and Internet networks can interconnect with each other, or through vendor partners.\n\n![Figure 14: Connectivity from Cloudflare to origin server(s) via Cloudflare Network Interconnect (CNI)](https://developers.cloudflare.com/_astro/Figure_14.pA3d5-ag_Z2vVWnb.webp)\n\nThe above diagram describes origin connectivity through [Cloudflare Network Interconnect (CNI)](https://blog.cloudflare.com/cloudflare-network-interconnect/) which allows you to connect your network infrastructure directly with Cloudflare and communicate only over those direct links. CNI allows customers to interconnect branch and headquarter locations directly with Cloudflare. Customers can interconnect with Cloudflare in one of three ways: over a private network interconnect (PNI) available at [Cloudflare peering facilities](https://www.peeringdb.com/net/4224), via an IX at any of the [many global exchanges Cloudflare participates in](https://bgp.he.net/AS13335#_ix), or through one of our [interconnection platform partners](https://blog.cloudflare.com/cloudflare-network-interconnect-partner-program).\n\nCloudflareâ€™s global network allows for ease of connecting to the network regardless of where your infrastructure and employees are.\n\n## Additional routing and security options\n\nMost vendors also provide additional capabilities for enhanced/optimized routing and additional security capabilities when communicating with the origin. You should check with respective vendor documentation to confirm support if parity is expected in terms of performance and security capabilities.\n\nCloudflare offers [Argo Smart Routing](https://developers.cloudflare.com/argo-smart-routing/) for finding and using optimized routes across the Cloudflare network to deliver responses to users more quickly and Authenticated Origin Pulls (mTLS) to ensure requests to your origin server come from the Cloudflare network\n\n### Argo Smart Routing\n\nArgo Smart Routing is a service that finds optimized routes across the Cloudflare network to deliver responses to users more quickly.\n\nArgo Smart Routing accelerates traffic by taking into account real-time data and network intelligence from routing over 28 million HTTP requests per second; it ensures the fastest and most reliable network paths are traversed over the Cloudflare network to the origin server. On average, Argo Smart Routing accounts for 30% faster performance on web assets.\n\nIn addition, Cloudflare CDN leverages Argo Smart Routing to determine the best upper tier data centers for Argo Tiered Cache. Argo Smart Routing can be enabled to ensure the fastest paths over the Cloudflare network are taken between upper tier data centers and origin servers at all times. Without Argo Smart Routing, communication between upper tier data centers to origin servers are still intelligently routed around problems on the Internet to ensure origin reachability. For more information on Argo Smart Routing as it relates to CDN, see the [Cloudflare CDN Reference Architecture](https://developers.cloudflare.com/reference-architecture/architectures/cdn/).\n\n### Authenticated Origin Pulls (mTLS)\n\nAuthenticated Origin Pulls helps ensure requests to your origin server come from the Cloudflare network, which provides an additional layer of security on top of [Full](https://developers.cloudflare.com/ssl/origin-configuration/ssl-modes/full/) or [Full (strict)](https://developers.cloudflare.com/ssl/origin-configuration/ssl-modes/full-strict/) SSL/TLS encryption modes Cloudflare offers.\n\nThis authentication becomes particularly important with the [Cloudflare Web Application Firewall (WAF)](https://developers.cloudflare.com/waf/). Together with the WAF, you can make sure that all traffic is evaluated before receiving a response from your origin server.\n\nIf you want your domain to be [FIPS](https://en.wikipedia.org/wiki/Federal_Information_Processing_Standards) compliant, you must upload your own certificate. This option is available for both [zone-level](https://developers.cloudflare.com/ssl/origin-configuration/authenticated-origin-pull/set-up/zone-level/) and [per-hostname](https://developers.cloudflare.com/ssl/origin-configuration/authenticated-origin-pull/set-up/per-hostname/) authenticated origin pulls.\n\nTo summarize, a successful multi-vendor strategy for application security and performance requires careful consideration of your business objectives, infrastructure requirements, and vendor capabilities. There are several options to choose from when deploying a multi-vendor strategy with various advantages and limitations to each. Cloudflare can support these configurations by delivering services through the Cloudflare Global Network that are highly resilient, performant, and cost effective to fit your organizations multi-vendor strategy.\n\n[Download this page as a PDF](https://developers.cloudflare.com/reference-architecture/static/multi-vendor-application-security-performance.pdf)\n\n<page>\n---\ntitle: Cloudflare Security Architecture Â· Cloudflare Reference Architecture docs\ndescription: This document provides insight into how this network and platform\n  are architected from a security perspective, how they are operated, and what\n  services are available for businesses to address their own security\n  challenges.\nlastUpdated: 2025-11-21T18:29:21.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/reference-architecture/architectures/security/\n  md: https://developers.cloudflare.com/reference-architecture/architectures/security/index.md\n---\n\nToday, everything and everyone needs to be connected to everything everywhere, all the time, and everything must be secure. However, many businesses are not built on infrastructure that supports this reality. Historically, employees worked in an office where most business systems (file servers, printers, applications) were located on and accessible only from the private office network. A security perimeter was created around the network to protect against outsider threats, most of which came from the public Internet.\n\nHowever, as Internet bandwidth increased and more people needed to do work outside of the office, VPNs allowed employees access to internal systems from anywhere they could get an Internet connection. Applications then started to move beyond the office network, living in the cloud either as SaaS applications or hosted in IaaS platforms. Companies rushed to expand access to their networks and invest in new, dynamic methods to detect, protect, and manage the constantly evolving security landscape. But this has left many businesses with complex policies and fragile networks with many point solutions trying to protect different points of access.\n\nSince 2010, Cloudflare has been building a unique, large-scale network on which we run a set of security services that allow organizations to build improved connectivity and better protect their public and private networks, applications, users, and data. This document provides insight into how this network and platform are architected from a security perspective, how they are operated, and what services are available for businesses to address their own security challenges. The document comprises two main sections:\n\n* How Cloudflare builds and operates its secure global network.\n* How to protect your business infrastructure and assets using Cloudflare services built on the network.\n\n### Who is this document for and what will you learn?\n\nThis document is designed for IT and security professionals who are looking at using Cloudflare to secure aspects of their businesses. It is aimed primarily at Chief Information Security Officers (CSO/CISO) and their direct teams who are responsible for the overall security program at their organizations. Because the document covers the security of the entire Cloudflare platform it does not go into deep details about any particular service. Instead, please visit our [Architecture Center](https://www.cloudflare.com/architecture/) to find specific information for a service or product.\n\nTo build a stronger baseline understanding of Cloudflare, we recommend the following resources:\n\n* What is Cloudflare? | [Website](https://www.cloudflare.com/what-is-cloudflare/) (5 minute read) or [video](https://youtu.be/XHvmX3FhTwU?feature=shared) (2 minutes)\n\n- [How Cloudflare strengthens security everywhere you do business](https://cf-assets.www.cloudflare.com/slt3lc6tev37/is7XGR7xZ8CqW0l9EyHZR/1b4311823f602f72036385a66fb96e8c/Everywhere_Security-Cloudflare-strengthens-security-everywhere-you_do-business.pdf) (10 minutes)\n\n## Secure global network\n\nAny cloud security solution needs to be fast and always available. Our network protects over 20% of Internet web properties, operates in over 330 cities, and is 50 ms away from 95% of the Internet-connected population. Each server in each data center runs every service, so that traffic is inspected in one pass and acted upon close to the end user. These servers are connected together by over 13,000 network peers with over 405 Tbps network capacity. Cloudflareâ€™s network is also connected to [every Internet exchange](https://bgp.he.net/report/exchanges#_participants) (more than Microsoft, AWS, and Google) to ensure that we are able to peer traffic from any part of the Internet.\n\nWith millions of customers using Cloudflare, the network serves over [57 million HTTP requests](https://radar.cloudflare.com/traffic) per second on average, with more than 77 million HTTP requests per second at peak. As we analyze all this traffic, we detect and block an average of [209 billion cyber threats each day](https://radar.cloudflare.com/security-and-attacks). This network runs at this massive scale to ensure that customers using our security products experience low latency, access to high bandwidth, and a level of reliability that ensures the ongoing security of their business. (Note metrics are correct as of June 2024.)\n\nThe Cloudflare network is not like a traditional enterprise network. It has been designed from the ground up using a service isolation, least privilege, and zero trust architecture. Public-facing edge servers, and the data centers they reside in, can be seen as islands in a vast lake of connectivity â€” where nothing trusts anything without strong credentials and tight access policies.\n\n![The Cloudflare network has data centers in over 320 major cities.](https://developers.cloudflare.com/_astro/security-ref-arch-1.WLeUmjWV_NNKU5.svg)\n\nA unique aspect of the network's security architecture is how we use anycast networking. In every data center we broadcast the entire Cloudflare network range (IPv6 and IPv4) for both UDP and TCP. [Border Gateway Protocol](https://www.cloudflare.com/learning/security/glossary/what-is-bgp/) (BGP) ensures routers all around the Internet provide the shortest possible path for any user to the nearest Cloudflare server where traffic is inspected. From a security perspective, this is very important. During distributed denial-of-service (DDoS) attacks to customers behind our network, a combination of high bandwidth capacity and distribution of requests across thousands of local servers helps ensure our network stays performant and available, even during some of the largest attacks in [Internet history](https://blog.cloudflare.com/cloudflare-mitigates-record-breaking-71-million-request-per-second-ddos-attack).\n\nServer updates, such as access policies, rate limiting, and firewall rules, are performed by our [Quicksilver service](https://blog.cloudflare.com/introducing-quicksilver-configuration-distribution-at-internet-scale). Customer changes are reflected across the entire network in seconds, allowing customers to respond to changing business requirements and ensuring policies are quickly implemented globally.\n\nEvery level of the network conforms to strict hardened security controls. Processes running on the edge are designed with a need-to-know basis and run with least privilege. We have our own key management system to ensure keys are secured at rest and in transit and that the right access to keys is given at the right time. To ensure tight control over and detailed visibility of changes to the network, all infrastructure is managed via code ([IaC](https://en.wikipedia.org/wiki/Infrastructure_as_code)).\n\nCloudflare designs and owns all the servers in our network. There are two main types.\n\n* **Private core servers**: The control plane where all customer configuration, logging, and other data lives.\n* **Public edge servers**: Where Internet and privately tunneled traffic terminates to the Cloudflare network, to be inspected and then routed to its destination.\n\nServer hardware is designed by Cloudflare and built by industry-respected manufacturers that complete a comprehensive supply chain and security review. Every server runs an identical software stack, allowing for consistent hardware design. The operating system on edge servers is also a single design and built from a highly modified Linux distribution, tailored for the scale and speed of our platform. Cloudflare is a significant contributor to the Linux kernel, and we regularly share information on how we secure our [servers and services](https://blog.cloudflare.com/the-linux-kernel-key-retention-service-and-why-you-should-use-it-in-your-next-application), helping the Linux community and the rest of the Internet benefit from our [engineering](https://blog.cloudflare.com/linux-kernel-hardening).\n\nEvery server runs all Cloudflare products and services that customers use to secure their networks and applications. Later in this document we provide an overview of these services, but for the moment it's important to provide insight into the development of the software. From the initial design of every product, the engineering team works hand in hand with security, compliance, and risk teams to review all aspects of the service. These teams can be viewed as part of the engineering and product teams, not an external group. They are essential to the development of everything we do at Cloudflare and we have some of the most respected professionals in the industry. Code is reviewed by security teams at every stage of development, and we implement many automated systems to analyze software looking for vulnerabilities. Threat modeling and penetration testing frameworks such as [OWASP](https://owasp.org/www-project-web-security-testing-guide/latest/3-The_OWASP_Testing_Framework/), [STRIDE](https://en.wikipedia.org/wiki/STRIDE_\\(security\\)), and [DREAD](https://en.wikipedia.org/wiki/DREAD_\\(risk_assessment_model\\)) are used during design, development, and the release process.\n\nMany of our products run on our [serverless runtime](https://developers.cloudflare.com/workers/) environment, which leverages the very latest techniques in service isolation. We anticipated this secure runtime environment could be very valuable to our customers, so we productized it, allowing them to [build](https://developers.cloudflare.com/workers/reference/how-workers-works/) and [run](https://blog.cloudflare.com/cloud-computing-without-containers) their own applications on our network. More about that at the very end of this document.\n\nTo ensure we are delivering the most secure network and platform possible, we are always innovating. New technologies need to be created to solve the ever-increasing range of security threats and challenges. Cloudflare leads many initiatives, such as further securing BGP using [RPKI](https://isbgpsafeyet.com/), and we regularly contribute to working IETF groups on many common Internet security protocols. We strive to help increase and monitor [IPv6 adoption](https://radar.cloudflare.com/adoption-and-usage), which inherently creates a more secure Internet, and we stay ahead of future challenges by deploying technologies such as [post-quantum cryptography](https://blog.cloudflare.com/post-quantum-for-all) before any increase in computing power from quantum computers threatens existing cryptographic techniques.\n\n### Operational security\n\nNot only must the design of the network be secure, but so should how we run and maintain it. We operate at a massive scale, and the common design of our servers helps optimize software deployments and monitoring. Defining who has access to maintain the network is fully automated, following infrastructure-as-code practices with role-based access controls (RBAC) and least privilege controls used everywhere.\n\nCustomers send sensitive information to our products and services. The mission for the Cloudflare compliance team is to ensure the underlying infrastructure that supports these services meets [industry compliance standards](https://www.cloudflare.com/trust-hub/compliance-resources/) such as FedRAMP, SOC II, ISO, PCI certifications, C5, privacy, and regulatory frameworks. The compliance team works with all engineering organizations to help integrate these requirements as part of the way we work. From a compliance perspective, our areas of focus include:\n\n* Privacy and security of customer data\n* Maintaining compliance validations\n* Helping customers with their own compliance\n* Monitoring the changes to the regulatory landscape\n* Providing feedback to regulatory bodies on upcoming changes\n\nWe also run a [bug bounty program](https://hackerone.com/cloudflare), giving incentives for the community to find and report vulnerabilities to us for financial reward.\n\nIn summary, Cloudflare not only has built the right technology to secure our network, but also has well-staffed and mature teams ensuring that the right processes are created, followed, and monitored. As Cloudflare has grown over the past decade, we've accrued some of the best security knowledge in the industry, which in turn has attracted top talent to come work with us. This effect compounds each year, bringing our security skills and knowledge to greater heights. We are also very transparent about how Cloudflare runs and secures its network, and we [often blog](https://blog.cloudflare.com/secure-by-design-principles) about our processes and evolving approach to security.\n\n## Using Cloudflare to protect your business\n\nThe reason the Cloudflare network exists is to provide services to customers to protect their own assets, such as users, applications, and data. The following section details what these services are, their basic architecture, and how they are used by customers. Note that this section does not go into extensive detail on each service. Instead, please refer to our [Architecture Center](https://cloudflare.com/architecture) or [product documentation](https://developers.cloudflare.com/directory/) to understand more about a specific product, service, or solution. The goal in this document is to provide information about the overall set of security services available and the general use cases they are designed for. As such, we provide a table of contents so you can jump to a section of interest.\n\n1. [Securing public and private resources](#securing-public-and-private-resources)\n\n2. [Protecting public resources](#protecting-public-resources)\n\n1. [Common attacks and protection](#common-attacks-and-protection)\n\n1. [DDoS attacks](#ddos-attacks)\n      2. [Zero-day attacks](#zero-day-attacks)\n      3. [Unauthorized access](#unauthorized-access)\n      4. [Client-side attacks](#client-side-attacks)\n      5. [Data exfiltration](#data-exfiltration)\n      6. [Credential stuffing](#credential-stuffing)\n      7. [Brute force attacks](#brute-force-attacks)\n      8. [Credit card skimming](#credit-card-skimming)\n      9. [Inventory hoarding](#inventory-hoarding)\n      10. [Fuzzing (vulnerability scanning)](#fuzzing-vulnerability-scanning)\n      11. [Cross-Site Scripting (XSS) attacks](#cross-site-scripting-xss-attacks)\n      12. [Remote Code Execution (RCE) attacks](#remote-code-execution-rce-attacks)\n      13. [SQL injection (SQLi) attacks](#sql-injection-sqli-attacks)\n      14. [Malware](#malware)\n\n2. [Cloudflare application security products](#cloudflare-application-security-products)\n\n1. [Security Analytics](#security-analytics)\n      2. [Web Application Firewall (WAF)](#web-application-firewall-waf)\n      3. [Rate limiting](#rate-limiting)\n      4. [L7 DDoS](#l7-ddos)\n      5. [API Shield](#api-shield)\n      6. [Bot Management](#bot-management)\n      7. [Page Shield](#page-shield)\n      8. [SSL/TLS](#ssltls)\n      9. [Security Center](#security-center)\n      10. [Cloudflare for SaaS](#cloudflare-for-saas)\n\n3. [Cloudflare network security products](#cloudflare-network-security-products)\n\n1. [Magic Transit](#magic-transit)\n      2. [Magic WAN](#magic-wan)\n      3. [Magic Firewall](#magic-firewall)\n      4. [Magic Network Monitoring](#magic-network-monitoring)\n      5. [Spectrum](#spectrum)\n\n3. [Protecting private resources](#protecting-private-resources)\n\n1. [Securing connectivity to private resources](#securing-connectivity-to-private-resources)\n   2. [User connectivity](#user-connectivity)\n   3. [Integrating identity systems](#integrating-identity-systems)\n   4. [Access control](#access-control)\n   5. [Protecting data](#protecting-data)\n   6. [Securing Internet access](#securing-internet-access)\n\n4. [Observability](#observability)\n\n5. [Developer platform](#developer-platform)\n\nIn general, what customers need to effectively combat and protect against the growing breadth and complexity of threats is a unified security solution that provides visibility, analytics, detection, and mitigation in an operationally consistent and efficient manner. Cloudflare addresses these needs in several ways:\n\n* Operational consistency: Cloudflare has a single dashboard/UI for all administrative tasks.\n* Operational simplicity: Cloudflare is well-known for minimizing operational complexity with well-designed user interfaces that minimize manual configurations and UI workflows. Additionally, cross-product integrations allow for automating configurations and policies.\n* Continuous innovation: Cloudflare continues to innovate across its broad security portfolio with unique differentiating capabilities such as its CAPTCHA replacement product, Turnstile, and the industry-first API Sequence Mitigation capability.\n* Workload location agnostic: Cloudflare was built first and foremost around performance and security services. As such, it was built from the ground up to be workload location agnostic with multi-cloud inherently being a top use case. Customers can deploy workloads in multiple clouds and/or on-prem and get the same operational consistency.\n* Performance and scale: All Cloudflare services run on every server in every data center on the same global cloud, allowing for maximum performance in terms of global reachability and latency and ability to scale out, leveraging the full capacity of Cloudflareâ€™s global infrastructure.\n* API first: Cloudflare is API first. All configurations and capabilities available from the UI/dashboard are also available from the API. Cloudflare can easily be configured with Terraform to support automation for customer workflows/processes.\n\nCloudflareâ€™s security services that protect networks, applications, devices, users, and data can be grouped into the following categories.\n\n![Cloudflare has a wide range of security services across SASE/SSE, application and network security.](https://developers.cloudflare.com/_astro/security-ref-arch-2.40SWzQcS_ZeLtJd.svg)\n\nNote this list is focused on security and doesn't include products such as our content delivery network (CDN), load balancing, and domain name services (DNS).\n\n### Securing public and private resources\n\nThere are two main types of resources our customers are trying to secure:\n\n* **Public resources** are defined as any content, asset, or infrastructure that has an interface available and accessible to the general Internet, such as brand websites, ecommerce sites, and APIs. They can also be defined by the fact they are accessible by anonymous users or people who register themselves to gain access, such as social media websites, video streaming services, and banking services.\n* **Private resources** are defined as content, assets, or infrastructure with the intended set of users constrained to a single company, organization, or set of customers. These services typically require accounts and credentials to gain access. Examples of such resources are the company HR system, source code repositories, and a point of sale (POS) system residing on a retail branch network. These resources are typically accessible only by employees, partners, and other trusted, known identities.\n\nPublic and private resources can also include both infrastructure-level components like servers and consumed resources like websites and API endpoints. Communication over networks and the Internet happens in different stages and levels as shown in the open systems interconnection (OSI) model diagram below.\n\n![The network OSI model describes network communication from the physical through to the application layer.](https://developers.cloudflare.com/_astro/security-ref-arch-3.D6GGUlec_Zyqm9m.svg)\n\nCloudflare can protect at multiple layers of the OSI model, and in this document we are primarily concerned with protecting resources at layers 3, 4, and 7.\n\n* Layer 3, referred to as the â€œnetwork layer,â€ is responsible for facilitating data transfer between two different networks. The network layer breaks up segments from the transport layer into smaller units, called packets, on the senderâ€™s device and reassembles these packets on the receiving device. The network layer is where routing takes place â€” finding the best physical path for the data to reach its destination.\n* Layer 4, referred to as the â€œtransport layer,â€ is responsible for end-to-end communication between the two devices. This includes taking data from the session layer and breaking it up into chunks called â€œsegmentsâ€ before sending it to layer 3.\n\nCloudflare security products that can be used for L3 and L4 security include Cloudflareâ€™s network services offerings, including [Magic Transit](https://developers.cloudflare.com/magic-transit/), [Magic Firewall](https://developers.cloudflare.com/magic-firewall/), [Magic WAN](https://developers.cloudflare.com/magic-wan/), [Magic Network Monitoring](https://developers.cloudflare.com/magic-network-monitoring/), and [Spectrum](https://developers.cloudflare.com/spectrum/).\n\n* Layer 7, referred to as the â€œapplication layer,â€ is the top layer of the data processing that occurs just below the surface or behind the scenes of the software applications that users interact with. HTTP and API requests/responses are layer 7 events.\n\nCloudflare has a suite of application security products that includes [Web Application Firewall](https://developers.cloudflare.com/waf/) (WAF), [Rate Limiting](https://developers.cloudflare.com/waf/rate-limiting-rules/), [L7 DDoS](https://developers.cloudflare.com/ddos-protection/managed-rulesets/http/), [API Shield](https://developers.cloudflare.com/api-shield/), [Bot Management](https://developers.cloudflare.com/bots/), and [Page Shield](https://developers.cloudflare.com/page-shield/).\n\nNote that SaaS applications could be considered both public and private. For example, Salesforce has direct Internet-facing access but contains very private information and is usually only accessible by employee accounts that are provisioned by IT. For the purpose of this document, we will consider SaaS applications as private resources.\n\nThese are general guidelines because with Cloudflare it's possible to have very sensitive internal applications be protected by publicly accessible remote access services. We will explain more as we continue through this document.\n\n### Protecting public resources\n\nBusinesses rely on public websites and API endpoints for daily ecommerce transactions and brand awareness, and often the entire business is an online service. High availability, performance, and security are top concerns, and customers use Cloudflare to ensure their businesses stay up and running. Cloudflare security services help prevent fraud, data exfiltration, and attacks that can create liability, cause losses and brand damage, and slow down or halt business.\n\nPublic assets need to be protected on multiple fronts and from various attacks; therefore, multiple different security capabilities need to be implemented. Additionally, customers must tackle the operational efficiency of solutions they implement. Managing multiple point products for mitigating different attacks or having multiple vendors to meet company security objectives and requirements creates many operational inefficiencies and issues, such as multiple UIs/dashboards, training, lack of cross-product integrations, etc.\n\nThe diagram below shows a typical request for a public asset going through the Cloudflare network. Our security services are part of many capabilities, and Cloudflare acts as a reverse proxy where requests are routed to the closest data center and performance and security services are applied prior to that request being routed onto the destination. These services can easily be consolidated and used together regardless of where workloads are deployed; the operations and implementation remain consistent. Note: the diagram doesn't detail all of Cloudflare's services.\n\n![Every request through Cloudflare passes once for inspection across all security products.](https://developers.cloudflare.com/_astro/security-ref-arch-4.PP-9vg85_1LJP4c.svg)\n\nThe diagram highlights the following:\n\n* The [world's fastest DNS service](https://www.dnsperf.com/) provides fast resolution of public hostnames\n* Ensure data compliance by [choosing geographic locations](https://www.cloudflare.com/data-localization/) for the inspection and storage of data\n* Spectrum extends Cloudflare security capabilities to all UDP/TCP applications\n* Security services inspect a request in one pass\n* Application performance services also act on the request in the same pass\n* [Smart routing](https://developers.cloudflare.com/argo-smart-routing/) finds the lowest latency path between Cloudflare and the public destination\n\n#### Common attacks and protection\n\nCloudflare's broad product portfolio protects against a wide variety of attacks. Several common attacks are described in more detail below and include a reference to the Cloudflare products that are used to mitigate the specific attack.\n\nA [distributed denial-of-service (DDoS) attack](https://www.cloudflare.com/learning/ddos/what-is-a-ddos-attack/) is a malicious attempt to disrupt the availability of a targeted server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of traffic. The goal is to slow down or crash a program, service, computer, or network, or to fill up capacity so that no one else can use or receive the service. DDoS attacks can occur at L3, L4, or L7, and Cloudflare provides protections at all these different layers.\n\n![DDoS attacks are prevented at layers 3, 4 and 7.](https://developers.cloudflare.com/_astro/security-ref-arch-5.Dk00_Til_Z17epiP.svg)\n\nCloudflareâ€™s L7 DDoS Protection prevents denial of service at layer 7; Spectrum protects at layer 4; and Magic Transit protects at layer 3. In addition to the core DDoS-specific security products, Cloudflare provides advanced rate limiting capabilities to allow for throttling traffic based on very granular request data, including headers information and API tokens. Cloudflareâ€™s Bot Management capabilities can also limit denial-of-service attacks by effectively mitigating bot traffic.\n\nProducts: [L7 DDoS](https://developers.cloudflare.com/ddos-protection/managed-rulesets/http/), [Spectrum](https://developers.cloudflare.com/spectrum/), [Magic Transit](https://developers.cloudflare.com/magic-transit/)\n\n##### Zero-day attacks\n\nA zero-day exploit (also called a zero-day threat) is an attack that takes advantage of a security vulnerability that does not have a fix in place. It is referred to as a \"zero-day\" threat because once the flaw is discovered, the developer or organization has \"zero days\" to then come up with a solution.\n\nWeb Application Firewall (WAF) [Managed Rules](https://developers.cloudflare.com/waf/managed-rules/) allow you to deploy pre-configured managed rulesets that provide immediate protection against the following:\n\n* Zero-day vulnerabilities\n* Top 10 attack techniques\n* Use of stolen/exposed credentials\n* Extraction of sensitive data\n\nWAF checks incoming web requests and filters undesired traffic based on sets of rules (rulesets) deployed at the edge. These managed rulesets are maintained and regularly updated by Cloudflare. From the extensive threat intelligence obtained from across our global network, Cloudflare is able to quickly detect and classify threats. As new attacks/threats are identified, Cloudflare will automatically push WAF rules to customers to ensure they are protected against the latest zero-day attacks.\n\nAdditionally, Cloudflare provides for [WAF Attack Score](https://developers.cloudflare.com/waf/detections/attack-score/), which complements Cloudflare managed rules by detecting attack variations. These variations are typically achieved by malicious actors via fuzzing techniques that are trying to identify ways to bypass existing security policies. WAF classifies each request using a machine learning algorithm, assigning an attack score from 1 to 99 based on the likelihood that the request is malicious. Rules can then be written which use these scores to determine what traffic is permitted to the application.\n\n![Machine learning maintains lists of managed rules to determine if the request should be let through the WAF or not.](https://developers.cloudflare.com/_astro/security-ref-arch-6.DGieuMIT_kwSAC.svg)\n\nProducts: [WAF - Cloudflare Managed Rules](https://developers.cloudflare.com/waf/managed-rules/)\n\n##### Unauthorized access\n\nUnauthorized access can result from broken authentication or broken access control due to vulnerabilities in authentication, weak passwords, or easily bypassed authorization. Cloudflare mTLS (mutual TLS) and JWT (JSON Web Tokens) validation can be used to bolster authentication. Clients or API requests that donâ€™t have a valid certificate or JWT can be denied access via security policy. Customers can create and manage mTLS certificates from the Cloudflare dashboard or an API. Cloudflareâ€™s WAF and [Exposed Credentials Check](https://developers.cloudflare.com/waf/managed-rules/check-for-exposed-credentials/) managed ruleset can be used to detect compromised credentials being used in authentication requests. WAF policies can also be used to restrict access to applications/paths based on different request criteria.\n\nProducts: [SSL/TLS - mTLS](https://developers.cloudflare.com/ssl/client-certificates/enable-mtls/), [API Shield (JWT Validation)](https://developers.cloudflare.com/api-shield/security/jwt-validation/), [WAF](https://developers.cloudflare.com/waf/)\n\n##### Client-side attacks\n\nClient-side attacks like [Magecart](https://blog.cloudflare.com/detecting-magecart-style-attacks-for-pageshield) involve compromising third-party libraries, compromising a website, or exploiting vulnerabilities in order to exfiltrate sensitive user data to an attacker-controlled domain. Page Shield leverages Cloudflareâ€™s position in the network as a reverse proxy to receive information directly from the browser about:\n\n1. What JavaScript files/modules are being loaded\n2. Outbound connections made\n3. Inventory of cookies used by the application (planned to be available late 2024)\n\nPage Shield uses threat-feed detections of malicious JavaScript domains and URLs. In addition, it can download JavaScript source files and run them through a machine learning classifier to identify malicious behavior and activity; the result is a JS Integrity Score designating if the JavaScript file is malicious. Page Shield can also detect changes to JavaScript files. Alerts using emails, webhooks, and PagerDuty can be set based on different criteria such as new resources identified, code changes, and malicious code/domains/URLs.\n\nPage Shield [Content Security policies](https://developers.cloudflare.com/page-shield/policies/) can be created and applied to add an additional level of security that helps detect and mitigate certain types of attacks, including:\n\n* Content/code injection\n* Cross-site scripting (XSS)\n* Embedding malicious resources\n* Malicious iframes (clickjacking)\n\nProducts: [Page Shield](https://developers.cloudflare.com/page-shield/)\n\n##### Data exfiltration\n\nData exfiltration is the process of acquiring sensitive data through malicious tactics or through misconfigured services. Cloudflare Sensitive Data Detection addresses common data loss threats. Within the WAF, these rules monitor the download of specific sensitive data â€” for example, financial and personally identifiable information. Specific patterns of sensitive data are matched upon and logged. Sensitive data detection is also integrated with API Shield so customers are alerted on any API responses returning sensitive data matches.\n\nProducts: [WAF - Sensitive Data Detection](https://developers.cloudflare.com/waf/managed-rules/)\n\n##### Credential stuffing\n\nCredential stuffing is a cyberattack in which credentials obtained from a data breach on one service are used to attempt to log in to another unrelated service. Usually, automation tools or scripting are used to loop through a vast number of stolen credentials, sometimes augmented with additional data in the hopes of achieving account takeover.\n\nCloudflare Bot Management can be used to detect potentially malicious bots. Cloudflare challenges can also be used to challenge suspect requests and stop automated attempts to gain access. WAF policies can be used with specific request criteria to prevent attacks. Additionally, Cloudflareâ€™s WAF and Exposed Credentials Check managed ruleset can be used to detect compromised credentials being used in auth requests. Rate limiting can also throttle requests and effectiveness of malicious credential stuffing techniques.\n\nProducts: [Bot Management](https://developers.cloudflare.com/bots/), [WAF](https://developers.cloudflare.com/waf/), [Rate Limiting](https://developers.cloudflare.com/waf/rate-limiting-rules/)\n\n##### Brute force attacks\n\nBrute force attacks attempt to guess passwords or clues, using random characters sometimes combined with common password suggestions. Usually, automation tools or scripting are used to loop through a vast number of possibilities in a short amount of time.\n\nCloudflare Bot Management can be used to detect potentially malicious bots. Cloudflare challenges can also be used to challenge suspect requests and stop automated brute force attacks. WAF and rate limiting policies can be used with specific request criteria to apply granular policies on application login pages to block or throttle traffic.\n\nProducts: [Bot Management](https://developers.cloudflare.com/bots/), [WAF](https://developers.cloudflare.com/waf/), [Rate Limiting](https://developers.cloudflare.com/waf/rate-limiting-rules/)\n\n##### Credit card skimming\n\nCredit card skimming is a fraudulent method to skim payment information from websites. Page Shield can be used to detect clients using malicious JavaScript libraries or making connections to known malicious domains or URLs. Page Shield will also detect changes to files/code being used on a site and give a JS Integrity Score to JavaScript files assessing whether the code is malicious. Content Security Policies (CSPs) can be deployed to enforce a positive security model. These capabilities can prevent compromised code from performing malicious behavior such as credit card skimming.\n\nProducts: [Page Shield](https://developers.cloudflare.com/page-shield/)\n\n##### Inventory hoarding\n\nInventory hoarding is when malicious bots are used to buy large quantities of products online, preventing legitimate consumers from purchasing them. This can cause many issues for businesses, including creating artificial scarcity, causing inflated prices, and disrupting access for legitimate customers. Cloudflare Bot Management can be used to detect potentially malicious bots. Cloudflare challenges can also be used to challenge suspect requests and stop automated processes. WAF policies can be used with specific request criteria to prevent attacks.\n\nProducts: [Bot management](https://developers.cloudflare.com/bots/), [WAF](https://developers.cloudflare.com/waf/)\n\n##### Fuzzing (vulnerability scanning)\n\n[Fuzzing](https://owasp.org/www-community/Fuzzing) is an automated testing method used by malicious actors that uses various combinations of data and patterns to inject invalid, malformed, or unexpected inputs into a system. The malicious user hopes to find defects and vulnerabilities that can then be exploited. Cloudflare WAF leverages machine learning to detect fuzzing based attempts to bypass security policies. The WAF attack score complements managed rules and highlights the likeliness of an attack.\n\nBot Management can detect potentially malicious bots by automating vulnerability scanning. With API Shield, customers can employ schema validation and sequence mitigation to prevent the automated scanning and fuzzing techniques with APIs.\n\nProducts: [WAF](https://developers.cloudflare.com/waf/), [Bot Management](https://developers.cloudflare.com/bots/), [API Shield](https://developers.cloudflare.com/api-shield/)\n\n##### Cross-Site Scripting (XSS) attacks\n\nCross-Site Scripting (XSS) attacks are a type of injection attack in which malicious scripts are injected into websites and then used by the end userâ€™s browser to access sensitive user information such as session tokens, cookies, and other information.\n\nCloudflare WAF leverages machine learning to detect attempts to bypass security policies and provides a specific WAF Attack Score for the likeliness the request is an XSS attack.\n\nProducts: [WAF](https://developers.cloudflare.com/waf/)\n\n##### Remote Code Execution (RCE) attacks\n\nIn a remote code execution (RCE) attack, an attacker runs malicious code on an organizationâ€™s computers or network. The ability to execute attacker-controlled code can be used for various purposes, including deploying additional malware or stealing sensitive data.\n\nCloudflare WAF leverages machine learning to detect attempts to bypass security policies and provides a specific WAF Attack Score for the likeliness the request is an RCE attack.\n\nProducts: [WAF](https://developers.cloudflare.com/waf/)\n\n##### SQL injection (SQLi) attacks\n\nStructured Query Language Injection (SQLi) is a code injection technique used to modify or retrieve data from SQL databases. By inserting specialized SQL statements into an entry field, an attacker is able to execute commands that allow for the retrieval of data from the database, the destruction of sensitive data, or other manipulative behaviors.\n\nCloudflare WAF leverages machine learning to detect attempts to bypass security policies and provides a specific WAF Attack Score for the likeliness the request is an SQLi attack.\n\nProducts: [WAF](https://developers.cloudflare.com/waf/)\n\nMalware can refer to viruses, worms, trojans, ransomware, spyware, adware, and other types of harmful software. A key distinction of malware is that it needs to be intentionally malicious; any software that unintentionally causes harm is not considered to be malware.\n\nWhen Uploaded Content Scanning is enabled, content scanning attempts to detect items such as uploaded files, and scans them for malicious signatures like malware. The scan results, along with additional metadata, are exposed as fields available in WAF custom rules, allowing customers to implement fine-grained mitigation rules.\n\nProducts: [WAF - Uploaded Content Scanning](https://developers.cloudflare.com/waf/detections/malicious-uploads/)\n\n#### Cloudflare application security products\n\nThis document has covered some common attacks and Cloudflare products used to detect and mitigate respective threats. Below we highlight and provide some additional details on each product across Cloudflareâ€™s application and network security portfolio.\n\n##### Security Analytics\n\nSecurity Analytics brings together all of Cloudflareâ€™s security detection capabilities within one dashboard. Customers can get a quick view and insight on mitigated and unmitigated traffic, attack traffic, bot traffic, malicious content upload attempts, and details around rate limiting analysis and account takeover analysis. Right from the dashboard displaying detected threats, with the click of a button customers can take action to put in place policies to mitigate.\n\n![All security detection can be seen from a single dashboard.](https://developers.cloudflare.com/_astro/security-ref-arch-7.BelBfrod_1gNuws.svg)\n\n##### Web Application Firewall (WAF)\n\nUsing Cloudflare [WAF](https://developers.cloudflare.com/waf/), customers can deploy custom rules based on very granular request criteria to mitigate specific threats or to block requests with certain HTTP anomalies. In addition, customers can deploy Cloudflare managed rules to mitigate zero-day attacks, common OWASP Top 10 attacks, requests using known leaked credentials, and requests extracting sensitive data.\n\n[WAF Managed Rules](https://developers.cloudflare.com/waf/managed-rules/) allow customers to deploy pre-configured managed rulesets that provide immediate protection against:\n\n* Zero-day vulnerabilities\n* Top 10 attack techniques\n* Use of stolen/exposed credentials\n* Extraction of sensitive data\n\n[Rate limiting](https://developers.cloudflare.com/waf/rate-limiting-rules/) can be used to mitigate various attacks, including volumetric attacks, credential stuffing, web scraping, and DoS attacks. Cloudflare rate limiting allows customers to define rate limits for requests matching an expression, and the action to perform when those rate limits are reached. Rate limiting can be granular based on specific request or header criteria and can also be based on sessions or API tokens. Customers can configure actions including logging, blocking, and challenges for when the specified rate is exceeded.\n\nCustomers can also configure which request criteria is used as a counter for determining when to throttle or block after a limit is exceeded. Customers can implement two different behaviors for rate limiting:\n\n1. **Block for the selected duration**. Once the rate is exceeded, the WAF will block all requests during the selected duration before the counter is reset.\n\n![All actions are blocked once the rate limit is reached.](https://developers.cloudflare.com/_astro/security-ref-arch-8.DyW4Rkuf_ZsTNBh.svg)\n\n1. **Throttle requests over the maximum configured rate**. The WAF will block any requests exceeding the configured rate, and the remaining requests will be allowed. The analogy for this behavior is a sliding window effect.\n\n![All security detection can be seen from a single dashboard.](https://developers.cloudflare.com/_astro/security-ref-arch-9.CXEx1mEx_2pFTXG.svg)\n\nThe Cloudflare [HTTP DDoS Attack Protection](https://developers.cloudflare.com/ddos-protection/managed-rulesets/http/) managed ruleset is a set of pre-configured rules used to match known DDoS attack vectors at layer 7 (application layer) on the Cloudflare global network. The rules match known attack patterns and tools, suspicious patterns, protocol violations, requests causing large amounts of origin errors, excessive traffic hitting the origin/cache, and additional attack vectors at the application layer. Cloudflare updates the list of rules in the managed ruleset on a regular basis.\n\n[API Shield](https://developers.cloudflare.com/api-shield/) is Cloudflareâ€™s API management and security product. API Shield delivers visibility via API discovery and analytics, provides endpoint management, implements a positive security model, and prevents API abuse.\n\n![All security detection can be seen from a single dashboard.](https://developers.cloudflare.com/_astro/security-ref-arch-10.B6IOqcpe_ZJaA5p.svg)\n\nAPI Gatewayâ€™s API Discovery is used to learn all API endpoints in a customerâ€™s environment using machine learning. After this step, customers can save endpoints to Endpoint Management so additional API performance and error information can be collected and security policies can be applied.\n\nCustomers can enable a positive security model using mTLS, JWT validation, and schema validation and protect against additional API abuse with rate limiting and volumetric abuse protection as well as sequence mitigation and GraphQL protections.\n\n![API Shield has many stages, discovery, review, using a positive security model, abuse protection, data protection and endpoint management/monitoring.](https://developers.cloudflare.com/_astro/security-ref-arch-11.CCbosnqv_QMJd4.svg)\n\n[Bot Management](https://developers.cloudflare.com/bots/) is used to mitigate various malicious activities, including web scraping, price scraping, inventory hoarding, and credential stuffing. Cloudflare has multi-layered bot mitigation capabilities that include heuristics, machine learning, anomaly detection, and JS fingerprinting. Bot management also assigns a bot score to every request. WAF rules can be created around bot scores to create very granular security policies.\n\n![Bot management can filter good and bad bots.](https://developers.cloudflare.com/_astro/security-ref-arch-12.8OEt5sGB_1NPN6C.svg)\n\nAdditionally, Cloudflare can take the action of challenging clients if it suspects undesired bot activity. Cloudflare offers its [challenge](https://developers.cloudflare.com/cloudflare-challenges/) platform where the appropriate type of challenge is dynamically chosen based on the characteristics of a request. This helps avoid CAPTCHAs, which result in a poor customer experience.\n\nDepending on the characteristics of a request, Cloudflare will choose an appropriate type of challenge, which may include but is not limited to:\n\n* A non-interactive challenge page (similar to the current JS Challenge).\n* A custom interactive challenge (such as clicking a button).\n* Private Access Tokens (using recent Apple operating systems).\n\nWith [Turnstile](https://developers.cloudflare.com/turnstile/), Cloudflare has completely moved away from CAPTCHA. Turnstile is Cloudflareâ€™s smart CAPTCHA alternative. It can be embedded into any website without sending traffic through Cloudflare and works without showing visitors a CAPTCHA. Turnstile allows you to run challenges anywhere on your site in a less intrusive way and uses APIs to communicate with Cloudflareâ€™s Managed Challenge platform.\n\n![Turnstile can be deployed to totally avoid presenting users with a CAPTCHA.](https://developers.cloudflare.com/_astro/security-ref-arch-13.Dw5VEN0r_MRCY7.svg)\n\n[Page Shield](https://developers.cloudflare.com/page-shield/) ensures the safety of website visitorsâ€™ browser environment and protects against client-side attacks like Magecart. By using a Content Security Policy (CSP) deployed with a report-only directive to collect information from the browser, Page Shield tracks loaded resources like scripts and detects new resources or connections being made by the browser. Additionally, Page Shield alerts customers if it detects scripts from malicious domains or URLs â€” or connections being made from the browser to malicious domains or URLs.\n\nPage Shield can download JavaScript source files and run them through a machine learning classifier to identify malicious behavior and activity; the result is a JS Integrity Score designating if the JavaScript file is malicious.\n\nCloudflareâ€™s [SSL/TLS](https://developers.cloudflare.com/ssl/) provides a number of features to meet customer encryption requirements and certificate management needs. An SSL/TLS certificate is what enables websites and applications to establish secure connections. With SSL/TLS, a client â€” such as a browser â€” can verify the authenticity and integrity of the server it is connecting with, and use encryption to exchange information.\n\nCloudflareâ€™s global network is at the core of several products and services that Cloudflare offers. In terms of SSL/TLS, this means instead of only one certificate, there can actually be two certificates involved in a single request: an edge certificate and an origin certificate.\n\n![SSL/TLS can be used for both Cloudflare to user, and origin server to Cloudflare security.](https://developers.cloudflare.com/_astro/security-ref-arch-14.JS7QlPBw_Z2lNlqq.svg)\n\nEdge certificates are presented to clients visiting the customerâ€™s website or application. Origin certificates guarantee the security and authentication on the other side of the network, between Cloudflare and the origin server of the customer's website or application. [SSL/TLS encryption modes](https://developers.cloudflare.com/ssl/origin-configuration/ssl-modes/) control whether and how Cloudflare will use both these certificates, and you can choose between different modes.\n\nCustomers can also enable [mutual Transport Layer Security (mTLS)](https://developers.cloudflare.com/ssl/client-certificates/enable-mtls/) for hostnames and API endpoints to bolster security for authentication, enforcing that only devices with valid certificates can gain access. Additional security features like [Authenticated Origin Pulls](https://developers.cloudflare.com/ssl/origin-configuration/authenticated-origin-pull/) can be configured to help ensure requests to the origin server come from the Cloudflare network. [Keyless SSL](https://developers.cloudflare.com/ssl/keyless-ssl/) allows security-conscious clients to upload their own custom certificates and benefit from Cloudflare, but without exposing their TLS private keys. With [Cloudflare for SaaS](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/), customers can also issue and validate certificates for their own customers.\n\n##### Security Center\n\n[Cloudflare Security Center](https://developers.cloudflare.com/security-center/) offers attack surface management (ASM) that inventories IT assets, enumerates potential security issues, controls phishing and spoofing risks, and enables security teams to investigate and mitigate threats in a few clicks. The Security Center is a great starting point for security analysts to get a global view of all potential issues across all applications/domains.\n\nKey capabilities offered:\n\n* Inventory and review IT infrastructure assets like domains, ASNs, and IPs.\n* Manage an always up-to-date list of misconfigurations and risks in Cloudflare IT assets.\n* Query threat data gathered from the Cloudflare network to investigate and respond to security risks.\n* Gain full control over who sends email on your organization's behalf with DMARC Management.\n\n##### Cloudflare for SaaS\n\nIf you build and host your own SaaS product offering, then [Cloudflare for SaaS](https://developers.cloudflare.com/cloudflare-for-platforms/) might be of interest. It allows customers to extend the security and performance benefits of Cloudflareâ€™s network to their customers via their own custom or vanity domains. Cloudflare for SaaS offers multiple configuration options. In the below diagram, custom hostnames are routed to a default origin server called â€œfallback originâ€.\n\n![Bring Cloudflare security to customer domains using your SaaS application.](https://developers.cloudflare.com/_astro/security-ref-arch-15.BuEBz4JW_UYXfL.svg)\n\n#### Cloudflare network security products\n\n[Magic Transit](https://developers.cloudflare.com/magic-transit/) protects entire IP subnets from DDoS attacks, providing for sub-second threat detection while also accelerating network traffic. It uses Cloudflareâ€™s global network to mitigate attacks, employing standards-based networking protocols like BGP, GRE, and IPsec for routing and encapsulation.\n\nAll network assets, whether on-premises or in private or public-hosted cloud environments, can easily be protected by sitting behind and being advertised from the Cloudflare network providing over 405 Tbps network capacity.\n\n![Magic Transit can secure your private network links.](https://developers.cloudflare.com/_astro/security-ref-arch-16.D6MVHn2o_Z1anBNe.svg)\n\nWith [Magic WAN](https://developers.cloudflare.com/magic-wan/), customers can securely connect any traffic source â€” data centers, offices, devices, cloud properties â€” to Cloudflareâ€™s network and configure routing policies to get the bits where they need to go. Magic WAN supports a variety of on-ramps, including anycast GRE and IPsec tunnels, Cloudflare Network Interconnect, Cloudflare Tunnel, WARP, and a variety of network on-ramp partners. Magic WAN can help end reliance on traditional SD-WAN appliances and securely connect users, offices, data centers, and hybrid cloud over the Cloudflare global network without relying on vendor-specific hardware or software.\n\n[Magic Firewall](https://developers.cloudflare.com/magic-firewall/) is Cloudflareâ€™s firewall-as-a-service solution delivered from Cloudflareâ€™s global network and is integrated with Magic Transit and Magic WAN. It allows for enforcing consistent network security policies across customersâ€™ entire WAN, including headquarters, branch offices, and virtual private clouds. Customers can deploy granular rules that globally filter on protocol, port, IP addresses, packet length, and bit field match.\n\n##### Magic Network Monitoring\n\n[Magic Network Monitoring](https://developers.cloudflare.com/magic-network-monitoring/) is a cloud network flow monitoring solution that gives customers end-to-end network traffic visibility, DDoS attack type identification, and volumetric traffic alerts. When a DDoS attack is detected, an alert can be received via email, webhook, or PagerDuty.\n\n[Spectrum](https://developers.cloudflare.com/spectrum/) is a reverse proxy product that extends the benefits of Cloudflare to all TCP/UDP applications providing L4 DDoS protection. Spectrum also provides an IP firewall allowing customers to deny IPs or IP ranges to granularly control traffic to application servers. Customers can also configure rules to block visitors from a specified country or even an Autonomous System Number (ASN).\n\n### Protecting private resources\n\nPrivate resources typically contain highly sensitive, company confidential information and either by way of laws and regulations, or by the nature of the confidentiality of the data, access to them is much more restricted. Traditionally, private applications were only accessible on private networks in company buildings that users had to have physical access to. But as we all know today, access to private resources needs to take place from a wide range of locations, and paradoxically, private applications can live in very public locations. Most SaaS applications are exposed to the public Internet.\n\nThe following are typical attributes of private resources:\n\n* Users have been pre-authorized and provisioned. They can't just sign up. They need to be given specific access to the resource either directly or via access control mechanisms such as certificates, group membership, or role assignment.\n* Network access to a self-hosted resource is typically over-managed, private network routes and not accessible via the general Internet.\n* Private resources that live in data centers (physical or virtual) and are connected to networks that are hosted and managed by the business, which are either on-premises or virtual private networks running in public cloud infrastructure.\n\nAs mentioned, traditional access to private resources required physical access to the network by being in the office connected via Ethernet. As remote access needs increased, companies installed on-premises VPN servers that allowed users and devices to \"dial in\" to these private networks. Many applications have left these private networks and instead migrated to SaaS applications or are hosted in public cloud infrastructure. This traditional approach has become unmanageable and costly, with a variety of technologies providing network connectivity and access control.\n\nAnother important thing to note is that many of the services used for securing and providing connectivity for public resources can also be used for private resources. The most obvious here is Magic WAN and Magic Firewall. Customers also use our WAF in front of privately hosted applications that are only accessible through private networks. The idea is that even if access to an application is only from trusted private connections, it is still possible for an attacker to compromise what seems to be a trusted device; therefore, application injection attacks and other vulnerabilities can be exploited by devices with existing trusted network access. This is exactly in line with the idea of a Zero Trust security program. Read more about the approaches to Zero Trust using a SASE platform in our [SASE reference architecture](https://developers.cloudflare.com/reference-architecture/architectures/sase/).\n\nAs we describe the following Cloudflare services, you will learn how the Cloudflare network and our methods of connecting it to your own private networks provides greater security, flexibility, and a more centralized control plane for access to private resources. The following diagram illustrates the sort of environment that represents a typical customer's private infrastructure.\n\n![Cloudflare's SASE platform can protect users and devices no matter where in your enterprise network, or not, they reside.](https://developers.cloudflare.com/_astro/security-ref-arch-18.D5ODORV0_ZNkzzQ.svg)\n\nProtecting internal resources can be broken down into the following areas.\n\n* Securing connectivity between the user and the application/network.\n* Identity systems providing authentication and maintaining user identities and group membership.\n* Policies controlling user access to applications/data.\n* Data protection controls to identify and protect sensitive and confidential data.\n* Protecting users and devices from attacks (malware, phishing, etc.) that originate from access to the Internet.\n* Operational visibility to IT and security teams.\n\n#### Securing connectivity to private resources\n\nMany privately hosted applications and networks do not have direct connectivity to the Internet. As mentioned previously, access traditionally has been enabled by one of two methods. One is when users connect physically to the same networks the private resources reside on, i.e. walking into the office and connecting to the office WiFi. The other is creating a virtual private network (VPN) connection over the Internet and \"dialing in\" to the private company network.\n\nHowever, the need today is still the same. You have private networks with private applications â€” and remote users need access. You should regard Cloudflare as your new enterprise network, where all authorized users (employees, contractors, partners) can connect to any private application from anywhere. This means your network topology will feature Cloudflare in the middle, providing connectivity from all networks to each other.\n\n![Cloudflare's SASE platform can also connect a wide variety of networks together into one larger, new corporate network.](https://developers.cloudflare.com/_astro/security-ref-arch-19.DZCNQ04z_Z1osvwt.svg)\n\nIn the above diagram you can see a variety of private networks and end user devices connected to Cloudflare, which then facilitates the routing and access controls between those networks, and therefore the applications and other resources. This is often regarded as East to West traffic. Because traffic originates from, and is destined for, a privately managed network.\n\nBecause all network traffic routes through Cloudflare, security controls are defined and apply to all traffic as it flows between networks. As long as a network, device, or user is connected to Cloudflare, you can identify it and apply policy. It also means things like data protection can be simplified â€” one single rule can be implemented to detect the transfer of and access to sensitive data and can be applied across the entire network with ease.\n\nExisting private infrastructure can be complex. Cloudflare provides a variety of methods by which businesses can connect their networks and user devices into this new enterprise network. We often call these methods \"on-ramps,\" which describes how traffic for a specific network or device is routed into Cloudflare. The following table outlines these different methods.\n\n| Method | Description | Common Use |\n| - | - | - |\n| [Magic WAN](https://developers.cloudflare.com/magic-wan/) | IPsec or GRE tunnel from networking devices to Cloudflare, routing entire network traffic. | Connecting existing network routers to Cloudflare. Allowing all traffic into and out of the network to go through Cloudflare. |\n| [Magic WAN Connector](https://developers.cloudflare.com/magic-wan/configuration/connector/) | Appliance-based IPsec or GRE tunnel from networking devices to Cloudflare, routing entire network traffic. | Uses the same technology as Magic WAN; however, instead of using existing networking devices, a dedicated appliance or virtual machine is used â€” the Magic WAN Connector. |\n| [cloudflared](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/) | Software agent deployed on servers or alongside services like Kubernetes for creating a tunnel for incoming connections to private applications or networks. | IT admins or application owners can easily install this tunnel software to expose their application to the Cloudflare network. |\n| [WARP Connector](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/private-net/warp-connector/) | Software agent deployed on servers for creating a tunnel for incoming and outgoing connections to private applications or networks. | Similar to cloudflared, but supports East to West traffic and is often used in place of Magic WAN when there is no ability to create an IPsec tunnel from existing devices. |\n| [WARP Desktop Agent](https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/warp/) | Software agent deployed on user devices, creating a tunnel for traffic to and from private applications and networks. | Connecting end user devices like phones and laptops to be part of the Cloudflare network. |\n| [Cloudflare Network Interconnect](https://www.cloudflare.com/network-services/products/network-interconnect/) | Direct connection between your physical networks and Cloudflare. | When your applications live in the same data centers we operate in, we can connect those networks directly to Cloudflare. |\n\nFor more details on how these methods work, please refer to our [SASE reference architecture](https://developers.cloudflare.com/reference-architecture/architectures/sase/).\n\n#### User connectivity\n\nAll the above methods are for connecting networks and applications to Cloudflare, and some users will be on devices connected directly to those networks. They might be in the corporate headquarters or working from a branch or retail location. However, many users are working from home, sitting in a coffee shop, or working on a plane. Cloudflare provides the following methods for connecting users to Cloudflare. This is the same concept of installing a VPN client on a user device, with the difference that the connection is made to our global network and not to your own VPN applicances.\n\nFor the best user experience and the greatest degree of access control, we recommend deploying our [device agent](https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/warp/) to devices. Supported on Windows, macOS, Linux, iOS, and Android, the agent performs two main roles. First, it routes all traffic from the device to Cloudflare, allowing for access to all your existing connected private networks and applications. Second, the agent provides device posture information such as operating system version, encrypted storage status, and other details. This information is then associated with the authenticated user and can be used as part of access control policy. The agent can be installed manually, but most enterprises deploy it using their device management (MDM) software.\n\nThere may be instances where you cannot install software on end user devices. In those instances, Cloudflare provides a proxy endpoint where browsers can be configured to on-ramp their traffic to Cloudflare. This is either done manually by the end user, or by using [automated browser configuration](https://developers.cloudflare.com/cloudflare-one/networks/resolvers-and-proxies/proxy-endpoints/) files.\n\n##### Isolated browser\n\nIn some situations, you have no ability to modify the end device in any way. In those instances we provide the ability for a user to access a browser that runs directly on our edge network. This [browser isolation service](https://developers.cloudflare.com/cloudflare-one/remote-browser-isolation/) requires users to point their browser at a Cloudflare URL, which in turn runs a headless, secure browser on one of our edge servers. Secure vectors are then used over HTTPS and WebRTC connections. For more information, refer to [this architecture](https://developers.cloudflare.com/reference-architecture/diagrams/sase/sase-clientless-access-private-dns/).\n\n#### Integrating identity systems\n\nUsers cannot just sign up and access your private resources; their identity and associated credentials are typically created and managed in an enterprise identity provider (IdP). Cloudflare integrates with both [enterprise and consumer-based identity services](https://developers.cloudflare.com/cloudflare-one/integrations/identity-providers/), as well as providing a simple one-time password (OTP) via email service for when you have a need to authenticate a user with only an email address.\n\nCloudflare supports integrations with multiple identity providers, including of the same type. So if you manage an Okta instance for your employees, but may have acquired another company with its own Okta instance, both can be integrated with Cloudflare. Cloudflare then acts as a proxy for the SSO process. Applications are configured using SAML and OIDC to use Cloudflare for authentication and then Cloudflare in turn redirects users through the authentication flow of an integrated IdP. Group information can also be synchronized via SCIM into Cloudflare to be used in access control policies.\n\n![Many different IdP's can be integrated, from Google, Microsoft and Github as well as any SAML or OAuth system.](https://developers.cloudflare.com/_astro/security-ref-arch-20.CGOXN25S_ixsmT.svg)\n\nThis centralization of identity into a common access control layer allows you to build clearly defined and easily managed policies that can be applied across the entire network. If you then decide to migrate from one IdP to another vendor, you only need to change one identity integration with Cloudflare, and all your downstream applications and existing policies will continue to work.\n\nThe focus on this document is about security, and now that applications, devices, identities, and networks are all connected, every request to and from any resource on the network, and also to the Internet, is now subject to Cloudflare's access control and firewall services. There are two services that apply policy-based controls to traffic.\n\n* **Zero Trust Network Access**: Our [Access](https://developers.cloudflare.com/cloudflare-one/access-controls/policies/) product manages access to specific networks or applications that are deemed private. It enforces authentication either for users via an existing identity provider, or for other applications via service tokens or mTLS.\n* **Secure Web Gateway**: Our [Gateway](https://developers.cloudflare.com/cloudflare-one/traffic-policies/) product is used to analyze traffic and apply policies, no matter the destination. It is most commonly used to allow, block, or isolate traffic that is destined for the Internet. This can be used to apply access controls to SaaS applications, but any traffic flowing through Cloudflare can be inspected and acted upon by Gateway. Therefore it can also be used to add additional access controls to non-Internet, private tunneled applications.\n\n![Cloudflare's ZTNA and SWG services can be combined to secure both private and Internet access.](https://developers.cloudflare.com/_astro/security-ref-arch-21.CYH5oM7H_14D6gt.svg)\n\nBoth of these technologies can be combined to ensure appropriate access to private applications. For users with our [device agent](https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/warp/) installed, the policies can also include device-level requirements. When combined with identity data, policies such as the following can be written to control access to, for example, an internal database administration tool.\n\n* User must have authenticated via the company IdP, and used MFA as part of the authentication\n* User must be in the \"Database Administrators\" group in the IdP\n* User device must have a Crowdstrike risk score above 70\n* User device must be on the very latest release of the operating system\n\nIt is possible to define access groups of users that can be applied across multiple policies. This allows IT and security administrators to create a single definition of what a secure administrator looks like, which is then reusable across many policies.\n\n![Policies can easily be written which define tight access groups to private resources.](https://developers.cloudflare.com/_astro/security-ref-arch-22.DQuxIF4A_1ABuvo.svg)\n\nAll traffic is flowing through Cloudflare, so therefore all data is flowing through Cloudflare. This allows you to apply data controls on that traffic. Typically, employees are allowed access to sensitive applications and data only on managed devices where the device agent installs Cloudflare certificates that allow Cloudflare to terminate SSL connections on our network. This in turn allows for inspection of the contents of HTTPS web traffic and policy can be written to manage and secure that data.\n\nCloudflare has a [data loss prevention](https://developers.cloudflare.com/cloudflare-one/data-loss-prevention/) (DLP) service that defines profiles that can be used to identify sensitive data. These profiles are then used in Gateway policies to match specific traffic and either allow, block, or isolate it.\n\nThe same DLP profiles can also be used in our Cloud Access Security Broker (CASB) service, where Cloudflare is integrated via APIs to SaaS applications. We then scan the storage and configuration of those applications looking for misconfiguration or sensitive data that's publicly exposed.\n\n#### Securing Internet access\n\nA lot of this section has focused on protecting access to private networks and applications, but a business must also protect their employees and their devices. Our [secure web gateway](https://developers.cloudflare.com/cloudflare-one/traffic-policies/) (SWG) service sits between users connected to Cloudflare and any resource they are attempting to access, both public and private. Policies can be written to prevent employees from accessing high-risk websites or known sites that distribute malware. Policies can also be written to mitigate phishing attacks by blocking access to domains and websites known to be part of phishing campaigns. Protecting users and their devices from Internet threats also reduces associated risks of those same users and devices accessing private resources.\n\nAnother critical private resource to secure is email. This is often one of the most private of all resources, as it contains confidential communications across your entire organization. It's also a common attack surface, mostly by way of phishing attacks. [Email security](https://www.cloudflare.com/zero-trust/products/email-security/) (CES) examines all emails in your employee's inboxes and detects spoofed, malicious, or suspicious emails and can be configured to act accordingly. CES can be integrated by changing your domain MX records and redirecting all email via Cloudflare. Another option, for Microsoft and Google, is to integrate via API and inspect email already in a userâ€™s inbox. For suspicious emails, links in the email are rewritten to leverage Cloudflare's [browser isolation service](https://developers.cloudflare.com/cloudflare-one/remote-browser-isolation/) so that when a user heads to that website, their local machine is protected against any malicious code that might be running in the browser.\n\n![Cloud email security filters unwanted email traffic from your users inboxes.](https://developers.cloudflare.com/_astro/security-ref-arch-23.DIu_T4WS_ZFJOVf.svg)\n\nNo matter if your resources are private or public, visibility into what's going on is critical. The Cloudflare administrative dashboard has a wide range of built-in dashboards and reports to get a quick overview. Notifications can also be configured to inform admins, either via email or services such as PagerDuty, of important events.\n\nAll Cloudflare services provide detailed logs into activity. These logs can also be exported into other security monitoring or SIEM tools via our log shipping integrations. There are built-in integrations for common services such as AWS, Datadog, Splunk, New Relic, and Sumo Logic. But we also support generic distribution of logs into Azure and Google storage as well as Amazon S3 and S3-compatible services.\n\nIn summary, the following diagram details how Cloudflare's SASE services can connect and secure access to your private resources. For a more in-depth review, please read our [SASE reference architecture](https://developers.cloudflare.com/reference-architecture/architectures/sase/).\n\n![Cloud email security filters unwanted email traffic from your users inboxes.](https://developers.cloudflare.com/_astro/security-ref-arch-24.DyfzYaJH_1OT1sz.svg)\n\n## Developer platform\n\nMany of Cloudflare's security services are built on a highly optimized serverless compute platform based on [V8 Isolates](https://blog.cloudflare.com/cloud-computing-without-containers) which powers our developer platform. Like all our services, serverless compute workloads run on all servers in our global network. While our security services offer a wide range of features, customers always want the ultimate flexibility of writing their own custom solution. Customers therefore can use Cloudflare Workers and its accompanying services (R2, D1, KV, Queues) to interact with network traffic as it flows to and from their resources, as well as implementing complex security logic.\n\nThe following use cases show how our customersâ€™ security teams have used our [developer platform](https://workers.cloudflare.com/):\n\n* In our ZTNA service, Cloudflare Access, when a request is made to access a private resource, that request can include a call to a Cloudflare Worker, passing in everything known about the user. Custom business logic can then be implemented to determine access. For example:\n\n* Only allow access during employee working hours. Check via API calls to employee systems.\n  * Allow access only if an incident has been declared in PagerDuty.\n\n* Implement honeypots for bots: Because Workers can be attached to routes of any Cloudflare-protected resource, you can examine the bot score of a request and then redirect or modify the request if you suspect it's not legitimate traffic. For example, execute the request but modify the response to redact information or change values to protect data.\n\n* Write complex web application firewall (WAF) type rules: As described above, our WAF is very powerful for protecting your public-facing applications. But with Workers, you can write incredibly complex rules based on information provided in the [IncomingRequestCfProperties](https://developers.cloudflare.com/workers/runtime-apis/request/#incomingrequestcfproperties), which expose metadata for every request. These properties contain extensive information and can be expressed as code for effective rule implementation.\n\n* Enhance traffic with extra security information: Your downstream application may have other security products in front of it, or maybe provides other security if certain HTTP headers exist. Using Workers, you can enhance any requests to the application and add in headers to help the downstream application implement greater security controls.\n\n* Write your own authentication service: Some customers have extreme requirements, and the power of Workers allows you, as we have with our own product suite, to write entire authentication stacks. One such customer [did just this](https://www.cloudflare.com/case-studies/epam/). While this isn't common, it's an example of the flexibility of using Cloudflare. You can mix complex code that you write with our own products to fine-tune exactly the right security outcome.\n\nUsing Workers for implementing some of your security controls has the following advantages:\n\n* **Advanced logic and testability**: Enables the implementation of highly sophisticated logic that's easily testable through unit tests.\n* **Accessibility to developers**: Security features are accessible to a broader audience due to native support in languages like JavaScript, TypeScript, Rust, and Python, catering to developers' familiarity.\n* **Granularity and flexibility**: Offers unparalleled granularity, with support for regex, JSON parsing, and easy access to request/response headers and bodies enriched by Cloudflare. Policies can be designed based on any feature of the request/response.\n* **Response modification**: While traditional security stacks often focus solely on requests, Workers empowers effortless modification of responses. For instance, verbose error messages can be obscured to enhance security.\n* **Implement DevSecOps lifecycles**: Workers makes it very easy to adhere to DevSecOps best practices like version control, code audits, automated tests, gradual roll-outs, and rollback capabilities.\n\nHowever, you should also consider the following:\n\n* **Cost**: By adding Workers into the request process, you will incur extra costs. However, this might be acceptable for the scenarios where the significant security outcome is highly beneficial.\n* **Latency**: While minimal, there will always be some impact on traffic latency because you are running your own logic on every request.\n* **Requires developer skill set**: This is a bit obvious, but worth mentioning. Using Workers requires a development team to create, test, and maintain whatever code is implemented.\n\nYou can review some examples of how our Workers platform can be used for [security](https://developers.cloudflare.com/workers/examples/?tags=Security) or [authentication](https://developers.cloudflare.com/workers/examples/?tags=Authentication) use cases.\n\nYou should now have a good understanding of the massive scale of the Cloudflare network, how it's secured and operated, and the broad range of services available to you for protecting your business assets. We have built the future of networking and security, and we invite you to consider using our services to better secure your business.\n\nIn summary, the benefits of using Cloudflare for your businessâ€™s security are:\n\n* Protect all your business assets, public or private.\n* Leverage a comprehensive range of security services on a single platform.\n* Rely on a massively scaled network with high performance and reliability.\n* Implement security controls once, in a single dashboard, and impact traffic from anywhere.\n* Empower DevSecOps teams with full API and Terraform support.\n\nWe have a very simple [self-service signup](https://dash.cloudflare.com/sign-up), where many of our services can be evaluated for free. If you wish to work with our expert team to evaluate Cloudflare, please [reach out](https://www.cloudflare.com/plans/enterprise/contact/).\n\n<page>\n---\ntitle: Evolving to a SASE architecture with Cloudflare Â· Cloudflare Reference\n  Architecture docs\ndescription: This reference architecture explains how organizations can work\n  towards a SASE architecture using Cloudflare.\nlastUpdated: 2025-12-02T17:49:01.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/reference-architecture/architectures/sase/\n  md: https://developers.cloudflare.com/reference-architecture/architectures/sase/index.md\n---\n\nDownload a [PDF version](https://developers.cloudflare.com/reference-architecture/static/cloudflare-evolving-to-a-sase-architecture.pdf) of this reference architecture.\n\nCloudflare One is a secure access service edge (SASE) platform that protects enterprise applications, users, devices, and networks. By progressively adopting Cloudflare One, organizations can move away from their patchwork of hardware appliances and other point solutions and instead consolidate security and networking capabilities on one unified control plane. Such network and security transformation helps address key challenges modern businesses face, including:\n\n* Securing access for any user to any resource with Zero Trust practices\n* Defending against cyber threats, including multi-channel phishing and ransomware attacks\n* Protecting data in order to comply with regulations and prevent leaks\n* Simplifying connectivity across offices, data centers, and cloud environments\n\nCloudflare One is built on Cloudflare's [connectivity cloud](https://www.cloudflare.com/connectivity-cloud/), â€‹â€‹a unified, intelligent platform of programmable cloud-native services that enable any-to-any connectivity between all networks (enterprise and Internet), cloud environments, applications, and users. It is one of the [largest global networks](https://www.cloudflare.com/network/), with data centers spanning [hundreds of cities worldwide](https://www.cloudflare.com/network/) and interconnection with over 13,000 network peers. It also has a greater presence in [core Internet exchanges](https://bgp.he.net/report/exchanges#_participants) than many other large technology companies.\n\nAs a result, Cloudflare operates within \\~50 ms of \\~95% of the world's Internet-connected population. And since all Cloudflare services are designed to run across every network location, all traffic is connected, inspected, and filtered close to the source for the best performance and consistent user experience.\n\nThis document describes a reference architecture for organizations working towards a SASE architecture, and shows how Cloudflare One enables such security and networking transformation.\n\n### Who is this document for and what will you learn?\n\nThis reference architecture is designed for IT or security professionals with some responsibility over or familiarity with their organization's existing infrastructure. It is useful to have some experience with technologies important to securing hybrid work, including identity providers (IdPs), user directories, single sign on (SSO), endpoint security or management (EPP, XDR, UEM, MDM), firewalls, routers, and point solutions like packet or content inspection hardware, threat prevention, and data loss prevention technologies.\n\nTo build a stronger baseline understanding of Cloudflare, we recommend the following resources:\n\n* What is Cloudflare? | [Website](https://www.cloudflare.com/what-is-cloudflare/) (5 minute read) or [video](https://youtu.be/XHvmX3FhTwU?feature=shared) (2 minutes)\n\n- Solution Brief: [Cloudflare One](https://cfl.re/SASE-SSE-platform-brief) (3 minute read)\n- Whitepaper: [Overview of Internet-Native SASE Architecture](https://cfl.re/internet-native-sase-architecture-whitepaper) (10 minute read)\n- Blog: [Zero Trust, SASE, and SSE: foundational concepts for your next-generation network](https://blog.cloudflare.com/zero-trust-sase-and-sse-foundational-concepts-for-your-next-generation-network/) (14 minute read)\n\nThose who read this reference architecture will learn:\n\n* How Cloudflare One protects an organization's employees, devices, applications, data, and networks\n* How Cloudflare One fits into your existing infrastructure, and how to approach migration to a SASE architecture\n* How to plan for deploying Cloudflare One\n\nWhile this document examines Cloudflare One at a technical level, it does not offer fine detail about every product in the platform. Instead, it looks at how all the services in Cloudflare One enable networking and network security to be consolidated on one architecture. Visit the [developer documentation](https://developers.cloudflare.com/) for further information specific to a product area or use case.\n\n## Disintegration of the traditional network perimeter\n\nTraditionally, most employees worked in an office and connected locally to the company network via Ethernet or Wi-Fi. Most business systems (e.g. file servers, printers, applications) were located on and accessible only from this internal network. Once connected, users would typically have broad access to local resources. A security perimeter was created around the network to protect against outsider threats, most of which came from the public Internet. The majority of business workloads were hosted on-premises and only accessible inside the network, with very little or no company data or applications existing on the Internet.\n\nHowever, three important trends created problems for this \"castle and moat\" approach to IT security:\n\n1. **Employees became more mobile**. Organizations increasingly embrace remote / hybrid work and support the use of personal (i.e. not company-owned) devices.\n2. **Cloud migration accelerated**. Organizations are moving applications, data, and infrastructure from expensive on-premises data centers to public or private cloud environments in order to improve flexibility, scalability, and cost-effectiveness.\n3. **Cyber threats evolved**. The above trends expand an organization's attack surface. For example, attack campaigns have become more sophisticated and persistent in exploiting multiple channels to infiltrate organizations, and cybercriminals face lower barriers to entry with the popularity of the \"cybercrime-as-a-service\" black market.\n\nTraditional perimeter-based security has struggled to adapt to these changes. In particular, extending the \"moat\" outwards has introduced operational complexity for administrators, poor experiences for users, and inconsistency in how security controls are applied across users and applications.\n\n![With many different methods to connect networks and filter/block traffic, managing access to company applications is costly and time consuming.](https://developers.cloudflare.com/_astro/cf1-ref-arch-1.DR89R8uB_Z1q6eem.svg)\n\nThe diagram above shows an example of this adapted perimeter-based approach, in which a mix of firewalls, WAN routers, and VPN concentrators are connected with dedicated WAN on-ramps consisting of MPLS circuits and/or leased lines. The diagram also demonstrates common problem areas. In an effort to centralize policy, organizations sometimes force all employee Internet traffic through their VPN infrastructure, which results in slow browsing and user complaints. Employees then seek workarounds â€” such as using non-approved devices â€” which increases their exposure to Internet-borne attacks when they work from home or on public Wi-Fi. In addition, IT teams are unable to respond quickly to changing business needs due to the complexity of their network infrastructure.\n\nSuch challenges are driving many organizations to prioritize goals like:\n\n* Accelerating business agility by supporting remote / hybrid work with secure any-to-any access\n* Improving productivity by simplifying policy management and by streamlining user experiences\n* Reducing cyber risk by protecting users and data from phishing, ransomware, and other threats across all channels\n* Consolidating visibility and controls across networking and security\n* Reducing costs by replacing expensive appliances and infrastructure (e.g. VPNs, hardware firewalls, and MPLS connections)\n\n## Understanding a SASE architecture\n\nIn recent years, [secure access service edge](https://www.cloudflare.com/learning/access-management/security-service-edge-sse/), or SASE, has emerged as an aspirational architecture to help achieve these goals. In a SASE architecture, network connectivity and security are unified on a single cloud platform and control plane for consistent visibility, control, and experiences from any user to any application.\n\nSASE platforms consist of networking and security services, all underpinned by supporting operational services and a policy engine:\n\n* Network services forward traffic from a variety of networks into a single global corporate network. These services provide capabilities like firewalling, routing, and load balancing.\n* Security services apply to traffic flowing over the network, allowing for filtering of certain types of traffic and control over who can access what.\n* Operational services provide platform-wide capabilities like logging, API access, and comprehensive Infrastructure-as-Code support through providers like Terraform.\n* A policy engine integrates across all services, allowing admins to define policies which are then applied across all the connected services.\n\n![Cloudflare's SASE cloud platform offers network, security, and operational services, as well as policy engine features, to provide zero trust connectivity between a variety of user identities, devices and access locations to customer applications, infrastructure and networks.](https://developers.cloudflare.com/_astro/cf1-ref-arch-2.BMHjAM9W_Z2qkFk1.svg)\n\n## Cloudflare One: single-vendor, single-network SASE\n\nMost organizations move towards a SASE architecture progressively rather than all at once, prioritizing key security and connectivity use cases and adopting services like [Zero Trust Network Access](https://www.cloudflare.com/learning/access-management/what-is-ztna/) (ZTNA) or [Secure Web Gateway](https://www.cloudflare.com/learning/access-management/what-is-a-secure-web-gateway/) (SWG). Some organizations choose to use SASE services from multiple vendors. For most organizations, however, the aspiration is to consolidate security with a single vendor, in order to achieve simplified management, comprehensive visibility, and consistent experiences.\n\n[Cloudflare One](https://www.cloudflare.com/cloudflare-one/) is a single-vendor SASE platform where all services are designed to run across all locations. All traffic is inspected closest to its source, which delivers consistent speed and scale everywhere. And thanks to composable and flexible on-ramps, traffic can be routed from any source to reach any destination.\n\nCloudflare's connectivity cloud also offers many other services that improve application performance and security, such as [API Gateway](https://www.cloudflare.com/learning/security/api/what-is-an-api-gateway/), [Web Application Firewall](https://www.cloudflare.com/learning/ddos/glossary/web-application-firewall-waf/), [Content Delivery](https://www.cloudflare.com/learning/cdn/what-is-a-cdn/), or [DDoS mitigation](https://www.cloudflare.com/learning/ddos/ddos-mitigation/), all of which can complement an organization's SASE architecture. For example, our Content Delivery Network (CDN) features can be used to improve the performance of a self hosted company intranet. Cloudflare's full range of services are illustrated below.\n\n![Cloudflare's anycast network allows provides services on all connected servers to enable secure connections on public and home networks and at corporate offices.](https://developers.cloudflare.com/_astro/cf1-ref-arch-4.Bjts0g1J_Z1wuo2t.svg)\n\n### Cloudflare's anycast network\n\nCloudflare's SASE platform benefits from our use of [anycast](https://www.cloudflare.com/learning/cdn/glossary/anycast-network/) technology. Anycast allows Cloudflare to announce the IP addresses of our services from every data center worldwide, so traffic is always routed to the Cloudflare data center closest to the source. This means traffic inspection, authentication, and policy enforcement take place close to the end user, leading to consistently high-quality experiences.\n\nUsing anycast ensures the Cloudflare network is well balanced. If there is a sudden increase in traffic on the network, the load can be distributed across multiple data centers â€“ which in turn, helps maintain consistent and reliable connectivity for users. Further, Cloudflare's large [network capacity](https://www.cloudflare.com/network/) and [AI/ML-optimized smart routing](https://blog.cloudflare.com/meet-traffic-manager/) also help ensure that performance is constantly optimized.\n\nBy contrast, many other SASE providers use Unicast routing in which a single IP address is associated with a single server and/or data center. In many such architectures, a single IP address is then associated with a specific application, which means requests to access that application may have very different network routing experiences depending on how far that traffic needs to travel. For example, performance may be excellent for employees working in the office next to the application's servers, but poor for remote employees or those working overseas. Unicast also complicates scaling traffic loads â€” that single service location must ramp up resources when load increases, whereas anycast networks can share traffic across many data centers and geographies.\n\n![Cloudflare's anycast network ensures fast and reliable connectivity, whereas Unicast routing often sends all traffic to a single IP address, resulting in slower and failure prone connections.](https://developers.cloudflare.com/_astro/cf1-ref-arch-5.DVAtCA4Y_1Fsa2c.svg)\n\n## Deploying a SASE architecture with Cloudflare\n\nTo understand how SASE fits into an organization's IT infrastructure, see the diagram below, which maps out all the common components of said infrastructure. Subsequent sections of this guide will add to the diagram, showing where each part of Cloudflare's SASE platform fits in.\n\n![Typical enterprise IT infrastructure may consist of different physical locations, devices and data centers that require connectivity to multiple cloud and on-premises applications.](https://developers.cloudflare.com/_astro/cf1-ref-arch-6.CZw0spTE_ZNkzzQ.svg)\n\nIn the diagram's top half there are a variety of Internet resources (e.g. Facebook), SaaS applications (e.g. ServiceNow), and applications running in an [infrastructure-as-a-service (IaaS)](https://www.cloudflare.com/learning/cloud/what-is-iaas/) platform (e.g. AWS). This example organization has already deployed cloud based [identity providers](https://www.cloudflare.com/learning/access-management/what-is-an-identity-provider/) (IdP), [unified endpoint management](https://www.cloudflare.com/learning/security/glossary/what-is-endpoint/) (UEM) and endpoint protection platforms (EPP) as part of a Zero Trust initiative.\n\nIn the bottom half are a variety of users, devices, networks, and locations. Users work from a variety of locations: homes, headquarters and branch offices, airports, and others. The devices they use might be managed by the organization or may be personal devices. In addition to the cloud, applications run in a data center in the organization's headquarters and in a data center operators' colo facility ([Equinix](https://www.equinix.com/), in this example).\n\nA SASE architecture will define, secure, and streamline how each user and device will connect to the various resources in the diagram. Over the following sections, this guide will show ways to integrate Cloudflare One into the above infrastructure:\n\n* **Applications and services**: Placing access to private applications and services behind Cloudflare\n* **Networks**: Connecting entire networks to Cloudflare\n* **Forwarding device traffic**: Facilitating access to Cloudflare-protected resources from any device\n* **Verifying users and devices**: Identifying which users access requests come from, and which devices those users have\n\n### Connecting applications\n\nThis journey to a SASE architecture starts with an organization needing to provide remote access to non-Internet facing, internal-only web applications and services (e.g. SSH or RDP). Organizations typically deploy VPN appliances to connect users to the company network where the applications are hosted. However, many applications now live in cloud Infrastructure-as-a-Service platforms, where traditional VPN solutions are hard to configure. This often results in poor application and connectivity performance for users.\n\n#### Tunnels to self-hosted applications\n\n[Zero Trust Network Access](https://www.cloudflare.com/learning/access-management/what-is-ztna/) (ZTNA) is a SASE service that secures access to self-hosted applications and services. ZTNA functionality can be divided broadly into two categories: 1) establishing connectivity between Cloudflare's network and the environments where the applications are running, and 2) setting policies to define how users are able to access these applications. In this section, we first examine the former â€” how to connect apps to Cloudflare.\n\nConnectivity to self-hosted applications is facilitated through tunnels that are created and maintained by a software connector, [`cloudflared`](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/get-started/). `cloudflared` is a lightweight daemon installed in an organizations' infrastructure that creates a tunnel via an outbound connection to Cloudflare's global network. The connector can be installed in a variety of ways:\n\n* In the OS installed on the bare metal server\n* In the OS that is running in a virtualized environment\n* In a [container](https://hub.docker.com/r/cloudflare/cloudflared) running in a Docker or Kubernetes environment\n\n`cloudflared` runs on Windows, Linux, or macOS operating systems and creates an encrypted tunnel using QUIC, a modern protocol that uses UDP (instead of TCP) for fast tunnel performance and modern encryption standards. Generally speaking, there are two approaches for how users can deploy `cloudflared` in their environment:\n\n1. **On the same server and operating system where the application or service is running**. This is typically in high-risk or compliance deployments where organizations require independent tunnels per application. `cloudflared` consumes a small amount of CPU and RAM, so impact to server performance is marginal.\n2. **On a dedicated server(s) in the same network where the applications run**. This often takes the form of multiple containers in a Docker or Kubernetes environment.\n\n`cloudflared` manages multiple outbound connections back to Cloudflare and usually requires no changes to network firewalls. Those connections are spread across servers in more than one Cloudflare data center for reliability and failover. Traffic destined for a tunnel is forwarded to the connection that is geographically closest to the request, and if a `cloudflared` connection isn't responding, the tunnel will automatically failover to the next available.\n\nFor more control over the traffic routed through each tunnel connection, users can integrate with the Cloudflare [load balancing](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/routing-to-tunnel/public-load-balancers/) service. To ensure reliable local connectivity, organizations should deploy more than one instance of `cloudflared` across their application infrastructure. For example, with ten front-end web servers running in a Kubernetes cluster, you might deploy three kubernetes services [running `cloudflared` replicas](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/deployment-guides/kubernetes/).\n\n![Using cloudflared, multiple outbound connections are created back to Cloudflare across multiple data centers to improve overall performance and reliability.](https://developers.cloudflare.com/_astro/cf1-ref-arch-7.Dk3BnKM8_1nIUVR.svg)\n\nOnce tunnels have been established, there are two methods for how user traffic is forwarded to your application or service. Each method below is protected by policies managed by the ZTNA service that enforces authentication and access (which will be explored in further depth [later in this document](#secure-access-to-self-hosted-apps-and-services)).\n\n##### Public hostname\n\nEach public hostname is specific to an address, protocol, and port associated with a private application, allowing for narrow access to a specific service when there might be multiple applications running on the same host.\n\nFor example, organizations can define a public hostname (`mywebapp.domain.com`) to provide access to a web server running on `https://localhost:8080`, while ensuring no access to local Kubernetes services.\n\n* A hostname is created in a public DNS zone and all requests to that hostname are first routed to the Cloudflare network, inspected against configured security and access policies, before being routed through the tunnel to the secured private resource\n* Multiple hostnames can be defined per tunnel, with each hostname mapping to a single application (service address and port)\n* Support for HTTP/HTTPS protocols\n* Access to resources only requires a browser\n* When Cloudflare's device client is deployed on an user device, policies can leverage additional contextual signals (e.g. determining whether the device is managed or running the latest OS) in policy enforcement\n* For access to SSH/VNC services, Cloudflare renders an SSH/VNC terminal using webassembly in the browser\n\nApplications exposed this way receive all of the benefits of Cloudflare's leading DNS, CDN, and DDoS services as well as our web application firewall (WAF), API, and bot services, all without exposing application servers directly to the Internet.\n\n##### Private network\n\nIn some cases, users may want to leverage ZTNA policies to provide access to many applications on an entire private network. This allows for greater flexibility over the ways clients connect and how services are exposed. It also enables communication to resources over protocols other than HTTP. In this scenario, users specify the subnet for the private network they wish to be accessible via Cloudflare.\n\n* `cloudflared`, combined with Cloudflare device agent, provides access to private networks, allowing for any arbitrary L4 TCP, UDP or ICMP connections\n* One or many networks can be configured using CIDR notation (e.g. 172.21.0.16/28)\n* Access to resources on the private network requires the Cloudflare device agent to be installed on clients, and at least one Cloudflare Tunnel server on the connecting network\n\nFor both methods, it is important to note that `cloudflared` only proxies inbound traffic to a private application or network. It does not become a gateway or \"on-ramp\" back to Cloudflare for the network that it proxies inbound connections to. This means that if the web server starts its own connection to another Internet-based API, that connection will not be routed via Cloudflare Tunnel and will instead be routed via the host server's default route and gateway.\n\nThis is the desirable outcome in most network topologies, but there are some instances in which network services need to communicate directly with a remotely-connected user, or with services on other segmented networks.\n\nIf users require connections that originate from the server or network to be routed through Cloudflare, there are multiple on-ramps through which to achieve this, which will be explained further in the \"Connecting Networks\" section.\n\n#### SaaS applications\n\nSaaS applications are inherently always connected to and accessed via the public Internet. As a result, the aforementioned tunnel-and-app-connector approach does not apply. Instead, organizations with a SASE architecture inspect and enforce policies on Internet-bound SaaS traffic via a [secure web gateway](https://www.cloudflare.com/learning/access-management/what-is-a-secure-web-gateway/) (SWG), which serves as a cloud-native forward proxy.\n\nThe SWG includes policies that examine outbound traffic requests and inbound content responses to determine if the user, device, or network location has access to resources on the Internet. Organizations can use these policies to control access to approved SaaS applications, as well as detect and block the use of unapproved applications (also known as [shadow IT](https://www.cloudflare.com/learning/access-management/what-is-shadow-it/)).\n\nSome SaaS applications allow organizations to configure an IP address allowlist, which limits access to the application based on the source IP address of the request. With Cloudflare, organizations can obtain dedicated [egress IP](https://developers.cloudflare.com/cloudflare-one/traffic-policies/egress-policies/dedicated-egress-ips/) addresses, which can be used as the source address for all traffic leaving their network. When combined with an allowlist in a SaaS application, organizations can ensure that users are only able to access applications if they are first connected to Cloudflare. (More detail on this approach is outlined in a later section about connecting user devices.)\n\nAnother method to secure access to SaaS applications is to configure single sign-on (SSO) so that Cloudflare becomes an identity proxy â€” acting as the identity provider (IDP) â€” as part of the authentication and authorization process.\n\n* Apply consistent access policies across both self-hosted and SaaS applications\n* Layer device security posture into the authentication process (e.g. users can ensure that only managed devices, running the latest operating system and passing all endpoint security checks, are able to access SaaS applications)\n* Ensure that certain network routes are used for access (e.g. users can require that devices are connected to Cloudflare using the device agent, which allows them to filter traffic to the SaaS application and prevent downloads of protected data)\n* Centralize SSO applications to Cloudflare and create one SSO integration from Cloudflare to their IdP â€” making both infrastructure and access policies SSO-agnostic (e.g. users can allow access to critical applications only when MFA is used, no matter which IdP is used to authenticate)\n\nWhen Cloudflare acts as the SSO service to an application, user authentication is still handled by an organization's existing identity provider, but is proxied via Cloudflare, where additional access restrictions can be applied. The diagram below is a high-level example of a typical request flow:\n\n![The flow of SSO requests is proxied through Cloudflare, where the IdP is still used to authenticate, but Cloudflare provides additional access controls.](https://developers.cloudflare.com/_astro/cf1-ref-arch-8.B5wnNeFj_CONnJ.svg)\n\nThe last method of connecting SaaS applications to Cloudflare's SASE architecture is with an API-based [cloud access security broker](https://www.cloudflare.com/learning/access-management/what-is-a-casb/) (CASB). The Cloudflare CASB integrates via API to [popular SaaS suites](https://developers.cloudflare.com/cloudflare-one/integrations/cloud-and-saas/) â€” including Google Workspace, Microsoft 365, Salesforce, and more â€” and continuously scans these applications for misconfigurations, unauthorized user activity, and other security risks.\n\nNative integration with the Cloudflare [data loss prevention](https://www.cloudflare.com/learning/access-management/what-is-dlp/) (DLP) service enables CASB to scan for sensitive or regulated data that may be stored in files with incorrect permissions â€” further risking leaks or unauthorized access. CASB reports findings that alert IT teams to items such as:\n\n* Administrative accounts without adequate MFA\n* Company-sensitive data in files stored with public access permissions\n* Missing application configurations (e.g. domains missing SPF/DMARC records)\n\n#### Checkpoint: Connecting applications to Cloudflare\n\nNow, this is what the architecture of a typical organization might look like once they have integrated with Cloudflare services. It is important to note that Cloudflare is designed to secure organizations' existing applications and services in the following ways:\n\n* All self-hosted applications and services are only accessible through Cloudflare and controlled by policies defined by the Cloudflare ZTNA\n* SaaS application traffic is filtered and secured via the Cloudflare SWG\n* SaaS services are scanned via the Cloudflare CASB to check for configuration and permissions of data at rest\n\n![Access to all applications is now only available via Cloudflare.](https://developers.cloudflare.com/_astro/cf1-ref-arch-9.DbbzPtNJ_Z2ns51a.svg)\n\n### Connecting networks\n\nOnce an organization's applications and services have been integrated, it is time to connect Cloudflare to their existing networks. Regional offices, corporate headquarters, retail locations, data centers, and cloud-hosted infrastructure all need to forward traffic to the new corporate SASE network.\n\nWhen all traffic flows through Cloudflare, SASE services perform the following actions:\n\n* Granting application access\n* Filtering general Internet-bound traffic (e.g. blocking access to sites that host malware)\n* Isolating web sites to protect users from day-zero or unknown harmful Internet content\n* Filtering traffic to identify data defined by DLP policies â€” then blocking the download/upload of that data to insecure devices or applications\n* Providing visibility into the use of non-approved applications and allowing admins to either block or apply policies around their use\n\nThere are several approaches for connecting networks to Cloudflare, which can provide further flexibility in how an organization provides access to SASE-protected resources:\n\n1. **Use software agents to create tunnels from host machines back to Cloudflare**. This is typically the method favored by users who own their own servers and applications.\n2. **Set up IPsec or GRE tunnels from network routers and firewalls to connect them to the Cloudflare WAN service**. This is the approach that network administrators use when they want to forward traffic to and from entire networks.\n3. **Connect a network directly to Cloudflare**. This method works best when an organization's network resides in a supported data center, usually one that is colocated with a Cloudflare data center.\n\nThese methods will be explained further in the next sections.\n\n#### Using software agents\n\nThere are two software-based methods of connecting networks to Cloudflare, depending on the type of applications that currently exist on the network.\n\n##### Client-to-server connectivity\n\nAs described in the previous section, [`cloudflared`](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/private-net/) proxies requests to applications and services on private networks. It installs on servers in the private network and creates secure tunnels to Cloudflare over the Internet. These connections are balanced across multiple Cloudflare data centers for reliability and can be made via multiple connectors, which helps increase the capacity of the tunnels.\n\nUsing `cloudflared`, Cloudflare Tunnel supports client to server connections over the Tunnel. Any service or application running behind the Tunnel will use the default routing table when initiating outbound connectivity.\n\nThis model is appropriate for a majority of scenarios, in which external users need to access resources within a private network that does not require bidirectionally-initiated communication.\n\n![Requests initiated from a client are securely tunneled to Cloudflare via a device agent, while requests from inside the private network follow the default route.](https://developers.cloudflare.com/_astro/cf1-ref-arch-10.PVIlTF5F_Zqb29Q.svg)\n\nFor bidirectional, or meshed connectivity, organizations should use the WARP Connector.\n\n##### Mesh connectivity\n\nThe [WARP Connector](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/private-net/warp-connector/) is a lightweight solution for site-to-site, bidirectional, and mesh networking connectivity that does not require changes to underlying network routing infrastructure. WARP Connector software is installed on a Linux server within an organization's network, which then becomes a gateway for other local networks that need to on-ramp traffic to Cloudflare.\n\nThis provides a lightweight solution to support services such as Microsoft's System Center Configuration Manager (SCCM), Active Directory server updates, VOIP and SIP traffic, and developer workflows with complex CI/CD pipeline interaction. It can either be run supplementally to `cloudflared` and Magic WAN, or can be a standalone remote access and site-to-site connector to the Cloudflare network.\n\nThe WARP Connector can proxy both user-to-network and network-to-network connectivity, or can be used to establish an overlay network of Carrier Grade NAT ([CGNAT](https://en.wikipedia.org/wiki/Carrier-grade_NAT)) addressed endpoints to provide secure, direct connectivity to established resources using CGNAT IP ranges. This helps address overlapping network IP range challenges, point-solution access problems, or the process of shifting network design without impacting a greater underlying system.\n\n![In an example scenario, a developer might push code to a git repository, which ends up in a Kubernetes cluster in a staging network. From staging, it is accessed by a QA tester. All of this traffic is routed and protected via WARP Connector.](https://developers.cloudflare.com/_astro/cf1-ref-arch-11.CZ1ltr0Y_qGFis.svg)\n\nCloudflare Tunnel via `cloudflared` is the primary method for connecting users to applications and services on private networks because it is a simpler, more granular and agile solution for many application owners (vs. IP tunnel based connectivity technology, like [IPsec](https://www.cloudflare.com/learning/network-layer/what-is-ipsec/) and [GRE](https://www.cloudflare.com/learning/network-layer/what-is-gre-tunneling/)). Cloudflare Tunnel via WARP Connector is the preferred method for mesh or other software-defined networking â€” most of which require bidirectional connectivity â€” when organizations do not want to make changes to the underlying network routing or edge infrastructure.\n\n#### Using network equipment\n\nWhere it is not optimal or possible to install software agents, networks can also be connected to Cloudflare using existing network equipment, such as routers and network firewalls. To do this, organizations create IPsec or GRE tunnels that connect to Cloudflare's cloud-native [Magic WAN](https://www.cloudflare.com/network-services/products/magic-wan/) service. With Magic WAN, existing network hardware can connect and route traffic from their respective network locations to Cloudflare through a) secure, IPsec-based tunnels over the Internet or, b) across [Cloudflare Network Interconnect](https://www.cloudflare.com/network-services/products/network-interconnect/) (CNI) â€” private, direct connections that link existing network locations to the nearest Cloudflare data center.\n\nCloudflare's WAN service uses a \"light-branch, heavy-cloud\" architecture that represents the evolution of software-defined WAN (SD-WAN) connectivity. With Magic WAN, as depicted in the network architecture diagram below, the Cloudflare global network functions as a centrally-managed connectivity hub that securely and efficiently routes traffic between all existing network locations:\n\n![Cloudflare's Connectivity Cloud securely links a variety of network locations to the Internet through products such as Firewall, ZTNA, CASB and Load Balancer.](https://developers.cloudflare.com/_astro/cf1-ref-arch-12.D-EXKLBe_ZzagoI.svg)\n\nAs previously described, Cloudflare uses a routing technique called [anycast](https://www.cloudflare.com/learning/cdn/glossary/anycast-network/) to globally advertise all of the services and endpoints on the Cloudflare network, including the endpoints for WAN IP tunnels.\n\nWith [anycast IPsec](https://blog.cloudflare.com/anycast-ipsec/) or anycast GRE tunnels, each tunnel configured from an organization's network device (e.g. edge router, firewall appliance, etc.) connects to hundreds of global Cloudflare data centers. Traffic sourced from an organization's network location is sent directly over these tunnels and always routes to the closest active Cloudflare data center. If the closest Cloudflare data center is unavailable, the traffic is automatically rerouted to the next-closest data center.\n\n![In an example scenario, IPsec traffic from an office network's router would be sent to the closest Cloudflare data center.](https://developers.cloudflare.com/_astro/cf1-ref-arch-13.5dK35i5D_CCed1.svg)\n\nTo further network resiliency, Magic WAN also supports Equal Cost Multi-Path (ECMP) routing between the Cloudflare network and an organization's network location(s). With ECMP, traffic can be load-balanced across multiple anycast IP tunnels, which helps increase throughput and maximize network reliability. In the event of network path failure of one or more tunnels, traffic can be automatically failed over to the remaining healthy tunnels.\n\nThe simplest and easiest way to on-ramp existing network locations to the Magic WAN service is to deploy Cloudflare Magic WAN Connector, a lightweight appliance you can install in corporate network locations to automatically connect, steer, and shape any IP traffic through secure IPsec tunnels. When the WAN Connector is installed into a network, it will automatically establish communication with the Cloudflare network, download and provision relevant configurations, establish resilient IPsec tunnels, and route connected site network traffic to Cloudflare.\n\nThe WAN Connector can be deployed as either a hardware or virtual appliance, making it versatile for a variety of user network environments â€” on-premises, virtual, or public cloud. Management, configuration, observability, and software updates for WAN Connectors is centrally managed from Cloudflare via either the dashboard or the Cloudflare API. As of 2023, the WAN Connector is currently best-suited for connecting small and medium-sized networks to Cloudflare (e.g. small offices and retail stores).\n\nIn situations where deploying the WAN Connector is not feasible or desirable, organizations can securely connect their site networks to Cloudflare by configuring IPsec tunnels from their existing IPsec-capable network devices, including WAN or SD-WAN routers, firewalls, and cloud VPN gateways. Please refer to the Cloudflare [documentation](https://developers.cloudflare.com/magic-wan/configuration/manually/third-party/) for up-to-date examples of validated IPsec devices.\n\nThere may also be situations where network-layer encryption is not necessary â€” for example, when a site's WAN-bound traffic is already encrypted at the application layer (via TLS), or when an IPsec network device offers very limited throughput performance as it encrypts and decrypts IPsec traffic. Under these circumstances, organizations can connect to the Cloudflare network using [GRE tunnels](https://developers.cloudflare.com/magic-wan/configuration/manually/how-to/configure-tunnel-endpoints/).\n\nOrganizations may also connect their network locations directly to the Cloudflare network via [Cloudflare Network Interconnect](https://www.cloudflare.com/network-services/products/network-interconnect/) (CNI). Cloudflare [supports a variety of options](https://developers.cloudflare.com/network-interconnect/) to connect your network to Cloudflare:\n\n* Direct CNI for Magic WAN and Magic Transit\n* Classic CNI for Magic Transit\n* Cloud CNI for Magic WAN and Magic Transit\n* Peering via either an internet exchange, or a private network interconnect (PNI).\n\nThe following table summarizes the different methods of connecting networks to Cloudflare:\n\n| **Use case** | **Recommended** | **Alternative solution** |\n| - | - | - |\n| Remote users connecting to applications on private networks in a Zero Trust model (e.g. most VPN replacement scenarios) | **Cloudflare Tunnel (with `cloudflared`)** | **Magic WAN** Alternative option if `cloudflared` not suitable for environment |\n| Site-to-site connectivity between branches, headquarters, and data centers | **Magic WAN** | **Cloudflare Tunnel (with WARP Connector)** Alternative option if routing changes cannot be made at perimeter |\n| Egress traffic from physical sites or cloud environments to cloud security inspection (e.g. most common SWG and branch firewall replacement scenarios) | **Magic WAN** | **N/A** |\n| Service-initiated communication with remote users (e.g. AD or SCCM updates, DevOps workflows, VOIP) | **Cloudflare Tunnel (with WARP Connector)** | **Magic WAN** Alternative option if inbound source IP fidelity not required |\n| Mesh networking and peer-to-peer connectivity | **Cloudflare Tunnel (with WARP Connector)** | **N/A** |\n\nEach of these methods of connecting and routing traffic can be deployed concurrently from any location. The following diagram highlights how different connectivity methods can be used in a single architecture.\n\nNote the following traffic flows:\n\n* All traffic connected via a WARP Connector or device agent can communicate with each other over the mesh network\n\n* Developers working from home can communicate with the production and staging servers in the cloud\n  * The employee in the retail location, as well as the developer at home, can receive VOIP calls on their laptop\n\n* A HPC Cluster in AWS represents a proprietary solution in which no third-party software agents can be installed; as a result, it uses an IPsec connection to Magic WAN\n\n* In the retail location, the Magic WAN Connector routes all traffic to Cloudflare via an IPsec tunnel\n  * An employee's laptop running the device agent creates its own secure connection to Cloudflare that is routed over the IPsec tunnel\n\n* The application owner of the reporting system maintains a connection to Cloudflare using `cloudflared` and doesn't require any networking help to expose their application to employees\n\n![Connecting and routing traffic can be created using various methods such as Cloudflare Network Interconnect, IPSEC tunnels, WARP Connector and cloudflared.](https://developers.cloudflare.com/_astro/cf1-ref-arch-14.BMsYJBWD_155tSw.svg)\n\n*Note: All of the endpoints connected via the WARP Connector or device agent are automatically assigned IP addresses from the 100.96.0.0/12 address range, while endpoints connected to Magic WAN retain their assigned RFC1918 private IP addresses. `cloudflared` can be deployed in any of the locations by an application owner to provide hostname-based connectivity to the application.*\n\nOnce the networks, applications, and user devices are connected to Cloudflare â€” regardless of the connection methods and devices used â€” all traffic can be inspected, authenticated, and filtered by the Cloudflare SASE services, then securely routed to their intended destinations. Additionally, consistent policies can be applied across all traffic, no matter how it arrives at Cloudflare.\n\n#### Checkpoint: Connecting networks to Cloudflare\n\nNow this is what a SASE architecture looks like where corporate network traffic from everywhere is forwarded to and processed by Cloudflare. In this architecture, it is possible to make a network connection from any remote location, office location or data center and connect to applications and services living in SaaS infrastructure, cloud-hosted infrastructure or an organization's own on-premise data centers.\n\n![Traffic from all networks, North and South, as well as East and West, is now flowing through and secured by Cloudflare.](https://developers.cloudflare.com/_astro/cf1-ref-arch-15.BL6UWZPA_ZLNfeP.svg)\n\n### Forwarding device traffic\n\nThe previous sections explain using ZTNA to secure access to self-hosted applications and using an SWG to inspect and filter traffic destined for the Internet. When a user is working on a device in any of the company networks that is connected to Cloudflare's connectivity cloud, all that traffic is inspected and policies applied without disrupting the user's workflow. Yet, users are not always (or ever) in the office; they work from home, on the road, or from other public networks. How do you ensure they have reliable access to your internal applications? How do you ensure their Internet browsing is secure no matter their work location?\n\nThere are several approaches to ensure that traffic from a user device which isn't connected to an existing Cloudflare protected network, are also forwarding traffic through Cloudflare and be protected.\n\n* [Install an agent on the device](#connecting-with-a-device-agent)\n* [Modify browser proxy configuration](#browser-proxy-configuration)\n* [Direct the user to a remote browser instance](#using-remote-browser-instances)\n* [Modify DNS configuration](#agentless-dns-filtering)\n\n#### Connecting with a device agent\n\nThe preferred method of ensuring device traffic is forwarded to Cloudflare is to install the device agent (also referred to as [Cloudflare WARP](https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/warp)). The agent runs on Windows, macOS, Linux, iOS, and Android/ChromeOS, and creates a secure connection to Cloudflare where all non-local traffic is sent. Because of Cloudflare's use of anycast networking, the device agent always connects to the nearest Cloudflare server to ensure the best performance for the user. The device agent also collects local machine and network information, which is sent in the request to enrich the policy in Cloudflare.\n\nTo allow for flexibility in how different devices and users connect, there are multiple [deployment modes](https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/warp/configure-warp/warp-modes/):\n\n* A full L4 traffic proxy\n* L7 DNS proxy\n* L7 HTTP proxy\n* The ability to just collect device posture information\n\nFor example, organizations might have an office that continues to use an existing [DNS filtering](https://www.cloudflare.com/learning/access-management/what-is-dns-filtering/) service, so they can configure the agent to just proxy network and HTTP traffic.\n\nThe agent can also be configured with flexible routing controls that allow for scenarios in which traffic destined for office printers is not sent to the Cloudflare network but, instead, routed to the local network. These [split tunnel configurations](https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/warp/configure-warp/route-traffic/split-tunnels/) can be made specific to groups of users, types of device operating system, or networks and by default, traffic destined to all private [IPv4 and IPv6 ranges](https://datatracker.ietf.org/doc/html/rfc1918) is sent to the device's default gateway. If the application the user is attempting to reach is not in public DNS, you can configure the hostname and domain to be resolved with [local DNS services](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/private-net/cloudflared/private-dns/), so that the device agent does not attempt to resolve these using Cloudflare DNS.\n\n![Using the device agent allows Internet and company application bound traffic to be secured by Cloudflare's SWG and ZTNA services.](https://developers.cloudflare.com/_astro/cf1-ref-arch-16.DBOEvI3k_Z19SAh0.svg)\n\nThe agent is more than just a network proxy; it is able to examine the device's security posture, such as if the operating system is fully up-to-date or if the hard disk is encrypted. Cloudflare's integrations with [CrowdStrike](https://www.cloudflare.com/partners/technology-partners/crowdstrike/endpoint-partners/), [SentinelOne](https://www.cloudflare.com/partners/technology-partners/sentinelone/), and other third-party services also provide additional data about the security posture of the device. All of this information is associated with each request and, therefore, available for use in company policies â€” as explained in the \"Unified Management\" section.\n\nThe agent can be [deployed](https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/warp/deployment/) to a device either manually or using existing endpoint management (UEM) technologies. Using the agent, users register and authenticate their device to Cloudflare with the integrated identity providers. Identity information â€” combined with information about the local device â€” is then used in your SWG and ZTNA policies (including inline CASB capabilities shared across these Cloudflare services).\n\n#### Browser proxy configuration\n\nWhen it is not possible to install software on the device, there are agentless approaches.\n\nOne option is to configure the browser to forward HTTP requests to Cloudflare by configuring proxy server details in the browser or OS. Although this can be done manually, it is more common for organizations to automate the configuration of browser proxy settings using Internet-hosted [Proxy Auto-Configuration](https://developers.cloudflare.com/cloudflare-one/networks/resolvers-and-proxies/proxy-endpoints/) (PAC) files. The browser identifies the PAC file location in several ways:\n\n* MDM software configuring the setting in the browser\n* In Windows domains, Group Policy Objects (GPO) can configure the browser's PAC file\n* Browsers can use [Web Proxy Auto-Discovery](https://datatracker.ietf.org/doc/html/draft-ietf-wrec-wpad-01) (WPAD)\n\nFrom there, configure a proxy endpoint where the browser will send all HTTP requests to. If using this method, please note that:\n\n* Filtering HTTPS traffic will also require [installing and trusting Cloudflare root certificates](https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/user-side-certificates/) on the devices.\n* A proxy endpoint will only proxy traffic sourced from a set of known IP addresses, such as the pool of public IP addresses used by a site's NAT gateway, that the administrator must specify.\n\n#### Using remote browser instances\n\nAnother option to ensure device traffic is sent to Cloudflare is to use [remote browser isolation](https://www.cloudflare.com/learning/access-management/what-is-browser-isolation/) (RBI). When a remote user attempts to visit a website, the corresponding requests and responses are handled by a headless remote browser running in the Cloudflare network that functions as a \"clone\" of the user device's local browser. This shields the user's device from potential harmful content and code execution that may be downloaded from the website it visits.\n\nRBI renders the received content in an isolated and secure cloud environment. Instead of executing the web content locally, the user device receives commands for how to \"draw\" the final rendered web page over a highly optimized protocol supported by all HTML5-compliant browsers on all operating systems. Because the remote browser runs on Cloudflare's servers, SWG policies are automatically applied to all browser requests.\n\nEnsuring access to sites is protected with RBI does not require any local software installation or reconfiguring the user's browser. Below are [several ways](https://developers.cloudflare.com/cloudflare-one/remote-browser-isolation/setup/) to accomplish this:\n\n* Typically, a remote browser session is started as the result of an SWG policy â€” the user just requests websites without being notified that the content is loading in a remote browser.\n* Organizations can also provide users with a link that automatically ensures RBI always processes each request.\n* Organizations can also opt to use the ZTNA service to redirect all traffic from self-hosted applications via RBI instances.\n\nAll requests via a remote browser pass through the Cloudflare SWG; therefore, policies can enforce certain website access limitations. For instance, browser isolation policies can be established to:\n\n* Disable copy/paste between a remote web page and the user's local machine; this can prevent the employee from pasting proprietary code into third-party chatbots.\n* Disable printing of remote web content to prevent contractors from printing confidential information\n* Disable file uploads/downloads to ensure sensitive company data is not sent to â€” or downloaded from â€” certain websites.\n* Disable keyboard input (in combination with other policies) to limit data being exposed, such as someone typing in passwords to a phishing site.\n\nIsolating web applications and applying policies to risky websites helps organizations limit data loss from cyber threats or user error. And, like many Cloudflare One capabilities, RBI can be leveraged across other areas of the SASE architecture. Cloudflare's [email security](https://www.cloudflare.com/learning/email-security/what-is-email-security/) service, for example, can automatically rewrite and isolate suspicious links in emails. This \"email link isolation\" capability helps protect the user from potential malicious activity such as credential harvesting phishing.\n\n#### Agentless DNS Filtering\n\nAnother option for securing traffic via the Cloudflare network is to configure the device to forward DNS traffic to Cloudflare to be inspected and filtered. First [DNS locations](https://developers.cloudflare.com/cloudflare-one/traffic-policies/initial-setup/dns/#connect-dns-locations) are created which allow policies to be applied based on different network locations. They can be determined either by the source IP address for the request or you can use \"[DNS over TLS](https://www.cloudflare.com/learning/dns/dns-over-tls/)\" or \"[DNS over HTTPS](https://www.cloudflare.com/learning/dns/dns-over-tls/)\".\n\nWhen using source IP addresses, either the device will need to be told which DNS servers to use, or the local DNS server on the network the device is connected to needs to forward all DNS queries to Cloudflare. For DNS over TLS or HTTPS support, the devices need to be configured and support varies. Our recommendation is to use DNS over HTTPS which has wider operating system support.\n\nAll of the above methods result in only the DNS requests â€” not all traffic â€” being sent to Cloudflare. SWG DNS policies are then implemented at this level to manage access to corporate network resources.\n\n#### Summary of SWG capabilities for each traffic forwarding method\n\nThe following table summarizes SWG capabilities for the various methods of forwarding traffic to Cloudflare (as of Oct 2023):\n\n| | IP tunnel or Interconnect (Magic WAN) | Device Agent (WARP)\\*1 | Remote Browser | Browser proxy | DNS proxy |\n| - | - | - | - | - | - |\n| Types of traffic forwarded | TCP/UDP | TPC/UDP | HTTP | HTTP | DNS |\n| **Policy types** | | | | | |\n| DNS | Yes | Yes | Yes | Yes | Yes |\n| HTTP/S\\*2 | Yes | Yes | Yes | Yes | N/A |\n| Network (L3/L4 parameter) | Yes | Yes | Yes | Yes | No |\n| **Data available in policies** | | | | | |\n| Identity information | No | Yes | Yes | No | No\\*3 |\n| Device posture | No | Yes | No | No | No |\n| **Capabilities** | | | | | |\n| Remote browser isolation | Yes | Yes | Yes | Yes | N/A |\n| Enforce egress IP | Yes | Yes | Yes | Yes | N/A |\n\n1. Running the device agent in DNS over HTTP mode provides user identity information, in addition to the same capabilities as connecting via DNS.\n2. To filter HTTPS traffic, the Cloudflare [certificate](https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/user-side-certificates/) needs to be installed on each device. This can be automated when using the device agent.\n3. If configuring DNS over HTTPS, it is possible to inject a [service token](https://developers.cloudflare.com/cloudflare-one/networks/resolvers-and-proxies/dns/dns-over-https/#filter-doh-requests-by-user) into the request, which associates the query with an authenticated user.\n\n#### Checkpoint: Forwarding device traffic to Cloudflare\n\nBy connecting entire networks or individual devices, organizations can now route user traffic to Cloudflare for secure access to privately-hosted applications and secure public Internet access.\n\nOnce traffic from all user devices is forwarded to the Cloudflare network, it is time for organizations to revisit their high-level SASE architecture:\n\n![With all devices and networks connected, any traffic destined for company applications and services all flows through Cloudflare, where policies are applied to determine access.](https://developers.cloudflare.com/_astro/cf1-ref-arch-17.Cv4XcukK_Z1KCWhH.svg)\n\n### Verifying users and devices\n\nAt this point in implementing SASE architecture, organizations have the ability to route and secure traffic beginning from the point a request is made from a browser on a user's device, all the way through Cloudflare's network to either a company-hosted private application/service or to the public Internet.\n\nBut, before organizations define policies to manage that access, they need to know who is making the request and determine the security posture of the device.\n\n#### Integrating identity providers\n\nThe first step in any access decision is to determine who is making the request â€“ i.e., to authenticate the user.\n\nCloudflare integrates with identity providers that manage secure access to resources for organizations' employees, contractors, partners, and other users. This includes support for integrations with any [SAML](https://developers.cloudflare.com/cloudflare-one/integrations/identity-providers/generic-saml/) - or OpenID Connect ([OIDC](https://developers.cloudflare.com/cloudflare-one/integrations/identity-providers/generic-oidc/)) - compliant service; Cloudflare One also includes pre-built integrations with [Okta](https://developers.cloudflare.com/cloudflare-one/integrations/identity-providers/okta/), [Microsoft Entra ID (formerly Azure Active Directory)](https://developers.cloudflare.com/cloudflare-one/integrations/identity-providers/entra-id/), [Google Workspace](https://developers.cloudflare.com/cloudflare-one/integrations/identity-providers/google-workspace/), as well as consumer IdPs such as [Facebook](https://developers.cloudflare.com/cloudflare-one/integrations/identity-providers/facebook-login/), [GitHub](https://developers.cloudflare.com/cloudflare-one/integrations/identity-providers/github/) and [LinkedIn](https://developers.cloudflare.com/cloudflare-one/integrations/identity-providers/linkedin/).\n\nMultiple IdPs can be integrated, allowing organizations to apply policies to a wide range of both internal and external users. When a user attempts to access a Cloudflare secured application or service, they are redirected to authenticate via one of the integrated IdPs. When using the device agent, users must also authenticate to one of their organization's configured IdPs.\n\n![Users are presented with a list of integrated identity providers before accessing protected applications.](https://developers.cloudflare.com/_astro/cf1-ref-arch-18.dg0Dmn3U_18nofX.svg)\n\nOnce a user is authenticated, Cloudflare receives that user's information, such as username, group membership, authentication method (password, whether MFA was involved and what type), and other associated attributes (i.e., the user's role, department, or office location). This information from the IdP is then made available to the policy engine.\n\nIn addition to user identities, most corporate directories also contain groups to which those identities are members. Cloudflare supports the importing of group information, which is then used as part of the policy. Group membership is a critical part of aggregating single identities so that policies can be less complex. It is far easier â€” for example â€” to set a policy allowing all employees in the sales department to access Salesforce, than to identify each user in the sales organization.\n\nCloudflare also supports authentication of devices that are not typically associated with a human user â€“ such as an IoT device monitoring weather conditions at a factory. For those secure connections, organizations can generate [service tokens](https://developers.cloudflare.com/cloudflare-one/access-controls/service-credentials/service-tokens/) or create [Mutual TLS](https://www.cloudflare.com/learning/access-management/what-is-mutual-tls/) (mTLS) certificates that can be deployed to such devices or machine applications.\n\n#### Trusting devices\n\nNot only does the user identity need to be verified, but the security posture of the user's device needs to be assessed. The device agent is able to provide a range of device information, which Cloudflare uses to build comprehensive security policies.\n\nThe following built-in posture checks are available:\n\n* [Application check](https://developers.cloudflare.com/cloudflare-one/reusable-components/posture-checks/warp-client-checks/application-check/): Checks that a specific application process is running\n* [File check](https://developers.cloudflare.com/cloudflare-one/reusable-components/posture-checks/warp-client-checks/file-check/): Checks for the presence of a file\n* [Firewall](https://developers.cloudflare.com/cloudflare-one/reusable-components/posture-checks/warp-client-checks/firewall/): Checks if a firewall is running\n* [Disk encryption](https://developers.cloudflare.com/cloudflare-one/reusable-components/posture-checks/warp-client-checks/disk-encryption/): Checks if/how many disks are encrypted\n* [Domain joined](https://developers.cloudflare.com/cloudflare-one/reusable-components/posture-checks/warp-client-checks/domain-joined/): Checks if the device is joined to a Microsoft Active Directory domain\n* [OS version](https://developers.cloudflare.com/cloudflare-one/reusable-components/posture-checks/warp-client-checks/os-version/): Checks what version of the OS is running\n* [Unique Client ID](https://developers.cloudflare.com/cloudflare-one/reusable-components/posture-checks/warp-client-checks/device-uuid/): When using an MDM too, organizations can assign a verifiable UUID to a mobile, desktop, or laptop device\n* [Device serial number](https://developers.cloudflare.com/cloudflare-one/reusable-components/posture-checks/warp-client-checks/corp-device/): Checks to see if the device serial matches a list of company desktop/laptop computers\n\nCloudflare One can also integrate with any deployed endpoint security solution, such as [Microsoft Endpoint Manager](https://developers.cloudflare.com/cloudflare-one/integrations/service-providers/microsoft/), [Tanium](https://developers.cloudflare.com/cloudflare-one/integrations/service-providers/taniums2s/), [Carbon Black](https://developers.cloudflare.com/cloudflare-one/reusable-components/posture-checks/warp-client-checks/carbon-black/), [CrowdStrike](https://developers.cloudflare.com/cloudflare-one/integrations/service-providers/crowdstrike/), [SentinelOne](https://developers.cloudflare.com/cloudflare-one/integrations/service-providers/sentinelone/), and more. Any data from those products can be passed to Cloudflare for use in access decisions.\n\nAll of the above device information, combined with data on the user identity and also the network the device is on, is available in Cloudflare to be used as part of the company policy. For example, organizations could choose to only allow administrators to SSH into servers when all of the following conditions are met: their device is free from threats, running the latest operating system, and joined to the company domain.\n\nBecause this information is available for every network request, any time a device posture changes, its ability to connect to an organization's resources is immediately impacted.\n\n#### Integrating email services\n\nEmail â€” the #1 communication tool for many organizations and the most common channel by which phishing attacks occur â€” is another important corporate resource that should be secured via a SASE architecture. Phishing is the root cause of upwards of 90% of breaches that lead to financial loss and brand damage.\n\nCloudflare's email security service scans for signs of malicious content or attachments before they can reach the inbox, and also proactively scans the Internet for attacker infrastructure and attack delivery mechanisms, looking for programmatically-created domains that are used to host content as part of a planned attack. Our service uses all this data to also protect against business and vendor email compromises ([BEC](https://www.cloudflare.com/learning/email-security/business-email-compromise-bec/) / [VEC](https://www.cloudflare.com/learning/email-security/what-is-vendor-email-compromise/)), which are notoriously hard to detect due to their lack of payloads and ability to look like legitimate email traffic.\n\nInstead of deploying tunnels to manage and control traffic to email servers, Cloudflare provides two methods of email security [setup](https://developers.cloudflare.com/email-security/deployment/):\n\n* [Inline](https://developers.cloudflare.com/email-security/deployment/inline/): Redirect all inbound email traffic through Cloudflare before they reach a user's inbox by modifying MX records\n* [API](https://developers.cloudflare.com/email-security/deployment/api/): Integrate Cloudflare directly with an email provider such as Microsoft 365 or Gmail\n\nModifying MX records (inline deployment) forces all inbound email traffic through our cloud email security service where it is scanned, and â€” if found to be malicious â€” blocked from reaching a user's inbox. Because the service works at the MX record level, it is possible to use the email security service with any [SMTP-compliant](https://www.cloudflare.com/learning/email-security/what-is-smtp/) email service.\n\n![Protecting email with Cloudflare using MX records ensures all emails are scanned and categorized.](https://developers.cloudflare.com/_astro/cf1-ref-arch-19.B4iJKLu2_Z22e1gD.svg)\n\nOrganizations can also opt to integrate email security directly with their email service via APIs. Note that this approach has two drawbacks: there are fewer integrations Cloudflare supports and there is always a small delay between the email being delivered to the service and Cloudflare detecting it via the API.\n\n![Protecting email with Cloudflare using APIs avoids the need to change DNS policy, but introduces delays into email detection and limits the types of email services that can be protected.](https://developers.cloudflare.com/_astro/cf1-ref-arch-20.CpqyyvgC_Z2fainl.svg)\n\n#### Checkpoint: A complete SASE architecture with Cloudflare\n\nThe steps above provide a complete view of evolving to SASE architecture using Cloudflare One. As the diagram below shows, secure access to all private applications, services, and networks â€” as well as ensuring the security of users' general Internet access â€” is now applied to all users in the organization, internal or external.\n\n![A fully deployed SASE solution with Cloudflare protects every aspect of your business. Ensuring all access to applications is secured and all threats from the Internet mitigated.](https://developers.cloudflare.com/_astro/cf1-ref-arch-21.B4dzMu9Q_1OT1sz.svg)\n\nFor ease of use, the entire Cloudflare One platform can be configured via [API](https://developers.cloudflare.com/api/); and with Cloudflare's [Terraform provider](https://registry.terraform.io/providers/cloudflare/cloudflare/latest/docs), organizations can manage the Cloudflare global network using the same tools they use to automate the rest of their infrastructure. This allows IT teams to fully manage their Cloudflare One infrastructure, including all the policies detailed in the next section, using code. There are also (as of Oct 2023) more than 500 [GitHub](https://github.com/cloudflare) repositories, many of which allow IT teams to use and build tools to manage their Cloudflare deployment.\n\n## Unified management\n\nNow that all users, devices, applications, networks, and other components are seamlessly integrated within a SASE architecture, Cloudflare One provides a centralized platform for comprehensive management. Because of the visibility Cloudflare has across the entire IT infrastructure, Cloudflare can aggregate signals from various sources, including devices, users, and networks. These signals can inform the creation of policies that govern access to organization resources.\n\nBefore we go into the details of how policies can be written to manage access to applications, services, and networks connected to Cloudflare, it's worth taking a look at the two main enforcement points in Cloudflare's SASE platform that control access: SWG and the ZTNA services. These services are configured through a single administrative dashboard, simplifying policy management across the entire SASE deployment.\n\nThe following diagram illustrates the flow of a request through these services, including the application of policies and the source of data for these policies. In the diagram below, the user request can either enter through the SWG or ZTNA depending on the type of service requested. It's also possible to combine both services, such as implementing a SWG HTTP policy that uses DLP service to inspect traffic related to a privately hosted application behind a ZTNA Cloudflare Tunnel. This configuration enables organizations to block downloads of sensitive data from internal applications that organizations have authorized for external access.\n\n![User requests to the Internet or self hosted applications go through our SWG and/or ZTNA service. Administrators have a single dashboard to manage policies across both.](https://developers.cloudflare.com/_astro/cf1-ref-arch-23.By2O_HTZ_Z1BmCAS.svg)\n\nIn the following sections, we introduce examples of how different policies can be configured to satisfy specific use cases. While these examples are not exhaustive, the goal is to demonstrate common ways Cloudflare One can be configured to address the challenges organizations encounter in its transition to a SASE architecture.\n\nConnecting an IdP to Cloudflare provides the ability to make access decisions based on factors such as group membership, authentication method, or specific user attributes. Cloudflare's device agent also supplies additional signals for policy considerations, such as assessing the operating system or verifying the device's serial number against company-managed devices. However, there are features that allow users to incorporate additional data into deployment for building powerful policies.\n\nCloudflare's vast intelligent network continually monitors billions of web assets and [categorizes them](https://developers.cloudflare.com/cloudflare-one/traffic-policies/domain-categories/) based on our threat intelligence and general knowledge of Internet content. You can use our free [Cloudflare Radar](https://radar.cloudflare.com/) service to examine what categories might be applied to any specific domain. Policies can then include these categories to block known and potential security risks on the public Internet, as well as specific categories of content.\n\nAdditionally, Cloudflare's SWG offers the flexibility to create and maintain customized [lists of data](https://developers.cloudflare.com/cloudflare-one/reusable-components/lists/). These lists can be uploaded via CSV files, manually maintained, or integrated with other processes and applications using the Cloudflare API. A list can contain the following data:\n\n* URLs\n* Hostnames\n* Serial numbers (macOS, Windows, Linux)\n* Emails\n* IP addresses\n* Device IDs (iOS, Android)\n\nFor example, organizations can maintain a list of IP addresses of all remote office locations, of short term contractors' email addresses, or trusted company domains. These lists can be used in a policy to allow contractors access to a specific application if their traffic is coming from a known office IP address.\n\n### DLP profiles and datasets\n\nCloudflare looks at various aspects of a request, including the source IP, the requested domain, and the identity of the authenticated user initiating the request. Cloudflare also offers a DLP service which has the ability to detect and block requests based on the presence of sensitive content. The service has built in DLP profiles for common data types such as financial information, personally identifiable information (PII), and API keys.\n\nThere is even a profile for source code, so users can detect and block the transfer of C++ or Python files. Organizations can create customized DLP profiles and use regular expressions to define the patterns of data they are looking for. For data that is hard to define a pattern for, datasets can be used which match exact data values. These datasets allow for the bulk upload of any data to be matched, such as lists of customer account IDs or sensitive project names. These profiles and data sets can be incorporated into policies to prevent users from downloading large files containing confidential customer data.\n\nTo reduce the risk of false positives, internal users have the option to establish a match count on the profile. This means that a specific number of matches within the data are required before profile triggers. This approach prevents scenarios where a random string resembling PII or a credit card number would trigger the profile unnecessarily. By implementing a match count, the policy demands that multiple data elements align with the profile, significantly increasing its accuracy.\n\nOrganizations can further increase the accuracy of the DLP profile by enabling context analysis. This feature requires certain proximity keywords to exist within approximately 1000 characters of a match. For example, the string \"123-45-6789\" will only count as a detection if it is in proximity to keywords such as \"ssn\". This contextual requirement bolsters the accuracy of the detection process.\n\nThe DLP service seamlessly integrates with both Cloudflare's SWG and API-driven CASB services. In the case of the API CASB, DLP profiles are selected for scanning each integration with each SaaS application. This customization allows tailored detection criteria based on the type of data you wish to secure within each application.\n\nFor the SWG service, DLP profiles can be included into any policy to detect the existence of sensitive data in any request passing through the gateway. The most common action associated with this detection is to block the request, providing a robust layer of security.\n\nAccess Groups are a powerful tool in the ZTNA service for aggregating users or devices into a unified entity that can be referenced within a policy. Within Cloudflare, multiple pieces of information can be combined into a single Access Group, efficiently reusing data across multiple policies while maintaining it in one centralized location.\n\nConsider an Access Group designed to manage access to critical server infrastructure. The same Access Group can be used in a device agent policy that prevents administrators from disabling their connection to Cloudflare. This approach streamlines policy management and ensures consistency across various policy implementations.\n\nBelow is a diagram featuring an Access Group named \"Secure Administrators,\" which uses a range of attributes to define the characteristics of secure administrators. The diagram shows the addition of two other Access Groups within \"Secure Administrators\". The groups include devices running on either the latest Windows or macOS, along with the requirement that the device must have either File Vault or Bitlocker enabled.\n\n![An example of using Access Groups can be for grouping up many device, network or user attributes into a single policy that can be reused across applications.](https://developers.cloudflare.com/_astro/cf1-ref-arch-24.aWooHqll_2v76br.svg)\n\nConsistent with Cloudflare's overarching flexibility, Access Groups can be created, updated, and applied to policies through Cloudflare API or using Terraform. This allows a seamless integration with existing IT systems and processes, ensuring a cohesive approach to access management.\n\nNow that we have a solid understanding of all the components available, let's zoom in and take a look at some common use cases and how they are configured. Keep in mind that Cloudflare's policy engines are incredibly powerful and flexible, so these examples are just a glimpse into the capabilities of Cloudflare's SASE platform.\n\n### Example use cases\n\n#### Secure access to self hosted apps and services\n\nOne common driver for moving to a SASE architecture is replacing existing VPN connectivity with a more flexible and secure solution. Cloudflare One SASE architecture enables high performance and secure access to self hosted applications from anywhere in the world. However, the next step entails defining the policies that control access to resources.\n\nIn this example, consider two services: a database administration application ([pgadmin](https://www.pgadmin.org/) for example) and an SSH daemon running on the database server. The diagram below illustrates the flow of traffic and highlights the ZTNA service. It's important to note that all other services still retain the ability to inspect the request. For instance, the contractor using their personal cell phone in Germany should only have access to the db admin tool, while the employee on a managed device can access both the db admin tool and SSH into the database server.\n\n![An employee working on a managed device at home can access both the db admin tool as well as the SSH service. However a contractor in Germany only has access to the db admin tool.](https://developers.cloudflare.com/_astro/cf1-ref-arch-25.DbM82XF7_1gYxP5.svg)\n\nThe policies that enable access rely on two Access Groups.\n\n* Users who authenticate through Okta and are part of the Okta group labeled \"Contractors\"\n  * Authentication requires the use of a hardware token\n\n* Database and IT administrators\n\n* Users who authenticate through Okta and are in the Okta groups \"IT administrators\" or \"Database administrators\"\n  * Authentication requires the use of a hardware token\n  * Users should be on a device with a serial number in the \"Managed Devices\" list\n\nBoth of these groups are then used in two different access policies.\n\n* Database administration tool access\n\n* Database and IT admins are allowed access\n  * Members of the \"Contractor\" access group are allowed access, but each authenticated session requires the user to complete a justification request\n  * The admin tool is rendered in an isolated browser on Cloudflare's Edge network and file downloads are disabled\n\n* Database server SSH access\n\n* \"Database and IT administrators\" group is allowed access\n  * Their device must pass a Crowdstrike risk score of at least 80\n  * Access must come from a device that is running our device agent and is connected to Cloudflare\n\nThese policies show that contractors are only allowed access to the database administration tool and do not have SSH access to the server. IT and database administrators can access the SSH service only when their devices are securely connected to Cloudflare via the device agent. Every element of the access groups and policies is evaluated for every login, so an IT administrator using a compromised laptop or a contractor unable to authenticate with a hardware token will be denied access.\n\nBoth user groups will connect to Cloudflare through the closest and fastest access point of Cloudflare's globally distributed network, resulting in a high quality experience for all users no matter where they are.\n\n#### Threat defense for distributed offices and remote workers\n\nAnother reason for using a SASE solution is to apply company security policies consistently across all users (whether they are employees or contractors) in the organization, regardless of where they work. The Cloudflare One SASE architecture shows that all user traffic, whether routed directly on the device or through the connected network, will go through Cloudflare. Cloudflare's SWG then handles inspection of this traffic. Depending on the connection method, policies can be applied either to the HTTP or DNS request. For example:\n\n![Blocking high risk websites can be done by selecting a few options in the SWG policy](https://developers.cloudflare.com/_astro/cf1-ref-arch-26.CctZYYxb_1NLKw6.svg)\n\nThis can then be applied to secure and protect all users in one policy. Cloudflare can write another policy allowing access to social media websites while isolating all sessions in a remote browser hosted on Cloudflare's network.\n\n![Isolating all social media websites can be done by identifying the application or website name and selecting what actions the user can take, such as stopping them from copy and pasting or printing.](https://developers.cloudflare.com/_astro/cf1-ref-arch-27.BlDxrRwj_Znjbgg.svg)\n\nWith this setup, every request to a social media website ensures the following security measures:\n\n* Any content on the social media website that contains harmful code is prevented from executing on the local device\n* External users are restricted from downloading content from the site that could potentially be infected with malware or spyware\n\n#### Data protection for regulatory compliance\n\nBecause Cloudflare One has visibility over every network request, Cloudflare can create policies that apply to the data in the request. This means that the DLP services can be used to detect the download of content from an application and block it for specific user demographics. Let's look at the following policy.\n\n![Our DLP policies allow for the inspection of content in a request and blocking it.](https://developers.cloudflare.com/_astro/cf1-ref-arch-28.DKy2S5nx_Znjbgg.svg)\n\nThis policy would prevent contractors from downloading a file containing customer accounts information. Furthermore, Cloudflare can configure an additional policy to block the same download if the user's device does not meet specific security posture requirements. This ensures the consistent enforcement of a common rule: no sensitive customer data can be downloaded onto a device that does not meet the required security standards.\n\nDLP policies can also be applied in the other direction, ensuring that company sensitive documents are not uploaded to non approved cloud storage or social media.\n\n![A DLP policy can also examine if a HTTP PUT, i.e. a file upload, is taking place to a non approved application where the request contains sensitive data.](https://developers.cloudflare.com/_astro/cf1-ref-arch-29.BGL4hCeF_Znjbgg.svg)\n\n### Visibility across the deployment\n\nAt this point in the SASE journey, users have re-architectured the IT network and security infrastructure to fully leverage all the capabilities of the Cloudflare One SASE platform. A critical element in long term deployment involves establishing complete visibility into the organization and the ability to diagnose and quickly resolve issues.\n\nFor quick analysis, Cloudflare provides built-in dashboards and analytics that offers a daily overview of the deployment's operational status. As traffic flows through Cloudflare, the dashboard will alert internal users to the most frequently used SaaS applications, enabling quick actions if any unauthorized applications are accessed by external users. Moreover, all logging information from all Cloudflare One services is accessible and searchable from the administrator's dashboard. This makes it efficient to filter for specific blocked requests, with each log containing useful information such as the user's identity, device information, and the specific rule that triggered the block. This can be very handy in the early stages of deployment where rules can often need tweaking.\n\nHowever, many organizations rely on existing dedicated tools to manage long term visibility over the performance of their infrastructure. To support this, Cloudflare allows the export of all logging information into such tools. Every aspect of Cloudflare One is logged and can be exported. Cloudflare offers built in integrations for continuous transmission of small data batches to a variety of platforms, including AWS, Google Cloud Storage, SumoLogic, Azure, Splunk, Datadog, and any S3 compatible service. This flexibility allows organizations to selectively choose which fields to control the type and volume of data to incorporate into existing tools.\n\nOn top of logs which are related to traffic and policies, Cloudflare also audits management activity. All administrative actions and changes to Cloudflare Tunnels are logged. This allows for change management auditing and, like all other logs, can be exported into other tools as part of a wider change management monitoring solution.\n\n#### Digital Experience Monitoring\n\nCloudflare has [deep insight](https://radar.cloudflare.com/) into the performance of the Internet and connected networks and devices. This knowledge empowers IT administrators with visibility into minute-by-minute experiences of their end-users, enabling swift resolution of issues that impact productivity.\n\nThe Digital Experience Monitoring (DEM) service enables IT to run constant tests against user devices to determine the quality of the connection to company resources. The results of these tests are available on the Cloudflare One dashboard, enabling IT administrators to review and identify root causes when a specific user encounters difficulties accessing an application. These issues could stem from the user's local ISP or a specific underperforming SaaS service provider. This data is invaluable in helping administrators in diagnosing and addressing poor user experiences, leading to faster issue resolution.\n\nThe dashboard shows a comprehensive summary of the entire device fleet, displaying real-time and historical connectivity metrics for all organization devices. IT admins can then drill down into specific devices for further analysis.\n\nHaving acquired a comprehensive understanding of Cloudflare's SASE platform, you are now well-equipped to integrate it with existing infrastructure. This system efficiently secures access to applications for both employees and external users, starting from the initial request on the device and extending across every network to the application, regardless of its location. This powerful new model for securing networks, applications, devices, and users is built on the massive Cloudflare network and managed through an intuitive management interface.\n\nIt's worth noting that many of the capabilities described in this document can be used for free, without any time constraints, for up to 50 users. [Sign up](https://dash.cloudflare.com/sign-up) for an account and head to the [Cloudflare One](https://one.dash.cloudflare.com/) section. While this document has provided an overview of the platform as a whole, for those interested in delving deeper into specific areas, we recommend exploring the following resources.\n\n| Topic | Content |\n| - | - |\n| Cloudflare Tunnels | [Understanding Cloudflare Tunnel](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/) - [Open source repository for `cloudflared`](https://github.com/cloudflare/cloudflared) |\n| WAN as a Service | [Cloudflare Magic WAN documentation](https://developers.cloudflare.com/magic-wan/) |\n| Secure Web Gateway | [How to build Gateway policies](https://developers.cloudflare.com/cloudflare-one/traffic-policies/) |\n| Zero Trust Network Access | [How to build Access policies](https://developers.cloudflare.com/cloudflare-one/access-controls/policies/) |\n| Remote Browser Isolation | [Understanding browser isolation](https://developers.cloudflare.com/cloudflare-one/remote-browser-isolation/) |\n| API-Driven CASB | [Scanning SaaS applications](https://developers.cloudflare.com/cloudflare-one/integrations/cloud-and-saas/) |\n| Email security | [Understanding Cloudflare Email security](https://developers.cloudflare.com/email-security/) |\n| Replacing your VPN | [Using Cloudflare to replace your VPN](https://developers.cloudflare.com/learning-paths/replace-vpn/concepts/) |\n\nIf you would like to discuss your SASE requirements in greater detail and connect with one of our architects, please visit <https://www.cloudflare.com/cloudflare-one/> and request a consultation.\n\n<page>\n---\ntitle: Designing ZTNA access policies for Cloudflare Access Â· Cloudflare\n  Reference Architecture docs\ndescription: This guide is for customers looking to deploy Cloudflare's ZTNA\n  service. It provides best practices and guidelines for how to effectively\n  build the right policies.\nlastUpdated: 2025-10-24T20:47:24.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/reference-architecture/design-guides/designing-ztna-access-policies/\n  md: https://developers.cloudflare.com/reference-architecture/design-guides/designing-ztna-access-policies/index.md\n---\n\nOrganizations today are increasingly adopting a [Zero Trust security](https://www.cloudflare.com/learning/security/glossary/what-is-zero-trust/) posture to safeguard company assets and infrastructure in a constantly evolving threat landscape. The traditional security associated with legacy network design assumes trust within the corporate network perimeter. In contrast, Zero Trust operates on the principle of \"Never trust, always verify\" and implements continuous [authentication and strict access controls](https://www.cloudflare.com/learning/access-management/what-is-access-control/) for all users, devices, and applications, regardless of their location or network.\n\nTypically two technologies play a role in a Zero Trust architecture. First, a [Secure Web Gateway (SWG)](https://www.cloudflare.com/learning/access-management/what-is-a-secure-web-gateway/) filters outbound traffic destined for the Internet and blocks users from accessing high risk websites such as those involved in phishing campaigns. Then, to enable remote access for users to SaaS apps, internally-hosted applications and networks, Zero Trust Network Access ([ZTNA](https://www.cloudflare.com/learning/access-management/what-is-ztna/)) services are used to create secure tunnels and provide access for remote users into private applications.\n\nThis guide is for customers looking to deploy Cloudflare's ZTNA service ([Access](https://developers.cloudflare.com/cloudflare-one/access-controls/policies/)) and provides best practices and guidelines for how to effectively build the right policies. If you have not already done so, we recommend also reading Cloudflare's [SASE reference architecture](https://developers.cloudflare.com/reference-architecture/architectures/sase/), which goes into detail on all aspects of how to use Cloudflare as part of your Zero Trust initiatives.\n\n### Who is this document for and what will you learn?\n\nThis document is aimed at administrators who are evaluating or have adopted Cloudflare to replace existing VPN services or provide new remote access to internal resources. This serves as a starting point for designing your first ZTNA policies and as an ongoing reference. This guide covers three main sections:\n\n* **Technical prerequisites**: What needs to be in place before you can secure access to your first application and define access policies.\n* **Building policies**: The main components of an access policy and how they are combined.\n* **Use cases**: Common use cases and policies that can serve as blueprints for your own policy designs.\n\nThis design guide assumes you have a basic understanding of Cloudflare's ZTNA solution, [Cloudflare Access](https://developers.cloudflare.com/cloudflare-one/access-controls/). Therefore, this guide focuses on designing effective access policies and assumes you have already configured [DNS](https://developers.cloudflare.com/cloudflare-one/traffic-policies/initial-setup/dns/), [identity](https://developers.cloudflare.com/cloudflare-one/integrations/identity-providers/) and [device posture providers](https://developers.cloudflare.com/cloudflare-one/integrations/service-providers/) as well as [created connectivity](https://developers.cloudflare.com/cloudflare-one/networks/) to self-hosted applications and related networks.\n\nBy the end of this guide, you will be equipped to implement granular access policies that enforce Zero Trust principles across various common enterprise scenarios.\n\nThis section covers the essential architectural components and concepts to understand before you can design granular access policies.\n\nWe recommend reading the [SASE reference architecture](https://developers.cloudflare.com/reference-architecture/architectures/sase/) to get a deeper understanding of connecting applications, identity providers, and device posture providers.\n\nCloudflare allows organizations to facilitate application access using our [connectivity cloud](https://www.cloudflare.com/connectivity-cloud/), which securely connects users, applications and data regardless of their location. Core to the platform is Cloudflare's [extensive global network](https://www.cloudflare.com/network/) which delivers low-latency connectivity for users worldwide. By running every service in every data center, Cloudflare applies networking, performance and security functions in a single pass, eliminating the need to route traffic through multiple, specialized security servers, and therefore reduces latency and avoids performance bottlenecks.\n\n![Figure 1 shows the basic components involved in remote access with Cloudflare's ZTNA service.](https://developers.cloudflare.com/_astro/figure1.CjKTWbna_Z19SAh0.svg)\n\nThere are two main ways to provide access to private applications and networks: by public hostname, where requests are proxied to the application, or by private IP, where the user is on a device or network that is connecting them to their private corporate network via Cloudflare.\n\n### Active domain in Cloudflare\n\nTo use public hostnames, you need to have an [active domain](https://developers.cloudflare.com/fundamentals/manage-domains/add-site/) in Cloudflare. Most customers use Cloudflare as their primary DNS service, but it is possible to configure domains for use with Access and maintain [DNS records elsewhere](https://developers.cloudflare.com/dns/zone-setups/partial-setup/).\n\n### Network route to applications\n\nFor Cloudflare to control access, it needs to be in front of the application and have a secure and reliable network route for successfully authenticated users. Requests for application access come to Cloudflare first, where policy is applied, and then if successful, user requests are routed to the application.\n\nCloudflare supports access to the following types of applications:\n\n* SaaS applications on the Internet\n* Self-hosted applications accessed via public hostname\n* Self-hosted applications accessed via private IP\n\nFor SaaS and other Internet-facing applications, access from Cloudflare is simple â€” it is already on the Internet. But for self-hosted applications, you create a tunnel from Cloudflare to the private network where the application is running. There are two methods for doing this:\n\n* Our recommended approach is to use [software agents](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/) such as [cloudflared](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/get-started/) or [WARP connector](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/private-net/warp-connector/). (Note, only cloudflared currently supports proxying of public hostnames to private applications.)\n* For network-based connectivity, [Magic WAN](https://developers.cloudflare.com/magic-wan/) uses IPsec or GRE tunnels connecting Cloudflare to existing network appliances that are connected to the private networks, and [Network Interconnect](https://developers.cloudflare.com/network-interconnect/) creates direct connectivity if your applications run on servers in a data center Cloudflare operates in. (For migrating from existing legacy VPN solutions to network-based tunnels, you may find [this guide](https://developers.cloudflare.com/reference-architecture/design-guides/network-vpn-migration/) useful.)\n\nOnce we have established connectivity to your applications, it is time to facilitate user access. Depending on your policy requirements (more on this later) users can access the application directly over an Internet connection to a public hostname, or â€” for greater security â€” we recommend using our [device agent](https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/warp/), Cloudflare WARP, which creates a tunnel directly to Cloudflare and also provides information about their device for use in access policies.\n\nA critical part of application access is authenticating a user. Cloudflare has a [built-in authentication](https://developers.cloudflare.com/cloudflare-one/integrations/identity-providers/one-time-pin/) method based on email. But we highly recommend configuring a third-party identity provider. We support both consumer and enterprise [identity providers](https://developers.cloudflare.com/cloudflare-one/integrations/identity-providers/), and any SAML or OpenID compliant service can be used. Group membership is one of the most common attributes of defining application access and can be defined manually or imported using the System for Cross-Domain Identity Management ([SCIM](https://developers.cloudflare.com/cloudflare-one/team-and-resources/users/scim/)).\n\nThe final prerequisite for building really effective access policies is to configure [device posture](https://developers.cloudflare.com/cloudflare-one/reusable-components/posture-checks/). When using the [device agent](https://developers.cloudflare.com/cloudflare-one/team-and-resources/devices/warp/), Cloudflare has access to a [variety of information](https://developers.cloudflare.com/cloudflare-one/reusable-components/posture-checks/warp-client-checks/) about the device which can then be used in an access policy. When using an [agentless method](https://developers.cloudflare.com/reference-architecture/diagrams/sase/sase-clientless-access-private-dns/) to access applications, only the user identity information is available. We also support using device posture information from [other vendors](https://developers.cloudflare.com/cloudflare-one/integrations/service-providers/), such as Microsoft, Crowdstrike and Sentinel One.\n\n![Figure 2 - two employees with different devices trying to access the same corporate application. Only the user with the device agent can access the SSH service.](https://developers.cloudflare.com/_astro/figure2.BibmIt2I_1gYxP5.svg)\n\nTo quickly summarize the architecture described so far, Cloudflare is:\n\n* In front of network access to the application.\n* Integrated with your identity providers.\n* Aware of device posture details for your users using our device agent or a third party vendor.\n\nWhen a user makes a request to access an application, they must first authenticate, then, before access is granted, policies in the application are evaluated based on the data associated with the requesting user. Policies and other application specific settings are defined in an Access application.\n\n### Access application types\n\nCloudflare Access supports four main types of applications:\n\n* **Self-hosted** refers to applications that your organization hosts and manages, either on premises or in the cloud. Cloudflare creates a public hostname which it uses to proxy traffic through a secure tunnel to the application. While access via public hostnames is supported if your server is just publicly facing on the Internet, we recommend you use `cloudflared` to create a secure, outbound-only connection from your application to Cloudflare's edge. Once that occurs, Cloudflare will then reverse proxy the target application/content to your users.\n* **Private IP** applications are similarly privately hosted, but lack fully-qualified public hostnames. Access can be facilitated via `cloudflared`, WARP Connector, Cloudflare Magic WAN, or Cloudflare Network Interconnect. Remote users not connected to a network already connected to Cloudflare will need to use the device client to get access to the application via private IP and to avoid using IP addresses with users, use [internal DNS services](https://developers.cloudflare.com/cloudflare-one/traffic-policies/resolver-policies/#use-cases) to resolve private hostnames to private IP addresses. But it is possible to provide access without any software deployed to the client by using our agentless [browser isolation service](https://developers.cloudflare.com/reference-architecture/diagrams/sase/sase-clientless-access-private-dns/).\n* **SaaS** applications are accessed over the public Internet, and therefore do not require any tunnel connectivity to Cloudflare. Instead, Access acts as an identity proxy between users and the SaaS application. When a user attempts to access the SaaS app, they are first authenticated by Cloudflare, which redirects to your main identity service. SaaS applications are then configured via SAML or OAuth to trust Cloudflare. This allows organizations to implement additional security layers (like device posture checks) and centralize access control for their SaaS applications, even if the SaaS or identity provider does not natively support these features.\n* **Infrastructure** applications enable users to control access to individual servers, clusters or databases in a private network. Infrastructure apps work by defining a 'target' proxied over `cloudflared`, but allows users to group multiple machines under the same target - essentially, allowing users to define common access policies across potentially disparate infrastructure resources. Built-in access and command logging capabilities means organizations can maintain detailed audit trails for compliance and security investigation purposes.\n\nIt is possible to configure SaaS applications to accept traffic only coming from Cloudflare. This forces all SaaS application traffic to be proxied and routed via Cloudflare Gateway which, in turn, allows for the use of security controls to inspect and filter traffic such as downloads of sensitive company data from SaaS applications. The second use case below will describe how to achieve this.\n\nAccess applications typically map directly to a single application. However, it is possible to have an Access application, and its associated policies sit in front of more than one application endpoint. This might be a range of IPs related to multiple Windows RDP servers where you wish to implement a common access policy. The same idea can also be applied to public hostnames, where you might have more than one hostname that refers to several applications you wish to have the same policies. For instance, you might have wiki.domain.com and wiki.domain.co.uk â€” different application instances, but with common access policy requirements.\n\nNext, we examine the main elements of a ZTNA-protected application that need to be understood to create effective access policies, then later in the document we will examine some use cases that apply those specific elements.\n\nAuthenticating a user's identity is a key component of any Zero Trust policy. When attempting to log into an application, a user will be redirected to a configured identity provider. If a user fails to authenticate with the identity provider, Cloudflare will not accept their request for the application.\n\nAs mentioned above, Cloudflare can be integrated with all your identity providers (IdPs), both enterprise and consumer. Then at the application and policy level, you choose which IdPs you want to allow for authentication. For example, you may have an application that only a limited number of employees can access. Therefore, you would only enable your corporate IdP. For another application, you may wish to allow access to a wider group of non-employee users, such as contractors or third-party partners. Some of those users you might authenticate via their GitHub or LinkedIn credentials.\n\nWhen a user attempts to access an application they will be presented with a sign-in page where they choose which IdP to authenticate with. For applications with only a single IdP, you can automatically redirect the user to that IdP. It is also possible to configure the application to display every possible IdP that has been configured, allowing you to add new providers in the future without the need to update the policy.\n\n![Figure 3 - How employees from different parts of the organization authenticate to the same application.](https://developers.cloudflare.com/_astro/figure3.eRr6LFPW_18nofX.svg)\n\nAfter authentication, the IdP is going to send information about the identity back to Cloudflare. Depending on the IdP, this information may include [Authentication Method Reference](https://datatracker.ietf.org/doc/html/rfc8176) (amr) values, IdP groups, SAML attributes or OIDC claims which can then be used in policies.\n\nWhen using our device agent, users must also authenticate and can be presented a custom list of IdPs. Once the agent is authenticated, they are able to connect to Cloudflare and it is possible to configure applications to skip authentication, instead trusting the existing authentication session associated with the device agent.\n\nNow we arrive at the main focus of this guide: the policies which define access to applications. This is where the real work is done to define who has access, and how. Before looking at example use cases, here is a breakdown of how policies work.\n\n![Figure 4 - Our ZNTA service Access can use a wide variety of attributes in an access policy.](https://developers.cloudflare.com/_astro/figure4.Hsz5t8u9_2jA9r2.svg)\n\nEach application can contain multiple policies, and are evaluated in order. Because multiple policies â€” each with multiple sets of rules â€” can get quite complex, there is a policy tester where you provide a username and see how the user is evaluated against all the policies and rules. Policies consist of the following elements:\n\nWhile it seems obvious what this is for, we highly recommend having a strategy for naming your policies. This is because you will likely create similar policies across multiple applications, such as \"Allow all full-time employees\" or \"Block high-risk users\". Using the same naming scheme across all applications will vastly streamline your ability to review application access and to understand the full list of policies in the future.\n\nThe Action field in a policy determines what happens when a user or service matches the policy's criteria. There are four main types of actions:\n\n* **Allow** grants access to the application. A login page will be presented to a user on initial access request.\n* **Block** denies access to the application. This is generally not required because Access is denied by default. The only reason users should implement a block policy is for testing a specific policy condition or short-circuiting policy evaluation. If a block policy has higher precedent than an Allow, and a user matches the block policy, all other policy evaluation ceases.\n* **Bypass** allows users or services to disable any enforcement for traffic before accessing the application. For example, a specific endpoint in an application may need to be broadly accessible over the Internet.\n* **Service Auth** allows you to authenticate requests from other services or applications using [mTLS](https://developers.cloudflare.com/ssl/client-certificates/enable-mtls/) or [service tokens](https://developers.cloudflare.com/cloudflare-one/access-controls/service-credentials/service-tokens/). No login page will be presented to the user or service if they meet this policy criteria. This is designed so that non-user requests, such as those from other applications, can access secured resources.\n\nCloudflare Access is a deny by default service, which means if a request does not match any policy action, the default action is \"Block.\"\n\n#### Session duration\n\nSession duration refers to the length of time a user's authentication remains valid after they have successfully logged in to an application. Typically, the session duration is set for 24 hours, but you can also set durations for sensitive applications to expire immediately. This approach aligns with the core Zero Trust principle of \"never trust, always verify.\" Even if a user initially presents the appropriate device posture and identity context, continuous verification ensures that access rights are reassessed with each new request. This method significantly reduces the risk window, as it removes the assumption that the initial authentication and authorization state remains valid over an extended period.\n\nThese are the main focus of a policy. Rules define all the attributes that dictate if the policy allows or denies access, or renders the application in an isolated browser. They are composed of a selector and value, which is essentially the attribute you wish to evaluate and the data you are evaluating.\n\nEach rule is a filter to determine which users this policy is going to affect. There are several categories of rules:\n\n* **Include** rules define who or what is eligible for access. When a user matches an \"Include\" rule, they become a candidate for access, subject to other rules types in the policy. These rules use OR logic â€” satisfying any one is sufficient. For example, you may make an application available to a specific group, but need to add in contractors for an email list, and as long as the user matches one of these (group membership, or a valid email) they are included in the rule. Every policy must have at least one Include clause.\n\n* **Require** rules set mandatory conditions that must be met for access to be granted. Unlike Include rules, \"Require\" rules use AND logic â€” every rule must be met. This is typically used to layer security on top of the basic access criteria defined by Include rules. For example, administrators can require that anyone trying to access an application use specific MFA methods.\n\n* **Exclude** rules define exceptions to access, overriding other rule types. If a user matches an \"Exclude\" rule, they're denied access regardless of other policy conditions. For example, a user may meet a requirement to use a MFA method during login, but if their specific [multifactor authentication (MFA) method](https://developers.cloudflare.com/cloudflare-one/access-controls/policies/mfa-requirements/) is defined in an Exclude rule, they will be blocked by the policy. Alternatively, if a user is associated with a 'high risk' IdP group, they can be excluded on that basis even if they meet all the other posture requirements.\n\nA useful way to imagine how these different types of rules are applied, is to imagine a funnel. Include selectors define what attributes of the user, traffic or device are included in the policy that will be Allowed, Blocked and so on. Require then further filters from that list what attributes must be associated with the user with the Exclude type filtering out users who have matched both the Include and Require.\n\n![Figure 5 - Policies and rules are evaluated in a funnel. With Include rules aggregating all users, Require rules mandating specific requirements and Exclude rules removing user identities from the policy evaluation.](https://developers.cloudflare.com/_astro/figure5.DEijf6Ia_au3nz.svg)\n\nThe above diagram visualises an example for the policy \"All employees and contractors on secure devices using strong MFA\". Anyone in the group \"All Employees\" or contractors who have authenticated with a username in their company domain will match this policy. They are required to be using a device that has the latest OS and is using encrypted storage. They must have authenticated with an MFA factor, but not SMS. Also, they must be accessing the application via Cloudflare's secure web gateway.\n\nThere are many different [types of selectors](https://developers.cloudflare.com/cloudflare-one/access-controls/policies/#selectors). While every possible selector is not listed here, the following lists specific outcomes that organizations using Cloudflare Access typically desire when building policies. This will help you understand how to achieve a specific outcome.\n\n* **Is user traffic coming over Cloudflare Gateway?** Guaranteeing that a user only accesses an application over our SWG, Cloudflare Gateway, is a great way to prevent unauthorized access due to phishing or credential theft. Additionally, you can ensure all traffic bound to the application is logged and filtered by Cloudflare Gateway.\n\nYou can configure this control by enabling the \"gateway\" device posture check and then requiring \"gateway\" in your application policies. Requiring \"gateway\" is more flexible than relying solely on the device agent because users can also on-ramp from Browser Isolation or a Magic WAN-connected site, both of which provide traffic logging and filtering. Additionally, when using the device agent, this allows you to guarantee that a user is coming from a compliant device that has passed a set of device posture checks.\n\nRequiring the gateway is enforced continuously for [self-hosted applications](https://developers.cloudflare.com/cloudflare-one/access-controls/applications/http-apps/self-hosted-public-app/). For SaaS apps, it is only enforced at the time of login. However, a dedicated egress IP can be leveraged in tandem to enforce that traffic always goes via Cloudflare Gateway.\n\n* **Does the user belong to an existing group, or have specific identity attributes?** If your IdP supports SCIM, group membership information can be imported into Cloudflare, where it can be used in policies. Group information can also come from the SAML or OAuth data sent as part of authentication. In fact, when OIDC or SAML is used and claims are sent, they can be used in a policy. So if your users authenticate to your IDP using SAML, and the resulting token contains their \"role,\" you can query that value in the rule.\n\n* **Which identity service was used for authentication ?** Similar to IdP groups and attributes, this \"Login methods\" selector asks which identity service was used, and, like IdP groups, this is better suited to an access group rather than a specific line item on an access policy. Login methods allow you to apply different policies to specific users who authenticated with certain identity providers. For example, you might only allow users who have authenticated with a consumer identity such as GitHub or LinkedIn to gain access if their authentication method included a hard token-based MFA.\n\nThis is an atypical scenario, but if you do need to enable multiple IdPs for authentication, then you can use this selector to make sure users are authenticating with a specific service. The value of this requirement becomes clearer when dealing with multiple layered security policies, and need to define different levels of access based on the login.\n\n* **Individual or organizational emails** All identity services provide an email address, which in many cases matches the individual's username. Using an email in a policy can be useful when wanting to allow access to an entire domain of users, but they might authenticate via a consumer IdP that allows for any email. For example, you might only allow access for users who have authenticated via GitHub using their @company.com email address.\n\nAnother good use of this selector is if you are managing a [list of emails](https://developers.cloudflare.com/cloudflare-one/reusable-components/lists/) of users that might be high risk or have been blocked from a specific application. You can use an Exclude rule, with your list to ensure a subset of users cannot access an application.\n\n* **How did the user authenticate?** When an identity provider authenticates a user and then redirects them back to Cloudflare, it includes information about what authentication method was used. This is typically sent as [Authentication Method Reference](https://datatracker.ietf.org/doc/html/rfc8176) data. Using this you can check if MFA was used and what type.\n\nThis can be useful to define different levels of credential requirements for different applications. For example, a general company application might just require that MFA was used and not care how. But a really sensitive administration tool might require a FIDO2 hardware-based security key,and therefore explicitly deny access if only an OTP via SMS is used as part of the authentication process.\n\n* **What country is the request coming from?** You can set rules based on the geographic lookup of the incoming request. This could be useful for restricting access to certain countries where you do business.\n\n* **What IP range is the request coming from?** You can set rules based on the IP range of the incoming request. This could be allowing access only from your corporate network IP ranges.\n\n* **Is it possible to verify device or user information from a list?** Sometimes, you might want to grant or restrict access based on specific device or user characteristics that do not fit neatly into other categories. This is where [lists](https://developers.cloudflare.com/cloudflare-one/reusable-components/lists/) come in handy: you can define or import a list of contractor emails, or a list of approved device serial numbers and use those as criteria within an Access policy. These lists can be updated manually or via our [API](https://developers.cloudflare.com/api/resources/zero_trust/subresources/gateway/subresources/lists/methods/create/), allowing for integration with other device or user management systems.\n\n* **Is the device's security posture adequate?** This is where the device client provides telemetry on the native device making the access request. It accomplishes this by performing device-level scans. Is the device's hard drive encrypted? The agent can check if technologies like BitLocker or FileVault are active, in addition to checking for specific volume names. If you are protecting a sensitive application, or something that holds critical information, this is an effective requirement to enforce.\n\n* **Is the request being made by another process or application?** It is not always a real human on a device attempting to access an application. This makes it useful to leverage Cloudflare Access to manage communication to APIs by other software. The request may contain service tokens, mutual TLS certificates, and SSH certificates, which enables logins for automated processes and machine-to-machine communication. Using service auth options within Cloudflare also centralizes the storage and lifecycle management of these tokens and certificates.\n\n* **What does your third-party tool say about your device?** Many organizations use other specialized tools for endpoint security, such as Crowdstrike, SentinelOne, or Microsoft Intune, to provide telemetry regarding the security posture of the device making the application request. Rather than require the user to navigate multiple UIs, you can integrate these tools into Cloudflare One via their API, and apply their insights into device posture attributes that can be enforced during an application login.\n\nSome third-party device posture integrations can be used even when the user device does not have our agent installed. Instead, the third party integration matches the user based on email and provides information directly to Cloudflare.\n\n#### Additional settings\n\nBelow are a few additional application settings to consider that help improve security.\n\n##### Isolate application\n\nSometimes you want to manage access to a self-hosted application for less trusted, third-party users such as contractors or partners. You might want to allow them to read content in an application, but limit their ability to download files, copy and paste data, and print the page. Cloudflare Access allows you to render the application in a remote [browser](https://developers.cloudflare.com/cloudflare-one/access-controls/policies/isolate-application/) (using [remote browser isolation, or RBI](https://developers.cloudflare.com/cloudflare-one/remote-browser-isolation/)) so that the application is rendered using a headless browser on our network versus sending all the content down to the user's browser. This allows Cloudflare to then enforce a range of controls over how the user can interact with the content.\n\nThe setting is at the policy level, so one policy can allow trusted users (such as employees) to access applications normally, while another policy with browser isolation enabled can apply the RBI service for contractors.\n\nThis setting forces traffic to an isolated browser before being delivered to the end user, which means all traffic is then inspected and managed by Cloudflare Gateway. To limit what the user can do, you need to create an accompanying policy in the gateway, which also identifies the same users and then enforces the [controls](https://developers.cloudflare.com/cloudflare-one/remote-browser-isolation/isolation-policies/#policy-settings) you wish to limit access. Note that it is important to write the Gateway policy such that it only enforces RBI for the same group of users accessing the application that the Cloudflare Access policy applies to. Otherwise, the policy will default to enforce browser isolation for all users.\n\nIt is possible to actually enforce RBI for the same set of users if they attempt to access the application using a non-secured device. In this case, you would continue to define a policy for employees in Cloudflare Access. But then, also create a policy in Cloudflare Gateway to isolate the application if users going to the same application URL have failed a device posture check that deems the device is not managed or secure. This could be if the device does not have the company endpoint security client (Crowdstrike or SentinelOne for example) installed, or has failed a security check. We will demonstrate this in the use cases below.\n\nInversely, isolating the browser also protects the local device from anyone attempting to exploit vulnerabilities or execute malicious code against the application.\n\nYou may wish to audit an application's every authentication event and capture justification details. This setting creates a more well-defined audit trail of user access, and allows administrators to review and analyze access patterns and justifications. When enabled, users will be prompted to provide a brief explanation before gaining access. This can be particularly useful for sensitive applications or during specific time periods, such as outside normal business hours.\n\n##### Temporary authentication\n\nAdd an additional layer of access control by requiring users to obtain \"temporary authentication\" approval from designated authorizers before accessing the application. When enabled, users requesting access will trigger a notification to authorized approvers.\n\nOne of the most important parts of defining ZTNA policies is to leverage reusable elements called [Access Groups](https://developers.cloudflare.com/cloudflare-one/access-controls/policies/groups/). Each access group uses the same rules we've just described to define users, traffic or devices. These groups can then be used across many policies to allow, deny, bypass, or isolate access to an application.\n\nFor example, you can define \"Employees\" once as an Access Group, and then use that in every application policy where you want to refer to employees. Updates to this Access Group would then be reflected in every policy. This is also a good way to include nested logic (for example, users with a Linux device and has antivirus software enabled)\n\nBelow is a diagram featuring an Access Group named \"Secure Administrators,\" which uses a range of attributes to define the characteristics of secure administrators. The diagram shows the addition of two other Access Groups within \"Secure Administrators\". The groups include devices running on either the latest Windows or macOS, along with the requirement that the device must have either File\n\n![Figure 6 - An access group that matches to IT administrators on secure systems.](https://developers.cloudflare.com/_astro/cf1-ref-arch-24.aWooHqll_2v76br.svg)\n\nNow that the basic infrastructure to secure access to an application and the policy systems have been covered, let's dive into some common use cases.\n\n### Only allow company wiki access to users on trusted devices\n\nMany companies host some sort of internal content system where confidential company information resides. Wiki's are a common type of application that allows employees to collaborate easily with anyone. But because this information is confidential, it is important to both validate the user authentication with strong credentials, and also ensure that their access is via a secure device, via a secure connection.\n\nHowever, sometimes company users use non-company devices and need to access the wiki. You may wish to set up a policy that allows this, but limits the user's actions. For instance, prevent them from editing the data, or from copying and pasting it to their unmanaged device. This use case explains how to set up a Cloudflare Access application to define secure access for employees, giving them fully functional access when they are on a secured device over a secured connection, but still allow them some limited access from a non secure device.\n\nFirst, create an Access application with the following parameters:\n\n| Name | Company Wiki |\n| - | - |\n| Type | Self-hosted |\n| Public Hostname | wiki.mycustomerexample.com |\n| Authentication | Company Microsoft Entra IdP |\n| Policies | Employees on trusted devices Employees using untrusted devices |\n\nBefore we examine how the two policies are defined, observe an example where an Access Group was created to identify an employee and approved devices were running the latest operating system version.\n\n#### Access Group: Secure employees\n\nThis access group is going to be used in both policies, and its sole goal is to identify what a \"Secure Employee\" is.\n\n| Name | Secure Employees |\n| - | - |\n| **Include** | |\n| Azure AD Groups | \"Full-Time Employees\" |\n| **Require** | |\n| Azure AD Groups | \"Completed security training\" |\n| OS Version | \"Latest version of macOS\", \"Latest version of Windows\", \"Latest Kernel version for Linux\" |\n\nThis is a very simple Access Group, with just two group selectors. Note that because we are checking membership based on groups from a specific directory, it also implies that the user must have authenticated to that directory. It means in the future, if you move to another identity provider or change the group membership requirements for what defines a Full-Time Employee, you change just this Access Group once.\n\nAs you can see, it defines that \"all employees\" are those in the Azure AD group \"Full Time Employees\", who are also in the group \"Completed security training.\" The first selector defines the initial scope of the Access Group, and the second selector requires that they must also be in that specific group.\n\nThis Access Group requires that three [device posture checks](https://developers.cloudflare.com/cloudflare-one/reusable-components/posture-checks/warp-client-checks/) have been created for the [OS version](https://developers.cloudflare.com/cloudflare-one/reusable-components/posture-checks/warp-client-checks/os-version/). For example, the posture check \"Latest version of macOS\" is defined as \"macOS version is greater than or equal to 15.1\" and reflects the latest version the company considers stable and secure (vs. the very latest OS version). Once included in the Access policy, this will enforce the logic weâ€™ve established here - if any user wants to sign in as a 'Secure Employee', they'll need to meet these requirements.\n\n#### Employees on trusted devices\n\nNow we define the first policy in the application. First, select the Access Group that has already been defined. Then, define the following rules to determine how users authenticate and how they connect to the application.\n\n| Policy name | Employees on trusted devices |\n| - | - |\n| Action | Allow |\n| Access groups | Include - Secure employees |\n| **Rules** | |\n| Require | |\n| Authentication Method | MFA - Multiple Factor Authentication |\n| Gateway | On |\n| **Additional settings** | |\n| Isolate Application | No |\n\nThis policy ensures that users can gain full access to your company wiki only if they have passed the following requirements:\n\n* They are full-time employees on devices with the latest operating system.\n* Users have authenticated using MFA.\n* Users are accessing the application via a device that has the Cloudflare device agent running.\n\n#### Employees using untrusted devices\n\nThe second policy should handle users who are not on secure devices. Note that this policy is second in the list of policies in the application and therefore will be evaluated when users do not meet the requirements of the first policy.\n\n| Policy name | Employees using untrusted devices |\n| - | - |\n| Action | Allow |\n| Access groups | Include - All Employees |\n| **Rules** | |\n| Require | |\n| Authentication Method | MFA - Multiple Factor Authentication |\n| **Additional settings** | |\n| Isolate Application | Yes |\n\nAlthough this policy is very similar to the first, it removes the requirement to have a device on the latest operating system and also using our device agent. The user is still required to be a full-time employee authenticated with strong, MFA-backed credentials.\n\nBut notice we now enable \"Isolate Application.\" What does this mean? This forces all requests to the application to now be rendered on our RBI technology. RBI will prevent the wiki UX from loading directly in the end user's browser, and instead renders the content in a headless browser running on a server in Cloudflare's global cloud network. Then, the results of that render are securely and efficiently communicated down to the end user's browser. Because of this, the request is also sent via our SWG service, which enables you to write a policy that controls how users can interact with the wiki.\n\n**Gateway HTTP Policy**\n\n| Isolate company applications for users on insecure devices | |\n| - | - |\n| Action | Isolate |\n| **Traffic** | |\n| Domain in | wiki.mycustomerexample.com |\n| **Device Posture** | |\n| Passed device posture not in | Warp Check |\n| **Settings** | |\n| Disable copy / paste | Yes |\n| Disable file downloads | Yes |\n| Disable file uploads | Yes |\n| Disable keyboard | Yes |\n| Disable printing | Yes |\n\nIn the example above, the SWG policy is matching any traffic heading to your company wiki, then enforcing RBI (to match the ZTNA application policy) and then disabling all interaction with the wiki.\n\nIt also adds the device posture check \"WARP Check (Mac OS)\" to scan the user's device for the presence of our device agent. If the user's device does not have the agent installed and enabled, then the device posture check cannot occur and they will automatically fail to meet the policy requirements. If the user does have the device agent enabled, then they will pass the posture check and be granted full wiki access. Note that WARP is the name used for our device agent.\n\nEssentially, the employee on an insecure device is permitted to view the wiki in a \"read-only\" mode, but is restricted from further interactions like uploading/downloading or copying/pasting confidential information.\n\nThis policy approach accomplishes several objectives:\n\n1. It enforces the use of trusted devices for full access to the wiki, aligning with your Zero Trust security goals.\n2. It provides a fallback option for employees using personal devices, allowing them to access the wiki in a limited, secure manner through browser isolation.\n3. It incentivizes employees to use their company devices and/or keep WARP enabled, which is a net positive for an organization's security posture.\n4. It demonstrates the power and flexibility of more granular security controls achieved by combining Cloudflare Access policies with Cloudflare Gateway HTTP policies.\n\nThis approach both secures your wiki and establishes a model for protecting other applications â€” allowing your organization to maintain strong cyber hygiene while adapting to the realities of hybrid work scenarios.\n\n### Secure access to Salesforce\n\nThe second use case implements a secure access strategy that also requires the use of the device client. However, the implementation is slightly more involved than the previous wiki example.\n\nBefore addressing the specifics, you will learn about the benefits of securing access to SaaS apps through Cloudflare. After all, Salesforce and other major SaaS providers already offer robust security features, including their own access controls, MFA, and audit logs. So why do some organizations still choose to route their SaaS traffic through Cloudflare?\n\nThe key benefit here is centralizing security policy enforcement across your entire IT ecosystem. By routing Salesforce access through Cloudflare, you are not just securing Salesforce â€“ you are integrating it into a broader Zero Trust strategy that includes a single point of visibility for all user activity, and reduces the complexity of managing multiple security systems. It also allows you to implement the enforcement of many different IdPs for access to a single SaaS application.\n\nIn the context of this use case, it is important to protect Salesforce â€” which contains sensitive customer data â€” against misuse, and to secure access only to authorized users. We are going to design a secure access policy that can cover both of these objectives.\n\nThe first step is to configure an [egress IP policy under Cloudflare Gateway](https://developers.cloudflare.com/cloudflare-one/traffic-policies/egress-policies/). This allows you to purchase and assign specific IPs to your users that have their traffic filtered via Gateway. Then in Salesforce, you can enforce that access is only permitted for traffic with a source IP that matches the one in your egress policy. This combination ensures that the only way to get access to Salesforce is via Cloudflare.\n\n| Egress Policy | |\n| - | - |\n| **Identity** | |\n| User Group Names | All Employees |\n| **Select Egress IP** | |\n| Use dedicated Cloudflare Egress IPs | \\[203.0.113.88] |\n\nThis is important not only for securing access to Salesforce, but also for adequately protecting its contents while in use. The next step is to examine the access policy which is similar to the one we just created for the wiki. However, this policy is limiting access to members of the Sales or Executives groups. We are also using our Crowdstrike integration to ensure that users are on company managed devices.\n\n| Policy name | Account executives on trusted devices |\n| - | - |\n| Action | Allow |\n| **Include** | |\n| Member of group | Sales, Executives |\n| **Require** | |\n| Authentication method | MFA - multi-factor authentication |\n| Gateway | On |\n| Crowdstrike Service to Service | Overall Score above 80 |\n\nThe second policy now applies to all employees but we are going to apply a few more steps before access is granted.\n\n| Policy name | Employees on trusted devices |\n| - | - |\n| Action | Allow |\n| **Include** | |\n| Member of group | All Employees |\n| **Require** | |\n| Authentication method | MFA - multi-factor authentication |\n| Gateway | On |\n| Crowdstrike Service to Service | Overall Score above 80 |\n| **Additional Settings** | |\n| Purpose justification | On |\n| Temporary authentication | On |\n| Email addresses of approvers | <salesforce-admin@company.com> |\n\nWe are going to add in temporary authentication to this second policy. That means if Cloudflare determines that the incoming request is from someone outside of the Sales or Executives department, an administrator will need to explicitly grant them temporary access. In context, this policy could be used to secure access to Salesforce for employees outside the Sales department, as the customer information could be sensitive and confidential.\n\nThis approach is important for several reasons:\n\n* It allows for human oversight on potentially risky access attempts, reducing the chance of unauthorized access through compromised or insecure devices.\n* It provides flexibility for legitimate users to access the application even when their device fails to meet the highest security standards. This encourages users to maintain good security practices on their devices.\n* In addition, since all user traffic is routed through Cloudflare, we can enforce additional security measures (such as preventing the download of sensitive data) via web traffic policies.\n\n### Only allow secure admins access to database tools\n\nThis scenario covers protecting a PostgreSQL database administration tool. This represents a privately-hosted, high-value target due to its access to sensitive data. It also requires taking extra care in designing secure access for it. Given the nature of database tools, access policies will not be layered for this use case.\n\n| Policy name | Only IT admin access |\n| - | - |\n| Action | Allow |\n| **Include** | |\n| Assign a group | IT Admins |\n| **Require** | |\n| Authentication method | MFA - multi-factor authentication |\n| Gateway | On |\n| Device Posture - Serial Number List | Company Managed Device Serial Numbers |\n| OS Version | Latest version of Windows |\n| Domain Joined | Joined to corporate AD domain |\n| **Exclude** | |\n| Authentication method | SMS |\n| **Additional Settings** | |\n| Purpose justification | On |\n\nHere, we are introducing a high number of security posture checks, starting with MFA. We have two expressions regarding MFA: the first one requires that users authenticate with a MFA method. The second 'excludes' expression pointing out that SMS is not considered a valid authentication method. We do this because SMS is one of the easier methods for attackers to exploit and subvert, and therefore [considered less secure](https://sec.okta.com/articles/2020/05/sms-two-factor-authentication-worse-just-good-password) than other MFA methods. As a result, we are only allowing access when the user provides stronger credentials such as a hard key or an OTP from an authenticator app. Enforcing these stricter MFA requirements reduces the risk of credential-based attacks, and makes it much more challenging for potential attackers to gain unauthorized access to this critical databaseâ€”even if they have obtained the user's password.\n\nOther posture elements here include:\n\n* Requiring the latest OS.\n* The user's device is joined to a Microsoft Active Directory domain.\n* The user's device is explicitly a company-managed device (shown by referencing a list of managed device serial numbers).\n\nThese combined posture checks ensure that only up-to-date, company-controlled devices within your managed environment can access the database, further reducing the attack surface and the risk of access from potentially compromised or uncontrolled endpoints.\n\nUnder additional settings, we are also requiring that users enter a purpose justification for accessing the database. This allows your security teams to analyze access patterns and identify potentially suspicious behavior. This set of security controls also ensures that access to your critical database is tightly regulated, logged, and justified â€” significantly reducing the risk of unauthorized access or misuse.\n\nThis level of protection and visibility would be significantly more complex and resource-intensive to achieve with disparate, standalone security solutions. Centralizing security policy enforcement via Cloudflare allows you to simplify how you implement fine-grained access to critical internal resources.\n\n### Secure RDP access\n\nThis final use case centers on securing remote access to devices via RDP in two ways â€” self-hosted or private IP. Both options offer unique benefits, but ultimately it comes down to your priorities: is it more important to simplify access, or to tightly monitor activity?\n\nWe will start with the self-hosted option â€” proxying port 3389 over a tunnel, mapping it to a hostname.\n\n| Application Configuration | |\n| - | - |\n| Application Name | RDP service on database server |\n| Hostname | rdp.databaseserver.company.internal |\n\n| Policy name | Admin Access |\n| - | - |\n| Action | Allow |\n| **Include** | |\n| Member of Group | IT Admins |\n| **Require** | |\n| Authentication method | MFA - multi-factor authentication |\n| Gateway | On |\n| WARP | On |\n| Device Posture - Serial Number List | Company Managed Device Serial Numbers |\n| External Evaluation | \\[Time Evaluator URL] |\n\nInside the policy, we have made this application available to our new access group for IT Admins. Under \"Require,\" we are enforcing the use of Cloudflare WARP specifically (as opposed to only Cloudflare Gateway). The user must be on a company-managed device, with an active device client that is authenticated to the company's instance of Cloudflare, MFA must be used during login, and there is an additional option below for external evaluation.\n\n[External evaluation](https://developers.cloudflare.com/cloudflare-one/access-controls/policies/external-evaluation/) means we have an API endpoint containing some sort of [access logic](https://github.com/cloudflare/workers-access-external-auth-example) â€” in this case, time of day access. We are making an API call to this endpoint, and defining the key that Cloudflare is using to verify that the response came from the API. This is useful for several reasons:\n\nExternal evaluation allows users to create bespoke security posture checks based on criteria that may not be covered by the default set of posture checks. For this example, we will be using a service built on [Cloudflare Workers](https://workers.cloudflare.com/).\n\n* Restricting access to the terminal outside of business hours implements a form of time-based access control. This adds an extra layer of security by limiting the window of opportunity for potential attackers.\n\nNow, you will learn how to secure RDP access as a private IP application:\n\n| Application Configuration | |\n| - | - |\n| Application Name | RDP |\n| Destination IP | 169.254.255.254 |\n\nAs mentioned before, private IP applications work because Cloudflare proxies the IP range across its network. The nature of this application necessitates the use of the device client, as unless the user is connected to Cloudflare (and more specifically, unless they can take advantage of the WARP-to-Tunnel connectivity), they will not be able to reach non-local RFC 1918 addresses.\n\n| Traffic | |\n| - | - |\n| Destination IP | 169.254.255.254 |\n| Destination Port | 3389 |\n| **Identity** | |\n| User Group Names | Server Admins |\n| **Device Posture** | |\n| Passed Device Posture Checks | WARP Check (Mac OS) (File) Latest Version of macOS (OS version) |\n| **Action** | Allow |\n| **Enforce WARP client session duration** | 60m0s |\n\nDefining the application here is simple, as Cloudflare automatically fills in the IP range, and you need to limit the detected protocol to RDP. However, the rules for private IP applications are slightly different. You will notice they appear as network policies under the Cloudflare Gateway menu, despite managing them in Access. Certain options, such as checking for MFA and external evaluation, do not appear here. However, these attributes can be verified when the user activates their device client and authenticates to their organization.\n\nOne option available here is enforcing the device agent client session duration. This means that after a certain amount of time, the user will be forced to reauthenticate. This feature allows you to take a Zero Trust approach to protecting private IP applications as well. It ensures that even if a user's credentials are compromised or their device is left unattended, the potential window for unauthorized access is limited. By regularly requiring reauthentication, we are continuously verifying the user's identity and authorization status, aligning with the core Zero Trust principle of \"never trust, always verify.\"\n\nBy combining granular access controls with detailed activity logging, Cloudflare provides a comprehensive security solution for protecting and monitoring access to critical resources in a Zero Trust methodology.\n\nSuccessful ZTNA implementation is about more than just technical configuration â€” it requires careful consideration of your organization's specific needs, user workflows, and security requirements. Cloudflare's flexibility allows you to start with basic secure access policies, then evolve them as your organization's needs change and security requirements mature. By following the principles and practices outlined in this guide, you can create a robust security posture that protects you as precisely and transparently as possible.\n\nIf you are interested in learning more about ZTNA, SASE, or other aspects of the Cloudflare One platform, please visit our [reference architecture library](https://developers.cloudflare.com/reference-architecture/) or our [developer docs](https://developers.cloudflare.com/) to get started.\n\n* [Cloudflare SASE reference architecture](https://developers.cloudflare.com/reference-architecture/architectures/sase/)\n* [Using Cloudflare SASE with Microsoft](https://developers.cloudflare.com/reference-architecture/architectures/cloudflare-sase-with-microsoft/)\n* [How to deploy Cloudflare ZTNA](https://developers.cloudflare.com/learning-paths/clientless-access/concepts/)\n\n<page>\n---\ntitle: Extend Cloudflare's benefits to SaaS providers' end-customers Â·\n  Cloudflare Reference Architecture docs\ndescription: Learn how to use Cloudflare to extend performance, security, and\n  data localization to your end users.\nlastUpdated: 2025-10-21T14:33:19.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/reference-architecture/design-guides/extending-cloudflares-benefits-to-saas-providers-end-customers/\n  md: https://developers.cloudflare.com/reference-architecture/design-guides/extending-cloudflares-benefits-to-saas-providers-end-customers/index.md\n---\n\nA key aspect of developing a Software-as-a-service (SaaS) application is ensuring its security against the wide array of potential attacks it faces on the Internet. Cloudflare's network and security services can be used to protect your customers using your SaaS application, off-loading the risk to a vendor with experience in [protecting applications](https://radar.cloudflare.com/reports/ddos).\n\nThis design guide illustrates how providers, building and hosting their own product/application offering, can leverage Cloudflare to extend the security, performance, and compliance benefits of Cloudflare's network to their end-customers.\n\nThe following diagrams visualize the use of the following services:\n\n* Data Localization Suite (specifically, [Regional Services](https://developers.cloudflare.com/data-localization/regional-services/))\n* [Cloudflare for SaaS](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/)\n* [Cloudflare Tunnels](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/) to securely expose web applications (with [public hostnames](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/routing-to-tunnel/) and [private networks](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/private-net/))\n* Load Balancers to manage traffic and ensure reliability and performance, implementing Global Traffic Management (GTM) and [Private Network Load Balancing](https://developers.cloudflare.com/load-balancing/private-network/).\n\nThis setup is ideal for SaaS providers who need to ensure minimal downtime, auto-renewal of SSL/TLS certificates, efficiently distribute traffic to healthy endpoints, and regional traffic management for compliance and performance optimization.\n\nThis document assumes that the provider's application DNS is registered and managed through Cloudflare as the primary and authoritative DNS provider. You can find details on how to set this up in the [Cloudflare DNS Zone Setup Guide](https://developers.cloudflare.com/dns/zone-setups/full-setup/).\n\nThis solution supports subdomains under your own zone while also allowing your customers to use their own domain names (vanity or custom domains) with your services. For example, for each customer you may create the custom hostname `mycustomer.myappexample.com` but also want to allow them to use their own domain, `app.mycustomerexample.com` to point to their tenant on your service. Each subdomain (`mycustomer.myappexample.com`) can be created on the main domain (`myappexample.com`) through the [Cloudflare API](https://developers.cloudflare.com/dns/manage-dns-records/how-to/create-dns-records/#create-dns-records), allowing you to easily automate the creation of DNS records when your customers create an account on your service.\n\nBefore looking at how Cloudflare can be configured to protect your SaaS application through your custom hostnames, it's worth reviewing the benefits of taking this approach.\n\n| Benefit | Description |\n| - | - |\n| Minimized Downtime | Ensure [minimal downtime](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/security/certificate-management/issue-and-validate/validate-certificates/#minimize-downtime) not only during custom hostname migrations to Cloudflare for SaaS but also throughout the entire lifecycle of the application. |\n| Security and Performance | Extends Cloudflare's [security](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/security/waf-for-saas/) and [performance](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/performance/) benefits to end-customers through their custom domains. |\n| Auto-Renewal | Automates the [renewal](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/security/certificate-management/issue-and-validate/renew-certificates/) and management process for custom hostname certificates. |\n| Apex Proxying | Supports end-customers using [domain apex](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/domain-support/hostname-validation/realtime-validation/#apex-proxying) (otherwise known as root domain) as custom hostnames. Used where your DNS service doesn't allow [CNAMEs for root domains](https://developers.cloudflare.com/dns/cname-flattening/), instead a [static IP](https://developers.cloudflare.com/byoip/address-maps/#static-ips-or-byoip) is used to allow an A record to be used. |\n| Smart Load Balancing | Use the load balancer as [custom origins](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/start/advanced-settings/custom-origin/) to steer traffic with [session affinity](https://developers.cloudflare.com/load-balancing/understand-basics/session-affinity/). In the context of Cloudflare for SaaS, a custom origin lets you send traffic from one or more custom hostnames to somewhere besides your default proxy fallback origin. |\n| Orange-to-Orange (O2O) | For end-customers who already proxy traffic through Cloudflare, [Orange-to-Orange (O2O)](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/saas-customers/how-it-works/) may be required. Generally, it's recommended for those end-customers to [not proxy](https://developers.cloudflare.com/dns/proxy-status/#dns-only-records) the hostnames used by the SaaS provider. If the Orange-to-Orange functionality is required, please review the [product compatibility](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/saas-customers/product-compatibility/). |\n| Regional Services | Allows [regional traffic management](https://developers.cloudflare.com/data-localization/regional-services/) to comply with data localization requirements. |\n\n## Products included in this guide\n\nThe following products are used to deliver this solution.\n\n| Product | Function |\n| - | - |\n| [Cloudflare for SaaS](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/) | Extends the security and performance benefits of Cloudflareâ€™s network to your customers through their own custom or vanity domains. This includes [Certificate Management](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/security/certificate-management/), [WAF for SaaS](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/security/waf-for-saas/), [Early Hints for SaaS](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/performance/early-hints-for-saas/) and [Cache for SaaS](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/performance/cache-for-saas/). |\n| [DDoS Protection](https://developers.cloudflare.com/ddos-protection/) | Volumetric attack protection is automatically enabled for [proxied](https://developers.cloudflare.com/dns/proxy-status/) hostnames. |\n| [Regional Services](https://developers.cloudflare.com/data-localization/regional-services/) (part of the Data Localization Suite) | Restrict inspection of data (processing) to only those data centers within jurisdictional boundaries. |\n| [Load Balancer](https://developers.cloudflare.com/load-balancing/) | Distributes traffic across your endpoints, which reduces endpoint strain and latency and improves the experience for end users. |\n| [Cloudflare Tunnel](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/) | Secure method to connect to customers' networks and servers without creating holes in [firewalls](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/configure-tunnels/tunnel-with-firewall/). cloudflared is the daemon (software) installed on origin servers to create a secure tunnel from applications back to Cloudflare. |\n\n## Cloudflare for SaaS examples\n\nThe primary objective of using Cloudflare is to ensure that all requests to your application's custom hostname are routed through Cloudflare's security and performance services first to apply security controls and routing or load balancing of traffic. Since the origin server often needs to be publicly accessible, securing the connection between Cloudflare and the origin server is crucial. For comprehensive guidance on securing origin servers, please refer to Cloudflare's documentation: [Protect your origin server](https://developers.cloudflare.com/fundamentals/security/protect-your-origin-server/).\n\nThe diagrams below begin by illustrating the simplest approach to achieving this goal, followed by more complex configurations.\n\n### Standard fallback origin setup\n\nThis standard Cloudflare for SaaS setup is the most commonly used and easiest to implement for most providers. Typically, these providers are SaaS companies, which develop and deliver software as a service solutions. This setup requires only a single DNS record to direct requests to Cloudflare, which then proxies the traffic to your application using an A record.\n\n![Figure 1: Standard fallback origin setup.](https://developers.cloudflare.com/_astro/standard-fallback-origin-setup.DrGJNOUB_Z1el3om.svg)\n\n1. The custom hostname (`custom.example.com`) is configured as a CNAME record pointing to the fallback origin of the provider. The fallback origin is the server or servers that Cloudflare will route traffic to by default when a request is made to the custom hostname. This DNS record does not need to be managed within Cloudflare; it just needs to point to the Cloudflare-hosted record from the provider (`fallback.myappexample.com`).\n2. The Fallback Origin is set up as an A record that points to the public IP address of the origin server. Cloudflare will route traffic sent to the custom hostnames to this origin server by default.\n\nThe origin server receives the details of the custom domain through either the [host header or SNI](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/reference/connection-details/). This enables the origin server to determine which application to direct the request to. This method is applicable for both custom hostnames (for example, `app.mycustomerexample.com`) and vanity domains (for example, `customer1.myappexample.com`). Since all requests for your application are now routed through the Cloudflare network, you can leverage a range of security and performance services for every request, including:\n\n* [Web Application Firewall](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/security/waf-for-saas/)\n* [Access control policies](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/security/secure-with-access/)\n* [Caching of application content](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/performance/cache-for-saas/)\n* [Support browser early hints](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/performance/early-hints-for-saas/)\n* [Image Transformations](https://developers.cloudflare.com/images/)\n* [Waiting Room](https://developers.cloudflare.com/waiting-room/)\n* [Workers for Platform](https://developers.cloudflare.com/cloudflare-for-platforms/workers-for-platforms/)\n\nFor implementation details to get started, review the [developer documentation](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/start/getting-started/).\n\n### Standard fallback origin setup with regional services\n\nThis approach introduces using Cloudflare's [Regional Services](https://developers.cloudflare.com/data-localization/regional-services/) solution to regionalize TLS termination and HTTP processing to confirm with any compliance regulations that dictate your service process data in specific geographic locations. This ensures that traffic destined for the origin server is handled exclusively within the chosen region.\n\n![Figure 2: Standard fallback origin setup with regional services.](https://developers.cloudflare.com/_astro/standard-fallback-origin-setup-regional-services.DgKfyYv8_29Ja7E.svg)\n\n1. The custom hostname (`custom.example.com`) is configured as a CNAME record that points to a regionalized SaaS hostname (`eu-customers.myappexample.com`). This configuration ensures that all processing, including TLS termination, occurs exclusively within the specified geographic region.\n2. The regionalized SaaS hostname is set up as a CNAME record that directs traffic to the standard [Fallback Origin](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/start/getting-started/#1-create-fallback-origin) of the SaaS provider (`fallback.myappexample.com`).\n3. The fallback origin is set up as an A record that points to the public IP address of the origin server. Cloudflare will route traffic sent to the custom hostnames to this origin server by default.\n\n### Cloudflare Tunnel as fallback origin setup with regional services\n\nFor enhanced security, rather than exposing your application servers directly to the Internet via public IPs, SaaS providers can use [Cloudflare Tunnels](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/). These tunnels connect your network to Cloudflare's nearest data centers, allowing SaaS applications to be accessed through [public hostnames](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/routing-to-tunnel/). As a result, Cloudflare becomes the sole entry point for end-customers from the public Internet into your application network.\n\n![Figure 3: Cloudflare Tunnel as Fallback Origin Setup with Regional Services.](https://developers.cloudflare.com/_astro/cloudflare-tunnel-fallback-origin-setup-regional-services.h18fhKDd_Z1RlVxB.svg)\n\n1. The custom hostname (`custom.example.com`) is configured as a CNAME record that points to a regionalized SaaS hostname (`eu-customers.myappexample.com`). This configuration ensures that all processing, including TLS termination, occurs exclusively within the specified geographic region.\n2. The regionalized SaaS hostname is set up as a CNAME record that directs traffic to the standard [Fallback Origin](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/start/getting-started/#1-create-fallback-origin) of the SaaS provider (`fallback.myappexample.com`).\n3. The fallback origin is a CNAME DNS record that points to a [public hostname](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/routing-to-tunnel/) exposed by Cloudflare Tunnel. This public hostname should be configured to route traffic to your application, for example, `localhost:8080`.\n\nThis setup is ideal for SaaS providers that do not need granular load balancing, such as [geo-based traffic steering](https://developers.cloudflare.com/load-balancing/understand-basics/traffic-steering/), across multiple origin servers. It's also well-suited for simple testing and development environments, where [protecting your origin server](https://developers.cloudflare.com/fundamentals/security/protect-your-origin-server/) by only allowing requests through the Cloudflare Tunnel is sufficient. However, for distributed applications requiring load balancing at both global and local levels, we recommend using [Cloudflare's Load Balancer](https://developers.cloudflare.com/load-balancing/) with global and private network load balancing capabilities.\n\n### Global Traffic Management (GTM) & Private Network Load Balancing as custom origin setup\n\nCloudflare offers a powerful set of load balancing capabilities. These allow you to reliably steer traffic to different origin servers where your SaaS applications are hosted, whether through public hostnames (as described above) or private IP addresses. This setup helps prevent origin overload by distributing traffic across multiple servers and enhances security by only permitting requests through the Cloudflare Tunnel.\n\n![Figure 4: Global Traffic Management (GTM) & Private Network Load Balancing as custom origin setup.](https://developers.cloudflare.com/_astro/gtm-ltm-custom-origin-setup.C_l8lMsz_2p0TxJ.svg)\n\n1. The custom hostname (`custom.example.com`) is configured as a CNAME record pointing to a Cloudflare [regionalized Load Balancer](https://developers.cloudflare.com/data-localization/how-to/load-balancing/) (`eu-lb.myappexample.com`). This ensures that all processing, including TLS termination, takes place within a specified geographic region. Additionally, the SaaS provider needs to set up the load balancer as the [custom origin](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/start/advanced-settings/custom-origin/) for the custom hostname.\n\n2. The regional load balancer is set up with [origin pools](https://developers.cloudflare.com/load-balancing/pools/) to distribute requests across multiple downstream servers. Each pool can be configured to use either [public hostnames](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/routing-to-tunnel/) with Global Traffic Management (GTM) or [private network](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/private-net/) addresses with Private Network Load Balancing. In the diagram above, we utilize both options:\n\n* Origin pool 1 uses the [Cloudflare Tunnel hostname](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/routing-to-tunnel/dns/) (`<UUID>.cfargotunnel.com`) as the endpoint or origin server for handling those requests. When using a public hostname, it is necessary to set the [HTTP host header value](https://developers.cloudflare.com/load-balancing/additional-options/override-http-host-headers/) to match the public hostname configured and exposed by the [Cloudflare Tunnel](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/). This ensures that the origin server can correctly route the incoming requests.\n   * Origin pool 2 uses the private IP address or private network (that is, `10.0.0.5`) within the SaaS provider's internal network, where the SaaS application resides. This pool must be configured to operate within the specified [virtual network](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/private-net/cloudflared/tunnel-virtual-networks/) to ensure proper routing of requests.\n\n3. Cloudflare Tunnel exposes both [public hostnames](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/routing-to-tunnel/) with GTM and [private networks](https://developers.cloudflare.com/cloudflare-one/networks/connectors/cloudflare-tunnel/private-net/) (private IPs) with Private Network Load Balancing.\n\nFor enhanced granularity in application serving and scalability, it is generally recommended to use private networks rather than public hostnames. Private networks enable Cloudflare to preserve and accurately pass the host header to the origin server. In contrast, when using public hostnames, providers must configure the [header value](https://developers.cloudflare.com/load-balancing/additional-options/override-http-host-headers/) on the load balancer, which is restricted to one public hostname per load balancer endpoint, potentially limiting flexibility.\n\nBe aware of the Zero Trust [Tunnel limitations](https://developers.cloudflare.com/cloudflare-one/account-limits/#cloudflare-tunnel), Cloudflare for SaaS [connection request details](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/reference/connection-details/), and the Custom Origin [SNI specification](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/start/advanced-settings/custom-origin/#sni-rewrites). For further information about the Cloudflare Load Balancer, review its [reference architecture](https://developers.cloudflare.com/reference-architecture/architectures/load-balancing/).\n\nAs a SaaS provider, it is advisable to automate most, if not all, of these processes using [APIs](https://developers.cloudflare.com/fundamentals/api/), [SDKs](https://developers.cloudflare.com/fundamentals/api/reference/sdks/), scripts, [Terraform](https://developers.cloudflare.com/terraform/), or other automation tools.\n\nAn example of a high-level migration plan can be [downloaded here](https://developers.cloudflare.com/reference-architecture/static/example-cloudflare-saas-migration-plan.pdf).\n\nIt is highly recommended to migrate to Cloudflare for SaaS in phases and address any issues as they arise, particularly with [Domain Control Validation (DCV)](https://developers.cloudflare.com/ssl/edge-certificates/changing-dcv-method/troubleshooting/). Be sure to review the [validation status](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/domain-support/hostname-validation/validation-status/) and relevant [documentation](https://developers.cloudflare.com/cloudflare-for-platforms/cloudflare-for-saas/domain-support/hostname-validation/) during the process.\n\nBy leveraging Cloudflare's infrastructure, SaaS providers can deliver secure, reliable, and performance services to their end-customers. This ensures a seamless and secure user experience while meeting compliance requirements, such as regionalization.\n\nSeveral Cloudflare customers are currently using the Cloudflare for SaaS solution (formerly known as SSL for SaaS). Notable public use cases include:\n\n* [Shopify](https://www.cloudflare.com/case-studies/shopify/)\n* [Porsche Informatik](https://www.cloudflare.com/case-studies/porsche-informatik/)\n* [Divio](https://www.cloudflare.com/case-studies/divio/)\n* [mogenius](https://www.cloudflare.com/case-studies/mogenius/)\n* [Quickbutik](https://www.cloudflare.com/case-studies/quickbutik/)\n\nAdditionally, when migrating to Cloudflare for SaaS, it is crucial to have a runbook and clear public documentation to communicate relevant details to your end-customers. Excellent public examples of this are the [Salesforce CDN](https://help.salesforce.com/s/articleView?id=sf.community_builder_cdn.htm\\&type=5) and [Shopify](https://help.shopify.com/en/manual/domains/add-a-domain/connecting-domains) documentation.\n\n<page>\n---\ntitle: Leveraging Cloudflare for your SaaS applications Â· Cloudflare Reference\n  Architecture docs\ndescription: This document provides a reference and guidance for using\n  Cloudflare for Platforms. It is designed for SaaS application owners,\n  engineers, or architects who want to learn how to make their application more\n  scalable and secure.\nlastUpdated: 2025-12-29T17:29:32.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/reference-architecture/design-guides/leveraging-cloudflare-for-your-saas-applications/\n  md: https://developers.cloudflare.com/reference-architecture/design-guides/leveraging-cloudflare-for-your-saas-applications/index.md\n---\n\nWhen building a SaaS application, it is common to create unique hostnames for each customer account (or tenant), for example `app.customer.com`. It is important to ensure that all communication to this application hostname is done using SSL/TLS and therefore a certificate must be created for your customer's hostname on your application. Certificate management is hard, and often application architects and developers would use a [multi-domain certificate](https://www.cloudflare.com/learning/ssl/types-of-ssl-certificates/) (MDC), so they can buy and add just one certificate that has hundreds of domains listed. However, this does not scale well when your application reaches thousands and millions of customers.\n\nAlso, a customer of your application might wish to have their main website domain hosted directly on your application. So that, for example, `www.customer.com` is actually delivering content directly from your SaaS application.\n\nMany SaaS applications have caching and security solutions, such as Cloudflare, in front of their applications and as such need to onboard these hostnames. This is often done using a \"Zone\" model, where inside Cloudflare, or another vendor such as AWS Cloudfront, a \"Zone\" is created for `app.customer.com`. This means that, as each new customer is onboarded, a new \"Zone\" must be created - this might be manageable in the tens and hundreds of customers but, when you get to thousands and millions, management of all these zones and their configurations is hard.\n\nCloudflare for Platforms extends far beyond this traditional model of most edge providers, by managing traffic across many hostnames and domains in one \"Zone\". You can now manage `www.customer1.com` and `www.customer2.net`, and millions more hostnames, through the same configuration while also customizing features as needed.\n\nThis document provides a reference and guidance for using Cloudflare for Platforms. The document is split into three main sections.\n\n* Overview of the SaaS model and the common challenges Cloudflare for Platforms solves\n* SSL certificate issuance in a SaaS model\n* Customizing the experience for each of your clients\n\n### Who is this document for and what will you learn?\n\nThis reference architecture is designed for SaaS application owners, engineers, or architects who want to learn how to make their application more scalable and secure through Cloudflare.\n\nTo build a stronger baseline understanding of Cloudflare, we recommend the following resources:\n\n* What is Cloudflare? | [Website](https://www.cloudflare.com/what-is-cloudflare/) (5 minute read) or [video](https://www.youtube.com/watch?v=XHvmX3FhTwU) (2 minutes)\n* [Cloudflare Ruleset Engine](https://developers.cloudflare.com/ruleset-engine/) - We will discuss integrations with the ruleset engine. Familiarity with that feature will be helpful.\n* [Cloudflare Workers](https://developers.cloudflare.com/workers/) - We will also discuss integrations with Cloudflare Workers, our serverless application platform. A basic familiarity with this platform will be helpful.\n\nThose who read this reference architecture will learn:\n\n* How Cloudflare's unique offering can solve key challenges for SaaS applications\n* How to customize the Cloudflare experience for each of your end customers\n* Tools to integrate serverless applications, for each of your clients, through Workers for Platforms\n\n## Why Cloudflare for Platforms?\n\nSoftware as a Service (SaaS) has been a key innovation of the cloud computing era. On premises managed legacy enterprise software - such as accounting, HR, and CRMs - required dedicated attention from IT personnel to establish a platform (whether dedicated hardware, VMs, or cloud instances) for each application in the enterprise. The SaaS model allows providers, like Shopify and Salesforce, to extend their own platform to their customers instead. Now, the customer does not have to provision hardware or consider any other infrastructure concerns; instead, they subscribe to access to the SaaS platform which is always up to date, secure and available.\n\n### Third party hostname challenges\n\nFor many SaaS applications, it is important to provide a service under the client's own domain. Their domain is important for branding, security, and organization; and many clients have heavily invested in the right `.com` to represent their business. Many clients with domains linked to their brand will push back against deploying their applications on the provider's domain.\n\nThis is especially true for customer-facing applications like an e-commerce solution. You would want to expose this as `shop.example.com`, not `example.shop.com`. To secure traffic to the SaaS application, the provider (\"shop\") needs a certificate for their customer, `example.com`.\n\n![Figure 1: eCommerce flow through a SaaS platform.](https://developers.cloudflare.com/_astro/figure1.T_DPd5f7_USkI4.svg)\n\nThis is a challenge for SaaS solutions, as certificate issuance is tightly controlled through the [DCV Validation process](https://developers.cloudflare.com/ssl/edge-certificates/changing-dcv-method/dcv-flow/). The owner of a domain needs to authorize any certificates, and traditional methods of validation are driven by the domain owner and deliver the certificate only to them.\n\n![Figure 2: Certificates cannot be automatically renewed on legacy platforms. They will expire and break traffic without manual action.](https://developers.cloudflare.com/_astro/figure2.BYh8B09n_Z2iz2dA.svg)\n\nThis poses a dilemma: the SaaS model offers clear advantages but introduces a new challenge of its own. A novel solution would let providers and end customers both get the most out of the SaaS model.\n\n## Issuing SSL certificates through Cloudflare for Platforms\n\n### Manage certificates for any hostname on the Internet\n\nCloudflare for SaaS provides a unique solution to these common challenges for SaaS providers. By leveraging Cloudflare's position as a low-latency, global network, we can transparently manage certificate issuance for end clients while also providing several other benefits to a SaaS platform.\n\n### Secure and powerful validation modes\n\nCloudflare has a unique ability to manage the Domain Control Validation (DCV) process in a SaaS scenario. In a traditional model, certificate issuers ask domain owners to place a [particular token](https://developers.cloudflare.com/ssl/edge-certificates/changing-dcv-method/dcv-flow/#dcv-tokens) (either a DNS TXT record or a small text file) at their origin in order to validate that they are authorized for that domain. This has to be done repeatedly at certificate renewal, which has become more common with recent security improvements.\n\n![Figure 3: The DCV process.](https://developers.cloudflare.com/_astro/figure3.DZ4GG0vx_Z1s3EeY.svg)\n\nSince Cloudflare's network can easily sit in between the client and the SaaS provider, we can automatically respond with the correct DCV token on behalf of any domain that points traffic to the SaaS provider on Cloudflare.\n\n![Figure 4: Certificates automatically renew on Cloudflare-enabled platforms.](https://developers.cloudflare.com/_astro/figure4.TeeqPEfC_vBp7j.svg)\n\nInstead of repeatedly performing a complex process at every certificate renewal, the client performs a much simpler process only once.",
  "code_samples": [
    {
      "code": "Install the required Python dependency and run the script:",
      "language": "unknown"
    },
    {
      "code": "## 5. Query the data with R2 SQL\n\nNow you can analyze your fraud detection data using R2 SQL. Here are some example queries:\n\n### 5.1. View recent transactions",
      "language": "unknown"
    },
    {
      "code": "### 5.2. Filter the raw transactions into a new table to highlight high-value transactions\n\nCreate a new sink that will write the filtered data to a new Apache Iceberg table in R2 Data Catalog:",
      "language": "unknown"
    },
    {
      "code": "Now you will create a new SQL query to process data from the original `raw_events_stream` stream and only write flagged transactions that are over the `amount` of 1,000.",
      "language": "unknown"
    },
    {
      "code": "Note\n\nIt may take a few minutes for the new Pipeline to fully Initialize and start processing the data. Also keep in mind the 30 second `roll-interval`.\n\nQuery the table and check the results:",
      "language": "unknown"
    },
    {
      "code": "Also verify that the non-fraudulent events are being filtered out:",
      "language": "unknown"
    },
    {
      "code": "You should see the following output:",
      "language": "unknown"
    },
    {
      "code": "## Conclusion\n\nYou have successfully built an end to end data pipeline using Cloudflare's data platform. Through this tutorial, you hve learned to:\n\n1. **Use R2 Data Catalog**: Leveraged Apache Iceberg tables for efficient data storage\n2. **Set up Cloudflare Pipelines**: Created streams, sinks, and pipelines for data ingestion\n3. **Generated sample data**: Created transaction data with some basic fraud patterns\n4. **Query your tables with R2 SQL**: Access raw and processed data tables stored in R2 Data Catalog\n\n</page>\n\n<page>\n---\ntitle: Get started - Workers and Wrangler Â· Cloudflare Realtime docs\ndescription: Deploy your first Realtime Agent using the CLI.\nlastUpdated: 2025-08-29T17:03:29.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/agents/getting-started/\n  md: https://developers.cloudflare.com/realtime/agents/getting-started/index.md\n---\n\nWarning\n\nThis guide is experimental, Realtime agents will be consolidated into the [Agents SDK](https://developers.cloudflare.com/agents/) in a future release\n\nThis guide will instruct you through setting up and deploying your first Realtime Agents project. You will use [Workers](https://developers.cloudflare.com/workers/), the Realtime Agents SDK, a Workers AI binding, and a large language model (LLM) to deploy your first AI-powered application on the Cloudflare global network.\n\n1. Sign up for a [Cloudflare account](https://dash.cloudflare.com/sign-up/workers-and-pages).\n2. Install [`Node.js`](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm).\n\nNode.js version manager\n\nUse a Node version manager like [Volta](https://volta.sh/) or [nvm](https://github.com/nvm-sh/nvm) to avoid permission issues and change Node.js versions. [Wrangler](https://developers.cloudflare.com/workers/wrangler/install-and-update/), discussed later in this guide, requires a Node version of `16.17.0` or later.\n\n## 1. Create a Worker project\n\nYou will create a new Worker project using the `create-cloudflare` CLI (C3). [C3](https://github.com/cloudflare/workers-sdk/tree/main/packages/create-cloudflare) is a command-line tool designed to help you set up and deploy new applications to Cloudflare.\n\nCreate a new project named `hello-agent` by running:\n\n* npm",
      "language": "unknown"
    },
    {
      "code": "* yarn",
      "language": "unknown"
    },
    {
      "code": "* pnpm",
      "language": "unknown"
    },
    {
      "code": "Running `npm create cloudflare@latest` will prompt you to install the [`create-cloudflare` package](https://www.npmjs.com/package/create-cloudflare), and lead you through setup. C3 will also install [Wrangler](https://developers.cloudflare.com/workers/wrangler/), the Cloudflare Developer Platform CLI.\n\nFor setup, select the following options:\n\n* For *What would you like to start with?*, choose `Hello World example`.\n* For *Which template would you like to use?*, choose `Worker only`.\n* For *Which language do you want to use?*, choose `TypeScript`.\n* For *Do you want to use git for version control?*, choose `Yes`.\n* For *Do you want to deploy your application?*, choose `No` (we will be making some changes before deploying).\n\nThis will create a new `hello-agent` directory. Your new `hello-agent` directory will include:\n\n* A `\"Hello World\"` [Worker](https://developers.cloudflare.com/workers/get-started/guide/#3-write-code) at `src/index.ts`.\n* A [`wrangler.jsonc`](https://developers.cloudflare.com/workers/wrangler/configuration/) configuration file.\n\nGo to your application directory:",
      "language": "unknown"
    },
    {
      "code": "## 2. Install the Realtime Agents SDK",
      "language": "unknown"
    },
    {
      "code": "## 3. Connect your Worker to Workers AI\n\nYou must create an AI binding for your Worker to connect to Workers AI. [Bindings](https://developers.cloudflare.com/workers/runtime-apis/bindings/) allow your Workers to interact with resources, like Workers AI, on the Cloudflare Developer Platform.\n\nTo bind Workers AI to your Worker, add the following to the end of your Wrangler file:\n\n* wrangler.jsonc",
      "language": "unknown"
    },
    {
      "code": "* wrangler.toml",
      "language": "unknown"
    },
    {
      "code": "Your binding is [available in your Worker code](https://developers.cloudflare.com/workers/reference/migrate-to-module-workers/#bindings-in-es-modules-format) on [`env.AI`](https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch/).\n\n## 4. Implement the Worker\n\nUpdate the `index.ts` file in your `hello-agent` application directory with the following code:\n\n* JavaScript",
      "language": "unknown"
    },
    {
      "code": "* TypeScript",
      "language": "unknown"
    },
    {
      "code": "The Realtime Agents SDK provides several elements that work together to create an end-to-end pipeline\n\n* `RealtimeKitTransport`: Represents a RealtimeKit meeting that will be joined by the agent\n\n* `DeepgramSTT`: Takes in meeting audio and provides transcripts powered by Deepgram\n\n* `TextComponent`: A concrete implementation for this element needs to be provided by the user as it is responsible for processing the text generated in the meeting and sending back responses. We have implemented it in the `MyTextProcessor` class\n\n* `ElevenLabsTTS`: Converts the generated responses to audio to be spoken in the meeting\n\nWe use all of these elements together to create a simple chatbot-like pipeline. As a pre-requisite, we require the meeting ID to be joined along with an authorization token for joining the meeting, which is passed during the worker invocation. Additionally, our class must extend `RealtimeAgent` as it contains certain internal logic to handle interactions with our pipeline backend\n\nIn `wrangler.jsonc`, append the following fields to enable the [Node.js Compatibility](https://developers.cloudflare.com/workers/runtime-apis/nodejs/) flag and create our Durable Object:",
      "language": "unknown"
    },
    {
      "code": "You must also setup a few [secrets](https://developers.cloudflare.com/workers/configuration/secrets/):\n\n* `ACCOUNT_ID`: Your Cloudflare account ID\n* `API_TOKEN`: Cloudflare API token scoped for `Admin` access to `Realtime`\n* `ELEVENLABS_API_KEY`, `DEEPGRAM_API_KEY`: ElevenLabs & Deepgram API keys\n\n## 5. Deploy your AI Worker\n\nBefore deploying your AI Worker globally, log in with your Cloudflare account by running:",
      "language": "unknown"
    },
    {
      "code": "You will be directed to a web page asking you to log in to the Cloudflare dashboard. After you have logged in, you will be asked if Wrangler can make changes to your Cloudflare account. Scroll down and select **Allow** to continue.\n\nFinally, deploy your Worker to make your project accessible on the Internet. To deploy your Worker, run:",
      "language": "unknown"
    },
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "## 6. Generate a RealtimeKit token\n\nFinally, to invoke the worker, we need to generate a RealtimeKit token from the [dashboard](https://dash.realtime.cloudflare.com/dashboard):\n\n1. Go to the `Meetings` tab and click on `Create Meeting`:\n\n![Meetings Tab](https://developers.cloudflare.com/_astro/create-meeting.Bb-QE-kr_22ugkR.webp)\n\n1. Click on `Join` next to the meeting and generate the RealtimeKit link. This contains the `meetingId` (`bbbb2fac-953c-4239-9ba8-75ba912d76fc`) and the `authToken` to be passed in the final step:\n\n`https://demo.realtime.cloudflare.com/v2/meeting?id=bbbb2fac-953c-4239-9ba8-75ba912d76fc&authToken=ey...`\n\n![Join Flow](https://developers.cloudflare.com/_astro/join-meeting.BktFJKMb_xBV9h.webp)\n\n1. Repeat the same `Join` flow to join the meeting yourself before adding in the Agent\n\nFinally, invoke the worker to make the agent join a meeting:",
      "language": "unknown"
    },
    {
      "code": "## Related resources\n\n* [Cloudflare Developers community on Discord](https://discord.cloudflare.com) - Submit feature requests, report bugs, and share your feedback directly with the Cloudflare team by joining the Cloudflare Discord server.\n\n</page>\n\n<page>\n---\ntitle: Message Broadcast APIs Â· Cloudflare Realtime docs\ndescription: The broadcast APIs allow a user to send custom messages to all\n  other users in a meeting.\nlastUpdated: 2025-12-26T08:34:28.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/realtimekit/broadcast-apis/\n  md: https://developers.cloudflare.com/realtime/realtimekit/broadcast-apis/index.md\n---\n\nThe broadcast APIs allow a user to send custom messages to all other users in a meeting.\n\n### Broadcasting a Message\n\nThe Participants module on the meeting object allows you to broadcast messages to all other users in a meeting (or to other meetings in case of connected meetings) over the signaling channel.\n\n### Subscribe to Messages\n\nUse the `broadcastedMessage` event to listen for messages sent via `broadcastMessage` and handle them in your application.\n\n### Rate Limiting & Constraints\n\n* The method is rateâ€‘limited (serverâ€‘side + clientâ€‘side) to prevent abuse.\n* Default clientâ€‘side config in the deprecated module: maxInvocations = 5 per period = 1s.\n* The Participants module exposes a `rateLimitConfig` and `updateRateLimits(maxInvocations, period)` for tuning on the client, but serverâ€‘side limits may still apply.\n* The event type cannot be `spotlight`. This is reserved for internal use by the SDK.\n\n### Examples\n\n#### Broadcast to everyone in the meeting\n\n#### Broadcast to a specific set of participants.\n\nOnly the participants with those participantIds receive the message.\n\n#### Broadcast to a preset\n\nAll participants whose preset name is `speaker` receive the message.\n\n#### Broadcast across multiple meetings\n\nAll participants in the specified meetings receive the message.\n\n</page>\n\n<page>\n---\ntitle: Storage and Broadcast Â· Cloudflare Realtime docs\ndescription: The RealtimeKit Stores API allows you to create multiple key-value\n  pair realtime stores. Users can subscribe to changes in a store and receive\n  real-time updates. Data is stored until a session is active.\nlastUpdated: 2025-12-30T17:46:42.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/realtimekit/collaborative-stores/\n  md: https://developers.cloudflare.com/realtime/realtimekit/collaborative-stores/index.md\n---\n\nThe RealtimeKit Stores API allows you to create multiple key-value pair realtime stores. Users can subscribe to changes in a store and receive real-time updates. Data is stored until a [session](https://developers.cloudflare.com/realtime/realtimekit/concepts/meeting/#session) is active.\n\n### Create a Store\n\nYou can create a realtime store (changes are synced with other users):\n\n| Param | Type | Description | Required |\n| - | - | - | - |\n| `name` | string | Name of the store | true |\n\nTo create a store:\n\nNote\n\nThis method must be executed for every user.\n\n### Update a Store\n\nYou can add, update or delete entires in a store:\n\n| Param | Type | Description | Required |\n| - | - | - | - |\n| `key` | string | Unique identifier used to store/update a value in the store | Yes |\n| `value` | StoreValue | Value that can be stored agains a key | Yes |\n\nNote\n\nThe `set` method overwrites the existing value, while the `update` method updates the existing value.\n\nFor example, if the stored value is `['a', 'b']` and you call `update` with `['c']`, the final value will be `['a', 'b', 'c']`.\n\n### Subscribe to a Store\n\nYou can attach event listeners on a store's key, which fire when the value changes.\n\n### Fetch Store Data\n\nYou can fetch the data stored in the store:\n\n</page>\n\n<page>\n---\ntitle: Concepts Â· Cloudflare Realtime docs\ndescription: This page outlines the core concepts and key terminology used\n  throughout RealtimeKit.\nlastUpdated: 2025-12-08T11:30:45.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/realtimekit/concepts/\n  md: https://developers.cloudflare.com/realtime/realtimekit/concepts/index.md\n---\n\nThis page outlines the core concepts and key terminology used throughout RealtimeKit.\n\n### App\n\nAn App represents a **workspace** within RealtimeKit. It groups together your meetings, participants, presets, recordings, and other configuration under an isolated namespace.\n\nTreat each App like an environment-specific containerâ€”most teams create one App for staging and another for production to avoid mixing data.\n\n### Meeting\n\nA Meeting is a **re-usable virtual room** that you can join anytime. Every time participants join a meeting, a new [session](https://developers.cloudflare.com/realtime/realtimekit/concepts#session) is created.\n\nA session is marked `ENDED` shortly after the last participant leaves. A meeting can have only **one active session** at any given time.\n\nFor more information about meetings, refer to [Meetings](https://developers.cloudflare.com/realtime/realtimekit/concepts#meeting).\n\n### Session\n\nA Session is the **live instance of a meeting**. It is created when the first participant joins a meeting and ends shortly after the last participant leaves.\n\nEach session is independent, with its own participants, chat, and recordings. It also inherits the configurations set while creating the meeting - `record on start`, `persist_chat`, and more.\n\nExample - A recurring â€œWeekly Standupâ€ **meeting will generate a new session** every time participants join.\n\n### Participant\n\nA **Participant** is created when you add a user to a meeting via the [REST API](https://developers.cloudflare.com/api/resources/realtime_kit/subresources/meetings/methods/create/). This API call returns a unique `authToken` that the client-side SDK uses to join the session and authenticate the user.\n\n> **Note:** Please do not re-use auth tokens for participants.\n\nFor more information about participants, refer to [Participants](https://developers.cloudflare.com/realtime/realtimekit/concepts/participant/).\n\n### Preset\n\nA Preset is a reusable set of permissions that defines the experience and the UIâ€™s look and feel for a participant.\n\nCreated at the App level, it can be applied to any participant across any meeting in that App.\n\nIt also defines the meeting type a user joinsâ€”video call, audio call, or webinar. Participants in the same meeting can use different presets to create flexible roles. Example: In a large ed-tech class:\n\n* **Teacher** will join with a `webinar-host` preset, allowing them to share their media and providing host controls.\n* **Students** will join with a `webinar-participant` preset, which restricts them from sharing media but allows them to use features like chat.\n* **Teaching assistant** will join with a `group-call-host` preset, enabling them to share their media but not have full control.\n\nIt also lets you customize the UIâ€™s look and feel, including colors and themes, so the experience matches your application's branding.\n\nFor more information about presets, refer to [Presets](https://developers.cloudflare.com/realtime/realtimekit/concepts/preset/).\n\n</page>\n\n<page>\n---\ntitle: Build using Core SDK Â· Cloudflare Realtime docs\ndescription: To integrate the Core SDK, you will need to initialize it with a\n  participant's auth token, and then use the provided SDK APIs to control the\n  peer in the session.\nlastUpdated: 2025-12-16T20:02:41.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/realtimekit/core/\n  md: https://developers.cloudflare.com/realtime/realtimekit/core/index.md\n---\n\n### Initialize Core SDK\n\nTo integrate the Core SDK, you will need to initialize it with a [participant's auth token](https://developers.cloudflare.com/api/resources/realtime_kit/#create-a-participant), and then use the provided SDK APIs to control the peer in the session.\n\nInitialization might differ slightly based on your tech stack. Please choose your preferred tech stack below.\n\n### Advanced Options\n\nThe Core SDK provides additional configuration options for advanced use cases. These options can be passed during initialization to customize the behavior of the RealtimeKit client.\n\n| Option | Description | Type | Reqired |\n| - | - | - | - |\n| **video** | Should video be enabled by default | `boolean` | false |\n| **audio** | Should audio be enabled by default | `boolean` | false |\n| **mediaConfiguration** | Allows you to pass custom media quality constraints | `MediaConfiguration` | false |\n| **autoSwitchAudioDevice** | Automatically switch to a ngAfterViewInit audio device | `boolean` | false |\n| **isNonPreferredDevice** | Allows you to set specific devices as \"not preferred\" | `(device: MediaDeviceInfo) => boolean` | false |\n| **recording** | Allows you to configure recording settings | RecordingConfig | false |\n\nReference for the types:",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: FAQ Â· Cloudflare Realtime docs\nlastUpdated: 2025-12-09T12:31:43.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/realtimekit/faq/\n  md: https://developers.cloudflare.com/realtime/realtimekit/faq/index.md\n---\n\nHow can I generate the Cloudflare API Token?\n\nTo use RealtimeKit APIs, you must have a [Cloudflare account](https://dash.cloudflare.com).\n\nFollow the [Create API token guide](https://developers.cloudflare.com/fundamentals/api/get-started/create-token/) to create a new token via the [Cloudflare dashboard](https://dash.cloudflare.com/profile/api-tokens). When configuring permissions, ensure that **Realtime** / **Realtime Admin** permissions are selected. Configure any additional [access policies and restrictions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) as needed for your use case.\n\n### Meetings\n\nCan I schedule meetings in advance with RealtimeKit?\n\nWhile RealtimeKit does not include a built-in scheduling system, you can implement the scheduling experience on top of it in your application. RealtimeKit meetings do not have start or end time, so your backend must store the schedule and enforce when users are allowed to join. A common approach is:\n\n* When a user schedules a meeting, your backend creates a meeting in RealtimeKit and stores the meeting `id` together with the start and end times.\n* When a user tries to join the meeting in your application, your backend checks whether the current time is within the allowed window.\n* If the checks pass, your backend [adds the participant](https://developers.cloudflare.com/api/resources/realtime_kit/subresources/meetings/methods/add_participant/) to the meeting, returns the participant auth token to the frontend and the frontend passes that token to the RealtimeKit SDK so the user can join.\n\nHow do I prevent participants from joining a meeting after a specific date or time?\n\nYou can disable the meeting at the required time by setting its status to `INACTIVE` using a `PATCH` request to the [Update Meeting](https://developers.cloudflare.com/api/resources/realtime_kit/subresources/meetings/methods/update_meeting_by_id/) endpoint.\n\nThis prevents participants from joining the meeting and prevents any new Sessions from starting.",
      "language": "unknown"
    },
    {
      "code": "### Participants\n\nHow do I generate an auth token for a participant?\n\nYour backend generates an authentication token by adding the user as a participant to a meeting with the [Add Participant](https://developers.cloudflare.com/api/resources/realtime_kit/subresources/meetings/methods/add_participant/) API endpoint. The API response includes a `token` field, which is the authentication token for that participant in that meeting.\n\nIf you need a new token for an existing participant after the previous token has expired, use the [Refresh Participant Token](https://developers.cloudflare.com/api/resources/realtime_kit/subresources/meetings/methods/refresh_participant_token/) endpoint.\n\nFor more details, see [Participant tokens](https://developers.cloudflare.com/realtime/realtimekit/concepts/participant/#participant-tokens).\n\nCan the same user join from multiple devices or browser tabs?\n\nYes. A single participant can be represented by multiple peers if the user joins the same meeting from different devices or tabs. Each connection becomes a separate peer, but they all map back to the same participant.\n\nHow can I prevent a user from joining a meeting again?\n\nDelete that user's participant for the meeting using the [Delete Participant](https://developers.cloudflare.com/api/resources/realtime_kit/subresources/meetings/methods/delete_meeting_participant/) API endpoint.\n\nOnce the participant is deleted and you stop issuing new tokens for them, they will no longer be able to join that meeting.\n\nCan the same participant join multiple sessions of a meeting?\n\nYes. As long as the participant exists for that meeting and has a valid authentication token, that participant can join multiple live sessions of the same meeting over time.\n\nDo I need to create a new participant for every session?\n\nIn most cases, no. You typically create a participant once for a given user and meeting, and then reuse that participant across sessions of that meeting. You may need to refresh the participantâ€™s authentication token over time, but you do not need to recreate the participant.\n\nWhat should I use for custom\\_participant\\_id?\n\nUse a stable internal identifier from your own system, such as a numeric user id or UUID. Do not use personal data such as email addresses, phone numbers, or other personally identifiable information.\n\n### Presets\n\nDo I need a new preset for every meeting or participant?\n\nPresets are **re-usable** set of rules and configurations that are defined at the App level. You can use the same preset for multiple participants.\n\nRead more about presets [here](https://developers.cloudflare.com/realtime/realtimekit/concepts/preset/).\n\n### Client Side SDKs\n\nHow do I decide which SDK to select?\n\nRealtimeKit support all the popular frameworks for web and mobile platforms.\n\nWe **recommend using our UI Kits** For most use cases.\n\nPlease Note: When you use our UI Kit, you also get the core SDK with it, which can be used to build additional features based on your needs.\n\nFor more information please refer to our [SDK Selection Guide](https://developers.cloudflare.com/realtime/realtimekit/sdk-selection/)\n\n</page>\n\n<page>\n---\ntitle: Legal Â· Cloudflare Realtime docs\nlastUpdated: 2025-12-30T18:29:53.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/realtimekit/legal/\n  md: https://developers.cloudflare.com/realtime/realtimekit/legal/index.md\n---\n\n* [Privacy Policy](https://www.cloudflare.com/application/privacypolicy/)\n* [Application Terms of Service](https://www.cloudflare.com/application/terms/)\n* [Third party licenses](https://developers.cloudflare.com/realtime/realtimekit/legal/3rdparty/)\n\n</page>\n\n<page>\n---\ntitle: Pricing Â· Cloudflare Realtime docs\ndescription: Cloudflare RealtimeKit is currently in Beta and is available at no\n  cost during this period.\nlastUpdated: 2025-12-30T04:31:37.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/realtimekit/pricing/\n  md: https://developers.cloudflare.com/realtime/realtimekit/pricing/index.md\n---\n\nCloudflare RealtimeKit is currently in Beta and is available at no cost during this period.\n\nWhen RealtimeKit reaches general availability (GA), usage will be charged according to the pricing model below:\n\n| Feature | Price |\n| - | - |\n| Audio/Video Participant | $0.002 / minute |\n| Audio-Only Participant | $0.0005 / minute |\n| Export (recording, RTMP or HLS streaming) | $0.010 / minute |\n| Export (recording, RTMP or HLS streaming, audio only) | $0.003 / minute |\n| Export (Raw RTP) into R2 | $0.0005 / minute |\n| Transcription (Real-time) | Standard model pricing via Workers AI |\n\nWhether a participant is an audio-only participant or an audio/video participant is determined by the `Meeting Type` of their [preset](https://developers.cloudflare.com/realtime/realtimekit/concepts/preset/).\n\n</page>\n\n<page>\n---\ntitle: Quickstart Â· Cloudflare Realtime docs\ndescription: To integrate RealtimeKit in your application, you must have a\n  Cloudflare account.\nlastUpdated: 2025-12-30T17:46:42.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/realtimekit/quickstart/\n  md: https://developers.cloudflare.com/realtime/realtimekit/quickstart/index.md\n---\n\n### Prerequisites\n\nTo integrate RealtimeKit in your application, you must have a [Cloudflare account](https://dash.cloudflare.com).\n\n1. Follow the [Create API token guide](https://developers.cloudflare.com/fundamentals/api/get-started/create-token/) to create a new token via the [Cloudflare dashboard](https://dash.cloudflare.com/profile/api-tokens).\n2. When configuring permissions, ensure that **Realtime** / **Realtime Admin** permissions are selected.\n3. Configure any additional [access policies and restrictions](https://developers.cloudflare.com/fundamentals/api/reference/permissions/) as needed for your use case.\n\n*Optional:* Alternatively, [create tokens programmatically via the API](https://developers.cloudflare.com/fundamentals/api/how-to/create-via-api/). Please ensure your access policy includes the **Realtime** permission.\n\n### Installation\n\nSelect a framework based on the platform you are building for.\n\n### Create a RealtimeKit App\n\nYou can create an application from the [Cloudflare Dashboard](https://dash.cloudflare.com/?to=/:account/realtime/kit), by clicking on Create App.\n\n*Optional:* You can also use our [API reference](https://developers.cloudflare.com/api/resources/realtime_kit/) for creating an application:",
      "language": "unknown"
    },
    {
      "code": "> **Note:** We recommend creating different apps for staging and production environments.\n\n### Create a Meeting\n\nUse our [Meetings API](https://developers.cloudflare.com/api/resources/realtime_kit/subresources/meetings/methods/create/) to create a meeting. We will use the **ID from the response** in subsequent steps.",
      "language": "unknown"
    },
    {
      "code": "### Add Participants\n\n#### Create a Preset\n\nPresets define what permissions a user should have. Learn more in the Concepts guide. You can create new presets using the [Presets API](https://developers.cloudflare.com/api/resources/realtime_kit/subresources/presets/methods/create/) or via the [RealtimeKit dashboard](https://dash.cloudflare.com/?to=/:account/realtime/kit).\n\n> **Note:** Skip this step if you created the app in the dashboardâ€”default presets are already set up for you.\n\n> **Note:** Presets can be reused across multiple meetings. Define a role (for example, admin or viewer) once and apply it to participants in any number of meetings.\n\n#### Add a Participant\n\nA participant is added to a meeting using the `Meeting ID` created above and selecting a `Preset Name` from the available options.\n\nThe response includes an `authToken` which the **Client SDK uses to add this participant to the meeting** room.",
      "language": "unknown"
    },
    {
      "code": "Learn more about adding participants in the [API reference](https://developers.cloudflare.com/api/resources/realtime_kit/subresources/meetings/methods/add_participant/).\n\n### Frontend Integration\n\nYou can now add the RealtimeKit Client SDK to your application.\n\n</page>\n\n<page>\n---\ntitle: Recording Â· Cloudflare Realtime docs\ndescription: Learn how RealtimeKit records the audio and video of multiple users\n  in a meeting, as well as interacts with RealtimeKit plugins, in a single file\n  using composite recording mode.\nlastUpdated: 2025-12-09T12:31:43.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/realtimekit/recording-guide/\n  md: https://developers.cloudflare.com/realtime/realtimekit/recording-guide/index.md\n---\n\nLearn how RealtimeKit records the audio and video of multiple users in a meeting, as well as interacts with RealtimeKit plugins, in a single file using composite recording mode.\n\nVisit the following pages to learn more about recording meetings:\n\n* [Configure Video Settings](https://developers.cloudflare.com/realtime/realtimekit/recording-guide/configure-codecs/)\n* [Set Audio Configurations](https://developers.cloudflare.com/realtime/realtimekit/recording-guide/configure-audio-codec/)\n* [Add Watermark](https://developers.cloudflare.com/realtime/realtimekit/recording-guide/add-watermark/)\n* [Disable Upload to RealtimeKit Bucket](https://developers.cloudflare.com/realtime/realtimekit/recording-guide/configure-realtimekit-bucket-config/)\n* [Create Custom Recording App Using Recording SDKs](https://developers.cloudflare.com/realtime/realtimekit/recording-guide/create-record-app-using-sdks/)\n* [Interactive Recordings with Timed Metadata](https://developers.cloudflare.com/realtime/realtimekit/recording-guide/interactive-recording/)\n* [Manage Recording Config Precedence Order](https://developers.cloudflare.com/realtime/realtimekit/recording-guide/manage-recording-config-hierarchy/)\n* [Upload Recording to Your Cloud](https://developers.cloudflare.com/realtime/realtimekit/recording-guide/custom-cloud-storage/)\n* [Start Recording](https://developers.cloudflare.com/realtime/realtimekit/recording-guide/start-recording/)\n* [Stop Recording](https://developers.cloudflare.com/realtime/realtimekit/recording-guide/stop-recording/)\n* [Monitor Recording Status](https://developers.cloudflare.com/realtime/realtimekit/recording-guide/monitor-status/)\n\nRealtimeKit records the audio and video of multiple users in a meeting, as well as interactions with RealtimeKit plugins, in a single file using composite recording mode.\n\n## How does RealtimeKit recording work?\n\nRealtimeKit recordings are powered by anonymous virtual bot users who join your meeting, record it, and then upload it to RealtimeKit's Cloudflare R2 bucket. For video files, we currently support the [H.264](https://en.wikipedia.org/wiki/Advanced_Video_Coding) and [VP8](https://en.wikipedia.org/wiki/VP8) codecs.\n\n1. When the recording is finished, it is stored in RealtimeKit's Cloudflare R2 bucket.\n\n2. RealtimeKit generates a downloadable link from which the recording can be downloaded. You can get the download URL using the [Fetch details of a recording API](https://developers.cloudflare.com/api/resources/realtime_kit/subresources/recordings/) or from the Developer Portal.\n\n   You can receive notifications of recording status in any of the following ways:\n\n   * Using the `recording.statusUpdate` webhook. RealtimeKit uses webhooks to notify your application when an event happens.\n   * Using the [Fetch active recording API](https://developers.cloudflare.com/api/resources/realtime_kit/subresources/recordings/methods/get_active_recordings/).\n   * You can also view the states of recording from the Developer Portal.\n\n3. Download the recording from the download url and store it to your cloud storage. The file is kept on RealtimeKit's server for seven days before being deleted.\n\n   You can get the download URL using the [Fetch active recording API](https://developers.cloudflare.com/api/resources/realtime_kit/subresources/recordings/methods/start_recordings/) or from the Developer Portal.\n\n   We support transferring recordings to AWS, Azure, and DigitalOcean storage buckets. You can also choose to preconfigure the storage configurations using the Developer Portal or the [Start recording a meeting API](https://developers.cloudflare.com/api/resources/realtime_kit/subresources/recordings/methods/start_recordings/).\n\n## Workflow\n\nA typical workflow for recording a meeting involves the following steps:\n\n1. Start a recording using the [Start Recording API](https://developers.cloudflare.com/api/resources/realtime_kit/subresources/recordings/methods/start_recordings/) or client side SDK.\n2. Stop the recording using the [Stop Recording API](https://developers.cloudflare.com/api/resources/realtime_kit/subresources/recordings/) or client side SDK.\n3. Fetch the download URL for downloading the recording using the [Fetch Recording Details API](https://developers.cloudflare.com/api/resources/realtime_kit/subresources/recordings/methods/get_one_recording/), webhook, or from the Developer Portal.\n\n</page>\n\n<page>\n---\ntitle: Release Notes Â· Cloudflare Realtime docs\ndescription: Subscribe to RSS\nlastUpdated: 2025-12-30T18:29:53.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/realtimekit/release-notes/\n  md: https://developers.cloudflare.com/realtime/realtimekit/release-notes/index.md\n---\n\n[Subscribe to RSS](https://developers.cloudflare.com/realtime/realtimekit/release-notes/index.xml)\n\n## 2025-11-18\n\n**RealtimeKit Web Core 1.2.1**\n\n**Fixes**\n\n* Resolved an issue preventing default media device selection.\n* Fixed SDK bundle to include `browser.js` instead of incorrectly shipping `index.iife.js` in 1.2.0.\n\n**Enhancements**\n\n* External media devices are now prioritized over internal devices when no preferred device is set.\n\n## 2025-10-30\n\n**RealtimeKit Web Core 1.2.0**\n\n**Features**\n\n* Added support for configuring simulcast via `initMeeting`:",
      "language": "unknown"
    },
    {
      "code": "**Fixes**\n\n* Resolved an issue where remote participants' video feeds were not visible during grid pagination in certain edge cases.\n* Fixed a bug preventing participants from switching microphones if the first listed microphone was non-functional.\n\n**Breaking changes**\n\n* Legacy media engine support has been removed. If your organization was created before March 1, 2025 and you are upgrading to this SDK version or later, you may experience recording issues. Contact support to migrate to the new Cloudflare SFU media engine to ensure continued recording functionality.\n\n## 2025-08-26\n\n**RealtimeKit Web Core 1.1.7**\n\n**Fixes**\n\n* Prevented speaker change events from being emitted when the active speaker does not change.\n* Addressed a behavioral change in microphone switching on recent versions of Google Chrome.\n* Added `deviceInfo` logs to improve debugging capabilities for React Native.\n* Fixed an issue that queued multiple media consumers for the same peer, optimizing resource usage.\n\n## 2025-08-14\n\n**RealtimeKit Web Core 1.1.6**\n\n**Enhancements**\n\n* Internal changes to make debugging of media consumption issues easier and faster.\n\n## 2025-08-04\n\n**RealtimeKit Web Core 1.1.5**\n\n**Fixes**\n\n* Improved React Native support for `AudioActivityReporter` with proper audio sampling.\n* Resolved issue preventing users from creating polls.\n* Fixed issue where leaving a meeting took more than 20 seconds.\n\n## 2025-07-17\n\n**RealtimeKit Web Core 1.1.4**\n\n**Fixes**\n\n* Livestream feature is now available to all beta users.\n* Fixed livestream stage functionality where hosts were not consuming peer videos upon participants' stage join.\n* Resolved issues with viewer joins and leaves in livestream stage.\n\n## 2025-07-08\n\n**RealtimeKit Web Core 1.1.3**\n\n**Fixes**\n\n* Fixed issue where users could not enable video mid-meeting if they joined without video initially.\n\n## 2025-07-02\n\n**RealtimeKit Web Core 1.1.2**\n\n**Fixes**\n\n* Fixed edge case in large meetings where existing participants could not hear or see newly joined users.\n\n## 2025-06-30\n\n**RealtimeKit Web Core 1.1.0â€“1.1.1**\n\n**Features**\n\n* Added methods to toggle self tile visibility.\n* Introduced broadcast functionality across connected meetings (breakout rooms).\n\n**New API**\n\n* Broadcast messages across meetings:",
      "language": "unknown"
    },
    {
      "code": "**Enhancements**\n\n* Reduced time to display videos of newly joined participants when joining in bulk.\n* Added support for multiple meetings on the same page in RealtimeKit Core SDK.\n\n## 2025-06-17\n\n**RealtimeKit Web Core 1.0.2**\n\n**Fixes**\n\n* Enhanced error handling for media operations.\n* Fixed issue where active participants with audio or video were not appearing in the active participant list.\n\n## 2025-05-29\n\n**RealtimeKit Web Core 1.0.1**\n\n**Fixes**\n\n* Resolved initial setup issues with Cloudflare RealtimeKit integration.\n* Fixed meeting join and media connectivity issues.\n* Enhanced media track handling.\n\n## 2025-05-29\n\n**RealtimeKit Web Core 1.0.0**\n\n**Features**\n\n* Initial release of Cloudflare RealtimeKit with support for group calls, webinars, livestreaming, polls, and chat.\n\n</page>\n\n<page>\n---\ntitle: REST API Reference Â· Cloudflare Realtime docs\nlastUpdated: 2025-12-30T18:29:53.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/realtimekit/rest-api-reference/\n  md: https://developers.cloudflare.com/realtime/realtimekit/rest-api-reference/index.md\n---\n\n\n</page>\n\n<page>\n---\ntitle: Select SDK(s) Â· Cloudflare Realtime docs\ndescription: \"RealtimeKit provides two ways to build real-time media applications:\"\nlastUpdated: 2025-12-30T17:46:42.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/realtimekit/sdk-selection/\n  md: https://developers.cloudflare.com/realtime/realtimekit/sdk-selection/index.md\n---\n\nNote\n\nIf you haven't already, we recommend trying out our [demo app](https://demo.realtime.cloudflare.com/meeting?demo=Default) to get a feel for what RealtimeKit can do.\n\n### Offerings\n\nRealtimeKit provides two ways to build real-time media applications:\n\n**UI Kit**: UI library of pre-built, customizable components for rapid development â€” sits on top of the Core SDK.\n\n**Core SDK**: Client SDK built on top of Realtime SFU that provides a full set of APIs for managing video calls, from joining and leaving sessions to muting, unmuting, and toggling audio and video.\n\nNote\n\nWhen you use our UI Kit, you also get access to the core SDK with it, which can be used to build additional features based on your needs.\n\n### Select you framework\n\nRealtimeKit support all the popular frameworks for web and mobile platforms. Please select the Platform and Framework that you are building on.\n\n| Framework/Library | Core SDK | UI Kit |\n| - | - | - |\n| Web-Components (HTML, Vue, Svelte) | [@cloudflare/realtimekit](https://www.npmjs.com/package/@cloudflare/realtimekit) | [@cloudflare/realtimekit-ui](https://www.npmjs.com/package/@cloudflare/realtimekit-ui) |\n| React | [@cloudflare/realtimekit-react](https://www.npmjs.com/package/@cloudflare/realtimekit-react) | [@cloudflare/realtimekit-react-ui](https://www.npmjs.com/package/@cloudflare/realtimekit-react-ui) |\n| Angular | [@cloudflare/realtimekit](https://www.npmjs.com/package/@cloudflare/realtimekit) | [@cloudflare/realtimekit-angular-ui](https://www.npmjs.com/package/@cloudflare/realtimekit-angular-ui) |\n| Android | [com.cloudflare.realtimekit:core](https://central.sonatype.com/artifact/com.cloudflare.realtimekit/core) | [com.cloudflare.realtimekit:ui-android](https://central.sonatype.com/artifact/com.cloudflare.realtimekit/ui-android) |\n| iOS | [RealtimeKit](https://github.com/dyte-in/RealtimeKitCoreiOS) | [RealtimeKitUI](https://github.com/dyte-in/RealtimeKitUI) |\n| Flutter | [realtimekit\\_core](https://pub.dev/packages/realtimekit_core) | [realtimekit\\_ui](https://pub.dev/packages/realtimekit_ui) |\n| React Native | [@cloudflare/realtimekit-react-native](https://www.npmjs.com/package/@cloudflare/realtimekit-react-native) | [@cloudflare/realtimekit-react-native-ui](https://www.npmjs.com/package/@cloudflare/realtimekit-react-native-ui) |\n\n### Technical comparison\n\nHere is a comprehensive guide to help you choose the right option for your project. This comparison will help you understand the trade-offs between using the Core SDK alone versus combining it with the UI Kit.\n\n| Feature | Core SDK only | UI Kit |\n| - | - | - |\n| **What you get** | Core APIs for managing media, host controls, chat, recording and more. | prebuilt UI components along with Core APIs. |\n| **Bundle size** | Minimal (media/network only) | Larger (includes Core SDK + UI components) |\n| **Time to ship** | Longer (build UI from scratch). Typically 5-6 days. | Faster (UI Kit handles Core SDK calls). Can build an ship under 2 hours. |\n| **Customization** | Complete control, manual implementation. Need to build you own UI | High level of customization with plug and play component library. |\n| **State management** | Needs to be manually handled. | Automatic, UI Kit takes care of state management. |\n| **UI flexibility** | Unlimited (build anything) | High (component library + add-ons) |\n| **Learning curve** | Steeper (learn Core SDK APIs directly) | Gentler (declarative components wrap Core SDK) |\n| **Maintenance** | More code to maintain. Larger project. | Less code, component updates included |\n| **Design system** | Headless, integrates with any design system. | Allows you to provide your theme. |\n| **Access to Core SDK** | Direct API access | Direct API access + UI components |\n\nNote\n\nIf you are building with our Core SDK only, you can reference our [open source repos](https://github.com/orgs/cloudflare/repositories?q=realtimekit) for implementation examples to speed up your development.\n\n</page>\n\n<page>\n---\ntitle: Build using UI Kit Â· Cloudflare Realtime docs\ndescription: The default RealtimeKit Meeting UI component gives you a complete\n  meeting experience out of the box, with all the essential features built in.\n  Just drop it into your app and you are ready to go.\nlastUpdated: 2025-12-30T17:46:42.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/realtimekit/ui-kit/\n  md: https://developers.cloudflare.com/realtime/realtimekit/ui-kit/index.md\n---\n\nThe default RealtimeKit Meeting UI component gives you a complete meeting experience out of the box, with all the essential features built in. Just drop it into your app and you are ready to go.\n\nSelect a framework based on the platform you are building for.\n\n## Next steps\n\nYou have successfully integrated RealtimeKit with the default meeting UI. Participants can now see and hear each other in sessions.\n\n#### Building Custom Meeting Experiences\n\nWhile the default UI provides a complete meeting experience, you may want to build a custom interface using individual UI Kit components. This approach gives you full control over the layout, design, and user experience.\n\nTo build your own custom meeting UI, follow these guides in order:\n\n1. **[UI Kit Components Library](https://developers.cloudflare.com/realtime/realtimekit/ui-kit/component-library/)** - Browse available components and their visual representations\n2. **[UI Kit Meeting Lifecycle](https://developers.cloudflare.com/realtime/realtimekit/ui-kit/state-management/)** - Lifecycle of a meeting and how components communicate and synchronize with each other\n3. **[Session Lifecycle](https://developers.cloudflare.com/realtime/realtimekit/concepts/session-lifecycle/)** - Understand different peer states and transitions\n4. **[Meeting Object Explained](https://developers.cloudflare.com/realtime/realtimekit/core/meeting-object-explained/)** - Access meeting data and participant information using the Core SDK\n5. **[Build Your Own UI](https://developers.cloudflare.com/realtime/realtimekit/ui-kit/build-your-own-ui/)** - Put everything together to create a custom meeting interface\n\n</page>\n\n<page>\n---\ntitle: Realtime vs Regular SFUs Â· Cloudflare Realtime docs\ndescription: Cloudflare Realtime represents a paradigm shift in building\n  real-time applications by leveraging a distributed real-time data plane. It\n  creates a seamless experience in real-time communication, transcending\n  traditional geographical limitations and scalability concerns. Realtime is\n  designed for developers looking to integrate WebRTC functionalities in a\n  server-client architecture without delving deep into the complexities of\n  regional scaling or server management.\nlastUpdated: 2025-08-12T17:36:47.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/sfu/calls-vs-sfus/\n  md: https://developers.cloudflare.com/realtime/sfu/calls-vs-sfus/index.md\n---\n\n## Cloudflare Realtime vs. Traditional SFUs\n\nCloudflare Realtime represents a paradigm shift in building real-time applications by leveraging a distributed real-time data plane. It creates a seamless experience in real-time communication, transcending traditional geographical limitations and scalability concerns. Realtime is designed for developers looking to integrate WebRTC functionalities in a server-client architecture without delving deep into the complexities of regional scaling or server management.\n\n### The Limitations of Centralized SFUs\n\nSelective Forwarding Units (SFUs) play a critical role in managing WebRTC connections by selectively forwarding media streams to participants in a video call. However, their centralized nature introduces inherent limitations:\n\n* **Regional Dependency:** A centralized SFU requires a specific region for deployment, leading to latency issues for global users except for those in proximity to the selected region.\n\n* **Scalability Concerns:** Scaling a centralized SFU to meet global demand can be challenging and inefficient, often requiring additional infrastructure and complexity.\n\n### How is Cloudflare Realtime different?\n\nCloudflare Realtime addresses these limitations by leveraging Cloudflare's global network infrastructure:\n\n* **Global Distribution Without Regions:** Unlike traditional SFUs, Cloudflare Realtime operates on a global scale without regional constraints. It utilizes Cloudflare's extensive network of over 250 locations worldwide to ensure low-latency video forwarding, making it fast and efficient for users globally.\n\n* **Decentralized Architecture:** There are no dedicated servers for Realtime. Every server within Cloudflare's network contributes to handling Realtime, ensuring scalability and reliability. This approach mirrors the distributed nature of Cloudflare's products such as 1.1.1.1 DNS or Cloudflare's CDN.\n\n## How Cloudflare Realtime Works\n\n### Establishing Peer Connections\n\nTo initiate a real-time communication session, an end user's client establishes a WebRTC PeerConnection to the nearest Cloudflare location. This connection benefits from anycast routing, optimizing for the lowest possible latency.\n\n### Signaling and Media Stream Management\n\n* **HTTPS API for Signaling:** Cloudflare Realtime simplifies signaling with a straightforward HTTPS API. This API manages the initiation and coordination of media streams, enabling clients to push new MediaStreamTracks or request these tracks from the server.\n\n* **Efficient Media Handling:** Unlike traditional approaches that require multiple connections for different media streams from different clients, Cloudflare Realtime maintains a single PeerConnection per client. This streamlined process reduces complexity and improves performance by handling both the push and pull of media through a singular connection.\n\n### Application-Level Management\n\nCloudflare Realtime delegates the responsibility of state management and participant tracking to the application layer. Developers are empowered to design their logic for handling events such as participant joins or media stream updates, offering flexibility to create tailored experiences in applications.\n\n## Getting Started with Cloudflare Realtime\n\nIntegrating Cloudflare Realtime into your application promises a straightforward and efficient process, removing the hurdles of regional scalability and server management so you can focus on creating engaging real-time experiences for users worldwide.\n\n</page>\n\n<page>\n---\ntitle: Changelog Â· Cloudflare Realtime docs\ndescription: Subscribe to RSS\nlastUpdated: 2025-08-12T17:36:47.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/sfu/changelog/\n  md: https://developers.cloudflare.com/realtime/sfu/changelog/index.md\n---\n\n[Subscribe to RSS](https://developers.cloudflare.com/realtime/sfu/changelog/index.xml)\n\n## 2025-11-21\n\n**WebSocket adapter video (JPEG) support**\n\nUpdated Media Transport Adapters (WebSocket adapter) to support video egress as JPEG frames in addition to audio.\n\n* Stream audio and video between WebRTC tracks and WebSocket endpoints\n* Video egress-only as JPEG at approximately 1 FPS for snapshots, thumbnails, and computer vision pipelines\n* Clarified media formats for PCM audio and JPEG video over Protocol Buffers\n* Updated docs: [Adapters](https://developers.cloudflare.com/realtime/sfu/media-transport-adapters/), [WebSocket adapter](https://developers.cloudflare.com/realtime/sfu/media-transport-adapters/websocket-adapter/)\n\n## 2025-08-29\n\n**Media Transport Adapters (WebSocket) open beta**\n\nOpen beta for Media Transport Adapters (WebSocket adapter) to bridge audio between WebRTC and WebSocket.\n\n* Ingest (WebSocket â†’ WebRTC) and Stream (WebRTC â†’ WebSocket)\n* Opus for WebRTC tracks; PCM over WebSocket via Protocol Buffers\n\nDocs: [Adapters](https://developers.cloudflare.com/realtime/sfu/media-transport-adapters/), [WebSocket adapter](https://developers.cloudflare.com/realtime/sfu/media-transport-adapters/websocket-adapter/)\n\n## 2024-09-25\n\n**TURN service is generally available (GA)**\n\nCloudflare Realtime TURN service is generally available and helps address common challenges with real-time communication. For more information, refer to the [blog post](https://blog.cloudflare.com/webrtc-turn-using-anycast/) or [TURN documentation](https://developers.cloudflare.com/realtime/turn/).\n\n## 2024-04-04\n\n**Orange Meets availability**\n\nOrange Meets, Cloudflare's internal video conferencing app, is open source and available for use from [Github](https://github.com/cloudflare/orange?cf_target_id=40DF7321015C5928F9359DD01303E8C2).\n\n## 2024-04-04\n\n**Cloudflare Realtime open beta**\n\nCloudflare Realtime is in open beta and available from the Cloudflare Dashboard.\n\n## 2022-09-27\n\n**Cloudflare Realtime closed beta**\n\nCloudflare Realtime is available as a closed beta for users who request an invitation. Refer to the [blog post](https://blog.cloudflare.com/announcing-cloudflare-calls/) for more information.\n\n</page>\n\n<page>\n---\ntitle: Demos Â· Cloudflare Realtime docs\ndescription: Learn how you can use Realtime within your existing architecture.\nlastUpdated: 2025-08-12T17:36:47.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/sfu/demos/\n  md: https://developers.cloudflare.com/realtime/sfu/demos/index.md\n---\n\nLearn how you can use Realtime within your existing architecture.\n\n## Demos\n\nExplore the following demo applications for Realtime.\n\n* [Realtime Echo Demo:](https://github.com/cloudflare/calls-examples/tree/main/echo) Demonstrates a local stream alongside a remote echo stream.\n* [Orange Meets:](https://github.com/cloudflare/orange) Orange Meets is a demo WebRTC application built using Cloudflare Realtime.\n* [WHIP-WHEP Server:](https://github.com/cloudflare/calls-examples/tree/main/whip-whep-server) WHIP and WHEP server implemented on top of Realtime API.\n* [Realtime DataChannel Test:](https://github.com/cloudflare/calls-examples/tree/main/echo-datachannels) This example establishes two datachannels, one publishes data and the other one subscribes, the test measures how fast a message travels to and from the server.\n\n</page>\n\n<page>\n---\ntitle: DataChannels Â· Cloudflare Realtime docs\ndescription: DataChannels are a way to send arbitrary data, not just audio or\n  video data, between client in low latency. DataChannels are useful for\n  scenarios like chat, game state, or any other data that doesn't need to be\n  encoded as audio or video but still needs to be sent between clients in real\n  time.\nlastUpdated: 2025-08-12T17:36:47.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/sfu/datachannels/\n  md: https://developers.cloudflare.com/realtime/sfu/datachannels/index.md\n---\n\nDataChannels are a way to send arbitrary data, not just audio or video data, between client in low latency. DataChannels are useful for scenarios like chat, game state, or any other data that doesn't need to be encoded as audio or video but still needs to be sent between clients in real time.\n\nWhile it is possible to send audio and video over DataChannels, it's not optimal because audio and video transfer includes media specific optimizations that DataChannels do not have, such as simulcast, forward error correction, better caching across the Cloudflare network for retransmissions.",
      "language": "unknown"
    },
    {
      "code": "DataChannels on Cloudflare Realtime can scale up to many subscribers per publisher, there is no limit to the number of subscribers per publisher.\n\n### How to use DataChannels\n\n1. Create two Realtime sessions, one for the publisher and one for the subscribers.\n2. Create a DataChannel by calling /datachannels/new with the location set to \"local\" and the dataChannelName set to the name of the DataChannel.\n3. Create a DataChannel by calling /datachannels/new with the location set to \"remote\" and the sessionId set to the sessionId of the publisher.\n4. Use the DataChannel to send data from the publisher to the subscribers.\n\n### Unidirectional DataChannels\n\nCloudflare Realtime SFU DataChannels are one way only. This means that you can only send data from the publisher to the subscribers. Subscribers cannot send data back to the publisher. While regular MediaStream WebRTC DataChannels are bidirectional, this introduces a problem for Cloudflare Realtime because the SFU does not know which session to send the data back to. This is especially problematic for scenarios where you have multiple subscribers and you want to send data from the publisher to all subscribers at scale, such as distributing game score updates to all players in a multiplayer game.\n\nTo send data in a bidirectional way, you can use two DataChannels, one for sending data from the publisher to the subscribers and one for sending data the opposite direction.\n\n## Example\n\nAn example of DataChannels in action can be found in the [Realtime Examples github repo](https://github.com/cloudflare/calls-examples/tree/main/echo-datachannels).\n\n</page>\n\n<page>\n---\ntitle: Example architecture Â· Cloudflare Realtime docs\nlastUpdated: 2025-08-12T17:36:47.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/sfu/example-architecture/\n  md: https://developers.cloudflare.com/realtime/sfu/example-architecture/index.md\n---\n\n![Example Architecture](https://developers.cloudflare.com/_astro/video-calling-application.CIYa-lzM_e7Gu.webp)\n\n1. Clients connect to the backend service\n2. Backend service manages the relationship between the clients and the tracks they should subscribe to\n3. Backend service contacts the Cloudflare Realtime API to pass the SDP from the clients to establish the WebRTC connection.\n4. Realtime API relays back the Realtime API SDP reply and renegotiation messages.\n5. If desired, headless clients can be used to record the content from other clients or publish content.\n6. Admin manages the rooms and room members.\n\n</page>\n\n<page>\n---\ntitle: Quickstart guide Â· Cloudflare Realtime docs\ndescription: >-\n  Every Realtime App is a separate environment, so you can make one for\n  development, staging and production versions for your product.\n\n  Either using Dashboard, or the API create a Realtime App. When you create a\n  Realtime App, you will get:\nlastUpdated: 2025-08-12T17:36:47.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/sfu/get-started/\n  md: https://developers.cloudflare.com/realtime/sfu/get-started/index.md\n---\n\nBefore you get started:\n\nYou must first [create a Cloudflare account](https://developers.cloudflare.com/fundamentals/account/create-account/).\n\n## Create your first app\n\nEvery Realtime App is a separate environment, so you can make one for development, staging and production versions for your product. Either using [Dashboard](https://dash.cloudflare.com/?to=/:account/calls), or the [API](https://developers.cloudflare.com/api/resources/calls/subresources/sfu/methods/create/) create a Realtime App. When you create a Realtime App, you will get:\n\n* App ID\n* App Secret\n\nThese two combined will allow you to make API Realtime from your backend server to Realtime.\n\n</page>\n\n<page>\n---\ntitle: Connection API Â· Cloudflare Realtime docs\ndescription: Cloudflare Realtime simplifies the management of peer connections\n  and media tracks through HTTPS API endpoints. These endpoints allow developers\n  to efficiently manage sessions, add or remove tracks, and gather session\n  information.\nlastUpdated: 2025-08-12T17:36:47.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/sfu/https-api/\n  md: https://developers.cloudflare.com/realtime/sfu/https-api/index.md\n---\n\nCloudflare Realtime simplifies the management of peer connections and media tracks through HTTPS API endpoints. These endpoints allow developers to efficiently manage sessions, add or remove tracks, and gather session information.\n\n## API Endpoints\n\n* **Create a New Session**: Initiates a new session on Cloudflare Realtime, which can be modified with other endpoints below.\n  * `POST /apps/{appId}/sessions/new`\n* **Add a New Track**: Adds a media track (audio or video) to an existing session.\n  * `POST /apps/{appId}/sessions/{sessionId}/tracks/new`\n* **Renegotiate a Session**: Updates the session's negotiation state to accommodate new tracks or changes in the existing ones.\n  * `PUT /apps/{appId}/sessions/{sessionId}/renegotiate`\n* **Close a Track**: Removes a specified track from the session.\n  * `PUT /apps/{appId}/sessions/{sessionId}/tracks/close`\n* **Retrieve Session Information**: Fetches detailed information about a specific session.\n  * `GET /apps/{appId}/sessions/{sessionId}`\n\n[View full API and schema (OpenAPI format)](https://developers.cloudflare.com/realtime/static/calls-api-2024-05-21.yaml)\n\n## Handling Secrets\n\nIt is vital to manage App ID and its secret securely. While track and session IDs can be public, they should be protected to prevent misuse. An attacker could exploit these IDs to disrupt service if your backend server does not authenticate request origins properly, for example by sending requests to close tracks on sessions other than their own. Ensuring the security and authenticity of requests to your backend server is crucial for maintaining the integrity of your application.\n\n## Using STUN and TURN Servers\n\nCloudflare Realtime is designed to operate efficiently without the need for TURN servers in most scenarios, as Cloudflare exposes a publicly routable IP address for Realtime. However, integrating a STUN server can be necessary for facilitating peer discovery and connectivity.\n\n* **Cloudflare STUN Server**: `stun.cloudflare.com:3478`\n\nUtilizing Cloudflare's STUN server can help the connection process for Realtime applications.\n\n## Lifecycle of a Simple Session\n\nThis section provides an overview of the typical lifecycle of a simple session, focusing on audio-only applications. It illustrates how clients are notified by the backend server as new remote clients join or leave, incorporating video would introduce additional tracks and considerations into the session.",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Introduction Â· Cloudflare Realtime docs\ndescription: Cloudflare Realtime can be used to add realtime audio, video and\n  data into your applications. Cloudflare Realtime uses WebRTC, which is the\n  lowest latency way to communicate across a broad range of platforms like\n  browsers, mobile, and native apps.\nlastUpdated: 2025-08-12T17:36:47.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/sfu/introduction/\n  md: https://developers.cloudflare.com/realtime/sfu/introduction/index.md\n---\n\nCloudflare Realtime can be used to add realtime audio, video and data into your applications. Cloudflare Realtime uses WebRTC, which is the lowest latency way to communicate across a broad range of platforms like browsers, mobile, and native apps.\n\nRealtime integrates with your backend and frontend application to add realtime functionality.\n\n## Why Cloudflare Realtime exists\n\n* **It is difficult to scale WebRTC**: Many struggle scaling WebRTC servers. Operators run into issues about how many users can be in the same \"room\" or want to build unique solutions that do not fit into the current concepts in high level APIs.\n\n* **High egress costs**: WebRTC is expensive to use as managed solutions charge a high premium on cloud egress and running your own servers incur system administration and scaling overhead. Cloudflare already has 300+ locations with upwards of 1,000 servers in some locations. Cloudflare Realtime scales easily on top of this architecture and can offer the lowest WebRTC usage costs.\n\n* **WebRTC is growing**: Developers are realizing that WebRTC is not just for video conferencing. WebRTC is supported on many platforms, it is mature and well understood.\n\n## What makes Cloudflare Realtime unique\n\n* **Unopinionated**: Cloudflare Realtime does not offer a SDK. It instead allows you to access raw WebRTC to solve unique problems that might not fit into existing concepts. The API is deliberately simple.\n\n* **No rooms**: Unlike other WebRTC products, Cloudflare Realtime lets you be in charge of each track (audio/video/data) instead of offering abstractions such as rooms. You define the presence protocol on top of simple pub/sub. Each end user can publish and subscribe to audio/video/data tracks as they wish.\n\n* **No lock-in**: You can use Cloudflare Realtime to solve scalability issues with your SFU. You can use in combination with peer-to-peer architecture. You can use Cloudflare Realtime standalone. To what extent you use Cloudflare Realtime is up to you.\n\n## What exactly does Cloudflare Realtime do?\n\n* **SFU**: Realtime is a special kind of pub/sub server that is good at forwarding media data to clients that subscribe to certain data. Each client connects to Cloudflare Realtime via WebRTC and either sends data, receives data or both using WebRTC. This can be audio/video tracks or DataChannels.\n\n* **It scales**: All Cloudflare servers act as a single server so millions of WebRTC clients can connect to Cloudflare Realtime. Each can send data, receive data or both with other clients.\n\n## How most developers get started\n\n1. Get started with the echo example, which you can download from the Cloudflare dashboard when you create a Realtime App or from [demos](https://developers.cloudflare.com/realtime/sfu/demos/). This will show you how to send and receive audio and video.\n\n2. Understand how you can manipulate who can receive what media by passing around session and track ids. Remember, you control who receives what media. Each media track is represented by a unique ID. It is your responsibility to save and distribute this ID.\n\nRealtime is not a presence protocol\n\nRealtime does not know what a room is. It only knows media tracks. It is up to you to make a room by saving who is in a room along with track IDs that unique identify media tracks. If each participant publishes their audio/video, and receives audio/video from each other, you have got yourself a video conference!\n\n1. Create an app where you manage each connection to Cloudflare Realtime and the track IDs created by each connection. You can use any tool to save and share tracks. Check out the example apps at [demos](https://developers.cloudflare.com/realtime/sfu/demos/), such as [Orange Meets](https://github.com/cloudflare/orange), which is a full-fledged video conferencing app that uses [Workers Durable Objects](https://developers.cloudflare.com/durable-objects/) to keep track of track IDs.\n\n</page>\n\n<page>\n---\ntitle: Limits, timeouts and quotas Â· Cloudflare Realtime docs\ndescription: Understanding the limits and timeouts of Cloudflare Realtime is\n  crucial for optimizing the performance and reliability of your applications.\n  This section outlines the key constraints and behaviors you should be aware of\n  when integrating Cloudflare Realtime into your app.\nlastUpdated: 2025-11-26T14:07:27.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/sfu/limits/\n  md: https://developers.cloudflare.com/realtime/sfu/limits/index.md\n---\n\nUnderstanding the limits and timeouts of Cloudflare Realtime is crucial for optimizing the performance and reliability of your applications. This section outlines the key constraints and behaviors you should be aware of when integrating Cloudflare Realtime into your app.\n\n## Free\n\n* Each account gets 1,000GB/month of data transfer from Cloudflare to your client for free.\n* Data transfer from your client to Cloudflare is always free of charge.\n\n## Limits\n\n* **API Realtime per Session**: You can make up to 50 API calls per second for each session. There is no ratelimit on a App basis, just sessions.\n\n* **Tracks per API Call**: Up to 64 tracks can be added with a single API call. If you need to add more tracks to a session, you should distribute them across multiple API calls.\n\n* **Tracks per Session**: There's no upper limit to the number of tracks a session can contain, the practical limit is governed by your connection's bandwidth to and from Cloudflare.\n\n## Inactivity Timeout\n\n* **Track Timeout**: Tracks will automatically timeout and be garbage collected after 30 seconds of inactivity, where inactivity is defined as no media packets being received by Cloudflare. This mechanism ensures efficient use of resources and session cleanliness across all Sessions that use a track.\n\n## PeerConnection Requirements\n\n* **Session State**: For any operation on a session (e.g., pulling or pushing tracks), the PeerConnection state must be `connected`. Operations will block for up to 5 seconds awaiting this state before timing out. This ensures that only active and viable sessions are engaged in media transmission.\n\n## Handling Connectivity Issues\n\n* **Internet Connectivity Considerations**: The potential for internet connectivity loss between the client and Cloudflare is an operational reality that must be addressed. Implementing a detection and reconnection strategy is recommended to maintain session continuity. This could involve periodic 'heartbeat' signals to your backend server to monitor connectivity status. Upon detecting connectivity issues, automatically attempting to reconnect and establish a new session is advised. Sessions and tracks will remain available for reuse for 30 seconds before timing out, providing a brief window for reconnection attempts.\n\nAdhering to these limits and understanding the timeout behaviors will help ensure that your applications remain responsive and stable while providing a seamless user experience.\n\n## Supported Codecs\n\nCloudflare Realtime supports the following codecs:\n\n### Supported video codecs\n\n* **H264**\n* **H265**\n* **VP8**\n* **VP9**\n* **AV1**\n\n### Supported audio codecs\n\n* **Opus**\n* **G.711 PCM (A-law)**\n* **G.711 PCM (Âµ-law)**\n\nNote\n\nFor external 48kHz PCM support refer to the [WebSocket adapter](https://developers.cloudflare.com/realtime/sfu/media-transport-adapters/websocket-adapter/)\n\n</page>\n\n<page>\n---\ntitle: Media Transport Adapters Â· Cloudflare Realtime docs\ndescription: Media Transport Adapters bridge WebRTC and other transport\n  protocols. Adapters handle protocol conversion, codec transcoding, and\n  bidirectional media flow between WebRTC sessions and external endpoints.\nlastUpdated: 2025-12-08T19:53:07.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/sfu/media-transport-adapters/\n  md: https://developers.cloudflare.com/realtime/sfu/media-transport-adapters/index.md\n---\n\nMedia Transport Adapters bridge WebRTC and other transport protocols. Adapters handle protocol conversion, codec transcoding, and bidirectional media flow between WebRTC sessions and external endpoints.\n\n## What adapters do\n\nAdapters extend Realtime beyond WebRTC-to-WebRTC communication:\n\n* Ingest audio/video from external sources into WebRTC sessions\n* Stream WebRTC media to external systems for processing or storage\n* Integrate with AI services for transcription, translation, or generation\n* Bridge WebRTC applications with legacy communication systems\n\n## Available adapters\n\n### WebSocket adapter (beta)\n\nStream audio and video between WebRTC tracks and WebSocket endpoints. Video is egress-only and is converted to JPEG. Currently in beta; the API may change.\n\n[Learn more](https://developers.cloudflare.com/realtime/sfu/media-transport-adapters/websocket-adapter/)\n\n## Architecture\n\nMedia Transport Adapters operate as intermediaries between Cloudflare Realtime SFU sessions and external endpoints:",
      "language": "unknown"
    },
    {
      "code": "### Key concepts\n\n**Adapter instance**: Each connection creates a unique instance with an `adapterId` to manage its lifecycle.\n\n**Location types**:\n\n* `local` (Ingest): Receives media from external endpoints to create new WebRTC tracks\n* `remote` (Stream): Sends media from existing WebRTC tracks to external endpoints\n\n**Codec support**: Adapters convert between WebRTC and external system formats.\n\n## Common use cases\n\n### AI processing\n\n* Speech-to-text transcription\n* Text-to-speech generation\n* Real-time translation\n* Audio enhancement\n\n### Media recording\n\n* Cloud recording\n* Content delivery networks\n* Media processing pipelines\n\n### Legacy integration\n\n* Traditional telephony\n* Broadcasting infrastructure\n* Custom media servers\n\n## API overview\n\nMedia Transport Adapters are managed through the Realtime SFU API:",
      "language": "unknown"
    },
    {
      "code": "Each adapter type has specific configuration requirements and capabilities. Refer to individual adapter documentation for detailed API specifications.\n\n## Best practices\n\n* Close adapter instances when no longer needed\n* Implement reconnection logic for network failures\n* Choose codecs based on bandwidth and quality requirements\n* Secure endpoints with authentication for sensitive media\n\n## Limitations\n\n* Each adapter type has specific codec and format support\n* Network latency between Cloudflare edge and external endpoints affects real-time performance\n* Maximum message size and streaming modes vary by adapter type\n\n## Get started\n\n[WebSocket adapter (beta)](https://developers.cloudflare.com/realtime/sfu/media-transport-adapters/websocket-adapter/) - Stream audio and video between WebRTC and WebSocket endpoints (video egress to JPEG)\n\n</page>\n\n<page>\n---\ntitle: Pricing Â· Cloudflare Realtime docs\ndescription: Cloudflare Realtime billing is based on data sent from Cloudflare\n  edge to your application.\nlastUpdated: 2025-08-12T17:36:47.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/sfu/pricing/\n  md: https://developers.cloudflare.com/realtime/sfu/pricing/index.md\n---\n\nCloudflare Realtime billing is based on data sent from Cloudflare edge to your application.\n\nCloudflare Realtime SFU and TURN services cost $0.05 per GB of data egress.\n\nThere is a free tier of 1,000 GB before any charges start. This free tier includes usage from both SFU and TURN services, not two independent free tiers. Cloudflare Realtime billing appears as a single line item on your Cloudflare bill, covering both SFU and TURN.\n\nTraffic between Cloudflare Realtime TURN and Cloudflare Realtime SFU or Cloudflare Stream (WHIP/WHEP) does not get double charged, so if you are using both SFU and TURN at the same time, you will get charged for only one.\n\n### TURN\n\nPlease see the [TURN FAQ page](https://developers.cloudflare.com/realtime/turn/faq), where there is additional information on specifically which traffic path from RFC8656 is measured and counts towards billing.\n\n### SFU\n\nOnly traffic originating from Cloudflare towards clients incurs charges. Traffic pushed to Cloudflare incurs no charge even if there is no client pulling same traffic from Cloudflare.\n\n</page>\n\n<page>\n---\ntitle: Sessions and Tracks Â· Cloudflare Realtime docs\ndescription: \"Cloudflare Realtime offers a simple yet powerful framework for\n  building real-time experiences. At the core of this system are three key\n  concepts: Applications,  Sessions and Tracks. Familiarizing yourself with\n  these concepts is crucial for using Realtime.\"\nlastUpdated: 2025-08-12T17:36:47.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/sfu/sessions-tracks/\n  md: https://developers.cloudflare.com/realtime/sfu/sessions-tracks/index.md\n---\n\nCloudflare Realtime offers a simple yet powerful framework for building real-time experiences. At the core of this system are three key concepts: **Applications**, **Sessions** and **Tracks**. Familiarizing yourself with these concepts is crucial for using Realtime.\n\n## Application\n\nA Realtime Application is an environment within different Sessions and Tracks can interact. Examples of this could be production, staging or different environments where you'd want separation between Sessions and Tracks. Cloudflare Realtime usage can be queried at Application, Session or Track level.\n\n## Sessions\n\nA **Session** in Cloudflare Realtime correlates directly to a WebRTC PeerConnection. It represents the establishment of a communication channel between a client and the nearest Cloudflare data center, as determined by Cloudflare's anycast routing. Typically, a client will maintain a single Session, encompassing all communications between the client and Cloudflare.\n\n* **One-to-One Mapping with PeerConnection**: Each Session is a direct representation of a WebRTC PeerConnection, facilitating real-time media data transfer.\n* **Anycast Routing**: The client connects to the closest Cloudflare data center, optimizing latency and performance.\n* **Unified Communication Channel**: A single Session can handle all types of communication between a client and Cloudflare, ensuring streamlined data flow.\n\n## Tracks\n\nWithin a Session, there can be one or more **Tracks**.\n\n* **Tracks map to MediaStreamTrack**: Tracks align with the MediaStreamTrack concept, facilitating audio, video, or data transmission.\n* **Globally Unique Ids**: When you push a track to Cloudflare, it is assigned a unique ID, which can then be used to pull the track into another session elsewhere.\n* **Available globally**: The ability to push and pull tracks is central to what makes Realtime a versatile tool for real-time applications. Each track is available globally to be retrieved from any Session within an App.\n\n## Realtime as a Programmable \"Switchboard\"\n\nThe analogy of a switchboard is apt for understanding Realtime. Historically, switchboard operators connected calls by manually plugging in jacks. Similarly, Realtime allows for the dynamic routing of media streams, acting as a programmable switchboard for modern real-time communication.\n\n## Beyond \"Rooms\", \"Users\", and \"Participants\"\n\nWhile many SFUs utilize concepts like \"rooms\" to manage media streams among users, this approach has scalability and flexibility limitations. Cloudflare Realtime opts for a more granular and flexible model with Sessions and Tracks, enabling a wide range of use cases:\n\n* Large-scale remote events, like 'fireside chats' with thousands of participants.\n* Interactive conversations with the ability to bring audience members \"on stage.\"\n* Educational applications where an instructor can present to multiple virtual classrooms simultaneously.\n\n### Presence Protocol vs. Media Flow\n\nRealtime distinguishes between the presence protocol and media flow, allowing for scalability and flexibility in real-time applications. This separation enables developers to craft tailored experiences, from intimate calls to massive, low-latency broadcasts.\n\n</page>\n\n<page>\n---\ntitle: Analytics Â· Cloudflare Realtime docs\ndescription: Cloudflare Realtime TURN service counts ingress and egress usage in\n  bytes. You can access this real-time and historical data using the TURN\n  analytics API. You can see TURN usage data in a time series or aggregate that\n  shows traffic in bytes over time.\nlastUpdated: 2025-12-05T17:40:43.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/turn/analytics/\n  md: https://developers.cloudflare.com/realtime/turn/analytics/index.md\n---\n\nCloudflare Realtime TURN service counts ingress and egress usage in bytes. You can access this real-time and historical data using the TURN analytics API. You can see TURN usage data in a time series or aggregate that shows traffic in bytes over time.\n\nCloudflare TURN analytics is available over the GraphQL API only.\n\nAPI token permissions\n\nYou will need the \"Account Analytics\" permission on your API token to make queries to the Realtime GraphQL API.\n\nNote\n\nSee [GraphQL API](https://developers.cloudflare.com/analytics/graphql-api/) for more information on how to set up your GraphQL client. The examples below use the same GraphQL endpoint at `https://api.cloudflare.com/client/v4/graphql`.\n\n## Available metrics and dimensions\n\nTURN analytics provides rich data that you can query and aggregate in various ways.\n\n### Metrics\n\nYou can query the following metrics:\n\n* **egressBytes**: Total bytes sent from TURN servers to clients\n* **ingressBytes**: Total bytes received by TURN servers from clients\n* **concurrentConnections**: Average number of concurrent connections\n\nThese metrics support aggregations using `sum` and `avg` functions.\n\n### Dimensions\n\nYou can break down your data by the following dimensions:\n\n* **Time aggregations**: `datetime`, `datetimeMinute`, `datetimeFiveMinutes`, `datetimeFifteenMinutes`, `datetimeHour`\n* **Geographic**: `datacenterCity`, `datacenterCountry`, `datacenterRegion` (Cloudflare data center location)\n* **Identity**: `keyId`, `customIdentifier`, `username`\n\n### Filters\n\nYou can filter the data in TURN analytics on:\n\n* Datetime range\n* TURN Key ID\n* TURN Username\n* Custom identifier\n\nNote\n\n[Custom identifiers](https://developers.cloudflare.com/realtime/turn/replacing-existing/#tag-users-with-custom-identifiers) are useful for accounting usage for different users in your system.\n\n## GraphQL clients\n\nGraphQL is a self-documenting protocol. You can use any GraphQL client to explore the schema and available fields. Popular options include:\n\n* **[Altair](https://altairgraphql.dev/)**: A feature-rich GraphQL client with schema documentation explorer\n* **[GraphiQL](https://github.com/graphql/graphiql)**: The original GraphQL IDE\n* **[Postman](https://www.postman.com/)**: Supports GraphQL queries with schema introspection\n\nTo explore the full schema, configure your client to connect to `https://api.cloudflare.com/client/v4/graphql` with your API credentials. Refer to [Explore the GraphQL schema](https://developers.cloudflare.com/analytics/graphql-api/getting-started/explore-graphql-schema/) for detailed instructions.\n\n## Useful TURN analytics queries\n\nBelow are some example queries for common usecases. You can modify them to adapt your use case and get different views to the analytics data.\n\n### Concurrent connections with data usage over time\n\nThis comprehensive query shows how to retrieve multiple metrics simultaneously, including concurrent connections, egress, and ingress bytes in 5-minute intervals. This is useful for building dashboards and monitoring real-time usage.",
      "language": "unknown"
    },
    {
      "code": "Example response:",
      "language": "unknown"
    },
    {
      "code": "### Top TURN keys by egress",
      "language": "unknown"
    },
    {
      "code": "Example response:",
      "language": "unknown"
    },
    {
      "code": "### Top TURN custom identifiers",
      "language": "unknown"
    },
    {
      "code": "Example response:",
      "language": "unknown"
    },
    {
      "code": "### Usage for a specific custom identifier",
      "language": "unknown"
    },
    {
      "code": "Example response:",
      "language": "unknown"
    },
    {
      "code": "### Usage as a timeseries (for graphs)",
      "language": "unknown"
    },
    {
      "code": "Example response:",
      "language": "unknown"
    },
    {
      "code": "### Usage breakdown by geographic location\n\nYou can break down usage data by Cloudflare data center location to understand where your TURN traffic is being served. This is useful for optimizing regional capacity and understanding geographic distribution of your users.",
      "language": "unknown"
    },
    {
      "code": "Example response:",
      "language": "unknown"
    },
    {
      "code": "### Filter by specific key or identifier\n\nYou can filter data to analyze a specific TURN key or custom identifier. This is useful for debugging specific connections or analyzing usage patterns for particular clients.",
      "language": "unknown"
    },
    {
      "code": "Example response:",
      "language": "unknown"
    },
    {
      "code": "### Time aggregation options\n\nYou can choose different time aggregation intervals depending on your analysis needs:\n\n* **`datetimeMinute`**: 1-minute intervals (most granular)\n* **`datetimeFiveMinutes`**: 5-minute intervals (recommended for dashboards)\n* **`datetimeFifteenMinutes`**: 15-minute intervals\n* **`datetimeHour`**: Hourly intervals (best for long-term trends)\n\nExample query with hourly aggregation:",
      "language": "unknown"
    },
    {
      "code": "Example response:",
      "language": "unknown"
    },
    {
      "code": "## Advanced use cases\n\n### Combining multiple dimensions\n\nYou can combine multiple dimensions in a single query to get more detailed breakdowns. For example, to see usage by both time and location:",
      "language": "unknown"
    },
    {
      "code": "Example response:",
      "language": "unknown"
    },
    {
      "code": "### Identifying top consumers\n\nTo find which keys or custom identifiers are using the most bandwidth:",
      "language": "unknown"
    },
    {
      "code": "Example response:",
      "language": "unknown"
    },
    {
      "code": "## Schema exploration\n\nThe GraphQL Analytics API is self-documenting. You can use introspection to discover all available fields, filters, and capabilities for `callsTurnUsageAdaptiveGroups`. Using a GraphQL client like Altair or GraphiQL, you can browse the schema interactively to find additional dimensions and metrics that may be useful for your specific use case.\n\nFor more information on GraphQL introspection and schema exploration, refer to:\n\n* [Explore the GraphQL schema](https://developers.cloudflare.com/analytics/graphql-api/getting-started/explore-graphql-schema/)\n* [GraphQL introspection](https://developers.cloudflare.com/analytics/graphql-api/features/discovery/introspection/)\n\n</page>\n\n<page>\n---\ntitle: Simulcast Â· Cloudflare Realtime docs\ndescription: Simulcast is a feature of WebRTC that allows a publisher to send\n  multiple video streams of the same media at different qualities. For example,\n  this is useful for scenarios where you want to send a high quality stream for\n  desktop users and a lower quality stream for mobile users.\nlastUpdated: 2025-10-01T17:28:53.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/sfu/simulcast/\n  md: https://developers.cloudflare.com/realtime/sfu/simulcast/index.md\n---\n\nSimulcast is a feature of WebRTC that allows a publisher to send multiple video streams of the same media at different qualities. For example, this is useful for scenarios where you want to send a high quality stream for desktop users and a lower quality stream for mobile users.",
      "language": "unknown"
    },
    {
      "code": "### How it works\n\nSimulcast in WebRTC allows a single video source, like a camera or screen share, to be encoded at multiple quality levels and sent simultaneously, which is beneficial for subscribers with varying network conditions and device capabilities. The video source is encoded into multiple streams, each identified by RIDs (RTP Stream Identifiers) for different quality levels, such as low, medium, and high. These simulcast streams are described in the SDP you send to Cloudflare Realtime SFU. It's the responsibility of the Cloudflare Realtime SFU to ensure that the appropriate quality stream is delivered to each subscriber based on their network conditions and device capabilities.\n\nCloudflare Realtime SFU will automatically handle the simulcast configuration based on the SDP you send to it from the publisher. The SFU will then automatically switch between the different quality levels based on the subscriber's network conditions, or the quality level can be controlled manually via the API. You can control the quality switching behavior using the `simulcast` configuration object when you send an API call to start pulling a remote track.\n\n### Quality Control\n\nThe `simulcast` configuration object in the API call when you start pulling a remote track allows you to specify:\n\n* `preferredRid`: The preferred quality level for the video stream (RID for the simulcast stream. [RIDs can be specified by the publisher.](https://developer.mozilla.org/en-US/docs/Web/API/RTCRtpSender/setParameters#encodings))\n\n* `priorityOrdering`: Controls how the SFU handles bandwidth constraints.\n\n  * `none`: Keep sending the preferred layer, set via the preferredRid, even if there's not enough bandwidth.\n  * `asciibetical`: Use alphabetical ordering (a-z) to determine priority, where 'a' is most desirable and 'z' is least desirable.\n\n* `ridNotAvailable`: Controls what happens when the preferred RID is no longer available, for example when the publisher stops sending it.\n\n  * `none`: Do nothing.\n  * `asciibetical`: Switch to the next available RID based on the priority ordering, where 'a' is most desirable and 'z' is least desirable.\n\n  You will likely want to order the asciibetical RIDs based on your desired metric, such as higest resoltion to lowest or highest bandwidth to lowest.\n\n### Bandwidth Management across media tracks\n\nCloudflare Realtime treats all media tracks equally at the transport level. For example, if you have multiple video tracks (cameras, screen shares, etc.), they all have equal priority for bandwidth allocation. This means:\n\n1. Each track's simulcast configuration is handled independently\n2. The SFU performs automatic bandwidth estimation and layer switching based on network conditions independently for each track\n\n### Layer Switching Behavior\n\nWhen a layer switch is requested (through updating `preferredRid`) with the `/tracks/update` API:\n\n1. The SFU will automatically generate a Full Intraframe Request (FIR)\n2. PLI generation is debounced to prevent excessive requests\n\n### Publisher Configuration\n\nFor publishers (local tracks), you only need to include the simulcast attributes in your SDP. The SFU will automatically handle the simulcast configuration based on the SDP. For example, the SDP should contain a section like this:",
      "language": "unknown"
    },
    {
      "code": "If the publisher endpoint is a browser you can include these by specifying `sendEncodings` when creating the transceiver like this:",
      "language": "unknown"
    },
    {
      "code": "## Example\n\nHere's an example of how to use simulcast with Cloudflare Realtime:\n\n1. Create a new local track with simulcast configuration. There should be a section in the SDP with `a=simulcast:send`.\n2. Use the [Cloudflare Realtime API](https://developers.cloudflare.com/realtime/sfu/https-api) to push this local track, by calling the /tracks/new endpoint.\n3. Use the [Cloudflare Realtime API](https://developers.cloudflare.com/realtime/sfu/https-api) to start pulling a remote track (from another browser or device), by calling the /tracks/new endpoint and specifying the `simulcast` configuration object along with the remote track ID you get from step 2.\n\nFor more examples, check out the [Realtime Examples GitHub repository](https://github.com/cloudflare/calls-examples/tree/main/echo-simulcast).\n\n</page>\n\n<page>\n---\ntitle: Custom TURN domains Â· Cloudflare Realtime docs\ndescription: Cloudflare Realtime TURN service supports using custom domains for\n  UDP, and TCP - but not TLS protocols. Custom domains do not affect any of the\n  performance of Cloudflare Realtime TURN and is set up via a simple CNAME DNS\n  record on your domain.\nlastUpdated: 2025-04-08T20:01:03.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/turn/custom-domains/\n  md: https://developers.cloudflare.com/realtime/turn/custom-domains/index.md\n---\n\nCloudflare Realtime TURN service supports using custom domains for UDP, and TCP - but not TLS protocols. Custom domains do not affect any of the performance of Cloudflare Realtime TURN and is set up via a simple CNAME DNS record on your domain.\n\n| Protocol | Custom domains | Primary port | Alternate port |\n| - | - | - | - |\n| STUN over UDP | âœ… | 3478/udp | 53/udp |\n| TURN over UDP | âœ… | 3478/udp | 53 udp |\n| TURN over TCP | âœ… | 3478/tcp | 80/tcp |\n| TURN over TLS | No | 5349/tcp | 443/tcp |\n\n## Setting up a CNAME record\n\nTo use custom domains for TURN, you must create a CNAME DNS record pointing to `turn.cloudflare.com`.\n\nWarning\n\nDo not resolve the address of `turn.cloudflare.com` or `stun.cloudflare.com` or use an IP address as the value you input to your DNS record. Only CNAME records are supported.\n\nAny DNS provider, including Cloudflare DNS can be used to set up a CNAME for custom domains.\n\nNote\n\nIf Cloudflare's authoritative DNS service is used, the record must be set to [DNS-only or \"grey cloud\" mode](https://developers.cloudflare.com/dns/proxy-status/#dns-only-records).\\`\n\nThere is no additional charge to using a custom hostname with Cloudflare Realtime TURN.\n\n</page>\n\n<page>\n---\ntitle: FAQ Â· Cloudflare Realtime docs\ndescription: Cloudflare TURN pricing is based on the data sent from the\n  Cloudflare edge to the TURN client, as described in RFC 8656 Figure 1. This\n  means data sent from the TURN server to the TURN client and captures all data,\n  including TURN overhead, following successful authentication.\nlastUpdated: 2025-10-26T16:28:30.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/turn/faq/\n  md: https://developers.cloudflare.com/realtime/turn/faq/index.md\n---\n\n## General\n\n### What is Cloudflare Realtime TURN pricing? How exactly is it calculated?\n\nCloudflare TURN pricing is based on the data sent from the Cloudflare edge to the TURN client, as described in [RFC 8656 Figure 1](https://datatracker.ietf.org/doc/html/rfc8656#fig-turn-model). This means data sent from the TURN server to the TURN client and captures all data, including TURN overhead, following successful authentication.\n\nPricing for Cloudflare Realtime TURN service is $0.05 per GB of data used.\n\nCloudflare's STUN service at `stun.cloudflare.com` is free and unlimited.\n\nThere is a free tier of 1,000 GB before any charges start. Cloudflare Realtime billing appears as a single line item on your Cloudflare bill, covering both SFU and TURN.\n\nTraffic between Cloudflare Realtime TURN and Cloudflare Realtime SFU or Cloudflare Stream (WHIP/WHEP) does not incur any charges.",
      "language": "unknown"
    },
    {
      "code": "### Is Realtime TURN HIPAA/GDPR/FedRAMP compliant?\n\nPlease view Cloudflare's [certifications and compliance resources](https://www.cloudflare.com/trust-hub/compliance-resources/) and contact your Cloudflare enterprise account manager for more information.\n\n### What data can Cloudflare access when TURN is used with WebRTC?\n\nWhen Cloudflare Realtime TURN is used in conjunction with WebRTC, Cloudflare cannot access the contents of the media being relayed. This is because WebRTC employs Datagram Transport Layer Security (DTLS) encryption for all media streams, which encrypts the data end-to-end between the communicating peers before it reaches the TURN server. As a result, Cloudflare only relays encrypted packets and cannot decrypt or inspect the media content, which may include audio, video, or data channel information.\n\nFrom a data privacy perspective, the only information Cloudflare processes to operate the TURN service is the metadata necessary for establishing and maintaining the relay connection. This includes IP addresses of the TURN clients, port numbers, and session timing information. Cloudflare does not have access to any personally identifiable information contained within the encrypted media streams themselves.\n\nThis architecture ensures that media communications relayed through Cloudflare Realtime TURN maintain end-to-end encryption between participants, with Cloudflare functioning solely as an intermediary relay service without visibility into the encrypted content.\n\n### Is Realtime TURN end-to-end encrypted?\n\nTURN protocol, [RFC 8656](https://datatracker.ietf.org/doc/html/rfc8656), does not discuss encryption beyond wrapper protocols such as TURN over TLS. If you are using TURN with WebRTC will encrypt data at the WebRTC level.\n\n### What regions does Cloudflare Realtime TURN operate at?\n\nCloudflare Realtime TURN server runs on [Cloudflare's global network](https://www.cloudflare.com/network) - a growing global network of thousands of machines distributed across hundreds of locations, with the notable exception of the Cloudflare's [China Network](https://developers.cloudflare.com/china-network/).\n\n### Does Cloudflare Realtime TURN use the Cloudflare Backbone or is there any \"magic\" Cloudflare do to speed connection up?\n\nCloudflare Realtime TURN allocations are homed in the nearest available Cloudflare data center to the TURN client via anycast routing. If both ends of a connection are using Cloudflare Realtime TURN, Cloudflare will be able to control the routing and, if possible, route TURN packets through the Cloudflare backbone.\n\n### What is the difference between Cloudflare Realtime TURN with a enterprise plan vs self-serve (pay with your credit card) plans?\n\nThere is no performance or feature level difference for Cloudflare Realtime TURN service in enterprise or self-serve plans, however those on [enterprise plans](https://www.cloudflare.com/enterprise/) will get the benefit of priority support, predictable flat-rate pricing and SLA guarantees.\n\n### Does Cloudflare Realtime TURN run in the Cloudflare China Network?\n\nCloudflare's [China Network](https://developers.cloudflare.com/china-network/) does not participate in serving Realtime traffic and TURN traffic from China will connect to Cloudflare locations outside of China.\n\n### How long does it take for TURN activity to be available in analytics?\n\nTURN usage shows up in analytics in 30 seconds.\n\n## Technical\n\n### I need to allowlist (whitelist) Cloudflare Realtime TURN IP addresses. Which IP addresses should I use?\n\nCloudflare Realtime TURN is easy to use by IT administrators who have strict firewalls because it requires very few IP addresses to be allowlisted compared to other providers. You must allowlist both IPv6 and IPv4 addresses.\n\nPlease allowlist the following IP addresses:\n\n* `2a06:98c1:3200::1/128`\n* `2606:4700:48::1/128`\n* `141.101.90.1/32`\n* `162.159.207.1/32`\n\nWatch for IP changes\n\nCloudflare tries to, but cannot guarantee that the IP addresses used for the TURN service won't change. If you are allowlisting IP addresses and do not have a enterprise contract, you must set up alerting that detects changes the DNS response from `turn.cloudflare.com` (A and AAAA records) and update the hardcoded IP address(es) accordingly within 14 days of the DNS change.\n\nFor more details about static IPs, guarantees and other arrangements please discuss with your enterprise account team.\n\nYour enterprise team will be able to provide additional addresses to allowlist as future backup to achieve address diversity while still keeping a short list of IPs.\n\n### I would like to hardcode IP addresses used for TURN in my application to save a DNS lookup\n\nAlthough this is not recommended, we understand there is a very small set of circumstances where hardcoding IP addresses might be useful. In this case, you must set up alerting that detects changes the DNS response from `turn.cloudflare.com` (A and AAAA records) and update the hardcoded IP address(es) accordingly within 14 days of the DNS change. Note that this DNS response could return more than one IP address. In addition, you must set up a failover to a DNS query if there is a problem connecting to the hardcoded IP address. Cloudflare tries to, but cannot guarantee that the IP address used for the TURN service won't change unless this is in your enterprise contract. For more details about static IPs, guarantees and other arrangements please discuss with your enterprise account team.\n\n### I see that TURN IP are published above. Do you also publish IPs for STUN?\n\nTURN service at `turn.cloudflare.com` will also respond to binding requests (\"STUN requests\").\n\n### Does Cloudflare Realtime TURN support the expired IETF RFC draft \"draft-uberti-behave-turn-rest-00\"?\n\nThe Cloudflare Realtime credential generation function returns a JSON structure similar to the [expired RFC draft \"draft-uberti-behave-turn-rest-00\"](https://datatracker.ietf.org/doc/html/draft-uberti-behave-turn-rest-00), but it does not include the TTL value. If you need a response in this format, you can modify the JSON from the Cloudflare Realtime credential generation endpoint to the required format in your backend server or Cloudflare Workers.\n\n### I am observing packet loss when using Cloudflare Realtime TURN - how can I debug this?\n\nPacket loss is normal in UDP and can happen occasionally even on reliable connections. However, if you observe systematic packet loss, consider the following:\n\n* Are you sending or receiving data at a high rate (>50-100Mbps) from a single TURN client? Realtime TURN might be dropping packets to signal you to slow down.\n* Are you sending or receiving large amounts of data with very small packet sizes (high packet rate > 5-10kpps) from a single TURN client? Cloudflare Realtime might be dropping packets.\n* Are you sending packets to new unique addresses at a high rate resembling to [port scanning](https://en.wikipedia.org/wiki/Port_scanner) behavior?\n\n### I plan to use Realtime TURN at scale. What is the rate at which I can issue credentials?\n\nThere is no defined limit for credential issuance. Start at 500 credentials/sec and scale up linearly. Ensure you use more than 50% of the issued credentials.\n\n### What is the maximum value I can use for TURN credential expiry time?\n\nYou can set a expiration time for a credential up to 48 hours in the future. If you need your TURN allocation to last longer than this, you will need to [update](https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/setConfiguration) the TURN credentials.\n\n### Does Realtime TURN support IPv6?\n\nYes. Cloudflare Realtime is available over both IPv4 and IPv6 for TURN Client to TURN server communication, however it does not issue relay addresses in IPv6 as described in [RFC 6156](https://datatracker.ietf.org/doc/html/rfc6156).\n\n### Does Realtime TURN issue IPv6 relay addresses?\n\nNo. Realtime TURN will not respect `REQUESTED-ADDRESS-FAMILY` STUN attribute if specified and will issue IPv4 addresses only.\n\n### Does Realtime TURN support TCP relaying?\n\nNo. Realtime does not implement [RFC6062](https://datatracker.ietf.org/doc/html/rfc6062) and will not respect `REQUESTED-TRANSPORT` STUN attribute.\n\n### I am unable to make CreatePermission or ChannelBind requests with certain IP addresses. Why is that?\n\nCloudflare Realtime denies CreatePermission or ChannelBind requests if private IP ranges (e.g loopback addresses, linklocal unicast or multicast blocks) or IP addresses that are part of [BYOIP](https://developers.cloudflare.com/byoip/) are used.\n\nIf you are a Cloudflare BYOIP customer and wish to connect to your BYOIP ranges with Realtime TURN, please reach out to your account manager for further details.\n\n### What is the maximum duration limit for a TURN allocation?\n\nThere is no maximum duration limit for a TURN allocation. Per [RFC 8656 Section 3.2](https://datatracker.ietf.org/doc/html/rfc8656#section-3.2), once a relayed transport address is allocated, a client must keep the allocation alive. To do this, the client periodically sends a Refresh request to the server. The Refresh request needs to be authenticated with a valid TURN credential. The maximum duration for a credential is 48 hours. If a longer allocation is required, a new credential must be generated at least every 48 hours.\n\n### How often does Cloudflare perform maintenance on a server that is actively handling a TURN allocation? What is the impact of this?\n\nEven though this is not common, in certain scenarios TURN allocations may be disrupted. This could be caused by maintenance on the Cloudflare server handling the allocation or could be related to Internet network topology changes that cause TURN packets to arrive at a different Cloudflare datacenter. Regardless of the reason, [ICE restart](https://datatracker.ietf.org/doc/html/rfc8445#section-2.4) support by clients is highly recommended.\n\n### What will happen if TURN credentials expire while the TURN allocation is in use?\n\nCloudflare Realtime will immediately stop billing and recording usage for analytics. After a short delay, the connection will be disconnected.\n\n</page>\n\n<page>\n---\ntitle: Generate Credentials Â· Cloudflare Realtime docs\ndescription: Cloudflare will issue TURN keys, but these keys cannot be used as\n  credentials with turn.cloudflare.com. To use TURN, you need to create\n  credentials with a expiring TTL value.\nlastUpdated: 2025-12-03T04:47:02.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/turn/generate-credentials/\n  md: https://developers.cloudflare.com/realtime/turn/generate-credentials/index.md\n---\n\nCloudflare will issue TURN keys, but these keys cannot be used as credentials with `turn.cloudflare.com`. To use TURN, you need to create credentials with a expiring TTL value.\n\n## Create a TURN key\n\nTo create a TURN credential, you first need to create a TURN key using [Dashboard](https://dash.cloudflare.com/?to=/:account/calls), or the [API](https://developers.cloudflare.com/api/resources/calls/subresources/turn/methods/create/).\n\nYou should keep your TURN key on the server side (don't share it with the browser/app). A TURN key is a long-term secret that allows you to generate unlimited, shorter lived TURN credentials for TURN clients.\n\nWith a TURN key you can:\n\n* Generate TURN credentials that expire\n* Revoke previously issued TURN credentials\n\n## Create credentials\n\nYou should generate short-lived credentials for each TURN user. In order to create credentials, you should have a back-end service that uses your TURN Token ID and API token to generate credentials. It will make an API call like this:",
      "language": "unknown"
    },
    {
      "code": "The JSON response below can then be passed on to your front-end application:",
      "language": "unknown"
    },
    {
      "code": "Note\n\nThe list of returned URLs contains URLs with the primary and alternate ports. The alternate port 53 is known to be blocked by web browsers, and the TURN URL will time out if used in browsers. If you are using trickle ICE, this will not cause issues. Without trickle ICE you might want to filter out the URL with port 53 to avoid waiting for a timeout.\n\nUse `iceServers` as follows when instantiating the `RTCPeerConnection`:",
      "language": "unknown"
    },
    {
      "code": "The `ttl` value can be adjusted to expire the short lived key in a certain amount of time. This value should be larger than the time you'd expect the users to use the TURN service. For example, if you're using TURN for a video conferencing app, the value should be set to the longest video call you'd expect to happen in the app.\n\nWhen using short-lived TURN credentials with WebRTC, credentials can be refreshed during a WebRTC session using the `RTCPeerConnection` [`setConfiguration()`](https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection/setConfiguration) API.\n\n## Revoke credentials\n\nShort lived credentials can also be revoked before their TTL expires with a API call like this:",
      "language": "unknown"
    },
    {
      "code": "</page>\n\n<page>\n---\ntitle: Replacing existing TURN servers Â· Cloudflare Realtime docs\ndescription: If you are a existing TURN provider but would like to switch to\n  providing Cloudflare Realtime TURN for your customers, there is a few\n  considerations.\nlastUpdated: 2025-04-08T20:01:03.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/realtime/turn/replacing-existing/\n  md: https://developers.cloudflare.com/realtime/turn/replacing-existing/index.md\n---\n\nIf you are a existing TURN provider but would like to switch to providing Cloudflare Realtime TURN for your customers, there is a few considerations.\n\n## Benefits\n\nCloudflare Realtime TURN service can reduce tangible and untangible costs associated with TURN servers:\n\n* Server costs (AWS EC2 etc)\n* Bandwidth costs (Egress, load balancing etc)\n* Time and effort to set up a TURN process and maintenance of server\n* Scaling the servers up and down\n* Maintain the TURN server with security and feature updates\n* Maintain high availability\n\n## Recommendations\n\n### Separate environments with TURN keys\n\nWhen using Cloudflare Realtime TURN service at scale, consider separating environments such as \"testing\", \"staging\" or \"production\" with TURN keys. You can create up to 1,000 TURN keys in your account, which can be used to generate end user credentials.\n\nThere is no limit to how many end-user credentials you can create with a particular TURN key.\n\n### Tag users with custom identifiers\n\nCloudflare Realtime TURN service lets you tag each credential with a custom identifier as you generate a credential like below:",
      "language": "unknown"
    },
    {
      "code": "Use this field to aggregate usage for a specific user or group of users and collect analytics.\n\n### Monitor usage\n\nYou can monitor account wide usage with the [GraphQL analytics API](https://developers.cloudflare.com/realtime/turn/analytics/). This is useful for keeping track of overall usage for billing purposes, watching for unexpected changes. You can get timeseries data from TURN analytics with various filters in place.\n\n### Monitor for credential abuse\n\nIf you share TURN credentials with end users, credential abuse is possible. You can monitor for abuse by tagging each credential with custom identifiers and monitoring for top custom identifiers in your application via the [GraphQL analytics API](https://developers.cloudflare.com/realtime/turn/analytics/).\n\n## How to bill end users for their TURN usage\n\nWhen billing for TURN usage in your application, it's crucial to understand and account for adaptive sampling in TURN analytics. This system employs adaptive sampling to efficiently handle large datasets while maintaining accuracy.\n\nThe sampling process in TURN analytics works on two levels:\n\n* At data collection: Usage data points may be sampled if they are generated too quickly.\n* At query time: Additional sampling may occur if the query is too complex or covers a large time range.\n\nTo ensure accurate billing, write a single query that sums TURN usage per customer per time period, returning a single value. Avoid using queries that list usage for multiple customers simultaneously.\n\nBy following these guidelines and understanding how TURN analytics handles sampling, you can ensure more accurate billing for your end users based on their TURN usage.\n\nNote\n\nCloudflare Realtime only bills for traffic from Cloudflare's servers to your client, called `egressBytes`.\n\n### Example queries\n\nIncorrect approach example\n\nQuerying TURN usage for multiple customers in a single query can lead to inaccurate results. This is because the usage pattern of one customer could affect the sampling rate applied to another customer's data, potentially skewing the results.",
      "language": "unknown"
    },
    {
      "code": "Below is a query that queries usage only for a single customer.",
      "language": "unknown"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "5. Query the data with R2 SQL",
      "id": "5.-query-the-data-with-r2-sql"
    },
    {
      "level": "h3",
      "text": "5.1. View recent transactions",
      "id": "5.1.-view-recent-transactions"
    },
    {
      "level": "h3",
      "text": "5.2. Filter the raw transactions into a new table to highlight high-value transactions",
      "id": "5.2.-filter-the-raw-transactions-into-a-new-table-to-highlight-high-value-transactions"
    },
    {
      "level": "h2",
      "text": "Conclusion",
      "id": "conclusion"
    },
    {
      "level": "h2",
      "text": "1. Create a Worker project",
      "id": "1.-create-a-worker-project"
    },
    {
      "level": "h2",
      "text": "2. Install the Realtime Agents SDK",
      "id": "2.-install-the-realtime-agents-sdk"
    },
    {
      "level": "h2",
      "text": "3. Connect your Worker to Workers AI",
      "id": "3.-connect-your-worker-to-workers-ai"
    },
    {
      "level": "h2",
      "text": "4. Implement the Worker",
      "id": "4.-implement-the-worker"
    },
    {
      "level": "h2",
      "text": "5. Deploy your AI Worker",
      "id": "5.-deploy-your-ai-worker"
    },
    {
      "level": "h2",
      "text": "6. Generate a RealtimeKit token",
      "id": "6.-generate-a-realtimekit-token"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h3",
      "text": "Broadcasting a Message",
      "id": "broadcasting-a-message"
    },
    {
      "level": "h3",
      "text": "Subscribe to Messages",
      "id": "subscribe-to-messages"
    },
    {
      "level": "h3",
      "text": "Rate Limiting & Constraints",
      "id": "rate-limiting-&-constraints"
    },
    {
      "level": "h3",
      "text": "Examples",
      "id": "examples"
    },
    {
      "level": "h3",
      "text": "Create a Store",
      "id": "create-a-store"
    },
    {
      "level": "h3",
      "text": "Update a Store",
      "id": "update-a-store"
    },
    {
      "level": "h3",
      "text": "Subscribe to a Store",
      "id": "subscribe-to-a-store"
    },
    {
      "level": "h3",
      "text": "Fetch Store Data",
      "id": "fetch-store-data"
    },
    {
      "level": "h3",
      "text": "App",
      "id": "app"
    },
    {
      "level": "h3",
      "text": "Meeting",
      "id": "meeting"
    },
    {
      "level": "h3",
      "text": "Session",
      "id": "session"
    },
    {
      "level": "h3",
      "text": "Participant",
      "id": "participant"
    },
    {
      "level": "h3",
      "text": "Preset",
      "id": "preset"
    },
    {
      "level": "h3",
      "text": "Initialize Core SDK",
      "id": "initialize-core-sdk"
    },
    {
      "level": "h3",
      "text": "Advanced Options",
      "id": "advanced-options"
    },
    {
      "level": "h3",
      "text": "Meetings",
      "id": "meetings"
    },
    {
      "level": "h3",
      "text": "Participants",
      "id": "participants"
    },
    {
      "level": "h3",
      "text": "Presets",
      "id": "presets"
    },
    {
      "level": "h3",
      "text": "Client Side SDKs",
      "id": "client-side-sdks"
    },
    {
      "level": "h3",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h3",
      "text": "Installation",
      "id": "installation"
    },
    {
      "level": "h3",
      "text": "Create a RealtimeKit App",
      "id": "create-a-realtimekit-app"
    },
    {
      "level": "h3",
      "text": "Create a Meeting",
      "id": "create-a-meeting"
    },
    {
      "level": "h3",
      "text": "Add Participants",
      "id": "add-participants"
    },
    {
      "level": "h3",
      "text": "Frontend Integration",
      "id": "frontend-integration"
    },
    {
      "level": "h2",
      "text": "How does RealtimeKit recording work?",
      "id": "how-does-realtimekit-recording-work?"
    },
    {
      "level": "h2",
      "text": "Workflow",
      "id": "workflow"
    },
    {
      "level": "h2",
      "text": "2025-11-18",
      "id": "2025-11-18"
    },
    {
      "level": "h2",
      "text": "2025-10-30",
      "id": "2025-10-30"
    },
    {
      "level": "h2",
      "text": "2025-08-26",
      "id": "2025-08-26"
    },
    {
      "level": "h2",
      "text": "2025-08-14",
      "id": "2025-08-14"
    },
    {
      "level": "h2",
      "text": "2025-08-04",
      "id": "2025-08-04"
    },
    {
      "level": "h2",
      "text": "2025-07-17",
      "id": "2025-07-17"
    },
    {
      "level": "h2",
      "text": "2025-07-08",
      "id": "2025-07-08"
    },
    {
      "level": "h2",
      "text": "2025-07-02",
      "id": "2025-07-02"
    },
    {
      "level": "h2",
      "text": "2025-06-30",
      "id": "2025-06-30"
    },
    {
      "level": "h2",
      "text": "2025-06-17",
      "id": "2025-06-17"
    },
    {
      "level": "h2",
      "text": "2025-05-29",
      "id": "2025-05-29"
    },
    {
      "level": "h2",
      "text": "2025-05-29",
      "id": "2025-05-29"
    },
    {
      "level": "h3",
      "text": "Offerings",
      "id": "offerings"
    },
    {
      "level": "h3",
      "text": "Select you framework",
      "id": "select-you-framework"
    },
    {
      "level": "h3",
      "text": "Technical comparison",
      "id": "technical-comparison"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "Cloudflare Realtime vs. Traditional SFUs",
      "id": "cloudflare-realtime-vs.-traditional-sfus"
    },
    {
      "level": "h3",
      "text": "The Limitations of Centralized SFUs",
      "id": "the-limitations-of-centralized-sfus"
    },
    {
      "level": "h3",
      "text": "How is Cloudflare Realtime different?",
      "id": "how-is-cloudflare-realtime-different?"
    },
    {
      "level": "h2",
      "text": "How Cloudflare Realtime Works",
      "id": "how-cloudflare-realtime-works"
    },
    {
      "level": "h3",
      "text": "Establishing Peer Connections",
      "id": "establishing-peer-connections"
    },
    {
      "level": "h3",
      "text": "Signaling and Media Stream Management",
      "id": "signaling-and-media-stream-management"
    },
    {
      "level": "h3",
      "text": "Application-Level Management",
      "id": "application-level-management"
    },
    {
      "level": "h2",
      "text": "Getting Started with Cloudflare Realtime",
      "id": "getting-started-with-cloudflare-realtime"
    },
    {
      "level": "h2",
      "text": "2025-11-21",
      "id": "2025-11-21"
    },
    {
      "level": "h2",
      "text": "2025-08-29",
      "id": "2025-08-29"
    },
    {
      "level": "h2",
      "text": "2024-09-25",
      "id": "2024-09-25"
    },
    {
      "level": "h2",
      "text": "2024-04-04",
      "id": "2024-04-04"
    },
    {
      "level": "h2",
      "text": "2024-04-04",
      "id": "2024-04-04"
    },
    {
      "level": "h2",
      "text": "2022-09-27",
      "id": "2022-09-27"
    },
    {
      "level": "h2",
      "text": "Demos",
      "id": "demos"
    },
    {
      "level": "h3",
      "text": "How to use DataChannels",
      "id": "how-to-use-datachannels"
    },
    {
      "level": "h3",
      "text": "Unidirectional DataChannels",
      "id": "unidirectional-datachannels"
    },
    {
      "level": "h2",
      "text": "Example",
      "id": "example"
    },
    {
      "level": "h2",
      "text": "Create your first app",
      "id": "create-your-first-app"
    },
    {
      "level": "h2",
      "text": "API Endpoints",
      "id": "api-endpoints"
    },
    {
      "level": "h2",
      "text": "Handling Secrets",
      "id": "handling-secrets"
    },
    {
      "level": "h2",
      "text": "Using STUN and TURN Servers",
      "id": "using-stun-and-turn-servers"
    },
    {
      "level": "h2",
      "text": "Lifecycle of a Simple Session",
      "id": "lifecycle-of-a-simple-session"
    },
    {
      "level": "h2",
      "text": "Why Cloudflare Realtime exists",
      "id": "why-cloudflare-realtime-exists"
    },
    {
      "level": "h2",
      "text": "What makes Cloudflare Realtime unique",
      "id": "what-makes-cloudflare-realtime-unique"
    },
    {
      "level": "h2",
      "text": "What exactly does Cloudflare Realtime do?",
      "id": "what-exactly-does-cloudflare-realtime-do?"
    },
    {
      "level": "h2",
      "text": "How most developers get started",
      "id": "how-most-developers-get-started"
    },
    {
      "level": "h2",
      "text": "Free",
      "id": "free"
    },
    {
      "level": "h2",
      "text": "Limits",
      "id": "limits"
    },
    {
      "level": "h2",
      "text": "Inactivity Timeout",
      "id": "inactivity-timeout"
    },
    {
      "level": "h2",
      "text": "PeerConnection Requirements",
      "id": "peerconnection-requirements"
    },
    {
      "level": "h2",
      "text": "Handling Connectivity Issues",
      "id": "handling-connectivity-issues"
    },
    {
      "level": "h2",
      "text": "Supported Codecs",
      "id": "supported-codecs"
    },
    {
      "level": "h3",
      "text": "Supported video codecs",
      "id": "supported-video-codecs"
    },
    {
      "level": "h3",
      "text": "Supported audio codecs",
      "id": "supported-audio-codecs"
    },
    {
      "level": "h2",
      "text": "What adapters do",
      "id": "what-adapters-do"
    },
    {
      "level": "h2",
      "text": "Available adapters",
      "id": "available-adapters"
    },
    {
      "level": "h3",
      "text": "WebSocket adapter (beta)",
      "id": "websocket-adapter-(beta)"
    },
    {
      "level": "h2",
      "text": "Architecture",
      "id": "architecture"
    },
    {
      "level": "h3",
      "text": "Key concepts",
      "id": "key-concepts"
    },
    {
      "level": "h2",
      "text": "Common use cases",
      "id": "common-use-cases"
    },
    {
      "level": "h3",
      "text": "AI processing",
      "id": "ai-processing"
    },
    {
      "level": "h3",
      "text": "Media recording",
      "id": "media-recording"
    },
    {
      "level": "h3",
      "text": "Legacy integration",
      "id": "legacy-integration"
    },
    {
      "level": "h2",
      "text": "API overview",
      "id": "api-overview"
    },
    {
      "level": "h2",
      "text": "Best practices",
      "id": "best-practices"
    },
    {
      "level": "h2",
      "text": "Limitations",
      "id": "limitations"
    },
    {
      "level": "h2",
      "text": "Get started",
      "id": "get-started"
    },
    {
      "level": "h3",
      "text": "TURN",
      "id": "turn"
    },
    {
      "level": "h3",
      "text": "SFU",
      "id": "sfu"
    },
    {
      "level": "h2",
      "text": "Application",
      "id": "application"
    },
    {
      "level": "h2",
      "text": "Sessions",
      "id": "sessions"
    },
    {
      "level": "h2",
      "text": "Tracks",
      "id": "tracks"
    },
    {
      "level": "h2",
      "text": "Realtime as a Programmable \"Switchboard\"",
      "id": "realtime-as-a-programmable-\"switchboard\""
    },
    {
      "level": "h2",
      "text": "Beyond \"Rooms\", \"Users\", and \"Participants\"",
      "id": "beyond-\"rooms\",-\"users\",-and-\"participants\""
    },
    {
      "level": "h3",
      "text": "Presence Protocol vs. Media Flow",
      "id": "presence-protocol-vs.-media-flow"
    },
    {
      "level": "h2",
      "text": "Available metrics and dimensions",
      "id": "available-metrics-and-dimensions"
    },
    {
      "level": "h3",
      "text": "Metrics",
      "id": "metrics"
    },
    {
      "level": "h3",
      "text": "Dimensions",
      "id": "dimensions"
    },
    {
      "level": "h3",
      "text": "Filters",
      "id": "filters"
    },
    {
      "level": "h2",
      "text": "GraphQL clients",
      "id": "graphql-clients"
    },
    {
      "level": "h2",
      "text": "Useful TURN analytics queries",
      "id": "useful-turn-analytics-queries"
    },
    {
      "level": "h3",
      "text": "Concurrent connections with data usage over time",
      "id": "concurrent-connections-with-data-usage-over-time"
    },
    {
      "level": "h3",
      "text": "Top TURN keys by egress",
      "id": "top-turn-keys-by-egress"
    },
    {
      "level": "h3",
      "text": "Top TURN custom identifiers",
      "id": "top-turn-custom-identifiers"
    },
    {
      "level": "h3",
      "text": "Usage for a specific custom identifier",
      "id": "usage-for-a-specific-custom-identifier"
    },
    {
      "level": "h3",
      "text": "Usage as a timeseries (for graphs)",
      "id": "usage-as-a-timeseries-(for-graphs)"
    },
    {
      "level": "h3",
      "text": "Usage breakdown by geographic location",
      "id": "usage-breakdown-by-geographic-location"
    },
    {
      "level": "h3",
      "text": "Filter by specific key or identifier",
      "id": "filter-by-specific-key-or-identifier"
    },
    {
      "level": "h3",
      "text": "Time aggregation options",
      "id": "time-aggregation-options"
    },
    {
      "level": "h2",
      "text": "Advanced use cases",
      "id": "advanced-use-cases"
    },
    {
      "level": "h3",
      "text": "Combining multiple dimensions",
      "id": "combining-multiple-dimensions"
    },
    {
      "level": "h3",
      "text": "Identifying top consumers",
      "id": "identifying-top-consumers"
    },
    {
      "level": "h2",
      "text": "Schema exploration",
      "id": "schema-exploration"
    },
    {
      "level": "h3",
      "text": "How it works",
      "id": "how-it-works"
    },
    {
      "level": "h3",
      "text": "Quality Control",
      "id": "quality-control"
    },
    {
      "level": "h3",
      "text": "Bandwidth Management across media tracks",
      "id": "bandwidth-management-across-media-tracks"
    },
    {
      "level": "h3",
      "text": "Layer Switching Behavior",
      "id": "layer-switching-behavior"
    },
    {
      "level": "h3",
      "text": "Publisher Configuration",
      "id": "publisher-configuration"
    },
    {
      "level": "h2",
      "text": "Example",
      "id": "example"
    },
    {
      "level": "h2",
      "text": "Setting up a CNAME record",
      "id": "setting-up-a-cname-record"
    },
    {
      "level": "h2",
      "text": "General",
      "id": "general"
    },
    {
      "level": "h3",
      "text": "What is Cloudflare Realtime TURN pricing? How exactly is it calculated?",
      "id": "what-is-cloudflare-realtime-turn-pricing?-how-exactly-is-it-calculated?"
    },
    {
      "level": "h3",
      "text": "Is Realtime TURN HIPAA/GDPR/FedRAMP compliant?",
      "id": "is-realtime-turn-hipaa/gdpr/fedramp-compliant?"
    },
    {
      "level": "h3",
      "text": "What data can Cloudflare access when TURN is used with WebRTC?",
      "id": "what-data-can-cloudflare-access-when-turn-is-used-with-webrtc?"
    },
    {
      "level": "h3",
      "text": "Is Realtime TURN end-to-end encrypted?",
      "id": "is-realtime-turn-end-to-end-encrypted?"
    },
    {
      "level": "h3",
      "text": "What regions does Cloudflare Realtime TURN operate at?",
      "id": "what-regions-does-cloudflare-realtime-turn-operate-at?"
    },
    {
      "level": "h3",
      "text": "Does Cloudflare Realtime TURN use the Cloudflare Backbone or is there any \"magic\" Cloudflare do to speed connection up?",
      "id": "does-cloudflare-realtime-turn-use-the-cloudflare-backbone-or-is-there-any-\"magic\"-cloudflare-do-to-speed-connection-up?"
    },
    {
      "level": "h3",
      "text": "What is the difference between Cloudflare Realtime TURN with a enterprise plan vs self-serve (pay with your credit card) plans?",
      "id": "what-is-the-difference-between-cloudflare-realtime-turn-with-a-enterprise-plan-vs-self-serve-(pay-with-your-credit-card)-plans?"
    },
    {
      "level": "h3",
      "text": "Does Cloudflare Realtime TURN run in the Cloudflare China Network?",
      "id": "does-cloudflare-realtime-turn-run-in-the-cloudflare-china-network?"
    },
    {
      "level": "h3",
      "text": "How long does it take for TURN activity to be available in analytics?",
      "id": "how-long-does-it-take-for-turn-activity-to-be-available-in-analytics?"
    },
    {
      "level": "h2",
      "text": "Technical",
      "id": "technical"
    },
    {
      "level": "h3",
      "text": "I need to allowlist (whitelist) Cloudflare Realtime TURN IP addresses. Which IP addresses should I use?",
      "id": "i-need-to-allowlist-(whitelist)-cloudflare-realtime-turn-ip-addresses.-which-ip-addresses-should-i-use?"
    },
    {
      "level": "h3",
      "text": "I would like to hardcode IP addresses used for TURN in my application to save a DNS lookup",
      "id": "i-would-like-to-hardcode-ip-addresses-used-for-turn-in-my-application-to-save-a-dns-lookup"
    },
    {
      "level": "h3",
      "text": "I see that TURN IP are published above. Do you also publish IPs for STUN?",
      "id": "i-see-that-turn-ip-are-published-above.-do-you-also-publish-ips-for-stun?"
    },
    {
      "level": "h3",
      "text": "Does Cloudflare Realtime TURN support the expired IETF RFC draft \"draft-uberti-behave-turn-rest-00\"?",
      "id": "does-cloudflare-realtime-turn-support-the-expired-ietf-rfc-draft-\"draft-uberti-behave-turn-rest-00\"?"
    },
    {
      "level": "h3",
      "text": "I am observing packet loss when using Cloudflare Realtime TURN - how can I debug this?",
      "id": "i-am-observing-packet-loss-when-using-cloudflare-realtime-turn---how-can-i-debug-this?"
    },
    {
      "level": "h3",
      "text": "I plan to use Realtime TURN at scale. What is the rate at which I can issue credentials?",
      "id": "i-plan-to-use-realtime-turn-at-scale.-what-is-the-rate-at-which-i-can-issue-credentials?"
    },
    {
      "level": "h3",
      "text": "What is the maximum value I can use for TURN credential expiry time?",
      "id": "what-is-the-maximum-value-i-can-use-for-turn-credential-expiry-time?"
    },
    {
      "level": "h3",
      "text": "Does Realtime TURN support IPv6?",
      "id": "does-realtime-turn-support-ipv6?"
    },
    {
      "level": "h3",
      "text": "Does Realtime TURN issue IPv6 relay addresses?",
      "id": "does-realtime-turn-issue-ipv6-relay-addresses?"
    },
    {
      "level": "h3",
      "text": "Does Realtime TURN support TCP relaying?",
      "id": "does-realtime-turn-support-tcp-relaying?"
    },
    {
      "level": "h3",
      "text": "I am unable to make CreatePermission or ChannelBind requests with certain IP addresses. Why is that?",
      "id": "i-am-unable-to-make-createpermission-or-channelbind-requests-with-certain-ip-addresses.-why-is-that?"
    },
    {
      "level": "h3",
      "text": "What is the maximum duration limit for a TURN allocation?",
      "id": "what-is-the-maximum-duration-limit-for-a-turn-allocation?"
    },
    {
      "level": "h3",
      "text": "How often does Cloudflare perform maintenance on a server that is actively handling a TURN allocation? What is the impact of this?",
      "id": "how-often-does-cloudflare-perform-maintenance-on-a-server-that-is-actively-handling-a-turn-allocation?-what-is-the-impact-of-this?"
    },
    {
      "level": "h3",
      "text": "What will happen if TURN credentials expire while the TURN allocation is in use?",
      "id": "what-will-happen-if-turn-credentials-expire-while-the-turn-allocation-is-in-use?"
    },
    {
      "level": "h2",
      "text": "Create a TURN key",
      "id": "create-a-turn-key"
    },
    {
      "level": "h2",
      "text": "Create credentials",
      "id": "create-credentials"
    },
    {
      "level": "h2",
      "text": "Revoke credentials",
      "id": "revoke-credentials"
    },
    {
      "level": "h2",
      "text": "Benefits",
      "id": "benefits"
    },
    {
      "level": "h2",
      "text": "Recommendations",
      "id": "recommendations"
    },
    {
      "level": "h3",
      "text": "Separate environments with TURN keys",
      "id": "separate-environments-with-turn-keys"
    },
    {
      "level": "h3",
      "text": "Tag users with custom identifiers",
      "id": "tag-users-with-custom-identifiers"
    },
    {
      "level": "h3",
      "text": "Monitor usage",
      "id": "monitor-usage"
    },
    {
      "level": "h3",
      "text": "Monitor for credential abuse",
      "id": "monitor-for-credential-abuse"
    },
    {
      "level": "h2",
      "text": "How to bill end users for their TURN usage",
      "id": "how-to-bill-end-users-for-their-turn-usage"
    },
    {
      "level": "h3",
      "text": "Example queries",
      "id": "example-queries"
    },
    {
      "level": "h2",
      "text": "What is TURN?",
      "id": "what-is-turn?"
    },
    {
      "level": "h2",
      "text": "How do I use TURN?",
      "id": "how-do-i-use-turn?"
    },
    {
      "level": "h2",
      "text": "Key concepts to know when understanding TURN",
      "id": "key-concepts-to-know-when-understanding-turn"
    },
    {
      "level": "h2",
      "text": "How TURN Works",
      "id": "how-turn-works"
    },
    {
      "level": "h2",
      "text": "TURN vs VPN",
      "id": "turn-vs-vpn"
    },
    {
      "level": "h2",
      "text": "Why is TURN Useful?",
      "id": "why-is-turn-useful?"
    },
    {
      "level": "h2",
      "text": "TURN client to TURN server protocols",
      "id": "turn-client-to-turn-server-protocols"
    },
    {
      "level": "h2",
      "text": "TURN client to TURN server protocols",
      "id": "turn-client-to-turn-server-protocols"
    },
    {
      "level": "h2",
      "text": "Pairing-based Cryptography",
      "id": "pairing-based-cryptography"
    },
    {
      "level": "h2",
      "text": "BLS Signatures",
      "id": "bls-signatures"
    },
    {
      "level": "h3",
      "text": "Key Generation",
      "id": "key-generation"
    },
    {
      "level": "h3",
      "text": "Signature Generation",
      "id": "signature-generation"
    },
    {
      "level": "h3",
      "text": "Signature Verification",
      "id": "signature-verification"
    },
    {
      "level": "h2",
      "text": "Threshold BLS Signature",
      "id": "threshold-bls-signature"
    },
    {
      "level": "h3",
      "text": "Key Generation",
      "id": "key-generation"
    },
    {
      "level": "h3",
      "text": "Partial Signature Generation",
      "id": "partial-signature-generation"
    },
    {
      "level": "h3",
      "text": "Partial Signature Verification",
      "id": "partial-signature-verification"
    },
    {
      "level": "h3",
      "text": "Signature Reconstruction",
      "id": "signature-reconstruction"
    },
    {
      "level": "h3",
      "text": "Signature Verification",
      "id": "signature-verification"
    },
    {
      "level": "h3",
      "text": "`ð”¾1/ð”¾2` swap",
      "id": "`ð”¾1/ð”¾2`-swap"
    },
    {
      "level": "h2",
      "text": "Chained Randomness",
      "id": "chained-randomness"
    },
    {
      "level": "h2",
      "text": "Unchained Randomness",
      "id": "unchained-randomness"
    },
    {
      "level": "h2",
      "text": "Secret Sharing",
      "id": "secret-sharing"
    },
    {
      "level": "h2",
      "text": "Shamirâ€™s Secret Sharing (SSS)",
      "id": "shamirâ€™s-secret-sharing-(sss)"
    },
    {
      "level": "h3",
      "text": "Share Distribution",
      "id": "share-distribution"
    },
    {
      "level": "h3",
      "text": "Secret Reconstruction",
      "id": "secret-reconstruction"
    },
    {
      "level": "h2",
      "text": "Verifiable Secret Sharing",
      "id": "verifiable-secret-sharing"
    },
    {
      "level": "h3",
      "text": "Share Distribution",
      "id": "share-distribution"
    },
    {
      "level": "h3",
      "text": "Secret Reconstruction",
      "id": "secret-reconstruction"
    },
    {
      "level": "h2",
      "text": "Distributed Key Generation (DKG)",
      "id": "distributed-key-generation-(dkg)"
    },
    {
      "level": "h3",
      "text": "Share Distribution",
      "id": "share-distribution"
    },
    {
      "level": "h3",
      "text": "Share Verification",
      "id": "share-verification"
    },
    {
      "level": "h3",
      "text": "Share Finalization",
      "id": "share-finalization"
    },
    {
      "level": "h2",
      "text": "Introduction",
      "id": "introduction"
    },
    {
      "level": "h3",
      "text": "Who is this document for and what will you learn?",
      "id": "who-is-this-document-for-and-what-will-you-learn?"
    },
    {
      "level": "h2",
      "text": "Traditional challenges deploying web applications",
      "id": "traditional-challenges-deploying-web-applications"
    },
    {
      "level": "h2",
      "text": "How a CDN tackles web application challenges",
      "id": "how-a-cdn-tackles-web-application-challenges"
    },
    {
      "level": "h3",
      "text": "Impacts",
      "id": "impacts"
    },
    {
      "level": "h3",
      "text": "Routing requests to CDN nodes",
      "id": "routing-requests-to-cdn-nodes"
    },
    {
      "level": "h2",
      "text": "Introducing the Cloudflare CDN",
      "id": "introducing-the-cloudflare-cdn"
    },
    {
      "level": "h2",
      "text": "Cloudflare CDN architecture and design",
      "id": "cloudflare-cdn-architecture-and-design"
    },
    {
      "level": "h3",
      "text": "Tiered Cache",
      "id": "tiered-cache"
    },
    {
      "level": "h3",
      "text": "Traffic flow: Tiered Cache, Smart Tiered Cache topology",
      "id": "traffic-flow:-tiered-cache,-smart-tiered-cache-topology"
    },
    {
      "level": "h3",
      "text": "Regional Tiered Cache",
      "id": "regional-tiered-cache"
    },
    {
      "level": "h3",
      "text": "Argo Smart Routing",
      "id": "argo-smart-routing"
    },
    {
      "level": "h3",
      "text": "Cache Reserve",
      "id": "cache-reserve"
    },
    {
      "level": "h3",
      "text": "Traffic flow: Cache Reserve topology",
      "id": "traffic-flow:-cache-reserve-topology"
    },
    {
      "level": "h3",
      "text": "China Network & Global Acceleration for clients in China",
      "id": "china-network-&-global-acceleration-for-clients-in-china"
    },
    {
      "level": "h2",
      "text": "Summary",
      "id": "summary"
    },
    {
      "level": "h2",
      "text": "Introduction",
      "id": "introduction"
    },
    {
      "level": "h3",
      "text": "Who is this document for and what will you learn?",
      "id": "who-is-this-document-for-and-what-will-you-learn?"
    },
    {
      "level": "h2",
      "text": "Integration of Cloudflare with Microsoft",
      "id": "integration-of-cloudflare-with-microsoft"
    },
    {
      "level": "h3",
      "text": "Microsoft Entra ID with Cloudflare",
      "id": "microsoft-entra-id-with-cloudflare"
    },
    {
      "level": "h3",
      "text": "Microsoft Intune with Cloudflare",
      "id": "microsoft-intune-with-cloudflare"
    },
    {
      "level": "h3",
      "text": "Cloudflare CASB for Microsoft 365",
      "id": "cloudflare-casb-for-microsoft-365"
    },
    {
      "level": "h3",
      "text": "Cloudflare's Secure Web Gateway for improved security to Microsoft SaaS applications",
      "id": "cloudflare's-secure-web-gateway-for-improved-security-to-microsoft-saas-applications"
    },
    {
      "level": "h3",
      "text": "Cloudflare's Email security for improved email protection",
      "id": "cloudflare's-email-security-for-improved-email-protection"
    },
    {
      "level": "h2",
      "text": "Summary",
      "id": "summary"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Introduction",
      "id": "introduction"
    },
    {
      "level": "h2",
      "text": "Who is this document for and what will you learn?",
      "id": "who-is-this-document-for-and-what-will-you-learn?"
    },
    {
      "level": "h2",
      "text": "Integration overview",
      "id": "integration-overview"
    },
    {
      "level": "h2",
      "text": "Technical components",
      "id": "technical-components"
    },
    {
      "level": "h3",
      "text": "SentinelOne components",
      "id": "sentinelone-components"
    },
    {
      "level": "h3",
      "text": "Cloudflare components",
      "id": "cloudflare-components"
    },
    {
      "level": "h2",
      "text": "Implementation architecture",
      "id": "implementation-architecture"
    },
    {
      "level": "h3",
      "text": "Authentication and authorization flow",
      "id": "authentication-and-authorization-flow"
    },
    {
      "level": "h3",
      "text": "Integration setup",
      "id": "integration-setup"
    },
    {
      "level": "h2",
      "text": "Security capabilities",
      "id": "security-capabilities"
    },
    {
      "level": "h3",
      "text": "Device posture verification",
      "id": "device-posture-verification"
    },
    {
      "level": "h3",
      "text": "User risk detection",
      "id": "user-risk-detection"
    },
    {
      "level": "h2",
      "text": "Core architecture",
      "id": "core-architecture"
    },
    {
      "level": "h3",
      "text": "Cloudflare Zero Trust platform operations",
      "id": "cloudflare-zero-trust-platform-operations"
    },
    {
      "level": "h3",
      "text": "SentinelOne platform integration",
      "id": "sentinelone-platform-integration"
    },
    {
      "level": "h3",
      "text": "Authentication and access flow",
      "id": "authentication-and-access-flow"
    },
    {
      "level": "h3",
      "text": "Security and monitoring capabilities",
      "id": "security-and-monitoring-capabilities"
    },
    {
      "level": "h2",
      "text": "Operational benefits",
      "id": "operational-benefits"
    },
    {
      "level": "h2",
      "text": "Deployment considerations",
      "id": "deployment-considerations"
    },
    {
      "level": "h3",
      "text": "Network architecture",
      "id": "network-architecture"
    },
    {
      "level": "h3",
      "text": "Policy design",
      "id": "policy-design"
    },
    {
      "level": "h2",
      "text": "Conclusion",
      "id": "conclusion"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Introduction",
      "id": "introduction"
    },
    {
      "level": "h2",
      "text": "Strengthen your email infrastructure with Cloudflare Email security",
      "id": "strengthen-your-email-infrastructure-with-cloudflare-email-security"
    },
    {
      "level": "h3",
      "text": "Who is this reference architecture for and what will you learn?",
      "id": "who-is-this-reference-architecture-for-and-what-will-you-learn?"
    },
    {
      "level": "h2",
      "text": "Email security deployment options",
      "id": "email-security-deployment-options"
    },
    {
      "level": "h2",
      "text": "Choose a deployment model",
      "id": "choose-a-deployment-model"
    },
    {
      "level": "h2",
      "text": "Deployment options",
      "id": "deployment-options"
    },
    {
      "level": "h3",
      "text": "Inline",
      "id": "inline"
    },
    {
      "level": "h3",
      "text": "API",
      "id": "api"
    },
    {
      "level": "h3",
      "text": "BCC/Journaling",
      "id": "bcc/journaling"
    },
    {
      "level": "h3",
      "text": "Hybrid",
      "id": "hybrid"
    },
    {
      "level": "h2",
      "text": "Automated Post Delivery",
      "id": "automated-post-delivery"
    },
    {
      "level": "h3",
      "text": "Post Delivery Response",
      "id": "post-delivery-response"
    },
    {
      "level": "h3",
      "text": "Phish Submission Response",
      "id": "phish-submission-response"
    },
    {
      "level": "h3",
      "text": "Submission Handling",
      "id": "submission-handling"
    },
    {
      "level": "h2",
      "text": "Summary",
      "id": "summary"
    },
    {
      "level": "h2",
      "text": "Introduction",
      "id": "introduction"
    },
    {
      "level": "h3",
      "text": "Who is this document for and what will you learn?",
      "id": "who-is-this-document-for-and-what-will-you-learn?"
    },
    {
      "level": "h2",
      "text": "Handling dynamic workloads in modern applications",
      "id": "handling-dynamic-workloads-in-modern-applications"
    },
    {
      "level": "h3",
      "text": "Concepts and terminology",
      "id": "concepts-and-terminology"
    },
    {
      "level": "h3",
      "text": "Challenges addressed by load balancers",
      "id": "challenges-addressed-by-load-balancers"
    },
    {
      "level": "h3",
      "text": "Types of traffic management",
      "id": "types-of-traffic-management"
    },
    {
      "level": "h2",
      "text": "Cloudflare Load Balancing architecture and design",
      "id": "cloudflare-load-balancing-architecture-and-design"
    },
    {
      "level": "h3",
      "text": "Inherent advantages in the Cloudflare architecture",
      "id": "inherent-advantages-in-the-cloudflare-architecture"
    },
    {
      "level": "h3",
      "text": "The structure of a Cloudflare Load Balancer",
      "id": "the-structure-of-a-cloudflare-load-balancer"
    },
    {
      "level": "h3",
      "text": "Steering types and methods",
      "id": "steering-types-and-methods"
    },
    {
      "level": "h3",
      "text": "Health monitors",
      "id": "health-monitors"
    },
    {
      "level": "h3",
      "text": "Endpoints and endpoint pools",
      "id": "endpoints-and-endpoint-pools"
    },
    {
      "level": "h3",
      "text": "Load balancers",
      "id": "load-balancers"
    },
    {
      "level": "h3",
      "text": "Protecting and securing load balancers",
      "id": "protecting-and-securing-load-balancers"
    },
    {
      "level": "h2",
      "text": "Summary",
      "id": "summary"
    },
    {
      "level": "h2",
      "text": "Introduction",
      "id": "introduction"
    },
    {
      "level": "h3",
      "text": "Who is this document for and what will you learn?",
      "id": "who-is-this-document-for-and-what-will-you-learn?"
    },
    {
      "level": "h2",
      "text": "What Is Magic Transit?",
      "id": "what-is-magic-transit?"
    },
    {
      "level": "h3",
      "text": "Baking resilience into our network using anycast",
      "id": "baking-resilience-into-our-network-using-anycast"
    },
    {
      "level": "h2",
      "text": "Deployment Architectures for Magic Transit",
      "id": "deployment-architectures-for-magic-transit"
    },
    {
      "level": "h3",
      "text": "Default Configuration (Ingress Only, Direct Server Return)",
      "id": "default-configuration-(ingress-only,-direct-server-return)"
    },
    {
      "level": "h3",
      "text": "Magic Transit With Egress Option Enabled",
      "id": "magic-transit-with-egress-option-enabled"
    },
    {
      "level": "h3",
      "text": "Magic Transit Over Cloudflare Network Interconnect (CNI)",
      "id": "magic-transit-over-cloudflare-network-interconnect-(cni)"
    },
    {
      "level": "h3",
      "text": "Magic Transit Protecting Public Cloud-Hosted Services",
      "id": "magic-transit-protecting-public-cloud-hosted-services"
    },
    {
      "level": "h3",
      "text": "Magic Transit and Magic WAN",
      "id": "magic-transit-and-magic-wan"
    },
    {
      "level": "h3",
      "text": "Magic Firewall: Control and Filter Unwanted Traffic Before It Reaches the Enterprise Network",
      "id": "magic-firewall:-control-and-filter-unwanted-traffic-before-it-reaches-the-enterprise-network"
    },
    {
      "level": "h2",
      "text": "A Note on Always-On and On-Demand Deployments",
      "id": "a-note-on-always-on-and-on-demand-deployments"
    },
    {
      "level": "h2",
      "text": "Summary",
      "id": "summary"
    },
    {
      "level": "h2",
      "text": "Introduction",
      "id": "introduction"
    },
    {
      "level": "h3",
      "text": "Who is this document for and what will you learn?",
      "id": "who-is-this-document-for-and-what-will-you-learn?"
    },
    {
      "level": "h2",
      "text": "Cloud based security and performance providers",
      "id": "cloud-based-security-and-performance-providers"
    },
    {
      "level": "h2",
      "text": "Cloudflareâ€™s reverse proxy architecture and solution",
      "id": "cloudflareâ€™s-reverse-proxy-architecture-and-solution"
    },
    {
      "level": "h2",
      "text": "Cloudflare onboarding options",
      "id": "cloudflare-onboarding-options"
    },
    {
      "level": "h2",
      "text": "Why multi-vendor?",
      "id": "why-multi-vendor?"
    },
    {
      "level": "h3",
      "text": "Regulatory/company compliance",
      "id": "regulatory/company-compliance"
    },
    {
      "level": "h3",
      "text": "Resiliency",
      "id": "resiliency"
    },
    {
      "level": "h3",
      "text": "Performance",
      "id": "performance"
    },
    {
      "level": "h3",
      "text": "Cost",
      "id": "cost"
    },
    {
      "level": "h2",
      "text": "Multi-vendor solution considerations",
      "id": "multi-vendor-solution-considerations"
    },
    {
      "level": "h3",
      "text": "Routing",
      "id": "routing"
    },
    {
      "level": "h3",
      "text": "Configuration",
      "id": "configuration"
    },
    {
      "level": "h3",
      "text": "Connectivity",
      "id": "connectivity"
    },
    {
      "level": "h2",
      "text": "Common deployments",
      "id": "common-deployments"
    },
    {
      "level": "h3",
      "text": "Multi-vendor active-active security and different provider for DNS",
      "id": "multi-vendor-active-active-security-and-different-provider-for-dns"
    },
    {
      "level": "h3",
      "text": "Multi-vendor active-active security with multi-vendor DNS from same providers",
      "id": "multi-vendor-active-active-security-with-multi-vendor-dns-from-same-providers"
    },
    {
      "level": "h2",
      "text": "Multi-vendor DNS setup options",
      "id": "multi-vendor-dns-setup-options"
    },
    {
      "level": "h2",
      "text": "Configuration and management best practices",
      "id": "configuration-and-management-best-practices"
    },
    {
      "level": "h2",
      "text": "Connectivity options",
      "id": "connectivity-options"
    },
    {
      "level": "h3",
      "text": "Internet (default)",
      "id": "internet-(default)"
    },
    {
      "level": "h3",
      "text": "Private connection - tunnel or VPN",
      "id": "private-connection---tunnel-or-vpn"
    },
    {
      "level": "h3",
      "text": "Direct connection",
      "id": "direct-connection"
    },
    {
      "level": "h2",
      "text": "Additional routing and security options",
      "id": "additional-routing-and-security-options"
    },
    {
      "level": "h3",
      "text": "Argo Smart Routing",
      "id": "argo-smart-routing"
    },
    {
      "level": "h3",
      "text": "Authenticated Origin Pulls (mTLS)",
      "id": "authenticated-origin-pulls-(mtls)"
    },
    {
      "level": "h2",
      "text": "Summary",
      "id": "summary"
    },
    {
      "level": "h2",
      "text": "Introduction",
      "id": "introduction"
    },
    {
      "level": "h3",
      "text": "Who is this document for and what will you learn?",
      "id": "who-is-this-document-for-and-what-will-you-learn?"
    },
    {
      "level": "h2",
      "text": "Secure global network",
      "id": "secure-global-network"
    },
    {
      "level": "h3",
      "text": "Architecture",
      "id": "architecture"
    },
    {
      "level": "h3",
      "text": "Operational security",
      "id": "operational-security"
    },
    {
      "level": "h2",
      "text": "Using Cloudflare to protect your business",
      "id": "using-cloudflare-to-protect-your-business"
    },
    {
      "level": "h3",
      "text": "Securing public and private resources",
      "id": "securing-public-and-private-resources"
    },
    {
      "level": "h3",
      "text": "Protecting public resources",
      "id": "protecting-public-resources"
    },
    {
      "level": "h3",
      "text": "Protecting private resources",
      "id": "protecting-private-resources"
    },
    {
      "level": "h3",
      "text": "Observability",
      "id": "observability"
    },
    {
      "level": "h2",
      "text": "Developer platform",
      "id": "developer-platform"
    },
    {
      "level": "h2",
      "text": "Summary",
      "id": "summary"
    },
    {
      "level": "h2",
      "text": "Introduction",
      "id": "introduction"
    },
    {
      "level": "h3",
      "text": "Who is this document for and what will you learn?",
      "id": "who-is-this-document-for-and-what-will-you-learn?"
    },
    {
      "level": "h2",
      "text": "Disintegration of the traditional network perimeter",
      "id": "disintegration-of-the-traditional-network-perimeter"
    },
    {
      "level": "h2",
      "text": "Understanding a SASE architecture",
      "id": "understanding-a-sase-architecture"
    },
    {
      "level": "h2",
      "text": "Cloudflare One: single-vendor, single-network SASE",
      "id": "cloudflare-one:-single-vendor,-single-network-sase"
    },
    {
      "level": "h3",
      "text": "Cloudflare's anycast network",
      "id": "cloudflare's-anycast-network"
    },
    {
      "level": "h2",
      "text": "Deploying a SASE architecture with Cloudflare",
      "id": "deploying-a-sase-architecture-with-cloudflare"
    },
    {
      "level": "h3",
      "text": "Connecting applications",
      "id": "connecting-applications"
    },
    {
      "level": "h3",
      "text": "Connecting networks",
      "id": "connecting-networks"
    },
    {
      "level": "h3",
      "text": "Forwarding device traffic",
      "id": "forwarding-device-traffic"
    },
    {
      "level": "h3",
      "text": "Verifying users and devices",
      "id": "verifying-users-and-devices"
    },
    {
      "level": "h2",
      "text": "Unified management",
      "id": "unified-management"
    },
    {
      "level": "h3",
      "text": "Lists",
      "id": "lists"
    },
    {
      "level": "h3",
      "text": "DLP profiles and datasets",
      "id": "dlp-profiles-and-datasets"
    },
    {
      "level": "h3",
      "text": "Access Groups",
      "id": "access-groups"
    },
    {
      "level": "h3",
      "text": "Example use cases",
      "id": "example-use-cases"
    },
    {
      "level": "h3",
      "text": "Visibility across the deployment",
      "id": "visibility-across-the-deployment"
    },
    {
      "level": "h2",
      "text": "Summary",
      "id": "summary"
    },
    {
      "level": "h2",
      "text": "Introduction",
      "id": "introduction"
    },
    {
      "level": "h3",
      "text": "Who is this document for and what will you learn?",
      "id": "who-is-this-document-for-and-what-will-you-learn?"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h3",
      "text": "Active domain in Cloudflare",
      "id": "active-domain-in-cloudflare"
    },
    {
      "level": "h3",
      "text": "Network route to applications",
      "id": "network-route-to-applications"
    },
    {
      "level": "h3",
      "text": "Identity",
      "id": "identity"
    },
    {
      "level": "h3",
      "text": "Device posture",
      "id": "device-posture"
    },
    {
      "level": "h2",
      "text": "Building policies",
      "id": "building-policies"
    },
    {
      "level": "h3",
      "text": "Access application types",
      "id": "access-application-types"
    },
    {
      "level": "h3",
      "text": "Authentication",
      "id": "authentication"
    },
    {
      "level": "h3",
      "text": "Policies",
      "id": "policies"
    },
    {
      "level": "h3",
      "text": "Access Groups",
      "id": "access-groups"
    },
    {
      "level": "h2",
      "text": "Use cases",
      "id": "use-cases"
    },
    {
      "level": "h3",
      "text": "Only allow company wiki access to users on trusted devices",
      "id": "only-allow-company-wiki-access-to-users-on-trusted-devices"
    },
    {
      "level": "h3",
      "text": "Secure access to Salesforce",
      "id": "secure-access-to-salesforce"
    },
    {
      "level": "h3",
      "text": "Only allow secure admins access to database tools",
      "id": "only-allow-secure-admins-access-to-database-tools"
    },
    {
      "level": "h3",
      "text": "Secure RDP access",
      "id": "secure-rdp-access"
    },
    {
      "level": "h2",
      "text": "Summary",
      "id": "summary"
    },
    {
      "level": "h2",
      "text": "Introduction",
      "id": "introduction"
    },
    {
      "level": "h2",
      "text": "Benefits",
      "id": "benefits"
    },
    {
      "level": "h2",
      "text": "Products included in this guide",
      "id": "products-included-in-this-guide"
    },
    {
      "level": "h2",
      "text": "Cloudflare for SaaS examples",
      "id": "cloudflare-for-saas-examples"
    },
    {
      "level": "h3",
      "text": "Standard fallback origin setup",
      "id": "standard-fallback-origin-setup"
    },
    {
      "level": "h3",
      "text": "Standard fallback origin setup with regional services",
      "id": "standard-fallback-origin-setup-with-regional-services"
    },
    {
      "level": "h3",
      "text": "Cloudflare Tunnel as fallback origin setup with regional services",
      "id": "cloudflare-tunnel-as-fallback-origin-setup-with-regional-services"
    },
    {
      "level": "h3",
      "text": "Global Traffic Management (GTM) & Private Network Load Balancing as custom origin setup",
      "id": "global-traffic-management-(gtm)-&-private-network-load-balancing-as-custom-origin-setup"
    },
    {
      "level": "h2",
      "text": "Automation",
      "id": "automation"
    },
    {
      "level": "h2",
      "text": "Summary",
      "id": "summary"
    },
    {
      "level": "h2",
      "text": "Introduction",
      "id": "introduction"
    },
    {
      "level": "h3",
      "text": "Who is this document for and what will you learn?",
      "id": "who-is-this-document-for-and-what-will-you-learn?"
    },
    {
      "level": "h2",
      "text": "Why Cloudflare for Platforms?",
      "id": "why-cloudflare-for-platforms?"
    },
    {
      "level": "h3",
      "text": "The SaaS model",
      "id": "the-saas-model"
    },
    {
      "level": "h3",
      "text": "Third party hostname challenges",
      "id": "third-party-hostname-challenges"
    },
    {
      "level": "h2",
      "text": "Issuing SSL certificates through Cloudflare for Platforms",
      "id": "issuing-ssl-certificates-through-cloudflare-for-platforms"
    },
    {
      "level": "h3",
      "text": "Manage certificates for any hostname on the Internet",
      "id": "manage-certificates-for-any-hostname-on-the-internet"
    },
    {
      "level": "h3",
      "text": "Secure and powerful validation modes",
      "id": "secure-and-powerful-validation-modes"
    }
  ],
  "url": "llms-txt#configuration---exported-from-the-prior-steps",
  "links": []
}