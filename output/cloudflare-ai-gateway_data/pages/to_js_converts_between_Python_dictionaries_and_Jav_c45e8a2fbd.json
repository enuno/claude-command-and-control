{
  "title": "to_js converts between Python dictionaries and JavaScript Objects",
  "content": "def to_js(obj):\n   return _to_js(obj, dict_converter=Object.fromEntries)\n  `\n\nFor more details, see out the [documentation on `pyodide.ffi.to_js`](https://pyodide.org/en/stable/usage/api/python-api/ffi.html#pyodide.ffi.to_js).\n\n## Using JavaScript globals from Python Workers\n\nWhen writing Workers in Python, you can access JavaScript globals by importing them from the `js` module. For example, note how `Response` is imported from `js` in the example below:\n\nRefer to the [Python examples](https://developers.cloudflare.com/workers/languages/python/examples/) to learn how to call into JavaScript functions from Python, including `console.log` and logging, providing options to `Response`, and parsing JSON.\n\n<page>\n---\ntitle: How Python Workers Work · Cloudflare Workers docs\ndescription: Workers written in Python are executed by Pyodide. Pyodide is a\n  port of CPython (the reference implementation of Python — commonly referred to\n  as just \"Python\") to WebAssembly.\nlastUpdated: 2025-11-11T15:40:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/languages/python/how-python-workers-work/\n  md: https://developers.cloudflare.com/workers/languages/python/how-python-workers-work/index.md\n---\n\nWorkers written in Python are executed by [Pyodide](https://pyodide.org/en/stable/index.html). Pyodide is a port of [CPython](https://github.com/python) (the reference implementation of Python — commonly referred to as just \"Python\") to WebAssembly.\n\nWhen you write a Python Worker, your code is interpreted directly by Pyodide, within a V8 isolate. Refer to [How Workers works](https://developers.cloudflare.com/workers/reference/how-workers-works/) to learn more.\n\nA basic Python Worker includes a Python file with a `Default` class extending `WorkerEntrypoint`, such as:\n\n...and a [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/) that points to this `.py` file:\n\nWhen you run `uv run pywrangler dev` to do local dev, the Workers runtime will:\n\n1. Determine which version of Pyodide is required, based on your compatibility date\n2. Install any packages necessary based on your `pyproject.toml` file\n3. Create a new v8 isolate for your Worker, and automatically inject Pyodide\n4. Serve your Python code using Pyodide\n\nThere are no extra toolchain or precompilation steps needed. The Python execution environment is provided directly by the Workers runtime, mirroring how Workers written in JavaScript work.\n\nRefer to the [Python examples](https://developers.cloudflare.com/workers/languages/python/examples/) to learn how to use Python within Workers.\n\n## Deployment Lifecycle and Cold Start Optimizations\n\nTo reduce cold start times, when you deploy a Python Worker, Cloudflare performs as much of the expensive work as possible upfront, at deploy time. When you run npx `uv run pywrangler deploy`, the following happens:\n\n1. Wrangler uploads your Python code and any packages included in your `pyproject.toml` to the Workers API.\n2. Cloudflare sends your Python code to the Workers runtime to be validated.\n3. Cloudflare creates a new v8 isolate for your Worker, automatically injecting Pyodide.\n4. Cloudflare scans the Worker’s code for import statements, execute them, and then take a snapshot of the Worker’s WebAssembly linear memory. Effectively, we perform the expensive work of importing packages at deploy time, rather than at runtime.\n5. Cloudflare deploys this snapshot alongside your Worker’s Python code to the Cloudflare network.\n\nWhen a request comes in to your Worker, we load this snapshot and use it to bootstrap your Worker in an isolate, avoiding expensive initialization time:\n\n![Diagram of how Python Workers are deployed to Cloudflare](https://developers.cloudflare.com/_astro/python-workers-deployment.B83dgcK7_vs24A.webp)\n\nRefer to the [blog post introducing Python Workers](https://blog.cloudflare.com/python-workers) for more detail about performance optimizations and how the Workers runtime will reduce cold starts for Python Workers.\n\n## Pyodide and Python versions\n\nA new version of Python is released every year in August, and a new version of Pyodide is released six (6) months later. When this new version of Pyodide is published, we will add it to Workers by gating it behind a Compatibility Flag, which is only enabled after a specified Compatibility Date. This lets us continually provide updates, without risk of breaking changes, extending the commitment we’ve made for JavaScript to Python.\n\nEach Python release has a [five (5) year support window](https://devguide.python.org/versions/). Once this support window has passed for a given version of Python, security patches are no longer applied, making this version unsafe to rely on. To mitigate this risk, while still trying to hold as true as possible to our commitment of stability and long-term support, after five years any Python Worker still on a Python release that is outside of the support window will be automatically moved forward to the next oldest Python release. Python is a mature and stable language, so we expect that in most cases, your Python Worker will continue running without issue. But we recommend updating the compatibility date of your Worker regularly, to stay within the support window.\n\n<page>\n---\ntitle: Python packages supported in Cloudflare Workers · Cloudflare Workers docs\ndescription: >-\n  Pywrangler is a CLI tool for managing packages and Python Workers.\n\nIt is meant as a wrapper for wrangler that sets up a full environment for you,\n  including bundling your packages into\n\nyour worker bundle on deployment.\nlastUpdated: 2025-11-11T15:40:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/languages/python/packages/\n  md: https://developers.cloudflare.com/workers/languages/python/packages/index.md\n---\n\n[Pywrangler](https://github.com/cloudflare/workers-py?tab=readme-ov-file#pywrangler) is a CLI tool for managing packages and Python Workers. It is meant as a wrapper for wrangler that sets up a full environment for you, including bundling your packages into your worker bundle on deployment.\n\nTo get started, create a pyproject.toml file with the following contents:\n\nThe above will allow your worker to depend on the [FastAPI](https://fastapi.tiangolo.com/) package.\n\nTo run the worker locally:\n\nTo deploy your worker:\n\nYour dependencies will get bundled with your worker automatically on deployment.\n\nThe `pywrangler` CLI also supports all commands supported by the `wrangler` tool, for the full list of commands run `uv run pywrangler --help`.\n\n## Supported Libraries\n\nPython Workers support pure Python packages on [PyPI](https://pypi.org/), as well as [packages that are included in Pyodide](https://pyodide.org/en/stable/usage/packages-in-pyodide.html).\n\nIf you would like to use a package that is not pure Python and not yet supported in Pyodide, request support via the [Python Packages Discussions](https://github.com/cloudflare/workerd/discussions/categories/python-packages) on the Cloudflare Workers Runtime GitHub repository.\n\n## HTTP Client Libraries\n\nOnly HTTP libraries that are able to make requests asynchronously are supported. Currently, these include [`aiohttp`](https://docs.aiohttp.org/en/stable/index.html) and [`httpx`](https://www.python-httpx.org/). You can also use the [`fetch()` API](https://developers.cloudflare.com/workers/runtime-apis/fetch/) from JavaScript, using Python Workers' [foreign function interface](https://developers.cloudflare.com/workers/languages/python/ffi) to make HTTP requests.\n\n<page>\n---\ntitle: Standard Library provided to Python Workers · Cloudflare Workers docs\ndescription: Workers written in Python are executed by Pyodide.\nlastUpdated: 2025-11-11T15:40:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/languages/python/stdlib/\n  md: https://developers.cloudflare.com/workers/languages/python/stdlib/index.md\n---\n\nWorkers written in Python are executed by [Pyodide](https://pyodide.org/en/stable/index.html).\n\nPyodide is a port of CPython to WebAssembly — for the most part it behaves identically to [CPython](https://github.com/python) (the reference implementation of Python — commonly referred to as just \"Python\"). The majority of the CPython test suite passes when run against Pyodide. For the most part, you shouldn't need to worry about differences in behavior.\n\nThe full [Python Standard Library](https://docs.python.org/3/library/index.html) is available in Python Workers, with the following exceptions:\n\n## Modules with limited functionality\n\n* `decimal`: The decimal module has C (\\_decimal) and Python (\\_pydecimal) implementations with the same functionality. Only the C implementation is available (compiled to WebAssembly)\n* `pydoc`: Help messages for Python builtins are not available\n* `webbrowser`: The original webbrowser module is not available.\n\nThe following modules are not available in Python Workers:\n\n* curses\n* dbm\n* ensurepip\n* fcntl\n* grp\n* idlelib\n* lib2to3\n* msvcrt\n* pwd\n* resource\n* syslog\n* termios\n* tkinter\n* turtle.py\n* turtledemo\n* venv\n* winreg\n* winsound\n\nThe following modules can be imported, but are not functional due to the limitations of the WebAssembly VM.\n\n* multiprocessing\n* threading\n* sockets\n\nThe following are present but cannot be imported due to a dependency on the termios package which has been removed:\n\n<page>\n---\ntitle: Supported crates · Cloudflare Workers docs\ndescription: >-\n  Learn about popular Rust crates which have been confirmed to work on Workers\n  when using workers-rs (or in some cases just wasm-bindgen), to write Workers\n  in WebAssembly.\n\nEach Rust crate example includes any custom configuration that is required.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/languages/rust/crates/\n  md: https://developers.cloudflare.com/workers/languages/rust/crates/index.md\n---\n\nLearn about popular Rust crates which have been confirmed to work on Workers when using [`workers-rs`](https://github.com/cloudflare/workers-rs) (or in some cases just `wasm-bindgen`), to write Workers in WebAssembly. Each Rust crate example includes any custom configuration that is required.\n\nThis is not an exhaustive list, many Rust crates can be compiled to the [`wasm32-unknown-unknown`](https://doc.rust-lang.org/rustc/platform-support/wasm64-unknown-unknown.html) target that is supported by Workers. In some cases, this may require disabling default features or enabling a Wasm-specific feature. It is important to consider the addition of new dependencies, as this can significantly increase the [size](https://developers.cloudflare.com/workers/platform/limits/#worker-size) of your Worker.\n\nMany crates which have been made Wasm-friendly, will use the `time` crate instead of `std::time`. For the `time` crate to work in Wasm, the `wasm-bindgen` feature must be enabled to obtain timing information from JavaScript.\n\nTracing can be enabled by using the `tracing-web` crate and the `time` feature for `tracing-subscriber`. Due to [timing limitations](https://developers.cloudflare.com/workers/reference/security-model/#step-1-disallow-timers-and-multi-threading) on Workers, spans will have identical start and end times unless they encompass I/O.\n\n[Refer to the `tracing` example](https://github.com/cloudflare/workers-rs/tree/main/examples/tracing) for more information.\n\nThe [`reqwest` library](https://docs.rs/reqwest/latest/reqwest/) can be compiled to Wasm, and hooks into the JavaScript `fetch` API automatically using `wasm-bindgen`.\n\n`tokio-postgres` can be compiled to Wasm. It must be configured to use a `Socket` from `workers-rs`:\n\n[Refer to the `tokio-postgres` example](https://github.com/cloudflare/workers-rs/tree/main/examples/tokio-postgres) for more information.\n\nThe `hyper` crate contains two HTTP clients, the lower-level `conn` module and the higher-level `Client`. The `conn` module can be used with Workers `Socket`, however `Client` requires timing dependencies which are not yet Wasm friendly.\n\n[Refer to the `hyper` example](https://github.com/cloudflare/workers-rs/tree/main/examples/hyper) for more information.\n\n<page>\n---\ntitle: Examples · Cloudflare Workers docs\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/languages/typescript/examples/\n  md: https://developers.cloudflare.com/workers/languages/typescript/examples/index.md\n---\n\n<page>\n---\ntitle: Breakpoints · Cloudflare Workers docs\ndescription: Debug your local and deployed Workers using breakpoints.\nlastUpdated: 2025-07-14T17:19:03.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/observability/dev-tools/breakpoints/\n  md: https://developers.cloudflare.com/workers/observability/dev-tools/breakpoints/index.md\n---\n\n## Debug via breakpoints\n\nWhen developing a Worker locally using Wrangler or Vite, you can debug via breakpoints in your Worker. Breakpoints provide the ability to review what is happening at a given point in the execution of your Worker. Breakpoint functionality exists in both DevTools and VS Code.\n\nFor more information on breakpoint debugging via Chrome's DevTools, refer to [Chrome's article on breakpoints](https://developer.chrome.com/docs/devtools/javascript/breakpoints/).\n\n### VSCode debug terminals\n\nUsing VSCode's built-in [JavaScript Debug Terminals](https://code.visualstudio.com/docs/nodejs/nodejs-debugging#_javascript-debug-terminal), all you have to do is open a JS debug terminal (`Cmd + Shift + P` and then type `javascript debug`) and run `wrangler dev` (or `vite dev`) from within the debug terminal. VSCode will automatically connect to your running Worker (even if you're running multiple Workers at once!) and start a debugging session.\n\n### Setup VS Code to use breakpoints with `launch.json` files\n\nTo setup VS Code for breakpoint debugging in your Worker project:\n\n1. Create a `.vscode` folder in your project's root folder if one does not exist.\n2. Within that folder, create a `launch.json` file with the following content:\n\n1. Open your project in VS Code, open a new terminal window from VS Code, and run `npx wrangler dev` to start the local dev server.\n\n2. At the top of the **Run & Debug** panel, you should see an option to select a configuration. Choose **Wrangler**, and select the play icon. **Wrangler: Remote Process \\[0]** should show up in the Call Stack panel on the left.\n\n3. Go back to a `.js` or `.ts` file in your project and add at least one breakpoint.\n\n4. Open your browser and go to the Worker's local URL (default `http://127.0.0.1:8787`). The breakpoint should be hit, and you should be able to review details about your code at the specified line.\n\nBreakpoint debugging in `wrangler dev` using `--remote` could extend Worker CPU time and incur additional costs since you are testing against actual resources that count against usage limits. It is recommended to use `wrangler dev` without the `--remote` option. This ensures you are developing locally.\n\nIf you are debugging using `--remote`, you cannot use code minification as the debugger will be unable to find vars when stopped at a breakpoint. Do not set minify to `true` in your Wrangler configuration file.\n\nThe `.vscode/launch.json` file only applies to a single workspace. If you prefer, you can add the above launch configuration to your User Settings (per the [official VS Code documentation](https://code.visualstudio.com/docs/editor/debugging#_global-launch-configuration)) to have it available for all your workspaces.\n\n* [Local Development](https://developers.cloudflare.com/workers/development-testing/) - Develop your Workers and connected resources locally via Wrangler and [`workerd`](https://github.com/cloudflare/workerd), for a fast, accurate feedback loop.\n\n<page>\n---\ntitle: Profiling CPU usage · Cloudflare Workers docs\ndescription: Learn how to profile CPU usage and ensure CPU-time per request\n  stays under Workers limits\nlastUpdated: 2025-09-18T22:01:54.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/observability/dev-tools/cpu-usage/\n  md: https://developers.cloudflare.com/workers/observability/dev-tools/cpu-usage/index.md\n---\n\nIf a Worker spends too much time performing CPU-intensive tasks, responses may be slow or the Worker might fail to startup due to [time limits](https://developers.cloudflare.com/workers/platform/limits/#worker-startup-time).\n\nProfiling in DevTools can help you identify and fix code that uses too much CPU.\n\nMeasuring execution time of specific functions in production can be difficult because Workers [only increment timers on I/O](https://developers.cloudflare.com/workers/reference/security-model/#step-1-disallow-timers-and-multi-threading) for security purposes. However, measuring CPU execution times is possible in local development with DevTools.\n\nWhen using DevTools to monitor CPU usage, it may be difficult to replicate specific behavior you are seeing in production. To mimic production behavior, make sure the requests you send to the local Worker are similar to requests in production. This might mean sending a large volume of requests, making requests to specific routes, or using production-like data via [remote bindings](https://developers.cloudflare.com/workers/development-testing/#remote-bindings).\n\nTo generate a CPU profile:\n\n* Run `wrangler dev` to start your Worker\n* Press the `D` key from your terminal to open DevTools\n* Select the \"Profiler\" tab\n* Select `Start` to begin recording CPU usage\n* Send requests to your Worker from a new tab\n* Select `Stop`\n\nYou now have a CPU profile.\n\nFor Rust Workers, add the following to your `Cargo.toml` to preserve [DWARF](https://dwarfstd.org/) debug symbols (from [this comment](https://github.com/rustwasm/wasm-pack/issues/1351#issuecomment-2100231587)):\n\nThen, update your `wrangler.toml` to configure wasm-pack (via worker-build) to use the `dev` [profile](https://rustwasm.github.io/docs/wasm-pack/commands/build.html#profile) to preserve debug symbols.\n\n## An Example Profile\n\nLet's look at an example to learn how to read a CPU profile. Imagine you have the following Worker:\n\nYou want to find which part of the code causes slow response times. How do you use DevTool profiling to identify the CPU-heavy code and fix the issue?\n\nFirst, as mentioned above, you open DevTools by pressing the `D` key after running `wrangler dev`. Then, you navigate to the \"Profiler\" tab and take a profile by pressing `Start` and sending a request.\n\n![CPU Profile](https://developers.cloudflare.com/_astro/profile.Dz8PUp_K_Z13cVAd.webp)\n\nThe top chart in this image shows a timeline of the profile, and you can use it to zoom in on a specific request.\n\nThe chart below shows the CPU time used for operations run during the request. In this screenshot, you can see \"fetch\" time at the top and the subscomponents of fetch beneath, including the two functions `addNumbers` and `moreAdditions`. By hovering over each box, you get more information, and by clicking the box, you navigate to the function's source code.\n\nUsing this graph, you can answer the question of \"what is taking CPU time?\". The `addNumbers` function has a very small box, representing 0.3ms of CPU time. The `moreAdditions` box is larger, representing 2.2ms of CPU time.\n\nTherefore, if you want to make response times faster, you need to optimize `moreAdditions`.\n\nYou can also change the visualization from ‘Chart’ to ‘Heavy (Bottom Up)’ for an alternative view.\n\n![CPU Profile](https://developers.cloudflare.com/_astro/heavy.17oO4-BN_ZAiwmI.webp)\n\nThis shows the relative times allocated to each function. At the top of the list, `moreAdditions` is clearly the slowest portion of your Worker. You can see that garbage collection also represents a large percentage of time, so memory optimization could be useful.\n\n## Additional Resources\n\nTo learn more about how to use the CPU profiler, see [Google's documentation on Profiling the CPU in DevTools](https://developer.chrome.com/docs/devtools/performance/nodejs#profile).\n\nTo learn how to use DevTools to gain insight into memory, see the [Memory Usage Documentation](https://developers.cloudflare.com/workers/observability/dev-tools/memory-usage/).\n\n<page>\n---\ntitle: Export to Axiom · Cloudflare Workers docs\ndescription: \"Axiom is a serverless log analytics platform that helps you store,\n  search, and analyze massive amounts of data. By exporting your Cloudflare\n  Workers application telemetry to Axiom, you can:\"\nlastUpdated: 2025-10-28T12:06:21.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/observability/exporting-opentelemetry-data/axiom/\n  md: https://developers.cloudflare.com/workers/observability/exporting-opentelemetry-data/axiom/index.md\n---\n\nAxiom is a serverless log analytics platform that helps you store, search, and analyze massive amounts of data. By exporting your Cloudflare Workers application telemetry to Axiom, you can:\n\n* Store and query logs and traces at scale\n* Create dashboards and alerts to monitor your Workers\n\n![Trace view with timing information displayed on a timeline](https://developers.cloudflare.com/_astro/axiom-example.BRPbEoGh_2rUf3j.webp)\n\nThis guide will walk you through exporting OpenTelemetry-compliant traces and logs to Axiom from your Cloudflare Worker application\n\nBefore you begin, ensure you have:\n\n* An active [Axiom account](https://app.axiom.co/register) (free tier available)\n* A deployed Worker that you want to monitor\n* An Axiom dataset to send data to\n\n## Step 1: Create a dataset\n\nIf you don't already have a dataset to send data to:\n\n1. Log in to your [Axiom account](https://app.axiom.co/)\n2. Navigate to **Datasets** in the left sidebar\n3. Click **New Dataset**\n4. Enter a name (e.g. `cloudflare-workers-otel`)\n5. Click **Create Dataset**\n\n## Step 2: Get your Axiom API token and dataset\n\n1. Navigate to **Settings** in the left sidebar\n\n2. Click on **API Tokens**\n\n3. Click **Create API Token**\n\n4. Configure your API token:\n\n* **Name**: Enter a descriptive name (e.g., `cloudflare-workers-otel`)\n   * **Permissions**: Select **Ingest** permission (required for sending telemetry data)\n   * **Datasets**: Choose which datasets this token can write to, or select **All Datasets**\n\n6. **Important**: Copy the API token immediately and store it securely - you won't be able to see it again\n\nThe API token will look something like: `xaat-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx`\n\n## Step 3: Configure Cloudflare destinations\n\nNow you'll create destinations in the Cloudflare dashboard that point to Axiom.\n\n### Axiom OTLP endpoints\n\nAxiom provides separate OTLP endpoints for traces and logs:\n\n* **Traces**: `https://api.axiom.co/v1/traces`\n* **Logs**: `https://api.axiom.co/v1/logs`\n\n### Configure trace or logs destination\n\n1. Navigate to your Cloudflare account's [Workers Observability](https://dash.cloudflare.com/?to=/:account/workers-and-pages/observability/pipelines) section\n\n2. Click **Add destination**\n\n3. Configure your trace destination:\n\n* **Destination Name**: `axiom-traces` (or any descriptive name)\n\n* **Destination Type**: Select **Traces**\n\n* **OTLP Endpoint**: `https://api.axiom.co/v1/traces` (or `/v1/logs`)\n\n* **Custom Headers**: Add two required headers:\n\n* Authentication header\n\n* Header name: `Authorization`\n       * Header value: `Bearer <your-api-token>`\n\n* Header name: `X-Axiom-Dataset`\n       * Header value: Your dataset name (e.g., `cloudflare-workers-otel`)\n\n## Step 3: Configure your Worker\n\nWith your destinations created in the Cloudflare dashboard, update your Worker's configuration to enable telemetry export.\n\nAfter updating your configuration, deploy your Worker for the changes to take effect.\n\nIt may take a few minutes after deployment for data to appear in Axiom.\n\n<page>\n---\ntitle: Profiling Memory · Cloudflare Workers docs\ndescription: >-\n  Understanding Worker memory usage can help you optimize performance, avoid Out\n  of Memory (OOM) errors\n\nwhen hitting Worker memory limits, and fix memory leaks.\nlastUpdated: 2025-06-18T17:02:32.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/observability/dev-tools/memory-usage/\n  md: https://developers.cloudflare.com/workers/observability/dev-tools/memory-usage/index.md\n---\n\nUnderstanding Worker memory usage can help you optimize performance, avoid Out of Memory (OOM) errors when hitting [Worker memory limits](https://developers.cloudflare.com/workers/platform/limits/#memory), and fix memory leaks.\n\nYou can profile memory usage with snapshots in DevTools. Memory snapshots let you view a summary of memory usage, see how much memory is allocated to different data types, and get details on specific objects in memory.\n\nWhen using DevTools to profile memory, it may be difficult to replicate specific behavior you are seeing in production. To mimic production behavior, make sure the requests you send to the local Worker are similar to requests in production. This might mean sending a large volume of requests, making requests to specific routes, or using production-like data with the [--remote flag](https://developers.cloudflare.com/workers/development-testing/#remote-bindings).\n\nTo generate a memory snapshot:\n\n* Run `wrangler dev` to start your Worker\n* Press the `D` from your terminal to open DevTools\n* Select on the \"Memory\" tab\n* Send requests to your Worker to start allocating memory\n  * Optionally include a debugger to make sure you can pause execution at the proper time\n* Select `Take snapshot`\n\nYou can now inspect Worker memory.\n\n## An Example Snapshot\n\nLet's look at an example to learn how to read a memory snapshot. Imagine you have the following Worker:\n\nWhile this code worked well initially, over time you notice slower responses and Out of Memory errors. Using DevTools, you can find out if this is a memory leak.\n\nFirst, as mentioned above, you open DevTools by pressing the `D` key after running `wrangler dev`. Then, you navigate to the \"Memory\" tab.\n\nNext, generate a large volume of traffic to the Worker by sending requests. You can do this with `curl` or by repeatedly reloading the browser. Note that other Workers may require more specific requests to reproduce a memory leak.\n\nThen, click the \"Take Snapshot\" button and view the results.\n\nFirst, navigate to \"Statistics\" in the dropdown to get a general sense of what takes up memory.\n\n![Memory Statistics](https://developers.cloudflare.com/_astro/memory-stats.BkZs-j29_ZMXg51.webp)\n\nLooking at these statistics, you can see that a lot of memory is dedicated to strings at 67 kB. This is likely the source of the memory leak. If you make more requests and take another snapshot, you would see this number grow.\n\n![Memory Summary](https://developers.cloudflare.com/_astro/memory-summary.CPf4-TMr_gcOCJ.webp)\n\nThe memory summary lists data types by the amount of memory they take up. When you click into \"(string)\", you can see a string that is far larger than the rest. The text shows that you are appending \"Requested at\" and a date repeatedly, inadvertently overwriting the global variable with an increasingly large string:\n\nUsing Memory Snapshotting in DevTools, you've identified the object and line of code causing the memory leak. You can now fix it with a small code change.\n\n## Additional Resources\n\nTo learn more about how to use Memory Snapshotting, see [Google's documentation on Memory Heap Snapshots](https://developer.chrome.com/docs/devtools/memory-problems/heap-snapshots).\n\nTo learn how to use DevTools to gain insight into CPU usage, see the [CPU Profiling Documentation](https://developers.cloudflare.com/workers/observability/dev-tools/cpu-usage/).\n\n<page>\n---\ntitle: Export to Grafana Cloud · Cloudflare Workers docs\ndescription: \"Grafana Cloud is a fully managed observability platform that\n  provides visualization, alerting, and analytics for your telemetry data. By\n  exporting your Cloudflare Workers telemetry to Grafana Cloud, you can:\"\nlastUpdated: 2025-10-28T12:06:21.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/observability/exporting-opentelemetry-data/grafana-cloud/\n  md: https://developers.cloudflare.com/workers/observability/exporting-opentelemetry-data/grafana-cloud/index.md\n---\n\nGrafana Cloud is a fully managed observability platform that provides visualization, alerting, and analytics for your telemetry data. By exporting your Cloudflare Workers telemetry to Grafana Cloud, you can:\n\n* Visualize distributed traces in **Grafana Tempo** to understand request flows and performance bottlenecks\n* Query and analyze logs in **Grafana Loki** alongside your traces\n\nThis guide will walk you through configuring Cloudflare Workers to export OpenTelemetry-compliant traces and logs to your Grafana Cloud stack.\n\n![Grafana Tempo trace view showing a distributed trace for a service with multiple spans including fetch requests, durable object subrequests, and queue operations, with timing information displayed on a timeline](https://developers.cloudflare.com/_astro/grafana-traces.CuFntNVO_Z1L4LWv.webp)\n\nBefore you begin, ensure you have:\n\n* An active [Grafana Cloud account](https://grafana.com/auth/sign-up/create-user) (free tier available)\n* A deployed Worker that you want to monitor\n\n## Step 1: Access the OpenTelemetry setup guide\n\n1. Log in to your [Grafana Cloud portal](https://grafana.com/)\n2. From your organization's home page, navigate to **Connections** → **Add new connection**\n3. Search for \"OpenTelemetry\" and select **OpenTelemetry (OTLP)**\n4. Select **Quickstart** then select **JavaScript**\n5. Click **Create a new token**\n6. Enter a name for your token (e.g., `cloudflare-workers-otel`) and click **create token**\n7. Click on **Close** without copying the token\n8. Copy and Save the value for `OTEL_EXPORTER_OTLP_ENDPOINT` and `OTEL_EXPORTER_OTLP_HEADERS` in the `Environment variables` code block as the OTel endpoint and as the Auth header value respectively\n\n## Step 2: Set up destination\n\n1. Navigate to your Cloudflare account's [Workers Observability](https://dash.cloudflare.com/?to=/:account/workers-and-pages/observability/pipelines) section\n2. Click **Add destination** and configure a destination name (e.g. `grafana-tracing`)\n3. From Grafana, copy your Otel endpoint, auth header, and auth value\n\n* Your OTEL endpoint will look like `https://otlp-gateway-prod-us-east-2.grafana.net/otlp` (append `/v1/traces` for traces and `/v1/logs` for logs)\n\n* Your custom header should include:\n\n* Your auth header name `Authorization`\n  * Your auth header value `Basic MTMxxx...`\n\n## Step 3: Configure your Worker\n\nWith your destination created in the Cloudflare dashboard, update your Worker's configuration to enable telemetry export.\n\nAfter updating your configuration, deploy your Worker for the changes to take effect.\n\nIt may take a few minutes after deployment for data to appear in Grafana Cloud.\n\n<page>\n---\ntitle: Export to Honeycomb · Cloudflare Workers docs\ndescription: \"Honeycomb is an observability platform built for high-cardinality\n  data that helps you understand and debug your applications. By exporting your\n  Cloudflare Workers application telemetry to Honeycomb, you can:\"\nlastUpdated: 2025-10-28T12:06:21.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/observability/exporting-opentelemetry-data/honeycomb/\n  md: https://developers.cloudflare.com/workers/observability/exporting-opentelemetry-data/honeycomb/index.md\n---\n\nHoneycomb is an observability platform built for high-cardinality data that helps you understand and debug your applications. By exporting your Cloudflare Workers application telemetry to Honeycomb, you can:\n\n* Visualize traces to understand request flows and identify performance bottlenecks\n* Query and analyze logs with unlimited dimensionality across any attribute\n* Create custom queries and dashboards to monitor your Workers\n\n![Trace view including POST request, fetch operations, durable object subrequest, and queue send, with timing information displayed on a timeline](https://developers.cloudflare.com/_astro/honeycomb-example.cEkEF1c4_aoHac.webp)\n\nThis guide will walk you through configuring your Cloudflare Worker application to export OpenTelemetry-compliant traces and logs to Honeycomb.\n\nBefore you begin, ensure you have:\n\n* An active [Honeycomb account](https://ui.honeycomb.io/signup) (free tier available)\n* A deployed Worker that you want to monitor\n\n## Step 1: Get your Honeycomb API key\n\n1. Log in to your [Honeycomb account](https://ui.honeycomb.io/)\n\n2. Navigate to your account settings by clicking on your profile icon in the top right\n\n3. Select **Team Settings**\n\n4. In the left sidebar, click **Environments** and click the gear icon\n\n5. Find your environment (e.g., `production`, `test`) or create a new one\n\n6. Under **API Keys**, click **Create Ingest API Key**\n\n7. Configure your API key:\n\n* **Name**: Enter a descriptive name (e.g., `cloudflare-workers-otel`)\n   * **Permissions**: Select **Can create services/datasets** (required for OTLP ingestion)\n\n9. **Important**: Copy the API key immediately and store it securely - you won't be able to see it again\n\nThe API key will look something like: `hcaik_01hq...`\n\n## Step 2: Configure Cloudflare destinations\n\nNow you'll create destinations in the Cloudflare dashboard that point to Honeycomb.\n\n### Honeycomb OTLP endpoints\n\nHoneycomb provides separate OTLP endpoints for traces and logs:\n\n* **Traces**: `https://api.honeycomb.io/v1/traces`\n* **Logs**: `https://api.honeycomb.io/v1/logs`\n\n### Configure trace destination\n\n1. Navigate to your Cloudflare account's [Workers Observability](https://dash.cloudflare.com/?to=/:account/workers-and-pages/observability/pipelines) section\n\n2. Click **Add destination**\n\n3. Configure your trace destination:\n\n* **Destination Name**: `honeycomb-traces` (or any descriptive name)\n\n* **Destination Type**: Select **Traces**\n\n* **OTLP Endpoint**: `https://api.honeycomb.io/v1/traces`\n\n* **Custom Headers**: Add the authentication header:\n\n* Header name: `x-honeycomb-team`\n     * Header value: Your Honeycomb API key (e.g., `hcaik_01hq...`)\n\n### Configure logs destination\n\nRepeat the process for logs:\n\n1. Click **Add destination** again\n\n2. Configure your logs destination:\n\n* **Destination Name**: `honeycomb-logs` (or any descriptive name)\n\n* **Destination Type**: Select **Logs**\n\n* **OTLP Endpoint**: `https://api.honeycomb.io/v1/logs`\n\n* **Custom Headers**: Add the authentication header:\n\n* Header name: `x-honeycomb-team`\n     * Header value: Your Honeycomb API key (same as above)\n\n## Step 3: Configure your Worker\n\nWith your destinations created in the Cloudflare dashboard, update your Worker's configuration to enable telemetry export.\n\nAfter updating your configuration, deploy your Worker for the changes to take effect.\n\nIt may take a few minutes after deployment for data to appear in Honeycomb.\n\n<page>\n---\ntitle: Workers Logpush · Cloudflare Workers docs\ndescription: Send Workers Trace Event Logs to a supported third party, such as a\n  storage or logging provider.\nlastUpdated: 2025-09-08T17:05:16.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/observability/logs/logpush/\n  md: https://developers.cloudflare.com/workers/observability/logs/logpush/index.md\n---\n\n[Cloudflare Logpush](https://developers.cloudflare.com/logs/logpush/) supports the ability to send [Workers Trace Event Logs](https://developers.cloudflare.com/logs/logpush/logpush-job/datasets/account/workers_trace_events/) to a [supported destination](https://developers.cloudflare.com/logs/logpush/logpush-job/enable-destinations/). Worker’s Trace Events Logpush includes metadata about requests and responses, unstructured `console.log()` messages and any uncaught exceptions. This product is available on the Workers Paid plan. For pricing information, refer to [Pricing](https://developers.cloudflare.com/workers/platform/pricing/#workers-trace-events-logpush).\n\nWorkers Trace Events Logpush is not available for zones on the [Cloudflare China Network](https://developers.cloudflare.com/china-network/).\n\n## Verify your Logpush access\n\nMinimum required Wrangler version: 2.2.0. Check your version by running `wrangler --version`. To update Wrangler, refer to [Install/Update Wrangler](https://developers.cloudflare.com/workers/wrangler/install-and-update/).\n\nTo configure a Logpush job, verify that your Cloudflare account role can use Logpush. To check your role:\n\n1. In the Cloudflare dashboard, go to the **Members** page.\n\n[Go to **Members**](https://dash.cloudflare.com/?to=/:account/members)\n\n2. Check your account permissions. Roles with Logpush configuration access are different than Workers permissions. Super Administrators, Administrators, and the Log Share roles have full access to Logpush.\n\nAlternatively, create a new [API token](https://developers.cloudflare.com/fundamentals/api/get-started/create-token/) scoped at the Account level with Logs Edit permissions.\n\n## Create a Logpush job\n\n### Via the Cloudflare dashboard\n\nTo create a Logpush job in the Cloudflare dashboard:\n\n1. In the Cloudflare dashboard, go to the **Logpush** page.\n\n[Go to **Logpush**](https://dash.cloudflare.com/?to=/:account/logs)\n\n2. Select **Create a Logpush job**.\n\n3. Select **Workers trace events** as the data set > **Next**.\n\n4. If needed, customize your data fields. Otherwise, select **Next**.\n\n5. Follow the instructions on the dashboard to verify ownership of your data's destination and complete job creation.\n\nThe following example sends Workers logs to R2. For more configuration options, refer to [Enable destinations](https://developers.cloudflare.com/logs/logpush/logpush-job/enable-destinations/) and [API configuration](https://developers.cloudflare.com/logs/logpush/logpush-job/api-configuration/) in the Logs documentation.\n\nIn Logpush, you can configure [filters](https://developers.cloudflare.com/logs/logpush/logpush-job/filters/) and a [sampling rate](https://developers.cloudflare.com/logs/logpush/logpush-job/api-configuration/#sampling-rate) to have more control of the volume of data that is sent to your configured destination. For example, if you only want to receive logs for requests that did not result in an exception, add the following `filter` JSON property below `output_options`:\n\n`\"filter\":\"{\\\"where\\\": {\\\"key\\\":\\\"Outcome\\\",\\\"operator\\\":\\\"!eq\\\",\\\"value\\\":\\\"exception\\\"}}\"`\n\n## Enable logging on your Worker\n\n### Local development\n\nEnable logging on your Worker by adding a new property, `logpush = true`, to your Wrangler file. This can be added either in the top-level configuration or under an [environment](https://developers.cloudflare.com/workers/wrangler/environments/). Any new Workers with this property will automatically get picked up by the Logpush job.\n\nConfigure via multipart script upload API:\n\nTo enable Logpush logging via the dashboard:\n\n1. In the Cloudflare dashboard, go to the **Workers & Pages** page.\n\n[Go to **Workers & Pages**](https://dash.cloudflare.com/?to=/:account/workers-and-pages)\n\n2. Select your Worker.\n\n3. Go to **Settings** > **Observability**.\n\n4. For **Logpush**, select **Enable** (this is only available if you have already [created a logpush job](https://developers.cloudflare.com/workers/observability/logs/logpush/#create-a-logpush-job)).\n\nThe `logs` and `exceptions` fields have a combined limit of 16,384 characters before fields will start being truncated. Characters are counted in the order of all `exception.name`s, `exception.message`s, and then `log.message`s.\n\nOnce that character limit is reached all fields will be truncated with `\"<<<Logpush: *field* truncated>>>\"` for one message before dropping logs or exceptions.\n\nTo illustrate this, suppose our Logpush event looks like the JSON below and the limit is 50 characters (rather than the actual limit of 16,384). The algorithm will:\n\n1. Count the characters in `exception.names`:\n   1. `\"SampleError\"` and `\"AuthError\"` as 20 characters.\n\n2. Count the characters in `exception.message`:\n\n1. `\"something went wrong\"` counted as 20 characters leaving 10 characters remaining.\n   2. The first 10 characters of `\"unable to process request authentication from client\"` will be taken and counted before being truncated to `\"unable to <<<Logpush: exception messages truncated>>>\"`.\n\n3. Count the characters in `log.message`:\n   1. We've already begun truncation, so `\"Hello \"` will be replaced with `\"<<<Logpush: messages truncated>>>\"` and `\"World!\"` will be dropped.\n\n<page>\n---\ntitle: Export to Sentry · Cloudflare Workers docs\ndescription: \"Sentry is a software monitoring tool that helps developers\n  identify and debug performance issues and errors. From end-to-end distributed\n  tracing to performance monitoring, Sentry provides code-level observability\n  that makes it easy to diagnose issues and learn continuously about your\n  application code health across systems and services. By exporting your\n  Cloudflare Workers application telemetry to Sentry, you can:\"\nlastUpdated: 2025-10-28T12:06:21.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/observability/exporting-opentelemetry-data/sentry/\n  md: https://developers.cloudflare.com/workers/observability/exporting-opentelemetry-data/sentry/index.md\n---\n\nSentry is a software monitoring tool that helps developers identify and debug performance issues and errors. From end-to-end distributed tracing to performance monitoring, Sentry provides code-level observability that makes it easy to diagnose issues and learn continuously about your application code health across systems and services. By exporting your Cloudflare Workers application telemetry to Sentry, you can:\n\n* Query logs and traces in Sentry\n* Create custom alerts and dashboards to monitor your Workers\n\n![Sentry trace view with timing information displayed on a timeline](https://developers.cloudflare.com/_astro/sentry-example.DU-HO2rh_Z1HuYQp.webp)\n\nThis guide will walk you through exporting OpenTelemetry-compliant traces and logs to Sentry from your Cloudflare Worker application\n\nBefore you begin, ensure you have:\n\n* Are signed up for a [Sentry account](https://sentry.io/signup/) (free tier available)\n* A deployed Worker that you want to monitor\n\n## Step 1: Create a Sentry project\n\nIf you don't already have a Sentry project to send data to, you'll need to create one to start sending Cloudflare Workers application telemetry to Sentry.\n\n1. Log in to your [Sentry account](https://sentry.io/)\n2. Navigate to the Insights > Projects in the navigation sidebar, which will open a list of your projects.\n3. Click [**New Project**](https://sentry.io/orgredirect/organizations/:orgslug/insights/projects/new/)\n4. Fill out the project creation form and click **Create Project** to complete the process.\n\n## Step 2: Get your Sentry OTLP endpoints\n\nSentry provides separate OTLP endpoints for traces and logs which you can use to send your telemetry data to Sentry.\n\n* **Traces**: `https://{HOST}/api/{PROJECT_ID}/integration/otlp/v1/traces`\n* **Logs**: `https://{HOST}/api/{PROJECT_ID}/integration/otlp/v1/logs`\n\nYou can find your OTLP endpoints in the your project settings.\n\n1. Go to the [Settings > Projects](https://sentry.io/orgredirect/organizations/:orgslug/settings/projects/) page in Sentry.\n2. Select your project from the list and click on the project name to open the project settings.\n3. Go to the \"Client Keys (DSN)\" sub-page for this project under the \"SDK Setup\" heading.\n\nThere you'll find your Sentry project's OTLP logs and OTLP traces endpoints, as well as authentication headers for the endpoints. Make sure to copy the endpoints and authentication headers.\n\nFor more details on how to use Sentry's OTLP endpoints, refer to [Sentry's OTLP documentation](https://docs.sentry.io/concepts/otlp/).\n\n## Step 3: Set up destination in the Cloudflare dashboard\n\nTo set up a destination in the Cloudflare dashboard, navigate to your Cloudflare account's [Workers Observability](https://dash.cloudflare.com/?to=/:account/workers-and-pages/observability/pipelines) section. Then click **Add destination** and configure either a traces or logs destination.\n\n### Traces Destination\n\nTo configure your traces destination, click **Add destination** and configure the following:\n\n* **Destination Name**: `sentry-traces` (or any descriptive name)\n\n* **Destination Type**: Select **Traces**\n\n* **OTLP Endpoint**: Your Sentry OTLP traces endpoint (e.g., `https://{HOST}/api/{PROJECT_ID}/integration/otlp/v1/traces`)\n\n* **Custom Headers**: Add the Sentry authentication header:\n\n* Header name: `x-sentry-auth`\n  * Header value: `sentry sentry_key={SENTRY_PUBLIC_KEY}` where `{SENTRY_PUBLIC_KEY}` is your Sentry project's public key\n\nTo configure your logs destination, click **Add destination** and configure the following:\n\n* **Destination Name**: `sentry-logs` (or any descriptive name)\n\n* **Destination Type**: Select **Logs**\n\n* **OTLP Endpoint**: Your Sentry OTLP logs endpoint (e.g., `https://{HOST}/api/{PROJECT_ID}/integration/otlp/v1/logs`)\n\n* **Custom Headers**: Add the Sentry authentication header:\n\n* Header name: `x-sentry-auth`\n  * Header value: `sentry sentry_key={SENTRY_PUBLIC_KEY}` where `{SENTRY_PUBLIC_KEY}` is your Sentry project's public key\n\n## Step 4: Configure your Worker\n\nWith your destinations created in the Cloudflare dashboard, update your Worker's configuration to enable telemetry export.\n\nAfter updating your configuration, deploy your Worker for the changes to take effect.\n\nIt may take a few minutes after deployment for data to appear in Sentry.\n\n<page>\n---\ntitle: Tail Workers · Cloudflare Workers docs\ndescription: Track and log Workers on invocation by assigning a Tail Worker to\n  your projects.\nlastUpdated: 2025-12-29T17:29:32.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/observability/logs/tail-workers/\n  md: https://developers.cloudflare.com/workers/observability/logs/tail-workers/index.md\n---\n\nA Tail Worker receives information about the execution of other Workers (known as producer Workers), such as HTTP statuses, data passed to `console.log()` or uncaught exceptions. Tail Workers can process logs for alerts, debugging, or analytics.\n\nTail Workers are available to all customers on the Workers Paid and Enterprise tiers. Tail Workers are billed by [CPU time](https://developers.cloudflare.com/workers/platform/pricing/#workers), not by the number of requests.\n\n![Tail Worker diagram](https://developers.cloudflare.com/_astro/tail-workers.CaYo-ajt_gkexF.webp)\n\nA Tail Worker is automatically invoked after the invocation of a producer Worker (the Worker the Tail Worker will track) that contains the application logic. It captures events after the producer has finished executing. Events throughout the request lifecycle, including potential sub-requests via [Service Bindings](https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings/) and [Dynamic Dispatch](https://developers.cloudflare.com/cloudflare-for-platforms/workers-for-platforms/configuration/dynamic-dispatch/), will be included. You can filter, change the format of the data, and send events to any HTTP endpoint. For quick debugging, Tail Workers can be used to send logs to [KV](https://developers.cloudflare.com/kv/api/) or any database.\n\nExport batches of logs and traces to Sentry, Grafana, Honeycomb and more\n\nIf you are using Tail Workers to export logs and errors to observability tools like Sentry, Grafana, Honeycomb and more — you may not need to use Tail Workers.\n\nInstead, you can configure your Worker to [export OpenTelemetry (OTEL) format logs and traces](https://developers.cloudflare.com/workers/observability/exporting-opentelemetry-data/) to these tools. Unlike Tail Workers, when you configure an OTEL destination, logs and traces are sent in batches to your destination, rather than sent after each invocation of the Worker.\n\nYou should think of Tail Workers as the advanced-mode option, for when you need to do something custom that is not built into the Workers observability platform.\n\n## Configure Tail Workers\n\nTo configure a Tail Worker:\n\n1. [Create a Worker](https://developers.cloudflare.com/workers/get-started/guide) to serve as the Tail Worker.\n2. Add a [`tail()`](https://developers.cloudflare.com/workers/runtime-apis/handlers/tail/) handler to your Worker. The `tail()` handler is invoked every time the producer Worker to which a Tail Worker is connected is invoked. The following Worker code is a Tail Worker that sends its data to an HTTP endpoint:\n\nThe following Worker code is an example of what the `events` object may look like:\n\n1. Add the following to the Wrangler file of the producer Worker:\n\nWorkers added to the `tail_consumers` array must have a `tail()` handler defined.\n\n* [`tail()`](https://developers.cloudflare.com/workers/runtime-apis/handlers/tail/) Handler API docs - Learn how to set up a `tail()` handler in your Worker.\n\n- [Errors and exceptions](https://developers.cloudflare.com/workers/observability/errors/) - Review common Workers errors.\n- [Local development and testing](https://developers.cloudflare.com/workers/development-testing/) - Develop and test you Workers locally.\n- [Source maps and stack traces](https://developers.cloudflare.com/workers/observability/source-maps) - Learn how to enable source maps and generate stack traces for Workers.\n\n<page>\n---\ntitle: Real-time logs · Cloudflare Workers docs\ndescription: Debug your Worker application by accessing logs and exceptions\n  through the Cloudflare dashboard or `wrangler tail`.\nlastUpdated: 2025-09-09T12:12:09.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/observability/logs/real-time-logs/\n  md: https://developers.cloudflare.com/workers/observability/logs/real-time-logs/index.md\n---\n\nWith Real-time logs, access all your log events in near real-time for log events happening globally. Real-time logs is helpful for immediate feedback, such as the status of a new deployment.\n\nReal-time logs captures [invocation logs](https://developers.cloudflare.com/workers/observability/logs/workers-logs/#invocation-logs), [custom logs](https://developers.cloudflare.com/workers/observability/logs/workers-logs/#custom-logs), errors, and uncaught exceptions. For high-traffic applications, real-time logs may enter sampling mode, which means some messages will be dropped and a warning will appear in your logs.\n\nReal-time logs are not available for zones on the [Cloudflare China Network](https://developers.cloudflare.com/china-network/).\n\n## View logs from the dashboard\n\nTo view real-time logs associated with any deployed Worker using the Cloudflare dashboard:\n\n1. In the Cloudflare dashboard, go to the **Workers & Pages** page.\n\n[Go to **Workers & Pages**](https://dash.cloudflare.com/?to=/:account/workers-and-pages)\n\n2. In **Overview**, select your **Worker**.\n\n4. In the right-hand navigation bar, select **Live**.\n\n## View logs using `wrangler tail`\n\nTo view real-time logs associated with any deployed Worker using Wrangler:\n\n1. Go to your Worker project directory.\n2. Run [`npx wrangler tail`](https://developers.cloudflare.com/workers/wrangler/commands/#tail).\n\nThis will log any incoming requests to your application available in your local terminal.\n\nThe output of each `wrangler tail` log is a structured JSON object:\n\nBy piping the output to tools like [`jq`](https://stedolan.github.io/jq/), you can query and manipulate the requests to look for specific information:\n\nYou can customize how `wrangler tail` works to fit your needs. Refer to [the `wrangler tail` documentation](https://developers.cloudflare.com/workers/wrangler/commands/#tail) for available configuration options.\n\nYou can filter real-time logs in the dashboard or using [`wrangler tail`](https://developers.cloudflare.com/workers/wrangler/commands/#tail). If your Worker has a high volume of messages, filtering real-time logs can help mitgate messages from being dropped.\n\n* Real-time logs does not store Workers Logs. To store logs, use [Workers Logs](https://developers.cloudflare.com/workers/observability/logs/workers-logs).\n* If your Worker has a high volume of traffic, the real-time logs might enter sampling mode. This will cause some of your messages to be dropped and a warning to appear in your logs.\n* Logs from any [Durable Objects](https://developers.cloudflare.com/durable-objects/) your Worker is using will show up in the dashboard.\n* A maximum of 10 clients can view a Worker's logs at one time. This can be a combination of either dashboard sessions or `wrangler tail` calls.\n* When using `wrangler tail` with [WebSocket event handlers](https://developers.cloudflare.com/workers/runtime-apis/websockets/), any `console.log` statements within those handlers are hidden until the WebSocket client closes the connection. Once the `close` is received, all messages are flushed, printing everything to the terminal at once.\n\nLogs can be persisted, filtered, and analyzed with [Workers Logs](https://developers.cloudflare.com/workers/observability/logs/workers-logs). To send logs to a third party, use [Workers Logpush](https://developers.cloudflare.com/workers/observability/logs/logpush/) or [Tail Workers](https://developers.cloudflare.com/workers/observability/logs/tail-workers/).\n\n* [Errors and exceptions](https://developers.cloudflare.com/workers/observability/errors/) - Review common Workers errors.\n* [Local development and testing](https://developers.cloudflare.com/workers/development-testing/) - Develop and test you Workers locally.\n* [Workers Logs](https://developers.cloudflare.com/workers/observability/logs/workers-logs) - Collect, store, filter and analyze logging data emitted from Cloudflare Workers.\n* [Logpush](https://developers.cloudflare.com/workers/observability/logs/logpush/) - Learn how to push Workers Trace Event Logs to supported destinations.\n* [Tail Workers](https://developers.cloudflare.com/workers/observability/logs/tail-workers/) - Learn how to attach Tail Workers to transform your logs and send them to HTTP endpoints.\n* [Source maps and stack traces](https://developers.cloudflare.com/workers/observability/source-maps) - Learn how to enable source maps and generate stack traces for Workers.\n\n<page>\n---\ntitle: Workers Logs · Cloudflare Workers docs\ndescription: Store, filter, and analyze log data emitted from Cloudflare Workers.\nlastUpdated: 2025-09-08T17:05:16.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/observability/logs/workers-logs/\n  md: https://developers.cloudflare.com/workers/observability/logs/workers-logs/index.md\n---\n\nWorkers Logs lets you automatically collect, store, filter, and analyze logging data emitted from Cloudflare Workers. Data is written to your Cloudflare Account, and you can query it in the dashboard for each of your Workers. All newly created Workers will come with the observability setting enabled by default.\n\nLogs include [invocation logs](https://developers.cloudflare.com/workers/observability/logs/workers-logs/#invocation-logs), [custom logs](https://developers.cloudflare.com/workers/observability/logs/workers-logs/#custom-logs), errors, and uncaught exceptions.\n\n![Example showing the Workers Logs Dashboard](https://developers.cloudflare.com/_astro/preview.B6xRDzZ-_Z1XdUPd.webp)\n\nTo send logs to a third party, use [Workers Logpush](https://developers.cloudflare.com/workers/observability/logs/logpush/) or [Tail Workers](https://developers.cloudflare.com/workers/observability/logs/tail-workers/).\n\n## Enable Workers Logs\n\nMinimum required Wrangler version: 3.78.6. Check your version by running `wrangler --version`. To update Wrangler, refer to [Install/Update Wrangler](https://developers.cloudflare.com/workers/wrangler/install-and-update/).\n\nYou must add the observability setting for your Worker to write logs to Workers Logs. Add the following setting to your Worker's Wrangler file and redeploy your Worker.\n\n[Head-based sampling](https://developers.cloudflare.com/workers/observability/logs/workers-logs/#head-based-sampling) allows you set the percentage of Workers requests that are logged.\n\n### Enabling with environments\n\n[Environments](https://developers.cloudflare.com/workers/wrangler/environments/) allow you to deploy the same Worker application with different configurations. For example, you may want to configure a different `head_sampling_rate` to staging and production. To configure observability for an environment named `staging`: 1. Add the following configuration below `[env.staging]`\n\n1. Deploy your Worker with `npx wrangler deploy -e staging`\n2. Repeat step 1 and 2 for each environment.\n\n## View logs from the dashboard\n\nAccess logs for your Worker from the Cloudflare dashboard:\n\n1. In the Cloudflare dashboard, go to the **Workers & Pages** page.\n\n[Go to **Workers & Pages**](https://dash.cloudflare.com/?to=/:account/workers-and-pages)\n\n2. In **Overview**, select your **Worker**.\n\n### Logging structured JSON objects\n\nTo get the most out of Workers Logs, it is recommended you log in JSON format. Workers Logs automatically extracts the fields and indexes them intelligently in the database. The benefit of this structured logging technique is in how it allows you to easily segment data across any dimension for fields with unlimited cardinality. Consider the following scenarios:\n\n| Scenario | Logging Code | Event Log (Partial) |\n| - | - | - |\n| 1 | `console.log(\"user_id: \" + 123)` | `{message: \"user_id: 123\"}` |\n| 2 | `console.log({user_id: 123})` | `{user_id: 123}` |\n| 3 | `console.log({user_id: 123, user_email: \"a@example.com\"})` | `{user_id: 123, user_email: \"a@example.com\"}` |\n\nThe difference between these examples is in how you index your logs to enable faster queries. In scenario 1, the `user_id` is embedded within a message. To find all logs relating to a particular user\\_id, you would have to run a text match. In scenarios 2 and 3, your logs can be filtered against the keys `user_id` and `user_email`.\n\nEach Workers invocation returns a single invocation log that contains details such as the Request, Response, and related metadata. These invocation logs can be identified by the field `$cloudflare.$metadata.type = \"cf-worker-event\"`. Each invocation log is enriched with information available to Cloudflare in the context of the invocation.\n\nIn the Workers Logs UI, logs are presented with a localized timestamp and a message. The message is dependent on the invocation handler. For example, Fetch requests will have a message describing the request method and the request URL, while cron events will be listed as cron. Below is a list of invocation handlers along with their invocation message.\n\nInvocation logs can be disabled in wrangler by adding the `invocation_logs = false` configuration.\n\n| Invocation Handler | Invocation Message |\n| - | - |\n| [Alarm](https://developers.cloudflare.com/durable-objects/api/alarms/) | \\<Scheduled Time> |\n| [Email](https://developers.cloudflare.com/email-routing/email-workers/runtime-api/) | \\<Email Recipient> |\n| [Fetch](https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch/) | \\<Method> \\<URL> |\n| [Queue](https://developers.cloudflare.com/queues/configuration/javascript-apis/#consumer) | \\<Queue Name> |\n| [Cron](https://developers.cloudflare.com/workers/runtime-apis/handlers/scheduled/) | \\<UNIX-cron schedule> |\n| [Tail](https://developers.cloudflare.com/workers/runtime-apis/handlers/tail/) | tail |\n| [RPC](https://developers.cloudflare.com/workers/runtime-apis/rpc/) | \\<RPC method> |\n| [WebSocket](https://developers.cloudflare.com/workers/examples/websockets/) | \\<WebSocket Event Type> |\n\nBy default a Worker will emit [invocation logs](https://developers.cloudflare.com/workers/observability/logs/workers-logs/#invocation-logs) containing details about the request, response and related metadata.\n\nYou can also add custom logs throughout your code. Any `console.log` statements within your Worker will be visible in Workers Logs. The following example demonstrates a custom `console.log` within a Worker request handler.\n\nService Workers are deprecated\n\nService Workers are deprecated, but still supported. We recommend using [Module Workers](https://developers.cloudflare.com/workers/reference/migrate-to-module-workers/) instead. New features may not be supported for Service Workers.\n\nAfter you deploy the code above, view your Worker's logs in [the dashboard](https://developers.cloudflare.com/workers/observability/logs/workers-logs/#view-logs-from-the-dashboard) or with [real-time logs](https://developers.cloudflare.com/workers/observability/logs/real-time-logs/).\n\n### Head-based sampling\n\nHead-based sampling allows you to log a percentage of incoming requests to your Cloudflare Worker. Especially for high-traffic applications, this helps reduce log volume and manage costs, while still providing meaningful insights into your application's performance. When you configure a head-based sampling rate, you can control the percentage of requests that get logged. All logs within the context of the request are collected.\n\nTo enable head-based sampling, set `head_sampling_rate` within the observability configuration. The valid range is from 0 to 1, where 0 indicates zero out of one hundred requests are logged, and 1 indicates every request is logged. If `head_sampling_rate` is unspecified, it is configured to a default value of 1 (100%). In the example below, `head_sampling_rate` is set to 0.01, which means one out of every one hundred requests is logged.\n\n| Description | Limit |\n| - | - |\n| Maximum log retention period | 7 Days |\n| Maximum logs per account per day1 | 5 Billion |\n| Maximum log size2 | 256 KB |\n\n1 There is a daily limit of 5 billion logs per account per day. After the limit is exceed, a 1% head-based sample will be applied for the remainder of the day.\n\n2 A single log has a maximum size limit of [256 KB](https://developers.cloudflare.com/workers/platform/limits/#log-size). Logs exceeding that size will be truncated and the log's `$cloudflare.truncated` field will be set to true.\n\nWorkers Logs billing will begin on April 21, 2025.\n\nWorkers Logs is included in both the Free and Paid [Workers plans](https://developers.cloudflare.com/workers/platform/pricing/).\n\n| | Log Events Written | Retention |\n| - | - | - |\n| **Workers Free** | 200,000 per day | 3 Days |\n| **Workers Paid** | 20 million included per month +$0.60 per additional million | 7 Days |\n\nA Worker serves 15 million requests per month. Each request emits 1 invocation log and 1 `console.log`. `head_sampling_rate` is configured to 1.\n\n| | Monthly Costs | Formula |\n| - | - | - |\n| **Logs** | $6.00 | ((15,000,000 requests per month \\* 2 logs per request \\* 100% sample) - 20,000,000 included logs) / 1,000,000 \\* $0.60 |\n| **Total** | $6.00 | |\n\nA Worker serves 1 billion requests per month. Each request emits 1 invocation log and 1 `console.log`. `head_sampling_rate` is configured to 0.1.\n\n| | Monthly Costs | Formula |\n| - | - | - |\n| **Logs** | $108.00 | ((1,000,000,000 requests per month \\* 2 logs per request \\* 10% sample) - 20,000,000 included logs) / 1,000,000 \\* $0.60 |\n| **Total** | $108.00 | |\n\n<page>\n---\ntitle: Sentry · Cloudflare Workers docs\ndescription: Connect to a Sentry project from your Worker to automatically send\n  errors and uncaught exceptions to Sentry.\nlastUpdated: 2025-06-11T18:31:10.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/observability/third-party-integrations/sentry/\n  md: https://developers.cloudflare.com/workers/observability/third-party-integrations/sentry/index.md\n---\n\nConnect to a Sentry project from your Worker to automatically send errors and uncaught exceptions to Sentry.\n\n<page>\n---\ntitle: Known limitations · Cloudflare Workers docs\ndescription: Workers tracing is currently in open beta. This page documents\n  current limitations and any upcoming features on our roadmap.\nlastUpdated: 2025-11-08T14:34:54.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/observability/traces/known-limitations/\n  md: https://developers.cloudflare.com/workers/observability/traces/known-limitations/index.md\n---\n\nWorkers tracing is currently in open beta. This page documents current limitations and any upcoming features on our roadmap.\n\nTo provide more feedback and send feature requests, head to the [Workers tracing GitHub discussion](https://github.com/cloudflare/workers-sdk/discussions/11062).\n\n### Non-I/O operations may report time of 0 ms\n\nDue to [security measures put in place to prevent Spectre attacks](https://developers.cloudflare.com/workers/reference/security-model/#step-1-disallow-timers-and-multi-threading), the Workers Runtime does not update time until I/O events take place. This means that some spans will return a length of `0 ms` even when the operation took longer.\n\nThe Cloudflare Workers team is exploring security measures that would allow exposing time lengths at milisecond-level granularity in these cases.\n\n### Trace context propagation not yet supported\n\nCurrently, Workers tracing does not propagate trace IDs to different platforms or accept trace IDs from other platforms.\n\nThis means that spans from Workers will not be nested within traces from services that call Workers (or vice versa).\n\nIdeally, trace context can flow across service boundaries and automatically link spans together to create complete, end-to-end visibility. When fully implemented, our automatic trace context propagation will follow [W3C standards](https://www.w3.org/TR/trace-context/) to ensure compatibility across your existing tools and services. This will allow for traces to include spans from both Workers and other services.\n\nWithout trace context propagation, calls to separate Workers and to Durable Objects create separate traces, rather than nested spans.\n\n### Incomplete spans attributes\n\nWe are planning to add more detailed attributes on each span. You can find a complete list of what is already instrumented [here](https://developers.cloudflare.com/workers/observability/traces/spans-and-attributes).\n\nYour feedback on any missing information will help us prioritize additions and changes. Please comment on the [Workers tracing GitHub discussion](https://github.com/cloudflare/workers-sdk/discussions/11062) if specific attributes would be helpful to use tracing effectively.\n\n### Support for custom spans and attributes\n\nAutomatic instrumentation covers many platform interactions, but we know you need visibility into your own application logic too. We're working to support the [OpenTelemetry API](https://www.npmjs.com/package/@opentelemetry/api) to make it easier for you to instrument custom spans within your application.\n\n### Span and attribute names subject to change\n\nAs Workers tracing is currently in beta, span names and attribute names are not yet finalized. We may refine these names during the beta period to improve clarity and align with OpenTelemetry semantic conventions. We recommend reviewing the [spans and attributes documentation](https://developers.cloudflare.com/workers/observability/traces/spans-and-attributes) periodically for updates.\n\n### Known bugs and other call outs\n\n* There are currently are a few attributes that only apply to some spans (e.g.`service.name`, `faas.name`). When filtering or grouping by the Worker name across traces and logs, use `$metadata.service` instead, as it will apply consistently across all event types.\n* While a trace is in progress, the event will show `Trace in Progress` on the root span. Please wait a few moments for the full trace to become available\n\n<page>\n---\ntitle: Spans and attributes · Cloudflare Workers docs\ndescription: Cloudflare Workers provides automatic tracing instrumentation out\n  of the box - no code changes or SDK are required.\nlastUpdated: 2025-11-25T15:35:41.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/observability/traces/spans-and-attributes/\n  md: https://developers.cloudflare.com/workers/observability/traces/spans-and-attributes/index.md\n---\n\nCloudflare Workers provides automatic tracing instrumentation **out of the box** - no code changes or SDK are required.\n\n## Currently supported spans and attributes\n\n### Attributes available on all spans\n\n* `cloud.provider` - Always set to `cloudflare`\n* `cloud.platform` - Always set to `cloudflare.workers`\n* `faas.name` - The name of your Worker\n* `faas.invocation_id` - A unique identifier for this specific Worker invocation\n* `faas.version` - The deployed version tag of your Worker\n* `faas.invoked_region` - The region where the Worker was invoked\n* `service.name` - The name of your Worker\n* `cloudflare.colo` - The three-letter IATA airport code of the Cloudflare data center that processed the request (e.g., `SFO`, `LHR`)\n* `cloudflare.script_name` - The name of your Worker\n* `cloudflare.script_tags` - Tags associated with your Worker deployment\n* `cloudflare.script_version.id` - The version identifier of your deployed Worker\n* `cloudflare.invocation.sequence.number` - A counter added to every emitted span and log that can be used to distinguish which was emitted first when the timestamps are the same\n* `telemetry.sdk.language` - The programming language used, set to `javascript`\n* `telemetry.sdk.name` - The telemetry SDK name, set to `cloudflare`\n\n### Attributes available on all root spans\n\n* `faas.trigger` - The trigger that your Worker was invoked by (e.g., `http`, `cron`, `queue`, `email`)\n* `cloudflare.ray_id` - A [unique identifier](https://developers.cloudflare.com/fundamentals/reference/cloudflare-ray-id/) for every request that goes through Cloudflare\n* `cloudflare.handler_type` - The type of handler that processed the request (e.g., `fetch`, `scheduled`, `queue`, `email`, `alarm`)\n* `cloudflare.entrypoint` - The entrypoint that was invoked in your Worker (e.g. the name of your Durable Object)\n* `cloudflare.execution_model` - The execution model of the Worker (e.g., `stateless`, `stateful` for Durable Objects)\n* `cloudflare.outcome` - The outcome of the Worker invocation (e.g., `ok`, `exception`, `exceededCpu`, `exceededMemory`)\n* `cloudflare.cpu_time_ms` - The CPU time used by the Worker invocation, in milliseconds\n* `cloudflare.wall_time_ms` - The wall time used by the Worker invocation, in milliseconds\n\n### [Runtime API](https://developers.cloudflare.com/workers/runtime-apis/)\n\n#### [`fetch`](https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch/)\n\n* `network.protocol.name`\n* `network.protocol.version`\n* `url.full`\n* `url.scheme`\n* `url.path`\n* `url.query`\n* `server.port`\n* `server.address`\n* `user_agent.original`\n* `http.request.method`\n* `http.request.header.content-type`\n* `http.request.header.content-length`\n* `http.request.header.accept`\n* `http.request.header.accept-encoding`\n* `http.request.body.size`\n* `http.response.status_code`\n* `http.response.body.size`\n\n#### [`cache_put`](https://developers.cloudflare.com/workers/runtime-apis/cache/#put)\n\n* `cache.request.url`\n* `cache.request.method`\n* `cache.request.payload.status_code`\n* `cache.request.payload.header.cache_control`\n* `cache.request.payload.header.cache_tag`\n* `cache.request.payload.header.etag`\n* `cache.request.payload.header.expires`\n* `cache.request.payload.header.last_modified`\n* `cache.request.payload.size`\n* `cache.response.success`\n\n#### [`cache_match`](https://developers.cloudflare.com/workers/runtime-apis/cache/#match)\n\n* `cache.request.ignore_method`\n* `cache.request.url`\n* `cache.request.method`\n* `cache.request.header.range`\n* `cache.request.header.if_modified_since`\n* `cache.request.header.if_none_match`\n* `cache.response.status_code`\n* `cache.response.body.size`\n* `cache.response.cache_status`\n* `cache.response.success`\n\n#### [`cache_delete`](https://developers.cloudflare.com/workers/runtime-apis/cache/#delete)\n\n* `cache.request.ignore_method`\n* `cache.request.url`\n* `cache.request.method`\n* `cache.response.status_code`\n* `cache.response.success`\n\n### [Handlers](https://developers.cloudflare.com/workers/runtime-apis/handlers/)\n\n#### [`Fetch Handler`](https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch/)\n\n* `cloudflare.verified_bot_category`\n* `cloudflare.asn`\n* `cloudflare.response.time_to_first_byte_ms`\n* `geo.timezone`\n* `geo.continent.code`\n* `geo.country.code`\n* `geo.locality.name`\n* `geo.locality.region`\n* `user_agent.orginal`\n* `user_agent.os.name`\n* `user_agent.os.version`\n* `user_agent.browser.name`\n* `user_agent.browser.major_version`\n* `user_agent.browser.version`\n* `user_agent.engine.name`\n* `user_agent.engine.version`\n* `user_agent.device.type`\n* `user_agent.device.vendor`\n* `user_agent.device.model`\n* `http.request.method`\n* `http.request.header.accept`\n* `http.request.header.accept-encoding`\n* `http.request.header.accept-language`\n* `url.full`\n* `url.path`\n* `network.protocol.name`\n\n#### [`Scheduled Handler`](https://developers.cloudflare.com/workers/runtime-apis/handlers/scheduled/)\n\n* `faas.cron`\n* `cloudflare.scheduled_time`\n\n#### [`QueueHandler`](https://developers.cloudflare.com/workers/runtime-apis/handlers/queue/)\n\n* `cloudflare.queue.name`\n* `cloudflare.queue.batch_size`\n\n#### [`RPC Handler`](https://developers.cloudflare.com/workers/runtime-apis/rpc/)\n\n* `cloudflare.jsrpc.method`\n\n#### [`Email Handler`](https://developers.cloudflare.com/email-routing/email-workers/runtime-api/)\n\n* `cloudflare.email.from`\n* `cloudflare.email.to`\n* `cloudflare.email.size`\n\n#### [`Tail Handler`](https://developers.cloudflare.com/workers/runtime-apis/handlers/tail/)\n\n* `cloudflare.trace.count`\n\n#### [`Alarm Handler`](https://developers.cloudflare.com/durable-objects/api/alarms/#alarm)\n\n* `cloudflare.scheduled_time`\n\n### [D1](https://developers.cloudflare.com/d1/)\n\n#### Attributes available on all D1 spans\n\n* `db.system.name`\n* `db.operation.name`\n* `db.query.text`\n* `cloudflare.binding.type`\n* `cloudflare.d1.response.size_after`\n* `cloudflare.d1.response.rows_read`\n* `cloudflare.d1.response.rows_written`\n* `cloudflare.d1.response.last_row_id`\n* `cloudflare.d1.response.changed_db`\n* `cloudflare.d1.response.changes`\n* `cloudflare.d1.response.served_by_region`\n* `cloudflare.d1.response.served_by_primary`\n* `cloudflare.d1.response.sql_duration_ms`\n* `cloudflare.d1.response.total_attempts`\n\n#### [`d1_batch`](https://developers.cloudflare.com/d1/worker-api/d1-database/#batch)\n\n* `db.operation.batch.size`\n* `cloudflare.d1.query.bookmark`\n* `cloudflare.d1.response.bookmark`\n\n#### [`d1_exec`](https://developers.cloudflare.com/d1/worker-api/d1-database/#exec)\n\n#### [`d1_first`](https://developers.cloudflare.com/d1/worker-api/prepared-statements/#first)\n\n* `cloudflare.d1.query.bookmark`\n* `cloudflare.d1.response.bookmark`\n\n#### [`d1_run`](https://developers.cloudflare.com/d1/worker-api/prepared-statements/#run)\n\n* `cloudflare.d1.query.bookmark`\n* `cloudflare.d1.response.bookmark`\n\n#### [`d1_all`](https://developers.cloudflare.com/d1/worker-api/prepared-statements/#run)\n\n* `cloudflare.d1.query.bookmark`\n* `cloudflare.d1.response.bookmark`\n\n#### [`d1_raw`](https://developers.cloudflare.com/d1/worker-api/prepared-statements/#raw)\n\n* `cloudflare.d1.query.bookmark`\n* `cloudflare.d1.response.bookmark`\n\n### [Browser Rendering](https://developers.cloudflare.com/browser-rendering/)\n\n#### `browser_rendering_fetch`\n\n### [Workers KV](https://developers.cloudflare.com/kv/)\n\n#### Attributes available on all KV spans\n\n* `db.system.name`\n* `db.operation.name`\n* `cloudflare.binding.name`\n* `cloudflare.binding.type`\n\n#### [`kv_get`](https://developers.cloudflare.com/kv/api/read-key-value-pairs/#get-method)\n\n* `cloudflare.kv.query.keys`\n* `cloudflare.kv.query.keys.count`\n* `cloudflare.kv.query.type`\n* `cloudflare.kv.query.cache_ttl`\n* `cloudflare.kv.response.size`\n* `cloudflare.kv.response.returned_rows`\n* `cloudflare.kv.response.metadata`\n* `cloudflare.kv.response.cache_status`\n\n#### [`kv_getWithMetadata`](https://developers.cloudflare.com/kv/api/read-key-value-pairs/#getwithmetadata-method)\n\n* `cloudflare.kv.query.keys`\n* `cloudflare.kv.query.keys.count`\n* `cloudflare.kv.query.type`\n* `cloudflare.kv.query.cache_ttl`\n* `cloudflare.kv.response.size`\n* `cloudflare.kv.response.returned_rows`\n* `cloudflare.kv.response.metadata`\n* `cloudflare.kv.response.cache_status`\n\n#### [`kv_put`](https://developers.cloudflare.com/kv/api/write-key-value-pairs/#put-method)\n\n* `cloudflare.kv.query.keys`\n* `cloudflare.kv.query.keys.count`\n* `cloudflare.kv.query.value_type`\n* `cloudflare.kv.query.expiration`\n* `cloudflare.kv.query.expiration_ttl`\n* `cloudflare.kv.query.metadata`\n* `cloudflare.kv.query.payload.size`\n\n#### [`kv_delete`](https://developers.cloudflare.com/kv/api/delete-key-value-pairs/#delete-method)\n\n* `cloudflare.kv.query.keys`\n* `cloudflare.kv.query.keys.colunt`\n\n#### [`kv_list`](https://developers.cloudflare.com/kv/api/list-keys/#list-method)\n\n* `cloudflare.kv.query.prefix`\n* `cloudflare.kv.query.limit`\n* `cloudflare.kv.query.cursor`\n* `cloudflare.kv.response.size`\n* `cloudflare.kv.response.returned_rows`\n* `cloudflare.kv.response.list_complete`\n* `cloudflare.kv.response.cursor`\n* `cloudflare.kv.response.cache_status`\n* `cloudflare.kv.response.expiration`\n\n### [R2](https://developers.cloudflare.com/r2/)\n\n#### Attributes available on all R2 spans\n\n* `cloudflare.binding.type`\n* `cloudflare.binding.name`\n* `cloudflare.r2.bucket`\n* `cloudflare.r2.operation`\n* `cloudflare.r2.response.success`\n* `cloudflare.r2.error.message`\n* `cloudflare.r2.error.code`\n\n#### [`r2_head`](https://developers.cloudflare.com/r2/api/workers/workers-api-reference/#bucket-method-definitions)\n\n* `cloudflare.r2.request.key`\n* `cloudflare.r2.response.etag`\n* `cloudflare.r2.response.size`\n* `cloudflare.r2.response.uploaded`\n* `cloudflare.r2.response.checksum.value`\n* `cloudflare.r2.response.checksum.type`\n* `cloudflare.r2.response.storage_class`\n* `cloudflare.r2.response.ssec_key`\n* `cloudflare.r2.response.content_type`\n* `cloudflare.r2.response.content_encoding`\n* `cloudflare.r2.response.content_disposition`\n* `cloudflare.r2.response.content_language`\n* `cloudflare.r2.response.cache_control`\n* `cloudflare.r2.response.cache_expiry`\n* `cloudflare.r2.response.custom_metadata`\n\n#### [`r2_get`](https://developers.cloudflare.com/r2/api/workers/workers-api-reference/#r2getoptions)\n\n* `cloudflare.r2.request.key`\n* `cloudflare.r2.request.range.offset`\n* `cloudflare.r2.request.range.length`\n* `cloudflare.r2.request.range.suffix`\n* `cloudflare.r2.request.range`\n* `cloudflare.r2.request.ssec_key`\n* `cloudflare.r2.request.only_if.etag_matches`\n* `cloudflare.r2.request.only_if.etag_does_not_match`\n* `cloudflare.r2.request.only_if.uploaded_before`\n* `cloudflare.r2.request.only_if.uploaded_after`\n* `cloudflare.r2.response.etag`\n* `cloudflare.r2.response.size`\n* `cloudflare.r2.response.uploaded`\n* `cloudflare.r2.response.checksum.value`\n* `cloudflare.r2.response.checksum.type`\n* `cloudflare.r2.response.storage_class`\n* `cloudflare.r2.response.ssec_key`\n* `cloudflare.r2.response.content_type`\n* `cloudflare.r2.response.content_encoding`\n* `cloudflare.r2.response.content_disposition`\n* `cloudflare.r2.response.content_language`\n* `cloudflare.r2.response.cache_control`\n* `cloudflare.r2.response.cache_expiry`\n* `cloudflare.r2.response.custom_metadata`\n\n#### [`r2_put`](https://developers.cloudflare.com/r2/api/workers/workers-api-reference/#r2putoptions)\n\n* `cloudflare.r2.request.key`\n* `cloudflare.r2.request.size`\n* `cloudflare.r2.request.checksum.type`\n* `cloudflare.r2.request.checksum.value`\n* `cloudflare.r2.request.custom_metadata`\n* `cloudflare.r2.request.http_metadata.content_type`\n* `cloudflare.r2.request.http_metadata.content_encoding`\n* `cloudflare.r2.request.http_metadata.content_disposition`\n* `cloudflare.r2.request.http_metadata.content_language`\n* `cloudflare.r2.request.http_metadata.cache_control`\n* `cloudflare.r2.request.http_metadata.cache_expiry`\n* `cloudflare.r2.request.storage_class`\n* `cloudflare.r2.request.ssec_key`\n* `cloudflare.r2.request.only_if.etag_matches`\n* `cloudflare.r2.request.only_if.etag_does_not_match`\n* `cloudflare.r2.request.only_if.uploaded_before`\n* `cloudflare.r2.request.only_if.uploaded_after`\n* `cloudflare.r2.response.etag`\n* `cloudflare.r2.response.size`\n* `cloudflare.r2.response.uploaded`\n* `cloudflare.r2.response.checksum.value`\n* `cloudflare.r2.response.checksum.type`\n* `cloudflare.r2.response.storage_class`\n* `cloudflare.r2.response.ssec_key`\n* `cloudflare.r2.response.content_type`\n* `cloudflare.r2.response.content_encoding`\n* `cloudflare.r2.response.content_disposition`\n* `cloudflare.r2.response.content_language`\n* `cloudflare.r2.response.cache_control`\n* `cloudflare.r2.response.cache_expiry`\n* `cloudflare.r2.response.custom_metadata`\n\n#### [`r2_list`](https://developers.cloudflare.com/r2/api/workers/workers-api-reference/#r2listoptions)\n\n* `cloudflare.r2.request.limit`\n* `cloudflare.r2.request.prefix`\n* `cloudflare.r2.request.cursor`\n* `cloudflare.r2.request.delimiter`\n* `cloudflare.r2.request.start_after`\n* `cloudflare.r2.request.include.http_metadata`\n* `cloudflare.r2.request.include.custom_metadata`\n* `cloudflare.r2.response.returned_objects`\n* `cloudflare.r2.response.delimited_prefixes`\n* `cloudflare.r2.response.truncated`\n* `cloudflare.r2.response.cursor`\n\n#### [`r2_delete`](https://developers.cloudflare.com/r2/api/workers/workers-api-reference/#bucket-method-definitions)\n\n* `cloudflare.r2.request.keys`\n\n#### [`r2_createMultipartUpload`](https://developers.cloudflare.com/r2/api/workers/workers-api-reference/#r2multipartoptions)\n\n* `cloudflare.r2.request.key`\n* `cloudflare.r2.request.custom_metadata`\n* `cloudflare.r2.request.http_metadata.content_type`\n* `cloudflare.r2.request.http_metadata.content_encoding`\n* `cloudflare.r2.request.http_metadata.content_disposition`\n* `cloudflare.r2.request.http_metadata.content_language`\n* `cloudflare.r2.request.http_metadata.cache_control`\n* `cloudflare.r2.request.http_metadata.cache_expiry`\n* `cloudflare.r2.request.storage_class`\n* `cloudflare.r2.request.ssec_key`\n* `cloudflare.r2.response.upload_id`\n\n#### [`r2_uploadPart`](https://developers.cloudflare.com/r2/api/workers/workers-multipart-usage/)\n\n* `cloudflare.r2.request.key`\n* `cloudflare.r2.request.upload_id`\n* `cloudflare.r2.request.part_number`\n* `cloudflare.r2.request.ssec_key`\n* `cloudflare.r2.request.size`\n* `cloudflare.r2.response.etag`\n\n#### [`r2_abortMultipartUpload`](https://developers.cloudflare.com/r2/api/workers/workers-multipart-usage/)\n\n* `cloudflare.r2.request.key`\n* `cloudflare.r2.request.upload_id`\n\n#### [`r2_completeMultipartUpload`](https://developers.cloudflare.com/r2/api/workers/workers-multipart-usage/)\n\n* `cloudflare.r2.request.key`\n* `cloudflare.r2.request.upload_id`\n* `cloudflare.r2.request.uploaded_parts`\n* `cloudflare.r2.response.etag`\n* `cloudflare.r2.response.size`\n* `cloudflare.r2.response.uploaded`\n* `cloudflare.r2.response.checksum.value`\n* `cloudflare.r2.response.checksum.type`\n* `cloudflare.r2.response.storage_class`\n* `cloudflare.r2.response.ssec_key`\n* `cloudflare.r2.response.content_type`\n* `cloudflare.r2.response.content_encoding`\n* `cloudflare.r2.response.content_disposition`\n* `cloudflare.r2.response.content_language`\n* `cloudflare.r2.response.cache_control`\n* `cloudflare.r2.response.cache_expiry`\n* `cloudflare.r2.response.custom_metadata`\n\n### [Durable Object API](https://developers.cloudflare.com/durable-objects/)\n\n#### `durable_object_subrequest`\n\n### [Durable Object Storage SQL API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api)\n\nThe SQL API allow you to modify the SQLite database embedded within a Durable Object.\n\n#### [`durable_object_storage_exec`](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#exec)\n\n* `db.system.name`\n* `db.operation.name`\n* `db.query.text`\n* `cloudflare.durable_object.query.bindings`\n* `cloudflare.durable_object.response.rows_read`\n* `cloudflare.durable_object.response.rows_written`\n\n#### [`durable_object_storage_getDatabaseSize`](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#databasesize)\n\n* `db.operation.name`\n* `cloudflare.durable_object.response.db_size`\n\n#### `durable_object_storage_ingest`\n\n* `cloudflare.durable_object.response.rows_read`\n* `cloudflare.durable_object.response.rows_written`\n* `cloudflare.durable_object.response.statement_count`\n\n#### [`durable_object_storage_kv_get`](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#get)\n\n* `cloudflare.durable_object.kv.query.keys`\n* `cloudflare.durable_object.kv.query.keys.count`\n\n#### [`durable_object_storage_kv_put`](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#put)\n\n* `cloudflare.durable_object.kv.query.keys`\n* `cloudflare.durable_object.kv.query.keys.count`\n\n#### [`durable_object_storage_kv_delete`](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#delete)\n\n* `cloudflare.durable_object.kv.query.keys`\n* `cloudflare.durable_object.kv.query.keys.count`\n* `cloudflare.durable_object.kv.response.deleted_count`\n\n#### [`durable_object_storage_kv_list`](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api/#list)\n\n* `cloudflare.durable_object.kv.query.start`\n* `cloudflare.durable_object.kv.query.startAfter`\n* `cloudflare.durable_object.kv.query.end`\n* `cloudflare.durable_object.kv.query.prefix`\n* `cloudflare.durable_object.kv.query.reverse`\n* `cloudflare.durable_object.kv.query.limit`\n\n### [Durable Object Storage KV API](https://developers.cloudflare.com/durable-objects/api/legacy-kv-storage-api)\n\nThe legacy KV-backed API allows you to modify embedded storage within a Durable Object.\n\n#### [`durable_object_storage_get`](https://developers.cloudflare.com/durable-objects/api/legacy-kv-storage-api/#do-kv-async-get)\n\n#### [`durable_object_storage_put`](https://developers.cloudflare.com/durable-objects/api/legacy-kv-storage-api/#do-kv-async-put)\n\n#### [`durable_object_storage_delete`](https://developers.cloudflare.com/durable-objects/api/legacy-kv-storage-api/#do-kv-async-delete)\n\n#### [`durable_object_storage_list`](https://developers.cloudflare.com/durable-objects/api/legacy-kv-storage-api/#do-kv-async-list)\n\n#### [`durable_object_storage_deleteAll`](https://developers.cloudflare.com/durable-objects/api/legacy-kv-storage-api/#deleteall)\n\n### [Durable Object Storage Alarms API](https://developers.cloudflare.com/durable-objects/api/alarms/)\n\n#### [`durable_object_alarms_getAlarm`](https://developers.cloudflare.com/durable-objects/api/alarms/#getalarm)\n\n#### [`durable_object_alarms_setAlarm`](https://developers.cloudflare.com/durable-objects/api/alarms/#setalarm)\n\n#### [`durable_object_alarms_deleteAlarm`](https://developers.cloudflare.com/durable-objects/api/alarms/#deletealarm)\n\n### [Images](https://developers.cloudflare.com/images/transform-images/bindings/)\n\n### [`images_output`](https://developers.cloudflare.com/images/transform-images/bindings/#output)\n\n* `cloudflare.binding.type`\n* `cloudflare.images.options.format`\n* `cloudflare.images.options.quality`\n* `cloudflare.images.options.background`\n* `cloudflare.images.options.anim`\n* `cloudflare.images.options.transforms`\n* `cloudflare.images.error.code`\n\n### [`images_info`](https://developers.cloudflare.com/images/transform-images/bindings/#info)\n\n* `cloudflare.binding.type`\n* `cloudflare.images.options.encoding`\n* `cloudflare.images.result.format`\n* `cloudflare.images.result.file_size`\n* `cloudflare.images.result.width`\n* `cloudflare.images.result.height`\n* `cloudflare.images.error.code`\n\n### [Email](https://developers.cloudflare.com/email-routing/)\n\n#### [`reply_email`](https://developers.cloudflare.com/email-routing/email-workers/reply-email-workers/)\n\n#### [`forward_email`](https://developers.cloudflare.com/email-routing/email-workers/runtime-api/)\n\n#### [`send_email`](https://developers.cloudflare.com/email-routing/email-workers/send-email-workers/)\n\n### [Queues](https://developers.cloudflare.com/queues/)\n\n#### [`queue_send`](https://developers.cloudflare.com/queues/configuration/javascript-apis/#queue)\n\n#### [`queue_sendBatch`](https://developers.cloudflare.com/queues/configuration/javascript-apis/#queue)\n\n### [`Rate limiting`](https://developers.cloudflare.com/workers/runtime-apis/bindings/rate-limit/)\n\n#### [`ratelimit_run`](https://developers.cloudflare.com/workers/runtime-apis/bindings/rate-limit/#best-practices)\n\n<page>\n---\ntitle: Historical changelog · Cloudflare Workers docs\ndescription: Review pre-2023 changes to Cloudflare Workers.\nlastUpdated: 2024-11-07T19:39:45.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/platform/changelog/historical-changelog/\n  md: https://developers.cloudflare.com/workers/platform/changelog/historical-changelog/index.md\n---\n\nThis page tracks changes made to Cloudflare Workers before 2023. For a view of more recent updates, refer to the [current changelog](https://developers.cloudflare.com/workers/platform/changelog/).\n\n* Conditional `PUT` requests have been fixed in the R2 bindings API.\n\n* Queues no longer support calling `send()` with an undefined JavaScript value as the message.\n\n* The DOMException constructor has been updated to align better with the standard specification. Specifically, the message and name arguments can now be any JavaScript value that is coercible into a string (previously, passing non-string values would throw).\n* Extended the R2 binding API to include support for multipart uploads.\n\n* V8 update: 10.6 → 10.8\n\n* Implemented `toJSON()` for R2Checksums so that it is usable with `JSON.stringify()`.\n\n* The alarm retry limit will no longer apply to errors that are our fault.\n* Compatibility dates have been added for multiple flags including the new streams implementation.\n* `DurableObjectStorage` has a new method `sync()` that provides a way for a Worker to wait for its writes (including those performed with `allowUnconfirmed`) to be synchronized with storage.\n\n* Fixed a bug where if an ES-modules-syntax script exported an array-typed value from the top-level module, the upload API would refuse it with a [`500` error](https://community.cloudflare.com/t/community-tip-fixing-error-500-internal-server-error/44453).\n* `console.log` now prints more information about certain objects, for example Promises.\n* The Workers Runtime is now built from the Open Source code in: [GitHub - cloudflare/workerd: The JavaScript / Wasm runtime that powers Cloudflare Workers](https://github.com/cloudflare/workerd).\n\n* R2 `put` bindings options can now have an `onlyIf` field similar to `get` that does a conditional upload.\n* Allow deleting multiple keys at once in R2 bindings.\n* Added support for SHA-1, SHA-256, SHA-384, SHA-512 checksums in R2 `put` options.\n* User-specified object checksums will now be available in the R2 `get/head` bindings response. MD5 is included by default for non-multipart uploaded objects.\n* Updated V8 to 10.6.\n\n* A `Headers` object with the `range` header can now be used for range within `R2GetOptions` for the `get` R2 binding.\n* When headers are used for `onlyIf` within `R2GetOptions` for the `get` R2 binding, they now correctly compare against the second granularity. This allows correctly round-tripping to the browser and back. Additionally, `secondsGranularity` is now an option that can be passed into options constructed by hand to specify this when constructing outside Headers for the same effect.\n* Fixed the TypeScript type of `DurableObjectState.id` in [@cloudflare/workers-types](https://github.com/cloudflare/workers-types) to always be a `DurableObjectId`.\n* Validation errors during Worker upload for module scripts now include correct line and column numbers.\n* Bugfix, Profiling tools and flame graphs via Chrome’s debug tools now properly report information.\n\n* Workers Usage Report and Workers Weekly Summary have been disabled due to scaling issues with the service.\n\n* `wrangler dev` in global network preview mode now supports scheduling alarms.\n* R2 GET requests made with the `range` option now contain the returned range in the `GetObject`’s `range` parameter.\n* Some Web Cryptography API error messages include more information now.\n* Updated V8 from 10.2 to 10.3.\n\n* Cron trigger events on Worker scripts using the old `addEventListener` syntax are now treated as failing if there is no event listener registered for `scheduled` events.\n* The `durable_object_alarms` flag no longer needs to be explicitly provided to use DO alarms.\n\n* No externally-visible changes.\n\n* It is now possible to create standard `TransformStream` instances that can perform transformations on the data. Because this changes the behavior of the default `new TransformStream()` with no arguments, the `transformstream_enable_standard_constructor` compatibility flag is required to enable.\n* Preview in Quick Edit now correctly uses the correct R2 bindings.\n* Updated V8 from 10.1 to 10.2.\n\n* The static `Response.json()` method can be used to initialize a Response object with a JSON-serialized payload (refer to [whatwg/fetch #1392](https://github.com/whatwg/fetch/pull/1392)).\n* R2 exceptions being thrown now have the `error` code appended in the message in parenthesis. This is a stop-gap until we are able to explicitly add the code property on the thrown `Error` object.\n\n* R2 bindings: `contentEncoding`, `contentLanguage`, and `cacheControl` are now correctly rendered.\n* ReadableStream `pipeTo` and `pipeThrough` now support cancellation using `AbortSignal`.\n* Calling `setAlarm()` in a DO with no `alarm()` handler implemented will now throw instead of failing silently. Calling `getAlarm()` when no `alarm()` handler is currently implemented will return null, even if an alarm was previously set on an old version of the DO class, as no execution will take place.\n* R2: Better runtime support for additional ranges.\n* R2 bindings now support ranges that have an `offset` and an optional `length`, a `length` and an optional `offset`, or a `suffix` (returns the last `N` bytes of a file).\n\n* Fix R2 bindings saving cache-control under content-language and rendering cache-control under content-language.\n* Fix R2 bindings list without options to use the default list limit instead of never returning any results.\n* Fix R2 bindings which did not correctly handle error messages from R2, resulting in `internal error` being thrown. Also fix behavior for get throwing an exception on a non-existent key instead of returning null. `R2Error` is removed for the time being and will be reinstated at some future time TBD.\n* R2 bindings: if the onlyIf condition results in a precondition failure or a not modified result, the object is returned without a body instead of returning null.\n* R2 bindings: sha1 is removed as an option because it was not actually hooked up to anything. TBD on additional checksum options beyond md5.\n* Added `startAfter` option to the `list()` method in the Durable Object storage API.\n\n* `Response.redirect(url)` will no longer coalesce multiple consecutive slash characters appearing in the URL’s path.\n* Fix generated types for Date.\n* Fix R2 bindings list without options to use the default list limit instead of never returning any results.\n* Fix R2 bindings did not correctly handle error messages from R2, resulting in internal error being thrown. Also fix behavior for get throwing an exception on a non-existent key instead of returning null. `R2Error` is removed for the time being and will be reinstated at some future time TBD.\n\n* Minor V8 update: 10.0 → 10.1.\n* R2 public beta bindings are the default regardless of compat date or flags. Internal beta bindings customers should transition to public beta bindings as soon as possible. A back compatibility flag is available if this is not immediately possible. After some lag, new scripts carrying the `r2_public_beta_bindings` compatibility flag will stop accepting to be published until that flag is removed.\n\n* Major V8 update: 9.9 → 10.0.\n\n* Performance and stability improvements.\n\n* The AES-GCM implementation that is part of the Web Cryptography API now returns a friendlier error explaining that 0-length IVs are not allowed.\n* R2 error responses now include better details.\n\n* A new compatibility flag has been introduced, `minimal_subrequests` , which removes some features that were unintentionally being applied to same-zone `fetch()` calls. The flag will default to enabled on Tuesday, 2022-04-05, and is described in [Workers `minimal_subrequests` compatibility flag](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#minimal-subrequests).\n* When creating a `Response` with JavaScript-backed ReadableStreams, the `Body` mixin functions (e.g. `await response.text()` ) are now implemented.\n* The `IdentityTransformStream` creates a byte-oriented `TransformStream` implementation that simply passes bytes through unmodified. The readable half of the `TransformStream` supports BYOB-reads. It is important to note that `IdentityTransformStream` is identical to the current non-spec compliant `TransformStream` implementation, which will be updated soon to conform to the WHATWG Stream Standard. All current uses of `new TransformStream()` should be replaced with `new IdentityTransformStream()` to avoid potentially breaking changes later.\n\n* The standard [ByteLengthQueuingStrategy](https://developer.mozilla.org/en-US/docs/Web/API/ByteLengthQueuingStrategy) and [CountQueuingStrategy](https://developer.mozilla.org/en-US/docs/Web/API/CountQueuingStrategy) classes are now available.\n* When the `capture_async_api_throws` flag is set, built-in Cloudflare-specific and Web Platform Standard APIs that return Promises will no longer throw errors synchronously and will instead return rejected promises. Exception is given with fatal errors such as out of memory errors.\n* Fix R2 publish date rendering.\n* Fix R2 bucket binding .get populating contentRange with garbage. contentRange is now undefined as intended.\n* When using JavaScript-backed `ReadableStream`, it is now possible to use those streams with `new Response()`.\n\n* Fixed a bug where the key size was not counted when determining how many write units to charge for a Durable Object single-key `put()`. This may result in future writes costing one write unit more than past writes when the key is large enough to bump the total write size up above the next billing unit threshold of 4096 bytes. Multi-key `put()` operations have always properly counted the key size when determining billable write units.\n* Implementations of `CompressionStream` and `DecompressionStream` are now available.\n\n* Initial pipeTo/pipeThrough support on ReadableStreams constructed using the new `ReadableStream()` constructor is now available.\n* With the `global_navigator` compatibility flag set, the `navigator.userAgent` property can be used to detect when code is running within the Workers environment.\n* A bug in the new URL implementation was fixed when setting the value of a `URLSearchParam`.\n* The global `addEventListener` and dispatchEvent APIs are now available when using module syntax.\n* An implementation of `URLPattern` is now available.\n\n* The `TextDecoder` class now supports the full range of text encodings defined by the WHATWG Encoding Standard.\n* Both global `fetch()` and durable object `fetch()` now throw a TypeError when they receive a WebSocket in response to a request without the “Upgrade: websocket” header.\n* Durable Objects users may now store up to 50 GB of data across the objects in their account by default. As before, if you need more storage than that you can contact us for an increase.\n\n* `TextDecoder` now supports Windows-1252 labels (aka ASCII): [Encoding API Encodings - Web APIs | MDN](https://developer.mozilla.org/en-US/docs/Web/API/Encoding_API/Encodings).\n\n* WebSocket message sends were erroneously not respecting Durable Object output gates as described in the [I/O gate blog post](https://blog.cloudflare.com/durable-objects-easy-fast-correct-choose-three/). That bug has now been fixed, meaning that WebSockets will now never send a message under the assumption that a storage write has succeeded unless that write actually has succeeded.\n\n* Fixed bug causing WebSockets to Durable Objects to occasionally hang when the script implementing both a Worker and a Durable Object is re-deployed with new code.\n* `crypto.getRandomValues` now supports BigInt64Array and BigUint64Array.\n* A new implementation of the standard URL implementation is available. Use `url_standard` feature flag to enable the spec-compliant URL API implementation.\n\n* No user-visible changes.\n\n* Updated V8: 9.7 → 9.8.\n\n* `HTMLRewriter` now supports inspecting and modifying end tags, not just start tags.\n* Fixed bug where Durable Objects experiencing a transient CPU overload condition would cause in-progress requests to be unable to return a response (appearing as an indefinite hang from the client side), even after the overload condition clears.\n\n* The `workers_api_getters_setters_on_prototype` configuration flag corrects the way Workers attaches property getters and setters to API objects so that they can be properly subclassed.\n\n* Async iteration (using `for` and `await`) on instances of `ReadableStream` is now available.\n\n* Raised the max value size in Durable Object storage from 32 KiB to 128 KiB.\n* `AbortSignal.timeout(delay)` returns an `AbortSignal` that will be triggered after the given number of milliseconds.\n* Preview implementations of the new `ReadableStream` and new `WritableStream` constructors are available behind the `streams_enable_constructors` feature flag.\n* `crypto.DigestStream` is a non-standard extension to the crypto API that supports generating a hash digest from streaming data. The `DigestStream` itself is a `WritableStream` that does not retain the data written into it; instead, it generates a digest hash automatically when the flow of data has ended. The same hash algorithms supported by `crypto.subtle.digest()` are supported by the `crypto.DigestStream`.\n* Added early support for the `scheduler.wait()` API, which is [going through the WICG standardization process](https://github.com/WICG/scheduling-apis), to provide an `await`-able alternative to `setTimeout()`.\n* Fixed bug in `deleteAll` in Durable Objects containing more than 10000 keys that could sometimes cause incomplete data deletion and/or hangs.\n\n* The Streams spec requires that methods returning promises must not throw synchronous errors. As part of the effort of making the Streams implementation more spec compliant, we are converting a number of sync throws to async rejections.\n* Major V8 update: 9.6 → 9.7. See [V8 release v9.7 · V8](https://v8.dev/blog/v8-release-97) for more details.\n\n* Durable Object stubs that receive an overload exception will be permanently broken to match the behavior of other exception types.\n* Fixed issue where preview service claimed Let’s Encrypt certificates were expired.\n* [`structuredClone()`](https://developer.mozilla.org/en-US/docs/Web/API/structuredClone) is now supported.\n\n* The `AbortSignal` object has a new `reason` property indicating the reason for the cancellation. The reason can be specified when the `AbortSignal` is triggered or created.\n* Unhandled rejection warnings will be printed to the inspector console.\n\n* Upgrade to V8 9.6. This adds support for WebAssembly reference types. Refer to the [V8 release v9.6 · V8](https://v8.dev/blog/v8-release-96) for more details.\n* Streams: When using the BYOB reader, the `ArrayBuffer` of the provided TypedArray should be detached, per the Streams spec. Because Workers was not previously enforcing that rule, and changing to comply with the spec could breaking existing code, a new compatibility flag, [streams\\_byob\\_reader\\_detaches\\_buffer](https://github.com/cloudflare/cloudflare-docs/pull/2644), has been introduced that will be enabled by default on 2021-11-10. User code should never try to reuse an `ArrayBuffer` that has been passed in to a BYOB readers `read()` method. The more recently added extension method `readAtLeast()` will always detach the `ArrayBuffer` and is unaffected by the compatibility flag setting.\n\n* Added support for the `signal` option in `EventTarget.addEventListener()`, to remove an event listener in response to an `AbortSignal`.\n* The `unhandledrejection` and `rejectionhandled` events are now supported.\n* The `ReadableStreamDefaultReader` and `ReadableStreamBYOBReader` constructors are now supported.\n* Added non-standard `ReadableStreamBYOBReader` method `.readAtLeast(size, buffer)` that can be used to return a buffer with at least `size` bytes. The `buffer` parameter must be an `ArrayBufferView`. Behavior is identical to `.read()` except that at least `size` bytes are read, only returning fewer if EOF is encountered. One final call to `.readAtLeast()` is still needed to get back a `done = true` value.\n* The compatibility flags `formdata_parser_supports_files`, `fetch_refuses_unknown_protocols`, and `durable_object_fetch_requires_full_url` have been scheduled to be turned on by default as of 2021-11-03, 2021-11-10, and 2021-11-10, respectively. For more details, refer to [Compatibility Dates](https://developers.cloudflare.com/workers/configuration/compatibility-dates/)\n\n* `request.signal` will always return an `AbortSignal`.\n* Cloudflare Workers’ integration with Chrome DevTools profiling now more accurately reports the line numbers and time elapsed. Previously, the line numbers were shown as one line later then the actual code, and the time shown would be proportional but much longer than the actual time used.\n* Upgrade to v8 9.5. Refer to [V8 release v9.5 · V8](https://v8.dev/blog/v8-release-95) for more details.\n\n* The `AbortController` and `AbortSignal` objects are now available.\n* The Web Platform `queueMicrotask` API is now available.\n* It is now possible to use new `EventTarget()` and to create custom `EventTarget` subclasses.\n* The `once` option is now supported on `addEventTarget` to register event handlers that will be invoked only once.\n* Per the HTML specification, a listener passed in to the `addEventListener` function is allowed to either be a function or an object with a `handleEvent` member function. Previously, Workers only supported the function option, now it supports both.\n* The `Event` object now supports most standard methods and properties.\n* V8 updated from 9.3 to 9.4.\n\n* The `crypto.randomUUID()` method can be used to generate a new random version 4 UUID.\n* Durable Objects are now scheduled more evenly around a colocation (colo).\n\n* No user-facing changes. Just bug fixes & internal maintenance.\n\n* Fixed a hang in Durable Objects when reading more than 16MB of data at once (for example, with a large `list()` operation).\n* Added a new compatibility flag `html_rewriter_treats_esi_include_as_void_tag` which causes `HTMLRewriter` to treat `<esi:include>` and `<esi:comment>` as void tags, such that they are considered to have neither an end tag nor nested content. To opt a worker into the new behavior, you must use Wrangler v1.19.0 or newer and specify the flag in `wrangler.toml`. Refer to the [Wrangler compatibility flag notes](https://github.com/cloudflare/wrangler-legacy/pull/2009) for details.\n\n* Performance and stability improvements.\n\n* Workers can now make up to 1000 subrequests to Durable Objects from a within a single request invocation, up from the prior limit of 50.\n* Major changes to Durable Objects implementation, the details of which will be the subject of an upcoming blog post. In theory, the changes should not harm existing apps, except to make them faster. Let your account team know if you observe anything unusual or report your issue in the [Workers Discord](https://discord.cloudflare.com).\n* Durable Object constructors may now initiate I/O, such as `fetch()` calls.\n* Added Durable Objects `state.blockConcurrencyWhile()` API useful for delaying delivery of requests and other events while performing some critical state-affecting task. For example, this can be used to perform start-up initialization in an object’s constructor.\n* In Durable Objects, the callback passed to `storage.transaction()` can now return a value, which will be propagated as the return value of the `transaction()` call.\n\n* The preview service now prints a warning in the devtools console when a script uses `Response/Request.clone()` but does not read one of the cloned bodies. Such a situation forces the runtime to buffer the entire message body in memory, which reduces performance. [Find an example here](https://cloudflareworkers.com/#823fbe463bfafd5a06bcfeabbdf5eeae:https://tutorial.cloudflareworkers.com).\n\n* Fixed bug where registering the same exact event listener method twice on the same event type threw an internal error.\n* Add support for the `.forEach()` method for `Headers`, `URLSearchParameters`, and `FormData`.\n\n* WebCrypto: Implemented non-standard Ed25519 operation (algorithm NODE-ED25519, curve name NODE-ED25519). The Ed25519 implementation differs from NodeJS’s in that raw import/export of private keys is disallowed, per parity with ECDSA/ECDH.\n\n* Updated V8 from 9.1 to 9.2.\n* `wrangler tail` now works on Durable Objects. Note that logs from long-lived WebSockets will not be visible until the WebSocket is closed.\n\n* Turn on V8 Sparkplug compiler.\n* Durable Objects that are finishing up existing requests after their code is updated will be disconnected from the persistent storage API, to maintain the invariant that only a single instance ever has access to persistent storage for a given Durable Object.\n\n* WebCrypto: We now support the “raw” import/export format for ECDSA/ECDH public keys.\n* `request.cf` is no longer missing when writing Workers using modules syntax.\n\n* Improve error messages coming from the WebCrypto API.\n* Updated V8: 9.0 → 9.1\n\nChanges in an earlier release:\n\n* WebCrypto: Implement JWK export for RSA, ECDSA, & ECDH.\n* WebCrypto: Add support for RSA-OAEP\n* WebCrypto: HKDF implemented.\n* Fix recently-introduced backwards clock jumps in Durable Objects.\n* `WebCrypto.generateKey()`, when asked to generate a key pair with algorithm RSA-PSS, would instead return a key pair using algorithm RSASSA-PKCS1-v1\\_5. Although the key structure is the same, the signature algorithms differ, and therefore, signatures generated using the key would not be accepted by a correct implementation of RSA-PSS, and vice versa. Since this would be a pretty obvious problem, but no one ever reported it to us, we guess that currently, no one is using this functionality on Workers.\n\n* WebCrypto: Implemented `wrapKey()` / `unwrapKey()` for AES algorithms.\n* The arguments to `WebSocket.close()` are now optional, as the standard says they should be.\n\n* In the WebCrypto API, encrypt and decrypt operations are now supported for the “AES-CTR” encryption algorithm.\n* For Durable Objects, CPU time limits are now enforced on the object level rather than the request level. Each time a new request arrives, the time limit is “topped up” to 500ms. After the (free) beta period ends and Durable Objects becomes generally available, we will increase this to 30 seconds.\n* When a Durable Object exceeds its CPU time limit, the entire object will be discarded and recreated. Previously, we allowed subrequest requests to continue using the same object, but this was dangerous because hitting the CPU time limit can leave the object in an inconsistent state.\n* Long running Durable Objects are given more subrequest quota as additional WebSocket messages are sent to them, to avoid the problem of a long-running Object being unable to make any more subrequests after it has been held open by a particular WebSocket for a while.\n* When a Durable Object’s code is updated, or when its isolate is reset due to exceeding the memory limit, all stubs pointing to the object will become invalidated and have to be recreated. This is consistent with what happens when the CPU time is exceeded, or when stubs become disconnected due to random network errors. This behavior is useful, as apps can now assume that two messages sent to the same stub will be delivered to exactly the same live instance (if they are delivered at all). Apps which do not care about this property should recreate their stubs for every request; there is no performance penalty from doing so.\n* When a Durable Object’s isolate exceeds its memory limit, an exception with an explanatory message will now be thrown to the caller, instead of “internal error”.\n* When a Durable Object exceeds its CPU time limit, an exception with an explanatory message will now be thrown to the caller, instead of “internal error”.\n* `wrangler tail` now reports CPU-time-exceeded exceptions with an explanatory message instead of “internal error”.\n\nChanges since the last post on 3/26:\n\n* Cron Triggers now have a 15 minute wall time limit, in addition to the existing CPU time limit. (Previously, there was no limit, so a cron trigger that spent all its time waiting for I/O could hang forever.)\n* Our WebCrypto implementation now supports importing and exporting HMAC and AES keys in JWK format.\n* Our WebCrypto implementation now supports AES key generation for CTR, CBC, and KW modes. AES-CTR encrypt/decrypt and AES-KW key wrapping/unwrapping support will land in a later release.\n* Fixed bug where `crypto.subtle.encrypt()` on zero-length inputs would sometimes throw an exception.\n* Errors on script upload will now be properly reported for module-based scripts, instead of appearing as a ReferenceError.\n* WebCrypto: Key derivation for ECDH.\n* WebCrypto: Support ECDH key generation & import.\n* WebCrypto: Support ECDSA key generation.\n* Fixed bug where `crypto.subtle.encrypt()` on zero-length inputs would sometimes throw an exception.\n* Improved exception messages thrown by the WebCrypto API somewhat.\n* `waitUntil` is now supported for module Workers. An additional argument called ‘ctx’ is passed after ‘env’, and `waitUntil` is a method on ‘ctx’.\n* `passThroughOnException` is now available under the ctx argument to module handlers\n* Reliability improvements for Durable Objects\n* Reliability improvements for Durable Objects persistent storage API\n* `ScheduledEvent.cron` is now set to the original cron string that the event was scheduled for.\n\n* Existing WebSocket connections to Durable Objects will now be forcibly disconnected on code updates, in order to force clients to connect to the instance running the new code.\n\n* When the Workers Runtime itself reloads due to us deploying a new version or config change, we now preload high-traffic Workers in the new instance of the runtime before traffic cuts over. This ensures that users do not observe cold starts for these Workers due to the upgrade, and also fixes a low rate of spurious 503 errors that we had previously been seeing due to overload during such reloads.\n\n(It looks like no release notes were posted the last few weeks, but there were no new user-visible changes to report.)\n\n* In the preview mode of the dashboard, a Worker that fails during startup will now return a 500 response, rather than getting the default passthrough behavior, which was making it harder to notice when a Worker was failing.\n* A Durable Object’s ID is now provided to it in its constructor. It can be accessed off of the `state` provided as the constructor’s first argument, as in `state.id`.\n\n* V8 has been updated from 8.8 to 8.9.\n* During a `fetch()`, if the destination server commits certain HTTP protocol errors, such as returning invalid (unparsable) headers, we now throw an exception whose description explains the problem, rather than an “internal error”.\n\nNew last week (forgot to post):\n\n* Added support for `waitUntil()` in Durable Objects. It is a method on the state object passed to the Durable Object class’s constructor.\n\nNew in the past week:\n\n* Fixed a bug which caused scripts with WebAssembly modules to hang when using devtools in the preview service.\n\n* Implemented File and Blob APIs, which can be used when constructing FormData in outgoing requests. Unfortunately, FormData from incoming requests at this time will still use strings even when file metadata was present, in order to avoid breaking existing deployed Workers. We will find a way to fix that in the future.\n\n* No user-visible changes.\n\nChanges in the prior release:\n\n* Fixed delivery of WebSocket “error” events.\n* Fixed a rare bug where a WritableStream could be garbage collected while it still had writes queued, causing those writes to be lost.\n\n* Major V8 update: 8.7.220.29 -> 8.8.278.8\n\n* Unannounced new feature. (Stay tuned.)\n* Enforced new limit on concurrent subrequests (see below).\n* Stability improvements.\n\n**Concurrent Subrequest Limit**\n\nAs of this release, we impose a limit on the number of outgoing HTTP requests that a Worker can make simultaneously. **For each incoming request**, a Worker can make up to 6 concurrent outgoing `fetch()` requests.\n\nIf a Worker’s request handler attempts to call `fetch()` more than six times (on behalf of a single incoming request) without waiting for previous fetches to complete, then fetches after the sixth will be delayed until previous fetches have finished. A Worker is still allowed to make up to 50 total subrequests per incoming request, as before; the new limit is only on how many can execute simultaneously.\n\n**Automatic deadlock avoidance**\n\nOur implementation automatically detects if delaying a fetch would cause the Worker to deadlock, and prevents the deadlock by cancelling the least-recently-used request. For example, imagine a Worker that starts 10 requests and waits to receive all the responses without reading the response bodies. A fetch is not considered complete until the response body is fully-consumed (for example, by calling `response.text()` or `response.json()`, or by reading from `response.body`). Therefore, in this scenario, the first six requests will run and their response objects would be returned, but the remaining four requests would not start until the earlier responses are consumed. If the Worker fails to actually read the earlier response bodies and is still waiting for the last four requests, then the Workers Runtime will automatically cancel the first four requests so that the remaining ones can complete. If the Worker later goes back and tries to read the response bodies, exceptions will be thrown.\n\n**Most Workers are Not Affected**\n\nThe vast majority of Workers make fewer than six outgoing requests per incoming request. Such Workers are totally unaffected by this change.\n\nOf Workers that do make more than six outgoing requests concurrently for a single incoming request, the vast majority either read the response bodies immediately upon each response returning, or never read the response bodies at all. In either case, these Workers will still work as intended – although they may be a little slower due to outgoing requests after the sixth being delayed.\n\nA very small number of deployed Workers (about 20 total) make more than 6 requests concurrently, wait for all responses to return, and then go back to read the response bodies later. For all known Workers that do this, we have temporarily grandfathered your zone into the old behavior, so that your Workers will continue to operate. However, we will be communicating with customers one-by-one to request that you update your code to proactively read request bodies, so that it works correctly under the new limit.\n\n**Why did we do this?**\n\nCloudflare communicates with origin servers using HTTP/1.1, not HTTP/2. Under HTTP/1.1, each concurrent request requires a separate connection. So, Workers that make many requests concurrently could force the creation of an excessive number of connections to origin servers. In some cases, this caused resource exhaustion problems either at the origin server or within our own stack.\n\nOn investigating the use cases for such Workers, every case we looked at turned out to be a mistake or otherwise unnecessary. Often, developers were making requests and receiving responses, but they only cared about the response status and headers but not the body. So, they threw away the response objects without reading the body, essentially leaking connections. In some other cases, developers had simply accidentally written code that made excessive requests in a loop for no good reason at all. Both of these cases should now cause no problems under the new behavior.\n\nWe chose the limit of 6 concurrent connections based on the fact that Chrome enforces the same limit on web sites in the browser.\n\n* Durable Objects storage API now supports listing keys by prefix.\n* Improved error message when a single request performs more than 1000 KV operations to make clear that a per-request limit was reached, not a global rate limit.\n* `wrangler dev` previews should now honor non-default resource limits, for example, longer CPU limits for those in the Workers Unbound beta.\n* Fixed off-by-one line numbers in Worker exceptions.\n* Exceptions thrown in a Durable Object’s `fetch()` method are now tunneled to its caller.\n* Fixed a bug where a large Durable Object response body could cause the Durable Object to become unresponsive.\n\nChanges over the past week:\n\n* `ReadableStream.cancel()` and `ReadableStream.getReader().cancel()` now take an optional, instead of a mandatory, argument, to conform with the Streams spec.\n* Fixed an error that occurred when a WASM module declared that it wanted to grow larger than 128MB. Instead, the actual memory usage of the module is monitored and an error is thrown if it exceeds 128MB used.\n\n* Major V8 update: 8.6 -> 8.7\n* Limit the maximum number of Durable Objects keys that can be changed in a single transaction to 128.\n\nWe had our usual weekly release last week, but:\n\n* No user-visible changes.\n\n* Internal changes to support upcoming features.\n\nAlso, a change from the 2020-09-08 release that it seems we forgot to post:\n\n* V8 major update: 8.5 -> 8.6\n\n* Fixed a regression which could cause `HTMLRewriter.transform()` to throw spurious “The parser has stopped.” errors.\n* Upgraded V8 from 8.4 to 8.5.\n\n* Fixed a regression in HTMLRewriter: <https://github.com/cloudflare/lol-html/issues/50>\n* Common HTTP method names passed to `fetch()` or `new Request()` are now case-insensitive as required by the Fetch API spec.\n\nChanges last week (… forgot to post):\n\n* `setTimeout`/`setInterval` can now take additional arguments which will be passed on to the callback, as required by the spec. (Few people use this feature today because it’s usually much easier to use lambda captures.)\n\nChanges the week before last (… also… forgot to post… we really need to code up a bot for this):\n\n* The HTMLRewriter now supports the `:nth-child` , `:first-child` , `:nth-of-type` , and `:first-of-type` selectors.\n\n* Implemented API for yet-to-be-announced new feature.\n\nLooks like we forgot to post release notes for a couple weeks. Releases still are happening weekly as always, but the “post to the community” step is insufficiently automated… 4/2 release:\n\n* Fixed a source of long garbage collection paused in memory limit enforcement.\n\n* No publicly-visible changes.\n\n* In preview, we now log a warning when attempting to construct a `Request` or `Response` whose body is of type `FormData` but with the `Content-Type` header overridden. Such bodies would not be parseable by the receiver.\n\n* Certain “internal errors” that could be thrown when using the Cache API are now reported with human-friendly error messages. For example, `caches.default.match(\"not a URL\")` now throws a TypeError.\n\nNew from the past two weeks:\n\n* Fixed a bug in the preview service where the CPU time limiter was overly lenient for the first several requests handled by a newly-started worker. The same bug actually exists in production as well, but we are much more cautious about fixing it there, since doing so might break live sites. If you find your worker now exceeds CPU time limits in preview, then it is likely exceeding time limits in production as well, but only appearing to work because the limits are too lenient for the first few requests. Such Workers will eventually fail in production, too (and always have), so it is best to fix the problem in preview before deploying.\n* Major V8 update: 8.0 -> 8.1\n* Minor bug fixes.\n\nChanges over the last couple weeks:\n\n* Fixed a bug where if two differently-named scripts within the same account had identical content and were deployed to the same zone, they would be treated as the “same Worker”, meaning they would share the same isolate and global variables. This only applied between Workers on the same zone, so was not a security threat, but it caused confusion. Now, two differently-named Worker scripts will never be considered the same Worker even if they have identical content.\n* Performance and stability improvements.\n\nIt has been a while since we posted release notes, partly due to the holidays. Here is what is new over the past month:\n\n* Performance and stability improvements.\n* A rare source of `daemonDown` errors when processing bursty traffic over HTTP/2 has been eliminated.\n* Updated V8 7.9 -> 8.0.\n\n* We now pass correct line and column numbers more often when reporting exceptions to the V8 inspector. There remain some cases where the reported line and column numbers will be wrong.\n* Fixed a significant source of daemonDown (1105) errors.\n\nRuntime release notes covering the past few weeks:\n\n* Increased total per-request `Cache.put()` limit to 5GiB.\n* Increased individual `Cache.put()` limits to the lesser of 5GiB or the zone’s normal [cache limits](https://developers.cloudflare.com/cache/concepts/default-cache-behavior/).\n* Added a helpful error message explaining AES decryption failures.\n* Some overload errors were erroneously being reported as daemonDown (1105) errors. They have been changed to exceededCpu (1102) errors, which better describes their cause.\n* More “internal errors” were converted to useful user-facing errors.\n* Stability improvements and bug fixes.\n\n<page>\n---\ntitle: Wrangler · Cloudflare Workers docs\nlastUpdated: 2025-03-27T15:46:34.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/platform/changelog/wrangler/\n  md: https://developers.cloudflare.com/workers/platform/changelog/wrangler/index.md\n---\n\n<page>\n---\ntitle: AI · Cloudflare Workers docs\ndescription: Run generative AI inference and machine learning models on GPUs,\n  without managing servers or infrastructure.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/ai/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/ai/index.md\n---\n\n<page>\n---\ntitle: Analytics Engine · Cloudflare Workers docs\ndescription: Write high-cardinality data and metrics at scale, directly from Workers.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/analytics-engine/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/analytics-engine/index.md\n---\n\n<page>\n---\ntitle: Assets · Cloudflare Workers docs\ndescription: APIs available in Cloudflare Workers to interact with a collection\n  of static assets. Static assets can be uploaded as part of your Worker.\nlastUpdated: 2024-09-26T06:18:51.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/assets/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/assets/index.md\n---\n\n<page>\n---\ntitle: Browser Rendering · Cloudflare Workers docs\ndescription: Programmatically control and interact with a headless browser instance.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/browser-rendering/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/browser-rendering/index.md\n---\n\n<page>\n---\ntitle: D1 · Cloudflare Workers docs\ndescription: APIs available in Cloudflare Workers to interact with D1.  D1 is\n  Cloudflare's native serverless database.\nlastUpdated: 2024-12-11T09:43:45.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/d1/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/d1/index.md\n---\n\n<page>\n---\ntitle: Dispatcher (Workers for Platforms) · Cloudflare Workers docs\ndescription: Let your customers deploy their own code to your platform, and\n  dynamically dispatch requests from your Worker to their Worker.\nlastUpdated: 2025-12-29T17:29:32.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/dispatcher/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/dispatcher/index.md\n---\n\n<page>\n---\ntitle: Durable Objects · Cloudflare Workers docs\ndescription: A globally distributed coordination API with strongly consistent storage.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/durable-objects/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/durable-objects/index.md\n---\n\n<page>\n---\ntitle: Environment Variables · Cloudflare Workers docs\ndescription: Add string and JSON values to your Worker.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/environment-variables/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/environment-variables/index.md\n---\n\n<page>\n---\ntitle: Hyperdrive · Cloudflare Workers docs\ndescription: Connect to your existing database from Workers, turning your\n  existing regional database into a globally distributed database.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/hyperdrive/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/hyperdrive/index.md\n---\n\n<page>\n---\ntitle: Images · Cloudflare Workers docs\ndescription: Store, transform, optimize, and deliver images at scale.\nlastUpdated: 2025-03-27T15:34:04.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/images/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/images/index.md\n---\n\n<page>\n---\ntitle: KV · Cloudflare Workers docs\ndescription: Global, low-latency, key-value data storage.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/kv/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/kv/index.md\n---\n\n<page>\n---\ntitle: mTLS · Cloudflare Workers docs\ndescription: Configure your Worker to present a client certificate to services\n  that enforce an mTLS connection.\nlastUpdated: 2025-02-11T10:50:09.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/mtls/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/mtls/index.md\n---\n\nWhen using [HTTPS](https://www.cloudflare.com/learning/ssl/what-is-https/), a server presents a certificate for the client to authenticate in order to prove their identity. For even tighter security, some services require that the client also present a certificate.\n\nThis process - known as [mTLS](https://www.cloudflare.com/learning/access-management/what-is-mutual-tls/) - moves authentication to the protocol of TLS, rather than managing it in application code. Connections from unauthorized clients are rejected during the TLS handshake instead.\n\nTo present a client certificate when communicating with a service, create a mTLS certificate [binding](https://developers.cloudflare.com/workers/runtime-apis/bindings/) in your Worker project's Wrangler file. This will allow your Worker to present a client certificate to a service on your behalf.\n\nCurrently, mTLS for Workers cannot be used for requests made to a service that is a [proxied zone](https://developers.cloudflare.com/dns/proxy-status/) on Cloudflare. If your Worker presents a client certificate to a service proxied by Cloudflare, Cloudflare will return a `520` error.\n\nFirst, upload a certificate and its private key to your account using the [`wrangler mtls-certificate`](https://developers.cloudflare.com/workers/wrangler/commands/#mtls-certificate) command:\n\nThe `wrangler mtls-certificate upload` command requires the [SSL and Certificates Edit API token scope](https://developers.cloudflare.com/fundamentals/api/reference/permissions/). If you are using the OAuth flow triggered by `wrangler login`, the correct scope is set automatically. If you are using API tokens, refer to [Create an API token](https://developers.cloudflare.com/fundamentals/api/get-started/create-token/) to set the right scope for your API token.\n\nThen, update your Worker project's Wrangler file to create an mTLS certificate binding:\n\nCertificate IDs are displayed after uploading, and can also be viewed with the command `wrangler mtls-certificate list`.\n\nAdding an mTLS certificate binding includes a variable in the Worker's environment on which the `fetch()` method is available. This `fetch()` method uses the standard [Fetch](https://developers.cloudflare.com/workers/runtime-apis/fetch/) API and has the exact same signature as the global `fetch`, but always presents the client certificate when establishing the TLS connection.\n\nmTLS certificate bindings present an API similar to [service bindings](https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings).\n\n<page>\n---\ntitle: Queues · Cloudflare Workers docs\ndescription: Send and receive messages with guaranteed delivery.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/queues/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/queues/index.md\n---\n\n<page>\n---\ntitle: R2 · Cloudflare Workers docs\ndescription: APIs available in Cloudflare Workers to read from and write to R2\n  buckets.  R2 is S3-compatible, zero egress-fee, globally distributed object\n  storage.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/r2/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/r2/index.md\n---\n\n<page>\n---\ntitle: Rate Limiting · Cloudflare Workers docs\ndescription: Define rate limits and interact with them directly from your Cloudflare Worker\nlastUpdated: 2025-10-09T19:29:09.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/rate-limit/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/rate-limit/index.md\n---\n\nThe Rate Limiting API lets you define rate limits and write code around them in your Worker.\n\nYou can use it to enforce:\n\n* Rate limits that are applied after your Worker starts, only once a specific part of your code is reached\n* Different rate limits for different types of customers or users (ex: free vs. paid)\n* Resource-specific or path-specific limits (ex: limit per API route)\n* Any combination of the above\n\nThe Rate Limiting API is backed by the same infrastructure that serves [rate limiting rules](https://developers.cloudflare.com/waf/rate-limiting-rules/).\n\nYou must use version 4.36.0 or later of the [Wrangler CLI](https://developers.cloudflare.com/workers/wrangler).\n\nFirst, add a [binding](https://developers.cloudflare.com/workers/runtime-apis/bindings) to your Worker that gives it access to the Rate Limiting API:\n\nThis binding makes the `MY_RATE_LIMITER` binding available, which provides a `limit()` method:\n\nThe `limit()` API accepts a single argument — a configuration object with the `key` field.\n\n* The key you provide can be any `string` value.\n* A common pattern is to define your key by combining a string that uniquely identifies the actor initiating the request (ex: a user ID or customer ID) and a string that identifies a specific resource (ex: a particular API route).\n\nYou can define and configure multiple rate limiting configurations per Worker, which allows you to define different limits against incoming request and/or user parameters as needed to protect your application or upstream APIs.\n\nFor example, here is how you can define two rate limiting configurations for free and paid tier users:\n\nA rate limiting binding has three settings:\n\n1. `namespace_id` (number) - a positive integer that uniquely defines this rate limiting configuration - e.g. `namespace_id = \"999\"`.\n2. `limit` (number) - the limit (number of requests, number of API calls) to be applied. This is incremented when you call the `limit()` function in your Worker.\n3. `period` (seconds) - must be `10` or `60`. The period to measure increments to the `limit` over, in seconds.\n\nFor example, to apply a rate limit of 1500 requests per minute, you would define a rate limiting configuration as follows:\n\nThe `key` passed to the `limit` function, that determines what to rate limit on, should represent a unique characteristic of a user or class of user that you wish to rate limit.\n\n* Good choices include API keys in `Authorization` HTTP headers, URL paths or routes, specific query parameters used by your application, and/or user IDs and tenant IDs. These are all stable identifiers and are unlikely to change from request-to-request.\n* It is not recommended to use IP addresses or locations (regions or countries), since these can be shared by many users in many valid cases. You may find yourself unintentionally rate limiting a wider group of users than you intended by rate limiting on these keys.\n\nRate limits that you define and enforce in your Worker are local to the [Cloudflare location](https://www.cloudflare.com/network/) that your Worker runs in.\n\nFor example, if a request comes in from Sydney, Australia, to the Worker shown above, after 100 requests in a 60 second window, any further requests for a particular path would be rejected, and a 429 HTTP status code returned. But this would only apply to requests served in Sydney. For each unique key you pass to your rate limiting binding, there is a unique limit per Cloudflare location.\n\nThe Rate Limiting API in Workers is designed to be fast.\n\nThe underlying counters are cached on the same machine that your Worker runs in, and updated asynchronously in the background by communicating with a backing store that is within the same Cloudflare location.\n\nThis means that while in your code you `await` a call to the `limit()` method:\n\nYou are not waiting on a network request. You can use the Rate Limiting API without introducing any meaningful latency to your Worker.\n\nThe above also means that the Rate Limiting API is permissive, eventually consistent, and intentionally designed to not be used as an accurate accounting system.\n\nFor example, if many requests come in to your Worker in a single Cloudflare location, all rate limited on the same key, the [isolate](https://developers.cloudflare.com/workers/reference/how-workers-works) that serves each request will check against its locally cached value of the rate limit. Very quickly, but not immediately, these requests will count towards the rate limit within that Cloudflare location.\n\n* [`@elithrar/workers-hono-rate-limit`](https://github.com/elithrar/workers-hono-rate-limit) — Middleware that lets you easily add rate limits to routes in your [Hono](https://hono.dev/) application.\n* [`@hono-rate-limiter/cloudflare`](https://github.com/rhinobase/hono-rate-limiter) — Middleware that lets you easily add rate limits to routes in your [Hono](https://hono.dev/) application, with multiple data stores to choose from.\n* [`hono-cf-rate-limit`](https://github.com/bytaesu/hono-cf-rate-limit) — Middleware for Hono applications that applies rate limiting in Cloudflare Workers, powered by Wrangler’s built-in features.\n\n<page>\n---\ntitle: Secrets · Cloudflare Workers docs\ndescription: Add encrypted secrets to your Worker.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/secrets/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/secrets/index.md\n---\n\n<page>\n---\ntitle: Secrets Store · Cloudflare Workers docs\ndescription: Account-level secrets that can be added to Workers applications as a binding.\nlastUpdated: 2025-06-20T13:44:20.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/secrets-store/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/secrets-store/index.md\n---\n\n<page>\n---\ntitle: Service bindings - Runtime APIs · Cloudflare Workers docs\ndescription: Facilitate Worker-to-Worker communication.\nlastUpdated: 2025-09-23T20:48:09.000Z\nchatbotDeprioritize: false\ntags: Bindings\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings/index.md\n---\n\n## About Service bindings\n\nService bindings allow one Worker to call into another, without going through a publicly-accessible URL. A Service binding allows Worker A to call a method on Worker B, or to forward a request from Worker A to Worker B.\n\nService bindings provide the separation of concerns that microservice or service-oriented architectures provide, without configuration pain, performance overhead or need to learn RPC protocols.\n\n* **Service bindings are fast.** When you use Service Bindings, there is zero overhead or added latency. By default, both Workers run on the same thread of the same Cloudflare server. And when you enable [Smart Placement](https://developers.cloudflare.com/workers/configuration/smart-placement/), each Worker runs in the optimal location for overall performance.\n* **Service bindings are not just HTTP.** Worker A can expose methods that can be directly called by Worker B. Communicating between services only requires writing JavaScript methods and classes.\n* **Service bindings don't increase costs.** You can split apart functionality into multiple Workers, without incurring additional costs. Learn more about [pricing for Service Bindings](https://developers.cloudflare.com/workers/platform/pricing/#service-bindings).\n\n![Service bindings are a zero-cost abstraction](https://developers.cloudflare.com/_astro/service-bindings-comparison.CeB5uD1k_Z2t71S1.webp)\n\nService bindings are commonly used to:\n\n* **Provide a shared internal service to multiple Workers.** For example, you can deploy an authentication service as its own Worker, and then have any number of separate Workers communicate with it via Service bindings.\n* **Isolate services from the public Internet.** You can deploy a Worker that is not reachable via the public Internet, and can only be reached via an explicit Service binding that another Worker declares.\n* **Allow teams to deploy code independently.** Team A can deploy their Worker on their own release schedule, and Team B can deploy their Worker separately.\n\nYou add a Service binding by modifying the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/) of the caller — the Worker that you want to be able to initiate requests.\n\nFor example, if you want Worker A to be able to call Worker B — you'd add the following to the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/) for Worker A:\n\n- `binding`: The name of the key you want to expose on the `env` object.\n- `service`: The name of the target Worker you would like to communicate with. This Worker must be on your Cloudflare account.\n\nWorker A that declares a Service binding to Worker B can call Worker B in two different ways:\n\n1. [RPC](https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings/rpc) lets you communicate between Workers using function calls that you define. For example, `await env.BINDING_NAME.myMethod(arg1)`. This is recommended for most use cases, and allows you to create your own internal APIs that your Worker makes available to other Workers.\n2. [HTTP](https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings/http) lets you communicate between Workers by calling the [`fetch()` handler](https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch) from other Workers, sending `Request` objects and receiving `Response` objects back. For example, `env.BINDING_NAME.fetch(request)`.\n\n## Example — build your first Service binding using RPC\n\nThis example [extends the `WorkerEntrypoint` class](https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings/rpc/#the-workerentrypoint-class) to support RPC-based Service bindings. First, create the Worker that you want to communicate with. Let's call this \"Worker B\". Worker B exposes the public method, `add(a, b)`:\n\nNext, create the Worker that will call Worker B. Let's call this \"Worker A\". Worker A declares a binding to Worker B. This is what gives it permission to call public methods on Worker B.\n\nTo run both Worker A and Worker B in local development, you must run two instances of [Wrangler](https://developers.cloudflare.com/workers/wrangler) in your terminal. For each Worker, open a new terminal and run [`npx wrangler@latest dev`](https://developers.cloudflare.com/workers/wrangler/commands#dev).\n\nEach Worker is deployed separately.\n\nThe Service bindings API is asynchronous — you must `await` any method you call. If Worker A invokes Worker B via a Service binding, and Worker A does not await the completion of Worker B, Worker B will be terminated early.\n\nFor more about the lifecycle of calling a Worker over a Service Binding via RPC, refer to the [RPC Lifecycle](https://developers.cloudflare.com/workers/runtime-apis/rpc/lifecycle) docs.\n\nLocal development is supported for Service bindings. For each Worker, open a new terminal and use [`wrangler dev`](https://developers.cloudflare.com/workers/wrangler/commands/#dev) in the relevant directory. When running `wrangler dev`, service bindings will show as `connected`/`not connected` depending on whether Wrangler can find a running `wrangler dev` session for that Worker. For example:\n\nWrangler also supports running multiple Workers at once with one command. To try it out, pass multiple `-c` flags to Wrangler, like this: `wrangler dev -c wrangler.json -c ../other-worker/wrangler.json`. The first config will be treated as the *primary* worker, which will be exposed over HTTP as usual at `http://localhost:8787`. The remaining config files will be treated as *secondary* and will only be accessible via a service binding from the primary worker.\n\nSupport for running multiple Workers at once with one Wrangler command is experimental, and subject to change as we work on the experience. If you run into bugs or have any feedback, [open an issue on the workers-sdk repository](https://github.com/cloudflare/workers-sdk/issues/new)\n\nWorkers using Service bindings are deployed separately.\n\nWhen getting started and deploying for the first time, this means that the target Worker (Worker B in the examples above) must be deployed first, before Worker A. Otherwise, when you attempt to deploy Worker A, deployment will fail, because Worker A declares a binding to Worker B, which does not yet exist.\n\nWhen making changes to existing Workers, in most cases you should:\n\n* Deploy changes to Worker B first, in a way that is compatible with the existing Worker A. For example, add a new method to Worker B.\n* Next, deploy changes to Worker A. For example, call the new method on Worker B, from Worker A.\n* Finally, remove any unused code. For example, delete the previously used method on Worker B.\n\n[Smart Placement](https://developers.cloudflare.com/workers/configuration/smart-placement) automatically places your Worker in an optimal location that minimizes latency.\n\nYou can use Smart Placement together with Service bindings to split your Worker into two services:\n\n![Smart Placement and Service Bindings](https://developers.cloudflare.com/_astro/smart-placement-service-bindings.Ce58BYeF_1YYSoG.webp)\n\nRefer to the [docs on Smart Placement](https://developers.cloudflare.com/workers/configuration/smart-placement/#best-practices) for more.\n\nService bindings have the following limits:\n\n* Each request to a Worker via a Service binding counts toward your [subrequest limit](https://developers.cloudflare.com/workers/platform/limits/#subrequests).\n* A single request has a maximum of 32 Worker invocations, and each call to a Service binding counts towards this limit. Subsequent calls will throw an exception.\n* Calling a service binding does not count towards [simultaneous open connection limits](https://developers.cloudflare.com/workers/platform/limits/#simultaneous-open-connections)\n\n<page>\n---\ntitle: Vectorize · Cloudflare Workers docs\ndescription: APIs available in Cloudflare Workers to interact with\n  Vectorize.  Vectorize is Cloudflare's globally distributed vector database.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/vectorize/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/vectorize/index.md\n---\n\n<page>\n---\ntitle: Version metadata binding · Cloudflare Workers docs\ndescription: Exposes Worker version metadata (`versionID` and `versionTag`).\n  These fields can be added to events emitted from the Worker to send to\n  downstream observability systems.\nlastUpdated: 2025-01-29T12:28:42.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/version-metadata/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/version-metadata/index.md\n---\n\nThe version metadata binding can be used to access metadata associated with a [version](https://developers.cloudflare.com/workers/configuration/versions-and-deployments/#versions) from inside the Workers runtime.\n\nWorker version ID, version tag and timestamp of when the version was created are available through the version metadata binding. They can be used in events sent to [Workers Analytics Engine](https://developers.cloudflare.com/analytics/analytics-engine/) or to any third-party analytics/metrics service in order to aggregate by Worker version.\n\nTo use the version metadata binding, update your Worker's Wrangler file:\n\nAn example of how to access the version ID and version tag from within a Worker to send events to [Workers Analytics Engine](https://developers.cloudflare.com/analytics/analytics-engine/):\n\n<page>\n---\ntitle: Dynamic Worker Loaders · Cloudflare Workers docs\ndescription: The Dynamic Worker Loader API, which allows dynamically spawning\n  isolates that run arbitrary code.\nlastUpdated: 2025-12-08T17:58:00.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/worker-loader/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/worker-loader/index.md\n---\n\nDynamic Worker Loading is in closed beta\n\nThe Worker Loader API is available in local development with Wrangler and workerd. But to run dynamic Workers on Cloudflare, you must [sign up for the closed beta](https://forms.gle/MoeDxE9wNiqdf8ri9).\n\nA Worker Loader binding allows you to load additional Workers containing arbitrary code at runtime.\n\nAn isolate is like a lightweight container. [The Workers platform uses isolates instead of containers or VMs](https://developers.cloudflare.com/workers/reference/how-workers-works/), so every Worker runs in an isolate already. But, a Worker Loader binding allows your Worker to create additional isolates that load arbitrary code on-demand.\n\nIsolates are much cheaper than containers. You can start an isolate in milliseconds, and it's fine to start one just to run a snippet of code and immediately throw away. There's no need to worry about pooling isolates or trying to reuse already-warm isolates, as you would need to do with containers.\n\nWorker Loaders also enable **sandboxing** of code, meaning that you can strictly limit what the code is allowed to do. In particular:\n\n* You can arrange to intercept or simply block all network requests made by the Worker within.\n* You can supply the sandboxed Worker with custom bindings to represent specific resources which it should be allowed to access.\n\nWith proper sandboxing configured, you can safely run code you do not trust in a dynamic isolate.\n\nA Worker Loader is a binding with just one method, `get()`, which loads an isolate. Example usage:\n\nTo add a dynamic worker loader binding to your worker, add it to your Wrangler config like so:\n\n`get(id string, getCodeCallback () => Promise<WorkerCode>): WorkerStub`\n\nLoads a Worker with the given ID, returning a `WorkerStub` which may be used to invoke the Worker.\n\nAs a convenience, the loader implements caching of isolates. When a new ID is seen the first time, a new isolate is loaded. But, the isolate may be kept warm in memory for a while. If later invocations of the loader request the same ID, the existing isolate may be returned again, rather than create a new one. But there is no guarantee: a later call with the same ID may instead start a new isolate from scratch.\n\nWhenever the system determines it needs to start a new isolate, and it does not already have a copy of the code cached, it will invoke `codeCallback` to get the Worker's code. This is an async callback, so the application can load the code from remote storage if desired. The callback returns a `WorkerCode` object (described below).\n\nBecause of the caching, you should ensure that the callback always returns exactly the same content, when called for the same ID. If anything about the content changes, you must use a new ID. But if the content hasn't changed, it's best to reuse the same ID in order to take advantage of caching. If the `WorkerCode` is different every time, you can pass a random ID.\n\nYou could, for example, use IDs of the form `<worker-name>:<version-number>`, where the version number increments every time the code changes. Or, you could compute IDs based on a hash of the code and config, so that any change results in a new ID.\n\n`get()` returns a `WorkerStub`, which can be used to send requests to the loaded Worker. Note that the stub is returned synchronously—you do not have to await it. If the Worker is not loaded yet, requests made to the stub will wait for the Worker to load before being delivered. If loading fails, the request will throw an exception.\n\nIt is never guaranteed that two requests will go to the same isolate. Even if you use the same `WorkerStub` to make multiple requests, they could execute in different isolates. The callback passed to `loader.get()` could be called any number of times (although it is unusual for it to be called more than once).\n\nThis is the structure returned by `getCodeCallback` to represent a worker.\n\n#### `compatibilityDate string`\n\nThe [compatibility date](https://developers.cloudflare.com/workers/configuration/compatibility-dates/) for the Worker. This has the same meaning as the `compatibility_date` setting in a Wrangler config file.\n\n#### `compatibilityFlags string[] Optional`\n\nAn optional list of [compatibility flags](https://developers.cloudflare.com/workers/configuration/compatibility-flags) augmenting the compatibility date. This has the same meaning as the `compatibility_flags` setting in a Wrangler config file.\n\n#### `allowExperimental boolean Optional`\n\nIf true, then experimental compatibility flags will be permitted in `compatibilityFlags`. In order to set this, the worker calling the loader must itself have the compatibility flag `\"experimental\"` set. Experimental flags cannot be enabled in production.\n\n#### `mainModule string`\n\nThe name of the Worker's main module. This must be one of the modules listed in `modules`.\n\n#### `modules Record<string, string | Module>`\n\nA dictionary object mapping module names to their string contents. If the module content is a plain string, then the module name must have a file extension indicating its type: either `.js` or `.py`.\n\nA module's content can also be specified as an object, in order to specify its type independent from the name. The allowed objects are:\n\n* `{js: string}`: A JavaScript module, using ES modules syntax for imports and exports.\n* `{cjs: string}`: A CommonJS module, using `require()` syntax for imports.\n* `{py: string}`: A [Python module](https://developers.cloudflare.com/workers/languages/python/), but see the warning below.\n* `{text: string}`: An importable string value.\n* `{data: ArrayBuffer}`: An importable `ArrayBuffer` value.\n* `{json: object}`: An importable object. The value must be JSON-serializable. However, note that value is provided as a parsed object, and is delivered as a parsed object; neither side actually sees the JSON serialization.\n\nWhile Dynamic Isolates support Python, please note that at this time, Python Workers are much slower to start than JavaScript Workers, which may defeat some of the benefits of dynamic isolate loading. They may also be priced differently, when Worker Loaders become generally available.\n\n#### `globalOutbound ServiceStub | null Optional`\n\nControls whether the dynamic Worker has access to the network. The global `fetch()` and `connect()` functions (for making HTTP requests and TCP connections, respectively) can be blocked or redirected to isolate the Worker.\n\nIf `globalOutbound` is not specified, the default is to inherit the parent's network access, which usually means the dynamic Worker will have full access to the public Internet.\n\nIf `globalOutbound` is `null`, then the dynamic Worker will be totally cut off from the network. Both `fetch()` and `connect()` will throw exceptions.\n\n`globalOutbound` can also be set to any service binding, including service bindings in the parent worker's `env` as well as [loopback bindings from `ctx.exports`](https://developers.cloudflare.com/workers/runtime-apis/context/#exports).\n\nUsing `ctx.exports` is particularly useful as it allows you to customize the binding further for the specific sandbox, by setting the value of `ctx.props` that should be passed back to it. The `props` can contain information to identify the specific dynamic Worker that made the request.\n\nThe environment object to provide to the dynamic Worker.\n\nUsing this, you can provide custom bindings to the Worker.\n\n`env` is serialized and transferred into the dynamic Worker, where it is used directly as the value of `env` there. It may contain:\n\n* [Structured clonable types](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm).\n* [Service Bindings](https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings), including [loopback bindings from `ctx.exports`](https://developers.cloudflare.com/workers/runtime-apis/context/#exports).\n\nThe second point is the key to creating custom bindings: you can define a binding with any arbitrary API, by defining a [`WorkerEntrypoint` class](https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings/rpc) implementing an RPC API, and then giving it to the dynamic Worker as a Service Binding.\n\nMoreover, by using `ctx.exports` loopback bindings, you can further customize the bindings for the specific dynamic Worker by setting `ctx.props`, just as described for `globalOutbound`, above.\n\n<page>\n---\ntitle: Workflows · Cloudflare Workers docs\ndescription: APIs available in Cloudflare Workers to interact with Workflows.\n  Workflows allow you to build durable, multi-step applications using Workers.\nlastUpdated: 2024-10-24T11:52:00.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/bindings/workflows/\n  md: https://developers.cloudflare.com/workers/runtime-apis/bindings/workflows/index.md\n---\n\n<page>\n---\ntitle: Alarm Handler · Cloudflare Workers docs\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/handlers/alarm/\n  md: https://developers.cloudflare.com/workers/runtime-apis/handlers/alarm/index.md\n---\n\n<page>\n---\ntitle: Email Handler · Cloudflare Workers docs\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/handlers/email/\n  md: https://developers.cloudflare.com/workers/runtime-apis/handlers/email/index.md\n---\n\n<page>\n---\ntitle: Fetch Handler · Cloudflare Workers docs\ndescription: \"Incoming HTTP requests to a Worker are passed to the fetch()\n  handler as a Request object. To respond to the request with a response, return\n  a Response object:\"\nlastUpdated: 2025-12-30T07:16:34.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch/\n  md: https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch/index.md\n---\n\nIncoming HTTP requests to a Worker are passed to the `fetch()` handler as a [`Request`](https://developers.cloudflare.com/workers/runtime-apis/request/) object. To respond to the request with a response, return a [`Response`](https://developers.cloudflare.com/workers/runtime-apis/response/) object:\n\nThe Workers runtime does not support `XMLHttpRequest` (XHR). Learn the difference between `XMLHttpRequest` and `fetch()` in the [MDN](https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest) documentation.\n\n* The incoming HTTP request.\n\n* The [bindings](https://developers.cloudflare.com/workers/runtime-apis/bindings/) available to the Worker. As long as the [environment](https://developers.cloudflare.com/workers/wrangler/environments/) has not changed, the same object (equal by identity) may be passed to multiple requests. You can also [import `env` from `cloudflare:workers`](https://developers.cloudflare.com/workers/runtime-apis/bindings/#importing-env-as-a-global) to access bindings from anywhere in your code.\n\n* `ctx.waitUntil(promisePromise)` : void\n\n* Refer to [`waitUntil`](https://developers.cloudflare.com/workers/runtime-apis/context/#waituntil).\n\n* `ctx.passThroughOnException()` : void\n\n* Refer to [`passThroughOnException`](https://developers.cloudflare.com/workers/runtime-apis/context/#passthroughonexception).\n\n<page>\n---\ntitle: Queue Handler · Cloudflare Workers docs\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/handlers/queue/\n  md: https://developers.cloudflare.com/workers/runtime-apis/handlers/queue/index.md\n---\n\n<page>\n---\ntitle: Scheduled Handler · Cloudflare Workers docs\ndescription: When a Worker is invoked via a Cron Trigger, the scheduled()\n  handler handles the invocation.\nlastUpdated: 2025-11-11T15:40:52.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/handlers/scheduled/\n  md: https://developers.cloudflare.com/workers/runtime-apis/handlers/scheduled/index.md\n---\n\nWhen a Worker is invoked via a [Cron Trigger](https://developers.cloudflare.com/workers/configuration/cron-triggers/), the `scheduled()` handler handles the invocation.\n\nTesting scheduled() handlers in local development\n\nYou can test the behavior of your `scheduled()` handler in local development using Wrangler.\n\nCron Triggers can be tested using `Wrangler` by passing in the `--test-scheduled` flag to [`wrangler dev`](https://developers.cloudflare.com/workers/wrangler/commands/#dev). This will expose a `/__scheduled` (or `/cdn-cgi/handler/scheduled` for Python Workers) route which can be used to test using a http request. To simulate different cron patterns, a `cron` query parameter can be passed in.\n\n* `controller.cron` string\n\n* The value of the [Cron Trigger](https://developers.cloudflare.com/workers/configuration/cron-triggers/) that started the `ScheduledEvent`.\n\n* `controller.type` string\n\n* The type of controller. This will always return `\"scheduled\"`.\n\n* `controller.scheduledTime` number\n\n* The time the `ScheduledEvent` was scheduled to be executed in milliseconds since January 1, 1970, UTC. It can be parsed as `new Date(controller.scheduledTime)`.\n\n* An object containing the bindings associated with your Worker using ES modules format, such as KV namespaces and Durable Objects.\n\n* An object containing the context associated with your Worker using ES modules format. Currently, this object just contains the `waitUntil` function.\n\nWhen a Workers script is invoked by a [Cron Trigger](https://developers.cloudflare.com/workers/configuration/cron-triggers/), the Workers runtime starts a `ScheduledEvent` which will be handled by the `scheduled` function in your Workers Module class. The `ctx` argument represents the context your function runs in, and contains the following methods to control what happens next:\n\n* `ctx.waitUntil(promisePromise)` : void - Use this method to notify the runtime to wait for asynchronous tasks (for example, logging, analytics to third-party services, streaming and caching). The first `ctx.waitUntil` to fail will be observed and recorded as the status in the [Cron Trigger](https://developers.cloudflare.com/workers/configuration/cron-triggers/) Past Events table. Otherwise, it will be reported as a success.\n\n<page>\n---\ntitle: Tail Handler · Cloudflare Workers docs\ndescription: The tail() handler is the handler you implement when writing a Tail\n  Worker. Tail Workers can be used to process logs in real-time and send them to\n  a logging or analytics service.\nlastUpdated: 2025-02-24T15:56:47.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/handlers/tail/\n  md: https://developers.cloudflare.com/workers/runtime-apis/handlers/tail/index.md\n---\n\nThe `tail()` handler is the handler you implement when writing a [Tail Worker](https://developers.cloudflare.com/workers/observability/logs/tail-workers/). Tail Workers can be used to process logs in real-time and send them to a logging or analytics service.\n\nThe `tail()` handler is called once each time the connected producer Worker is invoked.\n\nTo configure a Tail Worker, refer to [Tail Workers documentation](https://developers.cloudflare.com/workers/observability/logs/tail-workers/).\n\n* An array of [`TailItems`](https://developers.cloudflare.com/workers/runtime-apis/handlers/tail/#tailitems). One `TailItem` is collected for each event that triggers a Worker. For Workers for Platforms customers with a Tail Worker installed on the dynamic dispatch Worker, `events` will contain two elements: one for the dynamic dispatch Worker and one for the User Worker.\n\n* An object containing the bindings associated with your Worker using [ES modules format](https://developers.cloudflare.com/workers/reference/migrate-to-module-workers/), such as KV namespaces and Durable Objects.\n\n* An object containing the context associated with your Worker using [ES modules format](https://developers.cloudflare.com/workers/reference/migrate-to-module-workers/). Currently, this object just contains the `waitUntil` function.\n\n* `event.type` string\n\n* The type of event. This will always return `\"tail\"`.\n\n* `event.traces` array\n\n* An array of [`TailItems`](https://developers.cloudflare.com/workers/runtime-apis/handlers/tail/#tailitems). One `TailItem` is collected for each event that triggers a Worker. For Workers for Platforms customers with a Tail Worker installed on the dynamic dispatch Worker, `events` will contain two elements: one for the dynamic dispatch Worker and one for the user Worker.\n\n* `event.waitUntil(promisePromise)` : void\n\n* Refer to [`waitUntil`](https://developers.cloudflare.com/workers/runtime-apis/context/#waituntil). Note that unlike fetch event handlers, tail handlers do not return a value, so this is the only way for trace Workers to do asynchronous work.\n\n* `scriptName` string\n\n* The name of the producer script.\n\n* Contains information about the Worker’s triggering event.\n\n* For fetch events: a [`FetchEventInfo` object](https://developers.cloudflare.com/workers/runtime-apis/handlers/tail/#fetcheventinfo)\n    * For other event types: `null`, currently.\n\n* `eventTimestamp` number\n\n* Measured in epoch time.\n\n* An array of [TailLogs](https://developers.cloudflare.com/workers/runtime-apis/handlers/tail/#taillog).\n\n* An array of [`TailExceptions`](https://developers.cloudflare.com/workers/runtime-apis/handlers/tail/#tailexception). A single Worker invocation might result in multiple unhandled exceptions, since a Worker can register multiple asynchronous tasks.\n\n* The outcome of the Worker invocation, one of:\n\n* `unknown`: outcome status was not set.\n\n* `ok`: The worker invocation succeeded.\n\n* `exception`: An unhandled exception was thrown. This can happen for many reasons, including:\n\n* An uncaught JavaScript exception.\n      * A fetch handler that does not result in a Response.\n      * An internal error.\n\n* `exceededCpu`: The Worker invocation exceeded either its CPU limits.\n\n* `exceededMemory`: The Worker invocation exceeded memory limits.\n\n* `scriptNotFound`: An internal error from difficulty retrieving the Worker script.\n\n* `canceled`: The worker invocation was canceled before it completed. Commonly because the client disconnected before a response could be sent.\n\n* `responseStreamDisconnected`: The response stream was disconnected during deferred proxying. Happens when either the client or server hangs up early.\n\nOutcome is not the same as HTTP status.\n\nOutcome is equivalent to the exit status of a script and an indicator of whether it has fully run to completion. A Worker outcome may differ from a response code if, for example:\n\n* a script successfully processes a request but is logically designed to return a `4xx`/`5xx` response.\n* a script sends a successful `200` response but an asynchronous task registered via `waitUntil()` later exceeds CPU or memory limits.\n\n* A [`TailRequest` object](https://developers.cloudflare.com/workers/runtime-apis/handlers/tail/#tailrequest).\n\n* A [`TailResponse` object](https://developers.cloudflare.com/workers/runtime-apis/handlers/tail/#tailresponse).\n\n* Contains the data from [`IncomingRequestCfProperties`](https://developers.cloudflare.com/workers/runtime-apis/request/#incomingrequestcfproperties).\n\n* Header name/value entries (redacted by default). Header names are lowercased, and the values associated with duplicate header names are concatenated, with the string `\", \"` (comma space) interleaved, similar to [the Fetch standard](https://fetch.spec.whatwg.org/#concept-header-list-get).\n\n* The HTTP request method.\n\n* The HTTP request URL (redacted by default).\n\n* `getUnredacted()` object\n\n* Returns a TailRequest object with unredacted properties\n\nSome of the properties of `TailRequest` are redacted by default to make it harder to accidentally record sensitive information, like user credentials or API tokens. The redactions use heuristic rules, so they are subject to false positives and negatives. Clients can call `getUnredacted()` to bypass redaction, but they should always be careful about what information is retained, whether using the redaction or not.\n\n* Header redaction: The header value will be the string `“REDACTED”` when the (case-insensitive) header name is `cookie`/`set-cookie` or contains a substring `\"auth”`, `“key”`, `“secret”`, `“token”`, or `\"jwt\"`.\n* URL redaction: For each greedily matched substring of ID characters (a-z, A-Z, 0-9, '+', '-', '\\_') in the URL, if it meets the following criteria for a hex or base-64 ID, the substring will be replaced with the string `“REDACTED”`.\n* Hex ID: Contains 32 or more hex digits, and contains only hex digits and separators ('+', '-', '\\_')\n* Base-64 ID: Contains 21 or more characters, and contains at least two uppercase, two lowercase, and two digits.\n\n* The HTTP status code.\n\nRecords information sent to console functions.\n\n* Measured in epoch time.\n\n* A string indicating the console function that was called. One of: `debug`, `info`, `log`, `warn`, `error`.\n\n* The array of parameters passed to the console function.\n\nRecords an unhandled exception that occurred during the Worker invocation.\n\n* Measured in epoch time.\n\n* The error type (For example,`Error`, `TypeError`, etc.).\n\n* The error description (For example, `\"x\" is not a function`).\n\n* [Tail Workers](https://developers.cloudflare.com/workers/observability/logs/tail-workers/) - Configure a Tail Worker to receive information about the execution of other Workers.\n\n<page>\n---\ntitle: assert · Cloudflare Workers docs\ndescription: The node:assert module in Node.js provides a number of useful\n  assertions that are useful when building tests.\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/assert/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/assert/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\nThe [`node:assert`](https://nodejs.org/docs/latest/api/assert.html) module in Node.js provides a number of useful assertions that are useful when building tests.\n\nIn the Workers implementation of `assert`, all assertions run in, what Node.js calls, the strict assertion mode. In strict assertion mode, non-strict methods behave like their corresponding strict methods. For example, `deepEqual()` will behave like `deepStrictEqual()`.\n\nRefer to the [Node.js documentation for `assert`](https://nodejs.org/dist/latest-v19.x/docs/api/assert.html) for more information.\n\n<page>\n---\ntitle: AsyncLocalStorage · Cloudflare Workers docs\ndescription: Cloudflare Workers provides an implementation of a subset of the\n  Node.js AsyncLocalStorage API for creating in-memory stores that remain\n  coherent through asynchronous operations.\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/asynclocalstorage/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/asynclocalstorage/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\nCloudflare Workers provides an implementation of a subset of the Node.js [`AsyncLocalStorage`](https://nodejs.org/dist/latest-v18.x/docs/api/async_context.html#class-asynclocalstorage) API for creating in-memory stores that remain coherent through asynchronous operations.\n\n* `new AsyncLocalStorage()` : AsyncLocalStorage\n  * Returns a new `AsyncLocalStorage` instance.\n\n* Returns the current store. If called outside of an asynchronous context initialized by calling `asyncLocalStorage.run()`, it returns `undefined`.\n\n* `run(storeany, callbackfunction, ...argsarguments)` : any\n\n* Runs a function synchronously within a context and returns its return value. The store is not accessible outside of the callback function. The store is accessible to any asynchronous operations created within the callback. The optional `args` are passed to the callback function. If the callback function throws an error, the error is thrown by `run()` also.\n\n* `exit(callbackfunction, ...argsarguments)` : any\n\n* Runs a function synchronously outside of a context and returns its return value. This method is equivalent to calling `run()` with the `store` value set to `undefined`.\n\n* `AsyncLocalStorage.bind(fn)` : function\n\n* Captures the asynchronous context that is current when `bind()` is called and returns a function that enters that context before calling the passed in function.\n\n* `AsyncLocalStorage.snapshot()` : function\n\n* Captures the asynchronous context that is current when `snapshot()` is called and returns a function that enters that context before calling a given function.\n\nThe API supports multiple `AsyncLocalStorage` instances to be used concurrently.\n\n### Unhandled Rejections\n\nWhen a `Promise` rejects and the rejection is unhandled, the async context propagates to the `'unhandledrejection'` event handler:\n\n### `AsyncLocalStorage.bind()` and `AsyncLocalStorage.snapshot()`\n\nThe [`AsyncResource`](https://nodejs.org/dist/latest-v18.x/docs/api/async_context.html#class-asyncresource) class is a component of Node.js' async context tracking API that allows users to create their own async contexts. Objects that extend from `AsyncResource` are capable of propagating the async context in much the same way as promises.\n\nNote that `AsyncLocalStorage.snapshot()` and `AsyncLocalStorage.bind()` provide a better approach. `AsyncResource` is provided solely for backwards compatibility with Node.js.\n\n* `new AsyncResource(typestring, optionsAsyncResourceOptions)` : AsyncResource\n\n* Returns a new `AsyncResource`. Importantly, while the constructor arguments are required in Node.js' implementation of `AsyncResource`, they are not used in Workers.\n\n* `AsyncResource.bind(fnfunction, typestring, thisArgany)`\n  * Binds the given function to the current async context.\n\n* `asyncResource.bind(fnfunction, thisArgany)`\n  * Binds the given function to the async context associated with this `AsyncResource`.\n* `asyncResource.runInAsyncScope(fnfunction, thisArgany, ...argsarguments)`\n  * Call the provided function with the given arguments in the async context associated with this `AsyncResource`.\n\n* The `AsyncLocalStorage` implementation provided by Workers intentionally omits support for the [`asyncLocalStorage.enterWith()`](https://nodejs.org/dist/latest-v18.x/docs/api/async_context.html#asynclocalstorageenterwithstore) and [`asyncLocalStorage.disable()`](https://nodejs.org/dist/latest-v18.x/docs/api/async_context.html#asynclocalstoragedisable) methods.\n\n* Workers does not implement the full [`async_hooks`](https://nodejs.org/dist/latest-v18.x/docs/api/async_hooks.html) API upon which Node.js' implementation of `AsyncLocalStorage` is built.\n\n* Workers does not implement the ability to create an `AsyncResource` with an explicitly identified trigger context as allowed by Node.js. This means that a new `AsyncResource` will always be bound to the async context in which it was created.\n\n* Thenables (non-Promise objects that expose a `then()` method) are not fully supported when using `AsyncLocalStorage`. When working with thenables, instead use [`AsyncLocalStorage.snapshot()`](https://nodejs.org/api/async_context.html#static-method-asynclocalstoragesnapshot) to capture a snapshot of the current context.\n\n<page>\n---\ntitle: Buffer · Cloudflare Workers docs\ndescription: The Buffer API in Node.js is one of the most commonly used Node.js\n  APIs for manipulating binary data. Every Buffer instance extends from the\n  standard Uint8Array class, but adds a range of unique capabilities such as\n  built-in base64 and hex encoding/decoding, byte-order manipulation, and\n  encoding-aware substring searching.\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/buffer/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/buffer/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\nThe [`Buffer`](https://nodejs.org/docs/latest/api/buffer.html) API in Node.js is one of the most commonly used Node.js APIs for manipulating binary data. Every `Buffer` instance extends from the standard [`Uint8Array`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array) class, but adds a range of unique capabilities such as built-in base64 and hex encoding/decoding, byte-order manipulation, and encoding-aware substring searching.\n\nA Buffer extends from `Uint8Array`. Therefore, it can be used in any Workers API that currently accepts `Uint8Array`, such as creating a new Response:\n\nYou can also use the `Buffer` API when interacting with streams:\n\nOne key difference between the Workers implementation of `Buffer` and the Node.js implementation is that some methods of creating a `Buffer` in Node.js will allocate those from a global memory pool as a performance optimization. The Workers implementation does not use a memory pool and all `Buffer` instances are allocated independently.\n\nFurther, in Node.js it is possible to allocate a `Buffer` with uninitialized memory using the `Buffer.allocUnsafe()` method. This is not supported in Workers and `Buffer` instances are always initialized so that the `Buffer` is always filled with null bytes (`0x00`) when allocated.\n\nRefer to the [Node.js documentation for `Buffer`](https://nodejs.org/dist/latest-v19.x/docs/api/buffer.html) for more information.\n\n<page>\n---\ntitle: crypto · Cloudflare Workers docs\ndescription: The node:crypto module provides cryptographic functionality that\n  includes a set of wrappers for OpenSSL's hash, HMAC, cipher, decipher, sign,\n  and verify functions.\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/crypto/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/crypto/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\nThe [`node:crypto`](https://nodejs.org/docs/latest/api/crypto.html) module provides cryptographic functionality that includes a set of wrappers for OpenSSL's hash, HMAC, cipher, decipher, sign, and verify functions.\n\nAll `node:crypto` APIs are fully supported in Workers with the following exceptions:\n\n* The functions [generateKeyPair](https://nodejs.org/api/crypto.html#cryptogeneratekeypairtype-options-callback) and [generateKeyPairSync](https://nodejs.org/api/crypto.html#cryptogeneratekeypairsynctype-options) do not support DSA or DH key pairs.\n* `ed448` and `x448` curves are not supported.\n* It is not possible to manually enable or disable [FIPS mode](https://nodejs.org/docs/latest/api/crypto.html#fips-mode).\n\nThe full `node:crypto` API is documented in the [Node.js documentation for `node:crypto`](https://nodejs.org/api/crypto.html).\n\nThe [WebCrypto API](https://developers.cloudflare.com/workers/runtime-apis/web-crypto/) is also available within Cloudflare Workers. This does not require the `nodejs_compat` compatibility flag.\n\n<page>\n---\ntitle: dns · Cloudflare Workers docs\ndescription: |-\n  You can use node:dns for name resolution via DNS over HTTPS using\n  Cloudflare DNS at 1.1.1.1.\nlastUpdated: 2025-12-15T07:29:41.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/dns/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/dns/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\nYou can use [`node:dns`](https://nodejs.org/api/dns.html) for name resolution via [DNS over HTTPS](https://developers.cloudflare.com/1.1.1.1/encryption/dns-over-https/) using [Cloudflare DNS](https://www.cloudflare.com/application-services/products/dns/) at 1.1.1.1.\n\nAll `node:dns` functions are available, except `lookup`, `lookupService`, and `resolve` which throw \"Not implemented\" errors when called.\n\nDNS requests will execute a subrequest, counts for your [Worker's subrequest limit](https://developers.cloudflare.com/workers/platform/limits/#subrequests).\n\nThe full `node:dns` API is documented in the [Node.js documentation for `node:dns`](https://nodejs.org/api/dns.html).\n\n<page>\n---\ntitle: Diagnostics Channel · Cloudflare Workers docs\ndescription: The diagnostics_channel module provides an API to create named\n  channels to report arbitrary message data for diagnostics purposes. The API is\n  essentially a simple event pub/sub model that is specifically designed to\n  support low-overhead diagnostics reporting.\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/diagnostics-channel/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/diagnostics-channel/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\nThe [`diagnostics_channel`](https://nodejs.org/dist/latest-v20.x/docs/api/diagnostics_channel.html) module provides an API to create named channels to report arbitrary message data for diagnostics purposes. The API is essentially a simple event pub/sub model that is specifically designed to support low-overhead diagnostics reporting.\n\nAll `Channel` instances are singletons per each Isolate/context (for example, the same entry point). Subscribers are always invoked synchronously and in the order they were registered, much like an `EventTarget` or Node.js `EventEmitter` class.\n\n## Integration with Tail Workers\n\nWhen using [Tail Workers](https://developers.cloudflare.com/workers/observability/logs/tail-workers/), all messages published to any channel will be forwarded also to the [Tail Worker](https://developers.cloudflare.com/workers/observability/logs/tail-workers/). Within the Tail Worker, the diagnostic channel messages can be accessed via the `diagnosticsChannelEvents` property:\n\nNote that message published to the tail worker is passed through the [structured clone algorithm](https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm) (same mechanism as the [`structuredClone()`](https://developer.mozilla.org/en-US/docs/Web/API/structuredClone) API) so only values that can be successfully cloned are supported.\n\nPer the Node.js documentation, \"[`TracingChannel`](https://nodejs.org/api/diagnostics_channel.html#class-tracingchannel) is a collection of \\[Channels] which together express a single traceable action. `TracingChannel` is used to formalize and simplify the process of producing events for tracing application flow.\"\n\nRefer to the [Node.js documentation for `diagnostics_channel`](https://nodejs.org/dist/latest-v20.x/docs/api/diagnostics_channel.html) for more information.\n\n<page>\n---\ntitle: EventEmitter · Cloudflare Workers docs\ndescription: |-\n  An EventEmitter\n  is an object that emits named events that cause listeners to be called.\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/eventemitter/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/eventemitter/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\nAn [`EventEmitter`](https://nodejs.org/docs/latest/api/events.html#class-eventemitter) is an object that emits named events that cause listeners to be called.\n\nThe implementation in the Workers runtime supports the entire Node.js `EventEmitter` API. This includes the [`captureRejections`](https://nodejs.org/docs/latest/api/events.html#capture-rejections-of-promises) option that allows improved handling of async functions as event handlers:\n\nLike Node.js, when an `'error'` event is emitted on an `EventEmitter` and there is no listener for it, the error will be immediately thrown. However, in Node.js it is possible to add a handler on the `process` object for the `'uncaughtException'` event to catch globally uncaught exceptions. The `'uncaughtException'` event, however, is currently not implemented in the Workers runtime. It is strongly recommended to always add an `'error'` listener to any `EventEmitter` instance.\n\nRefer to the [Node.js documentation for `EventEmitter`](https://nodejs.org/api/events.html#class-eventemitter) for more information.\n\n<page>\n---\ntitle: fs · Cloudflare Workers docs\ndescription: |-\n  You can use node:fs to access a virtual file\n  system in Workers.\nlastUpdated: 2025-10-20T11:45:45.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/fs/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/fs/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\nYou can use [`node:fs`](https://nodejs.org/api/fs.html) to access a virtual file system in Workers.\n\nThe `node:fs` module is available in Workers runtimes that support Node.js compatibility using the `nodejs_compat` compatibility flag. Any Worker running with `nodejs_compat` enabled and with a compatibility date of `2025-09-01` or later will have access to `node:fs` by default. It is also possible to enable `node:fs` on Workers with an earlier compatibility date using a combination of the `nodejs_compat` and `enable_nodejs_fs_module` flags. To disable `node:fs` you can set the `disable_nodejs_fs_module` flag.\n\nThe Workers Virtual File System (VFS) is a memory-based file system that allows you to read modules included in your Worker bundle as read-only files, access a directory for writing temporary files, or access common [character devices](https://linux-kernel-labs.github.io/refs/heads/master/labs/device_drivers.html) like `/dev/null`, `/dev/random`, `/dev/full`, and `/dev/zero`.\n\nThe directory structure initially looks like:\n\nThe `/bundle` directory contains the files for all modules included in your Worker bundle, which you can read using APIs like `readFileSync` or `read(...)`, etc. These are always read-only. Reading from the bundle can be useful when you need to read a config file or a template.\n\nThe `/tmp` directory is writable, and you can use it to create temporary files or directories. You can also create symlinks in this directory. However, the contents of `/tmp` are not persistent and are unique to each request. This means that files created in `/tmp` within the context of one request will not be available in other concurrent or subsequent requests.\n\nThe `/dev` directory contains common character devices:\n\n* `/dev/null`: A null device that discards all data written to it and returns EOF on read.\n* `/dev/random`: A device that provides random bytes on reads and discards all data written to it. Reading from `/dev/random` is only permitted when within the context of a request.\n* `/dev/full`: A device that always returns EOF on reads and discards all data written to it.\n* `/dev/zero`: A device that provides an infinite stream of zero bytes on reads and discards all data written to it.\n\nAll operations on the VFS are synchronous. You can use the synchronous, asynchronous callback, or promise-based APIs provided by the `node:fs` module but all operations will be performed synchronously.\n\nTimestamps for files in the VFS are currently always set to the Unix epoch (`1970-01-01T00:00:00Z`). This means that operations that rely on timestamps, like `fs.stat`, will always return the same timestamp for all files in the VFS. This is a temporary limitation that will be addressed in a future release.\n\nSince all temporary files are held in memory, the total size of all temporary files and directories created count towards your Worker’s memory limit. If you exceed this limit, the Worker instance will be terminated and restarted.\n\nThe file system implementation has the following limits:\n\n* The maximum total length of a file path is 4096 characters, including path separators. Because paths are handled as file URLs internally, the limit accounts for percent-encoding of special characters, decoding characters that do not need encoding before the limit is checked. For example, the path `/tmp/abcde%66/ghi%zz' is 18 characters long because the `%66`does not need to be percent-encoded and is therefore counted as one character, while the`%zz\\` is an invalid percent-encoding that is counted as 3 characters.\n* The maximum number of path segments is 48. For example, the path `/a/b/c` is 3 segments.\n* The maximum size of an individual file is 128 MB total.\n\nThe following `node:fs` APIs are not supported in Workers, or are only partially supported:\n\n* `fs.watch` and `fs.watchFile` operations for watching for file changes.\n* The `fs.globSync()` and other glob APIs have not yet been implemented.\n* The `force` option in the `fs.rm` API has not yet been implemented.\n* Timestamps for files are always set to the Unix epoch (`1970-01-01T00:00:00Z`).\n* File permissions and ownership are not supported.\n\nThe full `node:fs` API is documented in the [Node.js documentation for `node:fs`](https://nodejs.org/api/fs.html).\n\n<page>\n---\ntitle: http · Cloudflare Workers docs\ndescription: To use the HTTP client-side methods (http.get, http.request, etc.),\n  you must enable the enable_nodejs_http_modules compatibility flag in addition\n  to the nodejs_compat flag.\nlastUpdated: 2025-08-26T18:22:59.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/http/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/http/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\n## Compatibility flags\n\n### Client-side methods\n\nTo use the HTTP client-side methods (`http.get`, `http.request`, etc.), you must enable the [`enable_nodejs_http_modules`](https://developers.cloudflare.com/workers/configuration/compatibility-flags/) compatibility flag in addition to the [`nodejs_compat`](https://developers.cloudflare.com/workers/runtime-apis/nodejs/) flag.\n\nThis flag is automatically enabled for Workers using a [compatibility date](https://developers.cloudflare.com/workers/configuration/compatibility-dates/) of `2025-08-15` or later when `nodejs_compat` is enabled. For Workers using an earlier compatibility date, you can manually enable it by adding the flag to your `wrangler.toml`:\n\n### Server-side methods\n\nTo use the HTTP server-side methods (`http.createServer`, `http.Server`, `http.ServerResponse`), you must enable the `enable_nodejs_http_server_modules` compatibility flag in addition to the [`nodejs_compat`](https://developers.cloudflare.com/workers/runtime-apis/nodejs/) flag.\n\nThis flag is automatically enabled for Workers using a [compatibility date](https://developers.cloudflare.com/workers/configuration/compatibility-dates/) of `2025-09-01` or later when `nodejs_compat` is enabled. For Workers using an earlier compatibility date, you can manually enable it by adding the flag to your `wrangler.toml`:\n\nTo use both client-side and server-side methods, enable both flags:\n\nAn implementation of the Node.js [`http.get`](https://nodejs.org/docs/latest/api/http.html#httpgetoptions-callback) method.\n\nThe `get` method performs a GET request to the specified URL and invokes the callback with the response. It's a convenience method that simplifies making HTTP GET requests without manually configuring request options.\n\nBecause `get` is a wrapper around `fetch(...)`, it may be used only within an exported fetch or similar handler. Outside of such a handler, attempts to use `get` will throw an error.\n\nThe implementation of `get` in Workers is a wrapper around the global [`fetch` API](https://developers.cloudflare.com/workers/runtime-apis/fetch/) and is therefore subject to the same [limits](https://developers.cloudflare.com/workers/platform/limits/).\n\nAs shown in the example above, it is necessary to arrange for requests to be correctly awaited in the `fetch` handler using a promise or the fetch may be canceled prematurely when the handler returns.\n\nAn implementation of the Node.js [\\`http.request'](https://nodejs.org/docs/latest/api/http.html#httprequesturl-options-callback) method.\n\nThe `request` method creates an HTTP request with customizable options like method, headers, and body. It provides full control over the request configuration and returns a Node.js [stream.Writable](https://developers.cloudflare.com/workers/runtime-apis/nodejs/streams/) for sending request data.\n\nBecause `request` is a wrapper around `fetch(...)`, it may be used only within an exported fetch or similar handler. Outside of such a handler, attempts to use `request` will throw an error.\n\nThe following options passed to the `request` (and `get`) method are not supported due to the differences required by Cloudflare Workers implementation of `node:http` as a wrapper around the global `fetch` API:\n\n* `maxHeaderSize`\n* `insecureHTTPParser`\n* `createConnection`\n* `lookup`\n* `socketPath`\n\nThe [`OutgoingMessage`](https://nodejs.org/docs/latest/api/http.html#class-httpoutgoingmessage) class represents an HTTP response that is sent to the client. It provides methods for writing response headers and body, as well as for ending the response. `OutgoingMessage` extends from the Node.js [`stream.Writable` stream class](https://developers.cloudflare.com/workers/runtime-apis/nodejs/streams/).\n\nThe `OutgoingMessage` class is a base class for outgoing HTTP messages (both requests and responses). It provides methods for writing headers and body data, as well as for ending the message. `OutgoingMessage` extends from the [`Writable` stream class](https://nodejs.org/docs/latest/api/stream.html#class-streamwritable).\n\nBoth `ClientRequest` and `ServerResponse` both extend from and inherit from `OutgoingMessage`.\n\nThe `IncomingMessage` class represents an HTTP request that is received from the client. It provides methods for reading request headers and body, as well as for ending the request. `IncomingMessage` extends from the `Readable` stream class.\n\nThe `IncomingMessage` class represents an HTTP message (request or response). It provides methods for reading headers and body data. `IncomingMessage` extends from the `Readable` stream class.\n\nThe Workers implementation includes a `cloudflare` property on `IncomingMessage` objects:\n\nThe `cloudflare.cf` property contains [Cloudflare-specific request properties](https://developers.cloudflare.com/workers/runtime-apis/request/#incomingrequestcfproperties).\n\nThe following differences exist between the Workers implementation and Node.js:\n\n* Trailer headers are not supported\n\n* The `socket` attribute **does not extend from `net.Socket`** and only contains the following properties: `encrypted`, `remoteFamily`, `remoteAddress`, `remotePort`, `localAddress`, `localPort`, and `destroy()` method.\n\n* The following `socket` attributes behave differently than their Node.js counterparts:\n\n* `remoteAddress` will return `127.0.0.1` when ran locally\n  * `remotePort` will return a random port number between 2^15 and 2^16\n  * `localAddress` will return the value of request's `host` header if exists. Otherwise, it will return `127.0.0.1`\n  * `localPort` will return the port number assigned to the server instance\n  * `req.socket.destroy()` falls through to `req.destroy()`\n\nA partial implementation of the Node.js [\\`http.Agent'](https://nodejs.org/docs/latest/api/http.html#class-httpagent) class.\n\nAn `Agent` manages HTTP connection reuse by maintaining request queues per host/port. In the workers environment, however, such low-level management of the network connection, ports, etc, is not relevant because it is handled by the Cloudflare infrastructure instead. Accordingly, the implementation of `Agent` in Workers is a stub implementation that does not support connection pooling or keep-alive.\n\nAn implementation of the Node.js [`http.createServer`](https://nodejs.org/docs/latest/api/http.html#httpcreateserveroptions-requestlistener) method.\n\nThe `createServer` method creates an HTTP server instance that can handle incoming requests.\n\n## Node.js integration\n\n### httpServerHandler\n\nThe `httpServerHandler` function integrates Node.js HTTP servers with the Cloudflare Workers request model. It supports two API patterns:\n\nThe handler automatically routes incoming Worker requests to your Node.js server. When using port-based routing, the port number acts as a routing key to determine which server handles requests, allowing multiple servers to coexist in the same Worker.\n\n### handleAsNodeRequest\n\nFor more direct control over request routing, you can use the `handleAsNodeRequest` function from `cloudflare:node`. This function directly routes a Worker request to a Node.js server running on a specific port:\n\nThis approach gives you full control over the fetch handler while still leveraging Node.js HTTP servers for request processing.\n\nFailing to call `close()` on an HTTP server may result in the server persisting until the worker is destroyed. In most cases, this is not an issue since servers typically live for the lifetime of the worker. However, if you need to create multiple servers during a worker's lifetime or want explicit lifecycle control (such as in test scenarios), call `close()` when you're done with the server, or use [explicit resource management](https://v8.dev/features/explicit-resource-management).\n\nAn implementation of the Node.js [`http.Server`](https://nodejs.org/docs/latest/api/http.html#class-httpserver) class.\n\nThe `Server` class represents an HTTP server and provides methods for handling incoming requests. It extends the Node.js `EventEmitter` class and can be used to create custom server implementations.\n\nWhen using `httpServerHandler`, the port number specified in `server.listen()` acts as a routing key rather than an actual network port. The handler uses this port to determine which HTTP server instance should handle incoming requests, allowing multiple servers to coexist within the same Worker by using different port numbers for identification. Using a port value of `0` (or `null` or `undefined`) will result in a random port number being assigned.\n\nThe following differences exist between the Workers implementation and Node.js:\n\n* Connection management methods such as `closeAllConnections()` and `closeIdleConnections()` are not implemented\n* Only `listen()` variants with a port number or no parameters are supported: `listen()`, `listen(0, callback)`, `listen(callback)`, etc. For reference, see the [Node.js documentation](https://nodejs.org/docs/latest/api/net.html#serverlisten).\n* The following server options are not supported: `maxHeaderSize`, `insecureHTTPParser`, `keepAliveTimeout`, `connectionsCheckingInterval`\n\nAn implementation of the Node.js [`http.ServerResponse`](https://nodejs.org/docs/latest/api/http.html#class-httpserverresponse) class.\n\nThe `ServerResponse` class represents the server-side response object that is passed to request handlers. It provides methods for writing response headers and body data, and extends the Node.js `Writable` stream class.\n\nThe following methods and features are not supported in the Workers implementation:\n\n* `assignSocket()` and `detachSocket()` methods are not available\n* Trailer headers are not supported\n* `writeContinue()` and `writeEarlyHints()` methods are not available\n* 1xx responses in general are not supported\n\n## Other differences between Node.js and Workers implementation of `node:http`\n\nBecause the Workers implementation of `node:http` is a wrapper around the global `fetch` API, there are some differences in behavior and limitations compared to a standard Node.js environment:\n\n* `Connection` headers are not used. Workers will manage connections automatically.\n* `Content-Length` headers will be handled the same way as in the `fetch` API. If a body is provided, the header will be set automatically and manually set values will be ignored.\n* `Expect: 100-continue` headers are not supported.\n* Trailing headers are not supported.\n* The `'continue'` event is not supported.\n* The `'information'` event is not supported.\n* The `'socket'` event is not supported.\n* The `'upgrade'` event is not supported.\n* Gaining direct access to the underlying `socket` is not supported.\n\n<page>\n---\ntitle: https · Cloudflare Workers docs\ndescription: To use the HTTPS client-side methods (https.get, https.request,\n  etc.), you must enable the enable_nodejs_http_modules compatibility flag in\n  addition to the nodejs_compat flag.\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/https/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/https/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\n## Compatibility flags\n\n### Client-side methods\n\nTo use the HTTPS client-side methods (`https.get`, `https.request`, etc.), you must enable the [`enable_nodejs_http_modules`](https://developers.cloudflare.com/workers/configuration/compatibility-flags/) compatibility flag in addition to the [`nodejs_compat`](https://developers.cloudflare.com/workers/runtime-apis/nodejs/) flag.\n\nThis flag is automatically enabled for Workers using a [compatibility date](https://developers.cloudflare.com/workers/configuration/compatibility-dates/) of `2025-08-15` or later when `nodejs_compat` is enabled. For Workers using an earlier compatibility date, you can manually enable it by adding the flag to your `wrangler.toml`:\n\n### Server-side methods\n\nTo use the HTTPS server-side methods (`https.createServer`, `https.Server`, `https.ServerResponse`), you must enable the `enable_nodejs_http_server_modules` compatibility flag in addition to the [`nodejs_compat`](https://developers.cloudflare.com/workers/runtime-apis/nodejs/) flag.\n\nThis flag is automatically enabled for Workers using a [compatibility date](https://developers.cloudflare.com/workers/configuration/compatibility-dates/) of `2025-09-01` or later when `nodejs_compat` is enabled. For Workers using an earlier compatibility date, you can manually enable it by adding the flag to your `wrangler.toml`:\n\nTo use both client-side and server-side methods, enable both flags:\n\nAn implementation of the Node.js [\\`https.get'](https://nodejs.org/docs/latest/api/https.html#httpsgetoptions-callback) method.\n\nThe `get` method performs a GET request to the specified URL and invokes the callback with the response. This is a convenience method that simplifies making HTTPS GET requests without manually configuring request options.\n\nBecause `get` is a wrapper around `fetch(...)`, it may be used only within an exported fetch or similar handler. Outside of such a handler, attempts to use `get` will throw an error.\n\nThe implementation of `get` in Workers is a wrapper around the global [`fetch` API](https://developers.cloudflare.com/workers/runtime-apis/fetch/) and is therefore subject to the same [limits](https://developers.cloudflare.com/workers/platform/limits/).\n\nAs shown in the example above, it is necessary to arrange for requests to be correctly awaited in the `fetch` handler using a promise or the fetch may be canceled prematurely when the handler returns.\n\nAn implementation of the Node.js [\\`https.request'](https://nodejs.org/docs/latest/api/https.html#httpsrequestoptions-callback) method.\n\nThe `request` method creates an HTTPS request with customizable options like method, headers, and body. It provides full control over the request configuration and returns a Node.js [stream.Writable](https://developers.cloudflare.com/workers/runtime-apis/nodejs/streams/) for sending request data.\n\nBecause `get` is a wrapper around `fetch(...)`, it may be used only within an exported fetch or similar handler. Outside of such a handler, attempts to use `get` will throw an error.\n\nThe request method accepts all options from [`http.request`](https://developers.cloudflare.com/workers/runtime-apis/nodejs/http#request) with some differences in default values:\n\n* `protocol`: default `https:`\n* `port`: default `443`\n* `agent`: default `https.globalAgent`\n\nThe following additional options are not supported: `ca`, `cert`, `ciphers`, `clientCertEngine` (deprecated), `crl`, `dhparam`, `ecdhCurve`, `honorCipherOrder`, `key`, `passphrase`, `pfx`, `rejectUnauthorized`, `secureOptions`, `secureProtocol`, `servername`, `sessionIdContext`, `highWaterMark`.\n\nAn implementation of the Node.js [`https.createServer`](https://nodejs.org/docs/latest/api/https.html#httpscreateserveroptions-requestlistener) method.\n\nThe `createServer` method creates an HTTPS server instance that can handle incoming secure requests. It's a convenience function that creates a new `Server` instance and optionally sets up a request listener callback.\n\nThe `httpServerHandler` function integrates Node.js HTTPS servers with the Cloudflare Workers request model. When a request arrives at your Worker, the handler automatically routes it to your Node.js server running on the specified port. This bridge allows you to use familiar Node.js server patterns while benefiting from the Workers runtime environment, including automatic scaling, edge deployment, and integration with other Cloudflare services.\n\nFailing to call `close()` on an HTTPS server may result in the server being leaked. To prevent this, call `close()` when you're done with the server, or use explicit resource management:\n\nAn implementation of the Node.js [`https.Agent`](https://nodejs.org/docs/latest/api/https.html#class-httpsagent) class.\n\nAn [Agent](https://nodejs.org/docs/latest/api/https.html#class-httpsagent) manages HTTPS connection reuse by maintaining request queues per host/port. In the Workers environment, however, such low-level management of the network connection, ports, etc, is not relevant because it is handled by the Cloudflare infrastructure instead. Accordingly, the implementation of `Agent` in Workers is a stub implementation that does not support connection pooling or keep-alive.\n\nAn implementation of the Node.js [`https.Server`](https://nodejs.org/docs/latest/api/https.html#class-httpsserver) class.\n\nIn Node.js, the `https.Server` class represents an HTTPS server and provides methods for handling incoming secure requests. In Workers, handling of secure requests is provided by the Cloudflare infrastructure so there really is not much difference between using `https.Server` or `http.Server`. The workers runtime provides an implementation for completeness but most workers should probably just use [`http.Server`](https://developers.cloudflare.com/workers/runtime-apis/nodejs/http#server).\n\nThe following differences exist between the Workers implementation and Node.js:\n\n* Connection management methods such as `closeAllConnections()` and `closeIdleConnections()` are not implemented due to the nature of the Workers environment.\n* Only `listen()` variants with a port number or no parameters are supported: `listen()`, `listen(0, callback)`, `listen(callback)`, etc.\n* The following server options are not supported: `maxHeaderSize`, `insecureHTTPParser`, `keepAliveTimeout`, `connectionsCheckingInterval`\n* TLS/SSL-specific options such as `ca`, `cert`, `key`, `pfx`, `rejectUnauthorized`, `secureProtocol` are not supported in the Workers environment. If you need to use mTLS, use the [mTLS binding](https://developers.cloudflare.com/workers/runtime-apis/bindings/mtls/).\n\n## Other differences between Node.js and Workers implementation of `node:https`\n\nBecause the Workers implementation of `node:https` is a wrapper around the global `fetch` API, there are some differences in behavior compared to Node.js:\n\n* `Connection` headers are not used. Workers will manage connections automatically.\n* `Content-Length` headers will be handled the same way as in the `fetch` API. If a body is provided, the header will be set automatically and manually set values will be ignored.\n* `Expect: 100-continue` headers are not supported.\n* Trailing headers are not supported.\n* The `'continue'` event is not supported.\n* The `'information'` event is not supported.\n* The `'socket'` event is not supported.\n* The `'upgrade'` event is not supported.\n* Gaining direct access to the underlying `socket` is not supported.\n* Configuring TLS-specific options like `ca`, `cert`, `key`, `rejectUnauthorized`, etc, is not supported.\n\n<page>\n---\ntitle: net · Cloudflare Workers docs\ndescription: >-\n  You can use node:net to create a direct connection to servers via a TCP\n  sockets\n\nwith net.Socket.\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/net/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/net/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\nYou can use [`node:net`](https://nodejs.org/api/net.html) to create a direct connection to servers via a TCP sockets with [`net.Socket`](https://nodejs.org/api/net.html#class-netsocket).\n\nThese functions use [`connect`](https://developers.cloudflare.com/workers/runtime-apis/tcp-sockets/#connect) functionality from the built-in `cloudflare:sockets` module.\n\nAdditionally, other APIs such as [`net.BlockList`](https://nodejs.org/api/net.html#class-netblocklist) and [`net.SocketAddress`](https://nodejs.org/api/net.html#class-netsocketaddress) are available.\n\nNote that the [`net.Server`](https://nodejs.org/api/net.html#class-netserver) class is not supported by Workers.\n\nThe full `node:net` API is documented in the [Node.js documentation for `node:net`](https://nodejs.org/api/net.html).\n\n<page>\n---\ntitle: path · Cloudflare Workers docs\ndescription: \"The node:path module provides utilities for working with file and\n  directory paths. The node:path module can be accessed using:\"\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/path/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/path/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\nThe [`node:path`](https://nodejs.org/api/path.html) module provides utilities for working with file and directory paths. The `node:path` module can be accessed using:\n\nRefer to the [Node.js documentation for `path`](https://nodejs.org/api/path.html) for more information.\n\n<page>\n---\ntitle: process · Cloudflare Workers docs\ndescription: The process module in Node.js provides a number of useful APIs\n  related to the current process.\nlastUpdated: 2025-12-30T07:16:34.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/process/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/process/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\nThe [`process`](https://nodejs.org/docs/latest/api/process.html) module in Node.js provides a number of useful APIs related to the current process.\n\nInitially Workers only supported `nextTick`, `env`, `exit`, `getBuiltinModule`, `platform` and `features` on process, which was then updated with the [`enable_nodejs_process_v2`](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#enable-process-v2-implementation) flag to include most Node.js process features.\n\nRefer to the [Node.js documentation for `process`](https://nodejs.org/docs/latest/api/process.html) for more information.\n\nWorkers-specific implementation details apply when adapting Node.js process support for a serverless environment, which are described in more detail below.\n\nIn the Node.js implementation of `process.env`, the `env` object is a copy of the environment variables at the time the process was started. In the Workers implementation, there is no process-level environment, so by default `env` is an empty object. You can still set and get values from `env`, and those will be globally persistent for all Workers running in the same isolate and context (for example, the same Workers entry point).\n\nWhen [Node.js compatibility](https://developers.cloudflare.com/workers/runtime-apis/nodejs/) is enabled and the [`nodejs_compat_populate_process_env`](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#enable-auto-populating-processenv) compatibility flag is set (enabled by default for compatibility dates on or after 2025-04-01), `process.env` will contain any [environment variables](https://developers.cloudflare.com/workers/configuration/environment-variables/), [secrets](https://developers.cloudflare.com/workers/configuration/secrets/), or [version metadata](https://developers.cloudflare.com/workers/runtime-apis/bindings/version-metadata/) metadata that has been configured on your Worker.\n\nSetting any value on `process.env` will coerce that value into a string.\n\n### Alternative: Import `env` from `cloudflare:workers`\n\nInstead of using `process.env`, you can [import `env` from `cloudflare:workers`](https://developers.cloudflare.com/workers/runtime-apis/bindings/#importing-env-as-a-global) to access environment variables and all other bindings from anywhere in your code.\n\nIt is strongly recommended that you *do not* replace the entire `process.env` object with the cloudflare `env` object. Doing so will cause you to lose any environment variables that were set previously and will cause unexpected behavior for other Workers running in the same isolate. Specifically, it would cause inconsistency with the `process.env` object when accessed via named imports.\n\n## `process.nextTick()`\n\nThe Workers implementation of `process.nextTick()` is a wrapper for the standard Web Platform API [`queueMicrotask()`](https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/queueMicrotask).\n\n[`process.stdout`](https://nodejs.org/docs/latest/api/process.html#processstdout), [`process.stderr`](https://nodejs.org/docs/latest/api/process.html#processstderr) and [`process.stdin`](https://nodejs.org/docs/latest/api/process.html#processstdin) are supported as streams. `stdin` is treated as an empty readable stream. `stdout` and `stderr` are non-TTY writable streams, which output to normal logging output only with `stdout: `and `stderr: `prefixing.\n\nThe line buffer works by storing writes to stdout or stderr until either a newline character `\\n` is encountered or until the next microtask, when the log is then flushed to the output.\n\nThis ensures compatibility with inspector and structured logging outputs.\n\n## Current Working Directory\n\n[`process.cwd()`](https://nodejs.org/docs/latest/api/process.html#processcwd) is the *current working directory*, used as the default path for all filesystem operations, and is initialized to `/bundle`.\n\n[`process.chdir()`](https://nodejs.org/docs/latest/api/process.html#processchdirdirectory) allows modifying the `cwd` and is respected by FS operations when using `enable_nodejs_fs_module`.\n\nWhile [`process.hrtime`](https://nodejs.org/docs/latest/api/process.html#processhrtimetime) high-resolution timer is available, it provides an inaccurate timer for compatibility only.\n\n<page>\n---\ntitle: Streams - Node.js APIs · Cloudflare Workers docs\ndescription: The Node.js streams API is the original API for working with\n  streaming data in JavaScript, predating the WHATWG ReadableStream standard. A\n  stream is an abstract interface for working with streaming data in Node.js.\n  Streams can be readable, writable, or both. All streams are instances of\n  EventEmitter.\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/streams/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/streams/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\nThe [Node.js streams API](https://nodejs.org/api/stream.html) is the original API for working with streaming data in JavaScript, predating the [WHATWG ReadableStream standard](https://streams.spec.whatwg.org/). A stream is an abstract interface for working with streaming data in Node.js. Streams can be readable, writable, or both. All streams are instances of [EventEmitter](https://developers.cloudflare.com/workers/runtime-apis/nodejs/eventemitter/).\n\nWhere possible, you should use the [WHATWG standard \"Web Streams\" API](https://streams.spec.whatwg.org/), which is [supported in Workers](https://streams.spec.whatwg.org/).\n\nRefer to the [Node.js documentation for `stream`](https://nodejs.org/api/stream.html) for more information.\n\n<page>\n---\ntitle: StringDecoder · Cloudflare Workers docs\ndescription: \"The node:string_decoder is a legacy utility module that predates\n  the WHATWG standard TextEncoder and TextDecoder API. In most cases, you should\n  use TextEncoder and TextDecoder instead. StringDecoder is available in the\n  Workers runtime primarily for compatibility with existing npm packages that\n  rely on it. StringDecoder can be accessed using:\"\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/string-decoder/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/string-decoder/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\nThe [`node:string_decoder`](https://nodejs.org/api/string_decoder.html) is a legacy utility module that predates the WHATWG standard [TextEncoder](https://developers.cloudflare.com/workers/runtime-apis/encoding/#textencoder) and [TextDecoder](https://developers.cloudflare.com/workers/runtime-apis/encoding/#textdecoder) API. In most cases, you should use `TextEncoder` and `TextDecoder` instead. `StringDecoder` is available in the Workers runtime primarily for compatibility with existing npm packages that rely on it. `StringDecoder` can be accessed using:\n\nRefer to the [Node.js documentation for `string_decoder`](https://nodejs.org/dist/latest-v20.x/docs/api/string_decoder.html) for more information.\n\n<page>\n---\ntitle: test · Cloudflare Workers docs\ndescription: >-\n  The MockTracker API in Node.js provides a means of tracking and managing mock\n  objects in a test\n\nenvironment.\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/test/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/test/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\nThe `MockTracker` API in Node.js provides a means of tracking and managing mock objects in a test environment.\n\nThe full `MockTracker` API is documented in the [Node.js documentation for `MockTracker`](https://nodejs.org/docs/latest/api/test.html#class-mocktracker).\n\nThe Workers implementation of `MockTracker` currently does not include an implementation of the [Node.js mock timers API](https://nodejs.org/docs/latest/api/test.html#class-mocktimers).\n\n<page>\n---\ntitle: timers · Cloudflare Workers docs\ndescription: Use node:timers APIs to schedule functions to be executed later.\nlastUpdated: 2025-09-05T13:56:13.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/timers/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/timers/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\nUse [`node:timers`](https://nodejs.org/api/timers.html) APIs to schedule functions to be executed later.\n\nThis includes [`setTimeout`](https://nodejs.org/api/timers.html#settimeoutcallback-delay-args) for calling a function after a delay, [`setInterval`](https://nodejs.org/api/timers.html#clearintervaltimeout) for calling a function repeatedly, and [`setImmediate`](https://nodejs.org/api/timers.html#setimmediatecallback-args) for calling a function in the next iteration of the event loop.\n\nDue to [security-based restrictions on timers](https://developers.cloudflare.com/workers/reference/security-model/#step-1-disallow-timers-and-multi-threading) in Workers, timers are limited to returning the time of the last I/O. This means that while setTimeout, setInterval, and setImmediate will defer your function execution until after other events have run, they will not delay them for the full time specified.\n\nWhen called from a global level (on [`globalThis`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/globalThis)), functions such as `clearTimeout` and `setTimeout` will respect web standards rather than Node.js-specific functionality. For complete Node.js compatibility, you must call functions from the `node:timers` module.\n\nThe full `node:timers` API is documented in the [Node.js documentation for `node:timers`](https://nodejs.org/api/timers.html).\n\n<page>\n---\ntitle: tls · Cloudflare Workers docs\ndescription: |-\n  You can use node:tls to create secure connections to\n  external services using TLS (Transport Layer Security).\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/tls/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/tls/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\nYou can use [`node:tls`](https://nodejs.org/api/tls.html) to create secure connections to external services using [TLS](https://developer.mozilla.org/en-US/docs/Web/Security/Transport_Layer_Security) (Transport Layer Security).\n\nThe following APIs are available:\n\n* [`connect`](https://nodejs.org/api/tls.html#tlsconnectoptions-callback)\n* [`TLSSocket`](https://nodejs.org/api/tls.html#class-tlstlssocket)\n* [`checkServerIdentity`](https://nodejs.org/api/tls.html#tlscheckserveridentityhostname-cert)\n* [`createSecureContext`](https://nodejs.org/api/tls.html#tlscreatesecurecontextoptions)\n\nAll other APIs, including [`tls.Server`](https://nodejs.org/api/tls.html#class-tlsserver) and [`tls.createServer`](https://nodejs.org/api/tls.html#tlscreateserveroptions-secureconnectionlistener), are not supported and will throw a `Not implemented` error when called.\n\nThe full `node:tls` API is documented in the [Node.js documentation for `node:tls`](https://nodejs.org/api/tls.html).\n\n<page>\n---\ntitle: util · Cloudflare Workers docs\ndescription: The promisify and callbackify APIs in Node.js provide a means of\n  bridging between a Promise-based programming model and a callback-based model.\nlastUpdated: 2025-10-31T19:17:51.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/util/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/util/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\n## promisify/callbackify\n\nThe `promisify` and `callbackify` APIs in Node.js provide a means of bridging between a Promise-based programming model and a callback-based model.\n\nThe `promisify` method allows taking a Node.js-style callback function and converting it into a Promise-returning async function:\n\nSimilarly to `promisify`, `callbackify` converts a Promise-returning async function into a Node.js-style callback function:\n\n`callbackify` and `promisify` make it easy to handle all of the challenges that come with bridging between callbacks and promises.\n\nRefer to the [Node.js documentation for `callbackify`](https://nodejs.org/dist/latest-v19.x/docs/api/util.html#utilcallbackifyoriginal) and [Node.js documentation for `promisify`](https://nodejs.org/dist/latest-v19.x/docs/api/util.html#utilpromisifyoriginal) for more information.\n\nThe `util.types` API provides a reliable and efficient way of checking that values are instances of various built-in types.\n\nThe Workers implementation currently does not provide implementations of the `util.types.isExternal()`, `util.types.isProxy()`, `util.types.isKeyObject()`, or `util.type.isWebAssemblyCompiledModule()` APIs.\n\nFor more about `util.types`, refer to the [Node.js documentation for `util.types`](https://nodejs.org/dist/latest-v19.x/docs/api/util.html#utiltypes).\n\n`util.MIMEType` provides convenience methods that allow you to more easily work with and manipulate [MIME types](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types). For example:\n\nFor more about `util.MIMEType`, refer to the [Node.js documentation for `util.MIMEType`](https://nodejs.org/api/util.html#class-utilmimetype).\n\n<page>\n---\ntitle: url · Cloudflare Workers docs\ndescription: Returns the Punycode ASCII serialization of the domain. If domain\n  is an invalid domain, the empty string is returned.\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/url/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/url/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\nReturns the Punycode ASCII serialization of the domain. If domain is an invalid domain, the empty string is returned.\n\nReturns the Unicode serialization of the domain. If domain is an invalid domain, the empty string is returned.\n\nIt performs the inverse operation to `domainToASCII()`.\n\n<page>\n---\ntitle: zlib · Cloudflare Workers docs\ndescription: >-\n  The node:zlib module provides compression functionality implemented using\n  Gzip, Deflate/Inflate, and Brotli.\n\nTo access it:\nlastUpdated: 2025-08-20T18:47:44.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/nodejs/zlib/\n  md: https://developers.cloudflare.com/workers/runtime-apis/nodejs/zlib/index.md\n---\n\nTo enable built-in Node.js APIs and polyfills, add the nodejs\\_compat compatibility flag to your [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). This also enables nodejs\\_compat\\_v2 as long as your compatibility date is 2024-09-23 or later. [Learn more about the Node.js compatibility flag and v2](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag).\n\nThe node:zlib module provides compression functionality implemented using Gzip, Deflate/Inflate, and Brotli. To access it:\n\nThe full `node:zlib` API is documented in the [Node.js documentation for `node:zlib`](https://nodejs.org/api/zlib.html).\n\n<page>\n---\ntitle: Workers RPC — Error Handling · Cloudflare Workers docs\ndescription: How exceptions, stack traces, and logging works with the Workers RPC system.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/rpc/error-handling/\n  md: https://developers.cloudflare.com/workers/runtime-apis/rpc/error-handling/index.md\n---\n\nAn exception thrown by an RPC method implementation will propagate to the caller. If it is one of the standard JavaScript Error types, the `message` and prototype's `name` will be retained, though the stack trace is not.\n\n### Unsupported error types\n\n* If an [`AggregateError`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/AggregateError) is thrown by an RPC method, it is not propagated back to the caller.\n* The [`SuppressedError`](https://github.com/tc39/proposal-explicit-resource-management?tab=readme-ov-file#the-suppressederror-error) type from the Explicit Resource Management proposal is not currently implemented or supported in Workers.\n* Own properties of error objects, such as the [`cause`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Error/cause) property, are not propagated back to the caller\n\n## Additional properties\n\nFor some remote exceptions, the runtime may set properties on the propagated exception to provide more information about the error; see [Durable Object error handling](https://developers.cloudflare.com/durable-objects/best-practices/error-handling) for more details.\n\n<page>\n---\ntitle: Workers RPC — Lifecycle · Cloudflare Workers docs\ndescription: Memory management, resource management, and the lifecycle of RPC stubs.\nlastUpdated: 2025-03-21T11:16:31.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/rpc/lifecycle/\n  md: https://developers.cloudflare.com/workers/runtime-apis/rpc/lifecycle/index.md\n---\n\n## Lifetimes, Memory and Resource Management\n\nWhen you call another Worker over RPC using a Service binding, you are using memory in the Worker you are calling. Consider the following example:\n\nAssume that `findUser()` on the server side returns an object extending `RpcTarget`, thus `user` on the client side ends up being a stub pointing to that remote object.\n\nAs long as the stub still exists on the client, the corresponding object on the server cannot be garbage collected. But, each isolate has its own garbage collector which cannot see into other isolates. So, in order for the server's isolate to know that the object can be collected, the calling isolate must send it an explicit signal saying so, called \"disposing\" the stub.\n\nIn many cases (described below), the system will automatically realize when a stub is no longer needed, and will dispose it automatically. However, for best performance, your code should dispose stubs explicitly when it is done with them.\n\n## Explicit Resource Management\n\nTo ensure resources are properly disposed of, you should use [Explicit Resource Management](https://github.com/tc39/proposal-explicit-resource-management), a new JavaScript language feature that allows you to explicitly signal when resources can be disposed of. Explicit Resource Management is a Stage 3 TC39 proposal — it is [coming to V8 soon](https://bugs.chromium.org/p/v8/issues/detail?id=13559).\n\nExplicit Resource Management adds the following language features:\n\n* The [`using` declaration](https://github.com/tc39/proposal-explicit-resource-management?tab=readme-ov-file#using-declarations)\n* [`Symbol.dispose` and `Symbol.asyncDispose`](https://github.com/tc39/proposal-explicit-resource-management?tab=readme-ov-file#additions-to-symbol)\n\nIf a variable is declared with `using`, when the variable is no longer in scope, the variable's disposer will be invoked. For example:\n\n`using` declarations are useful to make sure you can't forget to dispose stubs — even if your code is interrupted by an exception.\n\n### How to use the `using` declaration in your Worker\n\n[Wrangler](https://developers.cloudflare.com/workers/wrangler/) v4+ supports the `using` keyword natively. If you are using an earlier version of Wrangler, you will need to manually dispose of resources instead.\n\n## Automatic disposal and execution contexts\n\nThe RPC system automatically disposes of stubs in the following cases:\n\n### End of event handler / execution context\n\nWhen an event handler is \"done\", any stubs created as part of the event are automatically disposed.\n\nFor example, consider a [`fetch()` handler](https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch) which handles incoming HTTP events. The handler may make outgoing RPCs as part of handling the event, and those may return stubs. When the final HTTP response is sent, the handler is \"done\", and all stubs are immediately disposed.\n\nMore precisely, the event has an \"execution context\", which begins when the handler is first invoked, and ends when the HTTP response is sent. The execution context may also end early if the client disconnects before receiving a response, or it can be extended past its normal end point by calling [`ctx.waitUntil()`](https://developers.cloudflare.com/workers/runtime-apis/context).\n\nFor example, the Worker below does not make use of the `using` declaration, but stubs will be disposed of once the `fetch()` handler returns a response:\n\nA Worker invoked via RPC also has an execution context. The context begins when an RPC method on a `WorkerEntrypoint` is invoked. If no stubs are passed in the parameters or results of this RPC, the context ends (the event is \"done\") when the RPC returns. However, if any stubs are passed, then the execution context is implicitly extended until all such stubs are disposed (and all calls made through them have returned). As with HTTP, if the client disconnects, the server's execution context is canceled immediately, regardless of whether stubs still exist. A client that is itself another Worker is considered to have disconnected when its own execution context ends. Again, the context can be extended with [`ctx.waitUntil()`](https://developers.cloudflare.com/workers/runtime-apis/context).\n\n### Stubs received as parameters in an RPC call\n\nWhen stubs are received in the parameters of an RPC, those stubs are automatically disposed when the call returns. If you wish to keep the stubs longer than that, you must call the `dup()` method on them.\n\n### Disposing RPC objects disposes stubs that are part of that object\n\nWhen an RPC returns any kind of object, that object will have a disposer added by the system. Disposing it will dispose all stubs returned by the call. For instance, if an RPC returns an array of four stubs, the array itself will have a disposer that disposes all four stubs. The only time the value returned by an RPC does not have a disposer is when it is a primitive value, such as a number or string. These types cannot have disposers added to them, but because these types cannot themselves contain stubs, there is no need for a disposer in this case.\n\nThis means you should almost always store the result of an RPC into a `using` declaration:\n\nThis way, if the result contains any stubs, they will be disposed of. Even if you don't expect the RPC to return stubs, if it returns any kind of an object, it is a good idea to store it into a `using` declaration. This way, if the RPC is extended in the future to return stubs, your code is ready.\n\nIf you decide you want to keep a returned stub beyond the scope of the `using` declaration, you can call `dup()` on the stub before the end of the scope. (Remember to explicitly dispose the duplicate later.)\n\n## Disposers and `RpcTarget` classes\n\nA class that extends [`RpcTarget`](https://developers.cloudflare.com/workers/runtime-apis/rpc/) can optionally implement a disposer:\n\nThe RpcTarget's disposer runs after the last stub is disposed. Note that the client-side call to the stub's disposer does not wait for the server-side disposer to be called; the server's disposer is called later on. Because of this, any exceptions thrown by the disposer do not propagate to the client; instead, they are reported as uncaught exceptions. Note that an `RpcTarget`'s disposer must be declared as `Symbol.dispose`. `Symbol.asyncDispose` is not supported.\n\n## The `dup()` method\n\nSometimes, you need to pass a stub to a function which will dispose the stub when it is done, but you also want to keep the stub for later use. To solve this problem, you can \"dup\" the stub:\n\nYou can think of `dup()` like the [Unix system call of the same name](https://man7.org/linux/man-pages/man2/dup.2.html): it creates a new handle pointing at the same target, which must be independently closed (disposed).\n\nIf the instance of the [`RpcTarget` class](https://developers.cloudflare.com/workers/runtime-apis/rpc/) that the stubs point to has a disposer, the disposer will only be invoked when all duplicates have been disposed. However, this only applies to duplicates that originate from the same stub. If the same instance of `RpcTarget` is passed over RPC multiple times, a new stub is created each time, and these are not considered duplicates of each other. Thus, the disposer will be invoked once for each time the `RpcTarget` was sent.\n\nIn order to avoid this situation, you can manually create a stub locally, and then pass the stub across RPC multiple times. When passing a stub over RPC, ownership of the stub transfers to the recipient, so you must make a `dup()` for each time you send it:\n\n<page>\n---\ntitle: Workers RPC — Reserved Methods · Cloudflare Workers docs\ndescription: Reserved methods with special behavior that are treated differently.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/rpc/reserved-methods/\n  md: https://developers.cloudflare.com/workers/runtime-apis/rpc/reserved-methods/index.md\n---\n\nSome method names are reserved or have special semantics.\n\nFor backwards compatibility, when extending `WorkerEntrypoint` or `DurableObject`, the following method names have special semantics. Note that this does *not* apply to `RpcTarget`. On `RpcTarget`, these methods work like any other RPC method.\n\nThe `fetch()` method is treated specially — it can only be used to handle an HTTP request — equivalent to the [fetch handler](https://developers.cloudflare.com/workers/runtime-apis/handlers/fetch/).\n\nYou may implement a `fetch()` method in your class that extends `WorkerEntrypoint` — but it must accept only one parameter of type [`Request`](https://developer.mozilla.org/en-US/docs/Web/API/Request), and must return an instance of [`Response`](https://developer.mozilla.org/en-US/docs/Web/API/Response), or a [Promise](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise) of one.\n\nOn the client side, `fetch()` called on a service binding or Durable Object stub works like the standard global `fetch()`. That is, the caller may pass one or two parameters to `fetch()`. If the caller does not simply pass a single `Request` object, then a new `Request` is implicitly constructed, passing the parameters to its constructor, and that request is what is actually sent to the server.\n\nSome properties of `Request` control the behavior of `fetch()` on the client side and are not actually sent to the server. For example, the property `redirect: \"auto\"` (which is the default) instructs `fetch()` that if the server returns a redirect response, it should automatically be followed, resulting in an HTTP request to the public internet. Again, this behavior is according to the Fetch API standard. In short, `fetch()` doesn't have RPC semantics, it has Fetch API semantics.\n\nThe `connect()` method of the `WorkerEntrypoint` class is reserved for opening a socket-like connection to your Worker. This is currently not implemented or supported — though you can [open a TCP socket from a Worker](https://developers.cloudflare.com/workers/runtime-apis/tcp-sockets/) or connect directly to databases over a TCP socket with [Hyperdrive](https://developers.cloudflare.com/hyperdrive/get-started/).\n\n## Disallowed Method Names\n\nThe following method (or property) names may not be used as RPC methods on any RPC type (including `WorkerEntrypoint`, `DurableObject`, and `RpcTarget`):\n\n* `dup`: This is reserved for duplicating a stub. Refer to the [RPC Lifecycle](https://developers.cloudflare.com/workers/runtime-apis/rpc/lifecycle) docs to learn more about `dup()`.\n* `constructor`: This name has special meaning for JavaScript classes. It is not intended to be called as a method, so it is not allowed over RPC.\n\nThe following methods are disallowed only on `WorkerEntrypoint` and `DurableObject`, but allowed on `RpcTarget`. These methods have historically had special meaning to Durable Objects, where they are used to handle certain system-generated events.\n\n* `alarm`\n* `webSocketMessage`\n* `webSocketClose`\n* `webSocketError`\n\n<page>\n---\ntitle: Workers RPC — Visibility and Security Model · Cloudflare Workers docs\ndescription: Which properties are and are not exposed to clients that\n  communicate with your Worker or Durable Object via RPC\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/rpc/visibility/\n  md: https://developers.cloudflare.com/workers/runtime-apis/rpc/visibility/index.md\n---\n\nThe Workers RPC system is intended to allow safe communications between Workers that do not trust each other. The system does not allow either side of an RPC session to access arbitrary objects on the other side, much less invoke arbitrary code. Instead, each side can only invoke the objects and functions for which they have explicitly received stubs via previous calls.\n\nThis security model is commonly known as Object Capabilities, or Capability-Based Security. Workers RPC is built on [Cap'n Proto RPC](https://capnproto.org/rpc.html), which in turn is based on CapTP, the object transport protocol used by the [distributed programming language E](https://www.crockford.com/ec/etut.html).\n\n## Visibility of Methods and Properties\n\n### Private properties\n\n[Private properties](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes/Private_properties) of classes are not directly exposed over RPC.\n\n### Class instance properties\n\nWhen you send an instance of an application-defined class, the recipient can only access methods and properties declared on the class, not properties of the instance. For example:\n\nThis behavior is intentional — it is intended to protect you from accidentally exposing private class internals. Generally, instance properties should be declared private, [by prefixing them with `#`](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes/Private_properties). However, private properties are a relatively new feature of JavaScript, and are not yet widely used in the ecosystem.\n\nSince the RPC interface between two of your Workers may be a security boundary, we need to be extra-careful, so instance properties are always private when communicating between Workers using RPC, whether or not they have the `#` prefix. You can always declare an explicit getter at the class level if you wish to expose the property, as shown above.\n\nThese visibility rules apply only to objects that extend `RpcTarget`, `WorkerEntrypoint`, or `DurableObject`, and do not apply to plain objects. Plain objects are passed \"by value\", sending all of their \"own\" properties.\n\n### \"Own\" properties of functions\n\nWhen you pass a function over RPC, the caller can access the \"own\" properties of the function object itself.\n\nSuch properties on a function are accessed asynchronously, like class properties of an RpcTarget. But, unlike the `RpcTarget` example above, the function's instance properties that are accessible to the caller. In practice, properties are rarely added to functions.\n\n<page>\n---\ntitle: Workers RPC — TypeScript · Cloudflare Workers docs\ndescription: How TypeScript types for your Worker or Durable Object's RPC\n  methods are generated and exposed to clients\nlastUpdated: 2025-07-29T09:45:03.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/rpc/typescript/\n  md: https://developers.cloudflare.com/workers/runtime-apis/rpc/typescript/index.md\n---\n\nRunning [`wrangler types`](https://developers.cloudflare.com/workers/languages/typescript/#generate-types) generates runtime types including the `Service` and `DurableObjectNamespace` types, each of which accepts a single type parameter for the [`WorkerEntrypoint`](https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings/rpc) or [`DurableObject`](https://developers.cloudflare.com/durable-objects/best-practices/create-durable-object-stubs-and-send-requests/#call-rpc-methods) types.\n\nUsing higher-order types, we automatically generate client-side stub types (e.g., forcing all methods to be async).\n\n[`wrangler types`](https://developers.cloudflare.com/workers/languages/typescript/#generate-types) also generates types for the `env` object. You can pass in the path to the config files of the Worker or Durable Object being called so that the generated types include the type parameters for the `Service` and `DurableObjectNamespace` types.\n\nFor example, if your client Worker had bindings to a Worker in `../sum-worker/` and a Durable Object in `../counter/`, you should generate types for the client Worker's `env` by running:\n\nThis will produce a `worker-configuration.d.ts` file that includes:\n\nNow types for RPC method like the `env.SUM_SERVICE.sum` method will be exposed to the client Worker.\n\n<page>\n---\ntitle: ReadableStream · Cloudflare Workers docs\ndescription: A ReadableStream is returned by the readable property inside TransformStream.\nlastUpdated: 2025-07-17T13:26:40.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/streams/readablestream/\n  md: https://developers.cloudflare.com/workers/runtime-apis/streams/readablestream/index.md\n---\n\nA `ReadableStream` is returned by the `readable` property inside [`TransformStream`](https://developers.cloudflare.com/workers/runtime-apis/streams/transformstream/).\n\n* `locked` boolean\n  * A Boolean value that indicates if the readable stream is locked to a reader.\n\n* `pipeTo(destinationWritableStream, optionsPipeToOptions)` : Promise\\<void>\n\n* Pipes the readable stream to a given writable stream `destination` and returns a promise that is fulfilled when the `write` operation succeeds or rejects it if the operation fails.\n\n* `getReader(optionsObject)` : ReadableStreamDefaultReader\n\n* Gets an instance of `ReadableStreamDefaultReader` and locks the `ReadableStream` to that reader instance. This method accepts an object argument indicating options. The only supported option is `mode`, which can be set to `byob` to create a [`ReadableStreamBYOBReader`](https://developers.cloudflare.com/workers/runtime-apis/streams/readablestreambyobreader/), as shown here:\n\n* `preventClose` bool\n\n* When `true`, closure of the source `ReadableStream` will not cause the destination `WritableStream` to be closed.\n\n* `preventAbort` bool\n\n* When `true`, errors in the source `ReadableStream` will no longer abort the destination `WritableStream`. `pipeTo` will return a rejected promise with the error from the source or any error that occurred while aborting the destination.\n\n* [Streams](https://developers.cloudflare.com/workers/runtime-apis/streams/)\n* [Readable streams in the WHATWG Streams API specification](https://streams.spec.whatwg.org/#rs-model)\n* [MDN’s `ReadableStream` documentation](https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream)\n\n<page>\n---\ntitle: ReadableStreamBYOBReader · Cloudflare Workers docs\ndescription: BYOB is an abbreviation of bring your own buffer. A\n  ReadableStreamBYOBReader allows reading into a developer-supplied buffer, thus\n  minimizing copies.\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/streams/readablestreambyobreader/\n  md: https://developers.cloudflare.com/workers/runtime-apis/streams/readablestreambyobreader/index.md\n---\n\n`BYOB` is an abbreviation of bring your own buffer. A `ReadableStreamBYOBReader` allows reading into a developer-supplied buffer, thus minimizing copies.\n\nAn instance of `ReadableStreamBYOBReader` is functionally identical to [`ReadableStreamDefaultReader`](https://developers.cloudflare.com/workers/runtime-apis/streams/readablestreamdefaultreader/) with the exception of the `read` method.\n\nA `ReadableStreamBYOBReader` is not instantiated via its constructor. Rather, it is retrieved from a [`ReadableStream`](https://developers.cloudflare.com/workers/runtime-apis/streams/readablestream/):\n\n* `read(bufferArrayBufferView)` : Promise\\<ReadableStreamBYOBReadResult>\n\n* Returns a promise with the next available chunk of data read into a passed-in buffer.\n\n* `readAtLeast(minBytes, bufferArrayBufferView)` : Promise\\<ReadableStreamBYOBReadResult>\n\n* Returns a promise with the next available chunk of data read into a passed-in buffer. The promise will not resolve until at least `minBytes` have been read.\n\n`read` provides no control over the minimum number of bytes that should be read into the buffer. Even if you allocate a 1 MiB buffer, the kernel is perfectly within its rights to fulfill this read with a single byte, whether or not an EOF immediately follows.\n\nIn practice, the Workers team has found that `read` typically fills only 1% of the provided buffer.\n\n`readAtLeast` is a non-standard extension to the Streams API which allows users to specify that at least `minBytes` bytes must be read into the buffer before resolving the read.\n\n* [Streams](https://developers.cloudflare.com/workers/runtime-apis/streams/)\n* [Background about BYOB readers in the Streams API WHATWG specification](https://streams.spec.whatwg.org/#byob-readers)\n\n<page>\n---\ntitle: ReadableStreamDefaultReader · Cloudflare Workers docs\ndescription: A reader is used when you want to read from a ReadableStream,\n  rather than piping its output to a WritableStream.\nlastUpdated: 2025-02-19T14:52:46.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/streams/readablestreamdefaultreader/\n  md: https://developers.cloudflare.com/workers/runtime-apis/streams/readablestreamdefaultreader/index.md\n---\n\nA reader is used when you want to read from a [`ReadableStream`](https://developers.cloudflare.com/workers/runtime-apis/streams/readablestream/), rather than piping its output to a [`WritableStream`](https://developers.cloudflare.com/workers/runtime-apis/streams/writablestream/).\n\nA `ReadableStreamDefaultReader` is not instantiated via its constructor. Rather, it is retrieved from a [`ReadableStream`](https://developers.cloudflare.com/workers/runtime-apis/streams/readablestream/):\n\n* `reader.closed` : Promise\n\n* A promise indicating if the reader is closed. The promise is fulfilled when the reader stream closes and is rejected if there is an error in the stream.\n\n* A promise that returns the next available chunk of data being passed through the reader queue.\n\n* `cancel(reasonstringoptional)` : void\n\n* Cancels the stream. `reason` is an optional human-readable string indicating the reason for cancellation. `reason` will be passed to the underlying source’s cancel algorithm -- if this readable stream is one side of a [`TransformStream`](https://developers.cloudflare.com/workers/runtime-apis/streams/transformstream/), then its cancel algorithm causes the transform’s writable side to become errored with `reason`.\n\nAny data not yet read is lost.\n\n* `releaseLock()` : void\n\n* Releases the lock on the readable stream. A lock cannot be released if the reader has pending read operations. A `TypeError` is thrown and the reader remains locked.\n\n* [Streams](https://developers.cloudflare.com/workers/runtime-apis/streams/)\n* [Readable streams in the WHATWG Streams API specification](https://streams.spec.whatwg.org/#rs-model)\n\n<page>\n---\ntitle: TransformStream · Cloudflare Workers docs\ndescription: \"A transform stream consists of a pair of streams: a writable\n  stream, known as its writable side, and a readable stream, known as its\n  readable side. Writes to the writable side result in new data being made\n  available for reading from the readable side.\"\nlastUpdated: 2024-08-13T19:56:56.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/streams/transformstream/\n  md: https://developers.cloudflare.com/workers/runtime-apis/streams/transformstream/index.md\n---\n\nA transform stream consists of a pair of streams: a writable stream, known as its writable side, and a readable stream, known as its readable side. Writes to the writable side result in new data being made available for reading from the readable side.\n\nWorkers currently only implements an identity transform stream, a type of transform stream which forwards all chunks written to its writable side to its readable side, without any changes.\n\n* `TransformStream()` TransformStream\n\n* Returns a new identity transform stream.\n\n* `readable` ReadableStream\n  * An instance of a `ReadableStream`.\n* `writable` WritableStream\n  * An instance of a `WritableStream`.\n\n## `IdentityTransformStream`\n\nThe current implementation of `TransformStream` in the Workers platform is not current compliant with the [Streams Standard](https://streams.spec.whatwg.org/#transform-stream) and we will soon be making changes to the implementation to make it conform with the specification. In preparation for doing so, we have introduced the `IdentityTransformStream` class that implements behavior identical to the current `TransformStream` class. This type of stream forwards all chunks of byte data (in the form of `TypedArray`s) written to its writable side to its readable side, without any changes.\n\nThe `IdentityTransformStream` readable side supports [bring your own buffer (BYOB) reads](https://developer.mozilla.org/en-US/docs/Web/API/ReadableStreamBYOBReader).\n\n* `IdentityTransformStream()` IdentityTransformStream\n\n* Returns a new identity transform stream.\n\n* `readable` ReadableStream\n  * An instance of a `ReadableStream`.\n* `writable` WritableStream\n  * An instance of a `WritableStream`.\n\n## `FixedLengthStream`\n\nThe `FixedLengthStream` is a specialization of `IdentityTransformStream` that limits the total number of bytes that the stream will passthrough. It is useful primarily because, when using `FixedLengthStream` to produce either a `Response` or `Request`, the fixed length of the stream will be used as the `Content-Length` header value as opposed to use chunked encoding when using any other type of stream. An error will occur if too many, or too few bytes are written through the stream.\n\n* `FixedLengthStream(length)` FixedLengthStream\n\n* Returns a new identity transform stream.\n  * `length` maybe a `number` or `bigint` with a maximum value of `2^53 - 1`.\n\n* `readable` ReadableStream\n  * An instance of a `ReadableStream`.\n* `writable` WritableStream\n  * An instance of a `WritableStream`.\n\n* [Streams](https://developers.cloudflare.com/workers/runtime-apis/streams/)\n* [Transform Streams in the WHATWG Streams API specification](https://streams.spec.whatwg.org/#transform-stream)\n\n<page>\n---\ntitle: WritableStream · Cloudflare Workers docs\ndescription: A WritableStream is the writable property of a TransformStream. On\n  the Workers platform, WritableStream cannot be directly created using the\n  WritableStream constructor.\nlastUpdated: 2025-02-19T14:52:46.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/streams/writablestream/\n  md: https://developers.cloudflare.com/workers/runtime-apis/streams/writablestream/index.md\n---\n\nA `WritableStream` is the `writable` property of a [`TransformStream`](https://developers.cloudflare.com/workers/runtime-apis/streams/transformstream/). On the Workers platform, `WritableStream` cannot be directly created using the `WritableStream` constructor.\n\nA typical way to write to a `WritableStream` is to pipe a [`ReadableStream`](https://developers.cloudflare.com/workers/runtime-apis/streams/readablestream/) to it.\n\nTo write to a `WritableStream` directly, you must use its writer.\n\nRefer to the [WritableStreamDefaultWriter](https://developers.cloudflare.com/workers/runtime-apis/streams/writablestreamdefaultwriter/) documentation for further detail.\n\n* A Boolean value to indicate if the writable stream is locked to a writer.\n\n* `abort(reasonstringoptional)` : Promise\\<void>\n\n* Aborts the stream. This method returns a promise that fulfills with a response `undefined`. `reason` is an optional human-readable string indicating the reason for cancellation. `reason` will be passed to the underlying sink’s abort algorithm. If this writable stream is one side of a [TransformStream](https://developers.cloudflare.com/workers/runtime-apis/streams/transformstream/), then its abort algorithm causes the transform’s readable side to become errored with `reason`.\n\nAny data not yet written is lost upon abort.\n\n* `getWriter()` : WritableStreamDefaultWriter\n\n* Gets an instance of `WritableStreamDefaultWriter` and locks the `WritableStream` to that writer instance.\n\n* [Streams](https://developers.cloudflare.com/workers/runtime-apis/streams/)\n* [Writable streams in the WHATWG Streams API specification](https://streams.spec.whatwg.org/#ws-model)\n\n<page>\n---\ntitle: WritableStreamDefaultWriter · Cloudflare Workers docs\ndescription: \"A writer is used when you want to write directly to a\n  WritableStream, rather than piping data to it from a ReadableStream. For\n  example:\"\nlastUpdated: 2025-02-19T14:52:46.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/streams/writablestreamdefaultwriter/\n  md: https://developers.cloudflare.com/workers/runtime-apis/streams/writablestreamdefaultwriter/index.md\n---\n\nA writer is used when you want to write directly to a [`WritableStream`](https://developers.cloudflare.com/workers/runtime-apis/streams/writablestream/), rather than piping data to it from a [`ReadableStream`](https://developers.cloudflare.com/workers/runtime-apis/streams/readablestream/). For example:\n\n* `writer.desiredSize` int\n\n* The size needed to fill the stream’s internal queue, as an integer. Always returns 1, 0 (if the stream is closed), or `null` (if the stream has errors).\n\n* `writer.closed` Promise\\<void>\n\n* A promise that indicates if the writer is closed. The promise is fulfilled when the writer stream is closed and rejected if there is an error in the stream.\n\n* `abort(reasonstringoptional)` : Promise\\<void>\n\n* Aborts the stream. This method returns a promise that fulfills with a response `undefined`. `reason` is an optional human-readable string indicating the reason for cancellation. `reason` will be passed to the underlying sink’s abort algorithm. If this writable stream is one side of a [TransformStream](https://developers.cloudflare.com/workers/runtime-apis/streams/transformstream/), then its abort algorithm causes the transform’s readable side to become errored with `reason`.\n\nAny data not yet written is lost upon abort.\n\n* `close()` : Promise\\<void>\n\n* Attempts to close the writer. Remaining writes finish processing before the writer is closed. This method returns a promise fulfilled with `undefined` if the writer successfully closes and processes the remaining writes, or rejected on any error.\n\n* `releaseLock()` : void\n\n* Releases the writer’s lock on the stream. Once released, the writer is no longer active. You can call this method before all pending `write(chunk)` calls are resolved. This allows you to queue a `write` operation, release the lock, and begin piping into the writable stream from another source, as shown in the example below.\n\n* `write(chunkany)` : Promise\\<void>\n\n* Writes a chunk of data to the writer and returns a promise that resolves if the operation succeeds.\n  * The underlying stream may accept fewer kinds of type than `any`, it will throw an exception when encountering an unexpected type.\n\n* [Streams](https://developers.cloudflare.com/workers/runtime-apis/streams/)\n* [Writable streams in the WHATWG Streams API specification](https://streams.spec.whatwg.org/#ws-model)\n\n<page>\n---\ntitle: Wasm in JavaScript · Cloudflare Workers docs\ndescription: >-\n  Wasm can be used from within a Worker written in JavaScript or TypeScript by\n  importing a Wasm module,\n\nand instantiating an instance of this module using WebAssembly.instantiate().\n  This can be used to accelerate computationally intensive operations which do\n  not involve significant I/O.\nlastUpdated: 2025-02-12T13:41:31.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/runtime-apis/webassembly/javascript/\n  md: https://developers.cloudflare.com/workers/runtime-apis/webassembly/javascript/index.md\n---\n\nWasm can be used from within a Worker written in JavaScript or TypeScript by importing a Wasm module, and instantiating an instance of this module using [`WebAssembly.instantiate()`](https://developer.mozilla.org/en-US/docs/WebAssembly/JavaScript_interface/instantiate). This can be used to accelerate computationally intensive operations which do not involve significant I/O.\n\nThis guide demonstrates the basics of Wasm and JavaScript interoperability.\n\n## Simple Wasm Module\n\nIn this guide, you will use the WebAssembly Text Format to create a simple Wasm module to understand how imports and exports work. In practice, you would not write code in this format. You would instead use the programming language of your choice and compile directly to WebAssembly Binary Format (`.wasm`).\n\nReview the following example module (`;;` denotes a comment):\n\nUsing [`wat2wasm`](https://github.com/WebAssembly/wabt), convert the WAT format to WebAssembly Binary Format:\n\nWrangler will bundle any Wasm module that ends in `.wasm` or `.wasm?module`, so that it is available at runtime within your Worker. This is done using a default bundling rule which can be customized in the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/). Refer to [Wrangler Bundling](https://developers.cloudflare.com/workers/wrangler/bundling/) for more information.\n\n## Use from JavaScript\n\nAfter you have converted the WAT format to WebAssembly Binary Format, import and use the Wasm module in your existing JavaScript or TypeScript Worker:\n\nWhen invoked, this Worker should log `Hello from JavaScript: 42` and return `Success: 42`, demonstrating the ability to invoke Wasm methods with arguments from JavaScript and vice versa.\n\nIn practice, you will likely compile a language of your choice (such as Rust) to WebAssembly binaries. Many languages provide a `bindgen` to simplify the interaction between JavaScript and Wasm. These tools may integrate with your JavaScript bundler, and provide an API other than the WebAssembly API for initializing and invoking your Wasm module. As an example, refer to the [Rust `wasm-bindgen` documentation](https://rustwasm.github.io/wasm-bindgen/examples/without-a-bundler.html).\n\nAlternatively, to write your entire Worker in Rust, Workers provides many of the same [Runtime APIs](https://developers.cloudflare.com/workers/runtime-apis) and [bindings](https://developers.cloudflare.com/workers/runtime-apis/bindings/) when using the `workers-rs` crate. For more information, refer to the [Workers Rust guide](https://developers.cloudflare.com/workers/languages/rust/).\n\n<page>\n---\ntitle: Developing · Cloudflare Workers docs\nlastUpdated: 2025-04-10T14:17:11.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/workers/testing/miniflare/developing/\n  md: https://developers.cloudflare.com/workers/testing/miniflare/developing/index.md\n---\n\n* [⚡️ Live Reload](https://developers.cloudflare.com/workers/testing/miniflare/developing/live-reload/)\n* [🐛 Attaching a Debugger](https://developers.cloudflare.com/workers/testing/miniflare/developing/debugger/)\n\n<page>\n---\ntitle: Core · Cloudflare Workers docs\nlastUpdated: 2025-04-10T14:17:11.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/workers/testing/miniflare/core/\n  md: https://developers.cloudflare.com/workers/testing/miniflare/core/index.md\n---\n\n* [⏰ Scheduled Events](https://developers.cloudflare.com/workers/testing/miniflare/core/scheduled/)\n* [✉️ WebSockets](https://developers.cloudflare.com/workers/testing/miniflare/core/web-sockets/)\n* [📅 Compatibility Dates](https://developers.cloudflare.com/workers/testing/miniflare/core/compatibility/)\n* [📚 Modules](https://developers.cloudflare.com/workers/testing/miniflare/core/modules/)\n* [📨 Fetch Events](https://developers.cloudflare.com/workers/testing/miniflare/core/fetch/)\n* [🔌 Multiple Workers](https://developers.cloudflare.com/workers/testing/miniflare/core/multiple-workers/)\n* [🔑 Variables and Secrets](https://developers.cloudflare.com/workers/testing/miniflare/core/variables-secrets/)\n* [🕸 Web Standards](https://developers.cloudflare.com/workers/testing/miniflare/core/standards/)\n* [🚥 Queues](https://developers.cloudflare.com/workers/testing/miniflare/core/queues/)\n\n<page>\n---\ntitle: Get Started · Cloudflare Workers docs\ndescription: The Miniflare API allows you to dispatch events to workers without\n  making actual HTTP requests, simulate connections between Workers, and\n  interact with local emulations of storage products like KV, R2, and Durable\n  Objects. This makes it great for writing tests, or other advanced use cases\n  where you need finer-grained control.\nlastUpdated: 2025-05-16T16:37:37.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/testing/miniflare/get-started/\n  md: https://developers.cloudflare.com/workers/testing/miniflare/get-started/index.md\n---\n\nThe Miniflare API allows you to dispatch events to workers without making actual HTTP requests, simulate connections between Workers, and interact with local emulations of storage products like [KV](https://developers.cloudflare.com/workers/testing/miniflare/storage/kv), [R2](https://developers.cloudflare.com/workers/testing/miniflare/storage/r2), and [Durable Objects](https://developers.cloudflare.com/workers/testing/miniflare/storage/durable-objects). This makes it great for writing tests, or other advanced use cases where you need finer-grained control.\n\nMiniflare is installed using `npm` as a dev dependency:\n\nIn all future examples, we'll assume Node.js is running in ES module mode. You can do this by setting the `type` field in your `package.json`:\n\nTo initialise Miniflare, import the `Miniflare` class from `miniflare`:\n\nThe [rest of these docs](https://developers.cloudflare.com/workers/testing/miniflare/core/fetch) go into more detail on configuring specific features.\n\n### String and File Scripts\n\nNote in the above example we're specifying `script` as a string. We could've equally put the script in a file such as `worker.js`, then used the `scriptPath` property instead:\n\n### Watching, Reloading and Disposing\n\nMiniflare's API is primarily intended for testing use cases, where file watching isn't usually required. If you need to watch files, consider using a separate file watcher like [fs.watch()](https://nodejs.org/api/fs.html#fswatchfilename-options-listener) or [chokidar](https://github.com/paulmillr/chokidar), and calling setOptions() with your original configuration on change.\n\nTo cleanup and stop listening for requests, you should `dispose()` your instances:\n\nYou can also manually reload scripts (main and Durable Objects') and options by calling `setOptions()` with the original configuration object.\n\n### Updating Options and the Global Scope\n\nYou can use the `setOptions` method to update the options of an existing `Miniflare` instance. This accepts the same options object as the `new Miniflare` constructor, applies those options, then reloads the worker.\n\n### Dispatching Events\n\n`getWorker` dispatches `fetch`, `queues`, and `scheduled` events to workers respectively:\n\nSee [📨 Fetch Events](https://developers.cloudflare.com/workers/testing/miniflare/core/fetch) and [⏰ Scheduled Events](https://developers.cloudflare.com/workers/testing/miniflare/core/scheduled) for more details.\n\nMiniflare starts an HTTP server automatically. To wait for it to be ready, `await` the `ready` property:\n\n#### `Request#cf` Object\n\nBy default, Miniflare will fetch the `Request#cf` object from a trusted Cloudflare endpoint. You can disable this behaviour, using the `cf` option:\n\nYou can also provide a custom cf object via a filepath:\n\nTo start an HTTPS server instead, set the `https` option. To use the [default shared self-signed certificate](https://github.com/cloudflare/workers-sdk/tree/main/packages/miniflare/src/http/cert.ts), set `https` to `true`:\n\nTo load an existing certificate from the file system:\n\nTo load an existing certificate from strings instead:\n\nIf both a string and path are specified for an option (e.g. `httpsKey` and `httpsKeyPath`), the string will be preferred.\n\nBy default, `[mf:*]` logs are disabled when using the API. To enable these, set the `log` property to an instance of the `Log` class. Its only parameter is a log level indicating which messages should be logged:\n\n<page>\n---\ntitle: Migrations · Cloudflare Workers docs\ndescription: Review migration guides for specific versions of Miniflare.\nlastUpdated: 2025-04-10T14:17:11.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/workers/testing/miniflare/migrations/\n  md: https://developers.cloudflare.com/workers/testing/miniflare/migrations/index.md\n---\n\n* [⬆️ Migrating from Version 2](https://developers.cloudflare.com/workers/testing/miniflare/migrations/from-v2/)\n\n<page>\n---\ntitle: Storage · Cloudflare Workers docs\nlastUpdated: 2025-04-10T14:17:11.000Z\nchatbotDeprioritize: true\nsource_url:\n  html: https://developers.cloudflare.com/workers/testing/miniflare/storage/\n  md: https://developers.cloudflare.com/workers/testing/miniflare/storage/index.md\n---\n\n* [✨ Cache](https://developers.cloudflare.com/workers/testing/miniflare/storage/cache/)\n* [💾 D1](https://developers.cloudflare.com/workers/testing/miniflare/storage/d1/)\n* [📌 Durable Objects](https://developers.cloudflare.com/workers/testing/miniflare/storage/durable-objects/)\n* [📦 KV](https://developers.cloudflare.com/workers/testing/miniflare/storage/kv/)\n* [🪣 R2](https://developers.cloudflare.com/workers/testing/miniflare/storage/r2/)\n\n<page>\n---\ntitle: Writing tests · Cloudflare Workers docs\ndescription: Write integration tests against Workers using Miniflare.\nlastUpdated: 2025-05-16T16:37:37.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/testing/miniflare/writing-tests/\n  md: https://developers.cloudflare.com/workers/testing/miniflare/writing-tests/index.md\n---\n\nFor most users, Cloudflare recommends using the Workers Vitest integration. If you have been using test environments from Miniflare, refer to the [Migrate from Miniflare 2 guide](https://developers.cloudflare.com/workers/testing/vitest-integration/migration-guides/migrate-from-miniflare-2/).\n\nThis guide will show you how to set up [Miniflare](https://developers.cloudflare.com/workers/testing/miniflare) to test your Workers. Miniflare is a low-level API that allows you to fully control how your Workers are run and tested.\n\nTo use Miniflare, make sure you've installed the latest version of Miniflare v3:\n\nThe rest of this guide demonstrates concepts with the [`node:test`](https://nodejs.org/api/test.html) testing framework, but any testing framework can be used.\n\nMiniflare is a low-level API that exposes a large variety of configuration options for running your Worker. In most cases, your tests will only need a subset of the available options, but you can refer to the [full API reference](https://developers.cloudflare.com/workers/testing/miniflare/get-started/#reference) to explore what is possible with Miniflare.\n\nBefore writing a test, you will need to create a Worker. Since Miniflare is a low-level API that emulates the Cloudflare platform primitives, your Worker will need to be written in JavaScript or you'll need to [integrate your own build pipeline](#custom-builds) into your testing setup. Here's an example JavaScript-only Worker:\n\nNext, you will need to create an initial test file:\n\nYou should be able to run the above test via `node --test`\n\nThe highlighted lines of the test file above demonstrate how to set up Miniflare to run a JavaScript Worker. Once Miniflare has been set up, your individual tests can send requests to the running Worker and assert against the responses. This is the main limitation of using Miniflare for testing your Worker as compared to the [Vitest integration](https://developers.cloudflare.com/workers/testing/vitest-integration/) — all access to your Worker must be through the `dispatchFetch()` Miniflare API, and you cannot unit test individual functions from your Worker.\n\nWhat runtime are tests running in?\n\nWhen using the [Vitest integration](https://developers.cloudflare.com/workers/testing/vitest-integration/), your entire test suite runs in [`workerd`](https://github.com/cloudflare/workerd), which is why it is possible to unit test individual functions. By contrast, when using a different testing framework to run tests via Miniflare, only your Worker itself is running in [`workerd`](https://github.com/cloudflare/workerd) — your test files run in Node.js. This means that importing functions from your Worker into your test files might exhibit different behaviour than you'd see at runtime if the functions rely on `workerd`-specific behaviour.\n\n## Interacting with Bindings\n\nMiniflare does not read [Wrangler's config file](https://developers.cloudflare.com/workers/wrangler/configuration). All bindings that your Worker uses need to be specified in the Miniflare API options.\n\nThe `dispatchFetch()` API from Miniflare allows you to send requests to your Worker and assert that the correct response is returned, but sometimes you need to interact directly with bindings in tests. For use cases like that, Miniflare provides the [`getBindings()`](https://developers.cloudflare.com/workers/testing/miniflare/get-started/#reference) API. For instance, to access an environment variable in your tests, adapt the test file `src/index.test.js` as follows:\n\nYou can also interact with local resources such as KV and R2 using the same API as you would from a Worker. For example, here's how you would interact with a KV namespace:\n\n## More complex Workers\n\nThe example given above shows how to test a simple Worker consisting of a single JavaScript file. However, most real-world Workers are more complex than that. Miniflare supports providing all constituent files of your Worker directly using the API:\n\nThis can be a bit cumbersome as your Worker grows. To help with this, Miniflare can also crawl your module graph to automatically figure out which modules to include:\n\nIn many real-world cases, Workers are not written in plain JavaScript but instead consist of multiple TypeScript files that import from npm packages and other dependencies, which are then bundled by a build tool. When testing your Worker via Miniflare directly you need to run this build tool before your tests. Exactly how this build is run will depend on the specific test framework you use, but for `node:test` it would likely be in a `setup()` hook. For example, if you use [Wrangler](https://developers.cloudflare.com/workers/wrangler/) to build and deploy your Worker, you could spawn a `wrangler build` command like this:\n\n<page>\n---\ntitle: Debugging · Cloudflare Workers docs\ndescription: Debug your Workers tests with Vitest.\nlastUpdated: 2025-03-04T10:04:51.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/testing/vitest-integration/debugging/\n  md: https://developers.cloudflare.com/workers/testing/vitest-integration/debugging/index.md\n---\n\nThis guide shows you how to debug your Workers tests with Vitest. This is available with `@cloudflare/vitest-pool-workers` v0.7.5 or later.\n\n## Open inspector with Vitest\n\nTo start debugging, run Vitest with the following command and attach a debugger to port `9229`:\n\n## Customize the inspector port\n\nBy default, the inspector will be opened on port `9229`. If you need to use a different port (for example, `3456`), you can run the following command:\n\nAlternatively, you can define it in your Vitest configuration file:\n\n## Setup VS Code to use breakpoints\n\nTo setup VS Code for breakpoint debugging in your Worker tests, create a `.vscode/launch.json` file that contains the following configuration:\n\nSelect **Debug Workers tests** at the top of the **Run & Debug** panel to open an inspector with Vitest and attach a debugger to the Workers runtime. Then you can add breakpoints to your test files and start debugging.\n\n<page>\n---\ntitle: Configuration · Cloudflare Workers docs\ndescription: Vitest configuration specific to the Workers integration.\nlastUpdated: 2025-04-10T14:17:11.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/testing/vitest-integration/configuration/\n  md: https://developers.cloudflare.com/workers/testing/vitest-integration/configuration/index.md\n---\n\nThe Workers Vitest integration provides additional configuration on top of Vitest's usual options using the [`defineWorkersConfig()`](https://developers.cloudflare.com/workers/testing/vitest-integration/configuration/#defineworkersconfigoptions) API.\n\nAn example configuration would be:\n\nCustom Vitest `environment`s or `runner`s are not supported when using the Workers Vitest integration.\n\nThe following APIs are exported from the `@cloudflare/vitest-pool-workers/config` module.\n\n### `defineWorkersConfig(options)`\n\nEnsures Vitest is configured to use the Workers integration with the correct module resolution settings, and provides type checking for [WorkersPoolOptions](#workerspooloptions). This should be used in place of the [`defineConfig()`](https://vitest.dev/config/file.html) function from Vitest.\n\nIt also accepts a `Promise` of `options`, or an optionally-`async` function returning `options`.\n\n### `defineWorkersProject(options)`\n\nUse [`defineWorkersProject`](#defineworkersprojectoptions) with [Vitest Workspaces](https://vitest.dev/guide/workspace) to specify a different configuration for certain tests. It should be used in place of the [`defineProject()`](https://vitest.dev/guide/workspace) function from Vitest.\n\nSimilar to [`defineWorkersConfig()`](#defineworkersconfigoptions), this ensures Vitest is configured to use the Workers integration with the correct module resolution settings, and provides type checking for [WorkersPoolOptions](#workerspooloptions).\n\nIt also accepts a `Promise` of `options`, or an optionally-`async` function returning `options`.\n\n### `buildPagesASSETSBinding(assetsPath)`\n\nCreates a Pages ASSETS binding that serves files insides the `assetsPath`. This is required if you uses `createPagesEventContext()` or `SELF` to test your **Pages Functions**. Refer to the [Pages recipe](https://developers.cloudflare.com/workers/testing/vitest-integration/recipes) for a full example.\n\n### `readD1Migrations(migrationsPath)`\n\nReads all [D1 migrations](https://developers.cloudflare.com/d1/reference/migrations/) stored at `migrationsPath` and returns them ordered by migration number. Each migration will have its contents split into an array of individual SQL queries. Call the [`applyD1Migrations()`](https://developers.cloudflare.com/workers/testing/vitest-integration/test-apis/#d1) function inside a test or [setup file](https://vitest.dev/config/#setupfiles) to apply migrations. Refer to the [D1 recipe](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/d1) for an example project using migrations.\n\n## `WorkersPoolOptions`\n\n* `main`: string optional\n\n* Entry point to Worker run in the same isolate/context as tests. This option is required to use `import { SELF } from \"cloudflare:test\"` for integration tests, or Durable Objects without an explicit `scriptName` if classes are defined in the same Worker. This file goes through Vite transforms and can be TypeScript. Note that `import module from \"<path-to-main>\"` inside tests gives exactly the same `module` instance as is used internally for the `SELF` and Durable Object bindings. If `wrangler.configPath` is defined and this option is not, it will be read from the `main` field in that configuration file.\n\n* `isolatedStorage`: boolean optional\n\n* Enables per-test isolated storage. If enabled, any writes to storage performed in a test will be undone at the end of the test. The test's storage environment is copied from the containing suite, meaning `beforeAll()` hooks can be used to seed data. If this option is disabled, all tests will share the same storage. `.concurrent` tests are not supported when isolated storage is enabled. Refer to [Isolation and concurrency](https://developers.cloudflare.com/workers/testing/vitest-integration/isolation-and-concurrency/) for more information on the isolation model.\n\n* Defaults to `true`.\n\n* `singleWorker`: boolean optional\n\n* Runs all tests in this project serially in the same Worker, using the same module cache. This can significantly speed up execution if you have lots of small test files. Refer to the [Isolation and concurrency](https://developers.cloudflare.com/workers/testing/vitest-integration/isolation-and-concurrency/) page for more information on the isolation model.\n\n* Defaults to `false`.\n\n* `miniflare`: `SourcelessWorkerOptions & { workers?: WorkerOptions\\[]; }` optional\n\n* Use this to provide configuration information that is typically stored within the [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/), such as [bindings](https://developers.cloudflare.com/workers/runtime-apis/bindings/), [compatibility dates](https://developers.cloudflare.com/workers/configuration/compatibility-dates/), and [compatibility flags](https://developers.cloudflare.com/workers/configuration/compatibility-flags/). The `WorkerOptions` interface is defined [here](https://github.com/cloudflare/workers-sdk/tree/main/packages/miniflare#interface-workeroptions). Use the `main` option above to configure the entry point, instead of the Miniflare `script`, `scriptPath`, or `modules` options.\n\n* If your project makes use of multiple Workers, you can configure auxiliary Workers that run in the same `workerd` process as your tests and can be bound to. Auxiliary Workers are configured using the `workers` array, containing regular Miniflare [`WorkerOptions`](https://github.com/cloudflare/workers-sdk/tree/main/packages/miniflare#interface-workeroptions) objects. Note that unlike the `main` Worker, auxiliary Workers:\n\n* Cannot have TypeScript entrypoints. You must compile auxiliary Workers to JavaScript first. You can use the [`wrangler deploy --dry-run --outdir dist`](https://developers.cloudflare.com/workers/wrangler/commands/#deploy) command for this.\n    * Use regular Workers module resolution semantics. Refer to the [Isolation and concurrency](https://developers.cloudflare.com/workers/testing/vitest-integration/isolation-and-concurrency/#modules) page for more information.\n    * Cannot access the [`cloudflare:test`](https://developers.cloudflare.com/workers/testing/vitest-integration/test-apis/) module.\n    * Do not require specific compatibility dates or flags.\n    * Can be written with the [Service Worker syntax](https://developers.cloudflare.com/workers/reference/migrate-to-module-workers/#service-worker-syntax).\n    * Are not affected by global mocks defined in your tests.\n\n* `wrangler`: `{ configPath?: string; environment?: string; }` optional\n\n* Path to [Wrangler configuration file](https://developers.cloudflare.com/workers/wrangler/configuration/) to load `main`, [compatibility settings](https://developers.cloudflare.com/workers/configuration/compatibility-dates/) and [bindings](https://developers.cloudflare.com/workers/runtime-apis/bindings/) from. These options will be merged with the `miniflare` option above, with `miniflare` values taking precedence. For example, if your Wrangler configuration defined a [service binding](https://developers.cloudflare.com/workers/runtime-apis/bindings/service-bindings/) named `SERVICE` to a Worker named `service`, but you included `serviceBindings: { SERVICE(request) { return new Response(\"body\"); } }` in the `miniflare` option, all requests to `SERVICE` in tests would return `body`. Note `configPath` accepts both `.toml` and `.json` files.\n\n* The environment option can be used to specify the [Wrangler environment](https://developers.cloudflare.com/workers/wrangler/environments/) to pick up bindings and variables from.\n\n## `WorkersPoolOptionsContext`\n\n* `inject`: typeof import(\"vitest\").inject\n\n* The same `inject()` function usually imported from the `vitest` module inside tests. This allows you to define `miniflare` configuration based on injected values from [`globalSetup`](https://vitest.dev/config/#globalsetup) scripts. Use this if you have a value in your configuration that is dynamically generated and only known at runtime of your tests. For example, a global setup script might start an upstream server on a random port. This port could be `provide()`d and then `inject()`ed in the configuration for an external service binding or [Hyperdrive](https://developers.cloudflare.com/hyperdrive/). Refer to the [Hyperdrive recipe](https://github.com/cloudflare/workers-sdk/tree/main/fixtures/vitest-pool-workers-examples/hyperdrive) for an example project using this provide/inject approach.\n\n## `SourcelessWorkerOptions`\n\nSourceless `WorkerOptions` type without `script`, `scriptPath`, or `modules` properties. Refer to the Miniflare [`WorkerOptions`](https://github.com/cloudflare/workers-sdk/tree/main/packages/miniflare#interface-workeroptions) type for more details.\n\n<page>\n---\ntitle: Isolation and concurrency · Cloudflare Workers docs\ndescription: Review how the Workers Vitest integration runs your tests, how it\n  isolates tests from each other, and how it imports modules.\nlastUpdated: 2025-01-08T12:19:30.000Z\nchatbotDeprioritize: false\nsource_url:\n  html: https://developers.cloudflare.com/workers/testing/vitest-integration/isolation-and-concurrency/\n  md: https://developers.cloudflare.com/workers/testing/vitest-integration/isolation-and-concurrency/index.md\n---\n\nReview how the Workers Vitest integration runs your tests, how it isolates tests from each other, and how it imports modules.\n\nWhen you run your tests with the Workers Vitest integration, Vitest will:\n\n1. Read and evaluate your configuration file using Node.js.\n2. Run any [`globalSetup`](https://vitest.dev/config/#globalsetup) files using Node.js.\n3. Collect and sequence test files.\n4. For each Vitest project, depending on its configured isolation and concurrency, start one or more [`workerd`](https://github.com/cloudflare/workerd) processes, each running one or more Workers.\n5. Run [`setupFiles`](https://vitest.dev/config/#setupfiles) and test files in `workerd` using the appropriate Workers.\n6. Watch for changes and re-run test files using the same Workers if the configuration has not changed.\n\n## Isolation and concurrency models\n\nThe [`isolatedStorage` and `singleWorker`](https://developers.cloudflare.com/workers/testing/vitest-integration/configuration/#workerspooloptions) configuration options both control isolation and concurrency. The Workers Vitest integration tries to minimise the number of `workerd` processes it starts, reusing Workers and their module caches between test runs where possible. The current implementation of isolated storage requires each `workerd` process to run one test file at a time, and does not support `.concurrent` tests. A copy of all auxiliary `workers` exists in each `workerd` process.\n\nBy default, the `isolatedStorage` option is enabled. We recommend you enable the `singleWorker: true` option if you have lots of small test files.\n\n### `isolatedStorage: true, singleWorker: false` (Default)\n\nIn this model, a `workerd` process is started for each test file. Test files are executed concurrently but `.concurrent` tests are not supported. Each test will read/write from an isolated storage environment, and bind to its own set of auxiliary `workers`.\n\n![Isolation Model: Isolated Storage & No Single Worker](https://developers.cloudflare.com/_astro/isolation-model-3-isolated-storage-no-single-worker.DigZKXdc_t0LpD.svg)\n\n### `isolatedStorage: true, singleWorker: true`\n\nIn this model, a single `workerd` process is started with a single Worker for all test files. Test files are executed in serial and `.concurrent` tests are not supported. Each test will read/write from an isolated storage environment, and bind to the same auxiliary `workers`.\n\n![Isolation Model: Isolated Storage & Single Worker](https://developers.cloudflare.com/_astro/isolation-model-4-isolated-storage-single-worker.DVzBSzPO_f5qSq.svg)\n\n### `isolatedStorage: false, singleWorker: false`\n\nIn this model, a single `workerd` process is started with a Worker for each test file. Tests files are executed concurrently and `.concurrent` tests are supported. Every test will read/write from the same shared storage, and bind to the same auxiliary `workers`.\n\n![Isolation Model: No Isolated Storage & No Single Worker](https://developers.cloudflare.com/_astro/isolation-model-1-no-isolated-storage-no-single-worker.BFp0f7BV_f5qSq.svg)\n\n### `isolatedStorage: false, singleWorker: true`\n\nIn this model, a single `workerd` process is started with a single Worker for all test files. Test files are executed in serial but `.concurrent` tests are supported. Every test will read/write from the same shared storage, and bind to the same auxiliary `workers`.\n\n![Isolation Model: No Isolated Storage & Single Worker](https://developers.cloudflare.com/_astro/isolation-model-2-no-isolated-storage-single-worker.CA-pStER_f5qSq.svg)\n\nEach Worker has its own module cache. As Workers are reused between test runs, their module caches are also reused. Vitest invalidates parts of the module cache at the start of each test run based on changed files.\n\nThe Workers Vitest pool works by running code inside a Cloudflare Worker that Vitest would usually run inside a [Node.js Worker thread](https://nodejs.org/api/worker_threads.html). To make this possible, the pool **automatically injects** the [`nodejs_compat`](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#nodejs-compatibility-flag), \\[`no_nodejs_compat_v2`] and [`export_commonjs_default`](https://developers.cloudflare.com/workers/configuration/compatibility-flags/#commonjs-modules-do-not-export-a-module-namespace) compatibility flags. This is the minimal compatibility setup that still allows Vitest to run correctly, but without pulling in polyfills and globals that aren't required. If you already have a Node.js compatibility flag defined in your configuration, Vitest Pool Workers will not try to add those flags.\n\nUsing Vitest Pool Workers may cause your Worker to behave differently when deployed than during testing as the `nodejs_compat` flag is enabled by default. This means that Node.js-specific APIs and modules are available when running your tests. However, Cloudflare Workers do not support these Node.js APIs in the production environment unless you specify this flag in your Worker configuration.\n\nIf you do not have a `nodejs_compat` or `nodejs_compat_v2` flag in your configuration and you import a Node.js module in your Worker code, your tests may pass, but you will find that you will not be able to deploy this Worker, as the upload call (either via the REST API or via Wrangler) will throw an error.\n\nHowever, if you use Node.js globals that are not supported by the runtime, your Worker upload will be successful, but you may see errors in production code. Let's create a contrived example to illustrate the issue.\n\nThe `wrangler.toml` does not specify either `nodejs_compat` or `nodejs_compat_v2`:\n\n```toml\nname = \"test\"\nmain = \"src/index.ts\"\ncompatibility_date = \"2024-12-16\"",
  "code_samples": [
    {
      "code": "",
      "language": "unknown"
    },
    {
      "code": "from workers import WorkerEntrypoint\nfrom js import Response\n\n\nclass Default(WorkerEntrypoint):\n    async def fetch(self, request):\n        return Response.new(\"Hello World!\")",
      "language": "python"
    },
    {
      "code": "from workers import Response, WorkerEntrypoint\n\n\nclass Default(WorkerEntrypoint):\n    async def fetch(self, request):\n        return Response(\"Hello world!\")",
      "language": "python"
    },
    {
      "code": "{\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"hello-world-python-worker\",\n    \"main\": \"src/entry.py\",\n    \"compatibility_date\": \"2024-04-01\"\n  }",
      "language": "jsonc"
    },
    {
      "code": "name = \"hello-world-python-worker\"\n  main = \"src/entry.py\"\n  compatibility_date = \"2024-04-01\"",
      "language": "toml"
    },
    {
      "code": "[project]\nname = \"YourProjectName\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.12\"\ndependencies = [\n    \"fastapi\"\n]\n\n\n[dependency-groups]\ndev = [\n  \"workers-py\",\n  \"workers-runtime-sdk\"\n]",
      "language": "toml"
    },
    {
      "code": "uv run pywrangler dev",
      "language": "plaintext"
    },
    {
      "code": "uv run pywrangler deploy",
      "language": "plaintext"
    },
    {
      "code": "{\n  \"configurations\": [\n    {\n      \"name\": \"Wrangler\",\n      \"type\": \"node\",\n      \"request\": \"attach\",\n      \"port\": 9229,\n      \"cwd\": \"/\",\n      \"resolveSourceMapLocations\": null,\n      \"attachExistingChildren\": false,\n      \"autoAttachChildProcesses\": false,\n      \"sourceMaps\": true // works with or without this line\n    }\n  ]\n}",
      "language": "json"
    },
    {
      "code": "[package.metadata.wasm-pack.profile.dev.wasm-bindgen]\ndwarf-debug-info = true",
      "language": "toml"
    },
    {
      "code": "[build]\ncommand = \"cargo install -q worker-build && worker-build --dev\"",
      "language": "toml"
    },
    {
      "code": "const addNumbers = (body) => {\n  for (let i = 0; i < 5000; ++i) {\n    body = body + \" \" + i;\n  }\n  return body;\n};\n\n\nconst moreAddition = (body) => {\n  for (let i = 5001; i < 15000; ++i) {\n    body = body + \" \" + i;\n  }\n  return body;\n};\n\n\nexport default {\n  async fetch(request, env, ctx) {\n    let body = \"Hello Profiler! - \";\n    body = addNumbers(body);\n    body = moreAddition(body);\n    return new Response(body);\n  },\n};",
      "language": "js"
    },
    {
      "code": "{\n    \"observability\": {\n      \"traces\": {\n        \"enabled\": true,\n        // Must match the destination name in the dashboard\n        \"destinations\": [\"axiom-traces\"]\n      },\n      \"logs\": {\n        \"enabled\": true,\n        // Must match the destination name in the dashboard\n        \"destinations\": [\"axiom-logs\"]\n      }\n    }\n  }",
      "language": "jsonc"
    },
    {
      "code": "[observability.traces]\n  enabled = true\n  destinations = [ \"axiom-traces\" ]\n\n\n  [observability.logs]\n  enabled = true\n  destinations = [ \"axiom-logs\" ]",
      "language": "toml"
    },
    {
      "code": "let responseText = \"Hello world!\";\n\n\nexport default {\n  async fetch(request, env, ctx) {\n    let now = new Date().toISOString();\n    responseText = responseText + ` (Requested at: ${now})`;\n    return new Response(responseText.slice(0, 53));\n  },\n};",
      "language": "js"
    },
    {
      "code": "responseText = responseText + ` (Requested at: ${now})`;",
      "language": "js"
    },
    {
      "code": "{\n    \"observability\": {\n      \"traces\": {\n        \"enabled\": true,\n        // Must match the destination name in the dashboard\n        \"destinations\": [\"grafana-traces\"]\n      },\n      \"logs\": {\n        \"enabled\": true,\n        // Must match the destination name in the dashboard\n        \"destinations\": [\"grafana-logs\"]\n      }\n    }\n  }",
      "language": "jsonc"
    },
    {
      "code": "[observability.traces]\n  enabled = true\n  destinations = [ \"grafana-traces\" ]\n\n\n  [observability.logs]\n  enabled = true\n  destinations = [ \"grafana-logs\" ]",
      "language": "toml"
    },
    {
      "code": "{\n    \"observability\": {\n      \"traces\": {\n        \"enabled\": true,\n        // Must match the destination name in the dashboard\n        \"destinations\": [\"honeycomb-traces\"]\n      },\n      \"logs\": {\n        \"enabled\": true,\n        // Must match the destination name in the dashboard\n        \"destinations\": [\"honeycomb-logs\"]\n      }\n    }\n  }",
      "language": "jsonc"
    },
    {
      "code": "[observability.traces]\n  enabled = true\n  destinations = [ \"honeycomb-traces\" ]\n\n\n  [observability.logs]\n  enabled = true\n  destinations = [ \"honeycomb-logs\" ]",
      "language": "toml"
    },
    {
      "code": "curl \"https://api.cloudflare.com/client/v4/accounts/<ACCOUNT_ID>/logpush/jobs\" \\\n--header 'X-Auth-Key: <API_KEY>' \\\n--header 'X-Auth-Email: <EMAIL>' \\\n--header 'Content-Type: application/json' \\\n--data '{\n  \"name\": \"workers-logpush\",\n  \"output_options\": {\n    \"field_names\": [\"Event\", \"EventTimestampMs\", \"Outcome\", \"Exceptions\", \"Logs\", \"ScriptName\"],\n  },\n  \"destination_conf\": \"r2://<BUCKET_PATH>/{DATE}?account-id=<ACCOUNT_ID>&access-key-id=<R2_ACCESS_KEY_ID>&secret-access-key=<R2_SECRET_ACCESS_KEY>\",\n  \"dataset\": \"workers_trace_events\",\n  \"enabled\": true\n}' | jq .",
      "language": "bash"
    },
    {
      "code": "{\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"my-worker\",\n    \"main\": \"src/index.js\",\n    \"compatibility_date\": \"2022-07-12\",\n    \"workers_dev\": false,\n    \"logpush\": true,\n    \"route\": {\n      \"pattern\": \"example.org/*\",\n      \"zone_name\": \"example.org\"\n    }\n  }",
      "language": "jsonc"
    },
    {
      "code": "# Top-level configuration\n\n\n  name = \"my-worker\"\n  main = \"src/index.js\"\n  compatibility_date = \"2022-07-12\"\n\n\n  workers_dev = false\n  logpush = true\n  route = { pattern = \"example.org/*\", zone_name = \"example.org\" }",
      "language": "toml"
    },
    {
      "code": "curl --request PUT \\\n\"https://api.cloudflare.com/client/v4/accounts/{account_id}/workers/scripts/{script_name}\" \\\n--header \"Authorization: Bearer <API_TOKEN>\" \\\n--form 'metadata={\"main_module\": \"my-worker.js\", \"logpush\": true}' \\\n--form '\"my-worker.js\"=@./my-worker.js;type=application/javascript+module'",
      "language": "bash"
    },
    {
      "code": "{\n  \"Exceptions\": [\n    {\n      \"Name\": \"SampleError\",\n      \"Message\": \"something went wrong\",\n      \"TimestampMs\": 0\n    },\n    {\n      \"Name\": \"AuthError\",\n      \"Message\": \"unable to process request authentication from client\",\n      \"TimestampMs\": 1\n    },\n  ],\n  \"Logs\": [\n    {\n      \"Level\": \"log\",\n      \"Message\": [\"Hello \"],\n      \"TimestampMs\": 0\n    },\n    {\n      \"Level\": \"log\",\n      \"Message\": [\"World!\"],\n      \"TimestampMs\": 0\n    }\n  ]\n}",
      "language": "json"
    },
    {
      "code": "{\n  \"Exceptions\": [\n    {\n      \"name\": \"SampleError\",\n      \"message\": \"something went wrong\",\n      \"TimestampMs\": 0\n    },\n    {\n      \"name\": \"AuthError\",\n      \"message\": \"unable to <<<Logpush: exception messages truncated>>>\",\n      \"TimestampMs\": 1\n    },\n  ],\n  \"Logs\": [\n    {\n      \"Level\": \"log\",\n      \"Message\": [\"<<<Logpush: messages truncated>>>\"],\n      \"TimestampMs\": 0\n    }\n  ]\n}",
      "language": "json"
    },
    {
      "code": "{\n    \"observability\": {\n      \"traces\": {\n        \"enabled\": true,\n        // Must match the destination name in the dashboard\n        \"destinations\": [\"sentry-traces\"]\n      },\n      \"logs\": {\n        \"enabled\": true,\n        // Must match the destination name in the dashboard\n        \"destinations\": [\"sentry-logs\"]\n      }\n    }\n  }",
      "language": "jsonc"
    },
    {
      "code": "[observability.traces]\n  enabled = true\n  destinations = [ \"sentry-traces\" ]\n\n\n  [observability.logs]\n  enabled = true\n  destinations = [ \"sentry-logs\" ]",
      "language": "toml"
    },
    {
      "code": "export default {\n  async tail(events) {\n    fetch(\"https://example.com/endpoint\", {\n      method: \"POST\",\n      body: JSON.stringify(events),\n    });\n  },\n};",
      "language": "js"
    },
    {
      "code": "[\n  {\n    \"scriptName\": \"Example script\",\n    \"outcome\": \"exception\",\n    \"eventTimestamp\": 1587058642005,\n    \"event\": {\n      \"request\": {\n        \"url\": \"https://example.com/some/requested/url\",\n        \"method\": \"GET\",\n        \"headers\": {\n          \"cf-ray\": \"57d55f210d7b95f3\",\n          \"x-custom-header-name\": \"my-header-value\"\n        },\n        \"cf\": {\n          \"colo\": \"SJC\"\n        }\n      }\n    },\n    \"logs\": [\n      {\n        \"message\": [\"string passed to console.log()\"],\n        \"level\": \"log\",\n        \"timestamp\": 1587058642005\n      }\n    ],\n    \"exceptions\": [\n      {\n        \"name\": \"Error\",\n        \"message\": \"Threw a sample exception\",\n        \"timestamp\": 1587058642005\n      }\n    ],\n    \"diagnosticsChannelEvents\": [\n      {\n        \"channel\": \"foo\",\n        \"message\": \"The diagnostic channel message\",\n        \"timestamp\": 1587058642005\n      }\n    ]\n  }\n]",
      "language": "json"
    },
    {
      "code": "{\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"tail_consumers\": [\n      {\n        \"service\": \"<TAIL_WORKER_NAME>\"\n      }\n    ]\n  }",
      "language": "jsonc"
    },
    {
      "code": "tail_consumers = [{service = \"<TAIL_WORKER_NAME>\"}]",
      "language": "toml"
    },
    {
      "code": "{\n  \"outcome\": \"ok\",\n  \"scriptName\": null,\n  \"exceptions\": [],\n  \"logs\": [],\n  \"eventTimestamp\": 1590680082349,\n  \"event\": {\n    \"request\": {\n      \"url\": \"https://www.bytesized.xyz/\",\n      \"method\": \"GET\",\n      \"headers\": {},\n      \"cf\": {}\n    }\n  }\n}",
      "language": "json"
    },
    {
      "code": "npx wrangler tail | jq .event.request.url",
      "language": "sh"
    },
    {
      "code": "\"https://www.bytesized.xyz/\"\n\"https://www.bytesized.xyz/component---src-pages-index-js-a77e385e3bde5b78dbf6.js\"\n\"https://www.bytesized.xyz/page-data/app-data.json\"",
      "language": "sh"
    },
    {
      "code": "{\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"observability\": {\n      \"enabled\": true,\n      \"head_sampling_rate\": 1\n    }\n  }",
      "language": "jsonc"
    },
    {
      "code": "[observability]\n  enabled = true\n  head_sampling_rate = 1 # optional. default = 1.",
      "language": "toml"
    },
    {
      "code": "{\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"env\": {\n      \"staging\": {\n        \"observability\": {\n          \"enabled\": true,\n          \"head_sampling_rate\": 1\n        }\n      }\n    }\n  }",
      "language": "jsonc"
    },
    {
      "code": "[env.staging.observability]\n  enabled = true\n  head_sampling_rate = 1 # optional",
      "language": "toml"
    },
    {
      "code": "{\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"observability\": {\n      \"logs\": {\n        \"invocation_logs\": false\n      }\n    }\n  }",
      "language": "jsonc"
    },
    {
      "code": "[observability.logs]\n  invocation_logs = false",
      "language": "toml"
    },
    {
      "code": "export default {\n    async fetch(request) {\n      const { cf } = request;\n      const { city, country } = cf;\n\n\n      console.log(`Request came from city: ${city} in country: ${country}`);\n\n\n      return new Response(\"Hello worker!\", {\n        headers: { \"content-type\": \"text/plain\" },\n      });\n    },\n  };",
      "language": "js"
    },
    {
      "code": "addEventListener(\"fetch\", (event) => {\n    event.respondWith(handleRequest(event.request));\n  });\n\n\n  /**\n   * Respond with hello worker text\n   * @param {Request} request\n   */\n  async function handleRequest(request) {\n    const { cf } = request;\n    const { city, country } = cf;\n\n\n    console.log(`Request came from city: ${city} in country: ${country}`);\n\n\n    return new Response(\"Hello worker!\", {\n      headers: { \"content-type\": \"text/plain\" },\n    });\n  }",
      "language": "js"
    },
    {
      "code": "{\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"observability\": {\n      \"enabled\": true,\n      \"head_sampling_rate\": 0.01\n    }\n  }",
      "language": "jsonc"
    },
    {
      "code": "[observability]\n  enabled = true\n  head_sampling_rate = 0.01 # 1% sampling rate",
      "language": "toml"
    },
    {
      "code": "npx wrangler mtls-certificate upload --cert cert.pem --key key.pem --name my-client-cert",
      "language": "sh"
    },
    {
      "code": "{\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"mtls_certificates\": [\n      {\n        \"binding\": \"MY_CERT\",\n        \"certificate_id\": \"<CERTIFICATE_ID>\"\n      }\n    ]\n  }",
      "language": "jsonc"
    },
    {
      "code": "mtls_certificates = [\n    { binding = \"MY_CERT\", certificate_id = \"<CERTIFICATE_ID>\" }\n  ]",
      "language": "toml"
    },
    {
      "code": "export default {\n    async fetch(request, environment) {\n      return await environment.MY_CERT.fetch(\"https://a-secured-origin.com\");\n    },\n  };",
      "language": "js"
    },
    {
      "code": "interface Env {\n    MY_CERT: Fetcher;\n  }\n\n\n  export default {\n      async fetch(request, environment): Promise<Response> {\n          return await environment.MY_CERT.fetch(\"https://a-secured-origin.com\")\n      }\n  } satisfies ExportedHandler<Env>;",
      "language": "js"
    },
    {
      "code": "{\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"main\": \"src/index.js\",\n    \"ratelimits\": [\n      {\n        \"name\": \"MY_RATE_LIMITER\",\n        \"namespace_id\": \"1001\",\n        \"simple\": {\n          \"limit\": 100,\n          \"period\": 60\n        }\n      }\n    ]\n  }",
      "language": "jsonc"
    },
    {
      "code": "main = \"src/index.js\"\n\n\n  [[ratelimits]]\n  name = \"MY_RATE_LIMITER\"\n  # An identifier you define, that is unique to your Cloudflare account.\n  # Must be an integer.\n  namespace_id = \"1001\"\n\n\n  # Limit: the number of tokens allowed within a given period in a single\n  # Cloudflare location\n  # Period: the duration of the period, in seconds. Must be either 10 or 60\n  simple = { limit = 100, period = 60 }",
      "language": "toml"
    },
    {
      "code": "export default {\n    async fetch(request, env) {\n      const { pathname } = new URL(request.url)\n\n\n      const { success } = await env.MY_RATE_LIMITER.limit({ key: pathname }) // key can be any string of your choosing\n      if (!success) {\n        return new Response(`429 Failure – rate limit exceeded for ${pathname}`, { status: 429 })\n      }\n\n\n      return new Response(`Success!`)\n    }\n  }",
      "language": "javascript"
    },
    {
      "code": "interface Env {\n    MY_RATE_LIMITER: any;\n  }\n\n\n  export default {\n    async fetch(request, env): Promise<Response> {\n      const { pathname } = new URL(request.url)\n\n\n      const { success } = await env.MY_RATE_LIMITER.limit({ key: pathname }) // key can be any string of your choosing\n      if (!success) {\n        return new Response(`429 Failure – rate limit exceeded for ${pathname}`, { status: 429 })\n      }\n\n\n      return new Response(`Success!`)\n    }\n  } satisfies ExportedHandler<Env>;",
      "language": "ts"
    },
    {
      "code": "{\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"main\": \"src/index.js\",\n    \"ratelimits\": [\n      {\n        \"name\": \"FREE_USER_RATE_LIMITER\",\n        \"namespace_id\": \"1001\",\n        \"simple\": {\n          \"limit\": 100,\n          \"period\": 60\n        }\n      },\n      {\n        \"name\": \"PAID_USER_RATE_LIMITER\",\n        \"namespace_id\": \"1002\",\n        \"simple\": {\n          \"limit\": 1000,\n          \"period\": 60\n        }\n      }\n    ]\n  }",
      "language": "jsonc"
    },
    {
      "code": "main = \"src/index.js\"\n\n\n  # Free user rate limiting\n  [[ratelimits]]\n  name = \"FREE_USER_RATE_LIMITER\"\n  namespace_id = \"1001\"\n  simple = { limit = 100, period = 60 }\n\n\n  # Paid user rate limiting\n  [[ratelimits]]\n  name = \"PAID_USER_RATE_LIMITER\"\n  namespace_id = \"1002\"\n  simple = { limit = 1000, period = 60 }",
      "language": "toml"
    },
    {
      "code": "{\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"ratelimits\": [\n      {\n        \"name\": \"MY_RATE_LIMITER\",\n        \"namespace_id\": \"1001\",\n        \"simple\": {\n          \"limit\": 1500,\n          \"period\": 60\n        }\n      }\n    ]\n  }",
      "language": "jsonc"
    },
    {
      "code": "[[ratelimits]]\n  name = \"MY_RATE_LIMITER\"\n  namespace_id = \"1001\"\n\n\n  # 1500 requests - calls to limit() increment this\n  simple = { limit = 1500, period = 60 }",
      "language": "toml"
    },
    {
      "code": "// Recommended: use a key that represents a specific user or class of user\nconst url = new URL(req.url)\nconst userId = url.searchParams.get(\"userId\") || \"\"\nconst { success } = await env.MY_RATE_LIMITER.limit({ key: userId })\n\n\n// Not recommended:  many users may share a single IP, especially on mobile networks\n// or when using privacy-enabling proxies\nconst ipAddress = req.headers.get(\"cf-connecting-ip\") || \"\"\nconst { success } = await env.MY_RATE_LIMITER.limit({ key: ipAddress })",
      "language": "ts"
    },
    {
      "code": "const { success } = await env.MY_RATE_LIMITER.limit({ key: customerId })",
      "language": "javascript"
    },
    {
      "code": "{\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"services\": [\n      {\n        \"binding\": \"<BINDING_NAME>\",\n        \"service\": \"<WORKER_NAME>\"\n      }\n    ]\n  }",
      "language": "jsonc"
    },
    {
      "code": "services = [\n    { binding = \"<BINDING_NAME>\", service = \"<WORKER_NAME>\" }\n  ]",
      "language": "toml"
    },
    {
      "code": "{\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"worker_b\",\n    \"main\": \"./src/workerB.js\"\n  }",
      "language": "jsonc"
    },
    {
      "code": "name = \"worker_b\"\n  main = \"./src/workerB.js\"",
      "language": "toml"
    },
    {
      "code": "import { WorkerEntrypoint } from \"cloudflare:workers\";\n\n\nexport default class WorkerB extends WorkerEntrypoint {\n  // Currently, entrypoints without a named handler are not supported\n  async fetch() { return new Response(null, {status: 404}); }\n\n\n  async add(a, b) { return a + b; }\n}",
      "language": "js"
    },
    {
      "code": "{\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"name\": \"worker_a\",\n    \"main\": \"./src/workerA.js\",\n    \"services\": [\n      {\n        \"binding\": \"WORKER_B\",\n        \"service\": \"worker_b\"\n      }\n    ]\n  }",
      "language": "jsonc"
    },
    {
      "code": "name = \"worker_a\"\n  main = \"./src/workerA.js\"\n  services = [\n    { binding = \"WORKER_B\", service = \"worker_b\" }\n  ]",
      "language": "toml"
    },
    {
      "code": "export default {\n  async fetch(request, env) {\n    const result = await env.WORKER_B.add(1, 2);\n    return new Response(result);\n  }\n}",
      "language": "js"
    },
    {
      "code": "$ wrangler dev\n...\nYour worker has access to the following bindings:\n- Services:\n  - SOME_OTHER_WORKER: some-other-worker [connected]\n  - ANOTHER_WORKER: another-worker [not connected]",
      "language": "sh"
    },
    {
      "code": "{\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"version_metadata\": {\n      \"binding\": \"CF_VERSION_METADATA\"\n    }\n  }",
      "language": "jsonc"
    },
    {
      "code": "[version_metadata]\n  binding = \"CF_VERSION_METADATA\"",
      "language": "toml"
    },
    {
      "code": "export default {\n    async fetch(request, env, ctx) {\n      const { id: versionId, tag: versionTag, timestamp: versionTimestamp } = env.CF_VERSION_METADATA;\n      env.WAE.writeDataPoint({\n        indexes: [versionId],\n        blobs: [versionTag, versionTimestamp],\n        //...\n      });\n      //...\n    },\n  };",
      "language": "js"
    },
    {
      "code": "interface Environment {\n    CF_VERSION_METADATA: WorkerVersionMetadata;\n    WAE: AnalyticsEngineDataset;\n  }\n\n\n  export default {\n    async fetch(request, env, ctx) {\n      const { id: versionId, tag: versionTag } = env.CF_VERSION_METADATA;\n      env.WAE.writeDataPoint({\n        indexes: [versionId],\n        blobs: [versionTag],\n        //...\n      });\n      //...\n    },\n  } satisfies ExportedHandler<Env>;",
      "language": "ts"
    },
    {
      "code": "let id = \"foo\";\n\n\n// Get the isolate with the given ID, creating it if no such isolate exists yet.\nlet worker = env.LOADER.get(id, async () => {\n  // If the isolate does not already exist, this callback is invoked to fetch\n  // the isolate's Worker code.\n\n\n  return {\n    compatibilityDate: \"2025-06-01\",\n\n\n    // Specify the worker's code (module files).\n    mainModule: \"foo.js\",\n    modules: {\n      \"foo.js\":\n        \"export default {\\n\" +\n        \"  fetch(req, env, ctx) { return new Response('Hello'); }\\n\" +\n        \"}\\n\",\n    },\n\n\n    // Specify the dynamic Worker's environment (`env`). This is specified\n    // as a JavaScript object, exactly as you want it to appear to the\n    // child Worker. It can contain basic serializable types as well as\n    // Service Bindings (see below).\n    env: {\n      SOME_ENV_VAR: 123\n    },\n\n\n    // To block the worker from talking to the internet using `fetch()` or\n    // `connect()`, set `globalOutbound` to `null`. You can also set this\n    // to any service binding, to have calls be intercepted and redirected\n    // to that binding.\n    globalOutbound: null,\n  };\n});\n\n\n// Now you can get the Worker's entrypoint and send requests to it.\nlet defaultEntrypoint = worker.getEntrypoint();\nawait defaultEntrypoint.fetch(\"http://example.com\");\n\n\n// You can get non-default entrypoints as well, and specify the\n// `ctx.props` value to be delivered to the entrypoint.\nlet someEntrypoint = worker.getEntrypoint(\"SomeEntrypointClass\", {\n  props: {someProp: 123}\n});",
      "language": "js"
    },
    {
      "code": "{\n    \"$schema\": \"./node_modules/wrangler/config-schema.json\",\n    \"worker_loaders\": [\n      {\n        \"binding\": \"LOADER\"\n      }\n    ]\n  }",
      "language": "jsonc"
    },
    {
      "code": "[[worker_loaders]]\n  binding = \"LOADER\"",
      "language": "toml"
    },
    {
      "code": "import { WorkerEntrypoint } from \"cloudflare:workers\";\n\n\nexport class Greeter extends WorkerEntrypoint {\n  fetch(request) {\n    return new Response(`Hello, ${this.ctx.props.name}!`);\n  }\n}\n\n\nexport default {\n  async fetch(request, env, ctx) {\n    let worker = env.LOADER.get(\"alice\", () => {\n      return {\n        // Redirect the worker's global outbound to send all requests\n        // to the `Greeter` class, filling in `ctx.props.name` with\n        // the name \"Alice\", so that it always responds \"Hello, Alice!\".\n        globalOutbound: ctx.exports.Greeter({props: {name: \"Alice\"}})\n\n\n        // ... code ...\n      }\n    });\n  }\n}",
      "language": "js"
    },
    {
      "code": "import { WorkerEntrypoint } from \"cloudflare:workers\";\n\n\n// Implement a binding which can be called by the dynamic Worker.\nexport class Greeter extends WorkerEntrypoint {\n  greet() {\n    return `Hello, ${this.ctx.props.name}!`;\n  }\n}\n\n\nexport default {\n  async fetch(request, env, ctx) {\n    let worker = env.LOADER.get(\"alice\", () => {\n      return {\n        env: {\n          // Provide a binding which has a method greet() which can be called\n          // to receive a greeting. The binding knows the Worker's name.\n          GREETER: ctx.exports.Greeter({props: {name: \"Alice\"}})\n        }\n\n\n        // ... code ...\n      }\n    });\n  }\n}",
      "language": "js"
    },
    {
      "code": "export default {\n  async fetch(request, env, ctx) {\n    return new Response('Hello World!');\n  },\n};",
      "language": "js"
    },
    {
      "code": "npx wrangler dev --test-scheduled\n\n\ncurl \"http://localhost:8787/__scheduled?cron=*+*+*+*+*\"\n\n\ncurl \"http://localhost:8787/cdn-cgi/handler/scheduled?cron=*+*+*+*+*\" # Python Workers",
      "language": "sh"
    },
    {
      "code": "export default {\n    async scheduled(controller, env, ctx) {\n      ctx.waitUntil(doSomeTaskOnASchedule());\n    },\n  };",
      "language": "js"
    },
    {
      "code": "interface Env {}\n  export default {\n    async scheduled(\n      controller: ScheduledController,\n      env: Env,\n      ctx: ExecutionContext,\n    ) {\n      ctx.waitUntil(doSomeTaskOnASchedule());\n    },\n  };",
      "language": "ts"
    },
    {
      "code": "from workers import WorkerEntrypoint, Response, fetch\n\n\n  class Default(WorkerEntrypoint):\n      async def scheduled(self, controller, env, ctx):\n          ctx.waitUntil(doSomeTaskOnASchedule())",
      "language": "python"
    },
    {
      "code": "export default {\n  async tail(events, env, ctx) {\n    fetch(\"<YOUR_ENDPOINT>\", {\n      method: \"POST\",\n      body: JSON.stringify(events),\n    })\n  }\n}",
      "language": "js"
    },
    {
      "code": "import { strictEqual, deepStrictEqual, ok, doesNotReject } from \"node:assert\";\n\n\nstrictEqual(1, 1); // ok!\nstrictEqual(1, \"1\"); // fails! throws AssertionError\n\n\ndeepStrictEqual({ a: { b: 1 } }, { a: { b: 1 } }); // ok!\ndeepStrictEqual({ a: { b: 1 } }, { a: { b: 2 } }); // fails! throws AssertionError\n\n\nok(true); // ok!\nok(false); // fails! throws AssertionError\n\n\nawait doesNotReject(async () => {}); // ok!\nawait doesNotReject(async () => {\n  throw new Error(\"boom\");\n}); // fails! throws AssertionError",
      "language": "js"
    },
    {
      "code": "import { AsyncLocalStorage } from \"node:async_hooks\";\n\n\nconst asyncLocalStorage = new AsyncLocalStorage();",
      "language": "js"
    },
    {
      "code": "import { AsyncLocalStorage } from 'node:async_hooks';\n\n\nconst asyncLocalStorage = new AsyncLocalStorage();\nlet idSeq = 0;\n\n\nexport default {\n  async fetch(req) {\n    return asyncLocalStorage.run(idSeq++, () => {\n      // Simulate some async activity...\n      await scheduler.wait(1000);\n      return new Response(asyncLocalStorage.getStore());\n    });\n  }\n};",
      "language": "js"
    },
    {
      "code": "import { AsyncLocalStorage } from 'node:async_hooks';\n\n\nconst als1 = new AsyncLocalStorage();\nconst als2 = new AsyncLocalStorage();\n\n\nexport default {\n  async fetch(req) {\n    return als1.run(123, () => {\n      return als2.run(321, () => {\n        // Simulate some async activity...\n        await scheduler.wait(1000);\n        return new Response(`${als1.getStore()}-${als2.getStore()}`);\n      });\n    });\n  }\n};",
      "language": "js"
    },
    {
      "code": "import { AsyncLocalStorage } from \"node:async_hooks\";\n\n\nconst asyncLocalStorage = new AsyncLocalStorage();\nlet idSeq = 0;\n\n\naddEventListener(\"unhandledrejection\", (event) => {\n  console.log(asyncLocalStorage.getStore(), \"unhandled rejection!\");\n});\n\n\nexport default {\n  async fetch(req) {\n    return asyncLocalStorage.run(idSeq++, () => {\n      // Cause an unhandled rejection!\n      throw new Error(\"boom\");\n    });\n  },\n};",
      "language": "js"
    },
    {
      "code": "import { AsyncLocalStorage } from \"node:async_hooks\";\n\n\nconst als = new AsyncLocalStorage();\n\n\nfunction foo() {\n  console.log(als.getStore());\n}\nfunction bar() {\n  console.log(als.getStore());\n}\n\n\nconst oneFoo = als.run(123, () => AsyncLocalStorage.bind(foo));\noneFoo(); // prints 123\n\n\nconst snapshot = als.run(\"abc\", () => AsyncLocalStorage.snapshot());\nsnapshot(foo); // prints 'abc'\nsnapshot(bar); // prints 'abc'",
      "language": "js"
    },
    {
      "code": "import { AsyncLocalStorage } from \"node:async_hooks\";\n\n\nconst als = new AsyncLocalStorage();\n\n\nclass MyResource {\n  #runInAsyncScope = AsyncLocalStorage.snapshot();\n\n\n  doSomething() {\n    this.#runInAsyncScope(() => {\n      return als.getStore();\n    });\n  }\n}\n\n\nconst myResource = als.run(123, () => new MyResource());\nconsole.log(myResource.doSomething()); // prints 123",
      "language": "js"
    },
    {
      "code": "import { AsyncResource, AsyncLocalStorage } from \"node:async_hooks\";\n\n\nconst als = new AsyncLocalStorage();\n\n\nclass MyResource extends AsyncResource {\n  constructor() {\n    // The type string is required by Node.js but unused in Workers.\n    super(\"MyResource\");\n  }\n\n\n  doSomething() {\n    this.runInAsyncScope(() => {\n      return als.getStore();\n    });\n  }\n}\n\n\nconst myResource = als.run(123, () => new MyResource());\nconsole.log(myResource.doSomething()); // prints 123",
      "language": "js"
    },
    {
      "code": "import { Buffer } from \"node:buffer\";\n\n\nconst buf = Buffer.from(\"hello world\", \"utf8\");\n\n\nconsole.log(buf.toString(\"hex\"));\n// Prints: 68656c6c6f20776f726c64\nconsole.log(buf.toString(\"base64\"));\n// Prints: aGVsbG8gd29ybGQ=",
      "language": "js"
    },
    {
      "code": "const response = new Response(Buffer.from(\"hello world\"));",
      "language": "js"
    },
    {
      "code": "const writable = getWritableStreamSomehow();\nconst writer = writable.getWriter();\nwriter.write(Buffer.from(\"hello world\"));",
      "language": "js"
    },
    {
      "code": "import dns from \"node:dns\";\n\n\n  let response = await dns.promises.resolve4(\"cloudflare.com\", \"NS\");",
      "language": "js"
    },
    {
      "code": "import dns from 'node:dns';\n\n\n  let response = await dns.promises.resolve4('cloudflare.com', 'NS');",
      "language": "ts"
    },
    {
      "code": "",
      "language": "plaintext"
    },
    {
      "code": "import {\n  channel,\n  hasSubscribers,\n  subscribe,\n  unsubscribe,\n  tracingChannel,\n} from \"node:diagnostics_channel\";\n\n\n// For publishing messages to a channel, acquire a channel object:\nconst myChannel = channel(\"my-channel\");\n\n\n// Any JS value can be published to a channel.\nmyChannel.publish({ foo: \"bar\" });\n\n\n// For receiving messages on a channel, use subscribe:\n\n\nsubscribe(\"my-channel\", (message) => {\n  console.log(message);\n});",
      "language": "js"
    },
    {
      "code": "export default {\n  async tail(events) {\n    for (const event of events) {\n      for (const messageData of event.diagnosticsChannelEvents) {\n        console.log(\n          messageData.timestamp,\n          messageData.channel,\n          messageData.message,\n        );\n      }\n    }\n  },\n};",
      "language": "js"
    },
    {
      "code": "import { tracingChannel } from \"node:diagnostics_channel\";\nimport { AsyncLocalStorage } from \"node:async_hooks\";\n\n\nconst channels = tracingChannel(\"my-channel\");\nconst requestId = new AsyncLocalStorage();\nchannels.start.bindStore(requestId);\n\n\nchannels.subscribe({\n  start(message) {\n    console.log(requestId.getStore()); // { requestId: '123' }\n    // Handle start message\n  },\n  end(message) {\n    console.log(requestId.getStore()); // { requestId: '123' }\n    // Handle end message\n  },\n  asyncStart(message) {\n    console.log(requestId.getStore()); // { requestId: '123' }\n    // Handle asyncStart message\n  },\n  asyncEnd(message) {\n    console.log(requestId.getStore()); // { requestId: '123' }\n    // Handle asyncEnd message\n  },\n  error(message) {\n    console.log(requestId.getStore()); // { requestId: '123' }\n    // Handle error message\n  },\n});\n\n\n// The subscriber handlers will be invoked while tracing the execution of the async\n// function passed into `channel.tracePromise`...\nchannel.tracePromise(\n  async () => {\n    // Perform some asynchronous work...\n  },\n  { requestId: \"123\" },\n);",
      "language": "js"
    },
    {
      "code": "import { EventEmitter } from \"node:events\";\n\n\nconst emitter = new EventEmitter();\nemitter.on(\"hello\", (...args) => {\n  console.log(...args); // 1 2 3\n});\n\n\nemitter.emit(\"hello\", 1, 2, 3);",
      "language": "js"
    },
    {
      "code": "const emitter = new EventEmitter({ captureRejections: true });\nemitter.on(\"hello\", async (...args) => {\n  throw new Error(\"boom\");\n});\nemitter.on(\"error\", (err) => {\n  // the async promise rejection is emitted here!\n});",
      "language": "js"
    },
    {
      "code": "import { readFileSync, writeFileSync } from \"node:fs\";\n\n\nconst config = readFileSync(\"/bundle/config.txt\", \"utf8\");\n\n\nwriteFileSync(\"/tmp/abc.txt\", \"Hello, world!\");",
      "language": "js"
    },
    {
      "code": "/bundle\n└── (one file for each module in your Worker bundle)\n/tmp\n└── (empty, but you can write files, create directories, symlinks, etc)\n/dev\n├── null\n├── random\n├── full\n└── zero",
      "language": "plaintext"
    },
    {
      "code": "import { readFileSync } from \"node:fs\";\n\n\n// The config.txt file would be included in your Worker bundle.\n// Refer to the Wrangler documentation for details on how to\n// include additional files.\nconst config = readFileSync(\"/bundle/config.txt\", \"utf8\");\n\n\nexport default {\n  async fetch(request) {\n    return new Response(`Config contents: ${config}`);\n  },\n};",
      "language": "js"
    },
    {
      "code": "import { writeFileSync, readFileSync } from \"node:fs\";\n\n\nexport default {\n  fetch(request) {\n    // The file `/tmp/hello.txt` will only exist for the duration\n    // of this request.\n    writeFileSync(\"/tmp/hello.txt\", \"Hello, world!\");\n    const contents = readFileSync(\"/tmp/hello.txt\", \"utf8\");\n    return new Response(`File contents: ${contents}`);\n  },\n};",
      "language": "js"
    },
    {
      "code": "compatibility_flags = [\"nodejs_compat\", \"enable_nodejs_http_modules\"]",
      "language": "toml"
    },
    {
      "code": "compatibility_flags = [\"nodejs_compat\", \"enable_nodejs_http_server_modules\"]",
      "language": "toml"
    },
    {
      "code": "compatibility_flags = [\"nodejs_compat\", \"enable_nodejs_http_modules\", \"enable_nodejs_http_server_modules\"]",
      "language": "toml"
    },
    {
      "code": "import { get } from \"node:http\";\n\n\nexport default {\n  async fetch() {\n    const { promise, resolve, reject } = Promise.withResolvers();\n    get(\"http://example.org\", (res) => {\n      let data = \"\";\n      res.setEncoding(\"utf8\");\n      res.on(\"data\", (chunk) => {\n        data += chunk;\n      });\n      res.on(\"end\", () => {\n        resolve(new Response(data));\n      });\n      res.on(\"error\", reject);\n    }).on(\"error\", reject);\n    return promise;\n  },\n};",
      "language": "js"
    },
    {
      "code": "import { get } from \"node:http\";\n\n\nexport default {\n  async fetch() {\n    const { promise, resolve, reject } = Promise.withResolvers();\n    get(\n      {\n        method: \"GET\",\n        protocol: \"http:\",\n        hostname: \"example.org\",\n        path: \"/\",\n      },\n      (res) => {\n        let data = \"\";\n        res.setEncoding(\"utf8\");\n        res.on(\"data\", (chunk) => {\n          data += chunk;\n        });\n        res.on(\"end\", () => {\n          resolve(new Response(data));\n        });\n        res.on(\"error\", reject);\n      },\n    )\n      .on(\"error\", reject)\n      .end();\n    return promise;\n  },\n};",
      "language": "js"
    },
    {
      "code": "import { get, IncomingMessage } from \"node:http\";\nimport { ok, strictEqual } from \"node:assert\";\n\n\nexport default {\n  async fetch() {\n    // ...\n    get(\"http://example.org\", (res) => {\n      ok(res instanceof IncomingMessage);\n    });\n    // ...\n  },\n};",
      "language": "js"
    },
    {
      "code": "import { createServer } from \"node:http\";\nimport { httpServerHandler } from \"cloudflare:node\";\n\n\nconst server = createServer((req, res) => {\n  console.log(req.cloudflare.cf.country);\n  console.log(req.cloudflare.cf.ray);\n  res.write(\"Hello, World!\");\n  res.end();\n});\n\n\nserver.listen(8080);\n\n\nexport default httpServerHandler({ port: 8080 });",
      "language": "js"
    },
    {
      "code": "import { Agent } from \"node:http\";\nimport { strictEqual } from \"node:assert\";\n\n\nconst agent = new Agent();\nstrictEqual(agent.protocol, \"http:\");",
      "language": "js"
    },
    {
      "code": "import { createServer } from \"node:http\";\nimport { httpServerHandler } from \"cloudflare:node\";\n\n\nconst server = createServer((req, res) => {\n  res.writeHead(200, { \"Content-Type\": \"text/plain\" });\n  res.end(\"Hello from Node.js HTTP server!\");\n});\n\n\nserver.listen(8080);\nexport default httpServerHandler({ port: 8080 });",
      "language": "js"
    },
    {
      "code": "import http from \"node:http\";\nimport { httpServerHandler } from \"cloudflare:node\";\n\n\nconst server = http.createServer((req, res) => {\n  res.end(\"hello world\");\n});\n\n\n// Pass server directly (simplified) - automatically calls listen() if needed\nexport default httpServerHandler(server);\n\n\n// Or use port-based routing for multiple servers\nserver.listen(8080);\nexport default httpServerHandler({ port: 8080 });",
      "language": "js"
    },
    {
      "code": "import { createServer } from \"node:http\";\nimport { handleAsNodeRequest } from \"cloudflare:node\";\n\n\nconst server = createServer((req, res) => {\n  res.writeHead(200, { \"Content-Type\": \"text/plain\" });\n  res.end(\"Hello from Node.js HTTP server!\");\n});\n\n\nserver.listen(8080);\n\n\nexport default {\n  fetch(request) {\n    return handleAsNodeRequest(8080, request);\n  },\n};",
      "language": "js"
    },
    {
      "code": "import { Server } from \"node:http\";\nimport { httpServerHandler } from \"cloudflare:node\";\n\n\nconst server = new Server((req, res) => {\n  res.writeHead(200, { \"Content-Type\": \"application/json\" });\n  res.end(JSON.stringify({ message: \"Hello from HTTP Server!\" }));\n});\n\n\nserver.listen(8080);\nexport default httpServerHandler({ port: 8080 });",
      "language": "js"
    },
    {
      "code": "import { createServer, ServerResponse } from \"node:http\";\nimport { httpServerHandler } from \"cloudflare:node\";\nimport { ok } from \"node:assert\";\n\n\nconst server = createServer((req, res) => {\n  ok(res instanceof ServerResponse);\n\n\n  // Set multiple headers at once\n  res.writeHead(200, {\n    \"Content-Type\": \"application/json\",\n    \"X-Custom-Header\": \"Workers-HTTP\",\n  });\n\n\n  // Stream response data\n  res.write('{\"data\": [');\n  res.write('{\"id\": 1, \"name\": \"Item 1\"},');\n  res.write('{\"id\": 2, \"name\": \"Item 2\"}');\n  res.write(\"]}\");\n\n\n  // End the response\n  res.end();\n});\n\n\nexport default httpServerHandler(server);",
      "language": "js"
    },
    {
      "code": "compatibility_flags = [\"nodejs_compat\", \"enable_nodejs_http_modules\"]",
      "language": "toml"
    },
    {
      "code": "compatibility_flags = [\"nodejs_compat\", \"enable_nodejs_http_server_modules\"]",
      "language": "toml"
    },
    {
      "code": "compatibility_flags = [\"nodejs_compat\", \"enable_nodejs_http_modules\", \"enable_nodejs_http_server_modules\"]",
      "language": "toml"
    },
    {
      "code": "import { get } from \"node:https\";\n\n\nexport default {\n  async fetch() {\n    const { promise, resolve, reject } = Promise.withResolvers();\n    get(\"https://example.com\", (res) => {\n      let data = \"\";\n      res.setEncoding(\"utf8\");\n      res.on(\"data\", (chunk) => {\n        data += chunk;\n      });\n      res.on(\"end\", () => {\n        resolve(new Response(data));\n      });\n      res.on(\"error\", reject);\n    }).on(\"error\", reject);\n    return promise;\n  },\n};",
      "language": "js"
    },
    {
      "code": "import { request } from \"node:https\";\nimport { strictEqual, ok } from \"node:assert\";\n\n\nexport default {\n  async fetch() {\n    const { promise, resolve, reject } = Promise.withResolvers();\n    const req = request(\n      \"https://developers.cloudflare.com/robots.txt\",\n      {\n        method: \"GET\",\n      },\n      (res) => {\n        strictEqual(res.statusCode, 200);\n        let data = \"\";\n        res.setEncoding(\"utf8\");\n        res.on(\"data\", (chunk) => {\n          data += chunk;\n        });\n        res.once(\"error\", reject);\n        res.on(\"end\", () => {\n          ok(data.includes(\"User-agent\"));\n          resolve(new Response(data));\n        });\n      },\n    );\n    req.end();\n    return promise;\n  },\n};",
      "language": "js"
    },
    {
      "code": "import { createServer } from \"node:https\";\nimport { httpServerHandler } from \"cloudflare:node\";\n\n\nconst server = createServer((req, res) => {\n  res.writeHead(200, { \"Content-Type\": \"text/plain\" });\n  res.end(\"Hello from Node.js HTTPS server!\");\n});\n\n\nserver.listen(8080);\nexport default httpServerHandler({ port: 8080 });",
      "language": "js"
    },
    {
      "code": "import { createServer } from \"node:https\";\n\n\nawait using server = createServer((req, res) => {\n  res.end(\"Hello World\");\n});\n// Server will be automatically closed when it goes out of scope",
      "language": "js"
    },
    {
      "code": "import { Server } from \"node:https\";\nimport { httpServerHandler } from \"cloudflare:node\";\n\n\nconst server = new Server((req, res) => {\n  res.writeHead(200, { \"Content-Type\": \"application/json\" });\n  res.end(JSON.stringify({ message: \"Hello from HTTPS Server!\" }));\n});\nserver.listen(8080);\nexport default httpServerHandler({ port: 8080 });",
      "language": "js"
    },
    {
      "code": "import net from \"node:net\";\n\n\n  const exampleIP = \"127.0.0.1\";\n\n\n  export default {\n    async fetch(req) {\n      const socket = new net.Socket();\n      socket.connect(4000, exampleIP, function () {\n        console.log(\"Connected\");\n      });\n\n\n      socket.write(\"Hello, Server!\");\n      socket.end();\n\n\n      return new Response(\"Wrote to server\", { status: 200 });\n    },\n  };",
      "language": "js"
    },
    {
      "code": "import net from \"node:net\";\n\n\n  const exampleIP = \"127.0.0.1\";\n\n\n  export default {\n    async fetch(req): Promise<Response> {\n      const socket = new net.Socket();\n      socket.connect(4000, exampleIP, function () {\n        console.log(\"Connected\");\n      });\n\n\n      socket.write(\"Hello, Server!\");\n      socket.end();\n\n\n      return new Response(\"Wrote to server\", { status: 200 });\n\n\n  },\n  } satisfies ExportedHandler;",
      "language": "ts"
    },
    {
      "code": "",
      "language": "plaintext"
    },
    {
      "code": "import path from \"node:path\";\npath.join(\"/foo\", \"bar\", \"baz/asdf\", \"quux\", \"..\");\n// Returns: '/foo/bar/baz/asdf'",
      "language": "js"
    },
    {
      "code": "import * as process from \"node:process\";\n\n\nexport default {\n  fetch(req, env) {\n    // Set process.env.FOO to the value of env.FOO if process.env.FOO is not already set\n    // and env.FOO is a string.\n    process.env.FOO ??= (() => {\n      if (typeof env.FOO === \"string\") {\n        return env.FOO;\n      }\n    })();\n  },\n};",
      "language": "js"
    },
    {
      "code": "import * as process from \"node:process\";\nimport { env } from \"node:process\";\n\n\nprocess.env === env; // true! they are the same object\nprocess.env = {}; // replace the object! Do not do this!\nprocess.env === env; // false! they are no longer the same object\n\n\n// From this point forward, any changes to process.env will not be reflected in env,\n// and vice versa!",
      "language": "js"
    },
    {
      "code": "import { env, nextTick } from \"node:process\";\n\n\nenv[\"FOO\"] = \"bar\";\nconsole.log(env[\"FOO\"]); // Prints: bar\n\n\nnextTick(() => {\n  console.log(\"next tick\");\n});",
      "language": "js"
    },
    {
      "code": "import { Readable, Transform } from \"node:stream\";\n\n\nimport { text } from \"node:stream/consumers\";\n\n\nimport { pipeline } from \"node:stream/promises\";\n\n\n// A Node.js-style Transform that converts data to uppercase\n// and appends a newline to the end of the output.\nclass MyTransform extends Transform {\n  constructor() {\n    super({ encoding: \"utf8\" });\n  }\n  _transform(chunk, _, cb) {\n    this.push(chunk.toString().toUpperCase());\n    cb();\n  }\n  _flush(cb) {\n    this.push(\"\\n\");\n    cb();\n  }\n}\n\n\nexport default {\n  async fetch() {\n    const chunks = [\n      \"hello \",\n      \"from \",\n      \"the \",\n      \"wonderful \",\n      \"world \",\n      \"of \",\n      \"node.js \",\n      \"streams!\",\n    ];\n\n\n    function nextChunk(readable) {\n      readable.push(chunks.shift());\n      if (chunks.length === 0) readable.push(null);\n      else queueMicrotask(() => nextChunk(readable));\n    }\n\n\n    // A Node.js-style Readable that emits chunks from the\n    // array...\n    const readable = new Readable({\n      encoding: \"utf8\",\n      read() {\n        nextChunk(readable);\n      },\n    });\n\n\n    const transform = new MyTransform();\n    await pipeline(readable, transform);\n    return new Response(await text(transform));\n  },\n};",
      "language": "js"
    },
    {
      "code": "const { StringDecoder } = require(\"node:string_decoder\");\nconst decoder = new StringDecoder(\"utf8\");\n\n\nconst cent = Buffer.from([0xc2, 0xa2]);\nconsole.log(decoder.write(cent));\n\n\nconst euro = Buffer.from([0xe2, 0x82, 0xac]);\nconsole.log(decoder.write(euro));",
      "language": "js"
    },
    {
      "code": "import { mock } from 'node:test';\n\n\nconst fn = mock.fn();\nfn(1,2,3);  // does nothing... but\n\n\nconsole.log(fn.mock.callCount());  // Records how many times it was called\nconsole.log(fn.mock.calls[0].arguments));  // Recoreds the arguments that were passed each call",
      "language": "js"
    },
    {
      "code": "import timers from \"node:timers\";\n\n\n  export default {\n    async fetch() {\n      console.log(\"first\");\n      const { promise: promise1, resolve: resolve1 } = Promise.withResolvers();\n      const { promise: promise2, resolve: resolve2 } = Promise.withResolvers();\n      timers.setTimeout(() => {\n        console.log(\"last\");\n        resolve1();\n      }, 10);\n\n\n      timers.setTimeout(() => {\n        console.log(\"next\");\n        resolve2();\n      });\n\n\n      await Promise.all([promise1, promise2]);\n\n\n      return new Response(\"ok\");\n    },\n  };",
      "language": "js"
    },
    {
      "code": "import timers from \"node:timers\";\n\n\n  export default {\n    async fetch(): Promise<Response> {\n      console.log(\"first\");\n      const { promise: promise1, resolve: resolve1 } = Promise.withResolvers<void>();\n      const { promise: promise2, resolve: resolve2 } = Promise.withResolvers<void>();\n      timers.setTimeout(() => {\n        console.log(\"last\");\n        resolve1();\n      }, 10);\n\n\n      timers.setTimeout(() => {\n        console.log(\"next\");\n        resolve2();\n      });\n\n\n      await Promise.all([promise1, promise2]);\n\n\n      return new Response(\"ok\");\n    }\n  } satisfies ExportedHandler<Env>;",
      "language": "ts"
    },
    {
      "code": "import { connect } from \"node:tls\";\n\n\n// ... in a request handler ...\nconst connectionOptions = { key: env.KEY, cert: env.CERT };\nconst socket = connect(url, connectionOptions, () => {\n  if (socket.authorized) {\n    console.log(\"Connection authorized\");\n  }\n});\n\n\nsocket.on(\"data\", (data) => {\n  console.log(data);\n});\n\n\nsocket.on(\"end\", () => {\n  console.log(\"server ends connection\");\n});",
      "language": "js"
    },
    {
      "code": "import { promisify } from \"node:util\";\n\n\nfunction foo(args, callback) {\n  try {\n    callback(null, 1);\n  } catch (err) {\n    // Errors are emitted to the callback via the first argument.\n    callback(err);\n  }\n}\n\n\nconst promisifiedFoo = promisify(foo);\nawait promisifiedFoo(args);",
      "language": "js"
    },
    {
      "code": "import { callbackify } from 'node:util';\n\n\nasync function foo(args) {\n  throw new Error('boom');\n}\n\n\nconst callbackifiedFoo = callbackify(foo);\n\n\ncallbackifiedFoo(args, (err, value) => {\n  if (err) throw err;\n});",
      "language": "js"
    },
    {
      "code": "import { types } from \"node:util\";\n\n\ntypes.isAnyArrayBuffer(new ArrayBuffer()); // Returns true\ntypes.isAnyArrayBuffer(new SharedArrayBuffer()); // Returns true\ntypes.isArrayBufferView(new Int8Array()); // true\ntypes.isArrayBufferView(Buffer.from(\"hello world\")); // true\ntypes.isArrayBufferView(new DataView(new ArrayBuffer(16))); // true\ntypes.isArrayBufferView(new ArrayBuffer()); // false\nfunction foo() {\n  types.isArgumentsObject(arguments); // Returns true\n}\ntypes.isAsyncFunction(function foo() {}); // Returns false\ntypes.isAsyncFunction(async function foo() {}); // Returns true\n// .. and so on",
      "language": "js"
    },
    {
      "code": "import { MIMEType } from \"node:util\";\n\n\nconst myMIME = new MIMEType(\"text/javascript;key=value\");\n\n\nconsole.log(myMIME.type);\n// Prints: text\n\n\nconsole.log(myMIME.essence);\n// Prints: text/javascript\n\n\nconsole.log(myMIME.subtype);\n// Prints: javascript\n\n\nconsole.log(String(myMIME));\n// Prints: application/javascript;key=value",
      "language": "js"
    },
    {
      "code": "import { domainToASCII } from \"node:url\";\n\n\nconsole.log(domainToASCII(\"español.com\"));\n// Prints xn--espaol-zwa.com\nconsole.log(domainToASCII(\"中文.com\"));\n// Prints xn--fiq228c.com\nconsole.log(domainToASCII(\"xn--iñvalid.com\"));\n// Prints an empty string",
      "language": "js"
    },
    {
      "code": "import { domainToUnicode } from \"node:url\";\n\n\nconsole.log(domainToUnicode(\"xn--espaol-zwa.com\"));\n// Prints español.com\nconsole.log(domainToUnicode(\"xn--fiq228c.com\"));\n// Prints 中文.com\nconsole.log(domainToUnicode(\"xn--iñvalid.com\"));\n// Prints an empty string",
      "language": "js"
    },
    {
      "code": "import zlib from \"node:zlib\";",
      "language": "js"
    },
    {
      "code": "let user = await env.USER_SERVICE.findUser(id);",
      "language": "js"
    },
    {
      "code": "function sendEmail(id, message) {\n  using user = await env.USER_SERVICE.findUser(id);\n  await user.sendEmail(message);\n\n\n  // user[Symbol.dispose]() is implicitly called at the end of the scope.\n}",
      "language": "js"
    },
    {
      "code": "{\n  using counter = await env.COUNTER_SERVICE.newCounter();\n  await counter.increment(2);\n  await counter.increment(4);\n}",
      "language": "js"
    },
    {
      "code": "{\n  const counter = await env.COUNTER_SERVICE.newCounter();\n  try {\n    await counter.increment(2);\n    await counter.increment(4);\n  } finally {\n    counter[Symbol.dispose]();\n  }\n}",
      "language": "js"
    },
    {
      "code": "export default {\n  async fetch(request, env, ctx) {\n    let authResult = await env.AUTH_SERVICE.checkCookie(\n      req.headers.get(\"Cookie\"),\n    );\n    if (!authResult.authorized) {\n      return new Response(\"Not authorized\", { status: 403 });\n    }\n    let profile = await authResult.user.getProfile();\n\n\n    return new Response(`Hello, ${profile.name}!`);\n  },\n};",
      "language": "js"
    },
    {
      "code": "using result = stub.foo();",
      "language": "js"
    },
    {
      "code": "class Foo extends RpcTarget {\n  [Symbol.dispose]() {\n    // ...\n  }\n}",
      "language": "js"
    },
    {
      "code": "let stub = await env.SOME_SERVICE.getThing();\n\n\n// Create a duplicate.\nlet stub2 = stub.dup();\n\n\n// Call some function that will dispose the stub.\nawait func(stub);\n\n\n// stub2 is still valid",
      "language": "js"
    },
    {
      "code": "import { RpcTarget, RpcStub } from \"cloudflare:workers\";\n\n\nclass Foo extends RpcTarget {\n  // ...\n}\n\n\nlet obj = new Foo();\nlet stub = new RpcStub(obj);\nawait rpc1(stub.dup()); // sends a dup of `stub`\nawait rpc2(stub.dup()); // sends another dup of `stub`\nstub[Symbol.dispose](); // disposes the original stub\n\n\n// obj's disposer will be called when the other two stubs\n// are disposed remotely.",
      "language": "js"
    },
    {
      "code": "class Foo extends RpcTarget {\n  constructor() {\n    super();\n\n\n    // i CANNOT be accessed over RPC\n    this.i = 0;\n\n\n    // funcProp CANNOT be called over RPC\n    this.funcProp = () => {}\n  }\n\n\n  // value CAN be accessed over RPC\n  get value() {\n    return this.i;\n  }\n\n\n  // method CAN be called over RPC\n  method() {}\n}",
      "language": "js"
    },
    {
      "code": "someRpcMethod() {\n  let func = () => {};\n  func.prop = 123;  // `prop` is visible over RPC\n  return func;\n}",
      "language": "js"
    },
    {
      "code": "npx wrangler types -c ./client/wrangler.jsonc -c ../sum-worker/wrangler.jsonc -c ../counter/wrangler.jsonc",
      "language": "sh"
    },
    {
      "code": "yarn wrangler types -c ./client/wrangler.jsonc -c ../sum-worker/wrangler.jsonc -c ../counter/wrangler.jsonc",
      "language": "sh"
    },
    {
      "code": "pnpm wrangler types -c ./client/wrangler.jsonc -c ../sum-worker/wrangler.jsonc -c ../counter/wrangler.jsonc",
      "language": "sh"
    },
    {
      "code": "interface Env {\n  SUM_SERVICE: Service<import(\"../sum-worker/src/index\").SumService>;\n  COUNTER_OBJECT: DurableObjectNamespace<\n    import(\"../counter/src/index\").Counter\n  >;\n}",
      "language": "ts"
    },
    {
      "code": "export default {\n  async fetch(req, env, ctx): Promise<Response> {\n    const result = await env.SUM_SERVICE.sum(1, 2);\n    return new Response(result.toString());\n  },\n} satisfies ExportedHandler<Env>;",
      "language": "ts"
    },
    {
      "code": "let reader = readable.getReader({ mode: 'byob' });",
      "language": "js"
    },
    {
      "code": "const { readable, writable } = new TransformStream();\nconst reader = readable.getReader({ mode: 'byob' });",
      "language": "js"
    },
    {
      "code": "const { readable, writable } = new TransformStream();\nconst reader = readable.getReader();",
      "language": "js"
    },
    {
      "code": "let { readable, writable } = new TransformStream();",
      "language": "js"
    },
    {
      "code": "let { readable, writable } = new IdentityTransformStream();",
      "language": "js"
    },
    {
      "code": "let { readable, writable } = new FixedLengthStream(1000);",
      "language": "js"
    },
    {
      "code": "readableStream\n  .pipeTo(writableStream)\n  .then(() => console.log('All data successfully written!'))\n  .catch(e => console.error('Something went wrong!', e));",
      "language": "js"
    },
    {
      "code": "const writer = writableStream.getWriter();\nwriter.write(data);",
      "language": "js"
    },
    {
      "code": "function writeArrayToStream(array, writableStream) {\n  const writer = writableStream.getWriter();\n  array.forEach(chunk => writer.write(chunk).catch(() => {}));\n\n\n  return writer.close();\n}\n\n\nwriteArrayToStream([1, 2, 3, 4, 5], writableStream)\n  .then(() => console.log('All done!'))\n  .catch(e => console.error('Error with the stream: ' + e));",
      "language": "js"
    },
    {
      "code": "let writer = writable.getWriter();\n// Write a preamble.\nwriter.write(new TextEncoder().encode('foo bar'));\n// While that’s still writing, pipe the rest of the body from somewhere else.\nwriter.releaseLock();\nawait someResponse.body.pipeTo(writable);",
      "language": "js"
    },
    {
      "code": ";; src/simple.wat\n(module\n  ;; Import a function from JavaScript named `imported_func`\n  ;; which takes a single i32 argument and assign to\n  ;; variable $i\n  (func $i (import \"imports\" \"imported_func\") (param i32))\n  ;; Export a function named `exported_func` which takes a\n  ;; single i32 argument and returns an i32\n  (func (export \"exported_func\") (param $input i32) (result i32)\n    ;; Invoke `imported_func` with $input as argument\n    local.get $input\n    call $i\n    ;; Return $input\n    local.get $input\n    return\n  )\n)",
      "language": "txt"
    },
    {
      "code": "wat2wasm src/simple.wat -o src/simple.wasm",
      "language": "sh"
    },
    {
      "code": "import mod from \"./simple.wasm\";\n\n\n// Define imports available to Wasm instance.\nconst importObject = {\n  imports: {\n    imported_func: (arg: number) => {\n      console.log(`Hello from JavaScript: ${arg}`);\n    },\n  },\n};\n\n\n// Create instance of WebAssembly Module `mod`, supplying\n// the expected imports in `importObject`. This should be\n// done at the top level of the script to avoid instantiation on every request.\nconst instance = await WebAssembly.instantiate(mod, importObject);\n\n\nexport default {\n  async fetch() {\n    // Invoke the `exported_func` from our Wasm Instance with\n    // an argument.\n    const retval = instance.exports.exported_func(42);\n    // Return the return value!\n    return new Response(`Success: ${retval}`);\n  },\n};",
      "language": "typescript"
    },
    {
      "code": "npm i -D miniflare",
      "language": "sh"
    },
    {
      "code": "yarn add -D miniflare",
      "language": "sh"
    },
    {
      "code": "pnpm add -D miniflare",
      "language": "sh"
    },
    {
      "code": "{\n  ...\n  \"type\": \"module\"\n  ...\n}",
      "language": "json"
    },
    {
      "code": "import { Miniflare } from \"miniflare\";\n\n\nconst mf = new Miniflare({\n  modules: true,\n  script: `\n  export default {\n    async fetch(request, env, ctx) {\n      return new Response(\"Hello Miniflare!\");\n    }\n  }\n  `,\n});\n\n\nconst res = await mf.dispatchFetch(\"http://localhost:8787/\");\nconsole.log(await res.text()); // Hello Miniflare!\nawait mf.dispose();",
      "language": "js"
    },
    {
      "code": "const mf = new Miniflare({\n  scriptPath: \"worker.js\",\n});",
      "language": "js"
    },
    {
      "code": "await mf.dispose();",
      "language": "js"
    },
    {
      "code": "const mf = new Miniflare({\n  script: \"...\",\n  kvNamespaces: [\"TEST_NAMESPACE\"],\n  bindings: { KEY: \"value1\" },\n});\n\n\nawait mf.setOptions({\n  script: \"...\",\n  kvNamespaces: [\"TEST_NAMESPACE\"],\n  bindings: { KEY: \"value2\" },\n});",
      "language": "js"
    },
    {
      "code": "import { Miniflare } from \"miniflare\";\n\n\nconst mf = new Miniflare({\n  modules: true,\n  script: `\n  let lastScheduledController;\n  let lastQueueBatch;\n  export default {\n    async fetch(request, env, ctx) {\n      const { pathname } = new URL(request.url);\n      if (pathname === \"/scheduled\") {\n        return Response.json({\n          scheduledTime: lastScheduledController?.scheduledTime,\n          cron: lastScheduledController?.cron,\n        });\n      } else if (pathname === \"/queue\") {\n        return Response.json({\n          queue: lastQueueBatch.queue,\n          messages: lastQueueBatch.messages.map((message) => ({\n          id: message.id,\n          timestamp: message.timestamp.getTime(),\n          body: message.body,\n          bodyType: message.body.constructor.name,\n          })),\n        });\n      } else if (pathname === \"/get-url\") {\n        return new Response(request.url);\n      } else {\n        return new Response(null, { status: 404 });\n      }\n    },\n    async scheduled(controller, env, ctx) {\n      lastScheduledController = controller;\n      if (controller.cron === \"* * * * *\") controller.noRetry();\n    },\n    async queue(batch, env, ctx) {\n      lastQueueBatch = batch;\n      if (batch.queue === \"needy\") batch.retryAll();\n      for (const message of batch.messages) {\n        if (message.id === \"perfect\") message.ack();\n      }\n    }\n  }`,\n});\n\n\nconst res = await mf.dispatchFetch(\"http://localhost:8787/\", {\n  headers: { \"X-Message\": \"Hello Miniflare!\" },\n});\nconsole.log(await res.text()); // Hello Miniflare!\n\n\nconst worker = await mf.getWorker();\n\n\nconst scheduledResult = await worker.scheduled({\n  cron: \"* * * * *\",\n});\nconsole.log(scheduledResult); // { outcome: \"ok\", noRetry: true });\n\n\nconst queueResult = await worker.queue(\"needy\", [\n  { id: \"a\", timestamp: new Date(1000), body: \"a\", attempts: 1 },\n  { id: \"b\", timestamp: new Date(2000), body: { b: 1 }, attempts: 1 },\n]);\nconsole.log(queueResult); // { outcome: \"ok\", retryAll: true, ackAll: false, explicitRetries: [], explicitAcks: []}",
      "language": "js"
    },
    {
      "code": "import { Miniflare } from \"miniflare\";\n\n\nconst mf = new Miniflare({\n  modules: true,\n  script: `\n  export default {\n    async fetch(request, env, ctx) {\n      return new Response(\"Hello Miniflare!\");\n    })\n  }\n  `,\n  port: 5000,\n});\nawait mf.ready;\nconsole.log(\"Listening on :5000\");",
      "language": "js"
    },
    {
      "code": "const mf = new Miniflare({\n  cf: false,\n});",
      "language": "js"
    },
    {
      "code": "const mf = new Miniflare({\n  cf: \"cf.json\",\n});",
      "language": "js"
    },
    {
      "code": "const mf = new Miniflare({\n  https: true,\n});",
      "language": "js"
    },
    {
      "code": "const mf = new Miniflare({\n  // These are all optional, you don't need to include them all\n  httpsKeyPath: \"./key.pem\",\n  httpsCertPath: \"./cert.pem\",\n});",
      "language": "js"
    },
    {
      "code": "const mf = new Miniflare({\n  // These are all optional, you don't need to include them all\n  httpsKey: \"-----BEGIN RSA PRIVATE KEY-----...\",\n  httpsCert: \"-----BEGIN CERTIFICATE-----...\",\n});",
      "language": "js"
    },
    {
      "code": "import { Miniflare, Log, LogLevel } from \"miniflare\";\n\n\nconst mf = new Miniflare({\n  scriptPath: \"worker.js\",\n  log: new Log(LogLevel.DEBUG), // Enable debug messages\n});",
      "language": "js"
    },
    {
      "code": "import { Miniflare, Log, LogLevel } from \"miniflare\";\n\n\nconst mf = new Miniflare({\n  // All options are optional, but one of script or scriptPath is required\n\n\n  log: new Log(LogLevel.INFO), // Logger Miniflare uses for debugging\n\n\n  script: `\n    export default {\n      async fetch(request, env, ctx) {\n        return new Response(\"Hello Miniflare!\");\n      }\n    }\n  `,\n  scriptPath: \"./index.js\",\n\n\n  modules: true, // Enable modules\n  modulesRules: [\n    // Modules import rule\n    { type: \"ESModule\", include: [\"**/*.js\"], fallthrough: true },\n    { type: \"Text\", include: [\"**/*.text\"] },\n  ],\n  compatibilityDate: \"2021-11-23\", // Opt into backwards-incompatible changes from\n  compatibilityFlags: [\"formdata_parser_supports_files\"], // Control specific backwards-incompatible changes\n  upstream: \"https://miniflare.dev\", // URL of upstream origin\n  workers: [{\n    // reference additional named workers\n    name: \"worker2\",\n    kvNamespaces: { COUNTS: \"counts\" },\n    serviceBindings: {\n      INCREMENTER: \"incrementer\",\n      // Service bindings can also be defined as custom functions, with access\n      // to anything defined outside Miniflare.\n      async CUSTOM(request) {\n        // `request` is the incoming `Request` object.\n        return new Response(message);\n      },\n    },\n    modules: true,\n    script: `export default {\n        async fetch(request, env, ctx) {\n          // Get the message defined outside\n          const response = await env.CUSTOM.fetch(\"http://host/\");\n          const message = await response.text();\n\n\n          // Increment the count 3 times\n          await env.INCREMENTER.fetch(\"http://host/\");\n          await env.INCREMENTER.fetch(\"http://host/\");\n          await env.INCREMENTER.fetch(\"http://host/\");\n          const count = await env.COUNTS.get(\"count\");\n\n\n          return new Response(message + count);\n        }\n      }`,\n    },\n  }],\n  name: \"worker\", // Name of service\n  routes: [\"*site.mf/worker\"],\n\n\n\n\n  host: \"127.0.0.1\", // Host for HTTP(S) server to listen on\n  port: 8787, // Port for HTTP(S) server to listen on\n  https: true, // Enable self-signed HTTPS (with optional cert path)\n  httpsKey: \"-----BEGIN RSA PRIVATE KEY-----...\",\n  httpsKeyPath: \"./key.pem\", // Path to PEM SSL key\n  httpsCert: \"-----BEGIN CERTIFICATE-----...\",\n  httpsCertPath: \"./cert.pem\", // Path to PEM SSL cert chain\n  cf: \"./node_modules/.mf/cf.json\", // Path for cached Request cf object from Cloudflare\n  liveReload: true, // Reload HTML pages whenever worker is reloaded\n\n\n\n\n\n\n  kvNamespaces: [\"TEST_NAMESPACE\"], // KV namespace to bind\n  kvPersist: \"./kv-data\", // Persist KV data (to optional path)\n\n\n  r2Buckets: [\"BUCKET\"], // R2 bucket to bind\n  r2Persist: \"./r2-data\", // Persist R2 data (to optional path)\n\n\n  durableObjects: {\n    // Durable Object to bind\n    TEST_OBJECT: \"TestObject\", // className\n    API_OBJECT: { className: \"ApiObject\", scriptName: \"api\" },\n  },\n  durableObjectsPersist: \"./durable-objects-data\", // Persist Durable Object data (to optional path)\n\n\n  cache: false, // Enable default/named caches (enabled by default)\n  cachePersist: \"./cache-data\", // Persist cached data (to optional path)\n  cacheWarnUsage: true, // Warn on cache usage, for workers.dev subdomains\n\n\n  sitePath: \"./site\", // Path to serve Workers Site files from\n  siteInclude: [\"**/*.html\", \"**/*.css\", \"**/*.js\"], // Glob pattern of site files to serve\n  siteExclude: [\"node_modules\"], // Glob pattern of site files not to serve\n\n\n\n\n  bindings: { SECRET: \"sssh\" }, // Binds variable/secret to environment\n  wasmBindings: { ADD_MODULE: \"./add.wasm\" }, // WASM module to bind\n  textBlobBindings: { TEXT: \"./text.txt\" }, // Text blob to bind\n  dataBlobBindings: { DATA: \"./data.bin\" }, // Data blob to bind\n});\n\n\nawait mf.setOptions({ kvNamespaces: [\"TEST_NAMESPACE2\"] }); // Apply options and reload\n\n\nconst bindings = await mf.getBindings(); // Get bindings (KV/Durable Object namespaces, variables, etc)\n\n\n// Dispatch \"fetch\" event to worker\nconst res = await mf.dispatchFetch(\"http://localhost:8787/\", {\n  headers: { Authorization: \"Bearer ...\" },\n});\nconst text = await res.text();\n\n\nconst worker = await mf.getWorker();\n\n\n// Dispatch \"scheduled\" event to worker\nconst scheduledResult = await worker.scheduled({ cron: \"30 * * * *\" })\n\n\nconst TEST_NAMESPACE = await mf.getKVNamespace(\"TEST_NAMESPACE\");\n\n\nconst BUCKET = await mf.getR2Bucket(\"BUCKET\");\n\n\nconst caches = await mf.getCaches(); // Get global `CacheStorage` instance\nconst defaultCache = caches.default;\nconst namedCache = await caches.open(\"name\");\n\n\n// Get Durable Object namespace and storage for ID\nconst TEST_OBJECT = await mf.getDurableObjectNamespace(\"TEST_OBJECT\");\nconst id = TEST_OBJECT.newUniqueId();\nconst storage = await mf.getDurableObjectStorage(id);\n\n\n// Get Queue Producer\nconst producer = await mf.getQueueProducer(\"QUEUE_BINDING\");\n\n\n// Get D1 Database\nconst db = await mf.getD1Database(\"D1_BINDING\")\n\n\nawait mf.dispose(); // Cleanup storage database connections and watcher",
      "language": "js"
    },
    {
      "code": "npm i -D miniflare@latest",
      "language": "sh"
    },
    {
      "code": "yarn add -D miniflare@latest",
      "language": "sh"
    },
    {
      "code": "pnpm add -D miniflare@latest",
      "language": "sh"
    },
    {
      "code": "export default {\n  async fetch(request) {\n    return new Response(`Hello World`);\n  },\n};",
      "language": "js"
    },
    {
      "code": "import assert from \"node:assert\";\nimport test, { after, before, describe } from \"node:test\";\nimport { Miniflare } from \"miniflare\";\n\n\ndescribe(\"worker\", () => {\n  /**\n   * @type {Miniflare}\n   */\n  let worker;\n\n\n  before(async () => {\n    worker = new Miniflare({\n      modules: [\n        {\n          type: \"ESModule\",\n          path: \"src/index.js\",\n        },\n      ],\n    });\n    await worker.ready;\n  });\n\n\n  test(\"hello world\", async () => {\n    assert.strictEqual(\n      await (await worker.dispatchFetch(\"http://example.com\")).text(),\n      \"Hello World\",\n    );\n  });\n\n\n  after(async () => {\n    await worker.dispose();\n  });\n});",
      "language": "js"
    },
    {
      "code": "...\ndescribe(\"worker\", () => {\n  ...\n  before(async () => {\n    worker = new Miniflare({\n      ...\n      bindings: {\n        FOO: \"Hello Bindings\",\n      },\n    });\n    ...\n  });\n\n\n  test(\"text binding\", async () => {\n    const bindings = await worker.getBindings();\n    assert.strictEqual(bindings.FOO, \"Hello Bindings\");\n  });\n  ...\n});",
      "language": "js"
    },
    {
      "code": "...\ndescribe(\"worker\", () => {\n  ...\n  before(async () => {\n    worker = new Miniflare({\n      ...\n      kvNamespaces: [\"KV\"],\n    });\n    ...\n  });\n\n\n  test(\"kv binding\", async () => {\n    const bindings = await worker.getBindings();\n    await bindings.KV.put(\"key\", \"value\");\n    assert.strictEqual(await bindings.KV.get(\"key\"), \"value\");\n  });\n  ...\n});",
      "language": "js"
    },
    {
      "code": "new Miniflare({\n  modules: [\n    {\n      type: \"ESModule\",\n      path: \"src/index.js\",\n    },\n    {\n      type: \"ESModule\",\n      path: \"src/imported.js\",\n    },\n  ],\n});",
      "language": "js"
    },
    {
      "code": "new Miniflare({\n  scriptPath: \"src/index-with-imports.js\",\n  modules: true,\n  modulesRules: [{ type: \"ESModule\", include: [\"**/*.js\"] }],\n});",
      "language": "js"
    },
    {
      "code": "before(() => {\n  spawnSync(\"npx wrangler build -c wrangler-build.json\", {\n    shell: true,\n    stdio: \"pipe\",\n  });\n});",
      "language": "js"
    },
    {
      "code": "vitest --inspect --no-file-parallelism",
      "language": "sh"
    },
    {
      "code": "vitest --inspect=3456 --no-file-parallelism",
      "language": "sh"
    },
    {
      "code": "import { defineWorkersConfig } from \"@cloudflare/vitest-pool-workers/config\";\n\n\nexport default defineWorkersConfig({\n  test: {\n    inspector: {\n        port: 3456,\n    },\n    poolOptions: {\n      workers: {\n        // ...\n      },\n    },\n  },\n});",
      "language": "ts"
    },
    {
      "code": "{\n    \"configurations\": [\n        {\n            \"type\": \"node\",\n            \"request\": \"launch\",\n            \"name\": \"Open inspector with Vitest\",\n            \"program\": \"${workspaceRoot}/node_modules/vitest/vitest.mjs\",\n            \"console\": \"integratedTerminal\",\n            \"args\": [\"--inspect=9229\", \"--no-file-parallelism\"]\n        },\n        {\n            \"name\": \"Attach to Workers Runtime\",\n            \"type\": \"node\",\n            \"request\": \"attach\",\n            \"port\": 9229,\n            \"cwd\": \"/\",\n            \"resolveSourceMapLocations\": null,\n            \"attachExistingChildren\": false,\n            \"autoAttachChildProcesses\": false,\n        }\n    ],\n    \"compounds\": [\n        {\n            \"name\": \"Debug Workers tests\",\n            \"configurations\": [\"Open inspector with Vitest\", \"Attach to Workers Runtime\"],\n            \"stopAll\": true\n        }\n    ]\n}",
      "language": "json"
    },
    {
      "code": "import { defineWorkersConfig } from \"@cloudflare/vitest-pool-workers/config\";\n\n\nexport default defineWorkersConfig({\n  test: {\n    poolOptions: {\n      workers: {\n        wrangler: {\n          configPath: \"./wrangler.toml\",\n        },\n      },\n    },\n  },\n});",
      "language": "ts"
    },
    {
      "code": "import { defineWorkersConfig } from \"@cloudflare/vitest-pool-workers/config\";\n\n\nexport default defineWorkersConfig({\n  test: {\n    poolOptions: {\n      workers: {\n        // Refer to type of WorkersPoolOptions...\n      },\n    },\n  },\n});",
      "language": "ts"
    },
    {
      "code": "import { defineWorkspace, defineProject } from \"vitest/config\";\nimport { defineWorkersProject } from \"@cloudflare/vitest-pool-workers/config\";\n\n\nconst workspace = defineWorkspace([\n  defineWorkersProject({\n    test: {\n      name: \"Workers\",\n      include: [\"**/*.worker.test.ts\"],\n      poolOptions: {\n        workers: {\n          // Refer to type of WorkersPoolOptions...\n        },\n      },\n    },\n  }),\n\n\n  // ...\n]);\n\n\nexport default workspace;",
      "language": "ts"
    },
    {
      "code": "import path from \"node:path\";\nimport {\n  buildPagesASSETSBinding,\n  defineWorkersProject,\n} from \"@cloudflare/vitest-pool-workers/config\";\n\n\nexport default defineWorkersProject(async () => {\n  const assetsPath = path.join(__dirname, \"public\");\n\n\n  return {\n    test: {\n      poolOptions: {\n        workers: {\n          miniflare: {\n            serviceBindings: {\n              ASSETS: await buildPagesASSETSBinding(assetsPath),\n            },\n          },\n        },\n      },\n    },\n  };\n});",
      "language": "ts"
    },
    {
      "code": "import path from \"node:path\";\nimport {\n  defineWorkersProject,\n  readD1Migrations,\n} from \"@cloudflare/vitest-pool-workers/config\";\n\n\nexport default defineWorkersProject(async () => {\n  // Read all migrations in the `migrations` directory\n  const migrationsPath = path.join(__dirname, \"migrations\");\n  const migrations = await readD1Migrations(migrationsPath);\n\n\n  return {\n    test: {\n      setupFiles: [\"./test/apply-migrations.ts\"],\n      poolOptions: {\n        workers: {\n          miniflare: {\n            // Add a test-only binding for migrations, so we can apply them in a setup file\n            bindings: { TEST_MIGRATIONS: migrations },\n          },\n        },\n      },\n    },\n  };\n});",
      "language": "ts"
    },
    {
      "code": "import { env } from \"cloudflare:test\";\n    import { beforeAll, beforeEach, describe, test, expect } from \"vitest\";\n\n\n    // Get the current list stored in a KV namespace\n    async function get(): Promise<string[]> {\n      return (await env.NAMESPACE.get(\"list\", \"json\")) ?? [];\n    }\n    // Add an item to the end of the list\n    async function append(item: string) {\n      const value = await get();\n      value.push(item);\n      await env.NAMESPACE.put(\"list\", JSON.stringify(value));\n    }\n\n\n    beforeAll(() => append(\"all\"));\n    beforeEach(() => append(\"each\"));\n\n\n    test(\"one\", async () => {\n      // Each test gets its own storage environment copied from the parent\n      await append(\"one\");\n      expect(await get()).toStrictEqual([\"all\", \"each\", \"one\"]);\n    });\n    // `append(\"each\")` and `append(\"one\")` undone\n    test(\"two\", async () => {\n      await append(\"two\");\n      expect(await get()).toStrictEqual([\"all\", \"each\", \"two\"]);\n    });\n    // `append(\"each\")` and `append(\"two\")` undone\n\n\n    describe(\"describe\", async () => {\n      beforeAll(() => append(\"describe all\"));\n      beforeEach(() => append(\"describe each\"));\n\n\n      test(\"three\", async () => {\n        await append(\"three\");\n        expect(await get()).toStrictEqual([\n          // All `beforeAll()`s run before `beforeEach()`s\n          \"all\",\n          \"describe all\",\n          \"each\",\n          \"describe each\",\n          \"three\",\n        ]);\n      });\n      // `append(\"each\")`, `append(\"describe each\")` and `append(\"three\")` undone\n      test(\"four\", async () => {\n        await append(\"four\");\n        expect(await get()).toStrictEqual([\n          \"all\",\n          \"describe all\",\n          \"each\",\n          \"describe each\",\n          \"four\",\n        ]);\n      });\n      // `append(\"each\")`, `append(\"describe each\")` and `append(\"four\")` undone\n    });",
      "language": "ts"
    },
    {
      "code": "// env.d.ts\n    declare module \"vitest\" {\n      interface ProvidedContext {\n        port: number;\n      }\n    }\n\n\n    // global-setup.ts\n    import type { GlobalSetupContext } from \"vitest/node\";\n    export default function ({ provide }: GlobalSetupContext) {\n      // Runs inside Node.js, could start server here...\n      provide(\"port\", 1337);\n      return () => {\n        /* ...then teardown here */\n      };\n    }\n\n\n    // vitest.config.ts\n    import { defineWorkersConfig } from \"@cloudflare/vitest-pool-workers/config\";\n    export default defineWorkersConfig({\n      test: {\n        globalSetup: [\"./global-setup.ts\"],\n        pool: \"@cloudflare/vitest-pool-workers\",\n        poolOptions: {\n          workers: ({ inject }) => ({\n            miniflare: {\n              hyperdrives: {\n                DATABASE: `postgres://user:pass@example.com:${inject(\"port\")}/db`,\n              },\n            },\n          }),\n        },\n      },\n    });",
      "language": "ts"
    },
    {
      "code": "type SourcelessWorkerOptions = Omit<\n  WorkerOptions,\n  \"script\" | \"scriptPath\" | \"modules\" | \"modulesRoot\"\n>;",
      "language": "ts"
    }
  ],
  "headings": [
    {
      "level": "h2",
      "text": "Using JavaScript globals from Python Workers",
      "id": "using-javascript-globals-from-python-workers"
    },
    {
      "level": "h2",
      "text": "Local Development",
      "id": "local-development"
    },
    {
      "level": "h2",
      "text": "Deployment Lifecycle and Cold Start Optimizations",
      "id": "deployment-lifecycle-and-cold-start-optimizations"
    },
    {
      "level": "h2",
      "text": "Pyodide and Python versions",
      "id": "pyodide-and-python-versions"
    },
    {
      "level": "h2",
      "text": "Supported Libraries",
      "id": "supported-libraries"
    },
    {
      "level": "h2",
      "text": "HTTP Client Libraries",
      "id": "http-client-libraries"
    },
    {
      "level": "h2",
      "text": "Modules with limited functionality",
      "id": "modules-with-limited-functionality"
    },
    {
      "level": "h2",
      "text": "Excluded modules",
      "id": "excluded-modules"
    },
    {
      "level": "h2",
      "text": "Background",
      "id": "background"
    },
    {
      "level": "h2",
      "text": "`time`",
      "id": "`time`"
    },
    {
      "level": "h2",
      "text": "`tracing`",
      "id": "`tracing`"
    },
    {
      "level": "h2",
      "text": "`reqwest`",
      "id": "`reqwest`"
    },
    {
      "level": "h2",
      "text": "`tokio-postgres`",
      "id": "`tokio-postgres`"
    },
    {
      "level": "h2",
      "text": "`hyper`",
      "id": "`hyper`"
    },
    {
      "level": "h2",
      "text": "Debug via breakpoints",
      "id": "debug-via-breakpoints"
    },
    {
      "level": "h3",
      "text": "VSCode debug terminals",
      "id": "vscode-debug-terminals"
    },
    {
      "level": "h3",
      "text": "Setup VS Code to use breakpoints with `launch.json` files",
      "id": "setup-vs-code-to-use-breakpoints-with-`launch.json`-files"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Taking a profile",
      "id": "taking-a-profile"
    },
    {
      "level": "h2",
      "text": "An Example Profile",
      "id": "an-example-profile"
    },
    {
      "level": "h2",
      "text": "Additional Resources",
      "id": "additional-resources"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "Step 1: Create a dataset",
      "id": "step-1:-create-a-dataset"
    },
    {
      "level": "h2",
      "text": "Step 2: Get your Axiom API token and dataset",
      "id": "step-2:-get-your-axiom-api-token-and-dataset"
    },
    {
      "level": "h2",
      "text": "Step 3: Configure Cloudflare destinations",
      "id": "step-3:-configure-cloudflare-destinations"
    },
    {
      "level": "h3",
      "text": "Axiom OTLP endpoints",
      "id": "axiom-otlp-endpoints"
    },
    {
      "level": "h3",
      "text": "Configure trace or logs destination",
      "id": "configure-trace-or-logs-destination"
    },
    {
      "level": "h2",
      "text": "Step 3: Configure your Worker",
      "id": "step-3:-configure-your-worker"
    },
    {
      "level": "h2",
      "text": "Taking a snapshot",
      "id": "taking-a-snapshot"
    },
    {
      "level": "h2",
      "text": "An Example Snapshot",
      "id": "an-example-snapshot"
    },
    {
      "level": "h2",
      "text": "Additional Resources",
      "id": "additional-resources"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "Step 1: Access the OpenTelemetry setup guide",
      "id": "step-1:-access-the-opentelemetry-setup-guide"
    },
    {
      "level": "h2",
      "text": "Step 2: Set up destination",
      "id": "step-2:-set-up-destination"
    },
    {
      "level": "h2",
      "text": "Step 3: Configure your Worker",
      "id": "step-3:-configure-your-worker"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "Step 1: Get your Honeycomb API key",
      "id": "step-1:-get-your-honeycomb-api-key"
    },
    {
      "level": "h2",
      "text": "Step 2: Configure Cloudflare destinations",
      "id": "step-2:-configure-cloudflare-destinations"
    },
    {
      "level": "h3",
      "text": "Honeycomb OTLP endpoints",
      "id": "honeycomb-otlp-endpoints"
    },
    {
      "level": "h3",
      "text": "Configure trace destination",
      "id": "configure-trace-destination"
    },
    {
      "level": "h3",
      "text": "Configure logs destination",
      "id": "configure-logs-destination"
    },
    {
      "level": "h2",
      "text": "Step 3: Configure your Worker",
      "id": "step-3:-configure-your-worker"
    },
    {
      "level": "h2",
      "text": "Verify your Logpush access",
      "id": "verify-your-logpush-access"
    },
    {
      "level": "h2",
      "text": "Create a Logpush job",
      "id": "create-a-logpush-job"
    },
    {
      "level": "h3",
      "text": "Via the Cloudflare dashboard",
      "id": "via-the-cloudflare-dashboard"
    },
    {
      "level": "h3",
      "text": "Via cURL",
      "id": "via-curl"
    },
    {
      "level": "h2",
      "text": "Enable logging on your Worker",
      "id": "enable-logging-on-your-worker"
    },
    {
      "level": "h3",
      "text": "Local development",
      "id": "local-development"
    },
    {
      "level": "h3",
      "text": "Dashboard",
      "id": "dashboard"
    },
    {
      "level": "h2",
      "text": "Limits",
      "id": "limits"
    },
    {
      "level": "h3",
      "text": "Example",
      "id": "example"
    },
    {
      "level": "h2",
      "text": "Prerequisites",
      "id": "prerequisites"
    },
    {
      "level": "h2",
      "text": "Step 1: Create a Sentry project",
      "id": "step-1:-create-a-sentry-project"
    },
    {
      "level": "h2",
      "text": "Step 2: Get your Sentry OTLP endpoints",
      "id": "step-2:-get-your-sentry-otlp-endpoints"
    },
    {
      "level": "h2",
      "text": "Step 3: Set up destination in the Cloudflare dashboard",
      "id": "step-3:-set-up-destination-in-the-cloudflare-dashboard"
    },
    {
      "level": "h3",
      "text": "Traces Destination",
      "id": "traces-destination"
    },
    {
      "level": "h3",
      "text": "Logs destination",
      "id": "logs-destination"
    },
    {
      "level": "h2",
      "text": "Step 4: Configure your Worker",
      "id": "step-4:-configure-your-worker"
    },
    {
      "level": "h2",
      "text": "Configure Tail Workers",
      "id": "configure-tail-workers"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "View logs from the dashboard",
      "id": "view-logs-from-the-dashboard"
    },
    {
      "level": "h2",
      "text": "View logs using `wrangler tail`",
      "id": "view-logs-using-`wrangler-tail`"
    },
    {
      "level": "h2",
      "text": "Limits",
      "id": "limits"
    },
    {
      "level": "h2",
      "text": "Persist logs",
      "id": "persist-logs"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Enable Workers Logs",
      "id": "enable-workers-logs"
    },
    {
      "level": "h3",
      "text": "Enabling with environments",
      "id": "enabling-with-environments"
    },
    {
      "level": "h2",
      "text": "View logs from the dashboard",
      "id": "view-logs-from-the-dashboard"
    },
    {
      "level": "h2",
      "text": "Best Practices",
      "id": "best-practices"
    },
    {
      "level": "h3",
      "text": "Logging structured JSON objects",
      "id": "logging-structured-json-objects"
    },
    {
      "level": "h2",
      "text": "Features",
      "id": "features"
    },
    {
      "level": "h3",
      "text": "Invocation Logs",
      "id": "invocation-logs"
    },
    {
      "level": "h3",
      "text": "Custom logs",
      "id": "custom-logs"
    },
    {
      "level": "h3",
      "text": "Head-based sampling",
      "id": "head-based-sampling"
    },
    {
      "level": "h2",
      "text": "Limits",
      "id": "limits"
    },
    {
      "level": "h2",
      "text": "Pricing",
      "id": "pricing"
    },
    {
      "level": "h3",
      "text": "Examples",
      "id": "examples"
    },
    {
      "level": "h3",
      "text": "Non-I/O operations may report time of 0 ms",
      "id": "non-i/o-operations-may-report-time-of-0-ms"
    },
    {
      "level": "h3",
      "text": "Trace context propagation not yet supported",
      "id": "trace-context-propagation-not-yet-supported"
    },
    {
      "level": "h3",
      "text": "Incomplete spans attributes",
      "id": "incomplete-spans-attributes"
    },
    {
      "level": "h3",
      "text": "Support for custom spans and attributes",
      "id": "support-for-custom-spans-and-attributes"
    },
    {
      "level": "h3",
      "text": "Span and attribute names subject to change",
      "id": "span-and-attribute-names-subject-to-change"
    },
    {
      "level": "h3",
      "text": "Known bugs and other call outs",
      "id": "known-bugs-and-other-call-outs"
    },
    {
      "level": "h2",
      "text": "Currently supported spans and attributes",
      "id": "currently-supported-spans-and-attributes"
    },
    {
      "level": "h3",
      "text": "Attributes available on all spans",
      "id": "attributes-available-on-all-spans"
    },
    {
      "level": "h3",
      "text": "Attributes available on all root spans",
      "id": "attributes-available-on-all-root-spans"
    },
    {
      "level": "h3",
      "text": "[Runtime API](https://developers.cloudflare.com/workers/runtime-apis/)",
      "id": "[runtime-api](https://developers.cloudflare.com/workers/runtime-apis/)"
    },
    {
      "level": "h3",
      "text": "[Handlers](https://developers.cloudflare.com/workers/runtime-apis/handlers/)",
      "id": "[handlers](https://developers.cloudflare.com/workers/runtime-apis/handlers/)"
    },
    {
      "level": "h3",
      "text": "[D1](https://developers.cloudflare.com/d1/)",
      "id": "[d1](https://developers.cloudflare.com/d1/)"
    },
    {
      "level": "h3",
      "text": "[Browser Rendering](https://developers.cloudflare.com/browser-rendering/)",
      "id": "[browser-rendering](https://developers.cloudflare.com/browser-rendering/)"
    },
    {
      "level": "h3",
      "text": "[Workers KV](https://developers.cloudflare.com/kv/)",
      "id": "[workers-kv](https://developers.cloudflare.com/kv/)"
    },
    {
      "level": "h3",
      "text": "[R2](https://developers.cloudflare.com/r2/)",
      "id": "[r2](https://developers.cloudflare.com/r2/)"
    },
    {
      "level": "h3",
      "text": "[Durable Object API](https://developers.cloudflare.com/durable-objects/)",
      "id": "[durable-object-api](https://developers.cloudflare.com/durable-objects/)"
    },
    {
      "level": "h3",
      "text": "[Durable Object Storage SQL API](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api)",
      "id": "[durable-object-storage-sql-api](https://developers.cloudflare.com/durable-objects/api/sqlite-storage-api)"
    },
    {
      "level": "h3",
      "text": "[Durable Object Storage KV API](https://developers.cloudflare.com/durable-objects/api/legacy-kv-storage-api)",
      "id": "[durable-object-storage-kv-api](https://developers.cloudflare.com/durable-objects/api/legacy-kv-storage-api)"
    },
    {
      "level": "h3",
      "text": "[Durable Object Storage Alarms API](https://developers.cloudflare.com/durable-objects/api/alarms/)",
      "id": "[durable-object-storage-alarms-api](https://developers.cloudflare.com/durable-objects/api/alarms/)"
    },
    {
      "level": "h3",
      "text": "[Images](https://developers.cloudflare.com/images/transform-images/bindings/)",
      "id": "[images](https://developers.cloudflare.com/images/transform-images/bindings/)"
    },
    {
      "level": "h3",
      "text": "[`images_output`](https://developers.cloudflare.com/images/transform-images/bindings/#output)",
      "id": "[`images_output`](https://developers.cloudflare.com/images/transform-images/bindings/#output)"
    },
    {
      "level": "h3",
      "text": "[`images_info`](https://developers.cloudflare.com/images/transform-images/bindings/#info)",
      "id": "[`images_info`](https://developers.cloudflare.com/images/transform-images/bindings/#info)"
    },
    {
      "level": "h3",
      "text": "[Email](https://developers.cloudflare.com/email-routing/)",
      "id": "[email](https://developers.cloudflare.com/email-routing/)"
    },
    {
      "level": "h3",
      "text": "[Queues](https://developers.cloudflare.com/queues/)",
      "id": "[queues](https://developers.cloudflare.com/queues/)"
    },
    {
      "level": "h3",
      "text": "[`Rate limiting`](https://developers.cloudflare.com/workers/runtime-apis/bindings/rate-limit/)",
      "id": "[`rate-limiting`](https://developers.cloudflare.com/workers/runtime-apis/bindings/rate-limit/)"
    },
    {
      "level": "h2",
      "text": "2022-12-16",
      "id": "2022-12-16"
    },
    {
      "level": "h2",
      "text": "2022-12-02",
      "id": "2022-12-02"
    },
    {
      "level": "h2",
      "text": "2022-11-30",
      "id": "2022-11-30"
    },
    {
      "level": "h2",
      "text": "2022-11-17",
      "id": "2022-11-17"
    },
    {
      "level": "h2",
      "text": "2022-11-02",
      "id": "2022-11-02"
    },
    {
      "level": "h2",
      "text": "2022-10-21",
      "id": "2022-10-21"
    },
    {
      "level": "h2",
      "text": "2022-10-10",
      "id": "2022-10-10"
    },
    {
      "level": "h2",
      "text": "2022-09-16",
      "id": "2022-09-16"
    },
    {
      "level": "h2",
      "text": "2022-08-12",
      "id": "2022-08-12"
    },
    {
      "level": "h2",
      "text": "2022-07-08",
      "id": "2022-07-08"
    },
    {
      "level": "h2",
      "text": "2022-06-24",
      "id": "2022-06-24"
    },
    {
      "level": "h2",
      "text": "2022-06-18",
      "id": "2022-06-18"
    },
    {
      "level": "h2",
      "text": "2022-06-09",
      "id": "2022-06-09"
    },
    {
      "level": "h2",
      "text": "2022-06-03",
      "id": "2022-06-03"
    },
    {
      "level": "h2",
      "text": "2022-05-26",
      "id": "2022-05-26"
    },
    {
      "level": "h2",
      "text": "2022-05-19",
      "id": "2022-05-19"
    },
    {
      "level": "h2",
      "text": "2022-05-12",
      "id": "2022-05-12"
    },
    {
      "level": "h2",
      "text": "2022-05-05",
      "id": "2022-05-05"
    },
    {
      "level": "h2",
      "text": "2022-04-29",
      "id": "2022-04-29"
    },
    {
      "level": "h2",
      "text": "2022-04-22",
      "id": "2022-04-22"
    },
    {
      "level": "h2",
      "text": "2022-04-14",
      "id": "2022-04-14"
    },
    {
      "level": "h2",
      "text": "2022-04-08",
      "id": "2022-04-08"
    },
    {
      "level": "h2",
      "text": "2022-03-24",
      "id": "2022-03-24"
    },
    {
      "level": "h2",
      "text": "2022-03-17",
      "id": "2022-03-17"
    },
    {
      "level": "h2",
      "text": "2022-03-11",
      "id": "2022-03-11"
    },
    {
      "level": "h2",
      "text": "2022-03-04",
      "id": "2022-03-04"
    },
    {
      "level": "h2",
      "text": "2022-02-25",
      "id": "2022-02-25"
    },
    {
      "level": "h2",
      "text": "2022-02-18",
      "id": "2022-02-18"
    },
    {
      "level": "h2",
      "text": "2022-02-11",
      "id": "2022-02-11"
    },
    {
      "level": "h2",
      "text": "2022-02-05",
      "id": "2022-02-05"
    },
    {
      "level": "h2",
      "text": "2022-01-28",
      "id": "2022-01-28"
    },
    {
      "level": "h2",
      "text": "2022-01-20",
      "id": "2022-01-20"
    },
    {
      "level": "h2",
      "text": "2022-01-17",
      "id": "2022-01-17"
    },
    {
      "level": "h2",
      "text": "2022-01-07",
      "id": "2022-01-07"
    },
    {
      "level": "h2",
      "text": "2021-12-22",
      "id": "2021-12-22"
    },
    {
      "level": "h2",
      "text": "2021-12-10",
      "id": "2021-12-10"
    },
    {
      "level": "h2",
      "text": "2021-12-02",
      "id": "2021-12-02"
    },
    {
      "level": "h2",
      "text": "2021-11-19",
      "id": "2021-11-19"
    },
    {
      "level": "h2",
      "text": "2021-11-12",
      "id": "2021-11-12"
    },
    {
      "level": "h2",
      "text": "2021-11-05",
      "id": "2021-11-05"
    },
    {
      "level": "h2",
      "text": "2021-10-21",
      "id": "2021-10-21"
    },
    {
      "level": "h2",
      "text": "2021-10-14",
      "id": "2021-10-14"
    },
    {
      "level": "h2",
      "text": "2021-09-24",
      "id": "2021-09-24"
    },
    {
      "level": "h2",
      "text": "2021-09-03",
      "id": "2021-09-03"
    },
    {
      "level": "h2",
      "text": "2021-08-05",
      "id": "2021-08-05"
    },
    {
      "level": "h2",
      "text": "2021-07-30",
      "id": "2021-07-30"
    },
    {
      "level": "h2",
      "text": "2021-07-23",
      "id": "2021-07-23"
    },
    {
      "level": "h2",
      "text": "2021-07-16",
      "id": "2021-07-16"
    },
    {
      "level": "h2",
      "text": "2021-07-13",
      "id": "2021-07-13"
    },
    {
      "level": "h2",
      "text": "2021-07-01",
      "id": "2021-07-01"
    },
    {
      "level": "h2",
      "text": "2021-06-27",
      "id": "2021-06-27"
    },
    {
      "level": "h2",
      "text": "2021-06-17",
      "id": "2021-06-17"
    },
    {
      "level": "h2",
      "text": "2021-06-11",
      "id": "2021-06-11"
    },
    {
      "level": "h2",
      "text": "2021-06-04",
      "id": "2021-06-04"
    },
    {
      "level": "h2",
      "text": "2021-05-14",
      "id": "2021-05-14"
    },
    {
      "level": "h2",
      "text": "2021-04-29",
      "id": "2021-04-29"
    },
    {
      "level": "h2",
      "text": "2021-04-23",
      "id": "2021-04-23"
    },
    {
      "level": "h2",
      "text": "2021-04-19",
      "id": "2021-04-19"
    },
    {
      "level": "h2",
      "text": "2021-03-26",
      "id": "2021-03-26"
    },
    {
      "level": "h2",
      "text": "2021-03-11",
      "id": "2021-03-11"
    },
    {
      "level": "h2",
      "text": "2021-02-11",
      "id": "2021-02-11"
    },
    {
      "level": "h2",
      "text": "2021-02-05",
      "id": "2021-02-05"
    },
    {
      "level": "h2",
      "text": "2021-01-22",
      "id": "2021-01-22"
    },
    {
      "level": "h2",
      "text": "2021-01-14",
      "id": "2021-01-14"
    },
    {
      "level": "h2",
      "text": "2021-01-07",
      "id": "2021-01-07"
    },
    {
      "level": "h2",
      "text": "2020-12-10",
      "id": "2020-12-10"
    },
    {
      "level": "h2",
      "text": "2019-09-19",
      "id": "2019-09-19"
    },
    {
      "level": "h2",
      "text": "2020-12-04",
      "id": "2020-12-04"
    },
    {
      "level": "h2",
      "text": "2020-11-13",
      "id": "2020-11-13"
    },
    {
      "level": "h2",
      "text": "2020-11-05",
      "id": "2020-11-05"
    },
    {
      "level": "h2",
      "text": "2020-10-05",
      "id": "2020-10-05"
    },
    {
      "level": "h2",
      "text": "2020-09-24",
      "id": "2020-09-24"
    },
    {
      "level": "h2",
      "text": "2020-08-03",
      "id": "2020-08-03"
    },
    {
      "level": "h2",
      "text": "2020-07-09",
      "id": "2020-07-09"
    },
    {
      "level": "h2",
      "text": "2020-05-15",
      "id": "2020-05-15"
    },
    {
      "level": "h2",
      "text": "2020-04-20",
      "id": "2020-04-20"
    },
    {
      "level": "h2",
      "text": "2020-03-26",
      "id": "2020-03-26"
    },
    {
      "level": "h2",
      "text": "2020-02-28",
      "id": "2020-02-28"
    },
    {
      "level": "h2",
      "text": "2020-02-13",
      "id": "2020-02-13"
    },
    {
      "level": "h2",
      "text": "2020-01-24",
      "id": "2020-01-24"
    },
    {
      "level": "h2",
      "text": "2019-12-12",
      "id": "2019-12-12"
    },
    {
      "level": "h2",
      "text": "2019-12-06",
      "id": "2019-12-06"
    },
    {
      "level": "h3",
      "text": "Interface",
      "id": "interface"
    },
    {
      "level": "h2",
      "text": "Get started",
      "id": "get-started"
    },
    {
      "level": "h2",
      "text": "Configuration",
      "id": "configuration"
    },
    {
      "level": "h2",
      "text": "Best practices",
      "id": "best-practices"
    },
    {
      "level": "h2",
      "text": "Locality",
      "id": "locality"
    },
    {
      "level": "h2",
      "text": "Performance",
      "id": "performance"
    },
    {
      "level": "h2",
      "text": "Accuracy",
      "id": "accuracy"
    },
    {
      "level": "h2",
      "text": "Examples",
      "id": "examples"
    },
    {
      "level": "h2",
      "text": "About Service bindings",
      "id": "about-service-bindings"
    },
    {
      "level": "h2",
      "text": "Configuration",
      "id": "configuration"
    },
    {
      "level": "h2",
      "text": "Interfaces",
      "id": "interfaces"
    },
    {
      "level": "h2",
      "text": "Example — build your first Service binding using RPC",
      "id": "example-—-build-your-first-service-binding-using-rpc"
    },
    {
      "level": "h2",
      "text": "Lifecycle",
      "id": "lifecycle"
    },
    {
      "level": "h2",
      "text": "Local development",
      "id": "local-development"
    },
    {
      "level": "h2",
      "text": "Deployment",
      "id": "deployment"
    },
    {
      "level": "h2",
      "text": "Smart Placement",
      "id": "smart-placement"
    },
    {
      "level": "h2",
      "text": "Limits",
      "id": "limits"
    },
    {
      "level": "h3",
      "text": "Interface",
      "id": "interface"
    },
    {
      "level": "h2",
      "text": "Configuration",
      "id": "configuration"
    },
    {
      "level": "h2",
      "text": "API Reference",
      "id": "api-reference"
    },
    {
      "level": "h3",
      "text": "`get`",
      "id": "`get`"
    },
    {
      "level": "h3",
      "text": "`WorkerCode`",
      "id": "`workercode`"
    },
    {
      "level": "h2",
      "text": "Background",
      "id": "background"
    },
    {
      "level": "h3",
      "text": "Parameters",
      "id": "parameters"
    },
    {
      "level": "h2",
      "text": "Background",
      "id": "background"
    },
    {
      "level": "h2",
      "text": "Syntax",
      "id": "syntax"
    },
    {
      "level": "h3",
      "text": "Properties",
      "id": "properties"
    },
    {
      "level": "h3",
      "text": "Methods",
      "id": "methods"
    },
    {
      "level": "h2",
      "text": "Background",
      "id": "background"
    },
    {
      "level": "h2",
      "text": "Syntax",
      "id": "syntax"
    },
    {
      "level": "h3",
      "text": "Parameters",
      "id": "parameters"
    },
    {
      "level": "h3",
      "text": "Properties",
      "id": "properties"
    },
    {
      "level": "h3",
      "text": "`TailItems`",
      "id": "`tailitems`"
    },
    {
      "level": "h3",
      "text": "`FetchEventInfo`",
      "id": "`fetcheventinfo`"
    },
    {
      "level": "h3",
      "text": "`TailRequest`",
      "id": "`tailrequest`"
    },
    {
      "level": "h3",
      "text": "`TailResponse`",
      "id": "`tailresponse`"
    },
    {
      "level": "h3",
      "text": "`TailLog`",
      "id": "`taillog`"
    },
    {
      "level": "h3",
      "text": "`TailException`",
      "id": "`tailexception`"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Background",
      "id": "background"
    },
    {
      "level": "h2",
      "text": "Constructor",
      "id": "constructor"
    },
    {
      "level": "h2",
      "text": "Methods",
      "id": "methods"
    },
    {
      "level": "h2",
      "text": "Static Methods",
      "id": "static-methods"
    },
    {
      "level": "h2",
      "text": "Examples",
      "id": "examples"
    },
    {
      "level": "h3",
      "text": "Fetch Listener",
      "id": "fetch-listener"
    },
    {
      "level": "h3",
      "text": "Multiple stores",
      "id": "multiple-stores"
    },
    {
      "level": "h3",
      "text": "Unhandled Rejections",
      "id": "unhandled-rejections"
    },
    {
      "level": "h3",
      "text": "`AsyncLocalStorage.bind()` and `AsyncLocalStorage.snapshot()`",
      "id": "`asynclocalstorage.bind()`-and-`asynclocalstorage.snapshot()`"
    },
    {
      "level": "h2",
      "text": "`AsyncResource`",
      "id": "`asyncresource`"
    },
    {
      "level": "h3",
      "text": "Constructor",
      "id": "constructor"
    },
    {
      "level": "h3",
      "text": "Methods",
      "id": "methods"
    },
    {
      "level": "h2",
      "text": "Caveats",
      "id": "caveats"
    },
    {
      "level": "h2",
      "text": "Integration with Tail Workers",
      "id": "integration-with-tail-workers"
    },
    {
      "level": "h2",
      "text": "`TracingChannel`",
      "id": "`tracingchannel`"
    },
    {
      "level": "h2",
      "text": "Compatibility flags",
      "id": "compatibility-flags"
    },
    {
      "level": "h3",
      "text": "Client-side methods",
      "id": "client-side-methods"
    },
    {
      "level": "h3",
      "text": "Server-side methods",
      "id": "server-side-methods"
    },
    {
      "level": "h2",
      "text": "get",
      "id": "get"
    },
    {
      "level": "h2",
      "text": "request",
      "id": "request"
    },
    {
      "level": "h2",
      "text": "OutgoingMessage",
      "id": "outgoingmessage"
    },
    {
      "level": "h2",
      "text": "IncomingMessage",
      "id": "incomingmessage"
    },
    {
      "level": "h2",
      "text": "Agent",
      "id": "agent"
    },
    {
      "level": "h2",
      "text": "createServer",
      "id": "createserver"
    },
    {
      "level": "h2",
      "text": "Node.js integration",
      "id": "node.js-integration"
    },
    {
      "level": "h3",
      "text": "httpServerHandler",
      "id": "httpserverhandler"
    },
    {
      "level": "h3",
      "text": "handleAsNodeRequest",
      "id": "handleasnoderequest"
    },
    {
      "level": "h2",
      "text": "Server",
      "id": "server"
    },
    {
      "level": "h2",
      "text": "ServerResponse",
      "id": "serverresponse"
    },
    {
      "level": "h2",
      "text": "Other differences between Node.js and Workers implementation of `node:http`",
      "id": "other-differences-between-node.js-and-workers-implementation-of-`node:http`"
    },
    {
      "level": "h2",
      "text": "Compatibility flags",
      "id": "compatibility-flags"
    },
    {
      "level": "h3",
      "text": "Client-side methods",
      "id": "client-side-methods"
    },
    {
      "level": "h3",
      "text": "Server-side methods",
      "id": "server-side-methods"
    },
    {
      "level": "h2",
      "text": "get",
      "id": "get"
    },
    {
      "level": "h2",
      "text": "request",
      "id": "request"
    },
    {
      "level": "h2",
      "text": "createServer",
      "id": "createserver"
    },
    {
      "level": "h2",
      "text": "Agent",
      "id": "agent"
    },
    {
      "level": "h2",
      "text": "Server",
      "id": "server"
    },
    {
      "level": "h2",
      "text": "Other differences between Node.js and Workers implementation of `node:https`",
      "id": "other-differences-between-node.js-and-workers-implementation-of-`node:https`"
    },
    {
      "level": "h2",
      "text": "`process.env`",
      "id": "`process.env`"
    },
    {
      "level": "h3",
      "text": "Alternative: Import `env` from `cloudflare:workers`",
      "id": "alternative:-import-`env`-from-`cloudflare:workers`"
    },
    {
      "level": "h2",
      "text": "`process.nextTick()`",
      "id": "`process.nexttick()`"
    },
    {
      "level": "h2",
      "text": "Stdio",
      "id": "stdio"
    },
    {
      "level": "h2",
      "text": "Current Working Directory",
      "id": "current-working-directory"
    },
    {
      "level": "h2",
      "text": "Hrtime",
      "id": "hrtime"
    },
    {
      "level": "h2",
      "text": "`MockTracker`",
      "id": "`mocktracker`"
    },
    {
      "level": "h2",
      "text": "promisify/callbackify",
      "id": "promisify/callbackify"
    },
    {
      "level": "h2",
      "text": "util.types",
      "id": "util.types"
    },
    {
      "level": "h2",
      "text": "util.MIMEType",
      "id": "util.mimetype"
    },
    {
      "level": "h2",
      "text": "domainToASCII",
      "id": "domaintoascii"
    },
    {
      "level": "h2",
      "text": "domainToUnicode",
      "id": "domaintounicode"
    },
    {
      "level": "h2",
      "text": "Exceptions",
      "id": "exceptions"
    },
    {
      "level": "h3",
      "text": "Unsupported error types",
      "id": "unsupported-error-types"
    },
    {
      "level": "h2",
      "text": "Additional properties",
      "id": "additional-properties"
    },
    {
      "level": "h2",
      "text": "Lifetimes, Memory and Resource Management",
      "id": "lifetimes,-memory-and-resource-management"
    },
    {
      "level": "h2",
      "text": "Explicit Resource Management",
      "id": "explicit-resource-management"
    },
    {
      "level": "h3",
      "text": "How to use the `using` declaration in your Worker",
      "id": "how-to-use-the-`using`-declaration-in-your-worker"
    },
    {
      "level": "h2",
      "text": "Automatic disposal and execution contexts",
      "id": "automatic-disposal-and-execution-contexts"
    },
    {
      "level": "h3",
      "text": "End of event handler / execution context",
      "id": "end-of-event-handler-/-execution-context"
    },
    {
      "level": "h3",
      "text": "Stubs received as parameters in an RPC call",
      "id": "stubs-received-as-parameters-in-an-rpc-call"
    },
    {
      "level": "h3",
      "text": "Disposing RPC objects disposes stubs that are part of that object",
      "id": "disposing-rpc-objects-disposes-stubs-that-are-part-of-that-object"
    },
    {
      "level": "h2",
      "text": "Disposers and `RpcTarget` classes",
      "id": "disposers-and-`rpctarget`-classes"
    },
    {
      "level": "h2",
      "text": "The `dup()` method",
      "id": "the-`dup()`-method"
    },
    {
      "level": "h2",
      "text": "Special Methods",
      "id": "special-methods"
    },
    {
      "level": "h3",
      "text": "`fetch()`",
      "id": "`fetch()`"
    },
    {
      "level": "h3",
      "text": "`connect()`",
      "id": "`connect()`"
    },
    {
      "level": "h2",
      "text": "Disallowed Method Names",
      "id": "disallowed-method-names"
    },
    {
      "level": "h2",
      "text": "Security Model",
      "id": "security-model"
    },
    {
      "level": "h2",
      "text": "Visibility of Methods and Properties",
      "id": "visibility-of-methods-and-properties"
    },
    {
      "level": "h3",
      "text": "Private properties",
      "id": "private-properties"
    },
    {
      "level": "h3",
      "text": "Class instance properties",
      "id": "class-instance-properties"
    },
    {
      "level": "h3",
      "text": "\"Own\" properties of functions",
      "id": "\"own\"-properties-of-functions"
    },
    {
      "level": "h2",
      "text": "Background",
      "id": "background"
    },
    {
      "level": "h2",
      "text": "Properties",
      "id": "properties"
    },
    {
      "level": "h2",
      "text": "Methods",
      "id": "methods"
    },
    {
      "level": "h3",
      "text": "`PipeToOptions`",
      "id": "`pipetooptions`"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Background",
      "id": "background"
    },
    {
      "level": "h2",
      "text": "Methods",
      "id": "methods"
    },
    {
      "level": "h2",
      "text": "Common issues",
      "id": "common-issues"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Background",
      "id": "background"
    },
    {
      "level": "h2",
      "text": "Properties",
      "id": "properties"
    },
    {
      "level": "h2",
      "text": "Methods",
      "id": "methods"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Background",
      "id": "background"
    },
    {
      "level": "h2",
      "text": "Constructor",
      "id": "constructor"
    },
    {
      "level": "h2",
      "text": "Properties",
      "id": "properties"
    },
    {
      "level": "h2",
      "text": "`IdentityTransformStream`",
      "id": "`identitytransformstream`"
    },
    {
      "level": "h3",
      "text": "Constructor",
      "id": "constructor"
    },
    {
      "level": "h3",
      "text": "Properties",
      "id": "properties"
    },
    {
      "level": "h2",
      "text": "`FixedLengthStream`",
      "id": "`fixedlengthstream`"
    },
    {
      "level": "h3",
      "text": "Constructor",
      "id": "constructor"
    },
    {
      "level": "h3",
      "text": "Properties",
      "id": "properties"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Background",
      "id": "background"
    },
    {
      "level": "h2",
      "text": "Properties",
      "id": "properties"
    },
    {
      "level": "h2",
      "text": "Methods",
      "id": "methods"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Background",
      "id": "background"
    },
    {
      "level": "h2",
      "text": "Properties",
      "id": "properties"
    },
    {
      "level": "h2",
      "text": "Methods",
      "id": "methods"
    },
    {
      "level": "h2",
      "text": "Related resources",
      "id": "related-resources"
    },
    {
      "level": "h2",
      "text": "Simple Wasm Module",
      "id": "simple-wasm-module"
    },
    {
      "level": "h2",
      "text": "Bundling",
      "id": "bundling"
    },
    {
      "level": "h2",
      "text": "Use from JavaScript",
      "id": "use-from-javascript"
    },
    {
      "level": "h2",
      "text": "Next steps",
      "id": "next-steps"
    },
    {
      "level": "h2",
      "text": "Installation",
      "id": "installation"
    },
    {
      "level": "h2",
      "text": "Usage",
      "id": "usage"
    },
    {
      "level": "h3",
      "text": "String and File Scripts",
      "id": "string-and-file-scripts"
    },
    {
      "level": "h3",
      "text": "Watching, Reloading and Disposing",
      "id": "watching,-reloading-and-disposing"
    },
    {
      "level": "h3",
      "text": "Updating Options and the Global Scope",
      "id": "updating-options-and-the-global-scope"
    },
    {
      "level": "h3",
      "text": "Dispatching Events",
      "id": "dispatching-events"
    },
    {
      "level": "h3",
      "text": "HTTP Server",
      "id": "http-server"
    },
    {
      "level": "h3",
      "text": "HTTPS Server",
      "id": "https-server"
    },
    {
      "level": "h3",
      "text": "Logging",
      "id": "logging"
    },
    {
      "level": "h2",
      "text": "Reference",
      "id": "reference"
    },
    {
      "level": "h2",
      "text": "Interacting with Bindings",
      "id": "interacting-with-bindings"
    },
    {
      "level": "h2",
      "text": "More complex Workers",
      "id": "more-complex-workers"
    },
    {
      "level": "h2",
      "text": "Custom builds",
      "id": "custom-builds"
    },
    {
      "level": "h2",
      "text": "Open inspector with Vitest",
      "id": "open-inspector-with-vitest"
    },
    {
      "level": "h2",
      "text": "Customize the inspector port",
      "id": "customize-the-inspector-port"
    },
    {
      "level": "h2",
      "text": "Setup VS Code to use breakpoints",
      "id": "setup-vs-code-to-use-breakpoints"
    },
    {
      "level": "h2",
      "text": "APIs",
      "id": "apis"
    },
    {
      "level": "h3",
      "text": "`defineWorkersConfig(options)`",
      "id": "`defineworkersconfig(options)`"
    },
    {
      "level": "h3",
      "text": "`defineWorkersProject(options)`",
      "id": "`defineworkersproject(options)`"
    },
    {
      "level": "h3",
      "text": "`buildPagesASSETSBinding(assetsPath)`",
      "id": "`buildpagesassetsbinding(assetspath)`"
    },
    {
      "level": "h3",
      "text": "`readD1Migrations(migrationsPath)`",
      "id": "`readd1migrations(migrationspath)`"
    },
    {
      "level": "h2",
      "text": "`WorkersPoolOptions`",
      "id": "`workerspooloptions`"
    },
    {
      "level": "h2",
      "text": "`WorkersPoolOptionsContext`",
      "id": "`workerspooloptionscontext`"
    },
    {
      "level": "h2",
      "text": "`SourcelessWorkerOptions`",
      "id": "`sourcelessworkeroptions`"
    },
    {
      "level": "h2",
      "text": "Run tests",
      "id": "run-tests"
    },
    {
      "level": "h2",
      "text": "Isolation and concurrency models",
      "id": "isolation-and-concurrency-models"
    },
    {
      "level": "h3",
      "text": "`isolatedStorage: true, singleWorker: false` (Default)",
      "id": "`isolatedstorage:-true,-singleworker:-false`-(default)"
    },
    {
      "level": "h3",
      "text": "`isolatedStorage: true, singleWorker: true`",
      "id": "`isolatedstorage:-true,-singleworker:-true`"
    },
    {
      "level": "h3",
      "text": "`isolatedStorage: false, singleWorker: false`",
      "id": "`isolatedstorage:-false,-singleworker:-false`"
    },
    {
      "level": "h3",
      "text": "`isolatedStorage: false, singleWorker: true`",
      "id": "`isolatedstorage:-false,-singleworker:-true`"
    },
    {
      "level": "h2",
      "text": "Modules",
      "id": "modules"
    }
  ],
  "url": "llms-txt#to_js-converts-between-python-dictionaries-and-javascript-objects",
  "links": []
}